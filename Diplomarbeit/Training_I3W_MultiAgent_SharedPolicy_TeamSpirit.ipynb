{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING I3W\n",
    "\n",
    "\n",
    "# A) Create Envorinment, Vehicles etc\n",
    "\n",
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scenarios:\n",
      "['Scenario', 'BayBridgeScenario', 'BayBridgeTollScenario', 'BottleneckScenario', 'Figure8Scenario', 'SimpleGridScenario', 'HighwayScenario', 'LoopScenario', 'MergeScenario', 'TwoLoopsOneMergingScenario', 'MultiLoopScenario', 'IntersectionScenarioTW']\n",
      "\n",
      "Available environments:\n",
      "['MultiEnv', 'MultiAgentAccelEnv', 'MultiWaveAttenuationPOEnv', 'MultiAgentIntersectionEnv', 'MultiAgentTeamSpiritIntersectionEnv', 'MultiAgentIntersectionEnv_baseline_1', 'MultiAgentIntersectionEnv_baseline_2', 'MultiAgentIntersectionEnv_baseline_3', 'MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit']\n"
     ]
    }
   ],
   "source": [
    "# Define horizon as a variable to ensure consistent use across notebook (length of one rollout)\n",
    "HORIZON=500                                 #103 max Horizon, wenn es vor verlassen abbrechen soll!, default war 500\n",
    "\n",
    "# name of the experiment\n",
    "experiment_name = \"IntersectionExample\"\n",
    "\n",
    "# scenario class\n",
    "import flow.scenarios as scenarios\n",
    "print(\"Available scenarios:\")\n",
    "print(scenarios.__all__)\n",
    "scenario_name = \"IntersectionTWScenario\"\n",
    "\n",
    "# environment class\n",
    "import flow.multiagent_envs as flowenvs\n",
    "print(\"\\nAvailable environments:\")\n",
    "print(flowenvs.__all__)\n",
    "env_name = \"MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import NetParams\n",
    "from flow.scenarios.intersection import ADDITIONAL_NET_PARAMS\n",
    "\n",
    "additionalNetParams = {\n",
    "            \"edge_length\": 40,\n",
    "            \"lanes\": 1,\n",
    "            \"speed_limit\": 30\n",
    "        }\n",
    "\n",
    "net_params = NetParams( no_internal_links=False,                  #default: True   !! damit Kreuzungen nicht Ã¼berspr. werden\n",
    "                        inflows=None,                             #default: None\n",
    "                        osm_path=None,                            #default: None\n",
    "                        netfile=None,                             #default: None\n",
    "                        additional_params=additionalNetParams     #default: None   !!\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitialConfig Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import InitialConfig\n",
    "\n",
    "initial_config = InitialConfig( shuffle=True,                            #default: False         !!\n",
    "                                spacing=\"custom\",                        #default: \"uniform\"     !!\n",
    "                                min_gap=10,                              #default: 0\n",
    "                                perturbation=29.99,                      #default: 0.0            !!        \n",
    "                                x0=0,                                    #default: 0\n",
    "                                bunching=0,                              #default: 0\n",
    "                                lanes_distribution=float(\"inf\"),         #default: float(\"inf\")\n",
    "                                edges_distribution=\"all\",                #default: \"all\"\n",
    "                                additional_params=None )                 #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMO Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sumo_params = SumoParams( port = None,                  #default: None\n",
    "                          sim_step=0.1,                 #default: 0.1\n",
    "                          emission_path=None,           #default: None\n",
    "                          lateral_resolution=None,      #default: None\n",
    "                          no_step_log=True,             #default: True\n",
    "                          render=False,                 #default: False\n",
    "                          save_render=False,            #default: False\n",
    "                          sight_radius=25,              #default: 25\n",
    "                          show_radius=False,            #default: False\n",
    "                          pxpm=2,                       #default: 2\n",
    "                          overtake_right=False,         #default: False    \n",
    "                          seed=None,                    #default: None\n",
    "                          restart_instance=False,       #default: False\n",
    "                          print_warnings=True,          #default: True\n",
    "                          teleport_time=-1,             #default: -1\n",
    "                          num_clients=1,                #default: 1\n",
    "                          sumo_binary=None )            #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "additionalEnvParams = {\n",
    "        # maximum acceleration of autonomous vehicles\n",
    "        \"max_accel\": 3,\n",
    "        # maximum deceleration of autonomous vehicles\n",
    "        \"max_decel\": 3,\n",
    "        # desired velocity for all vehicles in the network, in m/s\n",
    "        \"target_velocity\": 30,\n",
    "        # initial teamspirit\n",
    "        \"ap_teamspirit_0\": -1,\n",
    "        \"ap_teamspirit_1\": -1,\n",
    "        # shuffle teamspirit?\n",
    "        \"ap_teamspirit_shuffle\": True    \n",
    "    }\n",
    "\n",
    "env_params = EnvParams( additional_params=additionalEnvParams, #default: None    !!\n",
    "                        horizon=HORIZON,                       #default: 500     !!\n",
    "                        warmup_steps=0,                        #default: 0       \n",
    "                        sims_per_step=1,                       #default: 1\n",
    "                        evaluate=False )                       #default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import VehicleParams\n",
    "\n",
    "# import vehicles dynamics models\n",
    "#from flow.controllers import SumoCarFollowingController\n",
    "from flow.controllers import ContinuousRouter\n",
    "#from flow.controllers.lane_change_controllers import SumoLaneChangeController\n",
    "from flow.controllers.lane_change_controllers import StaticLaneChanger\n",
    "from flow.controllers import RLController\n",
    "from flow.core.params import SumoLaneChangeParams\n",
    "from flow.core.params import SumoCarFollowingParams\n",
    "from random import *\n",
    "\n",
    "vehicles = VehicleParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add RL-Agent controlled vehicles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car following parameters, default: None\n",
    "cf_parameter = SumoCarFollowingParams(\n",
    "                speed_mode=\"aggressive\")\n",
    "# lane change parameters, default: None\n",
    "lc_parameter =  None\n",
    "\n",
    "vehicles.add( # name of the vehicle\n",
    "                veh_id = \"rl\",\n",
    "              # acceleration controller, default: (SumoCarFollowingController, {})\n",
    "                acceleration_controller=(RLController, {}),\n",
    "              # lane_change_controller, default: (SumoLaneChangeController, {})\n",
    "                lane_change_controller=(StaticLaneChanger,{}),\n",
    "              # routing controller, default: None\n",
    "                routing_controller=(ContinuousRouter, {}),\n",
    "              # initial speed, default: 0\n",
    "                initial_speed=0,\n",
    "              # number of vehicles, default: 1 \n",
    "                num_vehicles=2,\n",
    "                \n",
    "                car_following_params=cf_parameter\n",
    "              # speed mode, default: \"right_of_way\"\n",
    "                #speed_mode=\"aggressive\",\n",
    "              # lane change mode, default: \"no_lat_collide\"\n",
    "                #lane_change_mode=\"aggressive\", \n",
    "              # car following parameter, default: None\n",
    "                #sumo_car_following_params=cf_parameter,\n",
    "              # lane change parameter, default: None\n",
    "                #sumo_lc_params=lc_parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict( # name of the experiment\n",
    "                      exp_tag=experiment_name,\n",
    "                    # name of the flow environment the experiment is running on\n",
    "                      env_name=env_name,\n",
    "                    # name of the scenario class the experiment uses\n",
    "                      scenario=scenario_name,\n",
    "                    # simulator that is used by the experiment\n",
    "                      simulator='traci',\n",
    "                    # sumo-related parameters (see flow.core.params.SumoParams)\n",
    "                      sim=sumo_params,\n",
    "                    # environment related parameters (see flow.core.params.EnvParams)\n",
    "                      env=env_params,\n",
    "                    # network-related parameters (see flow.core.params.NetParams and\n",
    "                    # the scenario's documentation or ADDITIONAL_NET_PARAMS component)\n",
    "                      net=net_params,\n",
    "                    # vehicles to be placed in the network at the start of a rollout \n",
    "                    # (see flow.core.vehicles.Vehicles)\n",
    "                      veh=vehicles,\n",
    "                   # (optional) parameters affecting the positioning of vehicles upon \n",
    "                   # initialization/reset (see flow.core.params.InitialConfig)\n",
    "                      initial=initial_config\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo.ppo_policy_graph import PPOPolicyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-03-30_18-08-52_7633/logs.\n",
      "Waiting for redis server at 127.0.0.1:42231 to respond...\n",
      "Waiting for redis server at 127.0.0.1:50969 to respond...\n",
      "Starting the Plasma object store with 6.554658406 GB memory using /dev/shm.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=e780c08def7cacb64256967715c94ae4cfd2fb06f11817b8\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.2.102',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-03-30_18-08-52_7633/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-03-30_18-08-52_7633/sockets/raylet'],\n",
       " 'redis_address': '192.168.2.102:42231',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui.ipynb?token=e780c08def7cacb64256967715c94ae4cfd2fb06f11817b8'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "N_CPUS = 2\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 20\n",
    "\n",
    "ray.init(redirect_output=True, num_cpus=N_CPUS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm or model to train. This may refer to \"\n",
    "#      \"the name of a built-on algorithm (e.g. RLLib's DQN \"\n",
    "#      \"or PPO), or a user-defined trainable function or \"\n",
    "#      \"class registered in the tune registry.\")\n",
    "alg_run = \"PPO\"\n",
    "\n",
    "agent_cls = get_agent_class(alg_run)\n",
    "config = agent_cls._default_config.copy()\n",
    "config[\"num_workers\"] = N_CPUS  # number of parallel workers\n",
    "config[\"train_batch_size\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.999  # discount rate default 0.999\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [100, 50, 25]})  # size of hidden layers in network defaule 64 32\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "#config[\"sgd_minibatch_size\"] = min(16 * 1024, config[\"train_batch_size\"])  # stochastic gradient descent\n",
    "#config[\"sample_batch_size\"] = config[\"train_batch_size\"]/config[\"num_workers\"] # 200 default, trotzdem zu hoch?\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "config['env_config']['run'] = alg_run\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, gym_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(gym_name, create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Starting SUMO on port 55245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Teamspirit:\n",
      "-0.5393521226962619\n",
      "0.17788004549039993\n"
     ]
    }
   ],
   "source": [
    "# multi agent policy mapping\n",
    "test_env = create_env()\n",
    "obs_space = test_env.observation_space\n",
    "act_space = test_env.action_space\n",
    "\n",
    "def gen_policy():\n",
    "    return (PPOPolicyGraph, obs_space, act_space, {})\n",
    "\n",
    "# Setup PG with an ensemble of `num_policies` different policy graphs\n",
    "policy_graphs = {'rl_0': gen_policy()}\n",
    "    \n",
    "def policy_mapping_fn(agent_id):\n",
    "    return 'rl_0'\n",
    "\n",
    "config.update({\n",
    "        'multiagent': {\n",
    "            'policy_graphs': policy_graphs,\n",
    "            'policy_mapping_fn': tune.function(policy_mapping_fn),\n",
    "            'policies_to_train': ['rl_0']\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "\n",
      "Created LogSyncer for /home/thorsten/ray_results/IntersectionExample/PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0_2019-03-30_18-08-54osfmm20k -> \n",
      "WARNING: Falling back to serializing objects of type <class 'numpy.dtype'> by using pickle. This may be inefficient.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-09-44\n",
      "  done: false\n",
      "  episode_len_mean: 450.3333333333333\n",
      "  episode_reward_max: 446.540044230622\n",
      "  episode_reward_mean: 237.318160124313\n",
      "  episode_reward_min: -65.25893908935677\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 21\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4671.919\n",
      "    load_time_ms: 46.405\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20000004768371582\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.418556571006775\n",
      "      kl: 0.0020502859260886908\n",
      "      policy_loss: -0.002457158640027046\n",
      "      total_loss: 135.7422332763672\n",
      "      vf_explained_var: 0.04143756628036499\n",
      "      vf_loss: 135.74429321289062\n",
      "    sample_time_ms: 19150.262\n",
      "    update_time_ms: 583.397\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 118.6590800621565\n",
      "  time_since_restore: 24.51004672050476\n",
      "  time_this_iter_s: 24.51004672050476\n",
      "  time_total_s: 24.51004672050476\n",
      "  timestamp: 1553965784\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 24 s, 1 iter, 10000 ts, 237 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-10-08\n",
      "  done: false\n",
      "  episode_len_mean: 445.27272727272725\n",
      "  episode_reward_max: 876.3349280441076\n",
      "  episode_reward_mean: 303.3240623070106\n",
      "  episode_reward_min: -83.66525550148691\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 44\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4494.216\n",
      "    load_time_ms: 23.895\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10000002384185791\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4118235111236572\n",
      "      kl: 0.002998586744070053\n",
      "      policy_loss: -0.0017517793457955122\n",
      "      total_loss: 299.04327392578125\n",
      "      vf_explained_var: 0.02320546843111515\n",
      "      vf_loss: 299.0447082519531\n",
      "    sample_time_ms: 19315.08\n",
      "    update_time_ms: 295.548\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 151.66203115350532\n",
      "  time_since_restore: 48.33353853225708\n",
      "  time_this_iter_s: 23.82349181175232\n",
      "  time_total_s: 48.33353853225708\n",
      "  timestamp: 1553965808\n",
      "  timesteps_since_restore: 20000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 48 s, 2 iter, 20000 ts, 303 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-10-32\n",
      "  done: false\n",
      "  episode_len_mean: 408.28767123287673\n",
      "  episode_reward_max: 1167.7209406143381\n",
      "  episode_reward_mean: 328.31595144514466\n",
      "  episode_reward_min: -103.83407176825087\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 73\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4347.037\n",
      "    load_time_ms: 16.516\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.050000011920928955\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4084861278533936\n",
      "      kl: 0.002783587435260415\n",
      "      policy_loss: -0.0015958631411194801\n",
      "      total_loss: 600.8856201171875\n",
      "      vf_explained_var: 0.056993961334228516\n",
      "      vf_loss: 600.8871459960938\n",
      "    sample_time_ms: 19533.445\n",
      "    update_time_ms: 199.696\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 164.15797572257236\n",
      "  time_since_restore: 72.38290619850159\n",
      "  time_this_iter_s: 24.049367666244507\n",
      "  time_total_s: 72.38290619850159\n",
      "  timestamp: 1553965832\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 3\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 72 s, 3 iter, 30000 ts, 328 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-10-57\n",
      "  done: false\n",
      "  episode_len_mean: 403.9591836734694\n",
      "  episode_reward_max: 1167.7209406143381\n",
      "  episode_reward_mean: 412.59495564430813\n",
      "  episode_reward_min: -103.83407176825087\n",
      "  episodes_this_iter: 25\n",
      "  episodes_total: 98\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4288.6\n",
      "    load_time_ms: 12.781\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025000005960464478\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4098886251449585\n",
      "      kl: 0.006980678997933865\n",
      "      policy_loss: -0.0030754273757338524\n",
      "      total_loss: 819.6178588867188\n",
      "      vf_explained_var: 0.03228699788451195\n",
      "      vf_loss: 819.6206665039062\n",
      "    sample_time_ms: 19719.023\n",
      "    update_time_ms: 151.701\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 206.29747782215406\n",
      "  time_since_restore: 96.79816460609436\n",
      "  time_this_iter_s: 24.415258407592773\n",
      "  time_total_s: 96.79816460609436\n",
      "  timestamp: 1553965857\n",
      "  timesteps_since_restore: 40000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 4\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 96 s, 4 iter, 40000 ts, 413 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-11-21\n",
      "  done: false\n",
      "  episode_len_mean: 348.81\n",
      "  episode_reward_max: 1167.7209406143381\n",
      "  episode_reward_mean: 482.5005743946258\n",
      "  episode_reward_min: -103.83407176825087\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 133\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4237.856\n",
      "    load_time_ms: 10.602\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 50000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.012500002980232239\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4035018682479858\n",
      "      kl: 0.007910158485174179\n",
      "      policy_loss: -0.003478365484625101\n",
      "      total_loss: 1120.9227294921875\n",
      "      vf_explained_var: 0.05949464812874794\n",
      "      vf_loss: 1120.926025390625\n",
      "    sample_time_ms: 19900.621\n",
      "    update_time_ms: 123.467\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 241.25028719731293\n",
      "  time_since_restore: 121.49087357521057\n",
      "  time_this_iter_s: 24.69270896911621\n",
      "  time_total_s: 121.49087357521057\n",
      "  timestamp: 1553965881\n",
      "  timesteps_since_restore: 50000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 5\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 121 s, 5 iter, 50000 ts, 483 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-11-46\n",
      "  done: false\n",
      "  episode_len_mean: 317.26\n",
      "  episode_reward_max: 1107.553908557878\n",
      "  episode_reward_mean: 560.8260890809104\n",
      "  episode_reward_min: -93.2680168733728\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 168\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4204.283\n",
      "    load_time_ms: 9.054\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.006250001490116119\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4084738492965698\n",
      "      kl: 0.0033381700050085783\n",
      "      policy_loss: -0.0006521983887068927\n",
      "      total_loss: 1132.5985107421875\n",
      "      vf_explained_var: 0.06029045954346657\n",
      "      vf_loss: 1132.5989990234375\n",
      "    sample_time_ms: 19963.67\n",
      "    update_time_ms: 103.681\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.41304454045513\n",
      "  time_since_restore: 145.82975029945374\n",
      "  time_this_iter_s: 24.338876724243164\n",
      "  time_total_s: 145.82975029945374\n",
      "  timestamp: 1553965906\n",
      "  timesteps_since_restore: 60000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 6\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 145 s, 6 iter, 60000 ts, 561 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-12-10\n",
      "  done: false\n",
      "  episode_len_mean: 275.33\n",
      "  episode_reward_max: 1118.961312085598\n",
      "  episode_reward_mean: 554.0085051617156\n",
      "  episode_reward_min: -69.45696727616061\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 207\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4182.711\n",
      "    load_time_ms: 7.959\n",
      "    num_steps_sampled: 70000\n",
      "    num_steps_trained: 70000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0031250007450580597\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3955869674682617\n",
      "      kl: 0.005806670058518648\n",
      "      policy_loss: -0.0018706312403082848\n",
      "      total_loss: 1468.2860107421875\n",
      "      vf_explained_var: 0.08179561048746109\n",
      "      vf_loss: 1468.287841796875\n",
      "    sample_time_ms: 20037.061\n",
      "    update_time_ms: 89.523\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 277.00425258085784\n",
      "  time_since_restore: 170.38414692878723\n",
      "  time_this_iter_s: 24.554396629333496\n",
      "  time_total_s: 170.38414692878723\n",
      "  timestamp: 1553965930\n",
      "  timesteps_since_restore: 70000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 70000\n",
      "  training_iteration: 7\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 170 s, 7 iter, 70000 ts, 554 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-12-35\n",
      "  done: false\n",
      "  episode_len_mean: 258.39\n",
      "  episode_reward_max: 1118.961312085598\n",
      "  episode_reward_mean: 616.4209182260122\n",
      "  episode_reward_min: -69.45696727616061\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 246\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4167.082\n",
      "    load_time_ms: 7.132\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0015625003725290298\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3900927305221558\n",
      "      kl: 0.006034106481820345\n",
      "      policy_loss: -0.0019657297525554895\n",
      "      total_loss: 1764.03369140625\n",
      "      vf_explained_var: 0.07048988342285156\n",
      "      vf_loss: 1764.03564453125\n",
      "    sample_time_ms: 20064.024\n",
      "    update_time_ms: 78.983\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 308.2104591130062\n",
      "  time_since_restore: 194.71875429153442\n",
      "  time_this_iter_s: 24.334607362747192\n",
      "  time_total_s: 194.71875429153442\n",
      "  timestamp: 1553965955\n",
      "  timesteps_since_restore: 80000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 8\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 194 s, 8 iter, 80000 ts, 616 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-12-58\n",
      "  done: false\n",
      "  episode_len_mean: 236.62\n",
      "  episode_reward_max: 1118.961312085598\n",
      "  episode_reward_mean: 630.3583194523505\n",
      "  episode_reward_min: -72.15936598128272\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 292\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4155.118\n",
      "    load_time_ms: 6.547\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0007812501862645149\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3880422115325928\n",
      "      kl: 0.006215799134224653\n",
      "      policy_loss: -0.00214771693572402\n",
      "      total_loss: 2155.53369140625\n",
      "      vf_explained_var: 0.07274211943149567\n",
      "      vf_loss: 2155.53564453125\n",
      "    sample_time_ms: 20025.282\n",
      "    update_time_ms: 70.921\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 315.17915972617527\n",
      "  time_since_restore: 218.52089595794678\n",
      "  time_this_iter_s: 23.802141666412354\n",
      "  time_total_s: 218.52089595794678\n",
      "  timestamp: 1553965978\n",
      "  timesteps_since_restore: 90000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 9\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 218 s, 9 iter, 90000 ts, 630 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-13-23\n",
      "  done: false\n",
      "  episode_len_mean: 220.34\n",
      "  episode_reward_max: 1124.4251855484695\n",
      "  episode_reward_mean: 652.7648759859258\n",
      "  episode_reward_min: -74.37076037874948\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 339\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4142.643\n",
      "    load_time_ms: 6.095\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00039062509313225746\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.378147006034851\n",
      "      kl: 0.006944714579731226\n",
      "      policy_loss: -0.0013767591444775462\n",
      "      total_loss: 2486.608154296875\n",
      "      vf_explained_var: 0.09663662314414978\n",
      "      vf_loss: 2486.609375\n",
      "    sample_time_ms: 20062.693\n",
      "    update_time_ms: 64.323\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 326.38243799296293\n",
      "  time_since_restore: 242.97802257537842\n",
      "  time_this_iter_s: 24.45712661743164\n",
      "  time_total_s: 242.97802257537842\n",
      "  timestamp: 1553966003\n",
      "  timesteps_since_restore: 100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 10\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 242 s, 10 iter, 100000 ts, 653 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-13-47\n",
      "  done: false\n",
      "  episode_len_mean: 197.98\n",
      "  episode_reward_max: 1124.4251855484695\n",
      "  episode_reward_mean: 623.4015024460542\n",
      "  episode_reward_min: -91.32249735106\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 393\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4081.259\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 110000\n",
      "    num_steps_trained: 110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00019531254656612873\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.372615933418274\n",
      "      kl: 0.0037068778183311224\n",
      "      policy_loss: -0.0013310007052496076\n",
      "      total_loss: 2731.52685546875\n",
      "      vf_explained_var: 0.09271156042814255\n",
      "      vf_loss: 2731.528564453125\n",
      "    sample_time_ms: 20124.788\n",
      "    update_time_ms: 6.625\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 311.70075122302717\n",
      "  time_since_restore: 266.8316864967346\n",
      "  time_this_iter_s: 23.8536639213562\n",
      "  time_total_s: 266.8316864967346\n",
      "  timestamp: 1553966027\n",
      "  timesteps_since_restore: 110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 110000\n",
      "  training_iteration: 11\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 266 s, 11 iter, 110000 ts, 623 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-14-12\n",
      "  done: false\n",
      "  episode_len_mean: 184.25\n",
      "  episode_reward_max: 1091.446712153679\n",
      "  episode_reward_mean: 601.3516656137003\n",
      "  episode_reward_min: -94.5523003784263\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 447\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4055.648\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.765627328306437e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3685457706451416\n",
      "      kl: 0.0033682805951684713\n",
      "      policy_loss: -0.0010617321822792292\n",
      "      total_loss: 2712.84912109375\n",
      "      vf_explained_var: 0.145487442612648\n",
      "      vf_loss: 2712.850341796875\n",
      "    sample_time_ms: 20253.575\n",
      "    update_time_ms: 6.52\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.67583280685017\n",
      "  time_since_restore: 291.684378862381\n",
      "  time_this_iter_s: 24.852692365646362\n",
      "  time_total_s: 291.684378862381\n",
      "  timestamp: 1553966052\n",
      "  timesteps_since_restore: 120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 12\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 291 s, 12 iter, 120000 ts, 601 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-14-37\n",
      "  done: false\n",
      "  episode_len_mean: 200.53\n",
      "  episode_reward_max: 1169.974514875859\n",
      "  episode_reward_mean: 698.1214163881308\n",
      "  episode_reward_min: -94.5523003784263\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 492\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4063.192\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 130000\n",
      "    num_steps_trained: 130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.882813664153218e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3544336557388306\n",
      "      kl: 0.004294034093618393\n",
      "      policy_loss: -0.002004653215408325\n",
      "      total_loss: 2795.1318359375\n",
      "      vf_explained_var: 0.06995104253292084\n",
      "      vf_loss: 2795.1337890625\n",
      "    sample_time_ms: 20336.082\n",
      "    update_time_ms: 6.347\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.0607081940653\n",
      "  time_since_restore: 316.6342475414276\n",
      "  time_this_iter_s: 24.94986867904663\n",
      "  time_total_s: 316.6342475414276\n",
      "  timestamp: 1553966077\n",
      "  timesteps_since_restore: 130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 130000\n",
      "  training_iteration: 13\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 316 s, 13 iter, 130000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-15-02\n",
      "  done: false\n",
      "  episode_len_mean: 201.78\n",
      "  episode_reward_max: 1169.974514875859\n",
      "  episode_reward_mean: 728.2842012595419\n",
      "  episode_reward_min: -88.74630500735947\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 546\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4059.277\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3439167737960815\n",
      "      kl: 0.005454994738101959\n",
      "      policy_loss: -0.002482203533872962\n",
      "      total_loss: 2918.578125\n",
      "      vf_explained_var: 0.10316845029592514\n",
      "      vf_loss: 2918.580810546875\n",
      "    sample_time_ms: 20394.463\n",
      "    update_time_ms: 6.626\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.142100629771\n",
      "  time_since_restore: 341.6013593673706\n",
      "  time_this_iter_s: 24.967111825942993\n",
      "  time_total_s: 341.6013593673706\n",
      "  timestamp: 1553966102\n",
      "  timesteps_since_restore: 140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 14\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 341 s, 14 iter, 140000 ts, 728 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-15-27\n",
      "  done: false\n",
      "  episode_len_mean: 182.49\n",
      "  episode_reward_max: 1137.3333492900995\n",
      "  episode_reward_mean: 600.5218298604285\n",
      "  episode_reward_min: -99.10079973646961\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 601\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4058.143\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2207034160383046e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3493026494979858\n",
      "      kl: 0.008123906329274178\n",
      "      policy_loss: -0.0025888339150696993\n",
      "      total_loss: 2678.32568359375\n",
      "      vf_explained_var: 0.19203856587409973\n",
      "      vf_loss: 2678.328125\n",
      "    sample_time_ms: 20399.428\n",
      "    update_time_ms: 6.179\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.2609149302142\n",
      "  time_since_restore: 366.3282058238983\n",
      "  time_this_iter_s: 24.72684645652771\n",
      "  time_total_s: 366.3282058238983\n",
      "  timestamp: 1553966127\n",
      "  timesteps_since_restore: 150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 15\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 366 s, 15 iter, 150000 ts, 601 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-15-51\n",
      "  done: false\n",
      "  episode_len_mean: 164.07\n",
      "  episode_reward_max: 1137.3333492900995\n",
      "  episode_reward_mean: 561.2787224145716\n",
      "  episode_reward_min: -99.10079973646961\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 664\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4059.883\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.103517080191523e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3213788270950317\n",
      "      kl: 0.004909434821456671\n",
      "      policy_loss: -0.0016000875039026141\n",
      "      total_loss: 3587.86328125\n",
      "      vf_explained_var: 0.16436848044395447\n",
      "      vf_loss: 3587.864990234375\n",
      "    sample_time_ms: 20406.722\n",
      "    update_time_ms: 6.432\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.63936120728584\n",
      "  time_since_restore: 390.7619330883026\n",
      "  time_this_iter_s: 24.433727264404297\n",
      "  time_total_s: 390.7619330883026\n",
      "  timestamp: 1553966151\n",
      "  timesteps_since_restore: 160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 16\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 390 s, 16 iter, 160000 ts, 561 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-16-16\n",
      "  done: false\n",
      "  episode_len_mean: 163.06\n",
      "  episode_reward_max: 1093.2206064303496\n",
      "  episode_reward_mean: 634.8426057010863\n",
      "  episode_reward_min: -69.90847952706781\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 724\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4065.489\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 170000\n",
      "    num_steps_trained: 170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3331423997879028\n",
      "      kl: 0.003791195573285222\n",
      "      policy_loss: -0.0016616288339719176\n",
      "      total_loss: 3419.900146484375\n",
      "      vf_explained_var: 0.24253256618976593\n",
      "      vf_loss: 3419.90185546875\n",
      "    sample_time_ms: 20429.099\n",
      "    update_time_ms: 6.435\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 317.4213028505432\n",
      "  time_since_restore: 415.5955958366394\n",
      "  time_this_iter_s: 24.833662748336792\n",
      "  time_total_s: 415.5955958366394\n",
      "  timestamp: 1553966176\n",
      "  timesteps_since_restore: 170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 170000\n",
      "  training_iteration: 17\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 415 s, 17 iter, 170000 ts, 635 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-16-40\n",
      "  done: false\n",
      "  episode_len_mean: 172.68\n",
      "  episode_reward_max: 1135.7390034070268\n",
      "  episode_reward_mean: 741.3158045137868\n",
      "  episode_reward_min: -70.25249872133617\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 782\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4069.594\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5258792700478807e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3201123476028442\n",
      "      kl: 0.010296789929270744\n",
      "      policy_loss: -0.002825237577781081\n",
      "      total_loss: 4230.44873046875\n",
      "      vf_explained_var: 0.20033973455429077\n",
      "      vf_loss: 4230.45166015625\n",
      "    sample_time_ms: 20451.724\n",
      "    update_time_ms: 6.341\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 370.65790225689335\n",
      "  time_since_restore: 440.19449400901794\n",
      "  time_this_iter_s: 24.59889817237854\n",
      "  time_total_s: 440.19449400901794\n",
      "  timestamp: 1553966200\n",
      "  timesteps_since_restore: 180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 18\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 440 s, 18 iter, 180000 ts, 741 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-17-05\n",
      "  done: false\n",
      "  episode_len_mean: 174.05\n",
      "  episode_reward_max: 1100.518071278912\n",
      "  episode_reward_mean: 744.4812628973922\n",
      "  episode_reward_min: -102.63522018628046\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 840\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4068.794\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 190000\n",
      "    num_steps_trained: 190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5258792700478807e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3551419973373413\n",
      "      kl: 0.004011000972241163\n",
      "      policy_loss: -0.0024431750643998384\n",
      "      total_loss: 3636.780517578125\n",
      "      vf_explained_var: 0.2407255917787552\n",
      "      vf_loss: 3636.782958984375\n",
      "    sample_time_ms: 20519.954\n",
      "    update_time_ms: 6.261\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 372.2406314486961\n",
      "  time_since_restore: 464.66705894470215\n",
      "  time_this_iter_s: 24.472564935684204\n",
      "  time_total_s: 464.66705894470215\n",
      "  timestamp: 1553966225\n",
      "  timesteps_since_restore: 190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 190000\n",
      "  training_iteration: 19\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 464 s, 19 iter, 190000 ts, 744 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-17-30\n",
      "  done: false\n",
      "  episode_len_mean: 161.69\n",
      "  episode_reward_max: 1055.0758131987586\n",
      "  episode_reward_mean: 651.8546477681199\n",
      "  episode_reward_min: -93.33969810887191\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 904\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4068.7\n",
      "    load_time_ms: 1.393\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.629396350239404e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3252969980239868\n",
      "      kl: 0.003184128552675247\n",
      "      policy_loss: -0.0018541094614192843\n",
      "      total_loss: 3558.728271484375\n",
      "      vf_explained_var: 0.20572727918624878\n",
      "      vf_loss: 3558.72998046875\n",
      "    sample_time_ms: 20550.2\n",
      "    update_time_ms: 6.308\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 325.9273238840599\n",
      "  time_since_restore: 489.422367811203\n",
      "  time_this_iter_s: 24.755308866500854\n",
      "  time_total_s: 489.422367811203\n",
      "  timestamp: 1553966250\n",
      "  timesteps_since_restore: 200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 20\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 489 s, 20 iter, 200000 ts, 652 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-17-55\n",
      "  done: false\n",
      "  episode_len_mean: 177.41\n",
      "  episode_reward_max: 1117.115998055278\n",
      "  episode_reward_mean: 706.4820677633584\n",
      "  episode_reward_min: -105.99853480988938\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 957\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4066.175\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.814698175119702e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3743937015533447\n",
      "      kl: 0.004907951690256596\n",
      "      policy_loss: -0.0015779177192598581\n",
      "      total_loss: 3570.87255859375\n",
      "      vf_explained_var: 0.3115931749343872\n",
      "      vf_loss: 3570.87451171875\n",
      "    sample_time_ms: 20644.531\n",
      "    update_time_ms: 6.117\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.2410338816792\n",
      "  time_since_restore: 514.1962866783142\n",
      "  time_this_iter_s: 24.773918867111206\n",
      "  time_total_s: 514.1962866783142\n",
      "  timestamp: 1553966275\n",
      "  timesteps_since_restore: 210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 21\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 514 s, 21 iter, 210000 ts, 706 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-18-19\n",
      "  done: false\n",
      "  episode_len_mean: 177.21\n",
      "  episode_reward_max: 1117.115998055278\n",
      "  episode_reward_mean: 672.6511593510472\n",
      "  episode_reward_min: -105.99853480988938\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 1016\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4063.11\n",
      "    load_time_ms: 1.5\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.907349087559851e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3433706760406494\n",
      "      kl: 0.004157834220677614\n",
      "      policy_loss: -0.002163971308618784\n",
      "      total_loss: 3686.760009765625\n",
      "      vf_explained_var: 0.28146669268608093\n",
      "      vf_loss: 3686.761962890625\n",
      "    sample_time_ms: 20626.799\n",
      "    update_time_ms: 6.148\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.3255796755236\n",
      "  time_since_restore: 538.8489048480988\n",
      "  time_this_iter_s: 24.652618169784546\n",
      "  time_total_s: 538.8489048480988\n",
      "  timestamp: 1553966299\n",
      "  timesteps_since_restore: 220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 22\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 538 s, 22 iter, 220000 ts, 673 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-18-44\n",
      "  done: false\n",
      "  episode_len_mean: 151.15\n",
      "  episode_reward_max: 1080.157129446191\n",
      "  episode_reward_mean: 578.1242244475505\n",
      "  episode_reward_min: -75.09553359567298\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 1084\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4051.386\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 230000\n",
      "    num_steps_trained: 230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.536745437799254e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3104408979415894\n",
      "      kl: 0.0065603842958807945\n",
      "      policy_loss: -0.0026216679252684116\n",
      "      total_loss: 3638.556884765625\n",
      "      vf_explained_var: 0.23309607803821564\n",
      "      vf_loss: 3638.559814453125\n",
      "    sample_time_ms: 20611.38\n",
      "    update_time_ms: 5.974\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 289.06211222377533\n",
      "  time_since_restore: 563.5238656997681\n",
      "  time_this_iter_s: 24.67496085166931\n",
      "  time_total_s: 563.5238656997681\n",
      "  timestamp: 1553966324\n",
      "  timesteps_since_restore: 230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 230000\n",
      "  training_iteration: 23\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 563 s, 23 iter, 230000 ts, 578 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-19-09\n",
      "  done: false\n",
      "  episode_len_mean: 154.7\n",
      "  episode_reward_max: 1058.6276865562245\n",
      "  episode_reward_mean: 627.8558705627042\n",
      "  episode_reward_min: -89.28530344503672\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 1146\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4047.866\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.768372718899627e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3048739433288574\n",
      "      kl: 0.004028727300465107\n",
      "      policy_loss: -0.0012088321382179856\n",
      "      total_loss: 3976.999267578125\n",
      "      vf_explained_var: 0.23903636634349823\n",
      "      vf_loss: 3977.00048828125\n",
      "    sample_time_ms: 20566.532\n",
      "    update_time_ms: 5.437\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.9279352813522\n",
      "  time_since_restore: 587.9968490600586\n",
      "  time_this_iter_s: 24.472983360290527\n",
      "  time_total_s: 587.9968490600586\n",
      "  timestamp: 1553966349\n",
      "  timesteps_since_restore: 240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 24\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 587 s, 24 iter, 240000 ts, 628 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-19-32\n",
      "  done: false\n",
      "  episode_len_mean: 155.01\n",
      "  episode_reward_max: 1088.2855632048638\n",
      "  episode_reward_mean: 626.2367513672536\n",
      "  episode_reward_min: -89.28530344503672\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 1210\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4051.727\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 250000\n",
      "    num_steps_trained: 250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3841863594498136e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3166412115097046\n",
      "      kl: 0.004599244799464941\n",
      "      policy_loss: -0.0019703912548720837\n",
      "      total_loss: 3452.543701171875\n",
      "      vf_explained_var: 0.3251359164714813\n",
      "      vf_loss: 3452.545654296875\n",
      "    sample_time_ms: 20481.049\n",
      "    update_time_ms: 5.378\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.1183756836269\n",
      "  time_since_restore: 611.9039378166199\n",
      "  time_this_iter_s: 23.90708875656128\n",
      "  time_total_s: 611.9039378166199\n",
      "  timestamp: 1553966372\n",
      "  timesteps_since_restore: 250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 250000\n",
      "  training_iteration: 25\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 611 s, 25 iter, 250000 ts, 626 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-19-57\n",
      "  done: false\n",
      "  episode_len_mean: 156.81\n",
      "  episode_reward_max: 1115.8645239982295\n",
      "  episode_reward_mean: 665.6354987230028\n",
      "  episode_reward_min: -88.00339241288304\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 1274\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4051.65\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1920931797249068e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2774176597595215\n",
      "      kl: 0.00881178304553032\n",
      "      policy_loss: -0.0021456796675920486\n",
      "      total_loss: 4391.1689453125\n",
      "      vf_explained_var: 0.2786124050617218\n",
      "      vf_loss: 4391.1708984375\n",
      "    sample_time_ms: 20447.452\n",
      "    update_time_ms: 5.159\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 332.81774936150134\n",
      "  time_since_restore: 635.9997856616974\n",
      "  time_this_iter_s: 24.095847845077515\n",
      "  time_total_s: 635.9997856616974\n",
      "  timestamp: 1553966397\n",
      "  timesteps_since_restore: 260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 26\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 635 s, 26 iter, 260000 ts, 666 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-20-21\n",
      "  done: false\n",
      "  episode_len_mean: 164.67\n",
      "  episode_reward_max: 1115.8645239982295\n",
      "  episode_reward_mean: 755.4745809638499\n",
      "  episode_reward_min: -82.98746330643367\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 1331\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4044.384\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.960465898624534e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.34266197681427\n",
      "      kl: 0.008227948099374771\n",
      "      policy_loss: -0.0024427161552011967\n",
      "      total_loss: 4056.939208984375\n",
      "      vf_explained_var: 0.18927393853664398\n",
      "      vf_loss: 4056.94140625\n",
      "    sample_time_ms: 20396.531\n",
      "    update_time_ms: 5.131\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 377.73729048192484\n",
      "  time_since_restore: 660.2551412582397\n",
      "  time_this_iter_s: 24.25535559654236\n",
      "  time_total_s: 660.2551412582397\n",
      "  timestamp: 1553966421\n",
      "  timesteps_since_restore: 270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 27\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 660 s, 27 iter, 270000 ts, 755 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-20-45\n",
      "  done: false\n",
      "  episode_len_mean: 183.26\n",
      "  episode_reward_max: 1090.550099980552\n",
      "  episode_reward_mean: 762.8092661557192\n",
      "  episode_reward_min: -82.98746330643367\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 1383\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4043.075\n",
      "    load_time_ms: 1.638\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.980232949312267e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3994286060333252\n",
      "      kl: 0.008993882685899734\n",
      "      policy_loss: -0.0034186942502856255\n",
      "      total_loss: 3188.095703125\n",
      "      vf_explained_var: 0.3139376938343048\n",
      "      vf_loss: 3188.099609375\n",
      "    sample_time_ms: 20363.852\n",
      "    update_time_ms: 5.166\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 381.40463307785956\n",
      "  time_since_restore: 684.5190336704254\n",
      "  time_this_iter_s: 24.26389241218567\n",
      "  time_total_s: 684.5190336704254\n",
      "  timestamp: 1553966445\n",
      "  timesteps_since_restore: 280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 28\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 684 s, 28 iter, 280000 ts, 763 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-21-09\n",
      "  done: false\n",
      "  episode_len_mean: 187.79\n",
      "  episode_reward_max: 1134.4576540130283\n",
      "  episode_reward_mean: 723.4597115215777\n",
      "  episode_reward_min: -89.40070608312595\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 1437\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4043.759\n",
      "    load_time_ms: 1.635\n",
      "    num_steps_sampled: 290000\n",
      "    num_steps_trained: 290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4901164746561335e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.378185510635376\n",
      "      kl: 0.004136387258768082\n",
      "      policy_loss: -0.0012487194035202265\n",
      "      total_loss: 3544.724365234375\n",
      "      vf_explained_var: 0.2214432805776596\n",
      "      vf_loss: 3544.7255859375\n",
      "    sample_time_ms: 20320.915\n",
      "    update_time_ms: 5.345\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.72985576078884\n",
      "  time_since_restore: 708.5702333450317\n",
      "  time_this_iter_s: 24.051199674606323\n",
      "  time_total_s: 708.5702333450317\n",
      "  timestamp: 1553966469\n",
      "  timesteps_since_restore: 290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 290000\n",
      "  training_iteration: 29\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 708 s, 29 iter, 290000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-21-35\n",
      "  done: false\n",
      "  episode_len_mean: 181.15\n",
      "  episode_reward_max: 1134.4576540130283\n",
      "  episode_reward_mean: 698.7577269473842\n",
      "  episode_reward_min: -89.40070608312595\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 1491\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4045.969\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.450582373280668e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3785501718521118\n",
      "      kl: 0.005996346473693848\n",
      "      policy_loss: -0.00218829233199358\n",
      "      total_loss: 3255.31298828125\n",
      "      vf_explained_var: 0.19979770481586456\n",
      "      vf_loss: 3255.3154296875\n",
      "    sample_time_ms: 20364.978\n",
      "    update_time_ms: 5.415\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.37886347369204\n",
      "  time_since_restore: 733.7932839393616\n",
      "  time_this_iter_s: 25.223050594329834\n",
      "  time_total_s: 733.7932839393616\n",
      "  timestamp: 1553966495\n",
      "  timesteps_since_restore: 300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 30\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 733 s, 30 iter, 300000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-22-00\n",
      "  done: false\n",
      "  episode_len_mean: 177.09\n",
      "  episode_reward_max: 1108.8401106843423\n",
      "  episode_reward_mean: 746.9341896433828\n",
      "  episode_reward_min: -73.12248228410805\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1549\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4049.552\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 310000\n",
      "    num_steps_trained: 310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.725291186640334e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3094619512557983\n",
      "      kl: 0.004989637061953545\n",
      "      policy_loss: -0.0024950967635959387\n",
      "      total_loss: 3941.929931640625\n",
      "      vf_explained_var: 0.18630854785442352\n",
      "      vf_loss: 3941.932373046875\n",
      "    sample_time_ms: 20378.403\n",
      "    update_time_ms: 5.5\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 373.4670948216914\n",
      "  time_since_restore: 758.7375781536102\n",
      "  time_this_iter_s: 24.944294214248657\n",
      "  time_total_s: 758.7375781536102\n",
      "  timestamp: 1553966520\n",
      "  timesteps_since_restore: 310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 310000\n",
      "  training_iteration: 31\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 758 s, 31 iter, 310000 ts, 747 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-22-24\n",
      "  done: false\n",
      "  episode_len_mean: 166.45\n",
      "  episode_reward_max: 1108.8401106843423\n",
      "  episode_reward_mean: 752.291324662704\n",
      "  episode_reward_min: -73.9570977116314\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 1610\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4049.491\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.862645593320167e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3158950805664062\n",
      "      kl: 0.004690913017839193\n",
      "      policy_loss: -0.0019168003927916288\n",
      "      total_loss: 3975.480712890625\n",
      "      vf_explained_var: 0.22122615575790405\n",
      "      vf_loss: 3975.482666015625\n",
      "    sample_time_ms: 20385.818\n",
      "    update_time_ms: 5.31\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 376.145662331352\n",
      "  time_since_restore: 783.4538688659668\n",
      "  time_this_iter_s: 24.716290712356567\n",
      "  time_total_s: 783.4538688659668\n",
      "  timestamp: 1553966544\n",
      "  timesteps_since_restore: 320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 32\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 783 s, 32 iter, 320000 ts, 752 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-22-50\n",
      "  done: false\n",
      "  episode_len_mean: 171.55\n",
      "  episode_reward_max: 1111.8241060283954\n",
      "  episode_reward_mean: 780.6914790995246\n",
      "  episode_reward_min: -73.9570977116314\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 1667\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4053.584\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.313227966600834e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3112518787384033\n",
      "      kl: 0.004653040319681168\n",
      "      policy_loss: -0.0022690375335514545\n",
      "      total_loss: 4152.9189453125\n",
      "      vf_explained_var: 0.34570014476776123\n",
      "      vf_loss: 4152.92138671875\n",
      "    sample_time_ms: 20443.212\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 390.3457395497623\n",
      "  time_since_restore: 808.746256351471\n",
      "  time_this_iter_s: 25.29238748550415\n",
      "  time_total_s: 808.746256351471\n",
      "  timestamp: 1553966570\n",
      "  timesteps_since_restore: 330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 33\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 808 s, 33 iter, 330000 ts, 781 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-23-15\n",
      "  done: false\n",
      "  episode_len_mean: 171.62\n",
      "  episode_reward_max: 1142.903427784808\n",
      "  episode_reward_mean: 814.2698377175541\n",
      "  episode_reward_min: -86.26024167666033\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1727\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4056.419\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.656613983300417e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2878665924072266\n",
      "      kl: 0.0066308751702308655\n",
      "      policy_loss: -0.0022875862196087837\n",
      "      total_loss: 4347.7119140625\n",
      "      vf_explained_var: 0.15432605147361755\n",
      "      vf_loss: 4347.7138671875\n",
      "    sample_time_ms: 20483.471\n",
      "    update_time_ms: 5.342\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 407.1349188587771\n",
      "  time_since_restore: 833.6509568691254\n",
      "  time_this_iter_s: 24.90470051765442\n",
      "  time_total_s: 833.6509568691254\n",
      "  timestamp: 1553966595\n",
      "  timesteps_since_restore: 340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 34\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 833 s, 34 iter, 340000 ts, 814 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-23-39\n",
      "  done: false\n",
      "  episode_len_mean: 162.69\n",
      "  episode_reward_max: 1142.903427784808\n",
      "  episode_reward_mean: 771.913157865961\n",
      "  episode_reward_min: -105.1615548597262\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 1789\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4057.496\n",
      "    load_time_ms: 1.657\n",
      "    num_steps_sampled: 350000\n",
      "    num_steps_trained: 350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3283069916502086e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3021490573883057\n",
      "      kl: 0.005550066474825144\n",
      "      policy_loss: -0.003265372011810541\n",
      "      total_loss: 4060.927978515625\n",
      "      vf_explained_var: 0.2944382131099701\n",
      "      vf_loss: 4060.931396484375\n",
      "    sample_time_ms: 20550.789\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 385.9565789329805\n",
      "  time_since_restore: 858.2474739551544\n",
      "  time_this_iter_s: 24.596517086029053\n",
      "  time_total_s: 858.2474739551544\n",
      "  timestamp: 1553966619\n",
      "  timesteps_since_restore: 350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 350000\n",
      "  training_iteration: 35\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 858 s, 35 iter, 350000 ts, 772 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-24-03\n",
      "  done: false\n",
      "  episode_len_mean: 167.02\n",
      "  episode_reward_max: 1098.4748770424433\n",
      "  episode_reward_mean: 780.5823587204025\n",
      "  episode_reward_min: -81.43331111416303\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1847\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4058.527\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1641534958251043e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3025977611541748\n",
      "      kl: 0.009241444990038872\n",
      "      policy_loss: -0.004624489229172468\n",
      "      total_loss: 4281.3642578125\n",
      "      vf_explained_var: 0.23385800421237946\n",
      "      vf_loss: 4281.36865234375\n",
      "    sample_time_ms: 20556.549\n",
      "    update_time_ms: 5.377\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 390.2911793602012\n",
      "  time_since_restore: 882.4067583084106\n",
      "  time_this_iter_s: 24.159284353256226\n",
      "  time_total_s: 882.4067583084106\n",
      "  timestamp: 1553966643\n",
      "  timesteps_since_restore: 360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 36\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 882 s, 36 iter, 360000 ts, 781 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 171.63\n",
      "  episode_reward_max: 1120.2757905678227\n",
      "  episode_reward_mean: 787.099754987103\n",
      "  episode_reward_min: -86.54939695162415\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1905\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4063.344\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 370000\n",
      "    num_steps_trained: 370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.8207674791255215e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3363693952560425\n",
      "      kl: 0.00977290142327547\n",
      "      policy_loss: -0.004181556403636932\n",
      "      total_loss: 3850.061767578125\n",
      "      vf_explained_var: 0.348712295293808\n",
      "      vf_loss: 3850.065673828125\n",
      "    sample_time_ms: 20554.194\n",
      "    update_time_ms: 5.591\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 393.5498774935515\n",
      "  time_since_restore: 906.6877884864807\n",
      "  time_this_iter_s: 24.28103017807007\n",
      "  time_total_s: 906.6877884864807\n",
      "  timestamp: 1553966668\n",
      "  timesteps_since_restore: 370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 370000\n",
      "  training_iteration: 37\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 906 s, 37 iter, 370000 ts, 787 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-24-52\n",
      "  done: false\n",
      "  episode_len_mean: 166.45\n",
      "  episode_reward_max: 1120.2757905678227\n",
      "  episode_reward_mean: 723.6089059018166\n",
      "  episode_reward_min: -86.54939695162415\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 1966\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4063.756\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9103837395627608e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.30037260055542\n",
      "      kl: 0.0039030658081173897\n",
      "      policy_loss: -0.0014406507834792137\n",
      "      total_loss: 3982.741943359375\n",
      "      vf_explained_var: 0.33610713481903076\n",
      "      vf_loss: 3982.743896484375\n",
      "    sample_time_ms: 20505.413\n",
      "    update_time_ms: 5.642\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.8044529509083\n",
      "  time_since_restore: 930.4689128398895\n",
      "  time_this_iter_s: 23.781124353408813\n",
      "  time_total_s: 930.4689128398895\n",
      "  timestamp: 1553966692\n",
      "  timesteps_since_restore: 380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 38\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 930 s, 38 iter, 380000 ts, 724 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-25-16\n",
      "  done: false\n",
      "  episode_len_mean: 173.92\n",
      "  episode_reward_max: 1159.5510197425358\n",
      "  episode_reward_mean: 748.5170951028921\n",
      "  episode_reward_min: -61.74996583605895\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 2023\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4058.802\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4551918697813804e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.330047607421875\n",
      "      kl: 0.0062732994556427\n",
      "      policy_loss: -0.00198051193729043\n",
      "      total_loss: 3562.813232421875\n",
      "      vf_explained_var: 0.32502320408821106\n",
      "      vf_loss: 3562.81494140625\n",
      "    sample_time_ms: 20502.662\n",
      "    update_time_ms: 5.44\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 374.25854755144593\n",
      "  time_since_restore: 954.4425163269043\n",
      "  time_this_iter_s: 23.97360348701477\n",
      "  time_total_s: 954.4425163269043\n",
      "  timestamp: 1553966716\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 39\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 954 s, 39 iter, 390000 ts, 749 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-25-39\n",
      "  done: false\n",
      "  episode_len_mean: 172.62\n",
      "  episode_reward_max: 1159.5510197425358\n",
      "  episode_reward_mean: 750.5524585507773\n",
      "  episode_reward_min: -61.74996583605895\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 2079\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4076.412\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.275959348906902e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3076121807098389\n",
      "      kl: 0.00807783380150795\n",
      "      policy_loss: -0.004406006075441837\n",
      "      total_loss: 3478.736328125\n",
      "      vf_explained_var: 0.46309593319892883\n",
      "      vf_loss: 3478.740478515625\n",
      "    sample_time_ms: 20301.98\n",
      "    update_time_ms: 5.359\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 375.27622927538863\n",
      "  time_since_restore: 977.8331286907196\n",
      "  time_this_iter_s: 23.390612363815308\n",
      "  time_total_s: 977.8331286907196\n",
      "  timestamp: 1553966739\n",
      "  timesteps_since_restore: 400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 40\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 977 s, 40 iter, 400000 ts, 751 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-26-03\n",
      "  done: false\n",
      "  episode_len_mean: 171.05\n",
      "  episode_reward_max: 1114.3087592948104\n",
      "  episode_reward_mean: 769.9339808345518\n",
      "  episode_reward_min: -79.26246400639538\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2139\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4076.195\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 410000\n",
      "    num_steps_trained: 410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.637979674453451e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2452501058578491\n",
      "      kl: 0.00500862393528223\n",
      "      policy_loss: -0.0028102996293455362\n",
      "      total_loss: 4103.45263671875\n",
      "      vf_explained_var: 0.30183061957359314\n",
      "      vf_loss: 4103.45556640625\n",
      "    sample_time_ms: 20188.702\n",
      "    update_time_ms: 5.592\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 384.96699041727584\n",
      "  time_since_restore: 1001.6410562992096\n",
      "  time_this_iter_s: 23.80792760848999\n",
      "  time_total_s: 1001.6410562992096\n",
      "  timestamp: 1553966763\n",
      "  timesteps_since_restore: 410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 410000\n",
      "  training_iteration: 41\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1001 s, 41 iter, 410000 ts, 770 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-26-27\n",
      "  done: false\n",
      "  episode_len_mean: 165.34\n",
      "  episode_reward_max: 1131.432030652419\n",
      "  episode_reward_mean: 739.9791935165251\n",
      "  episode_reward_min: -71.90634940907148\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 2201\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4076.131\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8189898372267255e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2653781175613403\n",
      "      kl: 0.009828081354498863\n",
      "      policy_loss: -0.005120877642184496\n",
      "      total_loss: 3417.4287109375\n",
      "      vf_explained_var: 0.3641420304775238\n",
      "      vf_loss: 3417.43359375\n",
      "    sample_time_ms: 20086.942\n",
      "    update_time_ms: 5.56\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 369.9895967582625\n",
      "  time_since_restore: 1025.3416683673859\n",
      "  time_this_iter_s: 23.70061206817627\n",
      "  time_total_s: 1025.3416683673859\n",
      "  timestamp: 1553966787\n",
      "  timesteps_since_restore: 420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 42\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1025 s, 42 iter, 420000 ts, 740 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-26-51\n",
      "  done: false\n",
      "  episode_len_mean: 169.66\n",
      "  episode_reward_max: 1100.2454803150276\n",
      "  episode_reward_mean: 777.5707420099002\n",
      "  episode_reward_min: -91.11457147412848\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 2258\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4075.557\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 430000\n",
      "    num_steps_trained: 430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.094949186133627e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2585797309875488\n",
      "      kl: 0.006605152972042561\n",
      "      policy_loss: -0.0028631468303501606\n",
      "      total_loss: 3646.06640625\n",
      "      vf_explained_var: 0.3604012727737427\n",
      "      vf_loss: 3646.0693359375\n",
      "    sample_time_ms: 19959.576\n",
      "    update_time_ms: 5.56\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 388.78537100495\n",
      "  time_since_restore: 1049.3518345355988\n",
      "  time_this_iter_s: 24.01016616821289\n",
      "  time_total_s: 1049.3518345355988\n",
      "  timestamp: 1553966811\n",
      "  timesteps_since_restore: 430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 430000\n",
      "  training_iteration: 43\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1049 s, 43 iter, 430000 ts, 778 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-27-15\n",
      "  done: false\n",
      "  episode_len_mean: 170.49\n",
      "  episode_reward_max: 1099.5025684285392\n",
      "  episode_reward_mean: 802.0863994535883\n",
      "  episode_reward_min: -91.11457147412848\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 2316\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4070.509\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.5474745930668137e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2108081579208374\n",
      "      kl: 0.012782350182533264\n",
      "      policy_loss: -0.004360204096883535\n",
      "      total_loss: 3877.43359375\n",
      "      vf_explained_var: 0.39552438259124756\n",
      "      vf_loss: 3877.4375\n",
      "    sample_time_ms: 19931.35\n",
      "    update_time_ms: 5.522\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 401.0431997267943\n",
      "  time_since_restore: 1073.9232563972473\n",
      "  time_this_iter_s: 24.57142186164856\n",
      "  time_total_s: 1073.9232563972473\n",
      "  timestamp: 1553966835\n",
      "  timesteps_since_restore: 440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 44\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1073 s, 44 iter, 440000 ts, 802 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-27-39\n",
      "  done: false\n",
      "  episode_len_mean: 171.04\n",
      "  episode_reward_max: 1101.8739490416199\n",
      "  episode_reward_mean: 817.876185350294\n",
      "  episode_reward_min: -98.25694405831588\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 2375\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4079.921\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.5474745930668137e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2139211893081665\n",
      "      kl: 0.006084559950977564\n",
      "      policy_loss: -0.0029066968709230423\n",
      "      total_loss: 3572.15380859375\n",
      "      vf_explained_var: 0.5291177034378052\n",
      "      vf_loss: 3572.15673828125\n",
      "    sample_time_ms: 19854.029\n",
      "    update_time_ms: 5.565\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 408.938092675147\n",
      "  time_since_restore: 1097.8380534648895\n",
      "  time_this_iter_s: 23.914797067642212\n",
      "  time_total_s: 1097.8380534648895\n",
      "  timestamp: 1553966859\n",
      "  timesteps_since_restore: 450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 45\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1097 s, 45 iter, 450000 ts, 818 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-28-03\n",
      "  done: false\n",
      "  episode_len_mean: 164.98\n",
      "  episode_reward_max: 1101.8739490416199\n",
      "  episode_reward_mean: 799.6433917234237\n",
      "  episode_reward_min: -98.25694405831588\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 2437\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4079.58\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2737372965334068e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.159798264503479\n",
      "      kl: 0.007379862945526838\n",
      "      policy_loss: -0.0028604750987142324\n",
      "      total_loss: 3895.281982421875\n",
      "      vf_explained_var: 0.4649267792701721\n",
      "      vf_loss: 3895.284912109375\n",
      "    sample_time_ms: 19805.299\n",
      "    update_time_ms: 5.66\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 399.82169586171193\n",
      "  time_since_restore: 1121.509349822998\n",
      "  time_this_iter_s: 23.67129635810852\n",
      "  time_total_s: 1121.509349822998\n",
      "  timestamp: 1553966883\n",
      "  timesteps_since_restore: 460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 46\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1121 s, 46 iter, 460000 ts, 800 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-28-27\n",
      "  done: false\n",
      "  episode_len_mean: 166.33\n",
      "  episode_reward_max: 1111.7988910253778\n",
      "  episode_reward_mean: 806.5014605952091\n",
      "  episode_reward_min: -85.39097696255428\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2497\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4080.52\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 470000\n",
      "    num_steps_trained: 470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1368686482667034e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2078380584716797\n",
      "      kl: 0.009507985785603523\n",
      "      policy_loss: -0.003255621762946248\n",
      "      total_loss: 3655.10498046875\n",
      "      vf_explained_var: 0.5224972367286682\n",
      "      vf_loss: 3655.108642578125\n",
      "    sample_time_ms: 19771.066\n",
      "    update_time_ms: 5.687\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 403.25073029760443\n",
      "  time_since_restore: 1145.4561631679535\n",
      "  time_this_iter_s: 23.946813344955444\n",
      "  time_total_s: 1145.4561631679535\n",
      "  timestamp: 1553966907\n",
      "  timesteps_since_restore: 470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 470000\n",
      "  training_iteration: 47\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1145 s, 47 iter, 470000 ts, 807 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-28-51\n",
      "  done: false\n",
      "  episode_len_mean: 161.5\n",
      "  episode_reward_max: 1111.7988910253778\n",
      "  episode_reward_mean: 765.4785726516282\n",
      "  episode_reward_min: -94.57641311887119\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 2561\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4073.498\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.684343241333517e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2076672315597534\n",
      "      kl: 0.009592053480446339\n",
      "      policy_loss: -0.0031017374712973833\n",
      "      total_loss: 3556.097412109375\n",
      "      vf_explained_var: 0.569528341293335\n",
      "      vf_loss: 3556.1005859375\n",
      "    sample_time_ms: 19792.355\n",
      "    update_time_ms: 5.634\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 382.7392863258142\n",
      "  time_since_restore: 1169.3770649433136\n",
      "  time_this_iter_s: 23.920901775360107\n",
      "  time_total_s: 1169.3770649433136\n",
      "  timestamp: 1553966931\n",
      "  timesteps_since_restore: 480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 48\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1169 s, 48 iter, 480000 ts, 765 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-29-15\n",
      "  done: false\n",
      "  episode_len_mean: 167.27\n",
      "  episode_reward_max: 1077.0296029000733\n",
      "  episode_reward_mean: 756.5337793701058\n",
      "  episode_reward_min: -94.57641311887119\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 2615\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4073.244\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 490000\n",
      "    num_steps_trained: 490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.8421716206667585e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.267771601676941\n",
      "      kl: 0.0060329618863761425\n",
      "      policy_loss: -0.0028011517133563757\n",
      "      total_loss: 3319.76171875\n",
      "      vf_explained_var: 0.5713426470756531\n",
      "      vf_loss: 3319.7646484375\n",
      "    sample_time_ms: 19767.13\n",
      "    update_time_ms: 5.706\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 378.26688968505294\n",
      "  time_since_restore: 1193.1000621318817\n",
      "  time_this_iter_s: 23.722997188568115\n",
      "  time_total_s: 1193.1000621318817\n",
      "  timestamp: 1553966955\n",
      "  timesteps_since_restore: 490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 490000\n",
      "  training_iteration: 49\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1193 s, 49 iter, 490000 ts, 757 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-29-39\n",
      "  done: false\n",
      "  episode_len_mean: 173.47\n",
      "  episode_reward_max: 1082.2935884388326\n",
      "  episode_reward_mean: 801.9245177740133\n",
      "  episode_reward_min: -100.64443072601006\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 2673\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4068.361\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4210858103333793e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.209606647491455\n",
      "      kl: 0.01233711652457714\n",
      "      policy_loss: -0.004308192990720272\n",
      "      total_loss: 3621.5517578125\n",
      "      vf_explained_var: 0.4914213716983795\n",
      "      vf_loss: 3621.55615234375\n",
      "    sample_time_ms: 19818.745\n",
      "    update_time_ms: 5.688\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.9622588870066\n",
      "  time_since_restore: 1216.9585745334625\n",
      "  time_this_iter_s: 23.85851240158081\n",
      "  time_total_s: 1216.9585745334625\n",
      "  timestamp: 1553966979\n",
      "  timesteps_since_restore: 500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 50\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1216 s, 50 iter, 500000 ts, 802 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-30-03\n",
      "  done: false\n",
      "  episode_len_mean: 171.98\n",
      "  episode_reward_max: 1082.2935884388326\n",
      "  episode_reward_mean: 826.44159265948\n",
      "  episode_reward_min: -100.64443072601006\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2733\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4067.966\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4210858103333793e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1696932315826416\n",
      "      kl: 0.009127410128712654\n",
      "      policy_loss: -0.0031175841577351093\n",
      "      total_loss: 3484.78369140625\n",
      "      vf_explained_var: 0.5392105579376221\n",
      "      vf_loss: 3484.78759765625\n",
      "    sample_time_ms: 19841.26\n",
      "    update_time_ms: 5.372\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 413.22079632974\n",
      "  time_since_restore: 1240.9909632205963\n",
      "  time_this_iter_s: 24.03238868713379\n",
      "  time_total_s: 1240.9909632205963\n",
      "  timestamp: 1553967003\n",
      "  timesteps_since_restore: 510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 51\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1240 s, 51 iter, 510000 ts, 826 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-30-27\n",
      "  done: false\n",
      "  episode_len_mean: 166.29\n",
      "  episode_reward_max: 1140.5716828255252\n",
      "  episode_reward_mean: 783.0687893490866\n",
      "  episode_reward_min: -51.81447840614413\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 2792\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4071.134\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.105429051666896e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.203187108039856\n",
      "      kl: 0.016047874465584755\n",
      "      policy_loss: -0.00463015167042613\n",
      "      total_loss: 3427.072998046875\n",
      "      vf_explained_var: 0.578768789768219\n",
      "      vf_loss: 3427.07763671875\n",
      "    sample_time_ms: 19873.219\n",
      "    update_time_ms: 5.582\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 391.5343946745434\n",
      "  time_since_restore: 1265.045763015747\n",
      "  time_this_iter_s: 24.054799795150757\n",
      "  time_total_s: 1265.045763015747\n",
      "  timestamp: 1553967027\n",
      "  timesteps_since_restore: 520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 52\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1265 s, 52 iter, 520000 ts, 783 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-30-51\n",
      "  done: false\n",
      "  episode_len_mean: 179.1\n",
      "  episode_reward_max: 1140.5716828255252\n",
      "  episode_reward_mean: 827.4321048504219\n",
      "  episode_reward_min: -51.26527671519307\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 2845\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4071.634\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 530000\n",
      "    num_steps_trained: 530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.105429051666896e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.304919958114624\n",
      "      kl: 0.0035998309031128883\n",
      "      policy_loss: -0.002331846859306097\n",
      "      total_loss: 3259.485107421875\n",
      "      vf_explained_var: 0.5394369959831238\n",
      "      vf_loss: 3259.487548828125\n",
      "    sample_time_ms: 19851.019\n",
      "    update_time_ms: 5.527\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 413.71605242521105\n",
      "  time_since_restore: 1288.8383362293243\n",
      "  time_this_iter_s: 23.79257321357727\n",
      "  time_total_s: 1288.8383362293243\n",
      "  timestamp: 1553967051\n",
      "  timesteps_since_restore: 530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 530000\n",
      "  training_iteration: 53\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1288 s, 53 iter, 530000 ts, 827 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-31-14\n",
      "  done: false\n",
      "  episode_len_mean: 189.54\n",
      "  episode_reward_max: 1119.5069313768925\n",
      "  episode_reward_mean: 813.5783627740077\n",
      "  episode_reward_min: -92.99511521676285\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 2898\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4076.333\n",
      "    load_time_ms: 1.655\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.552714525833448e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.396266222000122\n",
      "      kl: 0.005247530993074179\n",
      "      policy_loss: -0.002062426647171378\n",
      "      total_loss: 3116.8359375\n",
      "      vf_explained_var: 0.5766688585281372\n",
      "      vf_loss: 3116.837646484375\n",
      "    sample_time_ms: 19773.128\n",
      "    update_time_ms: 5.638\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 406.7891813870039\n",
      "  time_since_restore: 1312.681985616684\n",
      "  time_this_iter_s: 23.84364938735962\n",
      "  time_total_s: 1312.681985616684\n",
      "  timestamp: 1553967074\n",
      "  timesteps_since_restore: 540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 54\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1312 s, 54 iter, 540000 ts, 814 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-31-39\n",
      "  done: false\n",
      "  episode_len_mean: 191.17\n",
      "  episode_reward_max: 1168.2858916808163\n",
      "  episode_reward_mean: 801.6874011297856\n",
      "  episode_reward_min: -92.99511521676285\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 2950\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4081.237\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 550000\n",
      "    num_steps_trained: 550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.776357262916724e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3836376667022705\n",
      "      kl: 0.009547418914735317\n",
      "      policy_loss: -0.0029874001629650593\n",
      "      total_loss: 2873.715087890625\n",
      "      vf_explained_var: 0.6084468364715576\n",
      "      vf_loss: 2873.71826171875\n",
      "    sample_time_ms: 19813.152\n",
      "    update_time_ms: 5.543\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.84370056489274\n",
      "  time_since_restore: 1337.0458137989044\n",
      "  time_this_iter_s: 24.36382818222046\n",
      "  time_total_s: 1337.0458137989044\n",
      "  timestamp: 1553967099\n",
      "  timesteps_since_restore: 550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 550000\n",
      "  training_iteration: 55\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1337 s, 55 iter, 550000 ts, 802 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-32-03\n",
      "  done: false\n",
      "  episode_len_mean: 183.56\n",
      "  episode_reward_max: 1168.2858916808163\n",
      "  episode_reward_mean: 802.5077286203102\n",
      "  episode_reward_min: -45.59903723494213\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 3008\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4082.462\n",
      "    load_time_ms: 1.61\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.88178631458362e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2779864072799683\n",
      "      kl: 0.004309674259275198\n",
      "      policy_loss: -0.0021526943892240524\n",
      "      total_loss: 3090.6005859375\n",
      "      vf_explained_var: 0.638628363609314\n",
      "      vf_loss: 3090.60302734375\n",
      "    sample_time_ms: 19860.254\n",
      "    update_time_ms: 5.424\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 401.25386431015505\n",
      "  time_since_restore: 1361.2030882835388\n",
      "  time_this_iter_s: 24.1572744846344\n",
      "  time_total_s: 1361.2030882835388\n",
      "  timestamp: 1553967123\n",
      "  timesteps_since_restore: 560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 56\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1361 s, 56 iter, 560000 ts, 803 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-32-28\n",
      "  done: false\n",
      "  episode_len_mean: 164.42\n",
      "  episode_reward_max: 1167.4989872037822\n",
      "  episode_reward_mean: 797.3515584068715\n",
      "  episode_reward_min: -84.87050639105821\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 3069\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4081.607\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.44089315729181e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1980719566345215\n",
      "      kl: 0.012594304047524929\n",
      "      policy_loss: -0.0033767628483474255\n",
      "      total_loss: 3483.02294921875\n",
      "      vf_explained_var: 0.5792570114135742\n",
      "      vf_loss: 3483.026123046875\n",
      "    sample_time_ms: 19948.669\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 398.6757792034358\n",
      "  time_since_restore: 1386.024659872055\n",
      "  time_this_iter_s: 24.821571588516235\n",
      "  time_total_s: 1386.024659872055\n",
      "  timestamp: 1553967148\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 57\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1386 s, 57 iter, 570000 ts, 797 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-32-53\n",
      "  done: false\n",
      "  episode_len_mean: 175.52\n",
      "  episode_reward_max: 1149.706550881473\n",
      "  episode_reward_mean: 799.2437205104102\n",
      "  episode_reward_min: -84.87050639105821\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 3121\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4083.991\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.44089315729181e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4066513776779175\n",
      "      kl: 0.023928547278046608\n",
      "      policy_loss: -0.004354103468358517\n",
      "      total_loss: 2831.31298828125\n",
      "      vf_explained_var: 0.5615197420120239\n",
      "      vf_loss: 2831.3173828125\n",
      "    sample_time_ms: 20010.521\n",
      "    update_time_ms: 5.497\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 399.62186025520504\n",
      "  time_since_restore: 1410.5885529518127\n",
      "  time_this_iter_s: 24.56389307975769\n",
      "  time_total_s: 1410.5885529518127\n",
      "  timestamp: 1553967173\n",
      "  timesteps_since_restore: 580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 58\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1410 s, 58 iter, 580000 ts, 799 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-33-17\n",
      "  done: false\n",
      "  episode_len_mean: 183.02\n",
      "  episode_reward_max: 1069.3324407652542\n",
      "  episode_reward_mean: 838.0654904139576\n",
      "  episode_reward_min: -79.08082593869536\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 3178\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4087.691\n",
      "    load_time_ms: 1.633\n",
      "    num_steps_sampled: 590000\n",
      "    num_steps_trained: 590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.44089315729181e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2249724864959717\n",
      "      kl: 0.009009693749248981\n",
      "      policy_loss: -0.0028402034658938646\n",
      "      total_loss: 3146.779541015625\n",
      "      vf_explained_var: 0.5420410633087158\n",
      "      vf_loss: 3146.782470703125\n",
      "    sample_time_ms: 20110.496\n",
      "    update_time_ms: 5.559\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 419.0327452069788\n",
      "  time_since_restore: 1435.3474276065826\n",
      "  time_this_iter_s: 24.758874654769897\n",
      "  time_total_s: 1435.3474276065826\n",
      "  timestamp: 1553967197\n",
      "  timesteps_since_restore: 590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 590000\n",
      "  training_iteration: 59\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1435 s, 59 iter, 590000 ts, 838 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-33-42\n",
      "  done: false\n",
      "  episode_len_mean: 169.1\n",
      "  episode_reward_max: 1055.2775803735185\n",
      "  episode_reward_mean: 818.6105252437403\n",
      "  episode_reward_min: -22.038267087483632\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 3239\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4075.731\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2777349948883057\n",
      "      kl: 0.019943147897720337\n",
      "      policy_loss: -0.0056765275076031685\n",
      "      total_loss: 3194.62548828125\n",
      "      vf_explained_var: 0.6013216972351074\n",
      "      vf_loss: 3194.631103515625\n",
      "    sample_time_ms: 20180.93\n",
      "    update_time_ms: 5.491\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 409.30526262187004\n",
      "  time_since_restore: 1459.7858955860138\n",
      "  time_this_iter_s: 24.438467979431152\n",
      "  time_total_s: 1459.7858955860138\n",
      "  timestamp: 1553967222\n",
      "  timesteps_since_restore: 600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 60\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1459 s, 60 iter, 600000 ts, 819 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-34-06\n",
      "  done: false\n",
      "  episode_len_mean: 178.99\n",
      "  episode_reward_max: 1092.1928024204626\n",
      "  episode_reward_mean: 810.2539534158011\n",
      "  episode_reward_min: -22.038267087483632\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 3291\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4079.261\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 610000\n",
      "    num_steps_trained: 610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3917882442474365\n",
      "      kl: 0.006629211828112602\n",
      "      policy_loss: -0.0021596408914774656\n",
      "      total_loss: 2757.827392578125\n",
      "      vf_explained_var: 0.6314541697502136\n",
      "      vf_loss: 2757.829345703125\n",
      "    sample_time_ms: 20174.555\n",
      "    update_time_ms: 5.572\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 405.12697670790044\n",
      "  time_since_restore: 1483.7865521907806\n",
      "  time_this_iter_s: 24.000656604766846\n",
      "  time_total_s: 1483.7865521907806\n",
      "  timestamp: 1553967246\n",
      "  timesteps_since_restore: 610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 610000\n",
      "  training_iteration: 61\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1483 s, 61 iter, 610000 ts, 810 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-34-30\n",
      "  done: false\n",
      "  episode_len_mean: 185.77\n",
      "  episode_reward_max: 1108.5437626132536\n",
      "  episode_reward_mean: 861.1545845519406\n",
      "  episode_reward_min: -86.13801613983286\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 3348\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4076.319\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1102232893229526e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2350174188613892\n",
      "      kl: 0.0293194018304348\n",
      "      policy_loss: -0.005777616519480944\n",
      "      total_loss: 3338.6171875\n",
      "      vf_explained_var: 0.5886070728302002\n",
      "      vf_loss: 3338.622802734375\n",
      "    sample_time_ms: 20208.788\n",
      "    update_time_ms: 5.532\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 430.57729227597025\n",
      "  time_since_restore: 1508.1545774936676\n",
      "  time_this_iter_s: 24.368025302886963\n",
      "  time_total_s: 1508.1545774936676\n",
      "  timestamp: 1553967270\n",
      "  timesteps_since_restore: 620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 62\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1508 s, 62 iter, 620000 ts, 861 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-34-55\n",
      "  done: false\n",
      "  episode_len_mean: 176.65\n",
      "  episode_reward_max: 1108.5437626132536\n",
      "  episode_reward_mean: 844.9574411360347\n",
      "  episode_reward_min: -86.13801613983286\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 3402\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4079.701\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1102232893229526e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3703476190567017\n",
      "      kl: 0.00946811307221651\n",
      "      policy_loss: -0.0024583828635513783\n",
      "      total_loss: 2757.731689453125\n",
      "      vf_explained_var: 0.5779985189437866\n",
      "      vf_loss: 2757.734130859375\n",
      "    sample_time_ms: 20266.384\n",
      "    update_time_ms: 5.536\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 422.4787205680175\n",
      "  time_since_restore: 1532.5579426288605\n",
      "  time_this_iter_s: 24.40336513519287\n",
      "  time_total_s: 1532.5579426288605\n",
      "  timestamp: 1553967295\n",
      "  timesteps_since_restore: 630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 63\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1532 s, 63 iter, 630000 ts, 845 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-35-19\n",
      "  done: false\n",
      "  episode_len_mean: 181.03\n",
      "  episode_reward_max: 1072.5623861085166\n",
      "  episode_reward_mean: 800.2872510003502\n",
      "  episode_reward_min: -91.12020509369782\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 3458\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4078.855\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 640000\n",
      "    num_steps_trained: 640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.551116446614763e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3344142436981201\n",
      "      kl: 0.00965187605470419\n",
      "      policy_loss: -0.0022848148364573717\n",
      "      total_loss: 3011.42919921875\n",
      "      vf_explained_var: 0.5680497884750366\n",
      "      vf_loss: 3011.43115234375\n",
      "    sample_time_ms: 20307.166\n",
      "    update_time_ms: 5.509\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.1436255001751\n",
      "  time_since_restore: 1556.8014607429504\n",
      "  time_this_iter_s: 24.243518114089966\n",
      "  time_total_s: 1556.8014607429504\n",
      "  timestamp: 1553967319\n",
      "  timesteps_since_restore: 640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 640000\n",
      "  training_iteration: 64\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1556 s, 64 iter, 640000 ts, 800 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-35-44\n",
      "  done: false\n",
      "  episode_len_mean: 177.78\n",
      "  episode_reward_max: 1103.6873506282707\n",
      "  episode_reward_mean: 813.1221541369954\n",
      "  episode_reward_min: -91.12020509369782\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 3514\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4066.703\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 650000\n",
      "    num_steps_trained: 650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7755582233073814e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.324386477470398\n",
      "      kl: 0.0062262872233986855\n",
      "      policy_loss: -0.0010529168648645282\n",
      "      total_loss: 2871.427978515625\n",
      "      vf_explained_var: 0.6241661310195923\n",
      "      vf_loss: 2871.428955078125\n",
      "    sample_time_ms: 20328.883\n",
      "    update_time_ms: 5.45\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 406.5610770684977\n",
      "  time_since_restore: 1581.2611117362976\n",
      "  time_this_iter_s: 24.459650993347168\n",
      "  time_total_s: 1581.2611117362976\n",
      "  timestamp: 1553967344\n",
      "  timesteps_since_restore: 650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 650000\n",
      "  training_iteration: 65\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1581 s, 65 iter, 650000 ts, 813 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-36-08\n",
      "  done: false\n",
      "  episode_len_mean: 172.46\n",
      "  episode_reward_max: 1129.2630107294244\n",
      "  episode_reward_mean: 797.805012970536\n",
      "  episode_reward_min: -80.06289373084853\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3574\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4079.33\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2282333374023438\n",
      "      kl: 0.029518146067857742\n",
      "      policy_loss: -0.005449789110571146\n",
      "      total_loss: 3151.203125\n",
      "      vf_explained_var: 0.5875621438026428\n",
      "      vf_loss: 3151.208740234375\n",
      "    sample_time_ms: 20316.291\n",
      "    update_time_ms: 5.591\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 398.90250648526796\n",
      "  time_since_restore: 1605.418836593628\n",
      "  time_this_iter_s: 24.157724857330322\n",
      "  time_total_s: 1605.418836593628\n",
      "  timestamp: 1553967368\n",
      "  timesteps_since_restore: 660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 66\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1605 s, 66 iter, 660000 ts, 798 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-36-32\n",
      "  done: false\n",
      "  episode_len_mean: 173.77\n",
      "  episode_reward_max: 1129.2630107294244\n",
      "  episode_reward_mean: 795.7539991811609\n",
      "  episode_reward_min: -78.76983031410425\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 3630\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4083.188\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 670000\n",
      "    num_steps_trained: 670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3318877220153809\n",
      "      kl: 0.012514989823102951\n",
      "      policy_loss: -0.003060916205868125\n",
      "      total_loss: 3039.258056640625\n",
      "      vf_explained_var: 0.5552838444709778\n",
      "      vf_loss: 3039.260986328125\n",
      "    sample_time_ms: 20218.647\n",
      "    update_time_ms: 5.397\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 397.8769995905804\n",
      "  time_since_restore: 1629.299331188202\n",
      "  time_this_iter_s: 23.880494594573975\n",
      "  time_total_s: 1629.299331188202\n",
      "  timestamp: 1553967392\n",
      "  timesteps_since_restore: 670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 670000\n",
      "  training_iteration: 67\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1629 s, 67 iter, 670000 ts, 796 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-36-55\n",
      "  done: false\n",
      "  episode_len_mean: 174.48\n",
      "  episode_reward_max: 1113.498078427383\n",
      "  episode_reward_mean: 801.1241278617942\n",
      "  episode_reward_min: -78.76983031410425\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 3687\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4083.59\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2470462322235107\n",
      "      kl: 0.008946798741817474\n",
      "      policy_loss: -0.0018390791956335306\n",
      "      total_loss: 2988.68994140625\n",
      "      vf_explained_var: 0.6571244597434998\n",
      "      vf_loss: 2988.691650390625\n",
      "    sample_time_ms: 20129.51\n",
      "    update_time_ms: 5.583\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.5620639308972\n",
      "  time_since_restore: 1652.976809501648\n",
      "  time_this_iter_s: 23.677478313446045\n",
      "  time_total_s: 1652.976809501648\n",
      "  timestamp: 1553967415\n",
      "  timesteps_since_restore: 680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 68\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1652 s, 68 iter, 680000 ts, 801 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-37-19\n",
      "  done: false\n",
      "  episode_len_mean: 169.84\n",
      "  episode_reward_max: 1113.498078427383\n",
      "  episode_reward_mean: 813.6968248218099\n",
      "  episode_reward_min: -64.77104884730176\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 3746\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4081.615\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2498221397399902\n",
      "      kl: 0.0057080029509961605\n",
      "      policy_loss: -0.0010120486840605736\n",
      "      total_loss: 3103.310791015625\n",
      "      vf_explained_var: 0.6539129614830017\n",
      "      vf_loss: 3103.31201171875\n",
      "    sample_time_ms: 20018.814\n",
      "    update_time_ms: 5.426\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 406.848412410905\n",
      "  time_since_restore: 1676.6035125255585\n",
      "  time_this_iter_s: 23.626703023910522\n",
      "  time_total_s: 1676.6035125255585\n",
      "  timestamp: 1553967439\n",
      "  timesteps_since_restore: 690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 69\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1676 s, 69 iter, 690000 ts, 814 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-37-43\n",
      "  done: false\n",
      "  episode_len_mean: 177.83\n",
      "  episode_reward_max: 1093.743208061826\n",
      "  episode_reward_mean: 791.8026273826299\n",
      "  episode_reward_min: -64.77104884730176\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 3801\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4089.703\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3199214935302734\n",
      "      kl: 0.011438222602009773\n",
      "      policy_loss: -0.0019077169708907604\n",
      "      total_loss: 2913.419921875\n",
      "      vf_explained_var: 0.6388545632362366\n",
      "      vf_loss: 2913.422119140625\n",
      "    sample_time_ms: 19933.742\n",
      "    update_time_ms: 5.423\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 395.90131369131495\n",
      "  time_since_restore: 1700.2745673656464\n",
      "  time_this_iter_s: 23.67105484008789\n",
      "  time_total_s: 1700.2745673656464\n",
      "  timestamp: 1553967463\n",
      "  timesteps_since_restore: 700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 70\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1700 s, 70 iter, 700000 ts, 792 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-38-06\n",
      "  done: false\n",
      "  episode_len_mean: 174.65\n",
      "  episode_reward_max: 1100.7682568862947\n",
      "  episode_reward_mean: 798.1618793738177\n",
      "  episode_reward_min: -98.31290432151532\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 3860\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4067.428\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 710000\n",
      "    num_steps_trained: 710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1723086833953857\n",
      "      kl: 0.013941681012511253\n",
      "      policy_loss: -0.0022111693397164345\n",
      "      total_loss: 3083.550537109375\n",
      "      vf_explained_var: 0.6325613856315613\n",
      "      vf_loss: 3083.552490234375\n",
      "    sample_time_ms: 19895.517\n",
      "    update_time_ms: 6.292\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 399.08093968690883\n",
      "  time_since_restore: 1723.6789593696594\n",
      "  time_this_iter_s: 23.40439200401306\n",
      "  time_total_s: 1723.6789593696594\n",
      "  timestamp: 1553967486\n",
      "  timesteps_since_restore: 710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 710000\n",
      "  training_iteration: 71\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1723 s, 71 iter, 710000 ts, 798 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 170.67\n",
      "  episode_reward_max: 1100.7682568862947\n",
      "  episode_reward_mean: 826.5977943035624\n",
      "  episode_reward_min: -91.3228585102851\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 3918\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4064.778\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.212500810623169\n",
      "      kl: 0.02213987149298191\n",
      "      policy_loss: -0.0032367759849876165\n",
      "      total_loss: 2978.591064453125\n",
      "      vf_explained_var: 0.6358087658882141\n",
      "      vf_loss: 2978.593994140625\n",
      "    sample_time_ms: 19809.929\n",
      "    update_time_ms: 6.574\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 413.2988971517812\n",
      "  time_since_restore: 1747.1656696796417\n",
      "  time_this_iter_s: 23.4867103099823\n",
      "  time_total_s: 1747.1656696796417\n",
      "  timestamp: 1553967510\n",
      "  timesteps_since_restore: 720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 72\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1747 s, 72 iter, 720000 ts, 827 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-38-53\n",
      "  done: false\n",
      "  episode_len_mean: 173.07\n",
      "  episode_reward_max: 1101.5845770370022\n",
      "  episode_reward_mean: 824.8124394172519\n",
      "  episode_reward_min: -91.3228585102851\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 3975\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4047.718\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 730000\n",
      "    num_steps_trained: 730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2223418951034546\n",
      "      kl: 0.03402140364050865\n",
      "      policy_loss: -0.006355116609483957\n",
      "      total_loss: 2922.438232421875\n",
      "      vf_explained_var: 0.6445280909538269\n",
      "      vf_loss: 2922.44482421875\n",
      "    sample_time_ms: 19697.581\n",
      "    update_time_ms: 6.653\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 412.40621970862594\n",
      "  time_since_restore: 1770.2765417099\n",
      "  time_this_iter_s: 23.11087203025818\n",
      "  time_total_s: 1770.2765417099\n",
      "  timestamp: 1553967533\n",
      "  timesteps_since_restore: 730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 730000\n",
      "  training_iteration: 73\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1770 s, 73 iter, 730000 ts, 825 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-39-15\n",
      "  done: false\n",
      "  episode_len_mean: 178.7\n",
      "  episode_reward_max: 1115.4085089641299\n",
      "  episode_reward_mean: 793.7060457634287\n",
      "  episode_reward_min: -89.26068674527305\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 4030\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4031.327\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3872559070587158\n",
      "      kl: 0.010759555734694004\n",
      "      policy_loss: -0.0026406787801533937\n",
      "      total_loss: 2504.913818359375\n",
      "      vf_explained_var: 0.6949473023414612\n",
      "      vf_loss: 2504.91650390625\n",
      "    sample_time_ms: 19531.813\n",
      "    update_time_ms: 6.796\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 396.85302288171425\n",
      "  time_since_restore: 1792.6947417259216\n",
      "  time_this_iter_s: 22.41820001602173\n",
      "  time_total_s: 1792.6947417259216\n",
      "  timestamp: 1553967555\n",
      "  timesteps_since_restore: 740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 74\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1792 s, 74 iter, 740000 ts, 794 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-39-39\n",
      "  done: false\n",
      "  episode_len_mean: 179.66\n",
      "  episode_reward_max: 1115.4085089641299\n",
      "  episode_reward_mean: 817.511397915126\n",
      "  episode_reward_min: -77.10659835703564\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 4086\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4019.282\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2389923334121704\n",
      "      kl: 0.008436481468379498\n",
      "      policy_loss: -0.003001149743795395\n",
      "      total_loss: 2786.84765625\n",
      "      vf_explained_var: 0.6732505559921265\n",
      "      vf_loss: 2786.85009765625\n",
      "    sample_time_ms: 19422.05\n",
      "    update_time_ms: 6.874\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 408.755698957563\n",
      "  time_since_restore: 1815.9352753162384\n",
      "  time_this_iter_s: 23.240533590316772\n",
      "  time_total_s: 1815.9352753162384\n",
      "  timestamp: 1553967579\n",
      "  timesteps_since_restore: 750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 75\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1815 s, 75 iter, 750000 ts, 818 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-40-02\n",
      "  done: false\n",
      "  episode_len_mean: 178.3\n",
      "  episode_reward_max: 1107.447789760729\n",
      "  episode_reward_mean: 829.183716141318\n",
      "  episode_reward_min: -77.10659835703564\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 4142\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3995.093\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 760000\n",
      "    num_steps_trained: 760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2498552799224854\n",
      "      kl: 0.023131979629397392\n",
      "      policy_loss: -0.0050431820563972\n",
      "      total_loss: 2467.269287109375\n",
      "      vf_explained_var: 0.7099127173423767\n",
      "      vf_loss: 2467.274169921875\n",
      "    sample_time_ms: 19374.644\n",
      "    update_time_ms: 6.671\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 414.59185807065893\n",
      "  time_since_restore: 1839.3723504543304\n",
      "  time_this_iter_s: 23.43707513809204\n",
      "  time_total_s: 1839.3723504543304\n",
      "  timestamp: 1553967602\n",
      "  timesteps_since_restore: 760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 760000\n",
      "  training_iteration: 76\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1839 s, 76 iter, 760000 ts, 829 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-40-25\n",
      "  done: false\n",
      "  episode_len_mean: 169.43\n",
      "  episode_reward_max: 1079.6805947663486\n",
      "  episode_reward_mean: 788.8864400004891\n",
      "  episode_reward_min: -48.78945530034531\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 4201\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3971.841\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 770000\n",
      "    num_steps_trained: 770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.255030870437622\n",
      "      kl: 0.013832268305122852\n",
      "      policy_loss: -0.002557950560003519\n",
      "      total_loss: 2826.67333984375\n",
      "      vf_explained_var: 0.7076217532157898\n",
      "      vf_loss: 2826.67578125\n",
      "    sample_time_ms: 19343.157\n",
      "    update_time_ms: 6.825\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 394.4432200002446\n",
      "  time_since_restore: 1862.7073767185211\n",
      "  time_this_iter_s: 23.335026264190674\n",
      "  time_total_s: 1862.7073767185211\n",
      "  timestamp: 1553967625\n",
      "  timesteps_since_restore: 770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 770000\n",
      "  training_iteration: 77\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1862 s, 77 iter, 770000 ts, 789 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-40-49\n",
      "  done: false\n",
      "  episode_len_mean: 167.62\n",
      "  episode_reward_max: 1088.0954307192155\n",
      "  episode_reward_mean: 802.7401549643347\n",
      "  episode_reward_min: -48.78945530034531\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4261\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3955.986\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.070596694946289\n",
      "      kl: 0.0141146807000041\n",
      "      policy_loss: -0.001731500611640513\n",
      "      total_loss: 2943.031982421875\n",
      "      vf_explained_var: 0.708634078502655\n",
      "      vf_loss: 2943.03369140625\n",
      "    sample_time_ms: 19301.571\n",
      "    update_time_ms: 6.62\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 401.37007748216723\n",
      "  time_since_restore: 1885.8081090450287\n",
      "  time_this_iter_s: 23.10073232650757\n",
      "  time_total_s: 1885.8081090450287\n",
      "  timestamp: 1553967649\n",
      "  timesteps_since_restore: 780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 78\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1885 s, 78 iter, 780000 ts, 803 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-41-11\n",
      "  done: false\n",
      "  episode_len_mean: 176.32\n",
      "  episode_reward_max: 1088.0954307192155\n",
      "  episode_reward_mean: 852.8178555033452\n",
      "  episode_reward_min: -60.64873056075794\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 4316\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3942.948\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 790000\n",
      "    num_steps_trained: 790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.283653736114502\n",
      "      kl: 0.016380365937948227\n",
      "      policy_loss: -0.0017226508352905512\n",
      "      total_loss: 2506.22900390625\n",
      "      vf_explained_var: 0.6959604024887085\n",
      "      vf_loss: 2506.230712890625\n",
      "    sample_time_ms: 19238.835\n",
      "    update_time_ms: 6.888\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 426.40892775167276\n",
      "  time_since_restore: 1908.6788811683655\n",
      "  time_this_iter_s: 22.870772123336792\n",
      "  time_total_s: 1908.6788811683655\n",
      "  timestamp: 1553967671\n",
      "  timesteps_since_restore: 790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 790000\n",
      "  training_iteration: 79\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1908 s, 79 iter, 790000 ts, 853 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-41-34\n",
      "  done: false\n",
      "  episode_len_mean: 178.6\n",
      "  episode_reward_max: 1068.649349828875\n",
      "  episode_reward_mean: 782.9398614770466\n",
      "  episode_reward_min: -91.9715838016032\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 4374\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.604\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 800000\n",
      "    num_steps_trained: 800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3264806270599365\n",
      "      kl: 0.009908439591526985\n",
      "      policy_loss: 0.000231235841056332\n",
      "      total_loss: 2817.73193359375\n",
      "      vf_explained_var: 0.6435861587524414\n",
      "      vf_loss: 2817.731689453125\n",
      "    sample_time_ms: 19138.908\n",
      "    update_time_ms: 6.921\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 391.4699307385234\n",
      "  time_since_restore: 1931.0946507453918\n",
      "  time_this_iter_s: 22.415769577026367\n",
      "  time_total_s: 1931.0946507453918\n",
      "  timestamp: 1553967694\n",
      "  timesteps_since_restore: 800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 800000\n",
      "  training_iteration: 80\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1931 s, 80 iter, 800000 ts, 783 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-41-57\n",
      "  done: false\n",
      "  episode_len_mean: 184.9\n",
      "  episode_reward_max: 1075.6538869329806\n",
      "  episode_reward_mean: 771.7330521629217\n",
      "  episode_reward_min: -91.9715838016032\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 4425\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.688\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5724972486495972\n",
      "      kl: 0.01749114878475666\n",
      "      policy_loss: -0.0010658210376277566\n",
      "      total_loss: 2107.489501953125\n",
      "      vf_explained_var: 0.7367463707923889\n",
      "      vf_loss: 2107.490478515625\n",
      "    sample_time_ms: 19102.523\n",
      "    update_time_ms: 6.146\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 385.8665260814609\n",
      "  time_since_restore: 1954.1645665168762\n",
      "  time_this_iter_s: 23.069915771484375\n",
      "  time_total_s: 1954.1645665168762\n",
      "  timestamp: 1553967717\n",
      "  timesteps_since_restore: 810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 81\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1954 s, 81 iter, 810000 ts, 772 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-42-20\n",
      "  done: false\n",
      "  episode_len_mean: 183.4\n",
      "  episode_reward_max: 1115.7157426617339\n",
      "  episode_reward_mean: 829.0714807022829\n",
      "  episode_reward_min: -87.4742262996836\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 4481\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.175\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 820000\n",
      "    num_steps_trained: 820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1810088157653809\n",
      "      kl: 0.022240303456783295\n",
      "      policy_loss: -0.0010883411159738898\n",
      "      total_loss: 2573.252685546875\n",
      "      vf_explained_var: 0.7292490005493164\n",
      "      vf_loss: 2573.25390625\n",
      "    sample_time_ms: 19101.063\n",
      "    update_time_ms: 5.736\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 414.5357403511414\n",
      "  time_since_restore: 1977.4560766220093\n",
      "  time_this_iter_s: 23.291510105133057\n",
      "  time_total_s: 1977.4560766220093\n",
      "  timestamp: 1553967740\n",
      "  timesteps_since_restore: 820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 820000\n",
      "  training_iteration: 82\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 1977 s, 82 iter, 820000 ts, 829 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-42-45\n",
      "  done: false\n",
      "  episode_len_mean: 179.12\n",
      "  episode_reward_max: 1115.7157426617339\n",
      "  episode_reward_mean: 793.081723093772\n",
      "  episode_reward_min: -80.69298703186337\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 4539\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.672\n",
      "    load_time_ms: 1.379\n",
      "    num_steps_sampled: 830000\n",
      "    num_steps_trained: 830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2399529218673706\n",
      "      kl: 0.011597086675465107\n",
      "      policy_loss: 0.0025643426924943924\n",
      "      total_loss: 2556.5888671875\n",
      "      vf_explained_var: 0.7241392731666565\n",
      "      vf_loss: 2556.58642578125\n",
      "    sample_time_ms: 19216.332\n",
      "    update_time_ms: 5.715\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 396.5408615468859\n",
      "  time_since_restore: 2001.6642196178436\n",
      "  time_this_iter_s: 24.20814299583435\n",
      "  time_total_s: 2001.6642196178436\n",
      "  timestamp: 1553967765\n",
      "  timesteps_since_restore: 830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 830000\n",
      "  training_iteration: 83\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2001 s, 83 iter, 830000 ts, 793 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-43-09\n",
      "  done: false\n",
      "  episode_len_mean: 173.76\n",
      "  episode_reward_max: 1064.0019990246608\n",
      "  episode_reward_mean: 743.0516050062812\n",
      "  episode_reward_min: -105.64742771467668\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 4595\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.576\n",
      "    load_time_ms: 1.389\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3469569683074951\n",
      "      kl: 0.017550028860569\n",
      "      policy_loss: 0.0024182964116334915\n",
      "      total_loss: 2456.150146484375\n",
      "      vf_explained_var: 0.7314652800559998\n",
      "      vf_loss: 2456.14794921875\n",
      "    sample_time_ms: 19344.091\n",
      "    update_time_ms: 5.518\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 371.52580250314054\n",
      "  time_since_restore: 2025.5071592330933\n",
      "  time_this_iter_s: 23.842939615249634\n",
      "  time_total_s: 2025.5071592330933\n",
      "  timestamp: 1553967789\n",
      "  timesteps_since_restore: 840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 84\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2025 s, 84 iter, 840000 ts, 743 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-43-32\n",
      "  done: false\n",
      "  episode_len_mean: 164.81\n",
      "  episode_reward_max: 1108.8495832927497\n",
      "  episode_reward_mean: 770.3678602792567\n",
      "  episode_reward_min: -105.64742771467668\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 4658\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.949\n",
      "    load_time_ms: 1.375\n",
      "    num_steps_sampled: 850000\n",
      "    num_steps_trained: 850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0121887922286987\n",
      "      kl: 0.028241047635674477\n",
      "      policy_loss: -0.0018965858034789562\n",
      "      total_loss: 3023.922607421875\n",
      "      vf_explained_var: 0.7100397944450378\n",
      "      vf_loss: 3023.924560546875\n",
      "    sample_time_ms: 19409.643\n",
      "    update_time_ms: 5.441\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 385.1839301396283\n",
      "  time_since_restore: 2049.343402862549\n",
      "  time_this_iter_s: 23.836243629455566\n",
      "  time_total_s: 2049.343402862549\n",
      "  timestamp: 1553967812\n",
      "  timesteps_since_restore: 850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 850000\n",
      "  training_iteration: 85\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2049 s, 85 iter, 850000 ts, 770 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-43-55\n",
      "  done: false\n",
      "  episode_len_mean: 160.55\n",
      "  episode_reward_max: 1128.2713244315844\n",
      "  episode_reward_mean: 773.2825260283863\n",
      "  episode_reward_min: -76.18259412910301\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 4716\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.13\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 860000\n",
      "    num_steps_trained: 860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2141854763031006\n",
      "      kl: 0.01798255555331707\n",
      "      policy_loss: 0.0008566807373426855\n",
      "      total_loss: 2578.387451171875\n",
      "      vf_explained_var: 0.7315371632575989\n",
      "      vf_loss: 2578.38671875\n",
      "    sample_time_ms: 19380.491\n",
      "    update_time_ms: 5.612\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 386.64126301419327\n",
      "  time_since_restore: 2072.4029400348663\n",
      "  time_this_iter_s: 23.059537172317505\n",
      "  time_total_s: 2072.4029400348663\n",
      "  timestamp: 1553967835\n",
      "  timesteps_since_restore: 860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 860000\n",
      "  training_iteration: 86\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2072 s, 86 iter, 860000 ts, 773 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-44-20\n",
      "  done: false\n",
      "  episode_len_mean: 169.88\n",
      "  episode_reward_max: 1117.6605486641338\n",
      "  episode_reward_mean: 807.9835213302706\n",
      "  episode_reward_min: -92.80355511380561\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 4775\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.031\n",
      "    load_time_ms: 1.354\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1796215772628784\n",
      "      kl: 0.018278876319527626\n",
      "      policy_loss: 0.0036818678490817547\n",
      "      total_loss: 2739.11572265625\n",
      "      vf_explained_var: 0.7364710569381714\n",
      "      vf_loss: 2739.112060546875\n",
      "    sample_time_ms: 19449.619\n",
      "    update_time_ms: 5.549\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 403.9917606651354\n",
      "  time_since_restore: 2096.401344537735\n",
      "  time_this_iter_s: 23.998404502868652\n",
      "  time_total_s: 2096.401344537735\n",
      "  timestamp: 1553967860\n",
      "  timesteps_since_restore: 870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 87\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2096 s, 87 iter, 870000 ts, 808 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-44-43\n",
      "  done: false\n",
      "  episode_len_mean: 171.54\n",
      "  episode_reward_max: 1132.2941684414955\n",
      "  episode_reward_mean: 845.0994660209798\n",
      "  episode_reward_min: -92.80355511380561\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 4833\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.32\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0883610248565674\n",
      "      kl: 0.02442345954477787\n",
      "      policy_loss: 0.0013851393014192581\n",
      "      total_loss: 2600.84765625\n",
      "      vf_explained_var: 0.7403693795204163\n",
      "      vf_loss: 2600.846435546875\n",
      "    sample_time_ms: 19496.291\n",
      "    update_time_ms: 5.527\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 422.5497330104899\n",
      "  time_since_restore: 2119.9748916625977\n",
      "  time_this_iter_s: 23.57354712486267\n",
      "  time_total_s: 2119.9748916625977\n",
      "  timestamp: 1553967883\n",
      "  timesteps_since_restore: 880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 88\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2119 s, 88 iter, 880000 ts, 845 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-45-07\n",
      "  done: false\n",
      "  episode_len_mean: 173.61\n",
      "  episode_reward_max: 1144.8926640088362\n",
      "  episode_reward_mean: 841.6426426144234\n",
      "  episode_reward_min: -87.90380569787305\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 4892\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.593\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 890000\n",
      "    num_steps_trained: 890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1554561853408813\n",
      "      kl: 0.03032495453953743\n",
      "      policy_loss: 0.004053572192788124\n",
      "      total_loss: 2611.31591796875\n",
      "      vf_explained_var: 0.752780020236969\n",
      "      vf_loss: 2611.31201171875\n",
      "    sample_time_ms: 19587.367\n",
      "    update_time_ms: 5.35\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 420.82132130721175\n",
      "  time_since_restore: 2143.8463385105133\n",
      "  time_this_iter_s: 23.87144684791565\n",
      "  time_total_s: 2143.8463385105133\n",
      "  timestamp: 1553967907\n",
      "  timesteps_since_restore: 890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 890000\n",
      "  training_iteration: 89\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2143 s, 89 iter, 890000 ts, 842 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 166.76\n",
      "  episode_reward_max: 1144.8926640088362\n",
      "  episode_reward_mean: 804.5642667974229\n",
      "  episode_reward_min: -95.13918985038518\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 4953\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.52\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0329564809799194\n",
      "      kl: 0.01720447652041912\n",
      "      policy_loss: 0.007094696629792452\n",
      "      total_loss: 2716.864013671875\n",
      "      vf_explained_var: 0.7346511483192444\n",
      "      vf_loss: 2716.856689453125\n",
      "    sample_time_ms: 19627.148\n",
      "    update_time_ms: 5.455\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 402.28213339871144\n",
      "  time_since_restore: 2166.6700842380524\n",
      "  time_this_iter_s: 22.823745727539062\n",
      "  time_total_s: 2166.6700842380524\n",
      "  timestamp: 1553967930\n",
      "  timesteps_since_restore: 900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 90\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2166 s, 90 iter, 900000 ts, 805 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-45-54\n",
      "  done: false\n",
      "  episode_len_mean: 161.63\n",
      "  episode_reward_max: 1132.1241335104633\n",
      "  episode_reward_mean: 786.8954901414456\n",
      "  episode_reward_min: -95.13918985038518\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 5015\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.968\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 910000\n",
      "    num_steps_trained: 910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8962885737419128\n",
      "      kl: 0.030889376997947693\n",
      "      policy_loss: 0.008791673928499222\n",
      "      total_loss: 2709.8271484375\n",
      "      vf_explained_var: 0.7574762105941772\n",
      "      vf_loss: 2709.818359375\n",
      "    sample_time_ms: 19722.557\n",
      "    update_time_ms: 5.435\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 393.4477450707228\n",
      "  time_since_restore: 2190.619733572006\n",
      "  time_this_iter_s: 23.949649333953857\n",
      "  time_total_s: 2190.619733572006\n",
      "  timestamp: 1553967954\n",
      "  timesteps_since_restore: 910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 910000\n",
      "  training_iteration: 91\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2190 s, 91 iter, 910000 ts, 787 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-46-17\n",
      "  done: false\n",
      "  episode_len_mean: 169.86\n",
      "  episode_reward_max: 1152.8848992353555\n",
      "  episode_reward_mean: 768.6070018077418\n",
      "  episode_reward_min: -94.88983014258964\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 5071\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.389\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.350685715675354\n",
      "      kl: 0.026362406089901924\n",
      "      policy_loss: 0.006730394437909126\n",
      "      total_loss: 2210.4375\n",
      "      vf_explained_var: 0.7726460099220276\n",
      "      vf_loss: 2210.4306640625\n",
      "    sample_time_ms: 19703.552\n",
      "    update_time_ms: 5.377\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 384.3035009038709\n",
      "  time_since_restore: 2213.7444880008698\n",
      "  time_this_iter_s: 23.124754428863525\n",
      "  time_total_s: 2213.7444880008698\n",
      "  timestamp: 1553967977\n",
      "  timesteps_since_restore: 920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 92\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2213 s, 92 iter, 920000 ts, 769 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-46-41\n",
      "  done: false\n",
      "  episode_len_mean: 171.18\n",
      "  episode_reward_max: 1152.8848992353555\n",
      "  episode_reward_mean: 804.1432464930991\n",
      "  episode_reward_min: -94.88983014258964\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 5130\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.949\n",
      "    load_time_ms: 1.583\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0495963096618652\n",
      "      kl: 0.054017677903175354\n",
      "      policy_loss: 0.008293332532048225\n",
      "      total_loss: 2478.215087890625\n",
      "      vf_explained_var: 0.7957372665405273\n",
      "      vf_loss: 2478.206787109375\n",
      "    sample_time_ms: 19612.464\n",
      "    update_time_ms: 5.666\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 402.07162324654956\n",
      "  time_since_restore: 2237.18106842041\n",
      "  time_this_iter_s: 23.436580419540405\n",
      "  time_total_s: 2237.18106842041\n",
      "  timestamp: 1553968001\n",
      "  timesteps_since_restore: 930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 93\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2237 s, 93 iter, 930000 ts, 804 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-47-04\n",
      "  done: false\n",
      "  episode_len_mean: 165.94\n",
      "  episode_reward_max: 1095.4449264005257\n",
      "  episode_reward_mean: 786.7361068754798\n",
      "  episode_reward_min: -82.11349305367506\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 5193\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.916\n",
      "    load_time_ms: 1.631\n",
      "    num_steps_sampled: 940000\n",
      "    num_steps_trained: 940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.301042529434423e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9300137758255005\n",
      "      kl: 0.09657149761915207\n",
      "      policy_loss: 0.008344253525137901\n",
      "      total_loss: 2663.698974609375\n",
      "      vf_explained_var: 0.766086995601654\n",
      "      vf_loss: 2663.690673828125\n",
      "    sample_time_ms: 19600.507\n",
      "    update_time_ms: 5.703\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 393.3680534377399\n",
      "  time_since_restore: 2260.707124233246\n",
      "  time_this_iter_s: 23.526055812835693\n",
      "  time_total_s: 2260.707124233246\n",
      "  timestamp: 1553968024\n",
      "  timesteps_since_restore: 940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 940000\n",
      "  training_iteration: 94\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2260 s, 94 iter, 940000 ts, 787 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-47-28\n",
      "  done: false\n",
      "  episode_len_mean: 160.06\n",
      "  episode_reward_max: 1080.9828563362355\n",
      "  episode_reward_mean: 801.0117782801267\n",
      "  episode_reward_min: -96.37281409579164\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 5254\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.435\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 950000\n",
      "    num_steps_trained: 950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.9515639880220904e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.894396960735321\n",
      "      kl: 0.048483457416296005\n",
      "      policy_loss: 0.012532751075923443\n",
      "      total_loss: 2543.390625\n",
      "      vf_explained_var: 0.7726237177848816\n",
      "      vf_loss: 2543.378173828125\n",
      "    sample_time_ms: 19584.367\n",
      "    update_time_ms: 5.691\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.50588914006335\n",
      "  time_since_restore: 2284.3292717933655\n",
      "  time_this_iter_s: 23.62214756011963\n",
      "  time_total_s: 2284.3292717933655\n",
      "  timestamp: 1553968048\n",
      "  timesteps_since_restore: 950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 950000\n",
      "  training_iteration: 95\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2284 s, 95 iter, 950000 ts, 801 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-47-51\n",
      "  done: false\n",
      "  episode_len_mean: 162.7\n",
      "  episode_reward_max: 1080.78772304768\n",
      "  episode_reward_mean: 824.0483528910177\n",
      "  episode_reward_min: -86.6476473596769\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 5315\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.265\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9273461759035917e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9721699357032776\n",
      "      kl: 0.043235842138528824\n",
      "      policy_loss: 0.014596002176404\n",
      "      total_loss: 2570.099853515625\n",
      "      vf_explained_var: 0.7690497040748596\n",
      "      vf_loss: 2570.08544921875\n",
      "    sample_time_ms: 19609.518\n",
      "    update_time_ms: 5.502\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 412.0241764455088\n",
      "  time_since_restore: 2307.6894478797913\n",
      "  time_this_iter_s: 23.36017608642578\n",
      "  time_total_s: 2307.6894478797913\n",
      "  timestamp: 1553968071\n",
      "  timesteps_since_restore: 960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 96\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2307 s, 96 iter, 960000 ts, 824 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-48-14\n",
      "  done: false\n",
      "  episode_len_mean: 162.44\n",
      "  episode_reward_max: 1074.9276970676215\n",
      "  episode_reward_mean: 800.404517176232\n",
      "  episode_reward_min: -98.15709470935535\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5375\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.514\n",
      "    load_time_ms: 1.663\n",
      "    num_steps_sampled: 970000\n",
      "    num_steps_trained: 970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.391018488373563e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9782657027244568\n",
      "      kl: 0.02716914191842079\n",
      "      policy_loss: 0.010869152843952179\n",
      "      total_loss: 2313.060791015625\n",
      "      vf_explained_var: 0.7934931516647339\n",
      "      vf_loss: 2313.049560546875\n",
      "    sample_time_ms: 19511.844\n",
      "    update_time_ms: 5.619\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.20225858811597\n",
      "  time_since_restore: 2330.743147134781\n",
      "  time_this_iter_s: 23.053699254989624\n",
      "  time_total_s: 2330.743147134781\n",
      "  timestamp: 1553968094\n",
      "  timesteps_since_restore: 970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 970000\n",
      "  training_iteration: 97\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2330 s, 97 iter, 970000 ts, 800 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-48-37\n",
      "  done: false\n",
      "  episode_len_mean: 163.61\n",
      "  episode_reward_max: 1141.141721601514\n",
      "  episode_reward_mean: 843.1104256299492\n",
      "  episode_reward_min: -98.15709470935535\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 5436\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.131\n",
      "    load_time_ms: 1.647\n",
      "    num_steps_sampled: 980000\n",
      "    num_steps_trained: 980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.391018488373563e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8388380408287048\n",
      "      kl: 0.08055906742811203\n",
      "      policy_loss: 0.019936557859182358\n",
      "      total_loss: 2660.321533203125\n",
      "      vf_explained_var: 0.7771588563919067\n",
      "      vf_loss: 2660.301513671875\n",
      "    sample_time_ms: 19428.285\n",
      "    update_time_ms: 5.61\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 421.5552128149746\n",
      "  time_since_restore: 2353.6958107948303\n",
      "  time_this_iter_s: 22.95266366004944\n",
      "  time_total_s: 2353.6958107948303\n",
      "  timestamp: 1553968117\n",
      "  timesteps_since_restore: 980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 980000\n",
      "  training_iteration: 98\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2353 s, 98 iter, 980000 ts, 843 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-49-01\n",
      "  done: false\n",
      "  episode_len_mean: 163.29\n",
      "  episode_reward_max: 1141.141721601514\n",
      "  episode_reward_mean: 844.1073176468442\n",
      "  episode_reward_min: -85.60900571248592\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 5498\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.801\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.586528508042169e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8942686915397644\n",
      "      kl: 0.04650158807635307\n",
      "      policy_loss: 0.014241967350244522\n",
      "      total_loss: 2660.878173828125\n",
      "      vf_explained_var: 0.7811834812164307\n",
      "      vf_loss: 2660.8642578125\n",
      "    sample_time_ms: 19403.915\n",
      "    update_time_ms: 6.236\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 422.053658823422\n",
      "  time_since_restore: 2377.2134668827057\n",
      "  time_this_iter_s: 23.517656087875366\n",
      "  time_total_s: 2377.2134668827057\n",
      "  timestamp: 1553968141\n",
      "  timesteps_since_restore: 990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 99\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2377 s, 99 iter, 990000 ts, 844 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-49-24\n",
      "  done: false\n",
      "  episode_len_mean: 158.77\n",
      "  episode_reward_max: 1099.9594074267527\n",
      "  episode_reward_mean: 822.2763052815515\n",
      "  episode_reward_min: -44.878882645447874\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 5560\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.394\n",
      "    load_time_ms: 1.655\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.879792503569312e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7565643191337585\n",
      "      kl: 0.059934940189123154\n",
      "      policy_loss: 0.02144371159374714\n",
      "      total_loss: 2572.982421875\n",
      "      vf_explained_var: 0.763198733329773\n",
      "      vf_loss: 2572.960693359375\n",
      "    sample_time_ms: 19450.269\n",
      "    update_time_ms: 6.115\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 411.1381526407757\n",
      "  time_since_restore: 2400.4566037654877\n",
      "  time_this_iter_s: 23.243136882781982\n",
      "  time_total_s: 2400.4566037654877\n",
      "  timestamp: 1553968164\n",
      "  timesteps_since_restore: 1000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 100\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2400 s, 100 iter, 1000000 ts, 822 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-49-47\n",
      "  done: false\n",
      "  episode_len_mean: 168.05\n",
      "  episode_reward_max: 1110.776895018683\n",
      "  episode_reward_mean: 825.4280898658678\n",
      "  episode_reward_min: -45.230914838613955\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 5616\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.862\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 1010000\n",
      "    num_steps_trained: 1010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4819686170414554e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.232783555984497\n",
      "      kl: 0.09148427844047546\n",
      "      policy_loss: 0.02256106026470661\n",
      "      total_loss: 2123.10107421875\n",
      "      vf_explained_var: 0.823503851890564\n",
      "      vf_loss: 2123.07861328125\n",
      "    sample_time_ms: 19356.816\n",
      "    update_time_ms: 6.011\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 412.7140449329339\n",
      "  time_since_restore: 2423.4749438762665\n",
      "  time_this_iter_s: 23.01834011077881\n",
      "  time_total_s: 2423.4749438762665\n",
      "  timestamp: 1553968187\n",
      "  timesteps_since_restore: 1010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1010000\n",
      "  training_iteration: 101\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2423 s, 101 iter, 1010000 ts, 825 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-50-10\n",
      "  done: false\n",
      "  episode_len_mean: 163.8\n",
      "  episode_reward_max: 1110.776895018683\n",
      "  episode_reward_mean: 824.6586542379679\n",
      "  episode_reward_min: -69.96434244548922\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 5680\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.397\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2229533908512777e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7260346412658691\n",
      "      kl: 0.06789279729127884\n",
      "      policy_loss: 0.019748589023947716\n",
      "      total_loss: 2472.81201171875\n",
      "      vf_explained_var: 0.8090124130249023\n",
      "      vf_loss: 2472.792724609375\n",
      "    sample_time_ms: 19341.941\n",
      "    update_time_ms: 6.088\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 412.32932711898394\n",
      "  time_since_restore: 2446.53537940979\n",
      "  time_this_iter_s: 23.06043553352356\n",
      "  time_total_s: 2446.53537940979\n",
      "  timestamp: 1553968210\n",
      "  timesteps_since_restore: 1020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 102\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2446 s, 102 iter, 1020000 ts, 825 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-50-33\n",
      "  done: false\n",
      "  episode_len_mean: 164.46\n",
      "  episode_reward_max: 1122.401136860594\n",
      "  episode_reward_mean: 812.2154647041201\n",
      "  episode_reward_min: -83.65414845051048\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5740\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.884\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 1030000\n",
      "    num_steps_trained: 1030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.334429776084187e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1485955715179443\n",
      "      kl: 1.4612191915512085\n",
      "      policy_loss: 0.07762722671031952\n",
      "      total_loss: 2345.345458984375\n",
      "      vf_explained_var: 0.8032186627388\n",
      "      vf_loss: 2345.267578125\n",
      "    sample_time_ms: 19281.909\n",
      "    update_time_ms: 6.39\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 406.1077323520601\n",
      "  time_since_restore: 2469.219279050827\n",
      "  time_this_iter_s: 22.683899641036987\n",
      "  time_total_s: 2469.219279050827\n",
      "  timestamp: 1553968233\n",
      "  timesteps_since_restore: 1030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1030000\n",
      "  training_iteration: 103\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2469 s, 103 iter, 1030000 ts, 812 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-50-56\n",
      "  done: false\n",
      "  episode_len_mean: 163.46\n",
      "  episode_reward_max: 1128.7656727618016\n",
      "  episode_reward_mean: 787.3194706541329\n",
      "  episode_reward_min: -83.30356938144479\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5800\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.846\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.0016443539335505e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0110416412353516\n",
      "      kl: 0.07256856560707092\n",
      "      policy_loss: 0.02119857259094715\n",
      "      total_loss: 2344.875\n",
      "      vf_explained_var: 0.8012616038322449\n",
      "      vf_loss: 2344.853759765625\n",
      "    sample_time_ms: 19212.052\n",
      "    update_time_ms: 6.346\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 393.65973532706647\n",
      "  time_since_restore: 2492.1033935546875\n",
      "  time_this_iter_s: 22.884114503860474\n",
      "  time_total_s: 2492.1033935546875\n",
      "  timestamp: 1553968256\n",
      "  timesteps_since_restore: 1040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 104\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2492 s, 104 iter, 1040000 ts, 787 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-51-19\n",
      "  done: false\n",
      "  episode_len_mean: 167.31\n",
      "  episode_reward_max: 1128.7656727618016\n",
      "  episode_reward_mean: 778.3719957711348\n",
      "  episode_reward_min: -82.58451173757678\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5860\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.926\n",
      "    load_time_ms: 1.661\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.502467771671245e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1225841045379639\n",
      "      kl: 0.6834498643875122\n",
      "      policy_loss: 0.02946390211582184\n",
      "      total_loss: 2219.59326171875\n",
      "      vf_explained_var: 0.8260247707366943\n",
      "      vf_loss: 2219.56396484375\n",
      "    sample_time_ms: 19186.239\n",
      "    update_time_ms: 6.468\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 389.1859978855675\n",
      "  time_since_restore: 2515.5115296840668\n",
      "  time_this_iter_s: 23.408136129379272\n",
      "  time_total_s: 2515.5115296840668\n",
      "  timestamp: 1553968279\n",
      "  timesteps_since_restore: 1050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 105\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2515 s, 105 iter, 1050000 ts, 778 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-51-43\n",
      "  done: false\n",
      "  episode_len_mean: 172.16\n",
      "  episode_reward_max: 1059.858917259211\n",
      "  episode_reward_mean: 759.4307358960328\n",
      "  episode_reward_min: -87.79369150095958\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 5915\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.645\n",
      "    load_time_ms: 1.633\n",
      "    num_steps_sampled: 1060000\n",
      "    num_steps_trained: 1060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1253700416735948e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5655521154403687\n",
      "      kl: 2.9528396129608154\n",
      "      policy_loss: 0.07903700321912766\n",
      "      total_loss: 2077.705810546875\n",
      "      vf_explained_var: 0.8393139243125916\n",
      "      vf_loss: 2077.626708984375\n",
      "    sample_time_ms: 19210.932\n",
      "    update_time_ms: 6.54\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 379.7153679480164\n",
      "  time_since_restore: 2539.0520622730255\n",
      "  time_this_iter_s: 23.54053258895874\n",
      "  time_total_s: 2539.0520622730255\n",
      "  timestamp: 1553968303\n",
      "  timesteps_since_restore: 1060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1060000\n",
      "  training_iteration: 106\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2539 s, 106 iter, 1060000 ts, 759 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-52-06\n",
      "  done: false\n",
      "  episode_len_mean: 172.7\n",
      "  episode_reward_max: 1099.6241646006667\n",
      "  episode_reward_mean: 806.397302206763\n",
      "  episode_reward_min: -69.89740010122924\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5975\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.558\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 1070000\n",
      "    num_steps_trained: 1070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6880549384333003e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.000569462776184\n",
      "      kl: 0.15823231637477875\n",
      "      policy_loss: 0.03857222944498062\n",
      "      total_loss: 2263.2138671875\n",
      "      vf_explained_var: 0.8257248997688293\n",
      "      vf_loss: 2263.175048828125\n",
      "    sample_time_ms: 19255.904\n",
      "    update_time_ms: 6.43\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 403.1986511033814\n",
      "  time_since_restore: 2562.530192375183\n",
      "  time_this_iter_s: 23.478130102157593\n",
      "  time_total_s: 2562.530192375183\n",
      "  timestamp: 1553968326\n",
      "  timesteps_since_restore: 1070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1070000\n",
      "  training_iteration: 107\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2562 s, 107 iter, 1070000 ts, 806 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-52-30\n",
      "  done: false\n",
      "  episode_len_mean: 166.07\n",
      "  episode_reward_max: 1073.7242873030912\n",
      "  episode_reward_mean: 814.9241176244749\n",
      "  episode_reward_min: -79.2769623033033\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 6037\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.987\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.532082903958318e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0166015625\n",
      "      kl: 0.09849642217159271\n",
      "      policy_loss: 0.028530796989798546\n",
      "      total_loss: 2155.072021484375\n",
      "      vf_explained_var: 0.8323745727539062\n",
      "      vf_loss: 2155.043701171875\n",
      "    sample_time_ms: 19313.193\n",
      "    update_time_ms: 7.356\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 407.4620588122375\n",
      "  time_since_restore: 2585.8571956157684\n",
      "  time_this_iter_s: 23.327003240585327\n",
      "  time_total_s: 2585.8571956157684\n",
      "  timestamp: 1553968350\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 108\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2585 s, 108 iter, 1080000 ts, 815 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-52-54\n",
      "  done: false\n",
      "  episode_len_mean: 168.3\n",
      "  episode_reward_max: 1082.6570032947586\n",
      "  episode_reward_mean: 782.5742207583421\n",
      "  episode_reward_min: -69.27513426650896\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 6096\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.662\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 1090000\n",
      "    num_steps_trained: 1090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.7981245213735996e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0084071159362793\n",
      "      kl: 11.511438369750977\n",
      "      policy_loss: 0.19044001400470734\n",
      "      total_loss: 2102.69384765625\n",
      "      vf_explained_var: 0.8171795606613159\n",
      "      vf_loss: 2102.503662109375\n",
      "    sample_time_ms: 19332.286\n",
      "    update_time_ms: 6.605\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 391.2871103791712\n",
      "  time_since_restore: 2609.5518000125885\n",
      "  time_this_iter_s: 23.69460439682007\n",
      "  time_total_s: 2609.5518000125885\n",
      "  timestamp: 1553968374\n",
      "  timesteps_since_restore: 1090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1090000\n",
      "  training_iteration: 109\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2609 s, 109 iter, 1090000 ts, 783 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-53-18\n",
      "  done: false\n",
      "  episode_len_mean: 169.05\n",
      "  episode_reward_max: 1119.9564686607926\n",
      "  episode_reward_mean: 794.4635377707887\n",
      "  episode_reward_min: -74.61612726005043\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 6157\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.726\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 1100000\n",
      "    num_steps_trained: 1100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.697185954879787e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.100933313369751\n",
      "      kl: 0.09604086726903915\n",
      "      policy_loss: 0.032131556421518326\n",
      "      total_loss: 2163.939453125\n",
      "      vf_explained_var: 0.831710934638977\n",
      "      vf_loss: 2163.906982421875\n",
      "    sample_time_ms: 19442.323\n",
      "    update_time_ms: 6.642\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 397.2317688853944\n",
      "  time_since_restore: 2633.926696538925\n",
      "  time_this_iter_s: 24.37489652633667\n",
      "  time_total_s: 2633.926696538925\n",
      "  timestamp: 1553968398\n",
      "  timesteps_since_restore: 1100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1100000\n",
      "  training_iteration: 110\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2633 s, 110 iter, 1100000 ts, 794 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-53-43\n",
      "  done: false\n",
      "  episode_len_mean: 160.88\n",
      "  episode_reward_max: 1093.2678397449824\n",
      "  episode_reward_mean: 797.2740418019146\n",
      "  episode_reward_min: -85.76030698011213\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 6220\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.787\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.54577959406417e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9222445487976074\n",
      "      kl: 0.40108275413513184\n",
      "      policy_loss: 0.02036120556294918\n",
      "      total_loss: 1989.0791015625\n",
      "      vf_explained_var: 0.8505953550338745\n",
      "      vf_loss: 1989.058837890625\n",
      "    sample_time_ms: 19589.815\n",
      "    update_time_ms: 6.672\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 398.63702090095745\n",
      "  time_since_restore: 2658.422346830368\n",
      "  time_this_iter_s: 24.49565029144287\n",
      "  time_total_s: 2658.422346830368\n",
      "  timestamp: 1553968423\n",
      "  timesteps_since_restore: 1110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 111\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2658 s, 111 iter, 1110000 ts, 797 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-54-06\n",
      "  done: false\n",
      "  episode_len_mean: 159.73\n",
      "  episode_reward_max: 1118.780793999078\n",
      "  episode_reward_mean: 817.7113478741078\n",
      "  episode_reward_min: -87.95304077669226\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 6282\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3871.714\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 1120000\n",
      "    num_steps_trained: 1120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.281866839847952e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7250064015388489\n",
      "      kl: 0.07293879985809326\n",
      "      policy_loss: 0.024942856281995773\n",
      "      total_loss: 1953.612548828125\n",
      "      vf_explained_var: 0.861777663230896\n",
      "      vf_loss: 1953.5872802734375\n",
      "    sample_time_ms: 19596.961\n",
      "    update_time_ms: 6.552\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 408.8556739370538\n",
      "  time_since_restore: 2681.4730310440063\n",
      "  time_this_iter_s: 23.050684213638306\n",
      "  time_total_s: 2681.4730310440063\n",
      "  timestamp: 1553968446\n",
      "  timesteps_since_restore: 1120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1120000\n",
      "  training_iteration: 112\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2681 s, 112 iter, 1120000 ts, 818 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-54-30\n",
      "  done: false\n",
      "  episode_len_mean: 159.33\n",
      "  episode_reward_max: 1118.780793999078\n",
      "  episode_reward_mean: 816.1428497348602\n",
      "  episode_reward_min: -68.74696878663624\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 6345\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.919\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 1130000\n",
      "    num_steps_trained: 1130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.922800392120826e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9378073215484619\n",
      "      kl: 0.1001933291554451\n",
      "      policy_loss: 0.033465269953012466\n",
      "      total_loss: 2110.3681640625\n",
      "      vf_explained_var: 0.8345685005187988\n",
      "      vf_loss: 2110.3349609375\n",
      "    sample_time_ms: 19726.49\n",
      "    update_time_ms: 5.991\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 408.0714248674301\n",
      "  time_since_restore: 2705.557228088379\n",
      "  time_this_iter_s: 24.08419704437256\n",
      "  time_total_s: 2705.557228088379\n",
      "  timestamp: 1553968470\n",
      "  timesteps_since_restore: 1130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1130000\n",
      "  training_iteration: 113\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2705 s, 113 iter, 1130000 ts, 816 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-54-53\n",
      "  done: false\n",
      "  episode_len_mean: 161.21\n",
      "  episode_reward_max: 1132.8532873634203\n",
      "  episode_reward_mean: 836.1449362096137\n",
      "  episode_reward_min: -54.77466270857329\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 6408\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.242\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.884200124960096e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8252381682395935\n",
      "      kl: 0.08575008809566498\n",
      "      policy_loss: 0.021205779165029526\n",
      "      total_loss: 2237.378173828125\n",
      "      vf_explained_var: 0.8546244502067566\n",
      "      vf_loss: 2237.357177734375\n",
      "    sample_time_ms: 19767.834\n",
      "    update_time_ms: 6.049\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 418.0724681048068\n",
      "  time_since_restore: 2728.7991828918457\n",
      "  time_this_iter_s: 23.241954803466797\n",
      "  time_total_s: 2728.7991828918457\n",
      "  timestamp: 1553968493\n",
      "  timesteps_since_restore: 1140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 114\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2728 s, 114 iter, 1140000 ts, 836 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-55-17\n",
      "  done: false\n",
      "  episode_len_mean: 157.31\n",
      "  episode_reward_max: 1132.8532873634203\n",
      "  episode_reward_mean: 805.4859090182154\n",
      "  episode_reward_min: -54.77466270857329\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 6473\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3868.01\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 1150000\n",
      "    num_steps_trained: 1150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.326301246231328e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7795997858047485\n",
      "      kl: 1.2043734788894653\n",
      "      policy_loss: 0.046786077320575714\n",
      "      total_loss: 2232.15380859375\n",
      "      vf_explained_var: 0.8331018090248108\n",
      "      vf_loss: 2232.10693359375\n",
      "    sample_time_ms: 19857.985\n",
      "    update_time_ms: 6.059\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 402.74295450910756\n",
      "  time_since_restore: 2753.014405488968\n",
      "  time_this_iter_s: 24.215222597122192\n",
      "  time_total_s: 2753.014405488968\n",
      "  timestamp: 1553968517\n",
      "  timesteps_since_restore: 1150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1150000\n",
      "  training_iteration: 115\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2753 s, 115 iter, 1150000 ts, 805 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-55-41\n",
      "  done: false\n",
      "  episode_len_mean: 161.71\n",
      "  episode_reward_max: 1119.360465698523\n",
      "  episode_reward_mean: 825.9421957226192\n",
      "  episode_reward_min: -49.33569313065445\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6533\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.168\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 1160000\n",
      "    num_steps_trained: 1160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.489450281160216e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8990891575813293\n",
      "      kl: 268.48272705078125\n",
      "      policy_loss: 0.24098528921604156\n",
      "      total_loss: 2221.95068359375\n",
      "      vf_explained_var: 0.8321108818054199\n",
      "      vf_loss: 2221.709716796875\n",
      "    sample_time_ms: 19826.65\n",
      "    update_time_ms: 6.075\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 412.97109786130966\n",
      "  time_since_restore: 2776.3832128047943\n",
      "  time_this_iter_s: 23.368807315826416\n",
      "  time_total_s: 2776.3832128047943\n",
      "  timestamp: 1553968541\n",
      "  timesteps_since_restore: 1160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1160000\n",
      "  training_iteration: 116\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2776 s, 116 iter, 1160000 ts, 826 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-56-04\n",
      "  done: false\n",
      "  episode_len_mean: 164.75\n",
      "  episode_reward_max: 1121.7574199019841\n",
      "  episode_reward_mean: 868.7626033828013\n",
      "  episode_reward_min: -84.56050387605448\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6593\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.629\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.734177804020488e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0255744457244873\n",
      "      kl: 122.2813720703125\n",
      "      policy_loss: 0.15810993313789368\n",
      "      total_loss: 2076.44873046875\n",
      "      vf_explained_var: 0.8520448207855225\n",
      "      vf_loss: 2076.29052734375\n",
      "    sample_time_ms: 19843.576\n",
      "    update_time_ms: 6.056\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 434.3813016914006\n",
      "  time_since_restore: 2800.0887830257416\n",
      "  time_this_iter_s: 23.705570220947266\n",
      "  time_total_s: 2800.0887830257416\n",
      "  timestamp: 1553968564\n",
      "  timesteps_since_restore: 1170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 117\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2800 s, 117 iter, 1170000 ts, 869 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 173.41\n",
      "  episode_reward_max: 1121.7574199019841\n",
      "  episode_reward_mean: 865.5299830160507\n",
      "  episode_reward_min: -71.72878598288682\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 6650\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.973\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 1180000\n",
      "    num_steps_trained: 1180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4601263000261588e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3403172492980957\n",
      "      kl: 0.07048246264457703\n",
      "      policy_loss: 0.01997981406748295\n",
      "      total_loss: 1908.22900390625\n",
      "      vf_explained_var: 0.8791325688362122\n",
      "      vf_loss: 1908.2091064453125\n",
      "    sample_time_ms: 19879.074\n",
      "    update_time_ms: 5.326\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 432.7649915080254\n",
      "  time_since_restore: 2823.8181829452515\n",
      "  time_this_iter_s: 23.729399919509888\n",
      "  time_total_s: 2823.8181829452515\n",
      "  timestamp: 1553968588\n",
      "  timesteps_since_restore: 1180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1180000\n",
      "  training_iteration: 118\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2823 s, 118 iter, 1180000 ts, 866 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-56-53\n",
      "  done: false\n",
      "  episode_len_mean: 175.22\n",
      "  episode_reward_max: 1083.2837532567924\n",
      "  episode_reward_mean: 847.3920517516665\n",
      "  episode_reward_min: -71.72878598288682\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 6706\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.381\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 1190000\n",
      "    num_steps_trained: 1190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.190189608857916e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3195304870605469\n",
      "      kl: 0.27545759081840515\n",
      "      policy_loss: 0.03722494840621948\n",
      "      total_loss: 1694.605224609375\n",
      "      vf_explained_var: 0.8730061650276184\n",
      "      vf_loss: 1694.5677490234375\n",
      "    sample_time_ms: 19944.827\n",
      "    update_time_ms: 5.293\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 423.69602587583324\n",
      "  time_since_restore: 2848.1878457069397\n",
      "  time_this_iter_s: 24.369662761688232\n",
      "  time_total_s: 2848.1878457069397\n",
      "  timestamp: 1553968613\n",
      "  timesteps_since_restore: 1190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1190000\n",
      "  training_iteration: 119\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2848 s, 119 iter, 1190000 ts, 847 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-57-16\n",
      "  done: false\n",
      "  episode_len_mean: 168.15\n",
      "  episode_reward_max: 1069.1114727081192\n",
      "  episode_reward_mean: 827.9004984784518\n",
      "  episode_reward_min: -56.460865772112555\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 6767\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.273\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.2852848368033474e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2021249532699585\n",
      "      kl: 0.34853631258010864\n",
      "      policy_loss: 0.029840704053640366\n",
      "      total_loss: 2247.373046875\n",
      "      vf_explained_var: 0.8357064723968506\n",
      "      vf_loss: 2247.343017578125\n",
      "    sample_time_ms: 19890.194\n",
      "    update_time_ms: 5.898\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 413.9502492392259\n",
      "  time_since_restore: 2871.9781250953674\n",
      "  time_this_iter_s: 23.790279388427734\n",
      "  time_total_s: 2871.9781250953674\n",
      "  timestamp: 1553968636\n",
      "  timesteps_since_restore: 1200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 120\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2871 s, 120 iter, 1200000 ts, 828 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-57-41\n",
      "  done: false\n",
      "  episode_len_mean: 163.47\n",
      "  episode_reward_max: 1067.0639660018003\n",
      "  episode_reward_mean: 806.3591881112098\n",
      "  episode_reward_min: -82.68881648609906\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 6823\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.18\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 1210000\n",
      "    num_steps_trained: 1210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.9279263022929554e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2761578559875488\n",
      "      kl: 0.7929095029830933\n",
      "      policy_loss: 0.05363516882061958\n",
      "      total_loss: 1656.5562744140625\n",
      "      vf_explained_var: 0.8949035406112671\n",
      "      vf_loss: 1656.5025634765625\n",
      "    sample_time_ms: 19828.603\n",
      "    update_time_ms: 5.854\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 403.1795940556048\n",
      "  time_since_restore: 2896.0356872081757\n",
      "  time_this_iter_s: 24.057562112808228\n",
      "  time_total_s: 2896.0356872081757\n",
      "  timestamp: 1553968661\n",
      "  timesteps_since_restore: 1210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1210000\n",
      "  training_iteration: 121\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2896 s, 121 iter, 1210000 ts, 806 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-58-04\n",
      "  done: false\n",
      "  episode_len_mean: 168.77\n",
      "  episode_reward_max: 1078.1043681431074\n",
      "  episode_reward_mean: 826.7705360855874\n",
      "  episode_reward_min: -101.76808693237159\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6883\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.944\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 1220000\n",
      "    num_steps_trained: 1220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.39188966519767e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1821188926696777\n",
      "      kl: 0.16796033084392548\n",
      "      policy_loss: 0.021369829773902893\n",
      "      total_loss: 1590.1802978515625\n",
      "      vf_explained_var: 0.8876684308052063\n",
      "      vf_loss: 1590.1588134765625\n",
      "    sample_time_ms: 19869.51\n",
      "    update_time_ms: 5.875\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 413.3852680427937\n",
      "  time_since_restore: 2919.5024819374084\n",
      "  time_this_iter_s: 23.466794729232788\n",
      "  time_total_s: 2919.5024819374084\n",
      "  timestamp: 1553968684\n",
      "  timesteps_since_restore: 1220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1220000\n",
      "  training_iteration: 122\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2919 s, 122 iter, 1220000 ts, 827 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-58-28\n",
      "  done: false\n",
      "  episode_len_mean: 180.53\n",
      "  episode_reward_max: 1096.6263520923205\n",
      "  episode_reward_mean: 846.6058128371035\n",
      "  episode_reward_min: -101.76808693237159\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 6936\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.711\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1087836615378873e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5403884649276733\n",
      "      kl: 0.10529924184083939\n",
      "      policy_loss: 0.031247805804014206\n",
      "      total_loss: 1716.105712890625\n",
      "      vf_explained_var: 0.8845117092132568\n",
      "      vf_loss: 1716.074462890625\n",
      "    sample_time_ms: 19869.391\n",
      "    update_time_ms: 5.951\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 423.30290641855174\n",
      "  time_since_restore: 2943.5139701366425\n",
      "  time_this_iter_s: 24.01148819923401\n",
      "  time_total_s: 2943.5139701366425\n",
      "  timestamp: 1553968708\n",
      "  timesteps_since_restore: 1230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 123\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2943 s, 123 iter, 1230000 ts, 847 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 180.17\n",
      "  episode_reward_max: 1086.8724279730802\n",
      "  episode_reward_mean: 843.1173478419503\n",
      "  episode_reward_min: -68.80162173740868\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 6994\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.553\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 1240000\n",
      "    num_steps_trained: 1240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.663175619361773e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1743842363357544\n",
      "      kl: 0.13891008496284485\n",
      "      policy_loss: 0.032529667019844055\n",
      "      total_loss: 1919.777587890625\n",
      "      vf_explained_var: 0.8699303865432739\n",
      "      vf_loss: 1919.7447509765625\n",
      "    sample_time_ms: 19908.538\n",
      "    update_time_ms: 5.857\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 421.55867392097497\n",
      "  time_since_restore: 2967.193652153015\n",
      "  time_this_iter_s: 23.67968201637268\n",
      "  time_total_s: 2967.193652153015\n",
      "  timestamp: 1553968732\n",
      "  timesteps_since_restore: 1240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1240000\n",
      "  training_iteration: 124\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2967 s, 124 iter, 1240000 ts, 843 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-59-16\n",
      "  done: false\n",
      "  episode_len_mean: 168.65\n",
      "  episode_reward_max: 1105.0835492343033\n",
      "  episode_reward_mean: 805.9183311416357\n",
      "  episode_reward_min: -94.05564312952582\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7054\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.706\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 1250000\n",
      "    num_steps_trained: 1250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4947630902294807e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.325010061264038\n",
      "      kl: 0.19322022795677185\n",
      "      policy_loss: 0.025433365255594254\n",
      "      total_loss: 1989.4443359375\n",
      "      vf_explained_var: 0.870192289352417\n",
      "      vf_loss: 1989.4188232421875\n",
      "    sample_time_ms: 19855.421\n",
      "    update_time_ms: 5.726\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 402.9591655708178\n",
      "  time_since_restore: 2990.9182212352753\n",
      "  time_this_iter_s: 23.724569082260132\n",
      "  time_total_s: 2990.9182212352753\n",
      "  timestamp: 1553968756\n",
      "  timesteps_since_restore: 1250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1250000\n",
      "  training_iteration: 125\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 2990 s, 125 iter, 1250000 ts, 806 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_18-59-39\n",
      "  done: false\n",
      "  episode_len_mean: 166.99\n",
      "  episode_reward_max: 1102.698335141756\n",
      "  episode_reward_mean: 816.9374459213885\n",
      "  episode_reward_min: -94.05564312952582\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 7111\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.714\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.7421448047508105e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3377302885055542\n",
      "      kl: 98.70047760009766\n",
      "      policy_loss: 0.21384994685649872\n",
      "      total_loss: 1671.3377685546875\n",
      "      vf_explained_var: 0.8775334358215332\n",
      "      vf_loss: 1671.1239013671875\n",
      "    sample_time_ms: 19882.572\n",
      "    update_time_ms: 5.877\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 408.46872296069427\n",
      "  time_since_restore: 3014.639520406723\n",
      "  time_this_iter_s: 23.721299171447754\n",
      "  time_total_s: 3014.639520406723\n",
      "  timestamp: 1553968779\n",
      "  timesteps_since_restore: 1260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 126\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3014 s, 126 iter, 1260000 ts, 817 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-00-03\n",
      "  done: false\n",
      "  episode_len_mean: 170.34\n",
      "  episode_reward_max: 1107.0377882137627\n",
      "  episode_reward_mean: 893.6847019317559\n",
      "  episode_reward_min: -41.31058437729641\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 7173\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.791\n",
      "    load_time_ms: 1.471\n",
      "    num_steps_sampled: 1270000\n",
      "    num_steps_trained: 1270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6132175459393946e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8214613199234009\n",
      "      kl: 0.06110236421227455\n",
      "      policy_loss: 0.026352161541581154\n",
      "      total_loss: 1759.52587890625\n",
      "      vf_explained_var: 0.8954786658287048\n",
      "      vf_loss: 1759.4996337890625\n",
      "    sample_time_ms: 19833.375\n",
      "    update_time_ms: 5.73\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 446.84235096587776\n",
      "  time_since_restore: 3037.799083709717\n",
      "  time_this_iter_s: 23.159563302993774\n",
      "  time_total_s: 3037.799083709717\n",
      "  timestamp: 1553968803\n",
      "  timesteps_since_restore: 1270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1270000\n",
      "  training_iteration: 127\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3037 s, 127 iter, 1270000 ts, 894 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-00-26\n",
      "  done: false\n",
      "  episode_len_mean: 166.18\n",
      "  episode_reward_max: 1080.050728773148\n",
      "  episode_reward_mean: 817.2951356349431\n",
      "  episode_reward_min: -78.88794907796753\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7233\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.065\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 1280000\n",
      "    num_steps_trained: 1280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.419825980095913e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2745850086212158\n",
      "      kl: 0.06848070025444031\n",
      "      policy_loss: 0.02272932417690754\n",
      "      total_loss: 1874.7525634765625\n",
      "      vf_explained_var: 0.8650546669960022\n",
      "      vf_loss: 1874.72998046875\n",
      "    sample_time_ms: 19761.994\n",
      "    update_time_ms: 5.605\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 408.64756781747155\n",
      "  time_since_restore: 3060.7375144958496\n",
      "  time_this_iter_s: 22.938430786132812\n",
      "  time_total_s: 3060.7375144958496\n",
      "  timestamp: 1553968826\n",
      "  timesteps_since_restore: 1280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1280000\n",
      "  training_iteration: 128\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3060 s, 128 iter, 1280000 ts, 817 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-00-50\n",
      "  done: false\n",
      "  episode_len_mean: 169.61\n",
      "  episode_reward_max: 1076.34074790296\n",
      "  episode_reward_mean: 817.9628713148148\n",
      "  episode_reward_min: -78.88794907796753\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 7292\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.771\n",
      "    load_time_ms: 1.471\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2629738292517512e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.180310606956482\n",
      "      kl: 0.1026315689086914\n",
      "      policy_loss: 0.03244743496179581\n",
      "      total_loss: 1752.6253662109375\n",
      "      vf_explained_var: 0.886103093624115\n",
      "      vf_loss: 1752.5928955078125\n",
      "    sample_time_ms: 19727.385\n",
      "    update_time_ms: 5.622\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 408.98143565740736\n",
      "  time_since_restore: 3084.735775232315\n",
      "  time_this_iter_s: 23.998260736465454\n",
      "  time_total_s: 3084.735775232315\n",
      "  timestamp: 1553968850\n",
      "  timesteps_since_restore: 1290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 129\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3084 s, 129 iter, 1290000 ts, 818 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-01-13\n",
      "  done: false\n",
      "  episode_len_mean: 167.23\n",
      "  episode_reward_max: 1148.9952533882617\n",
      "  episode_reward_mean: 804.4281082460227\n",
      "  episode_reward_min: -64.80942918667037\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7352\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.771\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 1300000\n",
      "    num_steps_trained: 1300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8944608794028983e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1664190292358398\n",
      "      kl: 0.6212053298950195\n",
      "      policy_loss: 0.07202661782503128\n",
      "      total_loss: 2045.2083740234375\n",
      "      vf_explained_var: 0.8600316047668457\n",
      "      vf_loss: 2045.136474609375\n",
      "    sample_time_ms: 19699.467\n",
      "    update_time_ms: 5.038\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 402.21405412301146\n",
      "  time_since_restore: 3108.215872526169\n",
      "  time_this_iter_s: 23.48009729385376\n",
      "  time_total_s: 3108.215872526169\n",
      "  timestamp: 1553968873\n",
      "  timesteps_since_restore: 1300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1300000\n",
      "  training_iteration: 130\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3108 s, 130 iter, 1300000 ts, 804 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-01-37\n",
      "  done: false\n",
      "  episode_len_mean: 166.89\n",
      "  episode_reward_max: 1148.9952533882617\n",
      "  episode_reward_mean: 792.819966089258\n",
      "  episode_reward_min: -65.30224103923194\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 7409\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.53\n",
      "    load_time_ms: 1.562\n",
      "    num_steps_sampled: 1310000\n",
      "    num_steps_trained: 1310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.841690912528533e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4173227548599243\n",
      "      kl: 0.09512065351009369\n",
      "      policy_loss: 0.025879856199026108\n",
      "      total_loss: 1743.269775390625\n",
      "      vf_explained_var: 0.8771145343780518\n",
      "      vf_loss: 1743.2440185546875\n",
      "    sample_time_ms: 19703.824\n",
      "    update_time_ms: 4.99\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 396.40998304462903\n",
      "  time_since_restore: 3132.3345029354095\n",
      "  time_this_iter_s: 24.118630409240723\n",
      "  time_total_s: 3132.3345029354095\n",
      "  timestamp: 1553968897\n",
      "  timesteps_since_restore: 1310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1310000\n",
      "  training_iteration: 131\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3132 s, 131 iter, 1310000 ts, 793 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-02-01\n",
      "  done: false\n",
      "  episode_len_mean: 169.31\n",
      "  episode_reward_max: 1132.5103420422597\n",
      "  episode_reward_mean: 736.3091721836062\n",
      "  episode_reward_min: -82.49720056932607\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 7472\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.3\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.2625362332675276e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3076387643814087\n",
      "      kl: 0.10500258952379227\n",
      "      policy_loss: 0.03404530882835388\n",
      "      total_loss: 2358.06005859375\n",
      "      vf_explained_var: 0.8412878513336182\n",
      "      vf_loss: 2358.026123046875\n",
      "    sample_time_ms: 19698.913\n",
      "    update_time_ms: 5.117\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 368.1545860918031\n",
      "  time_since_restore: 3155.7424952983856\n",
      "  time_this_iter_s: 23.407992362976074\n",
      "  time_total_s: 3155.7424952983856\n",
      "  timestamp: 1553968921\n",
      "  timesteps_since_restore: 1320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 132\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3155 s, 132 iter, 1320000 ts, 736 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-02-25\n",
      "  done: false\n",
      "  episode_len_mean: 166.96\n",
      "  episode_reward_max: 1141.2435088992802\n",
      "  episode_reward_mean: 818.2708155930677\n",
      "  episode_reward_min: -68.85612430883842\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 7533\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.634\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 1330000\n",
      "    num_steps_trained: 1330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.393804756477106e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9601563811302185\n",
      "      kl: 0.13965263962745667\n",
      "      policy_loss: 0.036621373146772385\n",
      "      total_loss: 1873.867431640625\n",
      "      vf_explained_var: 0.8753846287727356\n",
      "      vf_loss: 1873.83056640625\n",
      "    sample_time_ms: 19691.812\n",
      "    update_time_ms: 5.366\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 409.13540779653385\n",
      "  time_since_restore: 3179.708765745163\n",
      "  time_this_iter_s: 23.966270446777344\n",
      "  time_total_s: 3179.708765745163\n",
      "  timestamp: 1553968945\n",
      "  timesteps_since_restore: 1330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1330000\n",
      "  training_iteration: 133\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3179 s, 133 iter, 1330000 ts, 818 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-02-48\n",
      "  done: false\n",
      "  episode_len_mean: 171.14\n",
      "  episode_reward_max: 1141.2435088992802\n",
      "  episode_reward_mean: 812.4899541236588\n",
      "  episode_reward_min: -93.12355859003087\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 7589\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.431\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 1340000\n",
      "    num_steps_trained: 1340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.590706050513487e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4439254999160767\n",
      "      kl: 0.06890203803777695\n",
      "      policy_loss: 0.01991000771522522\n",
      "      total_loss: 1613.2701416015625\n",
      "      vf_explained_var: 0.8952795267105103\n",
      "      vf_loss: 1613.2501220703125\n",
      "    sample_time_ms: 19662.542\n",
      "    update_time_ms: 5.38\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 406.2449770618294\n",
      "  time_since_restore: 3203.0456414222717\n",
      "  time_this_iter_s: 23.336875677108765\n",
      "  time_total_s: 3203.0456414222717\n",
      "  timestamp: 1553968968\n",
      "  timesteps_since_restore: 1340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1340000\n",
      "  training_iteration: 134\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3203 s, 134 iter, 1340000 ts, 812 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-03-12\n",
      "  done: false\n",
      "  episode_len_mean: 161.88\n",
      "  episode_reward_max: 1118.3774261287995\n",
      "  episode_reward_mean: 785.1179860826148\n",
      "  episode_reward_min: -101.40477997076268\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 7653\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.573\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4386059617871316e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9135082960128784\n",
      "      kl: 52.90848922729492\n",
      "      policy_loss: 0.13626329600811005\n",
      "      total_loss: 2463.28955078125\n",
      "      vf_explained_var: 0.8348795771598816\n",
      "      vf_loss: 2463.153076171875\n",
      "    sample_time_ms: 19682.533\n",
      "    update_time_ms: 5.438\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 392.5589930413073\n",
      "  time_since_restore: 3226.9521317481995\n",
      "  time_this_iter_s: 23.906490325927734\n",
      "  time_total_s: 3226.9521317481995\n",
      "  timestamp: 1553968992\n",
      "  timesteps_since_restore: 1350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 135\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3226 s, 135 iter, 1350000 ts, 785 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-03-36\n",
      "  done: false\n",
      "  episode_len_mean: 154.93\n",
      "  episode_reward_max: 1075.5796242721099\n",
      "  episode_reward_mean: 763.5118055900504\n",
      "  episode_reward_min: -61.77838213449132\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 7718\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.375\n",
      "    load_time_ms: 1.621\n",
      "    num_steps_sampled: 1360000\n",
      "    num_steps_trained: 1360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.157909267941349e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8350138664245605\n",
      "      kl: 0.1553274393081665\n",
      "      policy_loss: 0.03063410334289074\n",
      "      total_loss: 1873.9146728515625\n",
      "      vf_explained_var: 0.8877995610237122\n",
      "      vf_loss: 1873.8841552734375\n",
      "    sample_time_ms: 19746.51\n",
      "    update_time_ms: 5.217\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 381.7559027950252\n",
      "  time_since_restore: 3251.1212050914764\n",
      "  time_this_iter_s: 24.169073343276978\n",
      "  time_total_s: 3251.1212050914764\n",
      "  timestamp: 1553969016\n",
      "  timesteps_since_restore: 1360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1360000\n",
      "  training_iteration: 136\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3251 s, 136 iter, 1360000 ts, 764 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-04-00\n",
      "  done: false\n",
      "  episode_len_mean: 151.55\n",
      "  episode_reward_max: 1167.7138546186843\n",
      "  episode_reward_mean: 758.2049120654113\n",
      "  episode_reward_min: -78.87313625732662\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 7784\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.091\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 1370000\n",
      "    num_steps_trained: 1370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.2368634682311548e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.939835786819458\n",
      "      kl: 0.06790558248758316\n",
      "      policy_loss: 0.022492676973342896\n",
      "      total_loss: 1924.54931640625\n",
      "      vf_explained_var: 0.8862530589103699\n",
      "      vf_loss: 1924.52685546875\n",
      "    sample_time_ms: 19811.43\n",
      "    update_time_ms: 5.354\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 379.1024560327057\n",
      "  time_since_restore: 3274.933887243271\n",
      "  time_this_iter_s: 23.812682151794434\n",
      "  time_total_s: 3274.933887243271\n",
      "  timestamp: 1553969040\n",
      "  timesteps_since_restore: 1370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1370000\n",
      "  training_iteration: 137\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3274 s, 137 iter, 1370000 ts, 758 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-04-23\n",
      "  done: false\n",
      "  episode_len_mean: 156.33\n",
      "  episode_reward_max: 1095.2706521242028\n",
      "  episode_reward_mean: 792.4522382112776\n",
      "  episode_reward_min: -78.87313625732662\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 7847\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.539\n",
      "    load_time_ms: 1.667\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.855295852868036e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0983819961547852\n",
      "      kl: 0.8538356423377991\n",
      "      policy_loss: 0.054715897887945175\n",
      "      total_loss: 2220.954345703125\n",
      "      vf_explained_var: 0.8518614172935486\n",
      "      vf_loss: 2220.899658203125\n",
      "    sample_time_ms: 19852.343\n",
      "    update_time_ms: 5.299\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 396.2261191056388\n",
      "  time_since_restore: 3298.2653081417084\n",
      "  time_this_iter_s: 23.3314208984375\n",
      "  time_total_s: 3298.2653081417084\n",
      "  timestamp: 1553969063\n",
      "  timesteps_since_restore: 1380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 138\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3298 s, 138 iter, 1380000 ts, 792 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-04-47\n",
      "  done: false\n",
      "  episode_len_mean: 171.11\n",
      "  episode_reward_max: 1142.723013637204\n",
      "  episode_reward_mean: 856.4289547277779\n",
      "  episode_reward_min: -43.52419625539011\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 7903\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3874.934\n",
      "    load_time_ms: 1.709\n",
      "    num_steps_sampled: 1390000\n",
      "    num_steps_trained: 1390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.28294508034466e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3867501020431519\n",
      "      kl: 0.2233004868030548\n",
      "      policy_loss: 0.05035794526338577\n",
      "      total_loss: 1844.251953125\n",
      "      vf_explained_var: 0.8742215037345886\n",
      "      vf_loss: 1844.2015380859375\n",
      "    sample_time_ms: 19787.818\n",
      "    update_time_ms: 5.311\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 428.2144773638889\n",
      "  time_since_restore: 3321.6124727725983\n",
      "  time_this_iter_s: 23.347164630889893\n",
      "  time_total_s: 3321.6124727725983\n",
      "  timestamp: 1553969087\n",
      "  timesteps_since_restore: 1390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1390000\n",
      "  training_iteration: 139\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3321 s, 139 iter, 1390000 ts, 856 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-05-11\n",
      "  done: false\n",
      "  episode_len_mean: 166.53\n",
      "  episode_reward_max: 1118.3418253851787\n",
      "  episode_reward_mean: 832.4187509309097\n",
      "  episode_reward_min: -91.27090788977121\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7963\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.422\n",
      "    load_time_ms: 1.731\n",
      "    num_steps_sampled: 1400000\n",
      "    num_steps_trained: 1400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0924415018431777e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0611108541488647\n",
      "      kl: 0.09775549173355103\n",
      "      policy_loss: 0.024193400517106056\n",
      "      total_loss: 1398.9171142578125\n",
      "      vf_explained_var: 0.9182217121124268\n",
      "      vf_loss: 1398.892822265625\n",
      "    sample_time_ms: 19779.941\n",
      "    update_time_ms: 5.332\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 416.20937546545485\n",
      "  time_since_restore: 3345.2203521728516\n",
      "  time_this_iter_s: 23.607879400253296\n",
      "  time_total_s: 3345.2203521728516\n",
      "  timestamp: 1553969111\n",
      "  timesteps_since_restore: 1400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1400000\n",
      "  training_iteration: 140\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3345 s, 140 iter, 1400000 ts, 832 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-05-34\n",
      "  done: false\n",
      "  episode_len_mean: 159.61\n",
      "  episode_reward_max: 1107.1097773433996\n",
      "  episode_reward_mean: 814.0074955374092\n",
      "  episode_reward_min: -91.27090788977121\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 8027\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.525\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6386621226605058e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9624813795089722\n",
      "      kl: 0.8474560976028442\n",
      "      policy_loss: 0.05014955624938011\n",
      "      total_loss: 2198.351806640625\n",
      "      vf_explained_var: 0.8689895272254944\n",
      "      vf_loss: 2198.3017578125\n",
      "    sample_time_ms: 19736.152\n",
      "    update_time_ms: 5.335\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 407.00374776870456\n",
      "  time_since_restore: 3368.7321112155914\n",
      "  time_this_iter_s: 23.511759042739868\n",
      "  time_total_s: 3368.7321112155914\n",
      "  timestamp: 1553969134\n",
      "  timesteps_since_restore: 1410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 141\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3368 s, 141 iter, 1410000 ts, 814 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-05-58\n",
      "  done: false\n",
      "  episode_len_mean: 159.03\n",
      "  episode_reward_max: 1106.7893549363419\n",
      "  episode_reward_mean: 805.0213969122696\n",
      "  episode_reward_min: -73.1984327722832\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 8088\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.555\n",
      "    load_time_ms: 1.704\n",
      "    num_steps_sampled: 1420000\n",
      "    num_steps_trained: 1420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4579933574631063e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2441474199295044\n",
      "      kl: 0.0630130022764206\n",
      "      policy_loss: 0.019174614921212196\n",
      "      total_loss: 1704.915283203125\n",
      "      vf_explained_var: 0.8978123068809509\n",
      "      vf_loss: 1704.896240234375\n",
      "    sample_time_ms: 19760.381\n",
      "    update_time_ms: 5.222\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 402.5106984561348\n",
      "  time_since_restore: 3392.351738214493\n",
      "  time_this_iter_s: 23.619626998901367\n",
      "  time_total_s: 3392.351738214493\n",
      "  timestamp: 1553969158\n",
      "  timesteps_since_restore: 1420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1420000\n",
      "  training_iteration: 142\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3392 s, 142 iter, 1420000 ts, 805 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-06-21\n",
      "  done: false\n",
      "  episode_len_mean: 162.4\n",
      "  episode_reward_max: 1135.0120489750752\n",
      "  episode_reward_mean: 786.7267390187595\n",
      "  episode_reward_min: -93.9371629908343\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 8150\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.161\n",
      "    load_time_ms: 1.691\n",
      "    num_steps_sampled: 1430000\n",
      "    num_steps_trained: 1430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6869896025137905e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.269425868988037\n",
      "      kl: 0.04052333906292915\n",
      "      policy_loss: 0.011393722146749496\n",
      "      total_loss: 1908.588134765625\n",
      "      vf_explained_var: 0.8714274764060974\n",
      "      vf_loss: 1908.5767822265625\n",
      "    sample_time_ms: 19687.869\n",
      "    update_time_ms: 4.816\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 393.36336950937977\n",
      "  time_since_restore: 3415.6171033382416\n",
      "  time_this_iter_s: 23.26536512374878\n",
      "  time_total_s: 3415.6171033382416\n",
      "  timestamp: 1553969181\n",
      "  timesteps_since_restore: 1430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1430000\n",
      "  training_iteration: 143\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3415 s, 143 iter, 1430000 ts, 787 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-06-45\n",
      "  done: false\n",
      "  episode_len_mean: 167.13\n",
      "  episode_reward_max: 1094.824244649424\n",
      "  episode_reward_mean: 837.4268154464326\n",
      "  episode_reward_min: -93.9371629908343\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8210\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.056\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.530484403770686e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0879688262939453\n",
      "      kl: 0.08178965002298355\n",
      "      policy_loss: 0.02348501607775688\n",
      "      total_loss: 1638.857177734375\n",
      "      vf_explained_var: 0.9076991677284241\n",
      "      vf_loss: 1638.8336181640625\n",
      "    sample_time_ms: 19787.391\n",
      "    update_time_ms: 4.964\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 418.7134077232164\n",
      "  time_since_restore: 3439.950254678726\n",
      "  time_this_iter_s: 24.33315134048462\n",
      "  time_total_s: 3439.950254678726\n",
      "  timestamp: 1553969205\n",
      "  timesteps_since_restore: 1440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 144\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3439 s, 144 iter, 1440000 ts, 837 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-07-10\n",
      "  done: false\n",
      "  episode_len_mean: 164.45\n",
      "  episode_reward_max: 1094.824244649424\n",
      "  episode_reward_mean: 788.1437993974209\n",
      "  episode_reward_min: -93.08849275930085\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 8273\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.933\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 1450000\n",
      "    num_steps_trained: 1450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.295726605656029e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2578314542770386\n",
      "      kl: 32.32261657714844\n",
      "      policy_loss: 0.10651286691427231\n",
      "      total_loss: 2013.3265380859375\n",
      "      vf_explained_var: 0.8822659254074097\n",
      "      vf_loss: 2013.219970703125\n",
      "    sample_time_ms: 19804.558\n",
      "    update_time_ms: 4.936\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 394.07189969871047\n",
      "  time_since_restore: 3464.2352406978607\n",
      "  time_this_iter_s: 24.28498601913452\n",
      "  time_total_s: 3464.2352406978607\n",
      "  timestamp: 1553969230\n",
      "  timesteps_since_restore: 1450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1450000\n",
      "  training_iteration: 145\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3464 s, 145 iter, 1450000 ts, 788 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-07-33\n",
      "  done: false\n",
      "  episode_len_mean: 172.49\n",
      "  episode_reward_max: 1090.2403120387016\n",
      "  episode_reward_mean: 806.4051012788652\n",
      "  episode_reward_min: -110.95991148885484\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 8329\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.543\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 1460000\n",
      "    num_steps_trained: 1460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2443589214594653e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4267526865005493\n",
      "      kl: 0.05341274291276932\n",
      "      policy_loss: 0.015807073563337326\n",
      "      total_loss: 1809.1221923828125\n",
      "      vf_explained_var: 0.8974918723106384\n",
      "      vf_loss: 1809.1063232421875\n",
      "    sample_time_ms: 19693.0\n",
      "    update_time_ms: 5.033\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 403.2025506394326\n",
      "  time_since_restore: 3487.315056324005\n",
      "  time_this_iter_s: 23.07981562614441\n",
      "  time_total_s: 3487.315056324005\n",
      "  timestamp: 1553969253\n",
      "  timesteps_since_restore: 1460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1460000\n",
      "  training_iteration: 146\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3487 s, 146 iter, 1460000 ts, 806 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-07-56\n",
      "  done: false\n",
      "  episode_len_mean: 170.69\n",
      "  episode_reward_max: 1090.2403120387016\n",
      "  episode_reward_mean: 840.3774628308506\n",
      "  episode_reward_min: -110.95991148885484\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8389\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.65\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8665390066896492e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1242313385009766\n",
      "      kl: 0.17785346508026123\n",
      "      policy_loss: 0.023768149316310883\n",
      "      total_loss: 1484.332763671875\n",
      "      vf_explained_var: 0.9182007908821106\n",
      "      vf_loss: 1484.308837890625\n",
      "    sample_time_ms: 19652.862\n",
      "    update_time_ms: 5.282\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 420.1887314154253\n",
      "  time_since_restore: 3510.7267212867737\n",
      "  time_this_iter_s: 23.411664962768555\n",
      "  time_total_s: 3510.7267212867737\n",
      "  timestamp: 1553969276\n",
      "  timesteps_since_restore: 1470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 147\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3510 s, 147 iter, 1470000 ts, 840 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-08-20\n",
      "  done: false\n",
      "  episode_len_mean: 167.26\n",
      "  episode_reward_max: 1114.80994036736\n",
      "  episode_reward_mean: 842.2852966831754\n",
      "  episode_reward_min: -70.3438928611944\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 8448\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.515\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 1480000\n",
      "    num_steps_trained: 1480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7998076079782663e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2887359857559204\n",
      "      kl: 0.09089445322751999\n",
      "      policy_loss: 0.026521116495132446\n",
      "      total_loss: 1644.5963134765625\n",
      "      vf_explained_var: 0.8895306587219238\n",
      "      vf_loss: 1644.5699462890625\n",
      "    sample_time_ms: 19700.214\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 421.1426483415878\n",
      "  time_since_restore: 3534.5192687511444\n",
      "  time_this_iter_s: 23.792547464370728\n",
      "  time_total_s: 3534.5192687511444\n",
      "  timestamp: 1553969300\n",
      "  timesteps_since_restore: 1480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1480000\n",
      "  training_iteration: 148\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3534 s, 148 iter, 1480000 ts, 842 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-08-43\n",
      "  done: false\n",
      "  episode_len_mean: 163.51\n",
      "  episode_reward_max: 1125.129929135148\n",
      "  episode_reward_mean: 779.6792734929493\n",
      "  episode_reward_min: -90.47573217402764\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 8510\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.701\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 1490000\n",
      "    num_steps_trained: 1490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.199711967078912e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.15851628780365\n",
      "      kl: 0.06804696470499039\n",
      "      policy_loss: 0.019047586247324944\n",
      "      total_loss: 1951.4122314453125\n",
      "      vf_explained_var: 0.8804675340652466\n",
      "      vf_loss: 1951.3931884765625\n",
      "    sample_time_ms: 19674.978\n",
      "    update_time_ms: 5.315\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 389.8396367464746\n",
      "  time_since_restore: 3557.636326789856\n",
      "  time_this_iter_s: 23.117058038711548\n",
      "  time_total_s: 3557.636326789856\n",
      "  timestamp: 1553969323\n",
      "  timesteps_since_restore: 1490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1490000\n",
      "  training_iteration: 149\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3557 s, 149 iter, 1490000 ts, 780 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-09-07\n",
      "  done: false\n",
      "  episode_len_mean: 162.8\n",
      "  episode_reward_max: 1104.0098510044552\n",
      "  episode_reward_mean: 809.6802452623244\n",
      "  episode_reward_min: -90.47573217402764\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 8571\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.347\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.29956919961927e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0921008586883545\n",
      "      kl: 0.08917335420846939\n",
      "      policy_loss: 0.02456122450530529\n",
      "      total_loss: 1713.521240234375\n",
      "      vf_explained_var: 0.9044482707977295\n",
      "      vf_loss: 1713.49658203125\n",
      "    sample_time_ms: 19676.298\n",
      "    update_time_ms: 5.243\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 404.8401226311622\n",
      "  time_since_restore: 3581.1712307929993\n",
      "  time_this_iter_s: 23.53490400314331\n",
      "  time_total_s: 3581.1712307929993\n",
      "  timestamp: 1553969347\n",
      "  timesteps_since_restore: 1500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 150\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3581 s, 150 iter, 1500000 ts, 810 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-09-31\n",
      "  done: false\n",
      "  episode_len_mean: 157.5\n",
      "  episode_reward_max: 1158.8851023853226\n",
      "  episode_reward_mean: 777.3808880671486\n",
      "  episode_reward_min: -78.61075652496258\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 8636\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.551\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 1510000\n",
      "    num_steps_trained: 1510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.449352411650125e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0800857543945312\n",
      "      kl: 0.5182511806488037\n",
      "      policy_loss: 0.05108334496617317\n",
      "      total_loss: 2500.721435546875\n",
      "      vf_explained_var: 0.8555253148078918\n",
      "      vf_loss: 2500.670166015625\n",
      "    sample_time_ms: 19721.883\n",
      "    update_time_ms: 5.36\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 388.6904440335743\n",
      "  time_since_restore: 3605.1635177135468\n",
      "  time_this_iter_s: 23.992286920547485\n",
      "  time_total_s: 3605.1635177135468\n",
      "  timestamp: 1553969371\n",
      "  timesteps_since_restore: 1510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1510000\n",
      "  training_iteration: 151\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3605 s, 151 iter, 1510000 ts, 777 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-09-53\n",
      "  done: false\n",
      "  episode_len_mean: 160.18\n",
      "  episode_reward_max: 1078.7452819982313\n",
      "  episode_reward_mean: 743.9897375619469\n",
      "  episode_reward_min: -78.61075652496258\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 8697\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.359\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 1520000\n",
      "    num_steps_trained: 1520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4174029727698212e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5245188474655151\n",
      "      kl: 0.2645411789417267\n",
      "      policy_loss: 0.01760527305305004\n",
      "      total_loss: 1756.6771240234375\n",
      "      vf_explained_var: 0.8940791487693787\n",
      "      vf_loss: 1756.659423828125\n",
      "    sample_time_ms: 19597.118\n",
      "    update_time_ms: 5.307\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 371.9948687809733\n",
      "  time_since_restore: 3627.572126865387\n",
      "  time_this_iter_s: 22.40860915184021\n",
      "  time_total_s: 3627.572126865387\n",
      "  timestamp: 1553969393\n",
      "  timesteps_since_restore: 1520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1520000\n",
      "  training_iteration: 152\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3627 s, 152 iter, 1520000 ts, 744 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-10-17\n",
      "  done: false\n",
      "  episode_len_mean: 170.79\n",
      "  episode_reward_max: 1101.5877702583848\n",
      "  episode_reward_mean: 859.4610905566938\n",
      "  episode_reward_min: -72.51883926448305\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8757\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.26\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1261037375097658e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1663182973861694\n",
      "      kl: 62.089805603027344\n",
      "      policy_loss: 0.134064719080925\n",
      "      total_loss: 1428.1478271484375\n",
      "      vf_explained_var: 0.9209408164024353\n",
      "      vf_loss: 1428.013671875\n",
      "    sample_time_ms: 19640.119\n",
      "    update_time_ms: 5.322\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 429.730545278347\n",
      "  time_since_restore: 3651.1958017349243\n",
      "  time_this_iter_s: 23.623674869537354\n",
      "  time_total_s: 3651.1958017349243\n",
      "  timestamp: 1553969417\n",
      "  timesteps_since_restore: 1530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 153\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3651 s, 153 iter, 1530000 ts, 859 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-10-41\n",
      "  done: false\n",
      "  episode_len_mean: 170.96\n",
      "  episode_reward_max: 1126.8046751171964\n",
      "  episode_reward_mean: 845.4009460921184\n",
      "  episode_reward_min: -72.51883926448305\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 8814\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.709\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 1540000\n",
      "    num_steps_trained: 1540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.1891556062646487e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4069567918777466\n",
      "      kl: 0.0382692888379097\n",
      "      policy_loss: 0.012568345293402672\n",
      "      total_loss: 1556.0584716796875\n",
      "      vf_explained_var: 0.9081858396530151\n",
      "      vf_loss: 1556.0460205078125\n",
      "    sample_time_ms: 19543.612\n",
      "    update_time_ms: 5.432\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 422.7004730460591\n",
      "  time_since_restore: 3674.709001302719\n",
      "  time_this_iter_s: 23.5131995677948\n",
      "  time_total_s: 3674.709001302719\n",
      "  timestamp: 1553969441\n",
      "  timesteps_since_restore: 1540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1540000\n",
      "  training_iteration: 154\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3674 s, 154 iter, 1540000 ts, 845 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-11-05\n",
      "  done: false\n",
      "  episode_len_mean: 161.76\n",
      "  episode_reward_max: 1126.8046751171964\n",
      "  episode_reward_mean: 815.9129515443185\n",
      "  episode_reward_min: -71.46990450800848\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 8878\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.565\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 1550000\n",
      "    num_steps_trained: 1550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.1891556062646487e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0710433721542358\n",
      "      kl: 0.034816380590200424\n",
      "      policy_loss: 0.01123580988496542\n",
      "      total_loss: 1623.8065185546875\n",
      "      vf_explained_var: 0.9136673212051392\n",
      "      vf_loss: 1623.79541015625\n",
      "    sample_time_ms: 19565.073\n",
      "    update_time_ms: 5.46\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 407.95647577215925\n",
      "  time_since_restore: 3699.038556575775\n",
      "  time_this_iter_s: 24.32955527305603\n",
      "  time_total_s: 3699.038556575775\n",
      "  timestamp: 1553969465\n",
      "  timesteps_since_restore: 1550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1550000\n",
      "  training_iteration: 155\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3699 s, 155 iter, 1550000 ts, 816 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-11-28\n",
      "  done: false\n",
      "  episode_len_mean: 160.53\n",
      "  episode_reward_max: 1101.856394346265\n",
      "  episode_reward_mean: 835.8467189055913\n",
      "  episode_reward_min: -63.75336495798257\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 8939\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.274\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.1891556062646487e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1738239526748657\n",
      "      kl: 0.06901784241199493\n",
      "      policy_loss: 0.01708357408642769\n",
      "      total_loss: 1598.5130615234375\n",
      "      vf_explained_var: 0.9133768081665039\n",
      "      vf_loss: 1598.495849609375\n",
      "    sample_time_ms: 19595.982\n",
      "    update_time_ms: 5.514\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 417.9233594527956\n",
      "  time_since_restore: 3722.4150397777557\n",
      "  time_this_iter_s: 23.37648320198059\n",
      "  time_total_s: 3722.4150397777557\n",
      "  timestamp: 1553969488\n",
      "  timesteps_since_restore: 1560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 156\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3722 s, 156 iter, 1560000 ts, 836 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-11-52\n",
      "  done: false\n",
      "  episode_len_mean: 154.67\n",
      "  episode_reward_max: 1081.9251211530714\n",
      "  episode_reward_mean: 749.1868037765879\n",
      "  episode_reward_min: -79.48654847003145\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 9005\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.156\n",
      "    load_time_ms: 1.67\n",
      "    num_steps_sampled: 1570000\n",
      "    num_steps_trained: 1570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.7837347416646026e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.105515480041504\n",
      "      kl: 0.14731574058532715\n",
      "      policy_loss: 0.01792738027870655\n",
      "      total_loss: 2082.136962890625\n",
      "      vf_explained_var: 0.8882175087928772\n",
      "      vf_loss: 2082.119384765625\n",
      "    sample_time_ms: 19637.982\n",
      "    update_time_ms: 5.4\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 374.593401888294\n",
      "  time_since_restore: 3746.1948153972626\n",
      "  time_this_iter_s: 23.779775619506836\n",
      "  time_total_s: 3746.1948153972626\n",
      "  timestamp: 1553969512\n",
      "  timesteps_since_restore: 1570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1570000\n",
      "  training_iteration: 157\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3746 s, 157 iter, 1570000 ts, 749 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-12-16\n",
      "  done: false\n",
      "  episode_len_mean: 160.02\n",
      "  episode_reward_max: 1097.5382418243269\n",
      "  episode_reward_mean: 757.4150036356715\n",
      "  episode_reward_min: -79.48654847003145\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 9064\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.625\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 1580000\n",
      "    num_steps_trained: 1580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.175601890452299e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.361997127532959\n",
      "      kl: 0.32657355070114136\n",
      "      policy_loss: 0.012935765087604523\n",
      "      total_loss: 1278.5093994140625\n",
      "      vf_explained_var: 0.9312176704406738\n",
      "      vf_loss: 1278.49658203125\n",
      "    sample_time_ms: 19585.821\n",
      "    update_time_ms: 5.395\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 378.70750181783575\n",
      "  time_since_restore: 3769.4702174663544\n",
      "  time_this_iter_s: 23.275402069091797\n",
      "  time_total_s: 3769.4702174663544\n",
      "  timestamp: 1553969536\n",
      "  timesteps_since_restore: 1580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1580000\n",
      "  training_iteration: 158\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3769 s, 158 iter, 1580000 ts, 757 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-12-39\n",
      "  done: false\n",
      "  episode_len_mean: 163.22\n",
      "  episode_reward_max: 1126.087518818706\n",
      "  episode_reward_mean: 818.897509206416\n",
      "  episode_reward_min: -86.0008155990774\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 9127\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.603\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0763401725455424e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0816709995269775\n",
      "      kl: 0.5509903430938721\n",
      "      policy_loss: 0.022966763004660606\n",
      "      total_loss: 2255.51513671875\n",
      "      vf_explained_var: 0.8676813840866089\n",
      "      vf_loss: 2255.4921875\n",
      "    sample_time_ms: 19588.992\n",
      "    update_time_ms: 5.507\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 409.448754603208\n",
      "  time_since_restore: 3792.870069026947\n",
      "  time_this_iter_s: 23.39985156059265\n",
      "  time_total_s: 3792.870069026947\n",
      "  timestamp: 1553969559\n",
      "  timesteps_since_restore: 1590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 159\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3792 s, 159 iter, 1590000 ts, 819 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-13-03\n",
      "  done: false\n",
      "  episode_len_mean: 165.65\n",
      "  episode_reward_max: 1126.087518818706\n",
      "  episode_reward_mean: 827.6998933941583\n",
      "  episode_reward_min: -86.0008155990774\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 9185\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.643\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 1600000\n",
      "    num_steps_trained: 1600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6145104808629185e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3350632190704346\n",
      "      kl: 0.061680927872657776\n",
      "      policy_loss: 0.019464850425720215\n",
      "      total_loss: 1639.866943359375\n",
      "      vf_explained_var: 0.9119861125946045\n",
      "      vf_loss: 1639.847412109375\n",
      "    sample_time_ms: 19613.076\n",
      "    update_time_ms: 5.53\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 413.84994669707913\n",
      "  time_since_restore: 3816.6069915294647\n",
      "  time_this_iter_s: 23.7369225025177\n",
      "  time_total_s: 3816.6069915294647\n",
      "  timestamp: 1553969583\n",
      "  timesteps_since_restore: 1600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1600000\n",
      "  training_iteration: 160\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3816 s, 160 iter, 1600000 ts, 828 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-13-27\n",
      "  done: false\n",
      "  episode_len_mean: 170.46\n",
      "  episode_reward_max: 1118.4839198601844\n",
      "  episode_reward_mean: 834.027903331139\n",
      "  episode_reward_min: -72.26109550679183\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 9246\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.732\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 1610000\n",
      "    num_steps_trained: 1610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.42176536602301e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2556700706481934\n",
      "      kl: 0.044710226356983185\n",
      "      policy_loss: 0.014652972109615803\n",
      "      total_loss: 1239.2188720703125\n",
      "      vf_explained_var: 0.9339370727539062\n",
      "      vf_loss: 1239.2042236328125\n",
      "    sample_time_ms: 19586.133\n",
      "    update_time_ms: 5.567\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 417.0139516655695\n",
      "  time_since_restore: 3840.330514192581\n",
      "  time_this_iter_s: 23.723522663116455\n",
      "  time_total_s: 3840.330514192581\n",
      "  timestamp: 1553969607\n",
      "  timesteps_since_restore: 1610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1610000\n",
      "  training_iteration: 161\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3840 s, 161 iter, 1610000 ts, 834 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-13-50\n",
      "  done: false\n",
      "  episode_len_mean: 162.59\n",
      "  episode_reward_max: 1102.048033752592\n",
      "  episode_reward_mean: 816.8984027835563\n",
      "  episode_reward_min: -72.26109550679183\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 9308\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.369\n",
      "    load_time_ms: 1.685\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.632648315488041e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2282058000564575\n",
      "      kl: 1.8947405815124512\n",
      "      policy_loss: 0.028897074982523918\n",
      "      total_loss: 1919.063720703125\n",
      "      vf_explained_var: 0.8840134739875793\n",
      "      vf_loss: 1919.034912109375\n",
      "    sample_time_ms: 19692.583\n",
      "    update_time_ms: 5.855\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 408.4492013917783\n",
      "  time_since_restore: 3863.7936174869537\n",
      "  time_this_iter_s: 23.46310329437256\n",
      "  time_total_s: 3863.7936174869537\n",
      "  timestamp: 1553969630\n",
      "  timesteps_since_restore: 1620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 162\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3863 s, 162 iter, 1620000 ts, 817 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-14-14\n",
      "  done: false\n",
      "  episode_len_mean: 167.64\n",
      "  episode_reward_max: 1149.657355595428\n",
      "  episode_reward_mean: 863.7647673748271\n",
      "  episode_reward_min: -26.932892414835294\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9368\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.813\n",
      "    load_time_ms: 1.667\n",
      "    num_steps_sampled: 1630000\n",
      "    num_steps_trained: 1630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.448972828503429e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3080276250839233\n",
      "      kl: 0.04128484055399895\n",
      "      policy_loss: 0.010102811269462109\n",
      "      total_loss: 1222.2161865234375\n",
      "      vf_explained_var: 0.9366531372070312\n",
      "      vf_loss: 1222.2061767578125\n",
      "    sample_time_ms: 19711.458\n",
      "    update_time_ms: 5.968\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 431.88238368741366\n",
      "  time_since_restore: 3887.6017990112305\n",
      "  time_this_iter_s: 23.808181524276733\n",
      "  time_total_s: 3887.6017990112305\n",
      "  timestamp: 1553969654\n",
      "  timesteps_since_restore: 1630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1630000\n",
      "  training_iteration: 163\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3887 s, 163 iter, 1630000 ts, 864 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-14-38\n",
      "  done: false\n",
      "  episode_len_mean: 170.37\n",
      "  episode_reward_max: 1102.6533306392926\n",
      "  episode_reward_mean: 882.7503118511845\n",
      "  episode_reward_min: -36.997730284640795\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 9425\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.645\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 1640000\n",
      "    num_steps_trained: 1640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.173458354576724e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3767203092575073\n",
      "      kl: 0.039410945028066635\n",
      "      policy_loss: 0.011076954193413258\n",
      "      total_loss: 1182.1015625\n",
      "      vf_explained_var: 0.9367619156837463\n",
      "      vf_loss: 1182.0904541015625\n",
      "    sample_time_ms: 19750.636\n",
      "    update_time_ms: 5.755\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 441.37515592559214\n",
      "  time_since_restore: 3911.6229887008667\n",
      "  time_this_iter_s: 24.02118968963623\n",
      "  time_total_s: 3911.6229887008667\n",
      "  timestamp: 1553969678\n",
      "  timesteps_since_restore: 1640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1640000\n",
      "  training_iteration: 164\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3911 s, 164 iter, 1640000 ts, 883 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-15-01\n",
      "  done: false\n",
      "  episode_len_mean: 163.85\n",
      "  episode_reward_max: 1086.0345865134168\n",
      "  episode_reward_mean: 840.2775202587571\n",
      "  episode_reward_min: -84.50009653786442\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 9488\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.963\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.173458354576724e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1854239702224731\n",
      "      kl: 60.29533386230469\n",
      "      policy_loss: 0.09990409761667252\n",
      "      total_loss: 1906.474609375\n",
      "      vf_explained_var: 0.8939045667648315\n",
      "      vf_loss: 1906.3746337890625\n",
      "    sample_time_ms: 19645.436\n",
      "    update_time_ms: 6.317\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 420.13876012937857\n",
      "  time_since_restore: 3934.8595309257507\n",
      "  time_this_iter_s: 23.236542224884033\n",
      "  time_total_s: 3934.8595309257507\n",
      "  timestamp: 1553969701\n",
      "  timesteps_since_restore: 1650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 165\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3934 s, 165 iter, 1650000 ts, 840 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-15-25\n",
      "  done: false\n",
      "  episode_len_mean: 163.45\n",
      "  episode_reward_max: 1175.8011865211556\n",
      "  episode_reward_mean: 878.5639872003252\n",
      "  episode_reward_min: -84.50009653786442\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 9547\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.481\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 1660000\n",
      "    num_steps_trained: 1660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2260187531865085e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.151755690574646\n",
      "      kl: 0.016008248552680016\n",
      "      policy_loss: 0.0036219388712197542\n",
      "      total_loss: 977.3670043945312\n",
      "      vf_explained_var: 0.950814962387085\n",
      "      vf_loss: 977.3634033203125\n",
      "    sample_time_ms: 19664.064\n",
      "    update_time_ms: 6.408\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 439.28199360016254\n",
      "  time_since_restore: 3958.4171500205994\n",
      "  time_this_iter_s: 23.557619094848633\n",
      "  time_total_s: 3958.4171500205994\n",
      "  timestamp: 1553969725\n",
      "  timesteps_since_restore: 1660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1660000\n",
      "  training_iteration: 166\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3958 s, 166 iter, 1660000 ts, 879 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-15-49\n",
      "  done: false\n",
      "  episode_len_mean: 166.74\n",
      "  episode_reward_max: 1119.4485320431063\n",
      "  episode_reward_mean: 837.0548325515905\n",
      "  episode_reward_min: -72.95318802542167\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 9608\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.92\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 1670000\n",
      "    num_steps_trained: 1670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2260187531865085e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2950210571289062\n",
      "      kl: 0.023188361898064613\n",
      "      policy_loss: 0.004196472465991974\n",
      "      total_loss: 1523.709228515625\n",
      "      vf_explained_var: 0.9172633290290833\n",
      "      vf_loss: 1523.7049560546875\n",
      "    sample_time_ms: 19655.686\n",
      "    update_time_ms: 6.19\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 418.5274162757952\n",
      "  time_since_restore: 3982.1943044662476\n",
      "  time_this_iter_s: 23.777154445648193\n",
      "  time_total_s: 3982.1943044662476\n",
      "  timestamp: 1553969749\n",
      "  timesteps_since_restore: 1670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1670000\n",
      "  training_iteration: 167\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 3982 s, 167 iter, 1670000 ts, 837 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-16-12\n",
      "  done: false\n",
      "  episode_len_mean: 166.61\n",
      "  episode_reward_max: 1163.556213513319\n",
      "  episode_reward_mean: 796.9926554995347\n",
      "  episode_reward_min: -72.95318802542167\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 9667\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.196\n",
      "    load_time_ms: 1.69\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2260187531865085e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5393543243408203\n",
      "      kl: 0.1320563554763794\n",
      "      policy_loss: 0.02008713036775589\n",
      "      total_loss: 1628.80908203125\n",
      "      vf_explained_var: 0.9120411276817322\n",
      "      vf_loss: 1628.7889404296875\n",
      "    sample_time_ms: 19664.742\n",
      "    update_time_ms: 6.314\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 398.4963277497674\n",
      "  time_since_restore: 4005.5436794757843\n",
      "  time_this_iter_s: 23.349375009536743\n",
      "  time_total_s: 4005.5436794757843\n",
      "  timestamp: 1553969772\n",
      "  timesteps_since_restore: 1680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 168\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4005 s, 168 iter, 1680000 ts, 797 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 163.83\n",
      "  episode_reward_max: 1076.880559424705\n",
      "  episode_reward_mean: 746.1633355663753\n",
      "  episode_reward_min: -67.26850507259141\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 9729\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.805\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 1690000\n",
      "    num_steps_trained: 1690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8390281297797628e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.32901132106781\n",
      "      kl: 0.8356814384460449\n",
      "      policy_loss: 0.03227188065648079\n",
      "      total_loss: 1613.03369140625\n",
      "      vf_explained_var: 0.9127143621444702\n",
      "      vf_loss: 1613.0013427734375\n",
      "    sample_time_ms: 19768.563\n",
      "    update_time_ms: 6.191\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 373.08166778318764\n",
      "  time_since_restore: 4029.8053317070007\n",
      "  time_this_iter_s: 24.26165223121643\n",
      "  time_total_s: 4029.8053317070007\n",
      "  timestamp: 1553969796\n",
      "  timesteps_since_restore: 1690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1690000\n",
      "  training_iteration: 169\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4029 s, 169 iter, 1690000 ts, 746 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-17-00\n",
      "  done: false\n",
      "  episode_len_mean: 162.65\n",
      "  episode_reward_max: 1086.9380251053597\n",
      "  episode_reward_mean: 779.443821296322\n",
      "  episode_reward_min: -65.90100287786015\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 9790\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.792\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 1700000\n",
      "    num_steps_trained: 1700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7585423367781914e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2846262454986572\n",
      "      kl: 0.04098884388804436\n",
      "      policy_loss: 0.012935626320540905\n",
      "      total_loss: 1530.6925048828125\n",
      "      vf_explained_var: 0.918121337890625\n",
      "      vf_loss: 1530.679443359375\n",
      "    sample_time_ms: 19734.039\n",
      "    update_time_ms: 6.789\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 389.721910648161\n",
      "  time_since_restore: 4053.150631427765\n",
      "  time_this_iter_s: 23.34529972076416\n",
      "  time_total_s: 4053.150631427765\n",
      "  timestamp: 1553969820\n",
      "  timesteps_since_restore: 1700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1700000\n",
      "  training_iteration: 170\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4053 s, 170 iter, 1700000 ts, 779 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-17-24\n",
      "  done: false\n",
      "  episode_len_mean: 159.2\n",
      "  episode_reward_max: 1146.58581027196\n",
      "  episode_reward_mean: 801.0023549815836\n",
      "  episode_reward_min: -65.90100287786015\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 9855\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.11\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.1378137893843814e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1518112421035767\n",
      "      kl: 0.05289381742477417\n",
      "      policy_loss: 0.009400761686265469\n",
      "      total_loss: 1791.872802734375\n",
      "      vf_explained_var: 0.910453200340271\n",
      "      vf_loss: 1791.8634033203125\n",
      "    sample_time_ms: 19743.86\n",
      "    update_time_ms: 6.732\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.50117749079175\n",
      "  time_since_restore: 4076.936865091324\n",
      "  time_this_iter_s: 23.78623366355896\n",
      "  time_total_s: 4076.936865091324\n",
      "  timestamp: 1553969844\n",
      "  timesteps_since_restore: 1710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 171\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4076 s, 171 iter, 1710000 ts, 801 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-17-48\n",
      "  done: false\n",
      "  episode_len_mean: 154.28\n",
      "  episode_reward_max: 1105.1470117594745\n",
      "  episode_reward_mean: 762.8175704240546\n",
      "  episode_reward_min: -71.80144647181814\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 9919\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.035\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 1720000\n",
      "    num_steps_trained: 1720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.206719831425289e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1802268028259277\n",
      "      kl: 25.596426010131836\n",
      "      policy_loss: 0.10403848439455032\n",
      "      total_loss: 2085.259521484375\n",
      "      vf_explained_var: 0.8857728838920593\n",
      "      vf_loss: 2085.155517578125\n",
      "    sample_time_ms: 19785.217\n",
      "    update_time_ms: 6.593\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 381.4087852120273\n",
      "  time_since_restore: 4100.832351207733\n",
      "  time_this_iter_s: 23.8954861164093\n",
      "  time_total_s: 4100.832351207733\n",
      "  timestamp: 1553969868\n",
      "  timesteps_since_restore: 1720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1720000\n",
      "  training_iteration: 172\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4100 s, 172 iter, 1720000 ts, 763 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-18-10\n",
      "  done: false\n",
      "  episode_len_mean: 164.69\n",
      "  episode_reward_max: 1105.1470117594745\n",
      "  episode_reward_mean: 803.372885793829\n",
      "  episode_reward_min: -71.80144647181814\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 9977\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.848\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 1730000\n",
      "    num_steps_trained: 1730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.310080031355028e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4268850088119507\n",
      "      kl: 0.04562436789274216\n",
      "      policy_loss: 0.012849769555032253\n",
      "      total_loss: 1767.7313232421875\n",
      "      vf_explained_var: 0.9022674560546875\n",
      "      vf_loss: 1767.71875\n",
      "    sample_time_ms: 19639.373\n",
      "    update_time_ms: 6.458\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 401.6864428969145\n",
      "  time_since_restore: 4123.3377141952515\n",
      "  time_this_iter_s: 22.50536298751831\n",
      "  time_total_s: 4123.3377141952515\n",
      "  timestamp: 1553969890\n",
      "  timesteps_since_restore: 1730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1730000\n",
      "  training_iteration: 173\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4123 s, 173 iter, 1730000 ts, 803 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-18-33\n",
      "  done: false\n",
      "  episode_len_mean: 169.84\n",
      "  episode_reward_max: 1094.3795787807574\n",
      "  episode_reward_mean: 832.0443454040543\n",
      "  episode_reward_min: -6.132943854697629\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 10036\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.336\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3965118341729976e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3631632328033447\n",
      "      kl: 0.1650644987821579\n",
      "      policy_loss: 0.017694225534796715\n",
      "      total_loss: 1270.2171630859375\n",
      "      vf_explained_var: 0.9328294396400452\n",
      "      vf_loss: 1270.199462890625\n",
      "    sample_time_ms: 19515.854\n",
      "    update_time_ms: 6.463\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 416.0221727020271\n",
      "  time_since_restore: 4145.867079734802\n",
      "  time_this_iter_s: 22.52936553955078\n",
      "  time_total_s: 4145.867079734802\n",
      "  timestamp: 1553969913\n",
      "  timesteps_since_restore: 1740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 174\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4145 s, 174 iter, 1740000 ts, 832 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-18-56\n",
      "  done: false\n",
      "  episode_len_mean: 162.18\n",
      "  episode_reward_max: 1108.8133970721062\n",
      "  episode_reward_mean: 790.7944789751907\n",
      "  episode_reward_min: -89.85517079069274\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 10100\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.401\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 1750000\n",
      "    num_steps_trained: 1750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.094767978633172e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.300175428390503\n",
      "      kl: 0.038553476333618164\n",
      "      policy_loss: 0.006306113675236702\n",
      "      total_loss: 1458.5003662109375\n",
      "      vf_explained_var: 0.9270948767662048\n",
      "      vf_loss: 1458.494140625\n",
      "    sample_time_ms: 19541.644\n",
      "    update_time_ms: 6.824\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 395.39723948759536\n",
      "  time_since_restore: 4169.403486728668\n",
      "  time_this_iter_s: 23.536406993865967\n",
      "  time_total_s: 4169.403486728668\n",
      "  timestamp: 1553969936\n",
      "  timesteps_since_restore: 1750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1750000\n",
      "  training_iteration: 175\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4169 s, 175 iter, 1750000 ts, 791 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 164.96\n",
      "  episode_reward_max: 1117.8375200951662\n",
      "  episode_reward_mean: 797.7028961630855\n",
      "  episode_reward_min: -89.85517079069274\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 10158\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.16\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 1760000\n",
      "    num_steps_trained: 1760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.094767978633172e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.318601369857788\n",
      "      kl: 0.0931718498468399\n",
      "      policy_loss: 0.013629581779241562\n",
      "      total_loss: 1637.8411865234375\n",
      "      vf_explained_var: 0.913762629032135\n",
      "      vf_loss: 1637.827392578125\n",
      "    sample_time_ms: 19504.758\n",
      "    update_time_ms: 6.587\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 398.8514480815426\n",
      "  time_since_restore: 4192.5690932273865\n",
      "  time_this_iter_s: 23.16560649871826\n",
      "  time_total_s: 4192.5690932273865\n",
      "  timestamp: 1553969959\n",
      "  timesteps_since_restore: 1760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1760000\n",
      "  training_iteration: 176\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4192 s, 176 iter, 1760000 ts, 798 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-19-43\n",
      "  done: false\n",
      "  episode_len_mean: 170.94\n",
      "  episode_reward_max: 1118.006649349296\n",
      "  episode_reward_mean: 900.7290865757294\n",
      "  episode_reward_min: 7.28092420312305\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 10216\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.966\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.1421520816365955e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1838414669036865\n",
      "      kl: 0.4243897795677185\n",
      "      policy_loss: 0.008134953677654266\n",
      "      total_loss: 1063.1651611328125\n",
      "      vf_explained_var: 0.9491499066352844\n",
      "      vf_loss: 1063.1571044921875\n",
      "    sample_time_ms: 19453.974\n",
      "    update_time_ms: 6.558\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 450.36454328786465\n",
      "  time_since_restore: 4215.7838933467865\n",
      "  time_this_iter_s: 23.214800119400024\n",
      "  time_total_s: 4215.7838933467865\n",
      "  timestamp: 1553969983\n",
      "  timesteps_since_restore: 1770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 177\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4215 s, 177 iter, 1770000 ts, 901 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-20-06\n",
      "  done: false\n",
      "  episode_len_mean: 172.95\n",
      "  episode_reward_max: 1118.006649349296\n",
      "  episode_reward_mean: 899.0360841514718\n",
      "  episode_reward_min: -70.32097825050047\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 10274\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.454\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 1780000\n",
      "    num_steps_trained: 1780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.713227099273354e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.428344488143921\n",
      "      kl: 0.07000544667243958\n",
      "      policy_loss: 0.004582380410283804\n",
      "      total_loss: 1060.2003173828125\n",
      "      vf_explained_var: 0.9433720707893372\n",
      "      vf_loss: 1060.1956787109375\n",
      "    sample_time_ms: 19451.474\n",
      "    update_time_ms: 6.676\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 449.5180420757359\n",
      "  time_since_restore: 4239.151901006699\n",
      "  time_this_iter_s: 23.36800765991211\n",
      "  time_total_s: 4239.151901006699\n",
      "  timestamp: 1553970006\n",
      "  timesteps_since_restore: 1780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1780000\n",
      "  training_iteration: 178\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4239 s, 178 iter, 1780000 ts, 899 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-20-29\n",
      "  done: false\n",
      "  episode_len_mean: 168.41\n",
      "  episode_reward_max: 1107.304000531788\n",
      "  episode_reward_mean: 836.5155710238176\n",
      "  episode_reward_min: -62.45398236153932\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 10335\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.147\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 1790000\n",
      "    num_steps_trained: 1790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.069843377394136e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3490604162216187\n",
      "      kl: 0.0611882321536541\n",
      "      policy_loss: 0.0107654370367527\n",
      "      total_loss: 1232.516845703125\n",
      "      vf_explained_var: 0.9393713474273682\n",
      "      vf_loss: 1232.506103515625\n",
      "    sample_time_ms: 19333.407\n",
      "    update_time_ms: 6.769\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 418.2577855119088\n",
      "  time_since_restore: 4262.168729543686\n",
      "  time_this_iter_s: 23.016828536987305\n",
      "  time_total_s: 4262.168729543686\n",
      "  timestamp: 1553970029\n",
      "  timesteps_since_restore: 1790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1790000\n",
      "  training_iteration: 179\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4262 s, 179 iter, 1790000 ts, 837 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-20-53\n",
      "  done: false\n",
      "  episode_len_mean: 171.43\n",
      "  episode_reward_max: 1099.9005393176703\n",
      "  episode_reward_mean: 843.058933177904\n",
      "  episode_reward_min: -66.83485944398953\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 10393\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.266\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0604764611343853e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3141069412231445\n",
      "      kl: 0.263039231300354\n",
      "      policy_loss: 0.009191672317683697\n",
      "      total_loss: 681.010986328125\n",
      "      vf_explained_var: 0.9632577896118164\n",
      "      vf_loss: 681.0017700195312\n",
      "    sample_time_ms: 19402.505\n",
      "    update_time_ms: 6.175\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 421.5294665889519\n",
      "  time_since_restore: 4286.247503757477\n",
      "  time_this_iter_s: 24.078774213790894\n",
      "  time_total_s: 4286.247503757477\n",
      "  timestamp: 1553970053\n",
      "  timesteps_since_restore: 1800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 180\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4286 s, 180 iter, 1800000 ts, 843 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-21-16\n",
      "  done: false\n",
      "  episode_len_mean: 164.43\n",
      "  episode_reward_max: 1078.960359398819\n",
      "  episode_reward_mean: 812.2113061567735\n",
      "  episode_reward_min: -69.78470189735461\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 10455\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.406\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 1810000\n",
      "    num_steps_trained: 1810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.590714782651048e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2163372039794922\n",
      "      kl: 0.06821148097515106\n",
      "      policy_loss: 0.014203958213329315\n",
      "      total_loss: 1507.0247802734375\n",
      "      vf_explained_var: 0.925145149230957\n",
      "      vf_loss: 1507.0106201171875\n",
      "    sample_time_ms: 19320.747\n",
      "    update_time_ms: 6.142\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 406.1056530783868\n",
      "  time_since_restore: 4309.205518722534\n",
      "  time_this_iter_s: 22.958014965057373\n",
      "  time_total_s: 4309.205518722534\n",
      "  timestamp: 1553970076\n",
      "  timesteps_since_restore: 1810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1810000\n",
      "  training_iteration: 181\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4309 s, 181 iter, 1810000 ts, 812 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-21-40\n",
      "  done: false\n",
      "  episode_len_mean: 163.46\n",
      "  episode_reward_max: 1115.8556464290637\n",
      "  episode_reward_mean: 834.6909796451409\n",
      "  episode_reward_min: -85.51143599442628\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 10517\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.325\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 1820000\n",
      "    num_steps_trained: 1820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3860717192292213e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2782739400863647\n",
      "      kl: 0.04803214594721794\n",
      "      policy_loss: 0.011984447948634624\n",
      "      total_loss: 1049.4683837890625\n",
      "      vf_explained_var: 0.9442523121833801\n",
      "      vf_loss: 1049.456298828125\n",
      "    sample_time_ms: 19315.266\n",
      "    update_time_ms: 6.105\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 417.3454898225705\n",
      "  time_since_restore: 4333.143910169601\n",
      "  time_this_iter_s: 23.93839144706726\n",
      "  time_total_s: 4333.143910169601\n",
      "  timestamp: 1553970100\n",
      "  timesteps_since_restore: 1820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1820000\n",
      "  training_iteration: 182\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4333 s, 182 iter, 1820000 ts, 835 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-22-04\n",
      "  done: false\n",
      "  episode_len_mean: 168.5\n",
      "  episode_reward_max: 1115.8556464290637\n",
      "  episode_reward_mean: 880.612927745737\n",
      "  episode_reward_min: -85.51143599442628\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 10575\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3874.685\n",
      "    load_time_ms: 1.372\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.579107942641713e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.366798996925354\n",
      "      kl: 10.80444049835205\n",
      "      policy_loss: 0.07504571974277496\n",
      "      total_loss: 921.9332885742188\n",
      "      vf_explained_var: 0.953467071056366\n",
      "      vf_loss: 921.8577880859375\n",
      "    sample_time_ms: 19420.543\n",
      "    update_time_ms: 6.083\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 440.3064638728685\n",
      "  time_since_restore: 4356.524418830872\n",
      "  time_this_iter_s: 23.38050866127014\n",
      "  time_total_s: 4356.524418830872\n",
      "  timestamp: 1553970124\n",
      "  timesteps_since_restore: 1830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 183\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4356 s, 183 iter, 1830000 ts, 881 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-22-28\n",
      "  done: false\n",
      "  episode_len_mean: 164.16\n",
      "  episode_reward_max: 1147.4657009494972\n",
      "  episode_reward_mean: 855.0013032470155\n",
      "  episode_reward_min: -77.34487999694711\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 10638\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.331\n",
      "    load_time_ms: 1.389\n",
      "    num_steps_sampled: 1840000\n",
      "    num_steps_trained: 1840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.368661368265748e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.131366491317749\n",
      "      kl: 0.026993947103619576\n",
      "      policy_loss: 0.005138796288520098\n",
      "      total_loss: 1391.0333251953125\n",
      "      vf_explained_var: 0.9282827377319336\n",
      "      vf_loss: 1391.0281982421875\n",
      "    sample_time_ms: 19574.697\n",
      "    update_time_ms: 6.127\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 427.50065162350785\n",
      "  time_since_restore: 4380.681198835373\n",
      "  time_this_iter_s: 24.156780004501343\n",
      "  time_total_s: 4380.681198835373\n",
      "  timestamp: 1553970148\n",
      "  timesteps_since_restore: 1840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1840000\n",
      "  training_iteration: 184\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4380 s, 184 iter, 1840000 ts, 855 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-22-52\n",
      "  done: false\n",
      "  episode_len_mean: 157.67\n",
      "  episode_reward_max: 1152.0134324402732\n",
      "  episode_reward_mean: 800.6347059716597\n",
      "  episode_reward_min: -72.2335025636513\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 10701\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.925\n",
      "    load_time_ms: 1.393\n",
      "    num_steps_sampled: 1850000\n",
      "    num_steps_trained: 1850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.368661368265748e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2114949226379395\n",
      "      kl: 0.02772413194179535\n",
      "      policy_loss: 0.003868794534355402\n",
      "      total_loss: 1880.470947265625\n",
      "      vf_explained_var: 0.9044846892356873\n",
      "      vf_loss: 1880.4674072265625\n",
      "    sample_time_ms: 19613.533\n",
      "    update_time_ms: 5.271\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.31735298582987\n",
      "  time_since_restore: 4404.552697896957\n",
      "  time_this_iter_s: 23.871499061584473\n",
      "  time_total_s: 4404.552697896957\n",
      "  timestamp: 1553970172\n",
      "  timesteps_since_restore: 1850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1850000\n",
      "  training_iteration: 185\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4404 s, 185 iter, 1850000 ts, 801 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-23-15\n",
      "  done: false\n",
      "  episode_len_mean: 154.65\n",
      "  episode_reward_max: 1152.0134324402732\n",
      "  episode_reward_mean: 772.4736423855854\n",
      "  episode_reward_min: -98.52751100034054\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 10765\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.481\n",
      "    load_time_ms: 1.355\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.368661368265748e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2278602123260498\n",
      "      kl: 0.06094217300415039\n",
      "      policy_loss: 0.00963460560888052\n",
      "      total_loss: 1384.7882080078125\n",
      "      vf_explained_var: 0.9346076846122742\n",
      "      vf_loss: 1384.7786865234375\n",
      "    sample_time_ms: 19595.59\n",
      "    update_time_ms: 5.44\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 386.23682119279255\n",
      "  time_since_restore: 4427.516512155533\n",
      "  time_this_iter_s: 22.96381425857544\n",
      "  time_total_s: 4427.516512155533\n",
      "  timestamp: 1553970195\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 186\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4427 s, 186 iter, 1860000 ts, 772 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-23-38\n",
      "  done: false\n",
      "  episode_len_mean: 164.43\n",
      "  episode_reward_max: 1117.6003127062854\n",
      "  episode_reward_mean: 871.0613122050314\n",
      "  episode_reward_min: -83.7854233672988\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 10826\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.355\n",
      "    load_time_ms: 1.384\n",
      "    num_steps_sampled: 1870000\n",
      "    num_steps_trained: 1870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.052992779994383e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2719451189041138\n",
      "      kl: 0.05250247195363045\n",
      "      policy_loss: 0.008342070505023003\n",
      "      total_loss: 1012.4776611328125\n",
      "      vf_explained_var: 0.9529592990875244\n",
      "      vf_loss: 1012.4693603515625\n",
      "    sample_time_ms: 19590.711\n",
      "    update_time_ms: 5.512\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 435.53065610251565\n",
      "  time_since_restore: 4450.794102430344\n",
      "  time_this_iter_s: 23.27759027481079\n",
      "  time_total_s: 4450.794102430344\n",
      "  timestamp: 1553970218\n",
      "  timesteps_since_restore: 1870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1870000\n",
      "  training_iteration: 187\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4450 s, 187 iter, 1870000 ts, 871 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-24-02\n",
      "  done: false\n",
      "  episode_len_mean: 165.23\n",
      "  episode_reward_max: 1117.6003127062854\n",
      "  episode_reward_mean: 864.5312992557982\n",
      "  episode_reward_min: -83.69521651363952\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 10888\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.173\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 1880000\n",
      "    num_steps_trained: 1880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00012079488806193694\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2249454259872437\n",
      "      kl: 0.14572051167488098\n",
      "      policy_loss: 0.008669055067002773\n",
      "      total_loss: 1135.66748046875\n",
      "      vf_explained_var: 0.9433718919754028\n",
      "      vf_loss: 1135.6588134765625\n",
      "    sample_time_ms: 19591.771\n",
      "    update_time_ms: 5.486\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 432.2656496278991\n",
      "  time_since_restore: 4474.153511285782\n",
      "  time_this_iter_s: 23.359408855438232\n",
      "  time_total_s: 4474.153511285782\n",
      "  timestamp: 1553970242\n",
      "  timesteps_since_restore: 1880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1880000\n",
      "  training_iteration: 188\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4474 s, 188 iter, 1880000 ts, 865 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-24-26\n",
      "  done: false\n",
      "  episode_len_mean: 161.62\n",
      "  episode_reward_max: 1088.0435036480746\n",
      "  episode_reward_mean: 814.596050015824\n",
      "  episode_reward_min: -83.69521651363952\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 10949\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.373\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00018119231390301138\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3185786008834839\n",
      "      kl: 0.11098726838827133\n",
      "      policy_loss: 0.011269941926002502\n",
      "      total_loss: 1614.7193603515625\n",
      "      vf_explained_var: 0.9183323979377747\n",
      "      vf_loss: 1614.7078857421875\n",
      "    sample_time_ms: 19683.724\n",
      "    update_time_ms: 5.683\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 407.298025007912\n",
      "  time_since_restore: 4498.104281425476\n",
      "  time_this_iter_s: 23.950770139694214\n",
      "  time_total_s: 4498.104281425476\n",
      "  timestamp: 1553970266\n",
      "  timesteps_since_restore: 1890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 189\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4498 s, 189 iter, 1890000 ts, 815 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-24-49\n",
      "  done: false\n",
      "  episode_len_mean: 165.2\n",
      "  episode_reward_max: 1088.1576897954342\n",
      "  episode_reward_mean: 838.9702136604443\n",
      "  episode_reward_min: -66.41981861751353\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11009\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.544\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 1900000\n",
      "    num_steps_trained: 1900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0002717884781304747\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.283471703529358\n",
      "      kl: 0.09955013543367386\n",
      "      policy_loss: 0.014609241858124733\n",
      "      total_loss: 1324.5284423828125\n",
      "      vf_explained_var: 0.9289427399635315\n",
      "      vf_loss: 1324.5137939453125\n",
      "    sample_time_ms: 19612.744\n",
      "    update_time_ms: 5.784\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 419.4851068302221\n",
      "  time_since_restore: 4521.4294447898865\n",
      "  time_this_iter_s: 23.3251633644104\n",
      "  time_total_s: 4521.4294447898865\n",
      "  timestamp: 1553970289\n",
      "  timesteps_since_restore: 1900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1900000\n",
      "  training_iteration: 190\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4521 s, 190 iter, 1900000 ts, 839 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-25-12\n",
      "  done: false\n",
      "  episode_len_mean: 166.74\n",
      "  episode_reward_max: 1137.208702912211\n",
      "  episode_reward_mean: 843.031389803781\n",
      "  episode_reward_min: -67.78367071572032\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 11068\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.699\n",
      "    load_time_ms: 1.403\n",
      "    num_steps_sampled: 1910000\n",
      "    num_steps_trained: 1910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00040768267353996634\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3577039241790771\n",
      "      kl: 0.06679554283618927\n",
      "      policy_loss: 0.007128635887056589\n",
      "      total_loss: 1541.46533203125\n",
      "      vf_explained_var: 0.9237751364707947\n",
      "      vf_loss: 1541.4581298828125\n",
      "    sample_time_ms: 19632.859\n",
      "    update_time_ms: 5.89\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 421.5156949018905\n",
      "  time_since_restore: 4544.59778213501\n",
      "  time_this_iter_s: 23.16833734512329\n",
      "  time_total_s: 4544.59778213501\n",
      "  timestamp: 1553970312\n",
      "  timesteps_since_restore: 1910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1910000\n",
      "  training_iteration: 191\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4544 s, 191 iter, 1910000 ts, 843 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-25-35\n",
      "  done: false\n",
      "  episode_len_mean: 166.12\n",
      "  episode_reward_max: 1137.208702912211\n",
      "  episode_reward_mean: 832.583508737843\n",
      "  episode_reward_min: -73.66839404454471\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 11129\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3871.693\n",
      "    load_time_ms: 1.395\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006115240976214409\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.36326265335083\n",
      "      kl: 0.04848768562078476\n",
      "      policy_loss: 0.005255353637039661\n",
      "      total_loss: 1500.390380859375\n",
      "      vf_explained_var: 0.9231634140014648\n",
      "      vf_loss: 1500.385009765625\n",
      "    sample_time_ms: 19570.351\n",
      "    update_time_ms: 5.869\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 416.29175436892154\n",
      "  time_since_restore: 4567.800904035568\n",
      "  time_this_iter_s: 23.20312190055847\n",
      "  time_total_s: 4567.800904035568\n",
      "  timestamp: 1553970335\n",
      "  timesteps_since_restore: 1920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 192\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4567 s, 192 iter, 1920000 ts, 833 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-25-59\n",
      "  done: false\n",
      "  episode_len_mean: 165.3\n",
      "  episode_reward_max: 1124.0084005373951\n",
      "  episode_reward_mean: 799.704662455079\n",
      "  episode_reward_min: -79.00854425674987\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 11190\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.312\n",
      "    load_time_ms: 1.401\n",
      "    num_steps_sampled: 1930000\n",
      "    num_steps_trained: 1930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0009172860882245004\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3148846626281738\n",
      "      kl: 0.11332622170448303\n",
      "      policy_loss: 0.0122004933655262\n",
      "      total_loss: 1788.5611572265625\n",
      "      vf_explained_var: 0.9129428267478943\n",
      "      vf_loss: 1788.548828125\n",
      "    sample_time_ms: 19615.369\n",
      "    update_time_ms: 6.016\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 399.8523312275395\n",
      "  time_since_restore: 4591.671112298965\n",
      "  time_this_iter_s: 23.870208263397217\n",
      "  time_total_s: 4591.671112298965\n",
      "  timestamp: 1553970359\n",
      "  timesteps_since_restore: 1930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1930000\n",
      "  training_iteration: 193\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4591 s, 193 iter, 1930000 ts, 800 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-26-23\n",
      "  done: false\n",
      "  episode_len_mean: 159.92\n",
      "  episode_reward_max: 1089.7787792723557\n",
      "  episode_reward_mean: 784.9072763670105\n",
      "  episode_reward_min: -45.855778694531125\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 11253\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3863.329\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 1940000\n",
      "    num_steps_trained: 1940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0013759293360635638\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2394564151763916\n",
      "      kl: 0.02967279963195324\n",
      "      policy_loss: 0.005014191847294569\n",
      "      total_loss: 1112.43115234375\n",
      "      vf_explained_var: 0.9550037980079651\n",
      "      vf_loss: 1112.426025390625\n",
      "    sample_time_ms: 19542.523\n",
      "    update_time_ms: 5.903\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 392.45363818350523\n",
      "  time_since_restore: 4614.980592727661\n",
      "  time_this_iter_s: 23.30948042869568\n",
      "  time_total_s: 4614.980592727661\n",
      "  timestamp: 1553970383\n",
      "  timesteps_since_restore: 1940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1940000\n",
      "  training_iteration: 194\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4614 s, 194 iter, 1940000 ts, 785 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-26-47\n",
      "  done: false\n",
      "  episode_len_mean: 157.57\n",
      "  episode_reward_max: 1072.6577269236352\n",
      "  episode_reward_mean: 764.4759128728214\n",
      "  episode_reward_min: -91.48442456113713\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 11316\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3866.455\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0013759293360635638\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3182278871536255\n",
      "      kl: 0.08497007191181183\n",
      "      policy_loss: 0.008726109750568867\n",
      "      total_loss: 1460.4393310546875\n",
      "      vf_explained_var: 0.9284413456916809\n",
      "      vf_loss: 1460.4305419921875\n",
      "    sample_time_ms: 19584.058\n",
      "    update_time_ms: 5.921\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 382.23795643641074\n",
      "  time_since_restore: 4639.299943447113\n",
      "  time_this_iter_s: 24.319350719451904\n",
      "  time_total_s: 4639.299943447113\n",
      "  timestamp: 1553970407\n",
      "  timesteps_since_restore: 1950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 195\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4639 s, 195 iter, 1950000 ts, 764 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-27-10\n",
      "  done: false\n",
      "  episode_len_mean: 159.35\n",
      "  episode_reward_max: 1101.8710538569978\n",
      "  episode_reward_mean: 807.3170820598812\n",
      "  episode_reward_min: -67.13177873573645\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 11377\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.834\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 1960000\n",
      "    num_steps_trained: 1960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.002063893713057041\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2183949947357178\n",
      "      kl: 0.14746035635471344\n",
      "      policy_loss: 0.010560986585915089\n",
      "      total_loss: 1564.7413330078125\n",
      "      vf_explained_var: 0.9243435263633728\n",
      "      vf_loss: 1564.7305908203125\n",
      "    sample_time_ms: 19582.661\n",
      "    update_time_ms: 5.743\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 403.6585410299405\n",
      "  time_since_restore: 4662.401579141617\n",
      "  time_this_iter_s: 23.101635694503784\n",
      "  time_total_s: 4662.401579141617\n",
      "  timestamp: 1553970430\n",
      "  timesteps_since_restore: 1960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1960000\n",
      "  training_iteration: 196\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4662 s, 196 iter, 1960000 ts, 807 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-27-33\n",
      "  done: false\n",
      "  episode_len_mean: 159.23\n",
      "  episode_reward_max: 1141.0397831743278\n",
      "  episode_reward_mean: 835.9853913685563\n",
      "  episode_reward_min: -60.9396874992934\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 11441\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3868.549\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 1970000\n",
      "    num_steps_trained: 1970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0030958408024162054\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.070550560951233\n",
      "      kl: 0.05687591806054115\n",
      "      policy_loss: 0.007760008331388235\n",
      "      total_loss: 1606.451904296875\n",
      "      vf_explained_var: 0.92622971534729\n",
      "      vf_loss: 1606.4439697265625\n",
      "    sample_time_ms: 19585.205\n",
      "    update_time_ms: 5.657\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 417.9926956842781\n",
      "  time_since_restore: 4685.5707087516785\n",
      "  time_this_iter_s: 23.169129610061646\n",
      "  time_total_s: 4685.5707087516785\n",
      "  timestamp: 1553970453\n",
      "  timesteps_since_restore: 1970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1970000\n",
      "  training_iteration: 197\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4685 s, 197 iter, 1970000 ts, 836 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-27-57\n",
      "  done: false\n",
      "  episode_len_mean: 164.65\n",
      "  episode_reward_max: 1141.0397831743278\n",
      "  episode_reward_mean: 854.8202662407037\n",
      "  episode_reward_min: -2.5173066973707705\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11501\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3871.644\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004643761087208986\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2806631326675415\n",
      "      kl: 0.11285719275474548\n",
      "      policy_loss: 0.008138387463986874\n",
      "      total_loss: 1786.8778076171875\n",
      "      vf_explained_var: 0.9167105555534363\n",
      "      vf_loss: 1786.869140625\n",
      "    sample_time_ms: 19581.022\n",
      "    update_time_ms: 5.661\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 427.410133120352\n",
      "  time_since_restore: 4708.918073654175\n",
      "  time_this_iter_s: 23.347364902496338\n",
      "  time_total_s: 4708.918073654175\n",
      "  timestamp: 1553970477\n",
      "  timesteps_since_restore: 1980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 198\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4708 s, 198 iter, 1980000 ts, 855 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-28-20\n",
      "  done: false\n",
      "  episode_len_mean: 163.1\n",
      "  episode_reward_max: 1080.8572467441265\n",
      "  episode_reward_mean: 790.8865556621421\n",
      "  episode_reward_min: -75.48445593662157\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 11563\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3872.598\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 1990000\n",
      "    num_steps_trained: 1990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.006965641863644123\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3869324922561646\n",
      "      kl: 0.09565085917711258\n",
      "      policy_loss: 0.010986180044710636\n",
      "      total_loss: 1022.4547119140625\n",
      "      vf_explained_var: 0.9526674151420593\n",
      "      vf_loss: 1022.443115234375\n",
      "    sample_time_ms: 19548.568\n",
      "    update_time_ms: 5.466\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 395.4432778310711\n",
      "  time_since_restore: 4732.552449941635\n",
      "  time_this_iter_s: 23.634376287460327\n",
      "  time_total_s: 4732.552449941635\n",
      "  timestamp: 1553970500\n",
      "  timesteps_since_restore: 1990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1990000\n",
      "  training_iteration: 199\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4732 s, 199 iter, 1990000 ts, 791 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-28-44\n",
      "  done: false\n",
      "  episode_len_mean: 162.06\n",
      "  episode_reward_max: 1090.6596510829584\n",
      "  episode_reward_mean: 818.7088041790671\n",
      "  episode_reward_min: -77.79483594539882\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 11625\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.392\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 2000000\n",
      "    num_steps_trained: 2000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.010448462329804897\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1952892541885376\n",
      "      kl: 0.12275510281324387\n",
      "      policy_loss: 0.012750579975545406\n",
      "      total_loss: 1853.168212890625\n",
      "      vf_explained_var: 0.9077105522155762\n",
      "      vf_loss: 1853.154296875\n",
      "    sample_time_ms: 19595.346\n",
      "    update_time_ms: 5.435\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 409.35440208953355\n",
      "  time_since_restore: 4756.411772012711\n",
      "  time_this_iter_s: 23.85932207107544\n",
      "  time_total_s: 4756.411772012711\n",
      "  timestamp: 1553970524\n",
      "  timesteps_since_restore: 2000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2000000\n",
      "  training_iteration: 200\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4756 s, 200 iter, 2000000 ts, 819 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-29-08\n",
      "  done: false\n",
      "  episode_len_mean: 161.1\n",
      "  episode_reward_max: 1090.6596510829584\n",
      "  episode_reward_mean: 769.8557253203352\n",
      "  episode_reward_min: -84.25981317713779\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 11686\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.153\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01567269302904606\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4072165489196777\n",
      "      kl: 0.036456335335969925\n",
      "      policy_loss: 0.0011186820920556784\n",
      "      total_loss: 1506.9146728515625\n",
      "      vf_explained_var: 0.9288122653961182\n",
      "      vf_loss: 1506.912841796875\n",
      "    sample_time_ms: 19616.649\n",
      "    update_time_ms: 5.338\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 384.92786266016753\n",
      "  time_since_restore: 4779.972256422043\n",
      "  time_this_iter_s: 23.560484409332275\n",
      "  time_total_s: 4779.972256422043\n",
      "  timestamp: 1553970548\n",
      "  timesteps_since_restore: 2010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 201\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4779 s, 201 iter, 2010000 ts, 770 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-29-32\n",
      "  done: false\n",
      "  episode_len_mean: 160.54\n",
      "  episode_reward_max: 1155.3276586691322\n",
      "  episode_reward_mean: 801.8965800798874\n",
      "  episode_reward_min: -84.25981317713779\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 11749\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.068\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 2020000\n",
      "    num_steps_trained: 2020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01567269302904606\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2100039720535278\n",
      "      kl: 0.04221860691905022\n",
      "      policy_loss: 0.004769975785166025\n",
      "      total_loss: 1396.1124267578125\n",
      "      vf_explained_var: 0.9321469068527222\n",
      "      vf_loss: 1396.10693359375\n",
      "    sample_time_ms: 19686.193\n",
      "    update_time_ms: 5.492\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 400.9482900399437\n",
      "  time_since_restore: 4803.873441934586\n",
      "  time_this_iter_s: 23.901185512542725\n",
      "  time_total_s: 4803.873441934586\n",
      "  timestamp: 1553970572\n",
      "  timesteps_since_restore: 2020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2020000\n",
      "  training_iteration: 202\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4803 s, 202 iter, 2020000 ts, 802 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 159.4\n",
      "  episode_reward_max: 1155.3276586691322\n",
      "  episode_reward_mean: 833.2263637046433\n",
      "  episode_reward_min: -80.44255401782723\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 11811\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.448\n",
      "    load_time_ms: 1.445\n",
      "    num_steps_sampled: 2030000\n",
      "    num_steps_trained: 2030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.023509040474891663\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2343981266021729\n",
      "      kl: 0.0412004217505455\n",
      "      policy_loss: 0.006369561888277531\n",
      "      total_loss: 1157.7724609375\n",
      "      vf_explained_var: 0.9477319717407227\n",
      "      vf_loss: 1157.7650146484375\n",
      "    sample_time_ms: 19631.769\n",
      "    update_time_ms: 5.535\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 416.6131818523216\n",
      "  time_since_restore: 4827.2012321949005\n",
      "  time_this_iter_s: 23.32779026031494\n",
      "  time_total_s: 4827.2012321949005\n",
      "  timestamp: 1553970595\n",
      "  timesteps_since_restore: 2030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2030000\n",
      "  training_iteration: 203\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4827 s, 203 iter, 2030000 ts, 833 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-30-19\n",
      "  done: false\n",
      "  episode_len_mean: 162.47\n",
      "  episode_reward_max: 1108.707555472567\n",
      "  episode_reward_mean: 831.2705779478081\n",
      "  episode_reward_min: -83.79726680026901\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 11872\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.313\n",
      "    load_time_ms: 1.392\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3218249082565308\n",
      "      kl: 0.030582822859287262\n",
      "      policy_loss: 0.005837195087224245\n",
      "      total_loss: 1135.9913330078125\n",
      "      vf_explained_var: 0.9459669589996338\n",
      "      vf_loss: 1135.9844970703125\n",
      "    sample_time_ms: 19629.843\n",
      "    update_time_ms: 5.607\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 415.6352889739039\n",
      "  time_since_restore: 4850.520350933075\n",
      "  time_this_iter_s: 23.31911873817444\n",
      "  time_total_s: 4850.520350933075\n",
      "  timestamp: 1553970619\n",
      "  timesteps_since_restore: 2040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 204\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4850 s, 204 iter, 2040000 ts, 831 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-30-42\n",
      "  done: false\n",
      "  episode_len_mean: 166.78\n",
      "  episode_reward_max: 1077.2820802662347\n",
      "  episode_reward_mean: 838.2064922370829\n",
      "  episode_reward_min: -83.79726680026901\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11932\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.091\n",
      "    load_time_ms: 1.392\n",
      "    num_steps_sampled: 2050000\n",
      "    num_steps_trained: 2050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3484686613082886\n",
      "      kl: 0.03331868350505829\n",
      "      policy_loss: 0.0010819989256560802\n",
      "      total_loss: 1223.1822509765625\n",
      "      vf_explained_var: 0.9398645162582397\n",
      "      vf_loss: 1223.1800537109375\n",
      "    sample_time_ms: 19492.36\n",
      "    update_time_ms: 5.49\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 419.10324611854145\n",
      "  time_since_restore: 4873.470984220505\n",
      "  time_this_iter_s: 22.95063328742981\n",
      "  time_total_s: 4873.470984220505\n",
      "  timestamp: 1553970642\n",
      "  timesteps_since_restore: 2050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2050000\n",
      "  training_iteration: 205\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4873 s, 205 iter, 2050000 ts, 838 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-31-05\n",
      "  done: false\n",
      "  episode_len_mean: 167.92\n",
      "  episode_reward_max: 1098.0887536648086\n",
      "  episode_reward_mean: 828.3577663044114\n",
      "  episode_reward_min: -75.77153824055989\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 11991\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.929\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 2060000\n",
      "    num_steps_trained: 2060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3807138204574585\n",
      "      kl: 0.03890307620167732\n",
      "      policy_loss: 0.0031532342545688152\n",
      "      total_loss: 1777.039306640625\n",
      "      vf_explained_var: 0.910167396068573\n",
      "      vf_loss: 1777.034912109375\n",
      "    sample_time_ms: 19510.134\n",
      "    update_time_ms: 5.508\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 414.1788831522056\n",
      "  time_since_restore: 4896.615831375122\n",
      "  time_this_iter_s: 23.14484715461731\n",
      "  time_total_s: 4896.615831375122\n",
      "  timestamp: 1553970665\n",
      "  timesteps_since_restore: 2060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2060000\n",
      "  training_iteration: 206\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4896 s, 206 iter, 2060000 ts, 828 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-31-28\n",
      "  done: false\n",
      "  episode_len_mean: 169.49\n",
      "  episode_reward_max: 1098.0887536648086\n",
      "  episode_reward_mean: 848.912223462809\n",
      "  episode_reward_min: -65.23913726959961\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 12053\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.049\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2376060485839844\n",
      "      kl: 0.03965412825345993\n",
      "      policy_loss: 0.006251226644963026\n",
      "      total_loss: 1486.048095703125\n",
      "      vf_explained_var: 0.9371660947799683\n",
      "      vf_loss: 1486.0404052734375\n",
      "    sample_time_ms: 19535.751\n",
      "    update_time_ms: 5.832\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 424.4561117314045\n",
      "  time_since_restore: 4920.107719659805\n",
      "  time_this_iter_s: 23.491888284683228\n",
      "  time_total_s: 4920.107719659805\n",
      "  timestamp: 1553970688\n",
      "  timesteps_since_restore: 2070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 207\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4920 s, 207 iter, 2070000 ts, 849 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-31-52\n",
      "  done: false\n",
      "  episode_len_mean: 171.83\n",
      "  episode_reward_max: 1153.9695093194332\n",
      "  episode_reward_mean: 835.6291404002943\n",
      "  episode_reward_min: -57.506750535277774\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 12109\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.579\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 2080000\n",
      "    num_steps_trained: 2080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5543529987335205\n",
      "      kl: 0.034698206931352615\n",
      "      policy_loss: 0.003672067541629076\n",
      "      total_loss: 1293.5582275390625\n",
      "      vf_explained_var: 0.9412208199501038\n",
      "      vf_loss: 1293.5533447265625\n",
      "    sample_time_ms: 19559.047\n",
      "    update_time_ms: 5.708\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 417.81457020014716\n",
      "  time_since_restore: 4943.655925512314\n",
      "  time_this_iter_s: 23.548205852508545\n",
      "  time_total_s: 4943.655925512314\n",
      "  timestamp: 1553970712\n",
      "  timesteps_since_restore: 2080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2080000\n",
      "  training_iteration: 208\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4943 s, 208 iter, 2080000 ts, 836 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-32-15\n",
      "  done: false\n",
      "  episode_len_mean: 159.51\n",
      "  episode_reward_max: 1169.2937884238736\n",
      "  episode_reward_mean: 740.3501035302728\n",
      "  episode_reward_min: -91.40279957925672\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 12175\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.981\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 2090000\n",
      "    num_steps_trained: 2090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3132611513137817\n",
      "      kl: 0.026898089796304703\n",
      "      policy_loss: 0.0009318122174590826\n",
      "      total_loss: 2386.2744140625\n",
      "      vf_explained_var: 0.9062463045120239\n",
      "      vf_loss: 2386.2724609375\n",
      "    sample_time_ms: 19539.989\n",
      "    update_time_ms: 5.612\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 370.1750517651364\n",
      "  time_since_restore: 4967.04235959053\n",
      "  time_this_iter_s: 23.386434078216553\n",
      "  time_total_s: 4967.04235959053\n",
      "  timestamp: 1553970735\n",
      "  timesteps_since_restore: 2090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2090000\n",
      "  training_iteration: 209\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4967 s, 209 iter, 2090000 ts, 740 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-32-39\n",
      "  done: false\n",
      "  episode_len_mean: 161.63\n",
      "  episode_reward_max: 1146.452714990803\n",
      "  episode_reward_mean: 775.0874864867434\n",
      "  episode_reward_min: -91.40279957925672\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 12234\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.303\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3449147939682007\n",
      "      kl: 0.0247237216681242\n",
      "      policy_loss: 0.003341972827911377\n",
      "      total_loss: 1192.152099609375\n",
      "      vf_explained_var: 0.943814218044281\n",
      "      vf_loss: 1192.1480712890625\n",
      "    sample_time_ms: 19507.833\n",
      "    update_time_ms: 5.514\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 387.54374324337186\n",
      "  time_since_restore: 4990.76078248024\n",
      "  time_this_iter_s: 23.718422889709473\n",
      "  time_total_s: 4990.76078248024\n",
      "  timestamp: 1553970759\n",
      "  timesteps_since_restore: 2100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 210\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 4990 s, 210 iter, 2100000 ts, 775 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-33-02\n",
      "  done: false\n",
      "  episode_len_mean: 161.08\n",
      "  episode_reward_max: 1120.6299338135846\n",
      "  episode_reward_mean: 806.3243370715278\n",
      "  episode_reward_min: -93.93705166727914\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 12298\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.725\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 2110000\n",
      "    num_steps_trained: 2110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.192821741104126\n",
      "      kl: 0.03416156396269798\n",
      "      policy_loss: 0.005478300154209137\n",
      "      total_loss: 1672.1136474609375\n",
      "      vf_explained_var: 0.9257571697235107\n",
      "      vf_loss: 1672.10693359375\n",
      "    sample_time_ms: 19474.217\n",
      "    update_time_ms: 5.519\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 403.1621685357639\n",
      "  time_since_restore: 5013.860913038254\n",
      "  time_this_iter_s: 23.100130558013916\n",
      "  time_total_s: 5013.860913038254\n",
      "  timestamp: 1553970782\n",
      "  timesteps_since_restore: 2110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2110000\n",
      "  training_iteration: 211\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5013 s, 211 iter, 2110000 ts, 806 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-33-26\n",
      "  done: false\n",
      "  episode_len_mean: 162.11\n",
      "  episode_reward_max: 1098.3293897735873\n",
      "  episode_reward_mean: 823.0493141544792\n",
      "  episode_reward_min: -82.9204160517227\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 12361\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.911\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 2120000\n",
      "    num_steps_trained: 2120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3832590579986572\n",
      "      kl: 0.022961007431149483\n",
      "      policy_loss: 0.002010276773944497\n",
      "      total_loss: 1853.826904296875\n",
      "      vf_explained_var: 0.9098082184791565\n",
      "      vf_loss: 1853.8240966796875\n",
      "    sample_time_ms: 19437.822\n",
      "    update_time_ms: 5.327\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 411.5246570772397\n",
      "  time_since_restore: 5037.394212245941\n",
      "  time_this_iter_s: 23.533299207687378\n",
      "  time_total_s: 5037.394212245941\n",
      "  timestamp: 1553970806\n",
      "  timesteps_since_restore: 2120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2120000\n",
      "  training_iteration: 212\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5037 s, 212 iter, 2120000 ts, 823 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-33-50\n",
      "  done: false\n",
      "  episode_len_mean: 153.78\n",
      "  episode_reward_max: 1138.1316577551897\n",
      "  episode_reward_mean: 748.0275243137563\n",
      "  episode_reward_min: -82.9204160517227\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 12425\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.196\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2922372817993164\n",
      "      kl: 0.036030132323503494\n",
      "      policy_loss: 0.005878765136003494\n",
      "      total_loss: 1621.917724609375\n",
      "      vf_explained_var: 0.929423987865448\n",
      "      vf_loss: 1621.91064453125\n",
      "    sample_time_ms: 19532.232\n",
      "    update_time_ms: 5.6\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 374.0137621568781\n",
      "  time_since_restore: 5061.621581792831\n",
      "  time_this_iter_s: 24.22736954689026\n",
      "  time_total_s: 5061.621581792831\n",
      "  timestamp: 1553970830\n",
      "  timesteps_since_restore: 2130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 213\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5061 s, 213 iter, 2130000 ts, 748 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-34-14\n",
      "  done: false\n",
      "  episode_len_mean: 154.64\n",
      "  episode_reward_max: 1138.1316577551897\n",
      "  episode_reward_mean: 733.5043973881636\n",
      "  episode_reward_min: -87.46625428367066\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 12489\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.286\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 2140000\n",
      "    num_steps_trained: 2140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3155722618103027\n",
      "      kl: 0.022350767627358437\n",
      "      policy_loss: 0.004354231059551239\n",
      "      total_loss: 1644.25830078125\n",
      "      vf_explained_var: 0.9287742376327515\n",
      "      vf_loss: 1644.253173828125\n",
      "    sample_time_ms: 19568.814\n",
      "    update_time_ms: 5.58\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 366.75219869408176\n",
      "  time_since_restore: 5085.328817605972\n",
      "  time_this_iter_s: 23.70723581314087\n",
      "  time_total_s: 5085.328817605972\n",
      "  timestamp: 1553970854\n",
      "  timesteps_since_restore: 2140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2140000\n",
      "  training_iteration: 214\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5085 s, 214 iter, 2140000 ts, 734 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-34-38\n",
      "  done: false\n",
      "  episode_len_mean: 165.04\n",
      "  episode_reward_max: 1075.3311869275517\n",
      "  episode_reward_mean: 809.9752213323217\n",
      "  episode_reward_min: -87.46625428367066\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 12548\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.223\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 2150000\n",
      "    num_steps_trained: 2150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3755062818527222\n",
      "      kl: 0.03945669159293175\n",
      "      policy_loss: 0.003726294497027993\n",
      "      total_loss: 946.7640991210938\n",
      "      vf_explained_var: 0.9562182426452637\n",
      "      vf_loss: 946.759033203125\n",
      "    sample_time_ms: 19634.941\n",
      "    update_time_ms: 5.677\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 404.9876106661609\n",
      "  time_since_restore: 5109.210522651672\n",
      "  time_this_iter_s: 23.881705045700073\n",
      "  time_total_s: 5109.210522651672\n",
      "  timestamp: 1553970878\n",
      "  timesteps_since_restore: 2150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2150000\n",
      "  training_iteration: 215\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5109 s, 215 iter, 2150000 ts, 810 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-35-01\n",
      "  done: false\n",
      "  episode_len_mean: 168.03\n",
      "  episode_reward_max: 1075.3311869275517\n",
      "  episode_reward_mean: 842.7724632780742\n",
      "  episode_reward_min: -64.24342457532634\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12608\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.855\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4006913900375366\n",
      "      kl: 0.02834336832165718\n",
      "      policy_loss: 0.0019361975137144327\n",
      "      total_loss: 858.5003051757812\n",
      "      vf_explained_var: 0.9601986408233643\n",
      "      vf_loss: 858.497314453125\n",
      "    sample_time_ms: 19648.661\n",
      "    update_time_ms: 5.695\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 421.3862316390371\n",
      "  time_since_restore: 5132.5023555755615\n",
      "  time_this_iter_s: 23.29183292388916\n",
      "  time_total_s: 5132.5023555755615\n",
      "  timestamp: 1553970901\n",
      "  timesteps_since_restore: 2160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 216\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5132 s, 216 iter, 2160000 ts, 843 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-35-24\n",
      "  done: false\n",
      "  episode_len_mean: 163.66\n",
      "  episode_reward_max: 1107.324064556789\n",
      "  episode_reward_mean: 837.7368478169752\n",
      "  episode_reward_min: -93.17114942508407\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 12670\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.923\n",
      "    load_time_ms: 1.384\n",
      "    num_steps_sampled: 2170000\n",
      "    num_steps_trained: 2170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3335143327713013\n",
      "      kl: 0.028747906908392906\n",
      "      policy_loss: -0.0012092911638319492\n",
      "      total_loss: 1671.8804931640625\n",
      "      vf_explained_var: 0.9276127219200134\n",
      "      vf_loss: 1671.880859375\n",
      "    sample_time_ms: 19604.302\n",
      "    update_time_ms: 5.687\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 418.86842390848756\n",
      "  time_since_restore: 5155.578780889511\n",
      "  time_this_iter_s: 23.076425313949585\n",
      "  time_total_s: 5155.578780889511\n",
      "  timestamp: 1553970924\n",
      "  timesteps_since_restore: 2170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2170000\n",
      "  training_iteration: 217\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5155 s, 217 iter, 2170000 ts, 838 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-35-48\n",
      "  done: false\n",
      "  episode_len_mean: 162.95\n",
      "  episode_reward_max: 1079.9491612499692\n",
      "  episode_reward_mean: 797.6413486815945\n",
      "  episode_reward_min: -93.17114942508407\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12730\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.083\n",
      "    load_time_ms: 1.344\n",
      "    num_steps_sampled: 2180000\n",
      "    num_steps_trained: 2180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4176992177963257\n",
      "      kl: 0.028083795681595802\n",
      "      policy_loss: 0.0026728129014372826\n",
      "      total_loss: 984.555908203125\n",
      "      vf_explained_var: 0.9569326639175415\n",
      "      vf_loss: 984.5521850585938\n",
      "    sample_time_ms: 19586.118\n",
      "    update_time_ms: 5.658\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 398.82067434079727\n",
      "  time_since_restore: 5178.9220061302185\n",
      "  time_this_iter_s: 23.343225240707397\n",
      "  time_total_s: 5178.9220061302185\n",
      "  timestamp: 1553970948\n",
      "  timesteps_since_restore: 2180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2180000\n",
      "  training_iteration: 218\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5178 s, 218 iter, 2180000 ts, 798 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-36-11\n",
      "  done: false\n",
      "  episode_len_mean: 166.86\n",
      "  episode_reward_max: 1089.5688928254622\n",
      "  episode_reward_mean: 796.6192243401267\n",
      "  episode_reward_min: -103.95506234784257\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 12791\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3932.261\n",
      "    load_time_ms: 1.38\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3787466287612915\n",
      "      kl: 0.027828406542539597\n",
      "      policy_loss: 0.0005809034337289631\n",
      "      total_loss: 1577.1456298828125\n",
      "      vf_explained_var: 0.9312861561775208\n",
      "      vf_loss: 1577.14404296875\n",
      "    sample_time_ms: 19568.705\n",
      "    update_time_ms: 5.677\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 398.30961217006336\n",
      "  time_since_restore: 5202.288719177246\n",
      "  time_this_iter_s: 23.366713047027588\n",
      "  time_total_s: 5202.288719177246\n",
      "  timestamp: 1553970971\n",
      "  timesteps_since_restore: 2190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 219\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5202 s, 219 iter, 2190000 ts, 797 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-36-35\n",
      "  done: false\n",
      "  episode_len_mean: 162.72\n",
      "  episode_reward_max: 1089.5688928254622\n",
      "  episode_reward_mean: 794.8916176090685\n",
      "  episode_reward_min: -107.25240778647495\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 12849\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.047\n",
      "    load_time_ms: 1.376\n",
      "    num_steps_sampled: 2200000\n",
      "    num_steps_trained: 2200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03526356443762779\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.465054988861084\n",
      "      kl: 0.04190998151898384\n",
      "      policy_loss: 0.0045685130171477795\n",
      "      total_loss: 1385.20556640625\n",
      "      vf_explained_var: 0.9379820227622986\n",
      "      vf_loss: 1385.1995849609375\n",
      "    sample_time_ms: 19576.272\n",
      "    update_time_ms: 5.681\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 397.4458088045342\n",
      "  time_since_restore: 5225.890403985977\n",
      "  time_this_iter_s: 23.60168480873108\n",
      "  time_total_s: 5225.890403985977\n",
      "  timestamp: 1553970995\n",
      "  timesteps_since_restore: 2200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2200000\n",
      "  training_iteration: 220\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5225 s, 220 iter, 2200000 ts, 795 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-36-58\n",
      "  done: false\n",
      "  episode_len_mean: 171.89\n",
      "  episode_reward_max: 1107.086933231542\n",
      "  episode_reward_mean: 854.64683701046\n",
      "  episode_reward_min: -107.25240778647495\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 12906\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.223\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 2210000\n",
      "    num_steps_trained: 2210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05289534851908684\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.476385474205017\n",
      "      kl: 0.041027095168828964\n",
      "      policy_loss: 0.0025481372140347958\n",
      "      total_loss: 945.6700439453125\n",
      "      vf_explained_var: 0.9538894295692444\n",
      "      vf_loss: 945.6654663085938\n",
      "    sample_time_ms: 19627.61\n",
      "    update_time_ms: 6.512\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 427.32341850522994\n",
      "  time_since_restore: 5249.4943969249725\n",
      "  time_this_iter_s: 23.60399293899536\n",
      "  time_total_s: 5249.4943969249725\n",
      "  timestamp: 1553971018\n",
      "  timesteps_since_restore: 2210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2210000\n",
      "  training_iteration: 221\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5249 s, 221 iter, 2210000 ts, 855 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-37-23\n",
      "  done: false\n",
      "  episode_len_mean: 169.87\n",
      "  episode_reward_max: 1134.1738549451325\n",
      "  episode_reward_mean: 848.0435501505024\n",
      "  episode_reward_min: -65.51817219675007\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 12969\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.029\n",
      "    load_time_ms: 1.441\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2820905447006226\n",
      "      kl: 0.024398526176810265\n",
      "      policy_loss: 0.002818470820784569\n",
      "      total_loss: 1389.44189453125\n",
      "      vf_explained_var: 0.9341475367546082\n",
      "      vf_loss: 1389.4371337890625\n",
      "    sample_time_ms: 19707.36\n",
      "    update_time_ms: 6.647\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 424.0217750752512\n",
      "  time_since_restore: 5273.847948074341\n",
      "  time_this_iter_s: 24.353551149368286\n",
      "  time_total_s: 5273.847948074341\n",
      "  timestamp: 1553971043\n",
      "  timesteps_since_restore: 2220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 222\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5273 s, 222 iter, 2220000 ts, 848 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-37-46\n",
      "  done: false\n",
      "  episode_len_mean: 161.98\n",
      "  episode_reward_max: 1134.1738549451325\n",
      "  episode_reward_mean: 792.3711828818481\n",
      "  episode_reward_min: -65.51817219675007\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 13031\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.949\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 2230000\n",
      "    num_steps_trained: 2230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.32732093334198\n",
      "      kl: 0.020428074523806572\n",
      "      policy_loss: 0.002673374256119132\n",
      "      total_loss: 1300.2694091796875\n",
      "      vf_explained_var: 0.9418516159057617\n",
      "      vf_loss: 1300.26513671875\n",
      "    sample_time_ms: 19649.674\n",
      "    update_time_ms: 6.29\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 396.18559144092404\n",
      "  time_since_restore: 5297.5534760952\n",
      "  time_this_iter_s: 23.705528020858765\n",
      "  time_total_s: 5297.5534760952\n",
      "  timestamp: 1553971066\n",
      "  timesteps_since_restore: 2230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2230000\n",
      "  training_iteration: 223\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5297 s, 223 iter, 2230000 ts, 792 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-38-10\n",
      "  done: false\n",
      "  episode_len_mean: 167.42\n",
      "  episode_reward_max: 1166.046510202243\n",
      "  episode_reward_mean: 848.0704291433145\n",
      "  episode_reward_min: -103.83421439770963\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13091\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3933.987\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 2240000\n",
      "    num_steps_trained: 2240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.336341381072998\n",
      "      kl: 0.02212494984269142\n",
      "      policy_loss: 0.0008374198223464191\n",
      "      total_loss: 1710.20556640625\n",
      "      vf_explained_var: 0.9203921556472778\n",
      "      vf_loss: 1710.203125\n",
      "    sample_time_ms: 19596.07\n",
      "    update_time_ms: 6.26\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 424.0352145716572\n",
      "  time_since_restore: 5320.876122236252\n",
      "  time_this_iter_s: 23.322646141052246\n",
      "  time_total_s: 5320.876122236252\n",
      "  timestamp: 1553971090\n",
      "  timesteps_since_restore: 2240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2240000\n",
      "  training_iteration: 224\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5320 s, 224 iter, 2240000 ts, 848 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-38-34\n",
      "  done: false\n",
      "  episode_len_mean: 166.8\n",
      "  episode_reward_max: 1166.046510202243\n",
      "  episode_reward_mean: 851.471900309134\n",
      "  episode_reward_min: -103.83421439770963\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 13152\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.571\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3126860857009888\n",
      "      kl: 0.03155256062746048\n",
      "      policy_loss: 0.005566806066781282\n",
      "      total_loss: 827.0004272460938\n",
      "      vf_explained_var: 0.9614819288253784\n",
      "      vf_loss: 826.9923095703125\n",
      "    sample_time_ms: 19622.76\n",
      "    update_time_ms: 6.215\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 425.735950154567\n",
      "  time_since_restore: 5344.746443033218\n",
      "  time_this_iter_s: 23.870320796966553\n",
      "  time_total_s: 5344.746443033218\n",
      "  timestamp: 1553971114\n",
      "  timesteps_since_restore: 2250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 225\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5344 s, 225 iter, 2250000 ts, 851 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-38-58\n",
      "  done: false\n",
      "  episode_len_mean: 172.25\n",
      "  episode_reward_max: 1151.5999138722498\n",
      "  episode_reward_mean: 918.6827979453817\n",
      "  episode_reward_min: 1.4190637993049506\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 13209\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.528\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 2260000\n",
      "    num_steps_trained: 2260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.369745135307312\n",
      "      kl: 0.02584715373814106\n",
      "      policy_loss: 0.001285996288061142\n",
      "      total_loss: 722.5281372070312\n",
      "      vf_explained_var: 0.9665983319282532\n",
      "      vf_loss: 722.5247802734375\n",
      "    sample_time_ms: 19679.205\n",
      "    update_time_ms: 6.169\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 459.34139897269085\n",
      "  time_since_restore: 5368.648702144623\n",
      "  time_this_iter_s: 23.90225911140442\n",
      "  time_total_s: 5368.648702144623\n",
      "  timestamp: 1553971138\n",
      "  timesteps_since_restore: 2260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2260000\n",
      "  training_iteration: 226\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5368 s, 226 iter, 2260000 ts, 919 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-39-21\n",
      "  done: false\n",
      "  episode_len_mean: 172.72\n",
      "  episode_reward_max: 1151.5999138722498\n",
      "  episode_reward_mean: 863.8298787139455\n",
      "  episode_reward_min: -110.07647356536077\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 13267\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.834\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 2270000\n",
      "    num_steps_trained: 2270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4323444366455078\n",
      "      kl: 0.029078202322125435\n",
      "      policy_loss: 0.0048062484711408615\n",
      "      total_loss: 1140.916015625\n",
      "      vf_explained_var: 0.9471890330314636\n",
      "      vf_loss: 1140.9088134765625\n",
      "    sample_time_ms: 19762.128\n",
      "    update_time_ms: 6.033\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 431.91493935697275\n",
      "  time_since_restore: 5392.467295408249\n",
      "  time_this_iter_s: 23.8185932636261\n",
      "  time_total_s: 5392.467295408249\n",
      "  timestamp: 1553971161\n",
      "  timesteps_since_restore: 2270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2270000\n",
      "  training_iteration: 227\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5392 s, 227 iter, 2270000 ts, 864 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-39-45\n",
      "  done: false\n",
      "  episode_len_mean: 169.08\n",
      "  episode_reward_max: 1098.612921595646\n",
      "  episode_reward_mean: 862.5923466983029\n",
      "  episode_reward_min: -74.04065047443578\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13327\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.393\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3037705421447754\n",
      "      kl: 0.024290677160024643\n",
      "      policy_loss: 0.004126935265958309\n",
      "      total_loss: 672.0381469726562\n",
      "      vf_explained_var: 0.9678280353546143\n",
      "      vf_loss: 672.0321044921875\n",
      "    sample_time_ms: 19733.71\n",
      "    update_time_ms: 6.064\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 431.29617334915133\n",
      "  time_since_restore: 5415.532776832581\n",
      "  time_this_iter_s: 23.065481424331665\n",
      "  time_total_s: 5415.532776832581\n",
      "  timestamp: 1553971185\n",
      "  timesteps_since_restore: 2280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 228\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5415 s, 228 iter, 2280000 ts, 863 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 167.6\n",
      "  episode_reward_max: 1100.211609920049\n",
      "  episode_reward_mean: 869.8262920133337\n",
      "  episode_reward_min: -71.68503807705275\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13387\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.506\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 2290000\n",
      "    num_steps_trained: 2290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3287204504013062\n",
      "      kl: 0.031169123947620392\n",
      "      policy_loss: 0.0038175475783646107\n",
      "      total_loss: 1032.7921142578125\n",
      "      vf_explained_var: 0.9537488222122192\n",
      "      vf_loss: 1032.785888671875\n",
      "    sample_time_ms: 19795.948\n",
      "    update_time_ms: 6.087\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 434.91314600666686\n",
      "  time_since_restore: 5439.504472017288\n",
      "  time_this_iter_s: 23.97169518470764\n",
      "  time_total_s: 5439.504472017288\n",
      "  timestamp: 1553971209\n",
      "  timesteps_since_restore: 2290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2290000\n",
      "  training_iteration: 229\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5439 s, 229 iter, 2290000 ts, 870 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-40-32\n",
      "  done: false\n",
      "  episode_len_mean: 169.45\n",
      "  episode_reward_max: 1121.6444395906572\n",
      "  episode_reward_mean: 857.1208997824147\n",
      "  episode_reward_min: -71.68503807705275\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 13444\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.992\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 2300000\n",
      "    num_steps_trained: 2300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3132812976837158\n",
      "      kl: 0.017792433500289917\n",
      "      policy_loss: 0.0011162200244143605\n",
      "      total_loss: 863.7312622070312\n",
      "      vf_explained_var: 0.958405613899231\n",
      "      vf_loss: 863.728759765625\n",
      "    sample_time_ms: 19782.69\n",
      "    update_time_ms: 6.092\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 428.56044989120716\n",
      "  time_since_restore: 5462.970124959946\n",
      "  time_this_iter_s: 23.46565294265747\n",
      "  time_total_s: 5462.970124959946\n",
      "  timestamp: 1553971232\n",
      "  timesteps_since_restore: 2300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2300000\n",
      "  training_iteration: 230\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5462 s, 230 iter, 2300000 ts, 857 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-40-55\n",
      "  done: false\n",
      "  episode_len_mean: 173.77\n",
      "  episode_reward_max: 1121.6444395906572\n",
      "  episode_reward_mean: 830.1032269618809\n",
      "  episode_reward_min: -53.88229845555392\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 13503\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.346\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4380100965499878\n",
      "      kl: 0.03137526288628578\n",
      "      policy_loss: 0.0029535056091845036\n",
      "      total_loss: 1417.099609375\n",
      "      vf_explained_var: 0.9382697939872742\n",
      "      vf_loss: 1417.0943603515625\n",
      "    sample_time_ms: 19727.374\n",
      "    update_time_ms: 6.052\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 415.0516134809405\n",
      "  time_since_restore: 5486.000758886337\n",
      "  time_this_iter_s: 23.0306339263916\n",
      "  time_total_s: 5486.000758886337\n",
      "  timestamp: 1553971255\n",
      "  timesteps_since_restore: 2310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 231\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5486 s, 231 iter, 2310000 ts, 830 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-41-18\n",
      "  done: false\n",
      "  episode_len_mean: 168.3\n",
      "  episode_reward_max: 1086.303736017526\n",
      "  episode_reward_mean: 779.5202055274129\n",
      "  episode_reward_min: -86.53431302670252\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 13566\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.244\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 2320000\n",
      "    num_steps_trained: 2320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1990735530853271\n",
      "      kl: 0.015958508476614952\n",
      "      policy_loss: -4.348044240032323e-05\n",
      "      total_loss: 1768.8353271484375\n",
      "      vf_explained_var: 0.9263544082641602\n",
      "      vf_loss: 1768.8343505859375\n",
      "    sample_time_ms: 19615.178\n",
      "    update_time_ms: 6.009\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 389.76010276370647\n",
      "  time_since_restore: 5509.230269908905\n",
      "  time_this_iter_s: 23.22951102256775\n",
      "  time_total_s: 5509.230269908905\n",
      "  timestamp: 1553971278\n",
      "  timesteps_since_restore: 2320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2320000\n",
      "  training_iteration: 232\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5509 s, 232 iter, 2320000 ts, 780 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-41-42\n",
      "  done: false\n",
      "  episode_len_mean: 169.24\n",
      "  episode_reward_max: 1121.707551425173\n",
      "  episode_reward_mean: 877.9690299878658\n",
      "  episode_reward_min: -78.10082248809715\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 13625\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.464\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 2330000\n",
      "    num_steps_trained: 2330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2706189155578613\n",
      "      kl: 0.02292344532907009\n",
      "      policy_loss: 0.0014533966314047575\n",
      "      total_loss: 579.5393676757812\n",
      "      vf_explained_var: 0.9740555882453918\n",
      "      vf_loss: 579.5360717773438\n",
      "    sample_time_ms: 19653.679\n",
      "    update_time_ms: 6.013\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 438.9845149939329\n",
      "  time_since_restore: 5533.283853530884\n",
      "  time_this_iter_s: 24.05358362197876\n",
      "  time_total_s: 5533.283853530884\n",
      "  timestamp: 1553971302\n",
      "  timesteps_since_restore: 2330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2330000\n",
      "  training_iteration: 233\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5533 s, 233 iter, 2330000 ts, 878 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-42-06\n",
      "  done: false\n",
      "  episode_len_mean: 169.31\n",
      "  episode_reward_max: 1092.3674856093103\n",
      "  episode_reward_mean: 859.9109297557568\n",
      "  episode_reward_min: -56.19849445909682\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 13683\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.692\n",
      "    load_time_ms: 1.447\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4980605840682983\n",
      "      kl: 0.021748436614871025\n",
      "      policy_loss: 0.0006130419787950814\n",
      "      total_loss: 1005.0567626953125\n",
      "      vf_explained_var: 0.9504406452178955\n",
      "      vf_loss: 1005.0545043945312\n",
      "    sample_time_ms: 19683.995\n",
      "    update_time_ms: 6.067\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 429.9554648778784\n",
      "  time_since_restore: 5556.742474555969\n",
      "  time_this_iter_s: 23.45862102508545\n",
      "  time_total_s: 5556.742474555969\n",
      "  timestamp: 1553971326\n",
      "  timesteps_since_restore: 2340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 234\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5556 s, 234 iter, 2340000 ts, 860 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-42-30\n",
      "  done: false\n",
      "  episode_len_mean: 166.62\n",
      "  episode_reward_max: 1104.7172872316376\n",
      "  episode_reward_mean: 846.4185158937019\n",
      "  episode_reward_min: -56.19849445909682\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 13742\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.752\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 2350000\n",
      "    num_steps_trained: 2350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.344213604927063\n",
      "      kl: 0.035584937781095505\n",
      "      policy_loss: 0.004413757938891649\n",
      "      total_loss: 818.8045043945312\n",
      "      vf_explained_var: 0.9636897444725037\n",
      "      vf_loss: 818.7971801757812\n",
      "    sample_time_ms: 19659.364\n",
      "    update_time_ms: 6.082\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 423.209257946851\n",
      "  time_since_restore: 5580.401388883591\n",
      "  time_this_iter_s: 23.65891432762146\n",
      "  time_total_s: 5580.401388883591\n",
      "  timestamp: 1553971350\n",
      "  timesteps_since_restore: 2350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2350000\n",
      "  training_iteration: 235\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5580 s, 235 iter, 2350000 ts, 846 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-42-53\n",
      "  done: false\n",
      "  episode_len_mean: 173.85\n",
      "  episode_reward_max: 1104.7172872316376\n",
      "  episode_reward_mean: 868.6101063071812\n",
      "  episode_reward_min: -72.47571740852322\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 13798\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.591\n",
      "    load_time_ms: 1.395\n",
      "    num_steps_sampled: 2360000\n",
      "    num_steps_trained: 2360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5469779968261719\n",
      "      kl: 0.01734113320708275\n",
      "      policy_loss: 0.0010237667011097074\n",
      "      total_loss: 932.1795043945312\n",
      "      vf_explained_var: 0.9528295993804932\n",
      "      vf_loss: 932.1770629882812\n",
      "    sample_time_ms: 19630.128\n",
      "    update_time_ms: 6.234\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 434.30505315359056\n",
      "  time_since_restore: 5603.952184200287\n",
      "  time_this_iter_s: 23.550795316696167\n",
      "  time_total_s: 5603.952184200287\n",
      "  timestamp: 1553971373\n",
      "  timesteps_since_restore: 2360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2360000\n",
      "  training_iteration: 236\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5603 s, 236 iter, 2360000 ts, 869 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-43-16\n",
      "  done: false\n",
      "  episode_len_mean: 171.89\n",
      "  episode_reward_max: 1114.5492726675527\n",
      "  episode_reward_mean: 863.9980079305936\n",
      "  episode_reward_min: -85.8989712399054\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 13857\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.652\n",
      "    load_time_ms: 1.414\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2962687015533447\n",
      "      kl: 0.023759542033076286\n",
      "      policy_loss: 0.0021097094286233187\n",
      "      total_loss: 1236.5762939453125\n",
      "      vf_explained_var: 0.943770170211792\n",
      "      vf_loss: 1236.572265625\n",
      "    sample_time_ms: 19562.091\n",
      "    update_time_ms: 6.079\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 431.9990039652969\n",
      "  time_since_restore: 5627.109607219696\n",
      "  time_this_iter_s: 23.15742301940918\n",
      "  time_total_s: 5627.109607219696\n",
      "  timestamp: 1553971396\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 237\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5627 s, 237 iter, 2370000 ts, 864 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-43-40\n",
      "  done: false\n",
      "  episode_len_mean: 166.93\n",
      "  episode_reward_max: 1109.5897746242922\n",
      "  episode_reward_mean: 805.9405717542421\n",
      "  episode_reward_min: -93.06793855972234\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13917\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.398\n",
      "    load_time_ms: 1.387\n",
      "    num_steps_sampled: 2380000\n",
      "    num_steps_trained: 2380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4312479496002197\n",
      "      kl: 0.02150413952767849\n",
      "      policy_loss: 0.0005029762978665531\n",
      "      total_loss: 1317.476318359375\n",
      "      vf_explained_var: 0.9422668218612671\n",
      "      vf_loss: 1317.4739990234375\n",
      "    sample_time_ms: 19584.629\n",
      "    update_time_ms: 6.017\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 402.970285877121\n",
      "  time_since_restore: 5650.587892532349\n",
      "  time_this_iter_s: 23.478285312652588\n",
      "  time_total_s: 5650.587892532349\n",
      "  timestamp: 1553971420\n",
      "  timesteps_since_restore: 2380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2380000\n",
      "  training_iteration: 238\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5650 s, 238 iter, 2380000 ts, 806 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-44-03\n",
      "  done: false\n",
      "  episode_len_mean: 172.78\n",
      "  episode_reward_max: 1109.5897746242922\n",
      "  episode_reward_mean: 839.4369047522854\n",
      "  episode_reward_min: -93.06793855972234\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 13973\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.878\n",
      "    load_time_ms: 1.398\n",
      "    num_steps_sampled: 2390000\n",
      "    num_steps_trained: 2390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5054765939712524\n",
      "      kl: 0.03186168894171715\n",
      "      policy_loss: 0.003261750331148505\n",
      "      total_loss: 639.7410888671875\n",
      "      vf_explained_var: 0.9679610133171082\n",
      "      vf_loss: 639.7352294921875\n",
      "    sample_time_ms: 19500.5\n",
      "    update_time_ms: 6.009\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 419.7184523761428\n",
      "  time_since_restore: 5673.580897808075\n",
      "  time_this_iter_s: 22.99300527572632\n",
      "  time_total_s: 5673.580897808075\n",
      "  timestamp: 1553971443\n",
      "  timesteps_since_restore: 2390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2390000\n",
      "  training_iteration: 239\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5673 s, 239 iter, 2390000 ts, 839 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-44-26\n",
      "  done: false\n",
      "  episode_len_mean: 179.46\n",
      "  episode_reward_max: 1111.080828348377\n",
      "  episode_reward_mean: 857.3177219029578\n",
      "  episode_reward_min: -99.78674413385693\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 14030\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.085\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4861844778060913\n",
      "      kl: 0.015199939720332623\n",
      "      policy_loss: -0.0006738111260347068\n",
      "      total_loss: 1003.736572265625\n",
      "      vf_explained_var: 0.9542635679244995\n",
      "      vf_loss: 1003.7359619140625\n",
      "    sample_time_ms: 19416.85\n",
      "    update_time_ms: 5.992\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 428.65886095147886\n",
      "  time_since_restore: 5696.19205904007\n",
      "  time_this_iter_s: 22.61116123199463\n",
      "  time_total_s: 5696.19205904007\n",
      "  timestamp: 1553971466\n",
      "  timesteps_since_restore: 2400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 240\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5696 s, 240 iter, 2400000 ts, 857 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-44-49\n",
      "  done: false\n",
      "  episode_len_mean: 168.76\n",
      "  episode_reward_max: 1098.5797246592374\n",
      "  episode_reward_mean: 807.2245496098386\n",
      "  episode_reward_min: -99.78674413385693\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14090\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.561\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 2410000\n",
      "    num_steps_trained: 2410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.33210289478302\n",
      "      kl: 0.011048290878534317\n",
      "      policy_loss: -0.0021760226227343082\n",
      "      total_loss: 1406.7275390625\n",
      "      vf_explained_var: 0.9424260258674622\n",
      "      vf_loss: 1406.728759765625\n",
      "    sample_time_ms: 19437.765\n",
      "    update_time_ms: 5.172\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 403.6122748049193\n",
      "  time_since_restore: 5719.438939332962\n",
      "  time_this_iter_s: 23.246880292892456\n",
      "  time_total_s: 5719.438939332962\n",
      "  timestamp: 1553971489\n",
      "  timesteps_since_restore: 2410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2410000\n",
      "  training_iteration: 241\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5719 s, 241 iter, 2410000 ts, 807 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-45-12\n",
      "  done: false\n",
      "  episode_len_mean: 171.83\n",
      "  episode_reward_max: 1125.6006078924547\n",
      "  episode_reward_mean: 867.5956901926937\n",
      "  episode_reward_min: -41.16439084588734\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 14148\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.918\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 2420000\n",
      "    num_steps_trained: 2420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.20304536819458\n",
      "      kl: 0.027727004140615463\n",
      "      policy_loss: 0.000956991920247674\n",
      "      total_loss: 1027.0111083984375\n",
      "      vf_explained_var: 0.9509085416793823\n",
      "      vf_loss: 1027.0079345703125\n",
      "    sample_time_ms: 19394.856\n",
      "    update_time_ms: 5.074\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 433.79784509634686\n",
      "  time_since_restore: 5742.265082359314\n",
      "  time_this_iter_s: 22.82614302635193\n",
      "  time_total_s: 5742.265082359314\n",
      "  timestamp: 1553971512\n",
      "  timesteps_since_restore: 2420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2420000\n",
      "  training_iteration: 242\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5742 s, 242 iter, 2420000 ts, 868 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-45-35\n",
      "  done: false\n",
      "  episode_len_mean: 174.82\n",
      "  episode_reward_max: 1125.6006078924547\n",
      "  episode_reward_mean: 898.5888756595789\n",
      "  episode_reward_min: 1.0992800773128977\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 14204\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.059\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3960323333740234\n",
      "      kl: 0.022298399358987808\n",
      "      policy_loss: 0.003008827567100525\n",
      "      total_loss: 461.265625\n",
      "      vf_explained_var: 0.979808509349823\n",
      "      vf_loss: 461.2608642578125\n",
      "    sample_time_ms: 19316.434\n",
      "    update_time_ms: 5.119\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 449.29443782978944\n",
      "  time_since_restore: 5765.547657966614\n",
      "  time_this_iter_s: 23.282575607299805\n",
      "  time_total_s: 5765.547657966614\n",
      "  timestamp: 1553971535\n",
      "  timesteps_since_restore: 2430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 243\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5765 s, 243 iter, 2430000 ts, 899 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-45-58\n",
      "  done: false\n",
      "  episode_len_mean: 186.07\n",
      "  episode_reward_max: 1096.9245650720877\n",
      "  episode_reward_mean: 866.4762871211336\n",
      "  episode_reward_min: -95.37939979221564\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 14257\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.974\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 2440000\n",
      "    num_steps_trained: 2440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07934301346540451\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.7136731147766113\n",
      "      kl: 0.05800594389438629\n",
      "      policy_loss: 0.0016972518060356379\n",
      "      total_loss: 1151.551513671875\n",
      "      vf_explained_var: 0.9429675340652466\n",
      "      vf_loss: 1151.5452880859375\n",
      "    sample_time_ms: 19281.912\n",
      "    update_time_ms: 5.121\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 433.23814356056675\n",
      "  time_since_restore: 5788.668507814407\n",
      "  time_this_iter_s: 23.12084984779358\n",
      "  time_total_s: 5788.668507814407\n",
      "  timestamp: 1553971558\n",
      "  timesteps_since_restore: 2440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2440000\n",
      "  training_iteration: 244\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5788 s, 244 iter, 2440000 ts, 866 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-46-22\n",
      "  done: false\n",
      "  episode_len_mean: 181.8\n",
      "  episode_reward_max: 1096.9245650720877\n",
      "  episode_reward_mean: 830.9553276674873\n",
      "  episode_reward_min: -95.37939979221564\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 14312\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.189\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 2450000\n",
      "    num_steps_trained: 2450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4486439228057861\n",
      "      kl: 0.017714710906147957\n",
      "      policy_loss: 0.0001611705811228603\n",
      "      total_loss: 1155.7650146484375\n",
      "      vf_explained_var: 0.9478329420089722\n",
      "      vf_loss: 1155.7626953125\n",
      "    sample_time_ms: 19256.08\n",
      "    update_time_ms: 5.123\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 415.47766383374363\n",
      "  time_since_restore: 5812.023043632507\n",
      "  time_this_iter_s: 23.354535818099976\n",
      "  time_total_s: 5812.023043632507\n",
      "  timestamp: 1553971582\n",
      "  timesteps_since_restore: 2450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2450000\n",
      "  training_iteration: 245\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5812 s, 245 iter, 2450000 ts, 831 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-46-45\n",
      "  done: false\n",
      "  episode_len_mean: 177.63\n",
      "  episode_reward_max: 1076.4081846600611\n",
      "  episode_reward_mean: 835.1742559266013\n",
      "  episode_reward_min: -79.94256570750173\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 14370\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.292\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.459232211112976\n",
      "      kl: 0.01925387978553772\n",
      "      policy_loss: -0.0009752067853696644\n",
      "      total_loss: 1337.277587890625\n",
      "      vf_explained_var: 0.9450777769088745\n",
      "      vf_loss: 1337.2762451171875\n",
      "    sample_time_ms: 19185.042\n",
      "    update_time_ms: 5.045\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 417.5871279633006\n",
      "  time_since_restore: 5834.863973140717\n",
      "  time_this_iter_s: 22.84092950820923\n",
      "  time_total_s: 5834.863973140717\n",
      "  timestamp: 1553971605\n",
      "  timesteps_since_restore: 2460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 246\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5834 s, 246 iter, 2460000 ts, 835 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-47-08\n",
      "  done: false\n",
      "  episode_len_mean: 167.61\n",
      "  episode_reward_max: 1118.6454074388669\n",
      "  episode_reward_mean: 839.0139099473308\n",
      "  episode_reward_min: -70.79795620224348\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14430\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.926\n",
      "    load_time_ms: 1.438\n",
      "    num_steps_sampled: 2470000\n",
      "    num_steps_trained: 2470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2653374671936035\n",
      "      kl: 0.015000025741755962\n",
      "      policy_loss: -0.0005916538648307323\n",
      "      total_loss: 956.0587158203125\n",
      "      vf_explained_var: 0.9565783739089966\n",
      "      vf_loss: 956.0574951171875\n",
      "    sample_time_ms: 19192.487\n",
      "    update_time_ms: 5.071\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 419.5069549736654\n",
      "  time_since_restore: 5858.221085309982\n",
      "  time_this_iter_s: 23.357112169265747\n",
      "  time_total_s: 5858.221085309982\n",
      "  timestamp: 1553971628\n",
      "  timesteps_since_restore: 2470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2470000\n",
      "  training_iteration: 247\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5858 s, 247 iter, 2470000 ts, 839 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-47-31\n",
      "  done: false\n",
      "  episode_len_mean: 165.78\n",
      "  episode_reward_max: 1112.9151908018157\n",
      "  episode_reward_mean: 889.153702119795\n",
      "  episode_reward_min: -84.93149404047517\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 14491\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3873.851\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 2480000\n",
      "    num_steps_trained: 2480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.183575987815857\n",
      "      kl: 0.01637853868305683\n",
      "      policy_loss: -0.0008916272199712694\n",
      "      total_loss: 813.6575317382812\n",
      "      vf_explained_var: 0.964677095413208\n",
      "      vf_loss: 813.6565551757812\n",
      "    sample_time_ms: 19124.668\n",
      "    update_time_ms: 5.063\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 444.57685105989754\n",
      "  time_since_restore: 5880.810693502426\n",
      "  time_this_iter_s: 22.589608192443848\n",
      "  time_total_s: 5880.810693502426\n",
      "  timestamp: 1553971651\n",
      "  timesteps_since_restore: 2480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2480000\n",
      "  training_iteration: 248\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5880 s, 248 iter, 2480000 ts, 889 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-47-54\n",
      "  done: false\n",
      "  episode_len_mean: 168.15\n",
      "  episode_reward_max: 1112.9151908018157\n",
      "  episode_reward_mean: 889.544928034073\n",
      "  episode_reward_min: -90.56159362405117\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 14548\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.306\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.331908941268921\n",
      "      kl: 0.015283755958080292\n",
      "      policy_loss: -0.001659223809838295\n",
      "      total_loss: 734.0009765625\n",
      "      vf_explained_var: 0.963711678981781\n",
      "      vf_loss: 734.000732421875\n",
      "    sample_time_ms: 19154.066\n",
      "    update_time_ms: 5.05\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 444.77246401703655\n",
      "  time_since_restore: 5904.111119747162\n",
      "  time_this_iter_s: 23.300426244735718\n",
      "  time_total_s: 5904.111119747162\n",
      "  timestamp: 1553971674\n",
      "  timesteps_since_restore: 2490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 249\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5904 s, 249 iter, 2490000 ts, 890 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-48-18\n",
      "  done: false\n",
      "  episode_len_mean: 176.97\n",
      "  episode_reward_max: 1090.9568305040673\n",
      "  episode_reward_mean: 883.881991420501\n",
      "  episode_reward_min: -90.56159362405117\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 14604\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.103\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 2500000\n",
      "    num_steps_trained: 2500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5965605974197388\n",
      "      kl: 0.01284952461719513\n",
      "      policy_loss: -0.0023739226162433624\n",
      "      total_loss: 1359.1287841796875\n",
      "      vf_explained_var: 0.9380506873130798\n",
      "      vf_loss: 1359.129638671875\n",
      "    sample_time_ms: 19285.627\n",
      "    update_time_ms: 5.043\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 441.94099571025055\n",
      "  time_since_restore: 5928.048368930817\n",
      "  time_this_iter_s: 23.937249183654785\n",
      "  time_total_s: 5928.048368930817\n",
      "  timestamp: 1553971698\n",
      "  timesteps_since_restore: 2500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2500000\n",
      "  training_iteration: 250\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5928 s, 250 iter, 2500000 ts, 884 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-48-42\n",
      "  done: false\n",
      "  episode_len_mean: 177.44\n",
      "  episode_reward_max: 1101.8517552940302\n",
      "  episode_reward_mean: 865.0902315040439\n",
      "  episode_reward_min: -41.37205147206623\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 14661\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.627\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 2510000\n",
      "    num_steps_trained: 2510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.260507345199585\n",
      "      kl: 0.01891939528286457\n",
      "      policy_loss: -0.004400599282234907\n",
      "      total_loss: 409.0079650878906\n",
      "      vf_explained_var: 0.9833667278289795\n",
      "      vf_loss: 409.01007080078125\n",
      "    sample_time_ms: 19337.631\n",
      "    update_time_ms: 5.127\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 432.54511575202196\n",
      "  time_since_restore: 5951.824143886566\n",
      "  time_this_iter_s: 23.77577495574951\n",
      "  time_total_s: 5951.824143886566\n",
      "  timestamp: 1553971722\n",
      "  timesteps_since_restore: 2510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2510000\n",
      "  training_iteration: 251\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5951 s, 251 iter, 2510000 ts, 865 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-49-05\n",
      "  done: false\n",
      "  episode_len_mean: 175.42\n",
      "  episode_reward_max: 1101.8517552940302\n",
      "  episode_reward_mean: 889.8838218606342\n",
      "  episode_reward_min: -73.24762500681456\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 14719\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3873.814\n",
      "    load_time_ms: 1.452\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4558483362197876\n",
      "      kl: 0.01828555203974247\n",
      "      policy_loss: 0.0004092133603990078\n",
      "      total_loss: 1000.6016845703125\n",
      "      vf_explained_var: 0.9564136862754822\n",
      "      vf_loss: 1000.5991821289062\n",
      "    sample_time_ms: 19417.536\n",
      "    update_time_ms: 5.12\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 444.94191093031725\n",
      "  time_since_restore: 5975.416970252991\n",
      "  time_this_iter_s: 23.59282636642456\n",
      "  time_total_s: 5975.416970252991\n",
      "  timestamp: 1553971745\n",
      "  timesteps_since_restore: 2520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 252\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5975 s, 252 iter, 2520000 ts, 890 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-49-29\n",
      "  done: false\n",
      "  episode_len_mean: 173.81\n",
      "  episode_reward_max: 1095.1618962667485\n",
      "  episode_reward_mean: 902.5070359908552\n",
      "  episode_reward_min: -47.89744666192601\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 14778\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3874.978\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 2530000\n",
      "    num_steps_trained: 2530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3011595010757446\n",
      "      kl: 0.013384074904024601\n",
      "      policy_loss: 0.0008040716056711972\n",
      "      total_loss: 710.1720581054688\n",
      "      vf_explained_var: 0.9680651426315308\n",
      "      vf_loss: 710.1697387695312\n",
      "    sample_time_ms: 19452.844\n",
      "    update_time_ms: 5.052\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 451.2535179954276\n",
      "  time_since_restore: 5999.067962646484\n",
      "  time_this_iter_s: 23.650992393493652\n",
      "  time_total_s: 5999.067962646484\n",
      "  timestamp: 1553971769\n",
      "  timesteps_since_restore: 2530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2530000\n",
      "  training_iteration: 253\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 5999 s, 253 iter, 2530000 ts, 903 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 172.93\n",
      "  episode_reward_max: 1095.1618962667485\n",
      "  episode_reward_mean: 901.4238224247171\n",
      "  episode_reward_min: -56.280299561807084\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 14835\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.867\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 2540000\n",
      "    num_steps_trained: 2540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2872717380523682\n",
      "      kl: 0.016173649579286575\n",
      "      policy_loss: 0.0008452622569166124\n",
      "      total_loss: 633.1160888671875\n",
      "      vf_explained_var: 0.9736552238464355\n",
      "      vf_loss: 633.11328125\n",
      "    sample_time_ms: 19463.499\n",
      "    update_time_ms: 5.05\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 450.7119112123585\n",
      "  time_since_restore: 6022.347243070602\n",
      "  time_this_iter_s: 23.279280424118042\n",
      "  time_total_s: 6022.347243070602\n",
      "  timestamp: 1553971792\n",
      "  timesteps_since_restore: 2540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2540000\n",
      "  training_iteration: 254\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6022 s, 254 iter, 2540000 ts, 901 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-50-15\n",
      "  done: false\n",
      "  episode_len_mean: 178.86\n",
      "  episode_reward_max: 1112.4682953199697\n",
      "  episode_reward_mean: 886.5056030625062\n",
      "  episode_reward_min: -56.280299561807084\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 14890\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.629\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4228379726409912\n",
      "      kl: 0.02112206071615219\n",
      "      policy_loss: -0.001324608107097447\n",
      "      total_loss: 684.7540283203125\n",
      "      vf_explained_var: 0.9696928858757019\n",
      "      vf_loss: 684.7528076171875\n",
      "    sample_time_ms: 19351.616\n",
      "    update_time_ms: 5.002\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 443.2528015312532\n",
      "  time_since_restore: 6044.611901760101\n",
      "  time_this_iter_s: 22.2646586894989\n",
      "  time_total_s: 6044.611901760101\n",
      "  timestamp: 1553971815\n",
      "  timesteps_since_restore: 2550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 255\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6044 s, 255 iter, 2550000 ts, 887 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-50-38\n",
      "  done: false\n",
      "  episode_len_mean: 173.93\n",
      "  episode_reward_max: 1119.7415533480769\n",
      "  episode_reward_mean: 847.6225392227509\n",
      "  episode_reward_min: -82.69755691609072\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14950\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.656\n",
      "    load_time_ms: 1.657\n",
      "    num_steps_sampled: 2560000\n",
      "    num_steps_trained: 2560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3950484991073608\n",
      "      kl: 0.030693115666508675\n",
      "      policy_loss: 0.0015694602625444531\n",
      "      total_loss: 1296.8809814453125\n",
      "      vf_explained_var: 0.9436619877815247\n",
      "      vf_loss: 1296.8758544921875\n",
      "    sample_time_ms: 19416.584\n",
      "    update_time_ms: 5.2\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 423.81126961137545\n",
      "  time_since_restore: 6068.3483238220215\n",
      "  time_this_iter_s: 23.736422061920166\n",
      "  time_total_s: 6068.3483238220215\n",
      "  timestamp: 1553971838\n",
      "  timesteps_since_restore: 2560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2560000\n",
      "  training_iteration: 256\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6068 s, 256 iter, 2560000 ts, 848 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-51-02\n",
      "  done: false\n",
      "  episode_len_mean: 172.12\n",
      "  episode_reward_max: 1119.7415533480769\n",
      "  episode_reward_mean: 832.4398764322874\n",
      "  episode_reward_min: -82.69755691609072\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 15006\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.515\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 2570000\n",
      "    num_steps_trained: 2570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.474847674369812\n",
      "      kl: 0.01450952049344778\n",
      "      policy_loss: -0.0003341157571412623\n",
      "      total_loss: 753.7987060546875\n",
      "      vf_explained_var: 0.9651828408241272\n",
      "      vf_loss: 753.7972412109375\n",
      "    sample_time_ms: 19411.073\n",
      "    update_time_ms: 5.237\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 416.21993821614365\n",
      "  time_since_restore: 6091.519187927246\n",
      "  time_this_iter_s: 23.17086410522461\n",
      "  time_total_s: 6091.519187927246\n",
      "  timestamp: 1553971862\n",
      "  timesteps_since_restore: 2570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2570000\n",
      "  training_iteration: 257\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6091 s, 257 iter, 2570000 ts, 832 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-51-25\n",
      "  done: false\n",
      "  episode_len_mean: 173.93\n",
      "  episode_reward_max: 1097.2653321226592\n",
      "  episode_reward_mean: 844.3385503251257\n",
      "  episode_reward_min: -74.9513091400856\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 15064\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.546\n",
      "    load_time_ms: 1.687\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4358575344085693\n",
      "      kl: 0.016714802011847496\n",
      "      policy_loss: -0.00024769073934294283\n",
      "      total_loss: 1129.702880859375\n",
      "      vf_explained_var: 0.9529201984405518\n",
      "      vf_loss: 1129.701171875\n",
      "    sample_time_ms: 19458.193\n",
      "    update_time_ms: 5.223\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 422.16927516256294\n",
      "  time_since_restore: 6114.641233682632\n",
      "  time_this_iter_s: 23.122045755386353\n",
      "  time_total_s: 6114.641233682632\n",
      "  timestamp: 1553971885\n",
      "  timesteps_since_restore: 2580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 258\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6114 s, 258 iter, 2580000 ts, 844 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-51-48\n",
      "  done: false\n",
      "  episode_len_mean: 167.42\n",
      "  episode_reward_max: 1102.9940817839874\n",
      "  episode_reward_mean: 822.7390450708288\n",
      "  episode_reward_min: -49.28990126705983\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 15125\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.328\n",
      "    load_time_ms: 1.65\n",
      "    num_steps_sampled: 2590000\n",
      "    num_steps_trained: 2590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3480063676834106\n",
      "      kl: 0.03405742719769478\n",
      "      policy_loss: -0.0006693042232654989\n",
      "      total_loss: 1278.349365234375\n",
      "      vf_explained_var: 0.943251371383667\n",
      "      vf_loss: 1278.345947265625\n",
      "    sample_time_ms: 19452.783\n",
      "    update_time_ms: 5.177\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 411.36952253541426\n",
      "  time_since_restore: 6137.858303308487\n",
      "  time_this_iter_s: 23.217069625854492\n",
      "  time_total_s: 6137.858303308487\n",
      "  timestamp: 1553971908\n",
      "  timesteps_since_restore: 2590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2590000\n",
      "  training_iteration: 259\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6137 s, 259 iter, 2590000 ts, 823 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-52-12\n",
      "  done: false\n",
      "  episode_len_mean: 168.3\n",
      "  episode_reward_max: 1102.9940817839874\n",
      "  episode_reward_mean: 872.4502429066297\n",
      "  episode_reward_min: -49.28990126705983\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 15184\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.511\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 2600000\n",
      "    num_steps_trained: 2600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2783123254776\n",
      "      kl: 0.01634092442691326\n",
      "      policy_loss: 0.0023409135174006224\n",
      "      total_loss: 530.1536865234375\n",
      "      vf_explained_var: 0.9767683148384094\n",
      "      vf_loss: 530.1494140625\n",
      "    sample_time_ms: 19439.271\n",
      "    update_time_ms: 5.311\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 436.22512145331484\n",
      "  time_since_restore: 6161.629389047623\n",
      "  time_this_iter_s: 23.771085739135742\n",
      "  time_total_s: 6161.629389047623\n",
      "  timestamp: 1553971932\n",
      "  timesteps_since_restore: 2600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2600000\n",
      "  training_iteration: 260\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6161 s, 260 iter, 2600000 ts, 872 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-52-35\n",
      "  done: false\n",
      "  episode_len_mean: 171.48\n",
      "  episode_reward_max: 1102.7348330738432\n",
      "  episode_reward_mean: 907.6487654964496\n",
      "  episode_reward_min: -13.057847114736916\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 15243\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.939\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.424512267112732\n",
      "      kl: 0.01080330926924944\n",
      "      policy_loss: -0.0020236948039382696\n",
      "      total_loss: 661.6357421875\n",
      "      vf_explained_var: 0.9711278080940247\n",
      "      vf_loss: 661.6364135742188\n",
      "    sample_time_ms: 19384.768\n",
      "    update_time_ms: 5.424\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 453.8243827482248\n",
      "  time_since_restore: 6184.883980989456\n",
      "  time_this_iter_s: 23.254591941833496\n",
      "  time_total_s: 6184.883980989456\n",
      "  timestamp: 1553971955\n",
      "  timesteps_since_restore: 2610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 261\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6184 s, 261 iter, 2610000 ts, 908 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 179.17\n",
      "  episode_reward_max: 1102.7348330738432\n",
      "  episode_reward_mean: 916.1241368297707\n",
      "  episode_reward_min: -13.057847114736916\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 15297\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.892\n",
      "    load_time_ms: 1.664\n",
      "    num_steps_sampled: 2620000\n",
      "    num_steps_trained: 2620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4840797185897827\n",
      "      kl: 0.011495769023895264\n",
      "      policy_loss: 0.00014962084242142737\n",
      "      total_loss: 321.26739501953125\n",
      "      vf_explained_var: 0.9843840003013611\n",
      "      vf_loss: 321.26593017578125\n",
      "    sample_time_ms: 19390.931\n",
      "    update_time_ms: 5.678\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 458.06206841488546\n",
      "  time_since_restore: 6208.555356502533\n",
      "  time_this_iter_s: 23.671375513076782\n",
      "  time_total_s: 6208.555356502533\n",
      "  timestamp: 1553971979\n",
      "  timesteps_since_restore: 2620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2620000\n",
      "  training_iteration: 262\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6208 s, 262 iter, 2620000 ts, 916 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 176.55\n",
      "  episode_reward_max: 1091.7102611683606\n",
      "  episode_reward_mean: 874.8080779406796\n",
      "  episode_reward_min: -20.567921494288612\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 15356\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.148\n",
      "    load_time_ms: 1.671\n",
      "    num_steps_sampled: 2630000\n",
      "    num_steps_trained: 2630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.335007667541504\n",
      "      kl: 0.03450578823685646\n",
      "      policy_loss: 0.004001227207481861\n",
      "      total_loss: 1271.1949462890625\n",
      "      vf_explained_var: 0.9444249272346497\n",
      "      vf_loss: 1271.186767578125\n",
      "    sample_time_ms: 19352.486\n",
      "    update_time_ms: 5.669\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 437.40403897033974\n",
      "  time_since_restore: 6231.841728210449\n",
      "  time_this_iter_s: 23.28637170791626\n",
      "  time_total_s: 6231.841728210449\n",
      "  timestamp: 1553972002\n",
      "  timesteps_since_restore: 2630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2630000\n",
      "  training_iteration: 263\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6231 s, 263 iter, 2630000 ts, 875 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-53-45\n",
      "  done: false\n",
      "  episode_len_mean: 174.51\n",
      "  episode_reward_max: 1129.2833075244928\n",
      "  episode_reward_mean: 877.0723835900098\n",
      "  episode_reward_min: -23.496957738032677\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 15414\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.491\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3437981605529785\n",
      "      kl: 0.010727004148066044\n",
      "      policy_loss: -0.0007736006518825889\n",
      "      total_loss: 705.8556518554688\n",
      "      vf_explained_var: 0.9719439744949341\n",
      "      vf_loss: 705.8551635742188\n",
      "    sample_time_ms: 19344.544\n",
      "    update_time_ms: 5.651\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 438.5361917950049\n",
      "  time_since_restore: 6255.001544713974\n",
      "  time_this_iter_s: 23.15981650352478\n",
      "  time_total_s: 6255.001544713974\n",
      "  timestamp: 1553972025\n",
      "  timesteps_since_restore: 2640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 264\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6255 s, 264 iter, 2640000 ts, 877 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-54-08\n",
      "  done: false\n",
      "  episode_len_mean: 174.96\n",
      "  episode_reward_max: 1134.3759365497835\n",
      "  episode_reward_mean: 870.4983469295969\n",
      "  episode_reward_min: -23.496957738032677\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 15470\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.155\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 2650000\n",
      "    num_steps_trained: 2650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4881855249404907\n",
      "      kl: 0.015096278861165047\n",
      "      policy_loss: 0.0005773687735199928\n",
      "      total_loss: 802.9954223632812\n",
      "      vf_explained_var: 0.9645723104476929\n",
      "      vf_loss: 802.9930419921875\n",
      "    sample_time_ms: 19401.147\n",
      "    update_time_ms: 5.834\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 435.24917346479845\n",
      "  time_since_restore: 6277.997839689255\n",
      "  time_this_iter_s: 22.99629497528076\n",
      "  time_total_s: 6277.997839689255\n",
      "  timestamp: 1553972048\n",
      "  timesteps_since_restore: 2650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2650000\n",
      "  training_iteration: 265\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6277 s, 265 iter, 2650000 ts, 870 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-54-32\n",
      "  done: false\n",
      "  episode_len_mean: 180.35\n",
      "  episode_reward_max: 1134.3759365497835\n",
      "  episode_reward_mean: 920.3686928559741\n",
      "  episode_reward_min: -51.96295969903505\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 15525\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.668\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 2660000\n",
      "    num_steps_trained: 2660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4541738033294678\n",
      "      kl: 0.015737885609269142\n",
      "      policy_loss: -0.005193860270082951\n",
      "      total_loss: 1051.7291259765625\n",
      "      vf_explained_var: 0.9551632404327393\n",
      "      vf_loss: 1051.732421875\n",
      "    sample_time_ms: 19448.946\n",
      "    update_time_ms: 5.667\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 460.18434642798707\n",
      "  time_since_restore: 6301.93296122551\n",
      "  time_this_iter_s: 23.935121536254883\n",
      "  time_total_s: 6301.93296122551\n",
      "  timestamp: 1553972072\n",
      "  timesteps_since_restore: 2660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2660000\n",
      "  training_iteration: 266\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6301 s, 266 iter, 2660000 ts, 920 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-54-57\n",
      "  done: false\n",
      "  episode_len_mean: 173.18\n",
      "  episode_reward_max: 1086.466964474931\n",
      "  episode_reward_mean: 839.650951985072\n",
      "  episode_reward_min: -89.5183432707315\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 15583\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.248\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4445881843566895\n",
      "      kl: 0.014454033225774765\n",
      "      policy_loss: -0.002693616785109043\n",
      "      total_loss: 1321.8719482421875\n",
      "      vf_explained_var: 0.9487457275390625\n",
      "      vf_loss: 1321.873046875\n",
      "    sample_time_ms: 19531.318\n",
      "    update_time_ms: 5.791\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 419.8254759925359\n",
      "  time_since_restore: 6325.934720754623\n",
      "  time_this_iter_s: 24.00175952911377\n",
      "  time_total_s: 6325.934720754623\n",
      "  timestamp: 1553972097\n",
      "  timesteps_since_restore: 2670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 267\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6325 s, 267 iter, 2670000 ts, 840 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 177.66\n",
      "  episode_reward_max: 1103.0964351404232\n",
      "  episode_reward_mean: 849.211299604092\n",
      "  episode_reward_min: -89.5183432707315\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 15638\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.909\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 2680000\n",
      "    num_steps_trained: 2680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.398054838180542\n",
      "      kl: 0.01373316254466772\n",
      "      policy_loss: 0.000121879274956882\n",
      "      total_loss: 728.2546997070312\n",
      "      vf_explained_var: 0.9643382430076599\n",
      "      vf_loss: 728.2529296875\n",
      "    sample_time_ms: 19568.773\n",
      "    update_time_ms: 5.833\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 424.60564980204595\n",
      "  time_since_restore: 6349.358825683594\n",
      "  time_this_iter_s: 23.424104928970337\n",
      "  time_total_s: 6349.358825683594\n",
      "  timestamp: 1553972120\n",
      "  timesteps_since_restore: 2680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2680000\n",
      "  training_iteration: 268\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6349 s, 268 iter, 2680000 ts, 849 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 176.78\n",
      "  episode_reward_max: 1103.0964351404232\n",
      "  episode_reward_mean: 881.9044839083259\n",
      "  episode_reward_min: -83.41497417862166\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 15696\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.662\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 2690000\n",
      "    num_steps_trained: 2690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3933887481689453\n",
      "      kl: 0.013353848829865456\n",
      "      policy_loss: -0.001729420037008822\n",
      "      total_loss: 822.4976196289062\n",
      "      vf_explained_var: 0.964044451713562\n",
      "      vf_loss: 822.4977416992188\n",
      "    sample_time_ms: 19560.217\n",
      "    update_time_ms: 5.905\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 440.952241954163\n",
      "  time_since_restore: 6372.50679898262\n",
      "  time_this_iter_s: 23.14797329902649\n",
      "  time_total_s: 6372.50679898262\n",
      "  timestamp: 1553972143\n",
      "  timesteps_since_restore: 2690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2690000\n",
      "  training_iteration: 269\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6372 s, 269 iter, 2690000 ts, 882 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-56-06\n",
      "  done: false\n",
      "  episode_len_mean: 163.8\n",
      "  episode_reward_max: 1110.6819773487177\n",
      "  episode_reward_mean: 828.7744163045428\n",
      "  episode_reward_min: -83.41497417862166\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 15760\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.87\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.233353853225708\n",
      "      kl: 0.021266456693410873\n",
      "      policy_loss: -0.00587339187040925\n",
      "      total_loss: 1187.76708984375\n",
      "      vf_explained_var: 0.9566842317581177\n",
      "      vf_loss: 1187.7703857421875\n",
      "    sample_time_ms: 19495.816\n",
      "    update_time_ms: 5.858\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 414.38720815227134\n",
      "  time_since_restore: 6395.66921210289\n",
      "  time_this_iter_s: 23.162413120269775\n",
      "  time_total_s: 6395.66921210289\n",
      "  timestamp: 1553972166\n",
      "  timesteps_since_restore: 2700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 270\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6395 s, 270 iter, 2700000 ts, 829 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-56-30\n",
      "  done: false\n",
      "  episode_len_mean: 162.71\n",
      "  episode_reward_max: 1127.5654772963378\n",
      "  episode_reward_mean: 864.6002433368147\n",
      "  episode_reward_min: -77.32897905785148\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 15821\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.043\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 2710000\n",
      "    num_steps_trained: 2710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2488857507705688\n",
      "      kl: 0.01138626504689455\n",
      "      policy_loss: -0.0012135845609009266\n",
      "      total_loss: 879.0821533203125\n",
      "      vf_explained_var: 0.961883544921875\n",
      "      vf_loss: 879.0819091796875\n",
      "    sample_time_ms: 19532.58\n",
      "    update_time_ms: 5.751\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 432.3001216684074\n",
      "  time_since_restore: 6419.252707719803\n",
      "  time_this_iter_s: 23.583495616912842\n",
      "  time_total_s: 6419.252707719803\n",
      "  timestamp: 1553972190\n",
      "  timesteps_since_restore: 2710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2710000\n",
      "  training_iteration: 271\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6419 s, 271 iter, 2710000 ts, 865 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-56-53\n",
      "  done: false\n",
      "  episode_len_mean: 165.55\n",
      "  episode_reward_max: 1146.2771494516592\n",
      "  episode_reward_mean: 859.4914840096957\n",
      "  episode_reward_min: -74.67645261158347\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15881\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.537\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 2720000\n",
      "    num_steps_trained: 2720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.306462049484253\n",
      "      kl: 0.014603097923099995\n",
      "      policy_loss: -0.0026035462506115437\n",
      "      total_loss: 1120.0985107421875\n",
      "      vf_explained_var: 0.9506071209907532\n",
      "      vf_loss: 1120.099609375\n",
      "    sample_time_ms: 19499.594\n",
      "    update_time_ms: 5.609\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 429.7457420048477\n",
      "  time_since_restore: 6442.612366914749\n",
      "  time_this_iter_s: 23.35965919494629\n",
      "  time_total_s: 6442.612366914749\n",
      "  timestamp: 1553972213\n",
      "  timesteps_since_restore: 2720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2720000\n",
      "  training_iteration: 272\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6442 s, 272 iter, 2720000 ts, 859 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-57-17\n",
      "  done: false\n",
      "  episode_len_mean: 172.63\n",
      "  episode_reward_max: 1146.2771494516592\n",
      "  episode_reward_mean: 856.1868694364063\n",
      "  episode_reward_min: -58.87150667902702\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 15938\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.877\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3781179189682007\n",
      "      kl: 0.012773983180522919\n",
      "      policy_loss: -0.00024550847592763603\n",
      "      total_loss: 1131.482421875\n",
      "      vf_explained_var: 0.9505276679992676\n",
      "      vf_loss: 1131.4810791015625\n",
      "    sample_time_ms: 19538.58\n",
      "    update_time_ms: 5.57\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 428.0934347182032\n",
      "  time_since_restore: 6466.29136633873\n",
      "  time_this_iter_s: 23.678999423980713\n",
      "  time_total_s: 6466.29136633873\n",
      "  timestamp: 1553972237\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 273\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6466 s, 273 iter, 2730000 ts, 856 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-57-41\n",
      "  done: false\n",
      "  episode_len_mean: 169.32\n",
      "  episode_reward_max: 1081.3095702387943\n",
      "  episode_reward_mean: 829.67828777972\n",
      "  episode_reward_min: -76.79317899939593\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 15996\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.641\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 2740000\n",
      "    num_steps_trained: 2740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11901451647281647\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3885740041732788\n",
      "      kl: 0.009974404238164425\n",
      "      policy_loss: -0.0005731116398237646\n",
      "      total_loss: 1075.8699951171875\n",
      "      vf_explained_var: 0.9525586366653442\n",
      "      vf_loss: 1075.869384765625\n",
      "    sample_time_ms: 19579.848\n",
      "    update_time_ms: 5.499\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 414.83914388986\n",
      "  time_since_restore: 6489.96063375473\n",
      "  time_this_iter_s: 23.669267416000366\n",
      "  time_total_s: 6489.96063375473\n",
      "  timestamp: 1553972261\n",
      "  timesteps_since_restore: 2740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2740000\n",
      "  training_iteration: 274\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6489 s, 274 iter, 2740000 ts, 830 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-58-04\n",
      "  done: false\n",
      "  episode_len_mean: 172.99\n",
      "  episode_reward_max: 1090.983300667671\n",
      "  episode_reward_mean: 889.8971041139905\n",
      "  episode_reward_min: -76.79317899939593\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 16053\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.579\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 2750000\n",
      "    num_steps_trained: 2750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.40337073802948\n",
      "      kl: 0.013911082409322262\n",
      "      policy_loss: -4.7931876906659454e-05\n",
      "      total_loss: 584.1410522460938\n",
      "      vf_explained_var: 0.9712815880775452\n",
      "      vf_loss: 584.1403198242188\n",
      "    sample_time_ms: 19619.363\n",
      "    update_time_ms: 5.391\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 444.9485520569953\n",
      "  time_since_restore: 6513.203240871429\n",
      "  time_this_iter_s: 23.24260711669922\n",
      "  time_total_s: 6513.203240871429\n",
      "  timestamp: 1553972284\n",
      "  timesteps_since_restore: 2750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2750000\n",
      "  training_iteration: 275\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6513 s, 275 iter, 2750000 ts, 890 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-58-28\n",
      "  done: false\n",
      "  episode_len_mean: 180.53\n",
      "  episode_reward_max: 1090.983300667671\n",
      "  episode_reward_mean: 872.0504326360352\n",
      "  episode_reward_min: -89.51803002381114\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 16108\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.077\n",
      "    load_time_ms: 1.447\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6041197776794434\n",
      "      kl: 0.013224149122834206\n",
      "      policy_loss: -0.003690514015033841\n",
      "      total_loss: 1395.5618896484375\n",
      "      vf_explained_var: 0.9361191987991333\n",
      "      vf_loss: 1395.564697265625\n",
      "    sample_time_ms: 19580.876\n",
      "    update_time_ms: 5.33\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 436.0252163180176\n",
      "  time_since_restore: 6536.837951183319\n",
      "  time_this_iter_s: 23.63471031188965\n",
      "  time_total_s: 6536.837951183319\n",
      "  timestamp: 1553972308\n",
      "  timesteps_since_restore: 2760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 276\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6536 s, 276 iter, 2760000 ts, 872 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-58-52\n",
      "  done: false\n",
      "  episode_len_mean: 180.8\n",
      "  episode_reward_max: 1134.8462311448966\n",
      "  episode_reward_mean: 875.830248246976\n",
      "  episode_reward_min: -89.51803002381114\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 16162\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.05\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 2770000\n",
      "    num_steps_trained: 2770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4091510772705078\n",
      "      kl: 0.01318281702697277\n",
      "      policy_loss: -0.0009490300435572863\n",
      "      total_loss: 464.6169738769531\n",
      "      vf_explained_var: 0.9791642427444458\n",
      "      vf_loss: 464.6171875\n",
      "    sample_time_ms: 19554.512\n",
      "    update_time_ms: 5.11\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 437.91512412348806\n",
      "  time_since_restore: 6560.575099468231\n",
      "  time_this_iter_s: 23.73714828491211\n",
      "  time_total_s: 6560.575099468231\n",
      "  timestamp: 1553972332\n",
      "  timesteps_since_restore: 2770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2770000\n",
      "  training_iteration: 277\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6560 s, 277 iter, 2770000 ts, 876 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-59-15\n",
      "  done: false\n",
      "  episode_len_mean: 172.18\n",
      "  episode_reward_max: 1134.8462311448966\n",
      "  episode_reward_mean: 911.5388921673484\n",
      "  episode_reward_min: 7.315801895724263\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 16223\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.174\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 2780000\n",
      "    num_steps_trained: 2780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3038238286972046\n",
      "      kl: 0.02125563658773899\n",
      "      policy_loss: 0.00018564362835604697\n",
      "      total_loss: 1002.2105102539062\n",
      "      vf_explained_var: 0.9557201862335205\n",
      "      vf_loss: 1002.2091064453125\n",
      "    sample_time_ms: 19594.487\n",
      "    update_time_ms: 5.031\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 455.7694460836742\n",
      "  time_since_restore: 6584.469676971436\n",
      "  time_this_iter_s: 23.894577503204346\n",
      "  time_total_s: 6584.469676971436\n",
      "  timestamp: 1553972355\n",
      "  timesteps_since_restore: 2780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2780000\n",
      "  training_iteration: 278\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6584 s, 278 iter, 2780000 ts, 912 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_19-59-39\n",
      "  done: false\n",
      "  episode_len_mean: 164.15\n",
      "  episode_reward_max: 1110.476481191911\n",
      "  episode_reward_mean: 862.4682943292536\n",
      "  episode_reward_min: -79.24674754380607\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 16284\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.69\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3454077243804932\n",
      "      kl: 0.027794700115919113\n",
      "      policy_loss: 0.0034412050154060125\n",
      "      total_loss: 647.4155883789062\n",
      "      vf_explained_var: 0.9731216430664062\n",
      "      vf_loss: 647.4105834960938\n",
      "    sample_time_ms: 19620.657\n",
      "    update_time_ms: 4.948\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 431.2341471646268\n",
      "  time_since_restore: 6608.041872501373\n",
      "  time_this_iter_s: 23.572195529937744\n",
      "  time_total_s: 6608.041872501373\n",
      "  timestamp: 1553972379\n",
      "  timesteps_since_restore: 2790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 279\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6608 s, 279 iter, 2790000 ts, 862 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 166.31\n",
      "  episode_reward_max: 1110.476481191911\n",
      "  episode_reward_mean: 832.6700783636605\n",
      "  episode_reward_min: -90.25007992795251\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16344\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.89\n",
      "    load_time_ms: 1.428\n",
      "    num_steps_sampled: 2800000\n",
      "    num_steps_trained: 2800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3264408111572266\n",
      "      kl: 0.014008674770593643\n",
      "      policy_loss: 0.0006344830617308617\n",
      "      total_loss: 1991.403076171875\n",
      "      vf_explained_var: 0.9157192707061768\n",
      "      vf_loss: 1991.401611328125\n",
      "    sample_time_ms: 19619.466\n",
      "    update_time_ms: 4.91\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 416.3350391818302\n",
      "  time_since_restore: 6631.1550850868225\n",
      "  time_this_iter_s: 23.11321258544922\n",
      "  time_total_s: 6631.1550850868225\n",
      "  timestamp: 1553972402\n",
      "  timesteps_since_restore: 2800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2800000\n",
      "  training_iteration: 280\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6631 s, 280 iter, 2800000 ts, 833 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-00-25\n",
      "  done: false\n",
      "  episode_len_mean: 167.55\n",
      "  episode_reward_max: 1150.416234154173\n",
      "  episode_reward_mean: 843.4244384863362\n",
      "  episode_reward_min: -62.36821838389827\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16404\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.818\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 2810000\n",
      "    num_steps_trained: 2810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3340113162994385\n",
      "      kl: 0.01657634787261486\n",
      "      policy_loss: -0.0027909805066883564\n",
      "      total_loss: 1164.789306640625\n",
      "      vf_explained_var: 0.9482464790344238\n",
      "      vf_loss: 1164.791015625\n",
      "    sample_time_ms: 19497.24\n",
      "    update_time_ms: 4.749\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 421.7122192431681\n",
      "  time_since_restore: 6653.525657653809\n",
      "  time_this_iter_s: 22.370572566986084\n",
      "  time_total_s: 6653.525657653809\n",
      "  timestamp: 1553972425\n",
      "  timesteps_since_restore: 2810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2810000\n",
      "  training_iteration: 281\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6653 s, 281 iter, 2810000 ts, 843 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-00-48\n",
      "  done: false\n",
      "  episode_len_mean: 169.58\n",
      "  episode_reward_max: 1122.6033795467026\n",
      "  episode_reward_mean: 872.905420640723\n",
      "  episode_reward_min: -49.04824488219512\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16464\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.031\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2443640232086182\n",
      "      kl: 0.034095875918865204\n",
      "      policy_loss: -0.00445952732115984\n",
      "      total_loss: 808.5750122070312\n",
      "      vf_explained_var: 0.9647967219352722\n",
      "      vf_loss: 808.5775146484375\n",
      "    sample_time_ms: 19482.371\n",
      "    update_time_ms: 4.755\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 436.45271032036146\n",
      "  time_since_restore: 6676.712215662003\n",
      "  time_this_iter_s: 23.18655800819397\n",
      "  time_total_s: 6676.712215662003\n",
      "  timestamp: 1553972448\n",
      "  timesteps_since_restore: 2820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 282\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6676 s, 282 iter, 2820000 ts, 873 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-01-12\n",
      "  done: false\n",
      "  episode_len_mean: 167.25\n",
      "  episode_reward_max: 1122.6033795467026\n",
      "  episode_reward_mean: 842.3351249486223\n",
      "  episode_reward_min: -51.908233193430505\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 16522\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.565\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 2830000\n",
      "    num_steps_trained: 2830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3362423181533813\n",
      "      kl: 0.01763978600502014\n",
      "      policy_loss: 4.94664091093e-05\n",
      "      total_loss: 1492.910888671875\n",
      "      vf_explained_var: 0.9314888119697571\n",
      "      vf_loss: 1492.90966796875\n",
      "    sample_time_ms: 19482.347\n",
      "    update_time_ms: 4.765\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 421.1675624743113\n",
      "  time_since_restore: 6700.377473115921\n",
      "  time_this_iter_s: 23.665257453918457\n",
      "  time_total_s: 6700.377473115921\n",
      "  timestamp: 1553972472\n",
      "  timesteps_since_restore: 2830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2830000\n",
      "  training_iteration: 283\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6700 s, 283 iter, 2830000 ts, 842 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-01-35\n",
      "  done: false\n",
      "  episode_len_mean: 168.39\n",
      "  episode_reward_max: 1115.4724787601167\n",
      "  episode_reward_mean: 840.0614617304041\n",
      "  episode_reward_min: -105.51896318516407\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16582\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.302\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 2840000\n",
      "    num_steps_trained: 2840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.059507258236408234\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3613897562026978\n",
      "      kl: 0.046094704419374466\n",
      "      policy_loss: 0.0014492227928712964\n",
      "      total_loss: 1139.406494140625\n",
      "      vf_explained_var: 0.9513623118400574\n",
      "      vf_loss: 1139.4022216796875\n",
      "    sample_time_ms: 19463.64\n",
      "    update_time_ms: 4.985\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 420.03073086520203\n",
      "  time_since_restore: 6723.798167467117\n",
      "  time_this_iter_s: 23.42069435119629\n",
      "  time_total_s: 6723.798167467117\n",
      "  timestamp: 1553972495\n",
      "  timesteps_since_restore: 2840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2840000\n",
      "  training_iteration: 284\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6723 s, 284 iter, 2840000 ts, 840 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-01-58\n",
      "  done: false\n",
      "  episode_len_mean: 168.1\n",
      "  episode_reward_max: 1115.4724787601167\n",
      "  episode_reward_mean: 862.8616401190628\n",
      "  episode_reward_min: -86.57626737375854\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 16641\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.904\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2463982105255127\n",
      "      kl: 0.012308136560022831\n",
      "      policy_loss: -0.001426463364623487\n",
      "      total_loss: 727.7142333984375\n",
      "      vf_explained_var: 0.9691119194030762\n",
      "      vf_loss: 727.714599609375\n",
      "    sample_time_ms: 19401.161\n",
      "    update_time_ms: 5.01\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 431.4308200595314\n",
      "  time_since_restore: 6746.41300535202\n",
      "  time_this_iter_s: 22.614837884902954\n",
      "  time_total_s: 6746.41300535202\n",
      "  timestamp: 1553972518\n",
      "  timesteps_since_restore: 2850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 285\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6746 s, 285 iter, 2850000 ts, 863 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-02-21\n",
      "  done: false\n",
      "  episode_len_mean: 170.69\n",
      "  episode_reward_max: 1106.859463937057\n",
      "  episode_reward_mean: 875.5456660857161\n",
      "  episode_reward_min: -86.57626737375854\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 16700\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.078\n",
      "    load_time_ms: 1.663\n",
      "    num_steps_sampled: 2860000\n",
      "    num_steps_trained: 2860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4341561794281006\n",
      "      kl: 0.019071059301495552\n",
      "      policy_loss: -0.002226315438747406\n",
      "      total_loss: 749.555908203125\n",
      "      vf_explained_var: 0.9666429162025452\n",
      "      vf_loss: 749.556396484375\n",
      "    sample_time_ms: 19404.181\n",
      "    update_time_ms: 5.044\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 437.77283304285794\n",
      "  time_since_restore: 6770.000296592712\n",
      "  time_this_iter_s: 23.58729124069214\n",
      "  time_total_s: 6770.000296592712\n",
      "  timestamp: 1553972541\n",
      "  timesteps_since_restore: 2860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2860000\n",
      "  training_iteration: 286\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6770 s, 286 iter, 2860000 ts, 876 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-02-45\n",
      "  done: false\n",
      "  episode_len_mean: 167.25\n",
      "  episode_reward_max: 1085.23791575351\n",
      "  episode_reward_mean: 856.6781975663378\n",
      "  episode_reward_min: -70.87436773366878\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 16759\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.779\n",
      "    load_time_ms: 1.642\n",
      "    num_steps_sampled: 2870000\n",
      "    num_steps_trained: 2870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3107280731201172\n",
      "      kl: 0.014352269470691681\n",
      "      policy_loss: -0.001939453766681254\n",
      "      total_loss: 1251.654052734375\n",
      "      vf_explained_var: 0.9459484815597534\n",
      "      vf_loss: 1251.6546630859375\n",
      "    sample_time_ms: 19366.986\n",
      "    update_time_ms: 5.113\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 428.3390987831688\n",
      "  time_since_restore: 6793.3329083919525\n",
      "  time_this_iter_s: 23.332611799240112\n",
      "  time_total_s: 6793.3329083919525\n",
      "  timestamp: 1553972565\n",
      "  timesteps_since_restore: 2870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2870000\n",
      "  training_iteration: 287\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6793 s, 287 iter, 2870000 ts, 857 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-03-08\n",
      "  done: false\n",
      "  episode_len_mean: 166.87\n",
      "  episode_reward_max: 1114.5149695153752\n",
      "  episode_reward_mean: 868.1599771077267\n",
      "  episode_reward_min: -70.87436773366878\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16819\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.54\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08926088362932205\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2142226696014404\n",
      "      kl: 0.008940489031374454\n",
      "      policy_loss: -0.0010777156567201018\n",
      "      total_loss: 954.4434814453125\n",
      "      vf_explained_var: 0.9573750495910645\n",
      "      vf_loss: 954.4437866210938\n",
      "    sample_time_ms: 19341.36\n",
      "    update_time_ms: 5.024\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 434.07998855386336\n",
      "  time_since_restore: 6817.066684007645\n",
      "  time_this_iter_s: 23.73377561569214\n",
      "  time_total_s: 6817.066684007645\n",
      "  timestamp: 1553972588\n",
      "  timesteps_since_restore: 2880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 288\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6817 s, 288 iter, 2880000 ts, 868 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-03-33\n",
      "  done: false\n",
      "  episode_len_mean: 161.69\n",
      "  episode_reward_max: 1138.1532474962398\n",
      "  episode_reward_mean: 832.9169109128474\n",
      "  episode_reward_min: -72.72474008792794\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 16880\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.925\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 2890000\n",
      "    num_steps_trained: 2890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2723629474639893\n",
      "      kl: 0.013323921710252762\n",
      "      policy_loss: 0.0011610809015110135\n",
      "      total_loss: 1185.8345947265625\n",
      "      vf_explained_var: 0.9524633884429932\n",
      "      vf_loss: 1185.832763671875\n",
      "    sample_time_ms: 19427.112\n",
      "    update_time_ms: 5.107\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 416.4584554564237\n",
      "  time_since_restore: 6841.3932094573975\n",
      "  time_this_iter_s: 24.326525449752808\n",
      "  time_total_s: 6841.3932094573975\n",
      "  timestamp: 1553972613\n",
      "  timesteps_since_restore: 2890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2890000\n",
      "  training_iteration: 289\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6841 s, 289 iter, 2890000 ts, 833 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-03-57\n",
      "  done: false\n",
      "  episode_len_mean: 170.69\n",
      "  episode_reward_max: 1078.26016055407\n",
      "  episode_reward_mean: 859.7264978075734\n",
      "  episode_reward_min: -34.877498572862805\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 16935\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.021\n",
      "    load_time_ms: 1.73\n",
      "    num_steps_sampled: 2900000\n",
      "    num_steps_trained: 2900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3294309377670288\n",
      "      kl: 0.015063964761793613\n",
      "      policy_loss: -0.0006663737003691494\n",
      "      total_loss: 481.97296142578125\n",
      "      vf_explained_var: 0.9785906672477722\n",
      "      vf_loss: 481.97296142578125\n",
      "    sample_time_ms: 19547.024\n",
      "    update_time_ms: 5.189\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 429.8632489037867\n",
      "  time_since_restore: 6865.80385684967\n",
      "  time_this_iter_s: 24.41064739227295\n",
      "  time_total_s: 6865.80385684967\n",
      "  timestamp: 1553972637\n",
      "  timesteps_since_restore: 2900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2900000\n",
      "  training_iteration: 290\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6865 s, 290 iter, 2900000 ts, 860 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 168.87\n",
      "  episode_reward_max: 1132.0282397665464\n",
      "  episode_reward_mean: 893.0284705933882\n",
      "  episode_reward_min: -51.36182007617427\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 16996\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.66\n",
      "    load_time_ms: 1.689\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2109750509262085\n",
      "      kl: 0.023629628121852875\n",
      "      policy_loss: -0.0029810608830302954\n",
      "      total_loss: 709.8713989257812\n",
      "      vf_explained_var: 0.9700929522514343\n",
      "      vf_loss: 709.873291015625\n",
      "    sample_time_ms: 19739.314\n",
      "    update_time_ms: 5.372\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 446.5142352966941\n",
      "  time_since_restore: 6890.082697153091\n",
      "  time_this_iter_s: 24.27884030342102\n",
      "  time_total_s: 6890.082697153091\n",
      "  timestamp: 1553972662\n",
      "  timesteps_since_restore: 2910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 291\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6890 s, 291 iter, 2910000 ts, 893 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-04-45\n",
      "  done: false\n",
      "  episode_len_mean: 168.77\n",
      "  episode_reward_max: 1132.0282397665464\n",
      "  episode_reward_mean: 848.5124658518223\n",
      "  episode_reward_min: -59.47082972980701\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 17054\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.097\n",
      "    load_time_ms: 1.624\n",
      "    num_steps_sampled: 2920000\n",
      "    num_steps_trained: 2920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3648654222488403\n",
      "      kl: 0.02486621029675007\n",
      "      policy_loss: -0.006400773301720619\n",
      "      total_loss: 1185.8018798828125\n",
      "      vf_explained_var: 0.9489173889160156\n",
      "      vf_loss: 1185.8072509765625\n",
      "    sample_time_ms: 19793.121\n",
      "    update_time_ms: 5.23\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 424.25623292591126\n",
      "  time_since_restore: 6913.837458848953\n",
      "  time_this_iter_s: 23.754761695861816\n",
      "  time_total_s: 6913.837458848953\n",
      "  timestamp: 1553972685\n",
      "  timesteps_since_restore: 2920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2920000\n",
      "  training_iteration: 292\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6913 s, 292 iter, 2920000 ts, 849 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-05-09\n",
      "  done: false\n",
      "  episode_len_mean: 164.43\n",
      "  episode_reward_max: 1114.5061221040403\n",
      "  episode_reward_mean: 799.6955265193933\n",
      "  episode_reward_min: -98.53154693520796\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17114\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.73\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 2930000\n",
      "    num_steps_trained: 2930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3382737636566162\n",
      "      kl: 0.014627323485910892\n",
      "      policy_loss: -0.0009503064793534577\n",
      "      total_loss: 1238.15966796875\n",
      "      vf_explained_var: 0.954737663269043\n",
      "      vf_loss: 1238.1600341796875\n",
      "    sample_time_ms: 19727.028\n",
      "    update_time_ms: 5.281\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 399.84776325969665\n",
      "  time_since_restore: 6936.937711238861\n",
      "  time_this_iter_s: 23.100252389907837\n",
      "  time_total_s: 6936.937711238861\n",
      "  timestamp: 1553972709\n",
      "  timesteps_since_restore: 2930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2930000\n",
      "  training_iteration: 293\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6936 s, 293 iter, 2930000 ts, 800 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-05-32\n",
      "  done: false\n",
      "  episode_len_mean: 161.58\n",
      "  episode_reward_max: 1154.2430055622885\n",
      "  episode_reward_mean: 845.3621474020158\n",
      "  episode_reward_min: -98.53154693520796\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17174\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.33\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2309634685516357\n",
      "      kl: 0.015162617899477482\n",
      "      policy_loss: -0.0009003995801322162\n",
      "      total_loss: 821.3040161132812\n",
      "      vf_explained_var: 0.9676977396011353\n",
      "      vf_loss: 821.3043823242188\n",
      "    sample_time_ms: 19744.432\n",
      "    update_time_ms: 5.202\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 422.681073701008\n",
      "  time_since_restore: 6960.521879196167\n",
      "  time_this_iter_s: 23.584167957305908\n",
      "  time_total_s: 6960.521879196167\n",
      "  timestamp: 1553972732\n",
      "  timesteps_since_restore: 2940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 294\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6960 s, 294 iter, 2940000 ts, 845 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-05-55\n",
      "  done: false\n",
      "  episode_len_mean: 175.2\n",
      "  episode_reward_max: 1154.2430055622885\n",
      "  episode_reward_mean: 908.0266854695278\n",
      "  episode_reward_min: -99.36231114480711\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 17230\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.816\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 2950000\n",
      "    num_steps_trained: 2950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3940832614898682\n",
      "      kl: 0.018462546169757843\n",
      "      policy_loss: -0.0007844460196793079\n",
      "      total_loss: 494.853759765625\n",
      "      vf_explained_var: 0.9785680770874023\n",
      "      vf_loss: 494.8537292480469\n",
      "    sample_time_ms: 19743.286\n",
      "    update_time_ms: 5.071\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 454.01334273476385\n",
      "  time_since_restore: 6983.165883302689\n",
      "  time_this_iter_s: 22.644004106521606\n",
      "  time_total_s: 6983.165883302689\n",
      "  timestamp: 1553972755\n",
      "  timesteps_since_restore: 2950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2950000\n",
      "  training_iteration: 295\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 6983 s, 295 iter, 2950000 ts, 908 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-06-18\n",
      "  done: false\n",
      "  episode_len_mean: 182.04\n",
      "  episode_reward_max: 1117.068789082974\n",
      "  episode_reward_mean: 903.840902703468\n",
      "  episode_reward_min: -99.36231114480711\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 17285\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.705\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 2960000\n",
      "    num_steps_trained: 2960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4566413164138794\n",
      "      kl: 0.019434258341789246\n",
      "      policy_loss: -0.0029889626894146204\n",
      "      total_loss: 686.1776123046875\n",
      "      vf_explained_var: 0.9682024717330933\n",
      "      vf_loss: 686.1798095703125\n",
      "    sample_time_ms: 19688.895\n",
      "    update_time_ms: 5.037\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 451.9204513517341\n",
      "  time_since_restore: 7006.216993570328\n",
      "  time_this_iter_s: 23.05111026763916\n",
      "  time_total_s: 7006.216993570328\n",
      "  timestamp: 1553972778\n",
      "  timesteps_since_restore: 2960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2960000\n",
      "  training_iteration: 296\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7006 s, 296 iter, 2960000 ts, 904 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-06-41\n",
      "  done: false\n",
      "  episode_len_mean: 181.62\n",
      "  episode_reward_max: 1117.068789082974\n",
      "  episode_reward_mean: 889.7644720867709\n",
      "  episode_reward_min: -74.72008282010142\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 17339\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.413\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5815905332565308\n",
      "      kl: 0.017175432294607162\n",
      "      policy_loss: -0.0026892339810729027\n",
      "      total_loss: 549.0551147460938\n",
      "      vf_explained_var: 0.9751713275909424\n",
      "      vf_loss: 549.0570068359375\n",
      "    sample_time_ms: 19652.606\n",
      "    update_time_ms: 5.039\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 444.8822360433853\n",
      "  time_since_restore: 7029.272218704224\n",
      "  time_this_iter_s: 23.055225133895874\n",
      "  time_total_s: 7029.272218704224\n",
      "  timestamp: 1553972801\n",
      "  timesteps_since_restore: 2970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 297\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7029 s, 297 iter, 2970000 ts, 890 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-07-04\n",
      "  done: false\n",
      "  episode_len_mean: 172.52\n",
      "  episode_reward_max: 1081.9758129880236\n",
      "  episode_reward_mean: 879.3188352661189\n",
      "  episode_reward_min: -50.4103876221061\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 17397\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.096\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 2980000\n",
      "    num_steps_trained: 2980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3498977422714233\n",
      "      kl: 0.019244734197854996\n",
      "      policy_loss: 0.0013262713328003883\n",
      "      total_loss: 1138.7313232421875\n",
      "      vf_explained_var: 0.9497504830360413\n",
      "      vf_loss: 1138.7291259765625\n",
      "    sample_time_ms: 19615.277\n",
      "    update_time_ms: 5.103\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 439.6594176330593\n",
      "  time_since_restore: 7052.537906169891\n",
      "  time_this_iter_s: 23.265687465667725\n",
      "  time_total_s: 7052.537906169891\n",
      "  timestamp: 1553972824\n",
      "  timesteps_since_restore: 2980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2980000\n",
      "  training_iteration: 298\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7052 s, 298 iter, 2980000 ts, 879 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-07-27\n",
      "  done: false\n",
      "  episode_len_mean: 168.52\n",
      "  episode_reward_max: 1079.6036857694742\n",
      "  episode_reward_mean: 876.0170752438273\n",
      "  episode_reward_min: -66.37971360429955\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 17456\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.578\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 2990000\n",
      "    num_steps_trained: 2990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3022524118423462\n",
      "      kl: 0.022680066525936127\n",
      "      policy_loss: -0.002105716150254011\n",
      "      total_loss: 1427.498779296875\n",
      "      vf_explained_var: 0.9385438561439514\n",
      "      vf_loss: 1427.499755859375\n",
      "    sample_time_ms: 19493.454\n",
      "    update_time_ms: 5.184\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 438.00853762191366\n",
      "  time_since_restore: 7075.611257076263\n",
      "  time_this_iter_s: 23.07335090637207\n",
      "  time_total_s: 7075.611257076263\n",
      "  timestamp: 1553972847\n",
      "  timesteps_since_restore: 2990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2990000\n",
      "  training_iteration: 299\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7075 s, 299 iter, 2990000 ts, 876 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-07-51\n",
      "  done: false\n",
      "  episode_len_mean: 176.51\n",
      "  episode_reward_max: 1099.764773741204\n",
      "  episode_reward_mean: 837.4855635058685\n",
      "  episode_reward_min: -74.16173913801396\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 17510\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.78\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.645684838294983\n",
      "      kl: 0.01041769701987505\n",
      "      policy_loss: -0.003236565738916397\n",
      "      total_loss: 1320.2430419921875\n",
      "      vf_explained_var: 0.9432415962219238\n",
      "      vf_loss: 1320.2457275390625\n",
      "    sample_time_ms: 19402.384\n",
      "    update_time_ms: 5.275\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 418.7427817529341\n",
      "  time_since_restore: 7099.014372587204\n",
      "  time_this_iter_s: 23.40311551094055\n",
      "  time_total_s: 7099.014372587204\n",
      "  timestamp: 1553972871\n",
      "  timesteps_since_restore: 3000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 300\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7099 s, 300 iter, 3000000 ts, 837 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-08-14\n",
      "  done: false\n",
      "  episode_len_mean: 167.43\n",
      "  episode_reward_max: 1118.116401777187\n",
      "  episode_reward_mean: 856.147563094981\n",
      "  episode_reward_min: -77.67201646814594\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 17575\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.233\n",
      "    load_time_ms: 1.447\n",
      "    num_steps_sampled: 3010000\n",
      "    num_steps_trained: 3010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1840382814407349\n",
      "      kl: 0.019490033388137817\n",
      "      policy_loss: -0.003899254137650132\n",
      "      total_loss: 1396.545654296875\n",
      "      vf_explained_var: 0.9435354471206665\n",
      "      vf_loss: 1396.548828125\n",
      "    sample_time_ms: 19269.57\n",
      "    update_time_ms: 5.241\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 428.0737815474905\n",
      "  time_since_restore: 7121.962409257889\n",
      "  time_this_iter_s: 22.948036670684814\n",
      "  time_total_s: 7121.962409257889\n",
      "  timestamp: 1553972894\n",
      "  timesteps_since_restore: 3010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3010000\n",
      "  training_iteration: 301\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7121 s, 301 iter, 3010000 ts, 856 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-08-37\n",
      "  done: false\n",
      "  episode_len_mean: 166.49\n",
      "  episode_reward_max: 1118.116401777187\n",
      "  episode_reward_mean: 904.4362664951692\n",
      "  episode_reward_min: -77.67201646814594\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 17633\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.718\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 3020000\n",
      "    num_steps_trained: 3020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2871716022491455\n",
      "      kl: 0.03312317654490471\n",
      "      policy_loss: 0.0053753238171339035\n",
      "      total_loss: 1081.3150634765625\n",
      "      vf_explained_var: 0.9536480903625488\n",
      "      vf_loss: 1081.3082275390625\n",
      "    sample_time_ms: 19169.926\n",
      "    update_time_ms: 5.359\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.2181332475846\n",
      "  time_since_restore: 7144.757372140884\n",
      "  time_this_iter_s: 22.794962882995605\n",
      "  time_total_s: 7144.757372140884\n",
      "  timestamp: 1553972917\n",
      "  timesteps_since_restore: 3020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3020000\n",
      "  training_iteration: 302\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7144 s, 302 iter, 3020000 ts, 904 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-09-00\n",
      "  done: false\n",
      "  episode_len_mean: 170.27\n",
      "  episode_reward_max: 1121.7544149313946\n",
      "  episode_reward_mean: 901.0641012838609\n",
      "  episode_reward_min: -100.1549081348195\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 17692\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.813\n",
      "    load_time_ms: 1.416\n",
      "    num_steps_sampled: 3030000\n",
      "    num_steps_trained: 3030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2533007860183716\n",
      "      kl: 0.010563020594418049\n",
      "      policy_loss: -0.0007271121139638126\n",
      "      total_loss: 1043.3255615234375\n",
      "      vf_explained_var: 0.953789234161377\n",
      "      vf_loss: 1043.32568359375\n",
      "    sample_time_ms: 19187.982\n",
      "    update_time_ms: 6.189\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 450.53205064193054\n",
      "  time_since_restore: 7167.94842839241\n",
      "  time_this_iter_s: 23.19105625152588\n",
      "  time_total_s: 7167.94842839241\n",
      "  timestamp: 1553972940\n",
      "  timesteps_since_restore: 3030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3030000\n",
      "  training_iteration: 303\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7167 s, 303 iter, 3030000 ts, 901 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-09-24\n",
      "  done: false\n",
      "  episode_len_mean: 169.43\n",
      "  episode_reward_max: 1121.7544149313946\n",
      "  episode_reward_mean: 860.3930421981607\n",
      "  episode_reward_min: -84.44858017466464\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17752\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.137\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 3040000\n",
      "    num_steps_trained: 3040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3852862119674683\n",
      "      kl: 0.020067792385816574\n",
      "      policy_loss: -0.000978589174337685\n",
      "      total_loss: 1536.371826171875\n",
      "      vf_explained_var: 0.938528299331665\n",
      "      vf_loss: 1536.371826171875\n",
      "    sample_time_ms: 19194.44\n",
      "    update_time_ms: 6.111\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 430.19652109908026\n",
      "  time_since_restore: 7191.559732437134\n",
      "  time_this_iter_s: 23.61130404472351\n",
      "  time_total_s: 7191.559732437134\n",
      "  timestamp: 1553972964\n",
      "  timesteps_since_restore: 3040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3040000\n",
      "  training_iteration: 304\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7191 s, 304 iter, 3040000 ts, 860 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-09-48\n",
      "  done: false\n",
      "  episode_len_mean: 170.97\n",
      "  episode_reward_max: 1120.3598328555854\n",
      "  episode_reward_mean: 839.0493887171733\n",
      "  episode_reward_min: -100.72120873197562\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 17810\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.118\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 3050000\n",
      "    num_steps_trained: 3050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.370450496673584\n",
      "      kl: 0.019343961030244827\n",
      "      policy_loss: -0.003138823201879859\n",
      "      total_loss: 1334.755615234375\n",
      "      vf_explained_var: 0.9473022818565369\n",
      "      vf_loss: 1334.7576904296875\n",
      "    sample_time_ms: 19331.334\n",
      "    update_time_ms: 6.226\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 419.52469435858654\n",
      "  time_since_restore: 7215.554810762405\n",
      "  time_this_iter_s: 23.995078325271606\n",
      "  time_total_s: 7215.554810762405\n",
      "  timestamp: 1553972988\n",
      "  timesteps_since_restore: 3050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3050000\n",
      "  training_iteration: 305\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7215 s, 305 iter, 3050000 ts, 839 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-10-11\n",
      "  done: false\n",
      "  episode_len_mean: 177.52\n",
      "  episode_reward_max: 1136.7418658170632\n",
      "  episode_reward_mean: 865.3376637137455\n",
      "  episode_reward_min: -100.72120873197562\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 17866\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.645\n",
      "    load_time_ms: 1.402\n",
      "    num_steps_sampled: 3060000\n",
      "    num_steps_trained: 3060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4849826097488403\n",
      "      kl: 0.019686821848154068\n",
      "      policy_loss: -0.002293879631906748\n",
      "      total_loss: 1239.0443115234375\n",
      "      vf_explained_var: 0.9440600275993347\n",
      "      vf_loss: 1239.045654296875\n",
      "    sample_time_ms: 19375.057\n",
      "    update_time_ms: 6.261\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 432.66883185687277\n",
      "  time_since_restore: 7239.052220106125\n",
      "  time_this_iter_s: 23.497409343719482\n",
      "  time_total_s: 7239.052220106125\n",
      "  timestamp: 1553973011\n",
      "  timesteps_since_restore: 3060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3060000\n",
      "  training_iteration: 306\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7239 s, 306 iter, 3060000 ts, 865 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-10-35\n",
      "  done: false\n",
      "  episode_len_mean: 174.46\n",
      "  episode_reward_max: 1136.7418658170632\n",
      "  episode_reward_mean: 879.8393558254589\n",
      "  episode_reward_min: -52.21347631952122\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 17923\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.055\n",
      "    load_time_ms: 1.451\n",
      "    num_steps_sampled: 3070000\n",
      "    num_steps_trained: 3070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.330431580543518\n",
      "      kl: 0.015074062161147594\n",
      "      policy_loss: -0.004488131497055292\n",
      "      total_loss: 706.4490356445312\n",
      "      vf_explained_var: 0.9694065451622009\n",
      "      vf_loss: 706.4528198242188\n",
      "    sample_time_ms: 19404.226\n",
      "    update_time_ms: 6.193\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 439.9196779127295\n",
      "  time_since_restore: 7262.407385826111\n",
      "  time_this_iter_s: 23.355165719985962\n",
      "  time_total_s: 7262.407385826111\n",
      "  timestamp: 1553973035\n",
      "  timesteps_since_restore: 3070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3070000\n",
      "  training_iteration: 307\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7262 s, 307 iter, 3070000 ts, 880 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-10-58\n",
      "  done: false\n",
      "  episode_len_mean: 176.45\n",
      "  episode_reward_max: 1161.784232803456\n",
      "  episode_reward_mean: 918.3554705739679\n",
      "  episode_reward_min: -52.21347631952122\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 17980\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.591\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 3080000\n",
      "    num_steps_trained: 3080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3232752084732056\n",
      "      kl: 0.018882812932133675\n",
      "      policy_loss: -0.002272937912493944\n",
      "      total_loss: 1082.7215576171875\n",
      "      vf_explained_var: 0.954788088798523\n",
      "      vf_loss: 1082.72314453125\n",
      "    sample_time_ms: 19425.891\n",
      "    update_time_ms: 6.781\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 459.17773528698393\n",
      "  time_since_restore: 7285.854396104813\n",
      "  time_this_iter_s: 23.447010278701782\n",
      "  time_total_s: 7285.854396104813\n",
      "  timestamp: 1553973058\n",
      "  timesteps_since_restore: 3080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3080000\n",
      "  training_iteration: 308\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7285 s, 308 iter, 3080000 ts, 918 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-11-22\n",
      "  done: false\n",
      "  episode_len_mean: 180.54\n",
      "  episode_reward_max: 1162.741461830508\n",
      "  episode_reward_mean: 911.3339442461886\n",
      "  episode_reward_min: -96.21117328118925\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 18034\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.776\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 3090000\n",
      "    num_steps_trained: 3090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5098190307617188\n",
      "      kl: 0.01733921468257904\n",
      "      policy_loss: -0.0011196098057553172\n",
      "      total_loss: 772.6098022460938\n",
      "      vf_explained_var: 0.9647335410118103\n",
      "      vf_loss: 772.6101684570312\n",
      "    sample_time_ms: 19463.927\n",
      "    update_time_ms: 6.72\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 455.66697212309424\n",
      "  time_since_restore: 7309.30660367012\n",
      "  time_this_iter_s: 23.452207565307617\n",
      "  time_total_s: 7309.30660367012\n",
      "  timestamp: 1553973082\n",
      "  timesteps_since_restore: 3090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3090000\n",
      "  training_iteration: 309\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7309 s, 309 iter, 3090000 ts, 911 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-11-45\n",
      "  done: false\n",
      "  episode_len_mean: 176.54\n",
      "  episode_reward_max: 1162.741461830508\n",
      "  episode_reward_mean: 904.3494670121661\n",
      "  episode_reward_min: -63.84386462738095\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 18092\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.809\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 3100000\n",
      "    num_steps_trained: 3100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3028454780578613\n",
      "      kl: 0.012193875387310982\n",
      "      policy_loss: -0.0003242945531383157\n",
      "      total_loss: 879.9146728515625\n",
      "      vf_explained_var: 0.9611752033233643\n",
      "      vf_loss: 879.9144897460938\n",
      "    sample_time_ms: 19453.998\n",
      "    update_time_ms: 6.439\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.174733506083\n",
      "  time_since_restore: 7332.582164049149\n",
      "  time_this_iter_s: 23.27556037902832\n",
      "  time_total_s: 7332.582164049149\n",
      "  timestamp: 1553973105\n",
      "  timesteps_since_restore: 3100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3100000\n",
      "  training_iteration: 310\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7332 s, 310 iter, 3100000 ts, 904 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-12-09\n",
      "  done: false\n",
      "  episode_len_mean: 169.89\n",
      "  episode_reward_max: 1089.0313233601826\n",
      "  episode_reward_mean: 847.9596382802227\n",
      "  episode_reward_min: -63.84386462738095\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 18151\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.005\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 3110000\n",
      "    num_steps_trained: 3110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4288054704666138\n",
      "      kl: 0.020006021484732628\n",
      "      policy_loss: -0.0012207748368382454\n",
      "      total_loss: 987.3313598632812\n",
      "      vf_explained_var: 0.9598779082298279\n",
      "      vf_loss: 987.3316040039062\n",
      "    sample_time_ms: 19581.395\n",
      "    update_time_ms: 6.314\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 423.97981914011126\n",
      "  time_since_restore: 7356.954808473587\n",
      "  time_this_iter_s: 24.372644424438477\n",
      "  time_total_s: 7356.954808473587\n",
      "  timestamp: 1553973129\n",
      "  timesteps_since_restore: 3110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3110000\n",
      "  training_iteration: 311\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7356 s, 311 iter, 3110000 ts, 848 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-12-33\n",
      "  done: false\n",
      "  episode_len_mean: 171.17\n",
      "  episode_reward_max: 1131.5265653414615\n",
      "  episode_reward_mean: 904.7695168704606\n",
      "  episode_reward_min: -98.88687654733154\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 18210\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.797\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 3120000\n",
      "    num_steps_trained: 3120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2098816633224487\n",
      "      kl: 0.010659808292984962\n",
      "      policy_loss: -0.0017083337297663093\n",
      "      total_loss: 542.6434326171875\n",
      "      vf_explained_var: 0.9764179587364197\n",
      "      vf_loss: 542.6447143554688\n",
      "    sample_time_ms: 19685.356\n",
      "    update_time_ms: 6.411\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.3847584352303\n",
      "  time_since_restore: 7380.779276132584\n",
      "  time_this_iter_s: 23.824467658996582\n",
      "  time_total_s: 7380.779276132584\n",
      "  timestamp: 1553973153\n",
      "  timesteps_since_restore: 3120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3120000\n",
      "  training_iteration: 312\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7380 s, 312 iter, 3120000 ts, 905 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-12-57\n",
      "  done: false\n",
      "  episode_len_mean: 170.85\n",
      "  episode_reward_max: 1131.5265653414615\n",
      "  episode_reward_mean: 890.0395936926191\n",
      "  episode_reward_min: -103.96836917127631\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 18268\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.454\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 3130000\n",
      "    num_steps_trained: 3130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3577278852462769\n",
      "      kl: 0.012640625238418579\n",
      "      policy_loss: -0.0033979422878473997\n",
      "      total_loss: 1133.604736328125\n",
      "      vf_explained_var: 0.9530621767044067\n",
      "      vf_loss: 1133.6075439453125\n",
      "    sample_time_ms: 19707.931\n",
      "    update_time_ms: 5.719\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 445.01979684630965\n",
      "  time_since_restore: 7404.13508105278\n",
      "  time_this_iter_s: 23.355804920196533\n",
      "  time_total_s: 7404.13508105278\n",
      "  timestamp: 1553973177\n",
      "  timesteps_since_restore: 3130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3130000\n",
      "  training_iteration: 313\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7404 s, 313 iter, 3130000 ts, 890 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-13-20\n",
      "  done: false\n",
      "  episode_len_mean: 168.29\n",
      "  episode_reward_max: 1097.2682360150172\n",
      "  episode_reward_mean: 878.5610737560595\n",
      "  episode_reward_min: -93.97393587001875\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 18327\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.306\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 3140000\n",
      "    num_steps_trained: 3140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2061638832092285\n",
      "      kl: 0.0189950130879879\n",
      "      policy_loss: -0.004295567981898785\n",
      "      total_loss: 1100.5849609375\n",
      "      vf_explained_var: 0.9500436782836914\n",
      "      vf_loss: 1100.58837890625\n",
      "    sample_time_ms: 19721.962\n",
      "    update_time_ms: 5.751\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 439.2805368780298\n",
      "  time_since_restore: 7428.014109611511\n",
      "  time_this_iter_s: 23.87902855873108\n",
      "  time_total_s: 7428.014109611511\n",
      "  timestamp: 1553973200\n",
      "  timesteps_since_restore: 3140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3140000\n",
      "  training_iteration: 314\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7428 s, 314 iter, 3140000 ts, 879 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-13-44\n",
      "  done: false\n",
      "  episode_len_mean: 170.38\n",
      "  episode_reward_max: 1119.5715538845159\n",
      "  episode_reward_mean: 872.603253331463\n",
      "  episode_reward_min: -94.9703791153103\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 18386\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.099\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 3150000\n",
      "    num_steps_trained: 3150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2735886573791504\n",
      "      kl: 0.021522659808397293\n",
      "      policy_loss: -0.0043439362198114395\n",
      "      total_loss: 1521.1259765625\n",
      "      vf_explained_var: 0.9408682584762573\n",
      "      vf_loss: 1521.12939453125\n",
      "    sample_time_ms: 19673.12\n",
      "    update_time_ms: 5.651\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 436.3016266657315\n",
      "  time_since_restore: 7451.489249706268\n",
      "  time_this_iter_s: 23.47514009475708\n",
      "  time_total_s: 7451.489249706268\n",
      "  timestamp: 1553973224\n",
      "  timesteps_since_restore: 3150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3150000\n",
      "  training_iteration: 315\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7451 s, 315 iter, 3150000 ts, 873 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-14-07\n",
      "  done: false\n",
      "  episode_len_mean: 173.6\n",
      "  episode_reward_max: 1119.5715538845159\n",
      "  episode_reward_mean: 858.8032194715976\n",
      "  episode_reward_min: -94.9703791153103\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 18443\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.614\n",
      "    load_time_ms: 1.69\n",
      "    num_steps_sampled: 3160000\n",
      "    num_steps_trained: 3160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3301376104354858\n",
      "      kl: 0.013317737728357315\n",
      "      policy_loss: -0.0041270786896348\n",
      "      total_loss: 773.5626831054688\n",
      "      vf_explained_var: 0.9678463935852051\n",
      "      vf_loss: 773.5662231445312\n",
      "    sample_time_ms: 19648.924\n",
      "    update_time_ms: 5.639\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 429.4016097357988\n",
      "  time_since_restore: 7474.918863773346\n",
      "  time_this_iter_s: 23.429614067077637\n",
      "  time_total_s: 7474.918863773346\n",
      "  timestamp: 1553973247\n",
      "  timesteps_since_restore: 3160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3160000\n",
      "  training_iteration: 316\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7474 s, 316 iter, 3160000 ts, 859 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-14-30\n",
      "  done: false\n",
      "  episode_len_mean: 183.98\n",
      "  episode_reward_max: 1131.0513447976289\n",
      "  episode_reward_mean: 914.5122634433641\n",
      "  episode_reward_min: -2.850353452340414\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 18497\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.153\n",
      "    load_time_ms: 1.647\n",
      "    num_steps_sampled: 3170000\n",
      "    num_steps_trained: 3170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4345788955688477\n",
      "      kl: 0.026837831363081932\n",
      "      policy_loss: -0.0012472695671021938\n",
      "      total_loss: 804.9652099609375\n",
      "      vf_explained_var: 0.9664166569709778\n",
      "      vf_loss: 804.9652709960938\n",
      "    sample_time_ms: 19584.119\n",
      "    update_time_ms: 5.841\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.2561317216821\n",
      "  time_since_restore: 7497.62873673439\n",
      "  time_this_iter_s: 22.70987296104431\n",
      "  time_total_s: 7497.62873673439\n",
      "  timestamp: 1553973270\n",
      "  timesteps_since_restore: 3170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3170000\n",
      "  training_iteration: 317\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7497 s, 317 iter, 3170000 ts, 915 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-14-54\n",
      "  done: false\n",
      "  episode_len_mean: 176.65\n",
      "  episode_reward_max: 1091.3214420221911\n",
      "  episode_reward_mean: 877.6154535893598\n",
      "  episode_reward_min: -96.83434934691962\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 18555\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.547\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 3180000\n",
      "    num_steps_trained: 3180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3302996158599854\n",
      "      kl: 0.01349205058068037\n",
      "      policy_loss: -0.00392576539888978\n",
      "      total_loss: 787.4887084960938\n",
      "      vf_explained_var: 0.967784583568573\n",
      "      vf_loss: 787.4920043945312\n",
      "    sample_time_ms: 19572.166\n",
      "    update_time_ms: 5.752\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 438.8077267946799\n",
      "  time_since_restore: 7520.958915710449\n",
      "  time_this_iter_s: 23.33017897605896\n",
      "  time_total_s: 7520.958915710449\n",
      "  timestamp: 1553973294\n",
      "  timesteps_since_restore: 3180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3180000\n",
      "  training_iteration: 318\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7520 s, 318 iter, 3180000 ts, 878 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-15-17\n",
      "  done: false\n",
      "  episode_len_mean: 169.36\n",
      "  episode_reward_max: 1106.515668227915\n",
      "  episode_reward_mean: 871.0931615062668\n",
      "  episode_reward_min: -96.83434934691962\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 18614\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.376\n",
      "    load_time_ms: 1.621\n",
      "    num_steps_sampled: 3190000\n",
      "    num_steps_trained: 3190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.319593906402588\n",
      "      kl: 0.016543984413146973\n",
      "      policy_loss: -0.00037636092747561634\n",
      "      total_loss: 1226.1861572265625\n",
      "      vf_explained_var: 0.9487780332565308\n",
      "      vf_loss: 1226.1856689453125\n",
      "    sample_time_ms: 19513.481\n",
      "    update_time_ms: 5.777\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 435.54658075313347\n",
      "  time_since_restore: 7543.844225645065\n",
      "  time_this_iter_s: 22.88530993461609\n",
      "  time_total_s: 7543.844225645065\n",
      "  timestamp: 1553973317\n",
      "  timesteps_since_restore: 3190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3190000\n",
      "  training_iteration: 319\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7543 s, 319 iter, 3190000 ts, 871 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-15-40\n",
      "  done: false\n",
      "  episode_len_mean: 171.02\n",
      "  episode_reward_max: 1117.2029519010334\n",
      "  episode_reward_mean: 853.6228871747617\n",
      "  episode_reward_min: -82.84859951307708\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 18672\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3928.616\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 3200000\n",
      "    num_steps_trained: 3200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.334177017211914\n",
      "      kl: 0.017325690016150475\n",
      "      policy_loss: -0.005289762746542692\n",
      "      total_loss: 2222.77392578125\n",
      "      vf_explained_var: 0.9043585658073425\n",
      "      vf_loss: 2222.778564453125\n",
      "    sample_time_ms: 19524.327\n",
      "    update_time_ms: 5.881\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 426.8114435873808\n",
      "  time_since_restore: 7567.368563175201\n",
      "  time_this_iter_s: 23.52433753013611\n",
      "  time_total_s: 7567.368563175201\n",
      "  timestamp: 1553973340\n",
      "  timesteps_since_restore: 3200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3200000\n",
      "  training_iteration: 320\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7567 s, 320 iter, 3200000 ts, 854 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-16-04\n",
      "  done: false\n",
      "  episode_len_mean: 165.58\n",
      "  episode_reward_max: 1117.7753136064234\n",
      "  episode_reward_mean: 867.602614446986\n",
      "  episode_reward_min: -71.68075859309263\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 18733\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.666\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 3210000\n",
      "    num_steps_trained: 3210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.12714684009552\n",
      "      kl: 0.019536443054676056\n",
      "      policy_loss: 0.00020220722944941372\n",
      "      total_loss: 1007.0224609375\n",
      "      vf_explained_var: 0.9577789306640625\n",
      "      vf_loss: 1007.0214233398438\n",
      "    sample_time_ms: 19503.56\n",
      "    update_time_ms: 5.888\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 433.8013072234928\n",
      "  time_since_restore: 7591.361333847046\n",
      "  time_this_iter_s: 23.992770671844482\n",
      "  time_total_s: 7591.361333847046\n",
      "  timestamp: 1553973364\n",
      "  timesteps_since_restore: 3210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3210000\n",
      "  training_iteration: 321\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7591 s, 321 iter, 3210000 ts, 868 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-16-28\n",
      "  done: false\n",
      "  episode_len_mean: 167.24\n",
      "  episode_reward_max: 1102.699748206205\n",
      "  episode_reward_mean: 879.1055833060328\n",
      "  episode_reward_min: -72.709857050736\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 18791\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.854\n",
      "    load_time_ms: 1.673\n",
      "    num_steps_sampled: 3220000\n",
      "    num_steps_trained: 3220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2175703048706055\n",
      "      kl: 0.01868787407875061\n",
      "      policy_loss: 0.0005145172472111881\n",
      "      total_loss: 741.5397338867188\n",
      "      vf_explained_var: 0.9671229720115662\n",
      "      vf_loss: 741.5383911132812\n",
      "    sample_time_ms: 19467.029\n",
      "    update_time_ms: 5.769\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 439.5527916530163\n",
      "  time_since_restore: 7614.782370090485\n",
      "  time_this_iter_s: 23.42103624343872\n",
      "  time_total_s: 7614.782370090485\n",
      "  timestamp: 1553973388\n",
      "  timesteps_since_restore: 3220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3220000\n",
      "  training_iteration: 322\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7614 s, 322 iter, 3220000 ts, 879 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-16-51\n",
      "  done: false\n",
      "  episode_len_mean: 178.22\n",
      "  episode_reward_max: 1129.3450943211408\n",
      "  episode_reward_mean: 932.925515563136\n",
      "  episode_reward_min: -94.67724680758258\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 18847\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.261\n",
      "    load_time_ms: 1.678\n",
      "    num_steps_sampled: 3230000\n",
      "    num_steps_trained: 3230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3196951150894165\n",
      "      kl: 0.014552553184330463\n",
      "      policy_loss: -0.0043577649630606174\n",
      "      total_loss: 772.1221313476562\n",
      "      vf_explained_var: 0.9673827886581421\n",
      "      vf_loss: 772.125732421875\n",
      "    sample_time_ms: 19459.275\n",
      "    update_time_ms: 5.563\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.4627577815679\n",
      "  time_since_restore: 7638.120058774948\n",
      "  time_this_iter_s: 23.3376886844635\n",
      "  time_total_s: 7638.120058774948\n",
      "  timestamp: 1553973411\n",
      "  timesteps_since_restore: 3230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3230000\n",
      "  training_iteration: 323\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7638 s, 323 iter, 3230000 ts, 933 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-17-14\n",
      "  done: false\n",
      "  episode_len_mean: 178.56\n",
      "  episode_reward_max: 1130.6633189965648\n",
      "  episode_reward_mean: 917.5788918278245\n",
      "  episode_reward_min: -94.67724680758258\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 18904\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.014\n",
      "    load_time_ms: 1.681\n",
      "    num_steps_sampled: 3240000\n",
      "    num_steps_trained: 3240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.29019033908844\n",
      "      kl: 0.01779858022928238\n",
      "      policy_loss: -0.0015929172514006495\n",
      "      total_loss: 592.7250366210938\n",
      "      vf_explained_var: 0.9753750562667847\n",
      "      vf_loss: 592.7257690429688\n",
      "    sample_time_ms: 19359.012\n",
      "    update_time_ms: 5.499\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 458.78944591391223\n",
      "  time_since_restore: 7660.902026176453\n",
      "  time_this_iter_s: 22.781967401504517\n",
      "  time_total_s: 7660.902026176453\n",
      "  timestamp: 1553973434\n",
      "  timesteps_since_restore: 3240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3240000\n",
      "  training_iteration: 324\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7660 s, 324 iter, 3240000 ts, 918 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-17-36\n",
      "  done: false\n",
      "  episode_len_mean: 167.33\n",
      "  episode_reward_max: 1112.7336476611108\n",
      "  episode_reward_mean: 917.5669265551883\n",
      "  episode_reward_min: -37.47557608855578\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 18964\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.758\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 3250000\n",
      "    num_steps_trained: 3250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1774232387542725\n",
      "      kl: 0.01937885396182537\n",
      "      policy_loss: -0.0018031528452411294\n",
      "      total_loss: 800.5188598632812\n",
      "      vf_explained_var: 0.9653463363647461\n",
      "      vf_loss: 800.519775390625\n",
      "    sample_time_ms: 19252.012\n",
      "    update_time_ms: 5.486\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 458.78346327759414\n",
      "  time_since_restore: 7683.332314968109\n",
      "  time_this_iter_s: 22.430288791656494\n",
      "  time_total_s: 7683.332314968109\n",
      "  timestamp: 1553973456\n",
      "  timesteps_since_restore: 3250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3250000\n",
      "  training_iteration: 325\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7683 s, 325 iter, 3250000 ts, 918 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-17-59\n",
      "  done: false\n",
      "  episode_len_mean: 176.3\n",
      "  episode_reward_max: 1107.2909625172388\n",
      "  episode_reward_mean: 910.4010297986981\n",
      "  episode_reward_min: -83.51173611344514\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 19018\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.035\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 3260000\n",
      "    num_steps_trained: 3260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.471172571182251\n",
      "      kl: 0.010827722027897835\n",
      "      policy_loss: -0.0025019848253577948\n",
      "      total_loss: 597.1332397460938\n",
      "      vf_explained_var: 0.9727216958999634\n",
      "      vf_loss: 597.1351928710938\n",
      "    sample_time_ms: 19194.367\n",
      "    update_time_ms: 5.612\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 455.20051489934895\n",
      "  time_since_restore: 7706.047814369202\n",
      "  time_this_iter_s: 22.71549940109253\n",
      "  time_total_s: 7706.047814369202\n",
      "  timestamp: 1553973479\n",
      "  timesteps_since_restore: 3260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3260000\n",
      "  training_iteration: 326\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7706 s, 326 iter, 3260000 ts, 910 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-18-22\n",
      "  done: false\n",
      "  episode_len_mean: 175.89\n",
      "  episode_reward_max: 1164.1672959001385\n",
      "  episode_reward_mean: 886.330041542634\n",
      "  episode_reward_min: -83.51173611344514\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 19077\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.038\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 3270000\n",
      "    num_steps_trained: 3270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2680448293685913\n",
      "      kl: 0.02221595123410225\n",
      "      policy_loss: -0.002243391005322337\n",
      "      total_loss: 1025.8411865234375\n",
      "      vf_explained_var: 0.9545756578445435\n",
      "      vf_loss: 1025.8424072265625\n",
      "    sample_time_ms: 19199.791\n",
      "    update_time_ms: 5.408\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 443.1650207713169\n",
      "  time_since_restore: 7728.789900064468\n",
      "  time_this_iter_s: 22.742085695266724\n",
      "  time_total_s: 7728.789900064468\n",
      "  timestamp: 1553973502\n",
      "  timesteps_since_restore: 3270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3270000\n",
      "  training_iteration: 327\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7728 s, 327 iter, 3270000 ts, 886 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-18-45\n",
      "  done: false\n",
      "  episode_len_mean: 175.02\n",
      "  episode_reward_max: 1164.1672959001385\n",
      "  episode_reward_mean: 910.9645082373929\n",
      "  episode_reward_min: -67.15083587317972\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 19132\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.879\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 3280000\n",
      "    num_steps_trained: 3280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.326319932937622\n",
      "      kl: 0.012651740573346615\n",
      "      policy_loss: -0.0008669759263284504\n",
      "      total_loss: 351.162109375\n",
      "      vf_explained_var: 0.9844247102737427\n",
      "      vf_loss: 351.1624450683594\n",
      "    sample_time_ms: 19199.616\n",
      "    update_time_ms: 4.981\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 455.48225411869635\n",
      "  time_since_restore: 7752.142039060593\n",
      "  time_this_iter_s: 23.352138996124268\n",
      "  time_total_s: 7752.142039060593\n",
      "  timestamp: 1553973525\n",
      "  timesteps_since_restore: 3280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3280000\n",
      "  training_iteration: 328\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7752 s, 328 iter, 3280000 ts, 911 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-19-09\n",
      "  done: false\n",
      "  episode_len_mean: 180.0\n",
      "  episode_reward_max: 1141.8763217703495\n",
      "  episode_reward_mean: 957.1858208296595\n",
      "  episode_reward_min: -26.047482270079342\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 19189\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.403\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 3290000\n",
      "    num_steps_trained: 3290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1591651439666748\n",
      "      kl: 0.015942152589559555\n",
      "      policy_loss: -0.0011613667011260986\n",
      "      total_loss: 252.98687744140625\n",
      "      vf_explained_var: 0.9889770746231079\n",
      "      vf_loss: 252.98733520507812\n",
      "    sample_time_ms: 19271.149\n",
      "    update_time_ms: 4.861\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.5929104148297\n",
      "  time_since_restore: 7775.906222105026\n",
      "  time_this_iter_s: 23.764183044433594\n",
      "  time_total_s: 7775.906222105026\n",
      "  timestamp: 1553973549\n",
      "  timesteps_since_restore: 3290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3290000\n",
      "  training_iteration: 329\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7775 s, 329 iter, 3290000 ts, 957 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-19-32\n",
      "  done: false\n",
      "  episode_len_mean: 174.01\n",
      "  episode_reward_max: 1113.716455552025\n",
      "  episode_reward_mean: 954.3442753086894\n",
      "  episode_reward_min: -98.35746735007966\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 19245\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.462\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 3300000\n",
      "    num_steps_trained: 3300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2316839694976807\n",
      "      kl: 0.019854098558425903\n",
      "      policy_loss: -0.004484560340642929\n",
      "      total_loss: 710.9193725585938\n",
      "      vf_explained_var: 0.9682855606079102\n",
      "      vf_loss: 710.9230346679688\n",
      "    sample_time_ms: 19233.864\n",
      "    update_time_ms: 4.802\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.1721376543447\n",
      "  time_since_restore: 7798.934410333633\n",
      "  time_this_iter_s: 23.028188228607178\n",
      "  time_total_s: 7798.934410333633\n",
      "  timestamp: 1553973572\n",
      "  timesteps_since_restore: 3300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3300000\n",
      "  training_iteration: 330\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7798 s, 330 iter, 3300000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-19-55\n",
      "  done: false\n",
      "  episode_len_mean: 177.2\n",
      "  episode_reward_max: 1117.5232117231426\n",
      "  episode_reward_mean: 915.4145395640303\n",
      "  episode_reward_min: -98.35746735007966\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 19300\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.044\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 3310000\n",
      "    num_steps_trained: 3310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3589426279067993\n",
      "      kl: 0.012768647633492947\n",
      "      policy_loss: -0.0013404476922005415\n",
      "      total_loss: 766.5516967773438\n",
      "      vf_explained_var: 0.9666470289230347\n",
      "      vf_loss: 766.552490234375\n",
      "    sample_time_ms: 19155.889\n",
      "    update_time_ms: 4.898\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.70726978201515\n",
      "  time_since_restore: 7822.16494011879\n",
      "  time_this_iter_s: 23.23052978515625\n",
      "  time_total_s: 7822.16494011879\n",
      "  timestamp: 1553973595\n",
      "  timesteps_since_restore: 3310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3310000\n",
      "  training_iteration: 331\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7822 s, 331 iter, 3310000 ts, 915 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-20-18\n",
      "  done: false\n",
      "  episode_len_mean: 182.21\n",
      "  episode_reward_max: 1147.006797180645\n",
      "  episode_reward_mean: 913.386987692674\n",
      "  episode_reward_min: -45.00211487008997\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 19358\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.3\n",
      "    load_time_ms: 1.389\n",
      "    num_steps_sampled: 3320000\n",
      "    num_steps_trained: 3320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1752448081970215\n",
      "      kl: 0.016578378155827522\n",
      "      policy_loss: 0.000438727525761351\n",
      "      total_loss: 1003.5126953125\n",
      "      vf_explained_var: 0.9570028781890869\n",
      "      vf_loss: 1003.5115966796875\n",
      "    sample_time_ms: 19090.43\n",
      "    update_time_ms: 4.895\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 456.6934938463371\n",
      "  time_since_restore: 7844.870794534683\n",
      "  time_this_iter_s: 22.705854415893555\n",
      "  time_total_s: 7844.870794534683\n",
      "  timestamp: 1553973618\n",
      "  timesteps_since_restore: 3320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3320000\n",
      "  training_iteration: 332\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7844 s, 332 iter, 3320000 ts, 913 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-20-42\n",
      "  done: false\n",
      "  episode_len_mean: 173.02\n",
      "  episode_reward_max: 1147.006797180645\n",
      "  episode_reward_mean: 897.8172420563435\n",
      "  episode_reward_min: -84.41563137188076\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 19415\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.916\n",
      "    load_time_ms: 1.403\n",
      "    num_steps_sampled: 3330000\n",
      "    num_steps_trained: 3330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3014150857925415\n",
      "      kl: 0.023255426436662674\n",
      "      policy_loss: -0.003882528515532613\n",
      "      total_loss: 1099.3135986328125\n",
      "      vf_explained_var: 0.9542357325553894\n",
      "      vf_loss: 1099.3165283203125\n",
      "    sample_time_ms: 19104.282\n",
      "    update_time_ms: 4.899\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 448.90862102817175\n",
      "  time_since_restore: 7868.32639336586\n",
      "  time_this_iter_s: 23.455598831176758\n",
      "  time_total_s: 7868.32639336586\n",
      "  timestamp: 1553973642\n",
      "  timesteps_since_restore: 3330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3330000\n",
      "  training_iteration: 333\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7868 s, 333 iter, 3330000 ts, 898 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-21-05\n",
      "  done: false\n",
      "  episode_len_mean: 175.09\n",
      "  episode_reward_max: 1104.6743090185569\n",
      "  episode_reward_mean: 887.7931052461072\n",
      "  episode_reward_min: -84.41563137188076\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 19471\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.637\n",
      "    load_time_ms: 1.401\n",
      "    num_steps_sampled: 3340000\n",
      "    num_steps_trained: 3340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2030768394470215\n",
      "      kl: 0.01752861961722374\n",
      "      policy_loss: -0.005167020484805107\n",
      "      total_loss: 487.7626647949219\n",
      "      vf_explained_var: 0.979565441608429\n",
      "      vf_loss: 487.76702880859375\n",
      "    sample_time_ms: 19127.185\n",
      "    update_time_ms: 4.901\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 443.8965526230534\n",
      "  time_since_restore: 7891.362384557724\n",
      "  time_this_iter_s: 23.035991191864014\n",
      "  time_total_s: 7891.362384557724\n",
      "  timestamp: 1553973665\n",
      "  timesteps_since_restore: 3340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3340000\n",
      "  training_iteration: 334\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7891 s, 334 iter, 3340000 ts, 888 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-21-28\n",
      "  done: false\n",
      "  episode_len_mean: 171.17\n",
      "  episode_reward_max: 1134.3756588343879\n",
      "  episode_reward_mean: 867.8460345121063\n",
      "  episode_reward_min: -68.89786627605702\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 19530\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.703\n",
      "    load_time_ms: 1.38\n",
      "    num_steps_sampled: 3350000\n",
      "    num_steps_trained: 3350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2106961011886597\n",
      "      kl: 0.011775939725339413\n",
      "      policy_loss: -0.0012890282087028027\n",
      "      total_loss: 1217.5633544921875\n",
      "      vf_explained_var: 0.9527857899665833\n",
      "      vf_loss: 1217.5640869140625\n",
      "    sample_time_ms: 19196.004\n",
      "    update_time_ms: 5.235\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 433.92301725605313\n",
      "  time_since_restore: 7914.51825428009\n",
      "  time_this_iter_s: 23.155869722366333\n",
      "  time_total_s: 7914.51825428009\n",
      "  timestamp: 1553973688\n",
      "  timesteps_since_restore: 3350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3350000\n",
      "  training_iteration: 335\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7914 s, 335 iter, 3350000 ts, 868 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-21-51\n",
      "  done: false\n",
      "  episode_len_mean: 172.49\n",
      "  episode_reward_max: 1104.2863495290726\n",
      "  episode_reward_mean: 890.4195958564223\n",
      "  episode_reward_min: -68.89786627605702\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 19589\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.148\n",
      "    load_time_ms: 1.387\n",
      "    num_steps_sampled: 3360000\n",
      "    num_steps_trained: 3360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1343847513198853\n",
      "      kl: 0.01679261215031147\n",
      "      policy_loss: -0.002018142957240343\n",
      "      total_loss: 790.137939453125\n",
      "      vf_explained_var: 0.9626539349555969\n",
      "      vf_loss: 790.13916015625\n",
      "    sample_time_ms: 19268.41\n",
      "    update_time_ms: 5.212\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 445.20979792821134\n",
      "  time_since_restore: 7937.931452989578\n",
      "  time_this_iter_s: 23.413198709487915\n",
      "  time_total_s: 7937.931452989578\n",
      "  timestamp: 1553973711\n",
      "  timesteps_since_restore: 3360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3360000\n",
      "  training_iteration: 336\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7937 s, 336 iter, 3360000 ts, 890 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-22-15\n",
      "  done: false\n",
      "  episode_len_mean: 167.72\n",
      "  episode_reward_max: 1093.4432269299864\n",
      "  episode_reward_mean: 896.4955979685395\n",
      "  episode_reward_min: -55.943158524345904\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 19648\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.378\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 3370000\n",
      "    num_steps_trained: 3370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0683929920196533\n",
      "      kl: 0.017162028700113297\n",
      "      policy_loss: -0.00038673976087011397\n",
      "      total_loss: 1390.1080322265625\n",
      "      vf_explained_var: 0.9392816424369812\n",
      "      vf_loss: 1390.1075439453125\n",
      "    sample_time_ms: 19359.036\n",
      "    update_time_ms: 5.289\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 448.24779898426976\n",
      "  time_since_restore: 7961.555580615997\n",
      "  time_this_iter_s: 23.624127626419067\n",
      "  time_total_s: 7961.555580615997\n",
      "  timestamp: 1553973735\n",
      "  timesteps_since_restore: 3370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3370000\n",
      "  training_iteration: 337\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7961 s, 337 iter, 3370000 ts, 896 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-22-38\n",
      "  done: false\n",
      "  episode_len_mean: 167.27\n",
      "  episode_reward_max: 1122.0119015006917\n",
      "  episode_reward_mean: 899.5935746069273\n",
      "  episode_reward_min: -77.58303706562576\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 19708\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.464\n",
      "    load_time_ms: 1.392\n",
      "    num_steps_sampled: 3380000\n",
      "    num_steps_trained: 3380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1374295949935913\n",
      "      kl: 0.017843617126345634\n",
      "      policy_loss: -0.003561220830306411\n",
      "      total_loss: 731.6044921875\n",
      "      vf_explained_var: 0.9671937823295593\n",
      "      vf_loss: 731.6072387695312\n",
      "    sample_time_ms: 19307.47\n",
      "    update_time_ms: 5.262\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 449.7967873034637\n",
      "  time_since_restore: 7984.670057296753\n",
      "  time_this_iter_s: 23.114476680755615\n",
      "  time_total_s: 7984.670057296753\n",
      "  timestamp: 1553973758\n",
      "  timesteps_since_restore: 3380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3380000\n",
      "  training_iteration: 338\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 7984 s, 338 iter, 3380000 ts, 900 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-23-01\n",
      "  done: false\n",
      "  episode_len_mean: 174.97\n",
      "  episode_reward_max: 1122.0119015006917\n",
      "  episode_reward_mean: 905.4786803879579\n",
      "  episode_reward_min: -83.04670949635984\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 19763\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.469\n",
      "    load_time_ms: 1.378\n",
      "    num_steps_sampled: 3390000\n",
      "    num_steps_trained: 3390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.29509437084198\n",
      "      kl: 0.017070217058062553\n",
      "      policy_loss: -0.005368589423596859\n",
      "      total_loss: 638.41259765625\n",
      "      vf_explained_var: 0.9729291200637817\n",
      "      vf_loss: 638.417236328125\n",
      "    sample_time_ms: 19263.529\n",
      "    update_time_ms: 5.306\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.73934019397893\n",
      "  time_since_restore: 8007.763791799545\n",
      "  time_this_iter_s: 23.09373450279236\n",
      "  time_total_s: 8007.763791799545\n",
      "  timestamp: 1553973781\n",
      "  timesteps_since_restore: 3390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3390000\n",
      "  training_iteration: 339\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8007 s, 339 iter, 3390000 ts, 905 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-23-25\n",
      "  done: false\n",
      "  episode_len_mean: 175.86\n",
      "  episode_reward_max: 1132.7712868831575\n",
      "  episode_reward_mean: 919.7597666359543\n",
      "  episode_reward_min: -83.04670949635984\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 19821\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.041\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 3400000\n",
      "    num_steps_trained: 3400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2323397397994995\n",
      "      kl: 0.019365429878234863\n",
      "      policy_loss: -0.0034968906547874212\n",
      "      total_loss: 693.151123046875\n",
      "      vf_explained_var: 0.9703087210655212\n",
      "      vf_loss: 693.15380859375\n",
      "    sample_time_ms: 19288.874\n",
      "    update_time_ms: 5.545\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 459.8798833179772\n",
      "  time_since_restore: 8031.071508407593\n",
      "  time_this_iter_s: 23.307716608047485\n",
      "  time_total_s: 8031.071508407593\n",
      "  timestamp: 1553973805\n",
      "  timesteps_since_restore: 3400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3400000\n",
      "  training_iteration: 340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8031 s, 340 iter, 3400000 ts, 920 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-23-48\n",
      "  done: false\n",
      "  episode_len_mean: 175.04\n",
      "  episode_reward_max: 1134.3682807436467\n",
      "  episode_reward_mean: 891.5913458327585\n",
      "  episode_reward_min: -49.96163394736888\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 19877\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.957\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 3410000\n",
      "    num_steps_trained: 3410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2651543617248535\n",
      "      kl: 0.016384383663535118\n",
      "      policy_loss: 0.0006666833069175482\n",
      "      total_loss: 782.3565673828125\n",
      "      vf_explained_var: 0.9710928201675415\n",
      "      vf_loss: 782.355224609375\n",
      "    sample_time_ms: 19259.972\n",
      "    update_time_ms: 5.786\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 445.79567291637926\n",
      "  time_since_restore: 8054.014465332031\n",
      "  time_this_iter_s: 22.942956924438477\n",
      "  time_total_s: 8054.014465332031\n",
      "  timestamp: 1553973828\n",
      "  timesteps_since_restore: 3410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3410000\n",
      "  training_iteration: 341\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8054 s, 341 iter, 3410000 ts, 892 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-24-11\n",
      "  done: false\n",
      "  episode_len_mean: 171.27\n",
      "  episode_reward_max: 1144.2584518340925\n",
      "  episode_reward_mean: 864.6193034907043\n",
      "  episode_reward_min: -87.82515682077371\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 19937\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.302\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 3420000\n",
      "    num_steps_trained: 3420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1091960668563843\n",
      "      kl: 0.019495459273457527\n",
      "      policy_loss: -0.00188743497710675\n",
      "      total_loss: 1109.28515625\n",
      "      vf_explained_var: 0.9564355611801147\n",
      "      vf_loss: 1109.2860107421875\n",
      "    sample_time_ms: 19314.613\n",
      "    update_time_ms: 5.777\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 432.30965174535214\n",
      "  time_since_restore: 8077.321033716202\n",
      "  time_this_iter_s: 23.306568384170532\n",
      "  time_total_s: 8077.321033716202\n",
      "  timestamp: 1553973851\n",
      "  timesteps_since_restore: 3420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3420000\n",
      "  training_iteration: 342\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8077 s, 342 iter, 3420000 ts, 865 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-24-34\n",
      "  done: false\n",
      "  episode_len_mean: 166.04\n",
      "  episode_reward_max: 1121.4046281839521\n",
      "  episode_reward_mean: 835.9468363726857\n",
      "  episode_reward_min: -87.82515682077371\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 19998\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.757\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 3430000\n",
      "    num_steps_trained: 3430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1374785900115967\n",
      "      kl: 0.015955349430441856\n",
      "      policy_loss: -0.0038350645918399096\n",
      "      total_loss: 1374.0616455078125\n",
      "      vf_explained_var: 0.9416035413742065\n",
      "      vf_loss: 1374.06494140625\n",
      "    sample_time_ms: 19287.515\n",
      "    update_time_ms: 5.811\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 417.9734181863429\n",
      "  time_since_restore: 8100.48928809166\n",
      "  time_this_iter_s: 23.168254375457764\n",
      "  time_total_s: 8100.48928809166\n",
      "  timestamp: 1553973874\n",
      "  timesteps_since_restore: 3430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3430000\n",
      "  training_iteration: 343\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8100 s, 343 iter, 3430000 ts, 836 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-24-58\n",
      "  done: false\n",
      "  episode_len_mean: 169.54\n",
      "  episode_reward_max: 1130.3409526804428\n",
      "  episode_reward_mean: 869.2234769210547\n",
      "  episode_reward_min: -71.33283233529966\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 20056\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.808\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 3440000\n",
      "    num_steps_trained: 3440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1515687704086304\n",
      "      kl: 0.013319507241249084\n",
      "      policy_loss: -0.0003729661402758211\n",
      "      total_loss: 1020.7899780273438\n",
      "      vf_explained_var: 0.9568411111831665\n",
      "      vf_loss: 1020.7896728515625\n",
      "    sample_time_ms: 19387.159\n",
      "    update_time_ms: 6.008\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 434.6117384605272\n",
      "  time_since_restore: 8124.484806060791\n",
      "  time_this_iter_s: 23.99551796913147\n",
      "  time_total_s: 8124.484806060791\n",
      "  timestamp: 1553973898\n",
      "  timesteps_since_restore: 3440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3440000\n",
      "  training_iteration: 344\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8124 s, 344 iter, 3440000 ts, 869 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-25-22\n",
      "  done: false\n",
      "  episode_len_mean: 167.03\n",
      "  episode_reward_max: 1109.5518847133746\n",
      "  episode_reward_mean: 895.1794701077616\n",
      "  episode_reward_min: -79.52177971394588\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 20116\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.542\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 3450000\n",
      "    num_steps_trained: 3450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0719445943832397\n",
      "      kl: 0.015445999801158905\n",
      "      policy_loss: 0.001506336615420878\n",
      "      total_loss: 957.0718383789062\n",
      "      vf_explained_var: 0.9631967544555664\n",
      "      vf_loss: 957.0696411132812\n",
      "    sample_time_ms: 19475.302\n",
      "    update_time_ms: 5.735\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 447.5897350538809\n",
      "  time_since_restore: 8148.49426150322\n",
      "  time_this_iter_s: 24.00945544242859\n",
      "  time_total_s: 8148.49426150322\n",
      "  timestamp: 1553973922\n",
      "  timesteps_since_restore: 3450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3450000\n",
      "  training_iteration: 345\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8148 s, 345 iter, 3450000 ts, 895 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-25-46\n",
      "  done: false\n",
      "  episode_len_mean: 178.28\n",
      "  episode_reward_max: 1109.5518847133746\n",
      "  episode_reward_mean: 914.0228914000144\n",
      "  episode_reward_min: -79.52177971394588\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 20170\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.354\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 3460000\n",
      "    num_steps_trained: 3460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3079299926757812\n",
      "      kl: 0.014156460762023926\n",
      "      policy_loss: -0.0006875737453810871\n",
      "      total_loss: 220.6678466796875\n",
      "      vf_explained_var: 0.9903687834739685\n",
      "      vf_loss: 220.66786193847656\n",
      "    sample_time_ms: 19517.121\n",
      "    update_time_ms: 5.63\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.0114457000073\n",
      "  time_since_restore: 8172.363392114639\n",
      "  time_this_iter_s: 23.869130611419678\n",
      "  time_total_s: 8172.363392114639\n",
      "  timestamp: 1553973946\n",
      "  timesteps_since_restore: 3460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3460000\n",
      "  training_iteration: 346\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8172 s, 346 iter, 3460000 ts, 914 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-26-10\n",
      "  done: false\n",
      "  episode_len_mean: 172.21\n",
      "  episode_reward_max: 1085.084809064007\n",
      "  episode_reward_mean: 868.9468179755713\n",
      "  episode_reward_min: -97.45724820743716\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 20231\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.975\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 3470000\n",
      "    num_steps_trained: 3470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0962666273117065\n",
      "      kl: 0.016808846965432167\n",
      "      policy_loss: -0.00314564211294055\n",
      "      total_loss: 1410.7269287109375\n",
      "      vf_explained_var: 0.9452219009399414\n",
      "      vf_loss: 1410.7293701171875\n",
      "    sample_time_ms: 19535.648\n",
      "    update_time_ms: 5.62\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 434.47340898778566\n",
      "  time_since_restore: 8196.306343078613\n",
      "  time_this_iter_s: 23.942950963974\n",
      "  time_total_s: 8196.306343078613\n",
      "  timestamp: 1553973970\n",
      "  timesteps_since_restore: 3470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3470000\n",
      "  training_iteration: 347\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8196 s, 347 iter, 3470000 ts, 869 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-26-33\n",
      "  done: false\n",
      "  episode_len_mean: 171.37\n",
      "  episode_reward_max: 1127.9474315082275\n",
      "  episode_reward_mean: 871.5233091840139\n",
      "  episode_reward_min: -97.45724820743716\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 20288\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.253\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 3480000\n",
      "    num_steps_trained: 3480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3142250776290894\n",
      "      kl: 0.018809424713253975\n",
      "      policy_loss: -0.003638744819909334\n",
      "      total_loss: 607.1038208007812\n",
      "      vf_explained_var: 0.9747043251991272\n",
      "      vf_loss: 607.1065673828125\n",
      "    sample_time_ms: 19557.088\n",
      "    update_time_ms: 6.296\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 435.76165459200695\n",
      "  time_since_restore: 8219.386368751526\n",
      "  time_this_iter_s: 23.080025672912598\n",
      "  time_total_s: 8219.386368751526\n",
      "  timestamp: 1553973993\n",
      "  timesteps_since_restore: 3480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3480000\n",
      "  training_iteration: 348\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8219 s, 348 iter, 3480000 ts, 872 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-26-56\n",
      "  done: false\n",
      "  episode_len_mean: 178.88\n",
      "  episode_reward_max: 1127.9474315082275\n",
      "  episode_reward_mean: 895.2864457738335\n",
      "  episode_reward_min: -95.18769893622087\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 20344\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.065\n",
      "    load_time_ms: 1.613\n",
      "    num_steps_sampled: 3490000\n",
      "    num_steps_trained: 3490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2899937629699707\n",
      "      kl: 0.014317426830530167\n",
      "      policy_loss: -0.0028941596392542124\n",
      "      total_loss: 993.6815795898438\n",
      "      vf_explained_var: 0.9554265141487122\n",
      "      vf_loss: 993.6838989257812\n",
      "    sample_time_ms: 19523.473\n",
      "    update_time_ms: 6.538\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 447.64322288691676\n",
      "  time_since_restore: 8242.117893457413\n",
      "  time_this_iter_s: 22.73152470588684\n",
      "  time_total_s: 8242.117893457413\n",
      "  timestamp: 1553974016\n",
      "  timesteps_since_restore: 3490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3490000\n",
      "  training_iteration: 349\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8242 s, 349 iter, 3490000 ts, 895 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-27-20\n",
      "  done: false\n",
      "  episode_len_mean: 176.08\n",
      "  episode_reward_max: 1108.963774726755\n",
      "  episode_reward_mean: 910.7035795862093\n",
      "  episode_reward_min: -75.4090503132663\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 20401\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.475\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 3500000\n",
      "    num_steps_trained: 3500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0832200050354004\n",
      "      kl: 0.016756650060415268\n",
      "      policy_loss: -0.004115536343306303\n",
      "      total_loss: 745.8418579101562\n",
      "      vf_explained_var: 0.9679898023605347\n",
      "      vf_loss: 745.8452758789062\n",
      "    sample_time_ms: 19616.216\n",
      "    update_time_ms: 6.369\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 455.3517897931048\n",
      "  time_since_restore: 8266.38015460968\n",
      "  time_this_iter_s: 24.262261152267456\n",
      "  time_total_s: 8266.38015460968\n",
      "  timestamp: 1553974040\n",
      "  timesteps_since_restore: 3500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3500000\n",
      "  training_iteration: 350\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8266 s, 350 iter, 3500000 ts, 911 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-27-44\n",
      "  done: false\n",
      "  episode_len_mean: 172.48\n",
      "  episode_reward_max: 1122.3241120473754\n",
      "  episode_reward_mean: 900.7250993112345\n",
      "  episode_reward_min: -75.4090503132663\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 20460\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.791\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 3510000\n",
      "    num_steps_trained: 3510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0593249797821045\n",
      "      kl: 0.01826149970293045\n",
      "      policy_loss: -0.0015325796557590365\n",
      "      total_loss: 1180.312744140625\n",
      "      vf_explained_var: 0.9533184766769409\n",
      "      vf_loss: 1180.313720703125\n",
      "    sample_time_ms: 19686.799\n",
      "    update_time_ms: 6.066\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 450.36254965561733\n",
      "  time_since_restore: 8289.98834490776\n",
      "  time_this_iter_s: 23.608190298080444\n",
      "  time_total_s: 8289.98834490776\n",
      "  timestamp: 1553974064\n",
      "  timesteps_since_restore: 3510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3510000\n",
      "  training_iteration: 351\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8289 s, 351 iter, 3510000 ts, 901 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-28-07\n",
      "  done: false\n",
      "  episode_len_mean: 163.68\n",
      "  episode_reward_max: 1108.955805871844\n",
      "  episode_reward_mean: 896.6370122865916\n",
      "  episode_reward_min: -50.75179233436057\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 20522\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.859\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 3520000\n",
      "    num_steps_trained: 3520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9848312735557556\n",
      "      kl: 0.02308579348027706\n",
      "      policy_loss: -0.0039005104918032885\n",
      "      total_loss: 2001.3377685546875\n",
      "      vf_explained_var: 0.9167219996452332\n",
      "      vf_loss: 2001.340576171875\n",
      "    sample_time_ms: 19687.526\n",
      "    update_time_ms: 6.049\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 448.3185061432958\n",
      "  time_since_restore: 8313.454499721527\n",
      "  time_this_iter_s: 23.46615481376648\n",
      "  time_total_s: 8313.454499721527\n",
      "  timestamp: 1553974087\n",
      "  timesteps_since_restore: 3520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3520000\n",
      "  training_iteration: 352\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8313 s, 352 iter, 3520000 ts, 897 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-28-31\n",
      "  done: false\n",
      "  episode_len_mean: 169.08\n",
      "  episode_reward_max: 1108.955805871844\n",
      "  episode_reward_mean: 883.1034179883864\n",
      "  episode_reward_min: -50.75179233436057\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 20579\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.267\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 3530000\n",
      "    num_steps_trained: 3530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.276959776878357\n",
      "      kl: 0.011501015163958073\n",
      "      policy_loss: -0.0018863051664084196\n",
      "      total_loss: 884.4803466796875\n",
      "      vf_explained_var: 0.9593645930290222\n",
      "      vf_loss: 884.4817504882812\n",
      "    sample_time_ms: 19734.142\n",
      "    update_time_ms: 6.247\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 441.5517089941932\n",
      "  time_since_restore: 8337.1335978508\n",
      "  time_this_iter_s: 23.67909812927246\n",
      "  time_total_s: 8337.1335978508\n",
      "  timestamp: 1553974111\n",
      "  timesteps_since_restore: 3530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3530000\n",
      "  training_iteration: 353\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8337 s, 353 iter, 3530000 ts, 883 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-28-54\n",
      "  done: false\n",
      "  episode_len_mean: 169.36\n",
      "  episode_reward_max: 1170.8598626865592\n",
      "  episode_reward_mean: 878.2054873650893\n",
      "  episode_reward_min: -90.53018556262528\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 20638\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.597\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 3540000\n",
      "    num_steps_trained: 3540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1292932033538818\n",
      "      kl: 0.02152617648243904\n",
      "      policy_loss: -0.0029173928778618574\n",
      "      total_loss: 1179.53662109375\n",
      "      vf_explained_var: 0.9491128921508789\n",
      "      vf_loss: 1179.5384521484375\n",
      "    sample_time_ms: 19651.934\n",
      "    update_time_ms: 6.315\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 439.10274368254466\n",
      "  time_since_restore: 8360.280303239822\n",
      "  time_this_iter_s: 23.146705389022827\n",
      "  time_total_s: 8360.280303239822\n",
      "  timestamp: 1553974134\n",
      "  timesteps_since_restore: 3540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3540000\n",
      "  training_iteration: 354\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8360 s, 354 iter, 3540000 ts, 878 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-29-18\n",
      "  done: false\n",
      "  episode_len_mean: 173.81\n",
      "  episode_reward_max: 1089.7809145389015\n",
      "  episode_reward_mean: 915.2266529996709\n",
      "  episode_reward_min: -90.53018556262528\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 20694\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.273\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 3550000\n",
      "    num_steps_trained: 3550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.309068202972412\n",
      "      kl: 0.018800558522343636\n",
      "      policy_loss: -9.303597471443936e-05\n",
      "      total_loss: 515.5939331054688\n",
      "      vf_explained_var: 0.9789854288101196\n",
      "      vf_loss: 515.5932006835938\n",
      "    sample_time_ms: 19564.226\n",
      "    update_time_ms: 6.303\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.61332649983547\n",
      "  time_since_restore: 8383.348453521729\n",
      "  time_this_iter_s: 23.068150281906128\n",
      "  time_total_s: 8383.348453521729\n",
      "  timestamp: 1553974158\n",
      "  timesteps_since_restore: 3550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3550000\n",
      "  training_iteration: 355\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8383 s, 355 iter, 3550000 ts, 915 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-29-41\n",
      "  done: false\n",
      "  episode_len_mean: 171.61\n",
      "  episode_reward_max: 1104.9139302776302\n",
      "  episode_reward_mean: 922.3792104022203\n",
      "  episode_reward_min: -81.80232412042795\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 20754\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.623\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 3560000\n",
      "    num_steps_trained: 3560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1081866025924683\n",
      "      kl: 0.030675187706947327\n",
      "      policy_loss: 0.0005930720362812281\n",
      "      total_loss: 1023.7771606445312\n",
      "      vf_explained_var: 0.9541653394699097\n",
      "      vf_loss: 1023.775146484375\n",
      "    sample_time_ms: 19546.728\n",
      "    update_time_ms: 6.344\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 461.1896052011101\n",
      "  time_since_restore: 8407.046963691711\n",
      "  time_this_iter_s: 23.69851016998291\n",
      "  time_total_s: 8407.046963691711\n",
      "  timestamp: 1553974181\n",
      "  timesteps_since_restore: 3560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3560000\n",
      "  training_iteration: 356\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8407 s, 356 iter, 3560000 ts, 922 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-30-04\n",
      "  done: false\n",
      "  episode_len_mean: 164.78\n",
      "  episode_reward_max: 1123.6418559508913\n",
      "  episode_reward_mean: 874.6635350206734\n",
      "  episode_reward_min: -92.4175315163541\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 20816\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.267\n",
      "    load_time_ms: 1.447\n",
      "    num_steps_sampled: 3570000\n",
      "    num_steps_trained: 3570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.044630441814661026\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0907012224197388\n",
      "      kl: 0.00967077910900116\n",
      "      policy_loss: -0.0005983557784929872\n",
      "      total_loss: 1780.730712890625\n",
      "      vf_explained_var: 0.9275215268135071\n",
      "      vf_loss: 1780.731201171875\n",
      "    sample_time_ms: 19400.478\n",
      "    update_time_ms: 6.313\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 437.3317675103368\n",
      "  time_since_restore: 8429.443173885345\n",
      "  time_this_iter_s: 22.396210193634033\n",
      "  time_total_s: 8429.443173885345\n",
      "  timestamp: 1553974204\n",
      "  timesteps_since_restore: 3570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3570000\n",
      "  training_iteration: 357\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8429 s, 357 iter, 3570000 ts, 875 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-30-27\n",
      "  done: false\n",
      "  episode_len_mean: 164.57\n",
      "  episode_reward_max: 1139.48174650593\n",
      "  episode_reward_mean: 868.7498957689365\n",
      "  episode_reward_min: -92.4175315163541\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 20876\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.516\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 3580000\n",
      "    num_steps_trained: 3580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1113183498382568\n",
      "      kl: 0.021739263087511063\n",
      "      policy_loss: -0.0037833654787391424\n",
      "      total_loss: 544.3031616210938\n",
      "      vf_explained_var: 0.977603018283844\n",
      "      vf_loss: 544.3064575195312\n",
      "    sample_time_ms: 19412.875\n",
      "    update_time_ms: 5.646\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 434.37494788446816\n",
      "  time_since_restore: 8452.632922410965\n",
      "  time_this_iter_s: 23.189748525619507\n",
      "  time_total_s: 8452.632922410965\n",
      "  timestamp: 1553974227\n",
      "  timesteps_since_restore: 3580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3580000\n",
      "  training_iteration: 358\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8452 s, 358 iter, 3580000 ts, 869 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-30-50\n",
      "  done: false\n",
      "  episode_len_mean: 169.58\n",
      "  episode_reward_max: 1139.48174650593\n",
      "  episode_reward_mean: 900.4943983110522\n",
      "  episode_reward_min: -43.65034420627015\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 20935\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.853\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 3590000\n",
      "    num_steps_trained: 3590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0993115901947021\n",
      "      kl: 0.02066570334136486\n",
      "      policy_loss: -0.004507856909185648\n",
      "      total_loss: 1264.2457275390625\n",
      "      vf_explained_var: 0.9447931051254272\n",
      "      vf_loss: 1264.2496337890625\n",
      "    sample_time_ms: 19460.064\n",
      "    update_time_ms: 5.411\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 450.2471991555261\n",
      "  time_since_restore: 8475.918069839478\n",
      "  time_this_iter_s: 23.285147428512573\n",
      "  time_total_s: 8475.918069839478\n",
      "  timestamp: 1553974250\n",
      "  timesteps_since_restore: 3590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3590000\n",
      "  training_iteration: 359\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8475 s, 359 iter, 3590000 ts, 900 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 168.94\n",
      "  episode_reward_max: 1119.4181082121065\n",
      "  episode_reward_mean: 901.5046845808714\n",
      "  episode_reward_min: -71.49396812431067\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 20995\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.691\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 3600000\n",
      "    num_steps_trained: 3600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0507025718688965\n",
      "      kl: 0.02128433622419834\n",
      "      policy_loss: -0.0026556341908872128\n",
      "      total_loss: 817.6498413085938\n",
      "      vf_explained_var: 0.9647671580314636\n",
      "      vf_loss: 817.6519165039062\n",
      "    sample_time_ms: 19333.837\n",
      "    update_time_ms: 5.552\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 450.75234229043565\n",
      "  time_since_restore: 8498.9057803154\n",
      "  time_this_iter_s: 22.98771047592163\n",
      "  time_total_s: 8498.9057803154\n",
      "  timestamp: 1553974273\n",
      "  timesteps_since_restore: 3600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3600000\n",
      "  training_iteration: 360\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8498 s, 360 iter, 3600000 ts, 902 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-31-36\n",
      "  done: false\n",
      "  episode_len_mean: 174.09\n",
      "  episode_reward_max: 1102.6618585189574\n",
      "  episode_reward_mean: 941.5845417492399\n",
      "  episode_reward_min: -71.49396812431067\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 21050\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.306\n",
      "    load_time_ms: 1.396\n",
      "    num_steps_sampled: 3610000\n",
      "    num_steps_trained: 3610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.179356575012207\n",
      "      kl: 0.019378527998924255\n",
      "      policy_loss: -0.0036911184433847666\n",
      "      total_loss: 216.0802001953125\n",
      "      vf_explained_var: 0.9903900027275085\n",
      "      vf_loss: 216.08346557617188\n",
      "    sample_time_ms: 19267.73\n",
      "    update_time_ms: 5.601\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.79227087462\n",
      "  time_since_restore: 8521.898137807846\n",
      "  time_this_iter_s: 22.9923574924469\n",
      "  time_total_s: 8521.898137807846\n",
      "  timestamp: 1553974296\n",
      "  timesteps_since_restore: 3610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3610000\n",
      "  training_iteration: 361\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8521 s, 361 iter, 3610000 ts, 942 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-31-59\n",
      "  done: false\n",
      "  episode_len_mean: 171.37\n",
      "  episode_reward_max: 1163.5205815836325\n",
      "  episode_reward_mean: 955.9018123909258\n",
      "  episode_reward_min: -84.56933474198844\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 21109\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.905\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 3620000\n",
      "    num_steps_trained: 3620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0713183879852295\n",
      "      kl: 0.02382049523293972\n",
      "      policy_loss: -0.004112338647246361\n",
      "      total_loss: 841.7958984375\n",
      "      vf_explained_var: 0.9630165100097656\n",
      "      vf_loss: 841.7994995117188\n",
      "    sample_time_ms: 19205.818\n",
      "    update_time_ms: 5.658\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.9509061954629\n",
      "  time_since_restore: 8544.559857606888\n",
      "  time_this_iter_s: 22.661719799041748\n",
      "  time_total_s: 8544.559857606888\n",
      "  timestamp: 1553974319\n",
      "  timesteps_since_restore: 3620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3620000\n",
      "  training_iteration: 362\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8544 s, 362 iter, 3620000 ts, 956 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-32-22\n",
      "  done: false\n",
      "  episode_len_mean: 164.98\n",
      "  episode_reward_max: 1163.5205815836325\n",
      "  episode_reward_mean: 914.3126379661761\n",
      "  episode_reward_min: -84.56933474198844\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 21171\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.286\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 3630000\n",
      "    num_steps_trained: 3630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0313467979431152\n",
      "      kl: 0.012972326949238777\n",
      "      policy_loss: -0.002883418696001172\n",
      "      total_loss: 887.9768676757812\n",
      "      vf_explained_var: 0.964655339717865\n",
      "      vf_loss: 887.9793701171875\n",
      "    sample_time_ms: 19182.042\n",
      "    update_time_ms: 5.479\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.15631898308806\n",
      "  time_since_restore: 8567.984429121017\n",
      "  time_this_iter_s: 23.42457151412964\n",
      "  time_total_s: 8567.984429121017\n",
      "  timestamp: 1553974342\n",
      "  timesteps_since_restore: 3630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3630000\n",
      "  training_iteration: 363\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8567 s, 363 iter, 3630000 ts, 914 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-32-46\n",
      "  done: false\n",
      "  episode_len_mean: 165.8\n",
      "  episode_reward_max: 1133.4409142203526\n",
      "  episode_reward_mean: 866.4138187322901\n",
      "  episode_reward_min: -61.495338786250926\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 21230\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.801\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 3640000\n",
      "    num_steps_trained: 3640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.235494613647461\n",
      "      kl: 0.01390900183469057\n",
      "      policy_loss: -0.0010507020633667707\n",
      "      total_loss: 1025.535888671875\n",
      "      vf_explained_var: 0.9610057473182678\n",
      "      vf_loss: 1025.53662109375\n",
      "    sample_time_ms: 19199.802\n",
      "    update_time_ms: 5.28\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 433.2069093661451\n",
      "  time_since_restore: 8591.315402269363\n",
      "  time_this_iter_s: 23.330973148345947\n",
      "  time_total_s: 8591.315402269363\n",
      "  timestamp: 1553974366\n",
      "  timesteps_since_restore: 3640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3640000\n",
      "  training_iteration: 364\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8591 s, 364 iter, 3640000 ts, 866 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-33-10\n",
      "  done: false\n",
      "  episode_len_mean: 168.0\n",
      "  episode_reward_max: 1089.9654336236251\n",
      "  episode_reward_mean: 899.2677061771437\n",
      "  episode_reward_min: -78.36383354198352\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 21290\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.829\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 3650000\n",
      "    num_steps_trained: 3650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1447663307189941\n",
      "      kl: 0.01677439548075199\n",
      "      policy_loss: -0.002222235780209303\n",
      "      total_loss: 1039.0196533203125\n",
      "      vf_explained_var: 0.9535458087921143\n",
      "      vf_loss: 1039.0216064453125\n",
      "    sample_time_ms: 19288.177\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 449.63385308857175\n",
      "  time_since_restore: 8615.438819408417\n",
      "  time_this_iter_s: 24.123417139053345\n",
      "  time_total_s: 8615.438819408417\n",
      "  timestamp: 1553974390\n",
      "  timesteps_since_restore: 3650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3650000\n",
      "  training_iteration: 365\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8615 s, 365 iter, 3650000 ts, 899 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-33-33\n",
      "  done: false\n",
      "  episode_len_mean: 166.73\n",
      "  episode_reward_max: 1175.7482337564734\n",
      "  episode_reward_mean: 887.733436648617\n",
      "  episode_reward_min: -67.48092119573852\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 21351\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.349\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 3660000\n",
      "    num_steps_trained: 3660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0616528987884521\n",
      "      kl: 0.017888525500893593\n",
      "      policy_loss: -0.0019167920108884573\n",
      "      total_loss: 1648.4210205078125\n",
      "      vf_explained_var: 0.9335827827453613\n",
      "      vf_loss: 1648.4222412109375\n",
      "    sample_time_ms: 19228.888\n",
      "    update_time_ms: 5.346\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 443.86671832430847\n",
      "  time_since_restore: 8638.507854223251\n",
      "  time_this_iter_s: 23.069034814834595\n",
      "  time_total_s: 8638.507854223251\n",
      "  timestamp: 1553974413\n",
      "  timesteps_since_restore: 3660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3660000\n",
      "  training_iteration: 366\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8638 s, 366 iter, 3660000 ts, 888 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-33-57\n",
      "  done: false\n",
      "  episode_len_mean: 168.56\n",
      "  episode_reward_max: 1166.3595500308656\n",
      "  episode_reward_mean: 870.6225059351391\n",
      "  episode_reward_min: -76.39112507053336\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 21407\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.287\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 3670000\n",
      "    num_steps_trained: 3670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1770823001861572\n",
      "      kl: 0.018588872626423836\n",
      "      policy_loss: -0.0033220022451132536\n",
      "      total_loss: 919.2083129882812\n",
      "      vf_explained_var: 0.9615269303321838\n",
      "      vf_loss: 919.2113647460938\n",
      "    sample_time_ms: 19372.366\n",
      "    update_time_ms: 5.4\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 435.31125296756954\n",
      "  time_since_restore: 8662.448793172836\n",
      "  time_this_iter_s: 23.94093894958496\n",
      "  time_total_s: 8662.448793172836\n",
      "  timestamp: 1553974437\n",
      "  timesteps_since_restore: 3670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3670000\n",
      "  training_iteration: 367\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8662 s, 367 iter, 3670000 ts, 871 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-34-20\n",
      "  done: false\n",
      "  episode_len_mean: 172.26\n",
      "  episode_reward_max: 1166.3595500308656\n",
      "  episode_reward_mean: 917.5839820722401\n",
      "  episode_reward_min: -76.39112507053336\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 21465\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.756\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 3680000\n",
      "    num_steps_trained: 3680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1903326511383057\n",
      "      kl: 0.013406953774392605\n",
      "      policy_loss: -0.002265416318550706\n",
      "      total_loss: 660.2943725585938\n",
      "      vf_explained_var: 0.9720182418823242\n",
      "      vf_loss: 660.29638671875\n",
      "    sample_time_ms: 19350.854\n",
      "    update_time_ms: 5.291\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 458.79199103612007\n",
      "  time_since_restore: 8685.44720029831\n",
      "  time_this_iter_s: 22.998407125473022\n",
      "  time_total_s: 8685.44720029831\n",
      "  timestamp: 1553974460\n",
      "  timesteps_since_restore: 3680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3680000\n",
      "  training_iteration: 368\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8685 s, 368 iter, 3680000 ts, 918 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-34-43\n",
      "  done: false\n",
      "  episode_len_mean: 176.18\n",
      "  episode_reward_max: 1132.5836401312963\n",
      "  episode_reward_mean: 939.2336556717647\n",
      "  episode_reward_min: -69.18956818695844\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 21525\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.584\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 3690000\n",
      "    num_steps_trained: 3690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.199527621269226\n",
      "      kl: 0.018171194940805435\n",
      "      policy_loss: -0.001962175127118826\n",
      "      total_loss: 603.9729614257812\n",
      "      vf_explained_var: 0.9737744331359863\n",
      "      vf_loss: 603.9744873046875\n",
      "    sample_time_ms: 19355.046\n",
      "    update_time_ms: 5.32\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.6168278358824\n",
      "  time_since_restore: 8708.755457639694\n",
      "  time_this_iter_s: 23.308257341384888\n",
      "  time_total_s: 8708.755457639694\n",
      "  timestamp: 1553974483\n",
      "  timesteps_since_restore: 3690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3690000\n",
      "  training_iteration: 369\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8708 s, 369 iter, 3690000 ts, 939 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-35-08\n",
      "  done: false\n",
      "  episode_len_mean: 172.23\n",
      "  episode_reward_max: 1163.510600925916\n",
      "  episode_reward_mean: 954.1762699367491\n",
      "  episode_reward_min: -69.18956818695844\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 21582\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.149\n",
      "    load_time_ms: 1.621\n",
      "    num_steps_sampled: 3700000\n",
      "    num_steps_trained: 3700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0877267122268677\n",
      "      kl: 0.015543794259428978\n",
      "      policy_loss: -0.002123774727806449\n",
      "      total_loss: 617.1732177734375\n",
      "      vf_explained_var: 0.9744067788124084\n",
      "      vf_loss: 617.1749877929688\n",
      "    sample_time_ms: 19448.907\n",
      "    update_time_ms: 5.181\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.08813496837456\n",
      "  time_since_restore: 8732.879183292389\n",
      "  time_this_iter_s: 24.123725652694702\n",
      "  time_total_s: 8732.879183292389\n",
      "  timestamp: 1553974508\n",
      "  timesteps_since_restore: 3700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3700000\n",
      "  training_iteration: 370\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8732 s, 370 iter, 3700000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-35-31\n",
      "  done: false\n",
      "  episode_len_mean: 180.33\n",
      "  episode_reward_max: 1151.1880022691194\n",
      "  episode_reward_mean: 962.3364388041509\n",
      "  episode_reward_min: -88.30079293730064\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 21636\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3925.494\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 3710000\n",
      "    num_steps_trained: 3710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2372379302978516\n",
      "      kl: 0.021184012293815613\n",
      "      policy_loss: -0.0027120052836835384\n",
      "      total_loss: 394.8152160644531\n",
      "      vf_explained_var: 0.9825742840766907\n",
      "      vf_loss: 394.81744384765625\n",
      "    sample_time_ms: 19476.466\n",
      "    update_time_ms: 5.096\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.1682194020756\n",
      "  time_since_restore: 8756.160989999771\n",
      "  time_this_iter_s: 23.281806707382202\n",
      "  time_total_s: 8756.160989999771\n",
      "  timestamp: 1553974531\n",
      "  timesteps_since_restore: 3710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3710000\n",
      "  training_iteration: 371\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8756 s, 371 iter, 3710000 ts, 962 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-35-55\n",
      "  done: false\n",
      "  episode_len_mean: 177.28\n",
      "  episode_reward_max: 1149.8649888516643\n",
      "  episode_reward_mean: 958.8679536302338\n",
      "  episode_reward_min: -88.30079293730064\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 21694\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.469\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 3720000\n",
      "    num_steps_trained: 3720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1035668849945068\n",
      "      kl: 0.03205983340740204\n",
      "      policy_loss: -0.004269206430763006\n",
      "      total_loss: 729.9974975585938\n",
      "      vf_explained_var: 0.9685615301132202\n",
      "      vf_loss: 730.0010986328125\n",
      "    sample_time_ms: 19614.981\n",
      "    update_time_ms: 5.101\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.43397681511686\n",
      "  time_since_restore: 8780.196611404419\n",
      "  time_this_iter_s: 24.035621404647827\n",
      "  time_total_s: 8780.196611404419\n",
      "  timestamp: 1553974555\n",
      "  timesteps_since_restore: 3720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3720000\n",
      "  training_iteration: 372\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8780 s, 372 iter, 3720000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-36-19\n",
      "  done: false\n",
      "  episode_len_mean: 173.94\n",
      "  episode_reward_max: 1149.8649888516643\n",
      "  episode_reward_mean: 930.5121226589895\n",
      "  episode_reward_min: -33.970196839958106\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 21751\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3923.067\n",
      "    load_time_ms: 1.449\n",
      "    num_steps_sampled: 3730000\n",
      "    num_steps_trained: 3730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1696969270706177\n",
      "      kl: 0.018251491710543633\n",
      "      policy_loss: -0.0045995209366083145\n",
      "      total_loss: 528.05517578125\n",
      "      vf_explained_var: 0.9760671854019165\n",
      "      vf_loss: 528.0593872070312\n",
      "    sample_time_ms: 19663.452\n",
      "    update_time_ms: 5.382\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 465.25606132949474\n",
      "  time_since_restore: 8804.093122243881\n",
      "  time_this_iter_s: 23.89651083946228\n",
      "  time_total_s: 8804.093122243881\n",
      "  timestamp: 1553974579\n",
      "  timesteps_since_restore: 3730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3730000\n",
      "  training_iteration: 373\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8804 s, 373 iter, 3730000 ts, 931 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-36-42\n",
      "  done: false\n",
      "  episode_len_mean: 181.33\n",
      "  episode_reward_max: 1148.17644343087\n",
      "  episode_reward_mean: 921.1134305372703\n",
      "  episode_reward_min: -30.32496424070004\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 21805\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.307\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 3740000\n",
      "    num_steps_trained: 3740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.290733814239502\n",
      "      kl: 0.016017822548747063\n",
      "      policy_loss: -0.0015288946451619267\n",
      "      total_loss: 700.46630859375\n",
      "      vf_explained_var: 0.9684072732925415\n",
      "      vf_loss: 700.4674682617188\n",
      "    sample_time_ms: 19648.056\n",
      "    update_time_ms: 5.383\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 460.5567152686353\n",
      "  time_since_restore: 8827.278518676758\n",
      "  time_this_iter_s: 23.185396432876587\n",
      "  time_total_s: 8827.278518676758\n",
      "  timestamp: 1553974602\n",
      "  timesteps_since_restore: 3740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3740000\n",
      "  training_iteration: 374\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8827 s, 374 iter, 3740000 ts, 921 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-37-05\n",
      "  done: false\n",
      "  episode_len_mean: 174.66\n",
      "  episode_reward_max: 1148.17644343087\n",
      "  episode_reward_mean: 909.5373371780937\n",
      "  episode_reward_min: -91.13606899203029\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 21866\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.858\n",
      "    load_time_ms: 1.438\n",
      "    num_steps_sampled: 3750000\n",
      "    num_steps_trained: 3750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0840359926223755\n",
      "      kl: 0.016295718029141426\n",
      "      policy_loss: -0.0033100969158113003\n",
      "      total_loss: 1297.6397705078125\n",
      "      vf_explained_var: 0.9474561810493469\n",
      "      vf_loss: 1297.6427001953125\n",
      "    sample_time_ms: 19540.627\n",
      "    update_time_ms: 5.228\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 454.76866858904685\n",
      "  time_since_restore: 8850.163697242737\n",
      "  time_this_iter_s: 22.885178565979004\n",
      "  time_total_s: 8850.163697242737\n",
      "  timestamp: 1553974625\n",
      "  timesteps_since_restore: 3750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3750000\n",
      "  training_iteration: 375\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8850 s, 375 iter, 3750000 ts, 910 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-37-28\n",
      "  done: false\n",
      "  episode_len_mean: 167.7\n",
      "  episode_reward_max: 1114.7174442742885\n",
      "  episode_reward_mean: 880.8150955614964\n",
      "  episode_reward_min: -61.34088508140303\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 21925\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.997\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 3760000\n",
      "    num_steps_trained: 3760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1080412864685059\n",
      "      kl: 0.014094269834458828\n",
      "      policy_loss: 0.0003620424249675125\n",
      "      total_loss: 1505.065673828125\n",
      "      vf_explained_var: 0.9409594535827637\n",
      "      vf_loss: 1505.0650634765625\n",
      "    sample_time_ms: 19555.395\n",
      "    update_time_ms: 5.278\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 440.4075477807483\n",
      "  time_since_restore: 8873.454024076462\n",
      "  time_this_iter_s: 23.290326833724976\n",
      "  time_total_s: 8873.454024076462\n",
      "  timestamp: 1553974648\n",
      "  timesteps_since_restore: 3760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3760000\n",
      "  training_iteration: 376\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8873 s, 376 iter, 3760000 ts, 881 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-37-52\n",
      "  done: false\n",
      "  episode_len_mean: 167.75\n",
      "  episode_reward_max: 1101.3305775928743\n",
      "  episode_reward_mean: 864.3533466756323\n",
      "  episode_reward_min: -79.66179689443887\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 21982\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.002\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 3770000\n",
      "    num_steps_trained: 3770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.187877893447876\n",
      "      kl: 0.01271461695432663\n",
      "      policy_loss: -0.002170150401070714\n",
      "      total_loss: 868.1654663085938\n",
      "      vf_explained_var: 0.9639715552330017\n",
      "      vf_loss: 868.16748046875\n",
      "    sample_time_ms: 19545.851\n",
      "    update_time_ms: 5.334\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 432.17667333781617\n",
      "  time_since_restore: 8897.162487506866\n",
      "  time_this_iter_s: 23.708463430404663\n",
      "  time_total_s: 8897.162487506866\n",
      "  timestamp: 1553974672\n",
      "  timesteps_since_restore: 3770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3770000\n",
      "  training_iteration: 377\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8897 s, 377 iter, 3770000 ts, 864 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-38-15\n",
      "  done: false\n",
      "  episode_len_mean: 173.82\n",
      "  episode_reward_max: 1157.7199193085623\n",
      "  episode_reward_mean: 932.8577918622988\n",
      "  episode_reward_min: -54.93861413033764\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 22040\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.959\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 3780000\n",
      "    num_steps_trained: 3780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1000771522521973\n",
      "      kl: 0.014830050058662891\n",
      "      policy_loss: -0.0006885750335641205\n",
      "      total_loss: 863.1599731445312\n",
      "      vf_explained_var: 0.9626157879829407\n",
      "      vf_loss: 863.1603393554688\n",
      "    sample_time_ms: 19572.385\n",
      "    update_time_ms: 5.504\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.4288959311493\n",
      "  time_since_restore: 8920.39637351036\n",
      "  time_this_iter_s: 23.233886003494263\n",
      "  time_total_s: 8920.39637351036\n",
      "  timestamp: 1553974695\n",
      "  timesteps_since_restore: 3780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3780000\n",
      "  training_iteration: 378\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8920 s, 378 iter, 3780000 ts, 933 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-38-39\n",
      "  done: false\n",
      "  episode_len_mean: 177.14\n",
      "  episode_reward_max: 1157.7199193085623\n",
      "  episode_reward_mean: 895.8934137046032\n",
      "  episode_reward_min: -15.32286589277507\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 22096\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3926.783\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 3790000\n",
      "    num_steps_trained: 3790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1854639053344727\n",
      "      kl: 0.01672450639307499\n",
      "      policy_loss: -0.003182206302881241\n",
      "      total_loss: 1326.3974609375\n",
      "      vf_explained_var: 0.9489495754241943\n",
      "      vf_loss: 1326.400390625\n",
      "    sample_time_ms: 19584.247\n",
      "    update_time_ms: 5.42\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 447.94670685230165\n",
      "  time_since_restore: 8944.106257915497\n",
      "  time_this_iter_s: 23.70988440513611\n",
      "  time_total_s: 8944.106257915497\n",
      "  timestamp: 1553974719\n",
      "  timesteps_since_restore: 3790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3790000\n",
      "  training_iteration: 379\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8944 s, 379 iter, 3790000 ts, 896 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-39-03\n",
      "  done: false\n",
      "  episode_len_mean: 174.95\n",
      "  episode_reward_max: 1137.3581795805758\n",
      "  episode_reward_mean: 891.8741579317262\n",
      "  episode_reward_min: -68.00405436790058\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 22154\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.921\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 3800000\n",
      "    num_steps_trained: 3800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1259812116622925\n",
      "      kl: 0.01425081305205822\n",
      "      policy_loss: -0.0020407342817634344\n",
      "      total_loss: 874.0821533203125\n",
      "      vf_explained_var: 0.9618838429450989\n",
      "      vf_loss: 874.0838623046875\n",
      "    sample_time_ms: 19595.648\n",
      "    update_time_ms: 5.59\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 445.9370789658632\n",
      "  time_since_restore: 8968.196293115616\n",
      "  time_this_iter_s: 24.09003520011902\n",
      "  time_total_s: 8968.196293115616\n",
      "  timestamp: 1553974743\n",
      "  timesteps_since_restore: 3800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3800000\n",
      "  training_iteration: 380\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8968 s, 380 iter, 3800000 ts, 892 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-39-26\n",
      "  done: false\n",
      "  episode_len_mean: 174.49\n",
      "  episode_reward_max: 1137.3581795805758\n",
      "  episode_reward_mean: 925.0935294442811\n",
      "  episode_reward_min: -86.13765583603548\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 22211\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.215\n",
      "    load_time_ms: 1.395\n",
      "    num_steps_sampled: 3810000\n",
      "    num_steps_trained: 3810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0670971870422363\n",
      "      kl: 0.018551954999566078\n",
      "      policy_loss: -0.002004000125452876\n",
      "      total_loss: 1013.69091796875\n",
      "      vf_explained_var: 0.9554594159126282\n",
      "      vf_loss: 1013.6925048828125\n",
      "    sample_time_ms: 19565.807\n",
      "    update_time_ms: 5.794\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 462.5467647221405\n",
      "  time_since_restore: 8991.152638673782\n",
      "  time_this_iter_s: 22.956345558166504\n",
      "  time_total_s: 8991.152638673782\n",
      "  timestamp: 1553974766\n",
      "  timesteps_since_restore: 3810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3810000\n",
      "  training_iteration: 381\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 8991 s, 381 iter, 3810000 ts, 925 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-39-50\n",
      "  done: false\n",
      "  episode_len_mean: 165.32\n",
      "  episode_reward_max: 1122.3897761147548\n",
      "  episode_reward_mean: 905.7583216933339\n",
      "  episode_reward_min: -99.594014203219\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 22272\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.894\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 3820000\n",
      "    num_steps_trained: 3820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9074607491493225\n",
      "      kl: 0.015545318834483624\n",
      "      policy_loss: -0.001616563880816102\n",
      "      total_loss: 1120.7403564453125\n",
      "      vf_explained_var: 0.9563973546028137\n",
      "      vf_loss: 1120.7415771484375\n",
      "    sample_time_ms: 19475.449\n",
      "    update_time_ms: 5.713\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.87916084666693\n",
      "  time_since_restore: 9014.305331230164\n",
      "  time_this_iter_s: 23.152692556381226\n",
      "  time_total_s: 9014.305331230164\n",
      "  timestamp: 1553974790\n",
      "  timesteps_since_restore: 3820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3820000\n",
      "  training_iteration: 382\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9014 s, 382 iter, 3820000 ts, 906 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-40-13\n",
      "  done: false\n",
      "  episode_len_mean: 168.78\n",
      "  episode_reward_max: 1148.527766806066\n",
      "  episode_reward_mean: 947.2729386385265\n",
      "  episode_reward_min: -21.105268227805794\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 22331\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.051\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 3830000\n",
      "    num_steps_trained: 3830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8918781876564026\n",
      "      kl: 0.016384372487664223\n",
      "      policy_loss: -0.0012552262051030993\n",
      "      total_loss: 578.2453002929688\n",
      "      vf_explained_var: 0.9763044714927673\n",
      "      vf_loss: 578.2462158203125\n",
      "    sample_time_ms: 19397.913\n",
      "    update_time_ms: 5.476\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.63646931926326\n",
      "  time_since_restore: 9037.406232357025\n",
      "  time_this_iter_s: 23.100901126861572\n",
      "  time_total_s: 9037.406232357025\n",
      "  timestamp: 1553974813\n",
      "  timesteps_since_restore: 3830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3830000\n",
      "  training_iteration: 383\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9037 s, 383 iter, 3830000 ts, 947 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-40-36\n",
      "  done: false\n",
      "  episode_len_mean: 172.58\n",
      "  episode_reward_max: 1148.527766806066\n",
      "  episode_reward_mean: 913.4591819217735\n",
      "  episode_reward_min: -85.2400401122252\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 22388\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.67\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 3840000\n",
      "    num_steps_trained: 3840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0974674224853516\n",
      "      kl: 0.01785281114280224\n",
      "      policy_loss: -0.0060989041812717915\n",
      "      total_loss: 1157.7552490234375\n",
      "      vf_explained_var: 0.9491370916366577\n",
      "      vf_loss: 1157.7608642578125\n",
      "    sample_time_ms: 19411.752\n",
      "    update_time_ms: 5.436\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 456.7295909608867\n",
      "  time_since_restore: 9060.758316993713\n",
      "  time_this_iter_s: 23.352084636688232\n",
      "  time_total_s: 9060.758316993713\n",
      "  timestamp: 1553974836\n",
      "  timesteps_since_restore: 3840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3840000\n",
      "  training_iteration: 384\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9060 s, 384 iter, 3840000 ts, 913 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-40-59\n",
      "  done: false\n",
      "  episode_len_mean: 168.35\n",
      "  episode_reward_max: 1118.946557926709\n",
      "  episode_reward_mean: 879.2131805739024\n",
      "  episode_reward_min: -85.2400401122252\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 22450\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.07\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 3850000\n",
      "    num_steps_trained: 3850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1236335039138794\n",
      "      kl: 0.01725088618695736\n",
      "      policy_loss: -0.00433792220428586\n",
      "      total_loss: 1727.441162109375\n",
      "      vf_explained_var: 0.9266921877861023\n",
      "      vf_loss: 1727.445068359375\n",
      "    sample_time_ms: 19416.12\n",
      "    update_time_ms: 5.618\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 439.6065902869512\n",
      "  time_since_restore: 9083.74150967598\n",
      "  time_this_iter_s: 22.983192682266235\n",
      "  time_total_s: 9083.74150967598\n",
      "  timestamp: 1553974859\n",
      "  timesteps_since_restore: 3850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3850000\n",
      "  training_iteration: 385\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9083 s, 385 iter, 3850000 ts, 879 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-41-23\n",
      "  done: false\n",
      "  episode_len_mean: 172.36\n",
      "  episode_reward_max: 1118.946557926709\n",
      "  episode_reward_mean: 912.9810447971022\n",
      "  episode_reward_min: -73.9172025022268\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 22506\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.954\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 3860000\n",
      "    num_steps_trained: 3860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0542833805084229\n",
      "      kl: 0.01593002863228321\n",
      "      policy_loss: -0.0039682211354374886\n",
      "      total_loss: 437.9085388183594\n",
      "      vf_explained_var: 0.980452299118042\n",
      "      vf_loss: 437.9122009277344\n",
      "    sample_time_ms: 19432.01\n",
      "    update_time_ms: 6.047\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 456.4905223985511\n",
      "  time_since_restore: 9107.151644229889\n",
      "  time_this_iter_s: 23.4101345539093\n",
      "  time_total_s: 9107.151644229889\n",
      "  timestamp: 1553974883\n",
      "  timesteps_since_restore: 3860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3860000\n",
      "  training_iteration: 386\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9107 s, 386 iter, 3860000 ts, 913 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-41-46\n",
      "  done: false\n",
      "  episode_len_mean: 177.17\n",
      "  episode_reward_max: 1112.8919522041667\n",
      "  episode_reward_mean: 944.4130819884922\n",
      "  episode_reward_min: -52.992003988247745\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 22564\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.226\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 3870000\n",
      "    num_steps_trained: 3870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.922739565372467\n",
      "      kl: 0.015141477808356285\n",
      "      policy_loss: -0.0008775587775744498\n",
      "      total_loss: 655.2643432617188\n",
      "      vf_explained_var: 0.973513662815094\n",
      "      vf_loss: 655.2649536132812\n",
      "    sample_time_ms: 19393.123\n",
      "    update_time_ms: 6.313\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.20654099424604\n",
      "  time_since_restore: 9130.475811719894\n",
      "  time_this_iter_s: 23.324167490005493\n",
      "  time_total_s: 9130.475811719894\n",
      "  timestamp: 1553974906\n",
      "  timesteps_since_restore: 3870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3870000\n",
      "  training_iteration: 387\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9130 s, 387 iter, 3870000 ts, 944 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-42-10\n",
      "  done: false\n",
      "  episode_len_mean: 166.63\n",
      "  episode_reward_max: 1145.7843664740128\n",
      "  episode_reward_mean: 906.9636115130915\n",
      "  episode_reward_min: -87.42112302839797\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 22625\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3925.08\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 3880000\n",
      "    num_steps_trained: 3880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.027400255203247\n",
      "      kl: 0.014170601032674313\n",
      "      policy_loss: -0.0017527234740555286\n",
      "      total_loss: 1181.037841796875\n",
      "      vf_explained_var: 0.9538179039955139\n",
      "      vf_loss: 1181.039306640625\n",
      "    sample_time_ms: 19426.828\n",
      "    update_time_ms: 6.219\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 453.48180575654567\n",
      "  time_since_restore: 9154.166446685791\n",
      "  time_this_iter_s: 23.690634965896606\n",
      "  time_total_s: 9154.166446685791\n",
      "  timestamp: 1553974930\n",
      "  timesteps_since_restore: 3880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3880000\n",
      "  training_iteration: 388\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9154 s, 388 iter, 3880000 ts, 907 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-42-33\n",
      "  done: false\n",
      "  episode_len_mean: 165.28\n",
      "  episode_reward_max: 1111.4882208838665\n",
      "  episode_reward_mean: 899.117832511939\n",
      "  episode_reward_min: -87.42112302839797\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 22685\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.142\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 3890000\n",
      "    num_steps_trained: 3890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.023489236831665\n",
      "      kl: 0.015137267298996449\n",
      "      policy_loss: -0.0011424452532082796\n",
      "      total_loss: 804.9637451171875\n",
      "      vf_explained_var: 0.9668719172477722\n",
      "      vf_loss: 804.9645385742188\n",
      "    sample_time_ms: 19420.014\n",
      "    update_time_ms: 6.508\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 449.55891625596945\n",
      "  time_since_restore: 9177.57336974144\n",
      "  time_this_iter_s: 23.406923055648804\n",
      "  time_total_s: 9177.57336974144\n",
      "  timestamp: 1553974953\n",
      "  timesteps_since_restore: 3890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3890000\n",
      "  training_iteration: 389\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9177 s, 389 iter, 3890000 ts, 899 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-42-57\n",
      "  done: false\n",
      "  episode_len_mean: 170.93\n",
      "  episode_reward_max: 1150.4874599175241\n",
      "  episode_reward_mean: 948.079027377832\n",
      "  episode_reward_min: -77.48562256306168\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 22744\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.569\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 3900000\n",
      "    num_steps_trained: 3900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9961903691291809\n",
      "      kl: 0.015368788503110409\n",
      "      policy_loss: -0.0022170650772750378\n",
      "      total_loss: 726.6397705078125\n",
      "      vf_explained_var: 0.9678517580032349\n",
      "      vf_loss: 726.6416015625\n",
      "    sample_time_ms: 19367.388\n",
      "    update_time_ms: 6.292\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.0395136889159\n",
      "  time_since_restore: 9201.120878458023\n",
      "  time_this_iter_s: 23.547508716583252\n",
      "  time_total_s: 9201.120878458023\n",
      "  timestamp: 1553974977\n",
      "  timesteps_since_restore: 3900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3900000\n",
      "  training_iteration: 390\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9201 s, 390 iter, 3900000 ts, 948 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 177.04\n",
      "  episode_reward_max: 1150.4874599175241\n",
      "  episode_reward_mean: 943.0531686831064\n",
      "  episode_reward_min: -81.81128506189145\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 22798\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.649\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 3910000\n",
      "    num_steps_trained: 3910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.040661334991455\n",
      "      kl: 0.01669672504067421\n",
      "      policy_loss: -0.0013317653210833669\n",
      "      total_loss: 837.9676513671875\n",
      "      vf_explained_var: 0.9618388414382935\n",
      "      vf_loss: 837.9686279296875\n",
      "    sample_time_ms: 19424.552\n",
      "    update_time_ms: 6.111\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.52658434155325\n",
      "  time_since_restore: 9224.628809452057\n",
      "  time_this_iter_s: 23.507930994033813\n",
      "  time_total_s: 9224.628809452057\n",
      "  timestamp: 1553975000\n",
      "  timesteps_since_restore: 3910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3910000\n",
      "  training_iteration: 391\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9224 s, 391 iter, 3910000 ts, 943 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-43-44\n",
      "  done: false\n",
      "  episode_len_mean: 180.37\n",
      "  episode_reward_max: 1140.7813285344207\n",
      "  episode_reward_mean: 915.804241146343\n",
      "  episode_reward_min: -81.81128506189145\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 22855\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.517\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 3920000\n",
      "    num_steps_trained: 3920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0542340278625488\n",
      "      kl: 0.012689527124166489\n",
      "      policy_loss: -0.0017321568448096514\n",
      "      total_loss: 781.6630859375\n",
      "      vf_explained_var: 0.9676709175109863\n",
      "      vf_loss: 781.6644897460938\n",
      "    sample_time_ms: 19439.971\n",
      "    update_time_ms: 6.155\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.9021205731715\n",
      "  time_since_restore: 9247.902257204056\n",
      "  time_this_iter_s: 23.2734477519989\n",
      "  time_total_s: 9247.902257204056\n",
      "  timestamp: 1553975024\n",
      "  timesteps_since_restore: 3920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3920000\n",
      "  training_iteration: 392\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9247 s, 392 iter, 3920000 ts, 916 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-44-07\n",
      "  done: false\n",
      "  episode_len_mean: 175.18\n",
      "  episode_reward_max: 1137.7979126827306\n",
      "  episode_reward_mean: 937.2172488009857\n",
      "  episode_reward_min: -86.8097798230378\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 22911\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.703\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 3930000\n",
      "    num_steps_trained: 3930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9866213798522949\n",
      "      kl: 0.01982724666595459\n",
      "      policy_loss: -0.0040996260941028595\n",
      "      total_loss: 594.8237915039062\n",
      "      vf_explained_var: 0.9758561253547668\n",
      "      vf_loss: 594.8275146484375\n",
      "    sample_time_ms: 19480.083\n",
      "    update_time_ms: 6.095\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.60862440049283\n",
      "  time_since_restore: 9271.636969089508\n",
      "  time_this_iter_s: 23.73471188545227\n",
      "  time_total_s: 9271.636969089508\n",
      "  timestamp: 1553975047\n",
      "  timesteps_since_restore: 3930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3930000\n",
      "  training_iteration: 393\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9271 s, 393 iter, 3930000 ts, 937 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-44-30\n",
      "  done: false\n",
      "  episode_len_mean: 172.94\n",
      "  episode_reward_max: 1132.7470574110669\n",
      "  episode_reward_mean: 907.8267489252999\n",
      "  episode_reward_min: -49.0761977747548\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 22971\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.715\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 3940000\n",
      "    num_steps_trained: 3940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9944230318069458\n",
      "      kl: 0.01888198032975197\n",
      "      policy_loss: -0.0023345022927969694\n",
      "      total_loss: 1210.2474365234375\n",
      "      vf_explained_var: 0.950833261013031\n",
      "      vf_loss: 1210.2491455078125\n",
      "    sample_time_ms: 19457.116\n",
      "    update_time_ms: 6.263\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 453.9133744626499\n",
      "  time_since_restore: 9294.772115468979\n",
      "  time_this_iter_s: 23.135146379470825\n",
      "  time_total_s: 9294.772115468979\n",
      "  timestamp: 1553975070\n",
      "  timesteps_since_restore: 3940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3940000\n",
      "  training_iteration: 394\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9294 s, 394 iter, 3940000 ts, 908 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-44-54\n",
      "  done: false\n",
      "  episode_len_mean: 175.64\n",
      "  episode_reward_max: 1132.7470574110669\n",
      "  episode_reward_mean: 914.9405158562823\n",
      "  episode_reward_min: -49.0761977747548\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 23025\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.326\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 3950000\n",
      "    num_steps_trained: 3950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0988293886184692\n",
      "      kl: 0.01612469181418419\n",
      "      policy_loss: -0.0018765830900520086\n",
      "      total_loss: 688.9654541015625\n",
      "      vf_explained_var: 0.9705450534820557\n",
      "      vf_loss: 688.9669189453125\n",
      "    sample_time_ms: 19502.147\n",
      "    update_time_ms: 6.402\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.47025792814105\n",
      "  time_since_restore: 9318.150527000427\n",
      "  time_this_iter_s: 23.378411531448364\n",
      "  time_total_s: 9318.150527000427\n",
      "  timestamp: 1553975094\n",
      "  timesteps_since_restore: 3950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3950000\n",
      "  training_iteration: 395\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9318 s, 395 iter, 3950000 ts, 915 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-45-17\n",
      "  done: false\n",
      "  episode_len_mean: 170.34\n",
      "  episode_reward_max: 1110.3476522223593\n",
      "  episode_reward_mean: 951.9301383549267\n",
      "  episode_reward_min: -51.433396146454925\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 23086\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.878\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 3960000\n",
      "    num_steps_trained: 3960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9438226222991943\n",
      "      kl: 0.0160690788179636\n",
      "      policy_loss: 7.496831676689908e-05\n",
      "      total_loss: 659.5469970703125\n",
      "      vf_explained_var: 0.972770094871521\n",
      "      vf_loss: 659.5465087890625\n",
      "    sample_time_ms: 19486.404\n",
      "    update_time_ms: 5.935\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.9650691774634\n",
      "  time_since_restore: 9341.356439590454\n",
      "  time_this_iter_s: 23.205912590026855\n",
      "  time_total_s: 9341.356439590454\n",
      "  timestamp: 1553975117\n",
      "  timesteps_since_restore: 3960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3960000\n",
      "  training_iteration: 396\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9341 s, 396 iter, 3960000 ts, 952 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-45-41\n",
      "  done: false\n",
      "  episode_len_mean: 173.31\n",
      "  episode_reward_max: 1154.4730037800164\n",
      "  episode_reward_mean: 932.227596258637\n",
      "  episode_reward_min: -89.0543999272573\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 23142\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.356\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 3970000\n",
      "    num_steps_trained: 3970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.974431574344635\n",
      "      kl: 0.018034053966403008\n",
      "      policy_loss: -0.0029163025319576263\n",
      "      total_loss: 982.4381103515625\n",
      "      vf_explained_var: 0.9584217667579651\n",
      "      vf_loss: 982.4404907226562\n",
      "    sample_time_ms: 19486.347\n",
      "    update_time_ms: 5.544\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.1137981293186\n",
      "  time_since_restore: 9364.786088228226\n",
      "  time_this_iter_s: 23.429648637771606\n",
      "  time_total_s: 9364.786088228226\n",
      "  timestamp: 1553975141\n",
      "  timesteps_since_restore: 3970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3970000\n",
      "  training_iteration: 397\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9364 s, 397 iter, 3970000 ts, 932 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-46-04\n",
      "  done: false\n",
      "  episode_len_mean: 170.26\n",
      "  episode_reward_max: 1135.374006779442\n",
      "  episode_reward_mean: 944.7058085599273\n",
      "  episode_reward_min: -89.0543999272573\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 23201\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.639\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 3980000\n",
      "    num_steps_trained: 3980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.88714998960495\n",
      "      kl: 0.01574137806892395\n",
      "      policy_loss: -0.0005864321137778461\n",
      "      total_loss: 682.4794921875\n",
      "      vf_explained_var: 0.970190167427063\n",
      "      vf_loss: 682.4797973632812\n",
      "    sample_time_ms: 19450.012\n",
      "    update_time_ms: 5.771\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.3529042799637\n",
      "  time_since_restore: 9388.03926706314\n",
      "  time_this_iter_s: 23.25317883491516\n",
      "  time_total_s: 9388.03926706314\n",
      "  timestamp: 1553975164\n",
      "  timesteps_since_restore: 3980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3980000\n",
      "  training_iteration: 398\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9388 s, 398 iter, 3980000 ts, 945 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-46-28\n",
      "  done: false\n",
      "  episode_len_mean: 170.45\n",
      "  episode_reward_max: 1136.7228570313546\n",
      "  episode_reward_mean: 913.1944389983609\n",
      "  episode_reward_min: -61.90579211290614\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 23260\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3916.848\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 3990000\n",
      "    num_steps_trained: 3990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9705532789230347\n",
      "      kl: 0.015829093754291534\n",
      "      policy_loss: -0.0013734010281041265\n",
      "      total_loss: 1399.1163330078125\n",
      "      vf_explained_var: 0.9431144595146179\n",
      "      vf_loss: 1399.117431640625\n",
      "    sample_time_ms: 19457.454\n",
      "    update_time_ms: 5.641\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 456.5972194991805\n",
      "  time_since_restore: 9411.568255901337\n",
      "  time_this_iter_s: 23.5289888381958\n",
      "  time_total_s: 9411.568255901337\n",
      "  timestamp: 1553975188\n",
      "  timesteps_since_restore: 3990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3990000\n",
      "  training_iteration: 399\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9411 s, 399 iter, 3990000 ts, 913 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-46-51\n",
      "  done: false\n",
      "  episode_len_mean: 176.94\n",
      "  episode_reward_max: 1124.8742115801697\n",
      "  episode_reward_mean: 874.9937049902952\n",
      "  episode_reward_min: -61.90579211290614\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 23314\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.442\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 4000000\n",
      "    num_steps_trained: 4000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1105564832687378\n",
      "      kl: 0.014561302028596401\n",
      "      policy_loss: -0.0007701073191128671\n",
      "      total_loss: 967.34326171875\n",
      "      vf_explained_var: 0.9573259353637695\n",
      "      vf_loss: 967.3436279296875\n",
      "    sample_time_ms: 19487.678\n",
      "    update_time_ms: 5.636\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 437.4968524951476\n",
      "  time_since_restore: 9435.404091119766\n",
      "  time_this_iter_s: 23.835835218429565\n",
      "  time_total_s: 9435.404091119766\n",
      "  timestamp: 1553975211\n",
      "  timesteps_since_restore: 4000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4000000\n",
      "  training_iteration: 400\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9435 s, 400 iter, 4000000 ts, 875 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-47-16\n",
      "  done: false\n",
      "  episode_len_mean: 180.14\n",
      "  episode_reward_max: 1124.8742115801697\n",
      "  episode_reward_mean: 902.0071322774336\n",
      "  episode_reward_min: -93.66865331520177\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 23371\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.68\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 4010000\n",
      "    num_steps_trained: 4010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0008803606033325\n",
      "      kl: 0.02365986257791519\n",
      "      policy_loss: -0.004877686966210604\n",
      "      total_loss: 1204.8516845703125\n",
      "      vf_explained_var: 0.9491115212440491\n",
      "      vf_loss: 1204.85595703125\n",
      "    sample_time_ms: 19640.906\n",
      "    update_time_ms: 5.751\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 451.0035661387168\n",
      "  time_since_restore: 9460.448448181152\n",
      "  time_this_iter_s: 25.04435706138611\n",
      "  time_total_s: 9460.448448181152\n",
      "  timestamp: 1553975236\n",
      "  timesteps_since_restore: 4010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4010000\n",
      "  training_iteration: 401\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9460 s, 401 iter, 4010000 ts, 902 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-47-41\n",
      "  done: false\n",
      "  episode_len_mean: 175.52\n",
      "  episode_reward_max: 1185.8811426598277\n",
      "  episode_reward_mean: 874.5323646910088\n",
      "  episode_reward_min: -93.66865331520177\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 23430\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3936.503\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 4020000\n",
      "    num_steps_trained: 4020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0492196083068848\n",
      "      kl: 0.02501044236123562\n",
      "      policy_loss: -0.005608629900962114\n",
      "      total_loss: 1377.808349609375\n",
      "      vf_explained_var: 0.9448083639144897\n",
      "      vf_loss: 1377.8133544921875\n",
      "    sample_time_ms: 19721.345\n",
      "    update_time_ms: 5.702\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 437.26618234550426\n",
      "  time_since_restore: 9484.732036352158\n",
      "  time_this_iter_s: 24.28358817100525\n",
      "  time_total_s: 9484.732036352158\n",
      "  timestamp: 1553975261\n",
      "  timesteps_since_restore: 4020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4020000\n",
      "  training_iteration: 402\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9484 s, 402 iter, 4020000 ts, 875 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-48-05\n",
      "  done: false\n",
      "  episode_len_mean: 179.45\n",
      "  episode_reward_max: 1185.8811426598277\n",
      "  episode_reward_mean: 883.2962697011551\n",
      "  episode_reward_min: -86.84793151444947\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 23482\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.46\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 4030000\n",
      "    num_steps_trained: 4030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2356152534484863\n",
      "      kl: 0.015391716733574867\n",
      "      policy_loss: -0.0010428085224702954\n",
      "      total_loss: 923.8975219726562\n",
      "      vf_explained_var: 0.9602514505386353\n",
      "      vf_loss: 923.8982543945312\n",
      "    sample_time_ms: 19748.143\n",
      "    update_time_ms: 5.735\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 441.6481348505776\n",
      "  time_since_restore: 9508.514407634735\n",
      "  time_this_iter_s: 23.782371282577515\n",
      "  time_total_s: 9508.514407634735\n",
      "  timestamp: 1553975285\n",
      "  timesteps_since_restore: 4030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4030000\n",
      "  training_iteration: 403\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9508 s, 403 iter, 4030000 ts, 883 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-48-28\n",
      "  done: false\n",
      "  episode_len_mean: 182.34\n",
      "  episode_reward_max: 1137.3958475041054\n",
      "  episode_reward_mean: 913.5454069643721\n",
      "  episode_reward_min: -18.610749856517913\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 23540\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.823\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 4040000\n",
      "    num_steps_trained: 4040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.049527883529663\n",
      "      kl: 0.02637305296957493\n",
      "      policy_loss: -0.004760843235999346\n",
      "      total_loss: 870.2886352539062\n",
      "      vf_explained_var: 0.9639466404914856\n",
      "      vf_loss: 870.2928466796875\n",
      "    sample_time_ms: 19758.799\n",
      "    update_time_ms: 5.582\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 456.77270348218605\n",
      "  time_since_restore: 9531.688773393631\n",
      "  time_this_iter_s: 23.174365758895874\n",
      "  time_total_s: 9531.688773393631\n",
      "  timestamp: 1553975308\n",
      "  timesteps_since_restore: 4040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4040000\n",
      "  training_iteration: 404\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9531 s, 404 iter, 4040000 ts, 914 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-48-51\n",
      "  done: false\n",
      "  episode_len_mean: 177.23\n",
      "  episode_reward_max: 1124.1622168286617\n",
      "  episode_reward_mean: 936.4651195444527\n",
      "  episode_reward_min: -43.429562603740806\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 23595\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.691\n",
      "    load_time_ms: 1.646\n",
      "    num_steps_sampled: 4050000\n",
      "    num_steps_trained: 4050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0906407833099365\n",
      "      kl: 0.015031165443360806\n",
      "      policy_loss: -0.002233543200418353\n",
      "      total_loss: 521.0032958984375\n",
      "      vf_explained_var: 0.9769909977912903\n",
      "      vf_loss: 521.005126953125\n",
      "    sample_time_ms: 19738.132\n",
      "    update_time_ms: 5.341\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.23255977222635\n",
      "  time_since_restore: 9554.898247480392\n",
      "  time_this_iter_s: 23.209474086761475\n",
      "  time_total_s: 9554.898247480392\n",
      "  timestamp: 1553975331\n",
      "  timesteps_since_restore: 4050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4050000\n",
      "  training_iteration: 405\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9554 s, 405 iter, 4050000 ts, 936 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-49-14\n",
      "  done: false\n",
      "  episode_len_mean: 187.38\n",
      "  episode_reward_max: 1124.4554038481888\n",
      "  episode_reward_mean: 944.9258060396515\n",
      "  episode_reward_min: -80.85527195688002\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 23648\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.4\n",
      "    load_time_ms: 1.618\n",
      "    num_steps_sampled: 4060000\n",
      "    num_steps_trained: 4060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.128313660621643\n",
      "      kl: 0.03664863482117653\n",
      "      policy_loss: -0.01144455373287201\n",
      "      total_loss: 688.2926635742188\n",
      "      vf_explained_var: 0.9693299531936646\n",
      "      vf_loss: 688.3032836914062\n",
      "    sample_time_ms: 19750.147\n",
      "    update_time_ms: 5.34\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.4629030198258\n",
      "  time_since_restore: 9578.245792150497\n",
      "  time_this_iter_s: 23.34754467010498\n",
      "  time_total_s: 9578.245792150497\n",
      "  timestamp: 1553975354\n",
      "  timesteps_since_restore: 4060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4060000\n",
      "  training_iteration: 406\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9578 s, 406 iter, 4060000 ts, 945 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-49-39\n",
      "  done: false\n",
      "  episode_len_mean: 187.91\n",
      "  episode_reward_max: 1124.4554038481888\n",
      "  episode_reward_mean: 934.2420046494346\n",
      "  episode_reward_min: -80.85527195688002\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 23701\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.707\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 4070000\n",
      "    num_steps_trained: 4070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.166486382484436\n",
      "      kl: 0.019985869526863098\n",
      "      policy_loss: -0.0006867782794870436\n",
      "      total_loss: 748.0989990234375\n",
      "      vf_explained_var: 0.9665480256080627\n",
      "      vf_loss: 748.0992431640625\n",
      "    sample_time_ms: 19811.693\n",
      "    update_time_ms: 5.48\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.1210023247173\n",
      "  time_since_restore: 9602.302361249924\n",
      "  time_this_iter_s: 24.05656909942627\n",
      "  time_total_s: 9602.302361249924\n",
      "  timestamp: 1553975379\n",
      "  timesteps_since_restore: 4070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4070000\n",
      "  training_iteration: 407\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9602 s, 407 iter, 4070000 ts, 934 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-50-02\n",
      "  done: false\n",
      "  episode_len_mean: 181.41\n",
      "  episode_reward_max: 1152.0160867184986\n",
      "  episode_reward_mean: 944.1893805227945\n",
      "  episode_reward_min: -40.142448964598515\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 23758\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.983\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 4080000\n",
      "    num_steps_trained: 4080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8957095146179199\n",
      "      kl: 0.049629729241132736\n",
      "      policy_loss: -0.002313976874575019\n",
      "      total_loss: 856.0473022460938\n",
      "      vf_explained_var: 0.9642811417579651\n",
      "      vf_loss: 856.0484619140625\n",
      "    sample_time_ms: 19857.205\n",
      "    update_time_ms: 5.404\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.0946902613972\n",
      "  time_since_restore: 9625.971690654755\n",
      "  time_this_iter_s: 23.669329404830933\n",
      "  time_total_s: 9625.971690654755\n",
      "  timestamp: 1553975402\n",
      "  timesteps_since_restore: 4080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4080000\n",
      "  training_iteration: 408\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9625 s, 408 iter, 4080000 ts, 944 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-50-25\n",
      "  done: false\n",
      "  episode_len_mean: 179.75\n",
      "  episode_reward_max: 1152.0160867184986\n",
      "  episode_reward_mean: 951.0907230215106\n",
      "  episode_reward_min: -44.99457706201949\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 23814\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.246\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 4090000\n",
      "    num_steps_trained: 4090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9119383692741394\n",
      "      kl: 0.023554028943181038\n",
      "      policy_loss: -0.007621521595865488\n",
      "      total_loss: 645.87255859375\n",
      "      vf_explained_var: 0.9732499718666077\n",
      "      vf_loss: 645.8793334960938\n",
      "    sample_time_ms: 19814.654\n",
      "    update_time_ms: 6.011\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.54536151075547\n",
      "  time_since_restore: 9649.044365406036\n",
      "  time_this_iter_s: 23.07267475128174\n",
      "  time_total_s: 9649.044365406036\n",
      "  timestamp: 1553975425\n",
      "  timesteps_since_restore: 4090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4090000\n",
      "  training_iteration: 409\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9649 s, 409 iter, 4090000 ts, 951 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-50-49\n",
      "  done: false\n",
      "  episode_len_mean: 184.65\n",
      "  episode_reward_max: 1113.9815355062099\n",
      "  episode_reward_mean: 883.7557046123551\n",
      "  episode_reward_min: -73.70023053656867\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 23867\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.691\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 4100000\n",
      "    num_steps_trained: 4100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1477786302566528\n",
      "      kl: 0.01628975011408329\n",
      "      policy_loss: -0.0006099872407503426\n",
      "      total_loss: 1629.910400390625\n",
      "      vf_explained_var: 0.9324881434440613\n",
      "      vf_loss: 1629.9105224609375\n",
      "    sample_time_ms: 19818.572\n",
      "    update_time_ms: 6.079\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 441.87785230617754\n",
      "  time_since_restore: 9672.88305926323\n",
      "  time_this_iter_s: 23.838693857192993\n",
      "  time_total_s: 9672.88305926323\n",
      "  timestamp: 1553975449\n",
      "  timesteps_since_restore: 4100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4100000\n",
      "  training_iteration: 410\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9672 s, 410 iter, 4100000 ts, 884 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-51-13\n",
      "  done: false\n",
      "  episode_len_mean: 182.73\n",
      "  episode_reward_max: 1141.9502593889613\n",
      "  episode_reward_mean: 920.0414601790125\n",
      "  episode_reward_min: -74.11692643605583\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 23921\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.237\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 4110000\n",
      "    num_steps_trained: 4110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9224296808242798\n",
      "      kl: 0.015500090084969997\n",
      "      policy_loss: -0.001119032152928412\n",
      "      total_loss: 439.298583984375\n",
      "      vf_explained_var: 0.9796355962753296\n",
      "      vf_loss: 439.2991638183594\n",
      "    sample_time_ms: 19669.851\n",
      "    update_time_ms: 5.897\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 460.02073008950623\n",
      "  time_since_restore: 9696.443467140198\n",
      "  time_this_iter_s: 23.560407876968384\n",
      "  time_total_s: 9696.443467140198\n",
      "  timestamp: 1553975473\n",
      "  timesteps_since_restore: 4110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4110000\n",
      "  training_iteration: 411\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9696 s, 411 iter, 4110000 ts, 920 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-51-37\n",
      "  done: false\n",
      "  episode_len_mean: 183.42\n",
      "  episode_reward_max: 1141.9502593889613\n",
      "  episode_reward_mean: 940.5397873949164\n",
      "  episode_reward_min: -74.11692643605583\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 23976\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.285\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 4120000\n",
      "    num_steps_trained: 4120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0067474842071533\n",
      "      kl: 0.012002759613096714\n",
      "      policy_loss: -0.00033050813362933695\n",
      "      total_loss: 793.7395629882812\n",
      "      vf_explained_var: 0.9634800553321838\n",
      "      vf_loss: 793.739501953125\n",
      "    sample_time_ms: 19655.736\n",
      "    update_time_ms: 6.007\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.26989369745803\n",
      "  time_since_restore: 9720.530219078064\n",
      "  time_this_iter_s: 24.08675193786621\n",
      "  time_total_s: 9720.530219078064\n",
      "  timestamp: 1553975497\n",
      "  timesteps_since_restore: 4120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4120000\n",
      "  training_iteration: 412\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9720 s, 412 iter, 4120000 ts, 941 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-52-01\n",
      "  done: false\n",
      "  episode_len_mean: 181.69\n",
      "  episode_reward_max: 1161.8391437173273\n",
      "  episode_reward_mean: 907.3569436200569\n",
      "  episode_reward_min: -44.312554567081634\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 24032\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.812\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 4130000\n",
      "    num_steps_trained: 4130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1577950716018677\n",
      "      kl: 0.013324063271284103\n",
      "      policy_loss: -0.00107192259747535\n",
      "      total_loss: 967.5260620117188\n",
      "      vf_explained_var: 0.9608587622642517\n",
      "      vf_loss: 967.5266723632812\n",
      "    sample_time_ms: 19687.505\n",
      "    update_time_ms: 6.095\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 453.67847181002827\n",
      "  time_since_restore: 9744.635494470596\n",
      "  time_this_iter_s: 24.10527539253235\n",
      "  time_total_s: 9744.635494470596\n",
      "  timestamp: 1553975521\n",
      "  timesteps_since_restore: 4130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4130000\n",
      "  training_iteration: 413\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9744 s, 413 iter, 4130000 ts, 907 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-52-25\n",
      "  done: false\n",
      "  episode_len_mean: 193.12\n",
      "  episode_reward_max: 1161.8391437173273\n",
      "  episode_reward_mean: 880.2379416608703\n",
      "  episode_reward_min: -40.4559305768872\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 24079\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.617\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 4140000\n",
      "    num_steps_trained: 4140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2024868726730347\n",
      "      kl: 0.01611366681754589\n",
      "      policy_loss: -0.00033120231819339097\n",
      "      total_loss: 896.9671630859375\n",
      "      vf_explained_var: 0.9579203724861145\n",
      "      vf_loss: 896.9668579101562\n",
      "    sample_time_ms: 19766.408\n",
      "    update_time_ms: 6.078\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 440.11897083043516\n",
      "  time_since_restore: 9768.656078338623\n",
      "  time_this_iter_s: 24.020583868026733\n",
      "  time_total_s: 9768.656078338623\n",
      "  timestamp: 1553975545\n",
      "  timesteps_since_restore: 4140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4140000\n",
      "  training_iteration: 414\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9768 s, 414 iter, 4140000 ts, 880 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-52-49\n",
      "  done: false\n",
      "  episode_len_mean: 192.82\n",
      "  episode_reward_max: 1131.8299285323774\n",
      "  episode_reward_mean: 923.8888450578575\n",
      "  episode_reward_min: -48.984064942204014\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 24136\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.987\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 4150000\n",
      "    num_steps_trained: 4150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9717198014259338\n",
      "      kl: 0.017644409090280533\n",
      "      policy_loss: -0.0010015681618824601\n",
      "      total_loss: 484.19781494140625\n",
      "      vf_explained_var: 0.9799436926841736\n",
      "      vf_loss: 484.1982116699219\n",
      "    sample_time_ms: 19778.821\n",
      "    update_time_ms: 6.165\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 461.9444225289288\n",
      "  time_since_restore: 9791.993455648422\n",
      "  time_this_iter_s: 23.337377309799194\n",
      "  time_total_s: 9791.993455648422\n",
      "  timestamp: 1553975569\n",
      "  timesteps_since_restore: 4150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4150000\n",
      "  training_iteration: 415\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9791 s, 415 iter, 4150000 ts, 924 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-53-13\n",
      "  done: false\n",
      "  episode_len_mean: 186.95\n",
      "  episode_reward_max: 1179.5229168157584\n",
      "  episode_reward_mean: 961.8217591373773\n",
      "  episode_reward_min: -48.984064942204014\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 24188\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.155\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 4160000\n",
      "    num_steps_trained: 4160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0019433498382568\n",
      "      kl: 0.02501923218369484\n",
      "      policy_loss: 0.0011794319143518806\n",
      "      total_loss: 766.5579833984375\n",
      "      vf_explained_var: 0.9630386233329773\n",
      "      vf_loss: 766.5559692382812\n",
      "    sample_time_ms: 19892.352\n",
      "    update_time_ms: 6.129\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.9108795686887\n",
      "  time_since_restore: 9816.472628593445\n",
      "  time_this_iter_s: 24.479172945022583\n",
      "  time_total_s: 9816.472628593445\n",
      "  timestamp: 1553975593\n",
      "  timesteps_since_restore: 4160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4160000\n",
      "  training_iteration: 416\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9816 s, 416 iter, 4160000 ts, 962 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-53-37\n",
      "  done: false\n",
      "  episode_len_mean: 198.62\n",
      "  episode_reward_max: 1179.5229168157584\n",
      "  episode_reward_mean: 932.6436244426238\n",
      "  episode_reward_min: -61.41590382915888\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 24237\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.424\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 4170000\n",
      "    num_steps_trained: 4170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0796018838882446\n",
      "      kl: 0.013770189136266708\n",
      "      policy_loss: -0.0007037210743874311\n",
      "      total_loss: 655.1878662109375\n",
      "      vf_explained_var: 0.9695185422897339\n",
      "      vf_loss: 655.1881103515625\n",
      "    sample_time_ms: 19833.653\n",
      "    update_time_ms: 5.943\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.321812221312\n",
      "  time_since_restore: 9839.8261551857\n",
      "  time_this_iter_s: 23.35352659225464\n",
      "  time_total_s: 9839.8261551857\n",
      "  timestamp: 1553975617\n",
      "  timesteps_since_restore: 4170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4170000\n",
      "  training_iteration: 417\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9839 s, 417 iter, 4170000 ts, 933 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-54-01\n",
      "  done: false\n",
      "  episode_len_mean: 191.19\n",
      "  episode_reward_max: 1119.9523204437114\n",
      "  episode_reward_mean: 910.003487394193\n",
      "  episode_reward_min: -61.41590382915888\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 24293\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.472\n",
      "    load_time_ms: 1.403\n",
      "    num_steps_sampled: 4180000\n",
      "    num_steps_trained: 4180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.073224425315857\n",
      "      kl: 0.03781965747475624\n",
      "      policy_loss: -0.0021118123549968004\n",
      "      total_loss: 1176.0521240234375\n",
      "      vf_explained_var: 0.9551211595535278\n",
      "      vf_loss: 1176.052978515625\n",
      "    sample_time_ms: 19876.956\n",
      "    update_time_ms: 5.848\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 455.00174369709663\n",
      "  time_since_restore: 9863.945469856262\n",
      "  time_this_iter_s: 24.119314670562744\n",
      "  time_total_s: 9863.945469856262\n",
      "  timestamp: 1553975641\n",
      "  timesteps_since_restore: 4180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4180000\n",
      "  training_iteration: 418\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9863 s, 418 iter, 4180000 ts, 910 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-54-25\n",
      "  done: false\n",
      "  episode_len_mean: 177.98\n",
      "  episode_reward_max: 1129.786403796764\n",
      "  episode_reward_mean: 925.7369510615165\n",
      "  episode_reward_min: -59.24040086786411\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 24350\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.304\n",
      "    load_time_ms: 1.351\n",
      "    num_steps_sampled: 4190000\n",
      "    num_steps_trained: 4190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9124430418014526\n",
      "      kl: 0.028288565576076508\n",
      "      policy_loss: -0.003887903643772006\n",
      "      total_loss: 992.5531005859375\n",
      "      vf_explained_var: 0.9569441676139832\n",
      "      vf_loss: 992.5559692382812\n",
      "    sample_time_ms: 19975.897\n",
      "    update_time_ms: 5.27\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 462.86847553075813\n",
      "  time_since_restore: 9887.961395263672\n",
      "  time_this_iter_s: 24.015925407409668\n",
      "  time_total_s: 9887.961395263672\n",
      "  timestamp: 1553975665\n",
      "  timesteps_since_restore: 4190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4190000\n",
      "  training_iteration: 419\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9887 s, 419 iter, 4190000 ts, 926 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-54-49\n",
      "  done: false\n",
      "  episode_len_mean: 177.26\n",
      "  episode_reward_max: 1140.9899547331147\n",
      "  episode_reward_mean: 975.0485767250892\n",
      "  episode_reward_min: -88.14434552489777\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 24407\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.93\n",
      "    load_time_ms: 1.35\n",
      "    num_steps_sampled: 4200000\n",
      "    num_steps_trained: 4200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7433549761772156\n",
      "      kl: 0.018135538324713707\n",
      "      policy_loss: -0.0032021014485508204\n",
      "      total_loss: 362.92706298828125\n",
      "      vf_explained_var: 0.9848646521568298\n",
      "      vf_loss: 362.92962646484375\n",
      "    sample_time_ms: 20012.262\n",
      "    update_time_ms: 5.231\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.5242883625446\n",
      "  time_since_restore: 9912.17859172821\n",
      "  time_this_iter_s: 24.217196464538574\n",
      "  time_total_s: 9912.17859172821\n",
      "  timestamp: 1553975689\n",
      "  timesteps_since_restore: 4200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4200000\n",
      "  training_iteration: 420\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9912 s, 420 iter, 4200000 ts, 975 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-55-13\n",
      "  done: false\n",
      "  episode_len_mean: 178.54\n",
      "  episode_reward_max: 1140.9899547331147\n",
      "  episode_reward_mean: 954.099613161243\n",
      "  episode_reward_min: -88.14434552489777\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 24461\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.619\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 4210000\n",
      "    num_steps_trained: 4210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.939172625541687\n",
      "      kl: 0.01867557503283024\n",
      "      policy_loss: -0.0026385497767478228\n",
      "      total_loss: 444.1158752441406\n",
      "      vf_explained_var: 0.9808688163757324\n",
      "      vf_loss: 444.1178894042969\n",
      "    sample_time_ms: 20006.672\n",
      "    update_time_ms: 5.315\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.0498065806215\n",
      "  time_since_restore: 9935.703866243362\n",
      "  time_this_iter_s: 23.525274515151978\n",
      "  time_total_s: 9935.703866243362\n",
      "  timestamp: 1553975713\n",
      "  timesteps_since_restore: 4210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4210000\n",
      "  training_iteration: 421\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9935 s, 421 iter, 4210000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-55-37\n",
      "  done: false\n",
      "  episode_len_mean: 193.45\n",
      "  episode_reward_max: 1135.3949336665369\n",
      "  episode_reward_mean: 922.7304122184797\n",
      "  episode_reward_min: -63.52084199773077\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 24511\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.112\n",
      "    load_time_ms: 1.412\n",
      "    num_steps_sampled: 4220000\n",
      "    num_steps_trained: 4220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.161586880683899\n",
      "      kl: 0.01831732876598835\n",
      "      policy_loss: 0.00021031766664236784\n",
      "      total_loss: 1040.837890625\n",
      "      vf_explained_var: 0.9536647200584412\n",
      "      vf_loss: 1040.837158203125\n",
      "    sample_time_ms: 20023.282\n",
      "    update_time_ms: 5.214\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 461.36520610924\n",
      "  time_since_restore: 9959.841356992722\n",
      "  time_this_iter_s: 24.13749074935913\n",
      "  time_total_s: 9959.841356992722\n",
      "  timestamp: 1553975737\n",
      "  timesteps_since_restore: 4220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4220000\n",
      "  training_iteration: 422\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9959 s, 422 iter, 4220000 ts, 923 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-56-01\n",
      "  done: false\n",
      "  episode_len_mean: 185.79\n",
      "  episode_reward_max: 1127.9361769714487\n",
      "  episode_reward_mean: 947.816016661259\n",
      "  episode_reward_min: -63.52084199773077\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 24569\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.739\n",
      "    load_time_ms: 1.372\n",
      "    num_steps_sampled: 4230000\n",
      "    num_steps_trained: 4230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7816362380981445\n",
      "      kl: 0.03163552284240723\n",
      "      policy_loss: -0.00044514506589621305\n",
      "      total_loss: 286.6136779785156\n",
      "      vf_explained_var: 0.9878033399581909\n",
      "      vf_loss: 286.6130676269531\n",
      "    sample_time_ms: 20047.328\n",
      "    update_time_ms: 5.642\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.9080083306295\n",
      "  time_since_restore: 9984.236631631851\n",
      "  time_this_iter_s: 24.39527463912964\n",
      "  time_total_s: 9984.236631631851\n",
      "  timestamp: 1553975761\n",
      "  timesteps_since_restore: 4230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4230000\n",
      "  training_iteration: 423\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 9984 s, 423 iter, 4230000 ts, 948 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-56-25\n",
      "  done: false\n",
      "  episode_len_mean: 175.69\n",
      "  episode_reward_max: 1159.038241389297\n",
      "  episode_reward_mean: 986.8108256438181\n",
      "  episode_reward_min: -96.20468841596842\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 24624\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.284\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 4240000\n",
      "    num_steps_trained: 4240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0353878736495972\n",
      "      kl: 0.01439135055989027\n",
      "      policy_loss: -0.0006043284083716571\n",
      "      total_loss: 517.928466796875\n",
      "      vf_explained_var: 0.9769723415374756\n",
      "      vf_loss: 517.9285888671875\n",
      "    sample_time_ms: 19995.765\n",
      "    update_time_ms: 5.63\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.4054128219089\n",
      "  time_since_restore: 10007.69731426239\n",
      "  time_this_iter_s: 23.46068263053894\n",
      "  time_total_s: 10007.69731426239\n",
      "  timestamp: 1553975785\n",
      "  timesteps_since_restore: 4240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4240000\n",
      "  training_iteration: 424\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10007 s, 424 iter, 4240000 ts, 987 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-56-48\n",
      "  done: false\n",
      "  episode_len_mean: 192.71\n",
      "  episode_reward_max: 1189.1335900779197\n",
      "  episode_reward_mean: 962.6219410014462\n",
      "  episode_reward_min: -96.20468841596842\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 24671\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.667\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 4250000\n",
      "    num_steps_trained: 4250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3519378900527954\n",
      "      kl: 0.021757811307907104\n",
      "      policy_loss: -0.002703363075852394\n",
      "      total_loss: 597.2476196289062\n",
      "      vf_explained_var: 0.9751307368278503\n",
      "      vf_loss: 597.2495727539062\n",
      "    sample_time_ms: 19983.517\n",
      "    update_time_ms: 5.532\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.3109705007232\n",
      "  time_since_restore: 10030.857578992844\n",
      "  time_this_iter_s: 23.16026473045349\n",
      "  time_total_s: 10030.857578992844\n",
      "  timestamp: 1553975808\n",
      "  timesteps_since_restore: 4250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4250000\n",
      "  training_iteration: 425\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10030 s, 425 iter, 4250000 ts, 963 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-57-12\n",
      "  done: false\n",
      "  episode_len_mean: 195.49\n",
      "  episode_reward_max: 1189.1335900779197\n",
      "  episode_reward_mean: 953.8196893001198\n",
      "  episode_reward_min: -54.23142964860301\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 24725\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.861\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 4260000\n",
      "    num_steps_trained: 4260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9959376454353333\n",
      "      kl: 0.02077447809278965\n",
      "      policy_loss: 0.00028707258752547204\n",
      "      total_loss: 546.8140258789062\n",
      "      vf_explained_var: 0.9741934537887573\n",
      "      vf_loss: 546.8130493164062\n",
      "    sample_time_ms: 19898.423\n",
      "    update_time_ms: 5.504\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.9098446500598\n",
      "  time_since_restore: 10054.496059894562\n",
      "  time_this_iter_s: 23.63848090171814\n",
      "  time_total_s: 10054.496059894562\n",
      "  timestamp: 1553975832\n",
      "  timesteps_since_restore: 4260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4260000\n",
      "  training_iteration: 426\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10054 s, 426 iter, 4260000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-57-35\n",
      "  done: false\n",
      "  episode_len_mean: 180.22\n",
      "  episode_reward_max: 1121.2704102345008\n",
      "  episode_reward_mean: 957.4303265060454\n",
      "  episode_reward_min: -54.23142964860301\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 24781\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3873.568\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 4270000\n",
      "    num_steps_trained: 4270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.039620041847229\n",
      "      kl: 0.03566940128803253\n",
      "      policy_loss: -0.0030311215668916702\n",
      "      total_loss: 1451.1663818359375\n",
      "      vf_explained_var: 0.9324252605438232\n",
      "      vf_loss: 1451.1680908203125\n",
      "    sample_time_ms: 19872.777\n",
      "    update_time_ms: 5.559\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.71516325302275\n",
      "  time_since_restore: 10077.535731077194\n",
      "  time_this_iter_s: 23.039671182632446\n",
      "  time_total_s: 10077.535731077194\n",
      "  timestamp: 1553975855\n",
      "  timesteps_since_restore: 4270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4270000\n",
      "  training_iteration: 427\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10077 s, 427 iter, 4270000 ts, 957 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-57-59\n",
      "  done: false\n",
      "  episode_len_mean: 183.69\n",
      "  episode_reward_max: 1151.599997073937\n",
      "  episode_reward_mean: 964.6148054780493\n",
      "  episode_reward_min: -38.75539315814038\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 24834\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.365\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 4280000\n",
      "    num_steps_trained: 4280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8574539422988892\n",
      "      kl: 0.012253508903086185\n",
      "      policy_loss: 0.0013757635606452823\n",
      "      total_loss: 478.419677734375\n",
      "      vf_explained_var: 0.9777137637138367\n",
      "      vf_loss: 478.4178771972656\n",
      "    sample_time_ms: 19896.574\n",
      "    update_time_ms: 5.465\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.30740273902467\n",
      "  time_since_restore: 10101.911360263824\n",
      "  time_this_iter_s: 24.37562918663025\n",
      "  time_total_s: 10101.911360263824\n",
      "  timestamp: 1553975879\n",
      "  timesteps_since_restore: 4280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4280000\n",
      "  training_iteration: 428\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10101 s, 428 iter, 4280000 ts, 965 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-58-23\n",
      "  done: false\n",
      "  episode_len_mean: 181.24\n",
      "  episode_reward_max: 1160.1663624211958\n",
      "  episode_reward_mean: 972.6809199386785\n",
      "  episode_reward_min: -49.082870127894296\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 24891\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.076\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 4290000\n",
      "    num_steps_trained: 4290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7577583193778992\n",
      "      kl: 0.0206757839769125\n",
      "      policy_loss: -0.0018834793008863926\n",
      "      total_loss: 785.1224975585938\n",
      "      vf_explained_var: 0.9637572169303894\n",
      "      vf_loss: 785.1237182617188\n",
      "    sample_time_ms: 19881.454\n",
      "    update_time_ms: 5.248\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.34045996933924\n",
      "  time_since_restore: 10125.799405813217\n",
      "  time_this_iter_s: 23.8880455493927\n",
      "  time_total_s: 10125.799405813217\n",
      "  timestamp: 1553975903\n",
      "  timesteps_since_restore: 4290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4290000\n",
      "  training_iteration: 429\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10125 s, 429 iter, 4290000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-58-47\n",
      "  done: false\n",
      "  episode_len_mean: 171.22\n",
      "  episode_reward_max: 1127.467351904507\n",
      "  episode_reward_mean: 938.9670742251542\n",
      "  episode_reward_min: -49.082870127894296\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 24951\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.567\n",
      "    load_time_ms: 1.545\n",
      "    num_steps_sampled: 4300000\n",
      "    num_steps_trained: 4300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8014717698097229\n",
      "      kl: 0.020937345921993256\n",
      "      policy_loss: -0.0022442711051553488\n",
      "      total_loss: 1059.3585205078125\n",
      "      vf_explained_var: 0.9541234970092773\n",
      "      vf_loss: 1059.3599853515625\n",
      "    sample_time_ms: 19868.427\n",
      "    update_time_ms: 5.205\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.48353711257715\n",
      "  time_since_restore: 10149.891707897186\n",
      "  time_this_iter_s: 24.092302083969116\n",
      "  time_total_s: 10149.891707897186\n",
      "  timestamp: 1553975927\n",
      "  timesteps_since_restore: 4300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4300000\n",
      "  training_iteration: 430\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10149 s, 430 iter, 4300000 ts, 939 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-59-11\n",
      "  done: false\n",
      "  episode_len_mean: 173.91\n",
      "  episode_reward_max: 1129.6639526589322\n",
      "  episode_reward_mean: 937.8055976019011\n",
      "  episode_reward_min: -25.68646777579079\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 25006\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.089\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 4310000\n",
      "    num_steps_trained: 4310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8605515956878662\n",
      "      kl: 0.022304153069853783\n",
      "      policy_loss: -0.001699734595604241\n",
      "      total_loss: 955.6812744140625\n",
      "      vf_explained_var: 0.9558740258216858\n",
      "      vf_loss: 955.6823120117188\n",
      "    sample_time_ms: 19936.499\n",
      "    update_time_ms: 5.329\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.90279880095056\n",
      "  time_since_restore: 10174.110936164856\n",
      "  time_this_iter_s: 24.219228267669678\n",
      "  time_total_s: 10174.110936164856\n",
      "  timestamp: 1553975951\n",
      "  timesteps_since_restore: 4310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4310000\n",
      "  training_iteration: 431\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10174 s, 431 iter, 4310000 ts, 938 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-59-35\n",
      "  done: false\n",
      "  episode_len_mean: 183.61\n",
      "  episode_reward_max: 1129.6639526589322\n",
      "  episode_reward_mean: 894.9449952378973\n",
      "  episode_reward_min: -31.543971910024595\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 25060\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.566\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 4320000\n",
      "    num_steps_trained: 4320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0824252367019653\n",
      "      kl: 0.017943305894732475\n",
      "      policy_loss: 0.00017534922517370433\n",
      "      total_loss: 1347.11474609375\n",
      "      vf_explained_var: 0.9492674469947815\n",
      "      vf_loss: 1347.114013671875\n",
      "    sample_time_ms: 19888.141\n",
      "    update_time_ms: 5.389\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 447.47249761894864\n",
      "  time_since_restore: 10197.768857717514\n",
      "  time_this_iter_s: 23.65792155265808\n",
      "  time_total_s: 10197.768857717514\n",
      "  timestamp: 1553975975\n",
      "  timesteps_since_restore: 4320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4320000\n",
      "  training_iteration: 432\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10197 s, 432 iter, 4320000 ts, 895 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_20-59-59\n",
      "  done: false\n",
      "  episode_len_mean: 186.65\n",
      "  episode_reward_max: 1124.042108439925\n",
      "  episode_reward_mean: 896.414092911824\n",
      "  episode_reward_min: -31.543971910024595\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 25112\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.191\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 4330000\n",
      "    num_steps_trained: 4330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0491636991500854\n",
      "      kl: 0.015161254443228245\n",
      "      policy_loss: -0.0019056174205616117\n",
      "      total_loss: 1064.3797607421875\n",
      "      vf_explained_var: 0.9490948915481567\n",
      "      vf_loss: 1064.381103515625\n",
      "    sample_time_ms: 19827.698\n",
      "    update_time_ms: 5.311\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 448.207046455912\n",
      "  time_since_restore: 10221.506358623505\n",
      "  time_this_iter_s: 23.7375009059906\n",
      "  time_total_s: 10221.506358623505\n",
      "  timestamp: 1553975999\n",
      "  timesteps_since_restore: 4330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4330000\n",
      "  training_iteration: 433\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10221 s, 433 iter, 4330000 ts, 896 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-00-23\n",
      "  done: false\n",
      "  episode_len_mean: 184.04\n",
      "  episode_reward_max: 1129.737081774519\n",
      "  episode_reward_mean: 904.5182671946019\n",
      "  episode_reward_min: -94.91445899530322\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 25167\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.409\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 4340000\n",
      "    num_steps_trained: 4340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9379362463951111\n",
      "      kl: 0.01411702111363411\n",
      "      policy_loss: -0.0018083604518324137\n",
      "      total_loss: 825.0946044921875\n",
      "      vf_explained_var: 0.965166449546814\n",
      "      vf_loss: 825.095947265625\n",
      "    sample_time_ms: 19873.314\n",
      "    update_time_ms: 5.526\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.25913359730094\n",
      "  time_since_restore: 10245.437798976898\n",
      "  time_this_iter_s: 23.931440353393555\n",
      "  time_total_s: 10245.437798976898\n",
      "  timestamp: 1553976023\n",
      "  timesteps_since_restore: 4340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4340000\n",
      "  training_iteration: 434\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10245 s, 434 iter, 4340000 ts, 905 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-00-47\n",
      "  done: false\n",
      "  episode_len_mean: 180.02\n",
      "  episode_reward_max: 1129.737081774519\n",
      "  episode_reward_mean: 930.9268620430335\n",
      "  episode_reward_min: -94.91445899530322\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 25221\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.741\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 4350000\n",
      "    num_steps_trained: 4350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0112699270248413\n",
      "      kl: 0.024290965870022774\n",
      "      policy_loss: -0.0017992487410083413\n",
      "      total_loss: 514.111083984375\n",
      "      vf_explained_var: 0.9776454567909241\n",
      "      vf_loss: 514.112060546875\n",
      "    sample_time_ms: 19943.091\n",
      "    update_time_ms: 5.521\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 465.4634310215167\n",
      "  time_since_restore: 10269.313051223755\n",
      "  time_this_iter_s: 23.87525224685669\n",
      "  time_total_s: 10269.313051223755\n",
      "  timestamp: 1553976047\n",
      "  timesteps_since_restore: 4350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4350000\n",
      "  training_iteration: 435\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10269 s, 435 iter, 4350000 ts, 931 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-01-11\n",
      "  done: false\n",
      "  episode_len_mean: 177.67\n",
      "  episode_reward_max: 1094.232575317852\n",
      "  episode_reward_mean: 912.713787208981\n",
      "  episode_reward_min: -55.52730381291559\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 25278\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.895\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 4360000\n",
      "    num_steps_trained: 4360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.94638592004776\n",
      "      kl: 0.024502979591488838\n",
      "      policy_loss: -0.00640106899663806\n",
      "      total_loss: 973.2291870117188\n",
      "      vf_explained_var: 0.9608649015426636\n",
      "      vf_loss: 973.2345581054688\n",
      "    sample_time_ms: 19970.804\n",
      "    update_time_ms: 5.504\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 456.3568936044904\n",
      "  time_since_restore: 10293.34185743332\n",
      "  time_this_iter_s: 24.02880620956421\n",
      "  time_total_s: 10293.34185743332\n",
      "  timestamp: 1553976071\n",
      "  timesteps_since_restore: 4360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4360000\n",
      "  training_iteration: 436\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10293 s, 436 iter, 4360000 ts, 913 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-01-34\n",
      "  done: false\n",
      "  episode_len_mean: 184.08\n",
      "  episode_reward_max: 1132.05980120041\n",
      "  episode_reward_mean: 929.2361767511685\n",
      "  episode_reward_min: -55.52730381291559\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 25332\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.618\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 4370000\n",
      "    num_steps_trained: 4370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.001854419708252\n",
      "      kl: 0.02198312245309353\n",
      "      policy_loss: -0.003856878262013197\n",
      "      total_loss: 1025.338623046875\n",
      "      vf_explained_var: 0.9538044333457947\n",
      "      vf_loss: 1025.341796875\n",
      "    sample_time_ms: 19995.95\n",
      "    update_time_ms: 5.525\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 464.61808837558414\n",
      "  time_since_restore: 10316.713114500046\n",
      "  time_this_iter_s: 23.371257066726685\n",
      "  time_total_s: 10316.713114500046\n",
      "  timestamp: 1553976094\n",
      "  timesteps_since_restore: 4370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4370000\n",
      "  training_iteration: 437\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10316 s, 437 iter, 4370000 ts, 929 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-01-57\n",
      "  done: false\n",
      "  episode_len_mean: 185.95\n",
      "  episode_reward_max: 1132.05980120041\n",
      "  episode_reward_mean: 959.4883666448524\n",
      "  episode_reward_min: -79.91095832313226\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 25386\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.013\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 4380000\n",
      "    num_steps_trained: 4380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9012311100959778\n",
      "      kl: 0.12476112693548203\n",
      "      policy_loss: 0.0022121237125247717\n",
      "      total_loss: 585.4210205078125\n",
      "      vf_explained_var: 0.9750720262527466\n",
      "      vf_loss: 585.4146728515625\n",
      "    sample_time_ms: 19814.442\n",
      "    update_time_ms: 5.535\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.7441833224261\n",
      "  time_since_restore: 10339.259241580963\n",
      "  time_this_iter_s: 22.54612708091736\n",
      "  time_total_s: 10339.259241580963\n",
      "  timestamp: 1553976117\n",
      "  timesteps_since_restore: 4380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4380000\n",
      "  training_iteration: 438\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10339 s, 438 iter, 4380000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-02-21\n",
      "  done: false\n",
      "  episode_len_mean: 175.75\n",
      "  episode_reward_max: 1140.0532304537176\n",
      "  episode_reward_mean: 915.3782952579594\n",
      "  episode_reward_min: -79.91095832313226\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 25446\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.39\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 4390000\n",
      "    num_steps_trained: 4390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05020924285054207\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8552384972572327\n",
      "      kl: 0.017488442361354828\n",
      "      policy_loss: -0.005192740820348263\n",
      "      total_loss: 1698.2099609375\n",
      "      vf_explained_var: 0.9278832674026489\n",
      "      vf_loss: 1698.21435546875\n",
      "    sample_time_ms: 19864.11\n",
      "    update_time_ms: 5.615\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.6891476289797\n",
      "  time_since_restore: 10363.621043205261\n",
      "  time_this_iter_s: 24.361801624298096\n",
      "  time_total_s: 10363.621043205261\n",
      "  timestamp: 1553976141\n",
      "  timesteps_since_restore: 4390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4390000\n",
      "  training_iteration: 439\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10363 s, 439 iter, 4390000 ts, 915 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-02-45\n",
      "  done: false\n",
      "  episode_len_mean: 170.29\n",
      "  episode_reward_max: 1163.7103499909035\n",
      "  episode_reward_mean: 925.8593463054833\n",
      "  episode_reward_min: -52.807828160653\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 25501\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.758\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 4400000\n",
      "    num_steps_trained: 4400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05020924285054207\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.793685257434845\n",
      "      kl: 0.021014567464590073\n",
      "      policy_loss: -0.0019095727475360036\n",
      "      total_loss: 490.43646240234375\n",
      "      vf_explained_var: 0.9781150817871094\n",
      "      vf_loss: 490.4372863769531\n",
      "    sample_time_ms: 19845.201\n",
      "    update_time_ms: 5.755\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 462.92967315274166\n",
      "  time_since_restore: 10387.538915872574\n",
      "  time_this_iter_s: 23.917872667312622\n",
      "  time_total_s: 10387.538915872574\n",
      "  timestamp: 1553976165\n",
      "  timesteps_since_restore: 4400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4400000\n",
      "  training_iteration: 440\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10387 s, 440 iter, 4400000 ts, 926 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-03-09\n",
      "  done: false\n",
      "  episode_len_mean: 188.98\n",
      "  episode_reward_max: 1163.7103499909035\n",
      "  episode_reward_mean: 985.2203348786793\n",
      "  episode_reward_min: -54.71661017585697\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 25550\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.49\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 4410000\n",
      "    num_steps_trained: 4410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05020924285054207\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2037724256515503\n",
      "      kl: 0.0161843691021204\n",
      "      policy_loss: -0.0003950481186620891\n",
      "      total_loss: 247.95230102539062\n",
      "      vf_explained_var: 0.9883279800415039\n",
      "      vf_loss: 247.951904296875\n",
      "    sample_time_ms: 19817.851\n",
      "    update_time_ms: 5.559\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.61016743933965\n",
      "  time_since_restore: 10411.601480007172\n",
      "  time_this_iter_s: 24.06256413459778\n",
      "  time_total_s: 10411.601480007172\n",
      "  timestamp: 1553976189\n",
      "  timesteps_since_restore: 4410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4410000\n",
      "  training_iteration: 441\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10411 s, 441 iter, 4410000 ts, 985 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-03-32\n",
      "  done: false\n",
      "  episode_len_mean: 187.12\n",
      "  episode_reward_max: 1134.662210153999\n",
      "  episode_reward_mean: 939.5020219579429\n",
      "  episode_reward_min: -62.28482992021762\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 25609\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.019\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 4420000\n",
      "    num_steps_trained: 4420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05020924285054207\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8726914525032043\n",
      "      kl: 0.019107989966869354\n",
      "      policy_loss: -0.0018521657912060618\n",
      "      total_loss: 1063.1571044921875\n",
      "      vf_explained_var: 0.958260178565979\n",
      "      vf_loss: 1063.157958984375\n",
      "    sample_time_ms: 19744.855\n",
      "    update_time_ms: 5.467\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.75101097897146\n",
      "  time_since_restore: 10434.513771057129\n",
      "  time_this_iter_s: 22.912291049957275\n",
      "  time_total_s: 10434.513771057129\n",
      "  timestamp: 1553976212\n",
      "  timesteps_since_restore: 4420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4420000\n",
      "  training_iteration: 442\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10434 s, 442 iter, 4420000 ts, 940 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-03-56\n",
      "  done: false\n",
      "  episode_len_mean: 175.36\n",
      "  episode_reward_max: 1135.7222015111852\n",
      "  episode_reward_mean: 912.251643130397\n",
      "  episode_reward_min: -77.69918057202847\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 25665\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.901\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 4430000\n",
      "    num_steps_trained: 4430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05020924285054207\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8611712455749512\n",
      "      kl: 0.040105391293764114\n",
      "      policy_loss: 0.0005598537973128259\n",
      "      total_loss: 1244.5322265625\n",
      "      vf_explained_var: 0.9466820955276489\n",
      "      vf_loss: 1244.5296630859375\n",
      "    sample_time_ms: 19747.266\n",
      "    update_time_ms: 5.081\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 456.1258215651984\n",
      "  time_since_restore: 10458.322809457779\n",
      "  time_this_iter_s: 23.809038400650024\n",
      "  time_total_s: 10458.322809457779\n",
      "  timestamp: 1553976236\n",
      "  timesteps_since_restore: 4430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4430000\n",
      "  training_iteration: 443\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10458 s, 443 iter, 4430000 ts, 912 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-04-20\n",
      "  done: false\n",
      "  episode_len_mean: 187.07\n",
      "  episode_reward_max: 1135.7222015111852\n",
      "  episode_reward_mean: 945.6305409173455\n",
      "  episode_reward_min: -114.19448640051844\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 25719\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.027\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 4440000\n",
      "    num_steps_trained: 4440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07531387358903885\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9699538946151733\n",
      "      kl: 0.00711754709482193\n",
      "      policy_loss: -0.0013521412620320916\n",
      "      total_loss: 637.5661010742188\n",
      "      vf_explained_var: 0.9708097577095032\n",
      "      vf_loss: 637.56689453125\n",
      "    sample_time_ms: 19775.278\n",
      "    update_time_ms: 4.91\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.81527045867284\n",
      "  time_since_restore: 10482.521185159683\n",
      "  time_this_iter_s: 24.198375701904297\n",
      "  time_total_s: 10482.521185159683\n",
      "  timestamp: 1553976260\n",
      "  timesteps_since_restore: 4440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4440000\n",
      "  training_iteration: 444\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10482 s, 444 iter, 4440000 ts, 946 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-04-44\n",
      "  done: false\n",
      "  episode_len_mean: 179.83\n",
      "  episode_reward_max: 1129.0931977418045\n",
      "  episode_reward_mean: 943.6950743718269\n",
      "  episode_reward_min: -114.19448640051844\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 25778\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.817\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 4450000\n",
      "    num_steps_trained: 4450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7082582712173462\n",
      "      kl: 0.01741882786154747\n",
      "      policy_loss: -0.0026976638473570347\n",
      "      total_loss: 774.0272216796875\n",
      "      vf_explained_var: 0.9691406488418579\n",
      "      vf_loss: 774.029296875\n",
      "    sample_time_ms: 19768.774\n",
      "    update_time_ms: 4.832\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.8475371859134\n",
      "  time_since_restore: 10506.332789421082\n",
      "  time_this_iter_s: 23.811604261398315\n",
      "  time_total_s: 10506.332789421082\n",
      "  timestamp: 1553976284\n",
      "  timesteps_since_restore: 4450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4450000\n",
      "  training_iteration: 445\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10506 s, 445 iter, 4450000 ts, 944 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-05-08\n",
      "  done: false\n",
      "  episode_len_mean: 169.06\n",
      "  episode_reward_max: 1128.6969022426897\n",
      "  episode_reward_mean: 993.9598682121127\n",
      "  episode_reward_min: -35.916871739382685\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 25836\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.358\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 4460000\n",
      "    num_steps_trained: 4460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7066893577575684\n",
      "      kl: 0.022053934633731842\n",
      "      policy_loss: -0.001226582913659513\n",
      "      total_loss: 490.6345520019531\n",
      "      vf_explained_var: 0.9773156642913818\n",
      "      vf_loss: 490.635009765625\n",
      "    sample_time_ms: 19747.588\n",
      "    update_time_ms: 4.845\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.9799341060563\n",
      "  time_since_restore: 10530.184101343155\n",
      "  time_this_iter_s: 23.851311922073364\n",
      "  time_total_s: 10530.184101343155\n",
      "  timestamp: 1553976308\n",
      "  timesteps_since_restore: 4460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4460000\n",
      "  training_iteration: 446\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10530 s, 446 iter, 4460000 ts, 994 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-05-31\n",
      "  done: false\n",
      "  episode_len_mean: 175.3\n",
      "  episode_reward_max: 1127.641049261086\n",
      "  episode_reward_mean: 959.2424501217498\n",
      "  episode_reward_min: -35.916871739382685\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 25890\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.427\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 4470000\n",
      "    num_steps_trained: 4470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9211500287055969\n",
      "      kl: 0.02282772585749626\n",
      "      policy_loss: -0.004553237464278936\n",
      "      total_loss: 670.0406494140625\n",
      "      vf_explained_var: 0.9706964492797852\n",
      "      vf_loss: 670.0443725585938\n",
      "    sample_time_ms: 19748.113\n",
      "    update_time_ms: 4.749\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.6212250608749\n",
      "  time_since_restore: 10553.499404907227\n",
      "  time_this_iter_s: 23.315303564071655\n",
      "  time_total_s: 10553.499404907227\n",
      "  timestamp: 1553976331\n",
      "  timesteps_since_restore: 4470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4470000\n",
      "  training_iteration: 447\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10553 s, 447 iter, 4470000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-05-56\n",
      "  done: false\n",
      "  episode_len_mean: 179.43\n",
      "  episode_reward_max: 1136.318762563715\n",
      "  episode_reward_mean: 947.9028009028676\n",
      "  episode_reward_min: -16.969521976996646\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 25948\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.802\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 4480000\n",
      "    num_steps_trained: 4480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.93299800157547\n",
      "      kl: 0.020125826820731163\n",
      "      policy_loss: -0.00302322069182992\n",
      "      total_loss: 927.3018798828125\n",
      "      vf_explained_var: 0.9611963033676147\n",
      "      vf_loss: 927.30419921875\n",
      "    sample_time_ms: 19909.708\n",
      "    update_time_ms: 5.181\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.9514004514338\n",
      "  time_since_restore: 10577.6793487072\n",
      "  time_this_iter_s: 24.179943799972534\n",
      "  time_total_s: 10577.6793487072\n",
      "  timestamp: 1553976356\n",
      "  timesteps_since_restore: 4480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4480000\n",
      "  training_iteration: 448\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10577 s, 448 iter, 4480000 ts, 948 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-06-19\n",
      "  done: false\n",
      "  episode_len_mean: 177.92\n",
      "  episode_reward_max: 1159.3116332786183\n",
      "  episode_reward_mean: 911.9641864524799\n",
      "  episode_reward_min: -16.969521976996646\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 26004\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.66\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 4490000\n",
      "    num_steps_trained: 4490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8608953952789307\n",
      "      kl: 0.01778287999331951\n",
      "      policy_loss: -0.0010673839133232832\n",
      "      total_loss: 1211.9437255859375\n",
      "      vf_explained_var: 0.9469848275184631\n",
      "      vf_loss: 1211.944091796875\n",
      "    sample_time_ms: 19795.036\n",
      "    update_time_ms: 5.26\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 455.98209322624\n",
      "  time_since_restore: 10600.913841962814\n",
      "  time_this_iter_s: 23.234493255615234\n",
      "  time_total_s: 10600.913841962814\n",
      "  timestamp: 1553976379\n",
      "  timesteps_since_restore: 4490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4490000\n",
      "  training_iteration: 449\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10600 s, 449 iter, 4490000 ts, 912 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-06-42\n",
      "  done: false\n",
      "  episode_len_mean: 179.23\n",
      "  episode_reward_max: 1159.3116332786183\n",
      "  episode_reward_mean: 925.0546303059097\n",
      "  episode_reward_min: 4.815352722075346\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 26059\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.431\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 4500000\n",
      "    num_steps_trained: 4500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6804177761077881\n",
      "      kl: 0.01698862574994564\n",
      "      policy_loss: -0.003129980294033885\n",
      "      total_loss: 649.8095703125\n",
      "      vf_explained_var: 0.9705662131309509\n",
      "      vf_loss: 649.81201171875\n",
      "    sample_time_ms: 19711.192\n",
      "    update_time_ms: 5.172\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 462.5273151529548\n",
      "  time_since_restore: 10623.971073627472\n",
      "  time_this_iter_s: 23.057231664657593\n",
      "  time_total_s: 10623.971073627472\n",
      "  timestamp: 1553976402\n",
      "  timesteps_since_restore: 4500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4500000\n",
      "  training_iteration: 450\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10623 s, 450 iter, 4500000 ts, 925 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-07-06\n",
      "  done: false\n",
      "  episode_len_mean: 176.41\n",
      "  episode_reward_max: 1125.4708619107846\n",
      "  episode_reward_mean: 976.2069072393924\n",
      "  episode_reward_min: 31.40678242855364\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 26117\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.285\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 4510000\n",
      "    num_steps_trained: 4510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8778944611549377\n",
      "      kl: 0.020767763257026672\n",
      "      policy_loss: -0.0011583310551941395\n",
      "      total_loss: 290.89697265625\n",
      "      vf_explained_var: 0.9864926338195801\n",
      "      vf_loss: 290.89739990234375\n",
      "    sample_time_ms: 19703.499\n",
      "    update_time_ms: 5.188\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.1034536196962\n",
      "  time_since_restore: 10647.86334657669\n",
      "  time_this_iter_s: 23.89227294921875\n",
      "  time_total_s: 10647.86334657669\n",
      "  timestamp: 1553976426\n",
      "  timesteps_since_restore: 4510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4510000\n",
      "  training_iteration: 451\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10647 s, 451 iter, 4510000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-07-30\n",
      "  done: false\n",
      "  episode_len_mean: 180.13\n",
      "  episode_reward_max: 1109.9375902744753\n",
      "  episode_reward_mean: 971.9783146743135\n",
      "  episode_reward_min: -70.9708981751975\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 26171\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.008\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 4520000\n",
      "    num_steps_trained: 4520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.042352557182312\n",
      "      kl: 0.01714072749018669\n",
      "      policy_loss: -0.00039005352300591767\n",
      "      total_loss: 490.6246643066406\n",
      "      vf_explained_var: 0.9781928658485413\n",
      "      vf_loss: 490.6243591308594\n",
      "    sample_time_ms: 19815.127\n",
      "    update_time_ms: 5.272\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.98915733715677\n",
      "  time_since_restore: 10671.898034334183\n",
      "  time_this_iter_s: 24.034687757492065\n",
      "  time_total_s: 10671.898034334183\n",
      "  timestamp: 1553976450\n",
      "  timesteps_since_restore: 4520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4520000\n",
      "  training_iteration: 452\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10671 s, 452 iter, 4520000 ts, 972 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-07-53\n",
      "  done: false\n",
      "  episode_len_mean: 181.13\n",
      "  episode_reward_max: 1113.3895991097081\n",
      "  episode_reward_mean: 952.1403530396165\n",
      "  episode_reward_min: -51.59411629934411\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 26229\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.102\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 4530000\n",
      "    num_steps_trained: 4530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8681173920631409\n",
      "      kl: 0.021758316084742546\n",
      "      policy_loss: -0.002225948963314295\n",
      "      total_loss: 816.847412109375\n",
      "      vf_explained_var: 0.9656338691711426\n",
      "      vf_loss: 816.848876953125\n",
      "    sample_time_ms: 19742.128\n",
      "    update_time_ms: 5.065\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.0701765198083\n",
      "  time_since_restore: 10694.962764501572\n",
      "  time_this_iter_s: 23.064730167388916\n",
      "  time_total_s: 10694.962764501572\n",
      "  timestamp: 1553976473\n",
      "  timesteps_since_restore: 4530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4530000\n",
      "  training_iteration: 453\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10694 s, 453 iter, 4530000 ts, 952 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-08-17\n",
      "  done: false\n",
      "  episode_len_mean: 187.23\n",
      "  episode_reward_max: 1146.5017967519923\n",
      "  episode_reward_mean: 917.4120665310584\n",
      "  episode_reward_min: -2.9916454325713175\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 26278\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.768\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 4540000\n",
      "    num_steps_trained: 4540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0202393531799316\n",
      "      kl: 0.016183435916900635\n",
      "      policy_loss: -0.0008783875382505357\n",
      "      total_loss: 846.138427734375\n",
      "      vf_explained_var: 0.959922194480896\n",
      "      vf_loss: 846.1386108398438\n",
      "    sample_time_ms: 19734.178\n",
      "    update_time_ms: 5.12\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 458.7060332655292\n",
      "  time_since_restore: 10719.098821878433\n",
      "  time_this_iter_s: 24.136057376861572\n",
      "  time_total_s: 10719.098821878433\n",
      "  timestamp: 1553976497\n",
      "  timesteps_since_restore: 4540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4540000\n",
      "  training_iteration: 454\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10719 s, 454 iter, 4540000 ts, 917 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 192.89\n",
      "  episode_reward_max: 1146.5017967519923\n",
      "  episode_reward_mean: 920.9772152228996\n",
      "  episode_reward_min: 2.859444317434395\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 26331\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.884\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 4550000\n",
      "    num_steps_trained: 4550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9218958616256714\n",
      "      kl: 0.018056590110063553\n",
      "      policy_loss: -0.004110103007405996\n",
      "      total_loss: 1115.0504150390625\n",
      "      vf_explained_var: 0.9481314420700073\n",
      "      vf_loss: 1115.0538330078125\n",
      "    sample_time_ms: 19754.686\n",
      "    update_time_ms: 5.184\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 460.48860761144977\n",
      "  time_since_restore: 10743.139753103256\n",
      "  time_this_iter_s: 24.040931224822998\n",
      "  time_total_s: 10743.139753103256\n",
      "  timestamp: 1553976521\n",
      "  timesteps_since_restore: 4550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4550000\n",
      "  training_iteration: 455\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10743 s, 455 iter, 4550000 ts, 921 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-09-05\n",
      "  done: false\n",
      "  episode_len_mean: 177.54\n",
      "  episode_reward_max: 1114.81810766257\n",
      "  episode_reward_mean: 940.2159574237712\n",
      "  episode_reward_min: 2.859444317434395\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 26388\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.876\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 4560000\n",
      "    num_steps_trained: 4560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7451159954071045\n",
      "      kl: 0.01934277079999447\n",
      "      policy_loss: -0.0025031426921486855\n",
      "      total_loss: 769.61865234375\n",
      "      vf_explained_var: 0.965358555316925\n",
      "      vf_loss: 769.6204223632812\n",
      "    sample_time_ms: 19749.347\n",
      "    update_time_ms: 5.228\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.1079787118856\n",
      "  time_since_restore: 10766.766643047333\n",
      "  time_this_iter_s: 23.626889944076538\n",
      "  time_total_s: 10766.766643047333\n",
      "  timestamp: 1553976545\n",
      "  timesteps_since_restore: 4560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4560000\n",
      "  training_iteration: 456\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10766 s, 456 iter, 4560000 ts, 940 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-09-29\n",
      "  done: false\n",
      "  episode_len_mean: 184.41\n",
      "  episode_reward_max: 1155.6775298647283\n",
      "  episode_reward_mean: 963.2289709751371\n",
      "  episode_reward_min: -30.124520466483347\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 26439\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.168\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 4570000\n",
      "    num_steps_trained: 4570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9911110997200012\n",
      "      kl: 0.02277776598930359\n",
      "      policy_loss: -0.0033010293263942003\n",
      "      total_loss: 398.8843994140625\n",
      "      vf_explained_var: 0.9816352725028992\n",
      "      vf_loss: 398.8868713378906\n",
      "    sample_time_ms: 19790.327\n",
      "    update_time_ms: 5.459\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.61448548756846\n",
      "  time_since_restore: 10790.527116060257\n",
      "  time_this_iter_s: 23.760473012924194\n",
      "  time_total_s: 10790.527116060257\n",
      "  timestamp: 1553976569\n",
      "  timesteps_since_restore: 4570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4570000\n",
      "  training_iteration: 457\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10790 s, 457 iter, 4570000 ts, 963 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-09-53\n",
      "  done: false\n",
      "  episode_len_mean: 187.25\n",
      "  episode_reward_max: 1155.6775298647283\n",
      "  episode_reward_mean: 969.1072444930876\n",
      "  episode_reward_min: -33.640201752467334\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 26496\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.675\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 4580000\n",
      "    num_steps_trained: 4580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8031474351882935\n",
      "      kl: 0.01939479447901249\n",
      "      policy_loss: -0.0019248008029535413\n",
      "      total_loss: 1064.96875\n",
      "      vf_explained_var: 0.9523308873176575\n",
      "      vf_loss: 1064.9700927734375\n",
      "    sample_time_ms: 19809.38\n",
      "    update_time_ms: 5.094\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.55362224654397\n",
      "  time_since_restore: 10814.848822832108\n",
      "  time_this_iter_s: 24.321706771850586\n",
      "  time_total_s: 10814.848822832108\n",
      "  timestamp: 1553976593\n",
      "  timesteps_since_restore: 4580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4580000\n",
      "  training_iteration: 458\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10814 s, 458 iter, 4580000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-10-18\n",
      "  done: false\n",
      "  episode_len_mean: 185.7\n",
      "  episode_reward_max: 1135.0119098717041\n",
      "  episode_reward_mean: 949.5395070125128\n",
      "  episode_reward_min: -56.03600559334592\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 26548\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.166\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 4590000\n",
      "    num_steps_trained: 4590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9470224380493164\n",
      "      kl: 0.016906486824154854\n",
      "      policy_loss: -0.00042398428195156157\n",
      "      total_loss: 676.5531616210938\n",
      "      vf_explained_var: 0.9687016010284424\n",
      "      vf_loss: 676.5528564453125\n",
      "    sample_time_ms: 19915.219\n",
      "    update_time_ms: 5.155\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.76975350625645\n",
      "  time_since_restore: 10839.106741189957\n",
      "  time_this_iter_s: 24.25791835784912\n",
      "  time_total_s: 10839.106741189957\n",
      "  timestamp: 1553976618\n",
      "  timesteps_since_restore: 4590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4590000\n",
      "  training_iteration: 459\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10839 s, 459 iter, 4590000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 180.62\n",
      "  episode_reward_max: 1143.5937716776186\n",
      "  episode_reward_mean: 905.9429272469384\n",
      "  episode_reward_min: -56.03600559334592\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 26605\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.606\n",
      "    load_time_ms: 1.452\n",
      "    num_steps_sampled: 4600000\n",
      "    num_steps_trained: 4600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8541198968887329\n",
      "      kl: 0.016653412953019142\n",
      "      policy_loss: -0.0009980598697438836\n",
      "      total_loss: 1056.787841796875\n",
      "      vf_explained_var: 0.95365971326828\n",
      "      vf_loss: 1056.7882080078125\n",
      "    sample_time_ms: 20070.835\n",
      "    update_time_ms: 5.179\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.97146362346916\n",
      "  time_since_restore: 10863.761813640594\n",
      "  time_this_iter_s: 24.655072450637817\n",
      "  time_total_s: 10863.761813640594\n",
      "  timestamp: 1553976642\n",
      "  timesteps_since_restore: 4600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4600000\n",
      "  training_iteration: 460\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10863 s, 460 iter, 4600000 ts, 906 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 180.46\n",
      "  episode_reward_max: 1143.527344392858\n",
      "  episode_reward_mean: 927.7633991698718\n",
      "  episode_reward_min: -41.89392370839053\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 26660\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.792\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 4610000\n",
      "    num_steps_trained: 4610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8825022578239441\n",
      "      kl: 0.022971566766500473\n",
      "      policy_loss: -0.005232092924416065\n",
      "      total_loss: 815.7666015625\n",
      "      vf_explained_var: 0.9622624516487122\n",
      "      vf_loss: 815.7709350585938\n",
      "    sample_time_ms: 20143.437\n",
      "    update_time_ms: 5.245\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 463.88169958493586\n",
      "  time_since_restore: 10888.460332155228\n",
      "  time_this_iter_s: 24.69851851463318\n",
      "  time_total_s: 10888.460332155228\n",
      "  timestamp: 1553976667\n",
      "  timesteps_since_restore: 4610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4610000\n",
      "  training_iteration: 461\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10888 s, 461 iter, 4610000 ts, 928 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-11-30\n",
      "  done: false\n",
      "  episode_len_mean: 179.63\n",
      "  episode_reward_max: 1143.527344392858\n",
      "  episode_reward_mean: 978.5927573931384\n",
      "  episode_reward_min: -26.543056789602616\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 26716\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.807\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 4620000\n",
      "    num_steps_trained: 4620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7422218918800354\n",
      "      kl: 0.03721558302640915\n",
      "      policy_loss: -0.0022728496696799994\n",
      "      total_loss: 156.5262451171875\n",
      "      vf_explained_var: 0.993112325668335\n",
      "      vf_loss: 156.52711486816406\n",
      "    sample_time_ms: 20078.153\n",
      "    update_time_ms: 5.354\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.29637869656915\n",
      "  time_since_restore: 10911.86642241478\n",
      "  time_this_iter_s: 23.406090259552002\n",
      "  time_total_s: 10911.86642241478\n",
      "  timestamp: 1553976690\n",
      "  timesteps_since_restore: 4620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4620000\n",
      "  training_iteration: 462\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10911 s, 462 iter, 4620000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-11-55\n",
      "  done: false\n",
      "  episode_len_mean: 177.04\n",
      "  episode_reward_max: 1153.632233840608\n",
      "  episode_reward_mean: 996.5780906421992\n",
      "  episode_reward_min: 64.78299167949507\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 26772\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.939\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 4630000\n",
      "    num_steps_trained: 4630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8722201585769653\n",
      "      kl: 0.01698409579694271\n",
      "      policy_loss: -0.0015404323348775506\n",
      "      total_loss: 327.8082275390625\n",
      "      vf_explained_var: 0.9849227666854858\n",
      "      vf_loss: 327.80914306640625\n",
      "    sample_time_ms: 20220.139\n",
      "    update_time_ms: 5.492\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.2890453210996\n",
      "  time_since_restore: 10936.354760885239\n",
      "  time_this_iter_s: 24.488338470458984\n",
      "  time_total_s: 10936.354760885239\n",
      "  timestamp: 1553976715\n",
      "  timesteps_since_restore: 4630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4630000\n",
      "  training_iteration: 463\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10936 s, 463 iter, 4630000 ts, 997 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-12-19\n",
      "  done: false\n",
      "  episode_len_mean: 180.05\n",
      "  episode_reward_max: 1153.632233840608\n",
      "  episode_reward_mean: 953.1879950168155\n",
      "  episode_reward_min: -83.35559122387053\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 26826\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.141\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 4640000\n",
      "    num_steps_trained: 4640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8612574934959412\n",
      "      kl: 0.015184464864432812\n",
      "      policy_loss: -0.0014099692925810814\n",
      "      total_loss: 880.9937744140625\n",
      "      vf_explained_var: 0.9591150283813477\n",
      "      vf_loss: 880.9946899414062\n",
      "    sample_time_ms: 20164.879\n",
      "    update_time_ms: 5.496\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.5939975084078\n",
      "  time_since_restore: 10959.90006685257\n",
      "  time_this_iter_s: 23.545305967330933\n",
      "  time_total_s: 10959.90006685257\n",
      "  timestamp: 1553976739\n",
      "  timesteps_since_restore: 4640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4640000\n",
      "  training_iteration: 464\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10959 s, 464 iter, 4640000 ts, 953 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-12-43\n",
      "  done: false\n",
      "  episode_len_mean: 176.85\n",
      "  episode_reward_max: 1128.5950257638174\n",
      "  episode_reward_mean: 905.504362587884\n",
      "  episode_reward_min: -91.19056692218561\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 26884\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.527\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 4650000\n",
      "    num_steps_trained: 4650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7658829689025879\n",
      "      kl: 0.020604964345693588\n",
      "      policy_loss: -0.004224024247378111\n",
      "      total_loss: 1414.54443359375\n",
      "      vf_explained_var: 0.9390554428100586\n",
      "      vf_loss: 1414.5478515625\n",
      "    sample_time_ms: 20200.927\n",
      "    update_time_ms: 5.54\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.7521812939421\n",
      "  time_since_restore: 10984.306019306183\n",
      "  time_this_iter_s: 24.40595245361328\n",
      "  time_total_s: 10984.306019306183\n",
      "  timestamp: 1553976763\n",
      "  timesteps_since_restore: 4650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4650000\n",
      "  training_iteration: 465\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 10984 s, 465 iter, 4650000 ts, 906 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-13-07\n",
      "  done: false\n",
      "  episode_len_mean: 172.82\n",
      "  episode_reward_max: 1128.5950257638174\n",
      "  episode_reward_mean: 902.788395330249\n",
      "  episode_reward_min: -91.19056692218561\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 26942\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.635\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 4660000\n",
      "    num_steps_trained: 4660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7030812501907349\n",
      "      kl: 0.015881262719631195\n",
      "      policy_loss: -0.0036577850114554167\n",
      "      total_loss: 1231.00830078125\n",
      "      vf_explained_var: 0.949551522731781\n",
      "      vf_loss: 1231.011474609375\n",
      "    sample_time_ms: 20195.041\n",
      "    update_time_ms: 5.582\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 451.3941976651245\n",
      "  time_since_restore: 11007.950581073761\n",
      "  time_this_iter_s: 23.644561767578125\n",
      "  time_total_s: 11007.950581073761\n",
      "  timestamp: 1553976787\n",
      "  timesteps_since_restore: 4660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4660000\n",
      "  training_iteration: 466\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11007 s, 466 iter, 4660000 ts, 903 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-13-29\n",
      "  done: false\n",
      "  episode_len_mean: 184.89\n",
      "  episode_reward_max: 1152.8334761808765\n",
      "  episode_reward_mean: 947.9032037942633\n",
      "  episode_reward_min: -3.3593191630530725\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 26994\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.372\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 4670000\n",
      "    num_steps_trained: 4670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.893829345703125\n",
      "      kl: 0.0339694619178772\n",
      "      policy_loss: -0.0005646126228384674\n",
      "      total_loss: 128.7133026123047\n",
      "      vf_explained_var: 0.9939948916435242\n",
      "      vf_loss: 128.71258544921875\n",
      "    sample_time_ms: 20104.769\n",
      "    update_time_ms: 5.607\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.95160189713164\n",
      "  time_since_restore: 11030.744443655014\n",
      "  time_this_iter_s: 22.79386258125305\n",
      "  time_total_s: 11030.744443655014\n",
      "  timestamp: 1553976809\n",
      "  timesteps_since_restore: 4670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4670000\n",
      "  training_iteration: 467\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11030 s, 467 iter, 4670000 ts, 948 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-13-53\n",
      "  done: false\n",
      "  episode_len_mean: 193.27\n",
      "  episode_reward_max: 1152.8334761808765\n",
      "  episode_reward_mean: 993.5459973970399\n",
      "  episode_reward_min: 114.87582656519349\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 27046\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.695\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 4680000\n",
      "    num_steps_trained: 4680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8094145059585571\n",
      "      kl: 0.010037328116595745\n",
      "      policy_loss: -0.0016592618776485324\n",
      "      total_loss: 238.36180114746094\n",
      "      vf_explained_var: 0.9881474375724792\n",
      "      vf_loss: 238.3630828857422\n",
      "    sample_time_ms: 20008.371\n",
      "    update_time_ms: 5.59\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.77299869851987\n",
      "  time_since_restore: 11054.094552516937\n",
      "  time_this_iter_s: 23.350108861923218\n",
      "  time_total_s: 11054.094552516937\n",
      "  timestamp: 1553976833\n",
      "  timesteps_since_restore: 4680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4680000\n",
      "  training_iteration: 468\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11054 s, 468 iter, 4680000 ts, 994 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-14-17\n",
      "  done: false\n",
      "  episode_len_mean: 177.41\n",
      "  episode_reward_max: 1122.3928354820928\n",
      "  episode_reward_mean: 932.0327317939566\n",
      "  episode_reward_min: -20.367154967144216\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 27106\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.225\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 4690000\n",
      "    num_steps_trained: 4690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9235362410545349\n",
      "      kl: 0.02146187424659729\n",
      "      policy_loss: -0.005562572740018368\n",
      "      total_loss: 1290.5552978515625\n",
      "      vf_explained_var: 0.9480262398719788\n",
      "      vf_loss: 1290.5599365234375\n",
      "    sample_time_ms: 20011.235\n",
      "    update_time_ms: 5.532\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.0163658969784\n",
      "  time_since_restore: 11078.42647767067\n",
      "  time_this_iter_s: 24.3319251537323\n",
      "  time_total_s: 11078.42647767067\n",
      "  timestamp: 1553976857\n",
      "  timesteps_since_restore: 4690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4690000\n",
      "  training_iteration: 469\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11078 s, 469 iter, 4690000 ts, 932 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-14-41\n",
      "  done: false\n",
      "  episode_len_mean: 178.41\n",
      "  episode_reward_max: 1129.3155341978895\n",
      "  episode_reward_mean: 938.0876050847261\n",
      "  episode_reward_min: -20.367154967144216\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 27160\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.318\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 4700000\n",
      "    num_steps_trained: 4700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8306893706321716\n",
      "      kl: 0.024003248661756516\n",
      "      policy_loss: -0.0016237669624388218\n",
      "      total_loss: 169.22679138183594\n",
      "      vf_explained_var: 0.9922627210617065\n",
      "      vf_loss: 169.2274932861328\n",
      "    sample_time_ms: 19940.859\n",
      "    update_time_ms: 5.526\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.043802542363\n",
      "  time_since_restore: 11102.380829334259\n",
      "  time_this_iter_s: 23.954351663589478\n",
      "  time_total_s: 11102.380829334259\n",
      "  timestamp: 1553976881\n",
      "  timesteps_since_restore: 4700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4700000\n",
      "  training_iteration: 470\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11102 s, 470 iter, 4700000 ts, 938 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 177.88\n",
      "  episode_reward_max: 1129.3155341978895\n",
      "  episode_reward_mean: 957.5506034766389\n",
      "  episode_reward_min: -36.87282292601779\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 27217\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.131\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 4710000\n",
      "    num_steps_trained: 4710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.875857412815094\n",
      "      kl: 0.015229952521622181\n",
      "      policy_loss: -0.0008622026070952415\n",
      "      total_loss: 756.095458984375\n",
      "      vf_explained_var: 0.9680159091949463\n",
      "      vf_loss: 756.0958251953125\n",
      "    sample_time_ms: 19954.308\n",
      "    update_time_ms: 5.477\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.7753017383194\n",
      "  time_since_restore: 11127.127096414566\n",
      "  time_this_iter_s: 24.746267080307007\n",
      "  time_total_s: 11127.127096414566\n",
      "  timestamp: 1553976906\n",
      "  timesteps_since_restore: 4710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4710000\n",
      "  training_iteration: 471\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11127 s, 471 iter, 4710000 ts, 958 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-15-30\n",
      "  done: false\n",
      "  episode_len_mean: 176.68\n",
      "  episode_reward_max: 1117.1678590735935\n",
      "  episode_reward_mean: 935.6664839286027\n",
      "  episode_reward_min: -36.87282292601779\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 27273\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.409\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 4720000\n",
      "    num_steps_trained: 4720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7966810464859009\n",
      "      kl: 0.015696687623858452\n",
      "      policy_loss: -0.00026225796318612993\n",
      "      total_loss: 1092.41015625\n",
      "      vf_explained_var: 0.9525033235549927\n",
      "      vf_loss: 1092.409912109375\n",
      "    sample_time_ms: 20043.76\n",
      "    update_time_ms: 5.333\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.8332419643013\n",
      "  time_since_restore: 11151.449749231339\n",
      "  time_this_iter_s: 24.32265281677246\n",
      "  time_total_s: 11151.449749231339\n",
      "  timestamp: 1553976930\n",
      "  timesteps_since_restore: 4720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4720000\n",
      "  training_iteration: 472\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11151 s, 472 iter, 4720000 ts, 936 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-15-55\n",
      "  done: false\n",
      "  episode_len_mean: 178.35\n",
      "  episode_reward_max: 1150.6549786706378\n",
      "  episode_reward_mean: 948.2750736772088\n",
      "  episode_reward_min: -23.221700816458366\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 27328\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.756\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 4730000\n",
      "    num_steps_trained: 4730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6885159015655518\n",
      "      kl: 0.02416102960705757\n",
      "      policy_loss: -0.004264358896762133\n",
      "      total_loss: 420.38763427734375\n",
      "      vf_explained_var: 0.9806064963340759\n",
      "      vf_loss: 420.39093017578125\n",
      "    sample_time_ms: 20024.3\n",
      "    update_time_ms: 5.318\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.1375368386045\n",
      "  time_since_restore: 11175.704604387283\n",
      "  time_this_iter_s: 24.254855155944824\n",
      "  time_total_s: 11175.704604387283\n",
      "  timestamp: 1553976955\n",
      "  timesteps_since_restore: 4730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4730000\n",
      "  training_iteration: 473\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11175 s, 473 iter, 4730000 ts, 948 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-16-18\n",
      "  done: false\n",
      "  episode_len_mean: 186.8\n",
      "  episode_reward_max: 1150.6549786706378\n",
      "  episode_reward_mean: 968.0716073430096\n",
      "  episode_reward_min: 19.693305405435922\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 27379\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.651\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 4740000\n",
      "    num_steps_trained: 4740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8720667958259583\n",
      "      kl: 0.018629174679517746\n",
      "      policy_loss: -0.00013828717055730522\n",
      "      total_loss: 666.701904296875\n",
      "      vf_explained_var: 0.9670509696006775\n",
      "      vf_loss: 666.7012939453125\n",
      "    sample_time_ms: 20017.727\n",
      "    update_time_ms: 5.229\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.0358036715048\n",
      "  time_since_restore: 11199.21393084526\n",
      "  time_this_iter_s: 23.509326457977295\n",
      "  time_total_s: 11199.21393084526\n",
      "  timestamp: 1553976978\n",
      "  timesteps_since_restore: 4740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4740000\n",
      "  training_iteration: 474\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11199 s, 474 iter, 4740000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-16-42\n",
      "  done: false\n",
      "  episode_len_mean: 182.36\n",
      "  episode_reward_max: 1119.427639870186\n",
      "  episode_reward_mean: 959.2796976346259\n",
      "  episode_reward_min: 19.693305405435922\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 27438\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.716\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 4750000\n",
      "    num_steps_trained: 4750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6800675988197327\n",
      "      kl: 0.01859212853014469\n",
      "      policy_loss: -0.0031217921059578657\n",
      "      total_loss: 127.10787200927734\n",
      "      vf_explained_var: 0.9948022365570068\n",
      "      vf_loss: 127.11029052734375\n",
      "    sample_time_ms: 19991.411\n",
      "    update_time_ms: 5.135\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.6398488173129\n",
      "  time_since_restore: 11223.349005699158\n",
      "  time_this_iter_s: 24.135074853897095\n",
      "  time_total_s: 11223.349005699158\n",
      "  timestamp: 1553977002\n",
      "  timesteps_since_restore: 4750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4750000\n",
      "  training_iteration: 475\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11223 s, 475 iter, 4750000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-17-06\n",
      "  done: false\n",
      "  episode_len_mean: 173.25\n",
      "  episode_reward_max: 1127.373331649795\n",
      "  episode_reward_mean: 1004.4000840120528\n",
      "  episode_reward_min: 41.913930790296064\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 27495\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.141\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 4760000\n",
      "    num_steps_trained: 4760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6836113929748535\n",
      "      kl: 0.01954001933336258\n",
      "      policy_loss: -0.0028246089350432158\n",
      "      total_loss: 218.80206298828125\n",
      "      vf_explained_var: 0.9909380674362183\n",
      "      vf_loss: 218.80413818359375\n",
      "    sample_time_ms: 20001.781\n",
      "    update_time_ms: 5.065\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 502.2000420060265\n",
      "  time_since_restore: 11247.009789705276\n",
      "  time_this_iter_s: 23.660784006118774\n",
      "  time_total_s: 11247.009789705276\n",
      "  timestamp: 1553977026\n",
      "  timesteps_since_restore: 4760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4760000\n",
      "  training_iteration: 476\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11247 s, 476 iter, 4760000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-17-31\n",
      "  done: false\n",
      "  episode_len_mean: 169.47\n",
      "  episode_reward_max: 1144.0362329557183\n",
      "  episode_reward_mean: 963.536046687854\n",
      "  episode_reward_min: -30.622740089259025\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 27556\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.579\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 4770000\n",
      "    num_steps_trained: 4770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7763574719429016\n",
      "      kl: 0.011740832589566708\n",
      "      policy_loss: -0.0005556972464546561\n",
      "      total_loss: 787.12158203125\n",
      "      vf_explained_var: 0.9678407311439514\n",
      "      vf_loss: 787.1216430664062\n",
      "    sample_time_ms: 20155.304\n",
      "    update_time_ms: 5.005\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.76802334392704\n",
      "  time_since_restore: 11271.395074605942\n",
      "  time_this_iter_s: 24.385284900665283\n",
      "  time_total_s: 11271.395074605942\n",
      "  timestamp: 1553977051\n",
      "  timesteps_since_restore: 4770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4770000\n",
      "  training_iteration: 477\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11271 s, 477 iter, 4770000 ts, 964 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-17-54\n",
      "  done: false\n",
      "  episode_len_mean: 171.93\n",
      "  episode_reward_max: 1135.4093949718356\n",
      "  episode_reward_mean: 924.0176473303861\n",
      "  episode_reward_min: -43.99681635550678\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 27611\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.269\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 4780000\n",
      "    num_steps_trained: 4780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8119307160377502\n",
      "      kl: 0.016067644581198692\n",
      "      policy_loss: -0.0008596170227974653\n",
      "      total_loss: 1204.7802734375\n",
      "      vf_explained_var: 0.9433290362358093\n",
      "      vf_loss: 1204.7803955078125\n",
      "    sample_time_ms: 20159.908\n",
      "    update_time_ms: 5.071\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 462.00882366519295\n",
      "  time_since_restore: 11294.798380613327\n",
      "  time_this_iter_s: 23.403306007385254\n",
      "  time_total_s: 11294.798380613327\n",
      "  timestamp: 1553977074\n",
      "  timesteps_since_restore: 4780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4780000\n",
      "  training_iteration: 478\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11294 s, 478 iter, 4780000 ts, 924 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-18-18\n",
      "  done: false\n",
      "  episode_len_mean: 183.32\n",
      "  episode_reward_max: 1126.6041435537143\n",
      "  episode_reward_mean: 952.2867129837418\n",
      "  episode_reward_min: -87.7920816306633\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 27664\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.766\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 4790000\n",
      "    num_steps_trained: 4790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8049721121788025\n",
      "      kl: 0.02706083282828331\n",
      "      policy_loss: -0.0032597146928310394\n",
      "      total_loss: 368.3543701171875\n",
      "      vf_explained_var: 0.9819574356079102\n",
      "      vf_loss: 368.35662841796875\n",
      "    sample_time_ms: 20129.201\n",
      "    update_time_ms: 5.032\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.14335649187086\n",
      "  time_since_restore: 11318.845108747482\n",
      "  time_this_iter_s: 24.046728134155273\n",
      "  time_total_s: 11318.845108747482\n",
      "  timestamp: 1553977098\n",
      "  timesteps_since_restore: 4790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4790000\n",
      "  training_iteration: 479\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11318 s, 479 iter, 4790000 ts, 952 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-18-42\n",
      "  done: false\n",
      "  episode_len_mean: 178.87\n",
      "  episode_reward_max: 1110.2989792244364\n",
      "  episode_reward_mean: 977.61773025854\n",
      "  episode_reward_min: -87.7920816306633\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 27721\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.325\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 4800000\n",
      "    num_steps_trained: 4800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7580445408821106\n",
      "      kl: 0.022764431312680244\n",
      "      policy_loss: -0.0004981693346053362\n",
      "      total_loss: 487.55084228515625\n",
      "      vf_explained_var: 0.9792429804801941\n",
      "      vf_loss: 487.55047607421875\n",
      "    sample_time_ms: 20120.849\n",
      "    update_time_ms: 5.03\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.80886512927003\n",
      "  time_since_restore: 11342.704578638077\n",
      "  time_this_iter_s: 23.859469890594482\n",
      "  time_total_s: 11342.704578638077\n",
      "  timestamp: 1553977122\n",
      "  timesteps_since_restore: 4800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4800000\n",
      "  training_iteration: 480\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11342 s, 480 iter, 4800000 ts, 978 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-19-06\n",
      "  done: false\n",
      "  episode_len_mean: 170.69\n",
      "  episode_reward_max: 1143.7098662863941\n",
      "  episode_reward_mean: 949.3618672591166\n",
      "  episode_reward_min: -81.47302891430174\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 27779\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.86\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 4810000\n",
      "    num_steps_trained: 4810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6495079398155212\n",
      "      kl: 0.02237693779170513\n",
      "      policy_loss: -0.0014988314360380173\n",
      "      total_loss: 1138.09375\n",
      "      vf_explained_var: 0.9491794109344482\n",
      "      vf_loss: 1138.0943603515625\n",
      "    sample_time_ms: 20004.854\n",
      "    update_time_ms: 5.018\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.6809336295582\n",
      "  time_since_restore: 11366.324228048325\n",
      "  time_this_iter_s: 23.619649410247803\n",
      "  time_total_s: 11366.324228048325\n",
      "  timestamp: 1553977146\n",
      "  timesteps_since_restore: 4810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4810000\n",
      "  training_iteration: 481\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11366 s, 481 iter, 4810000 ts, 949 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-19-30\n",
      "  done: false\n",
      "  episode_len_mean: 178.24\n",
      "  episode_reward_max: 1143.7098662863941\n",
      "  episode_reward_mean: 929.8010469715515\n",
      "  episode_reward_min: -90.70017601679739\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 27832\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.438\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 4820000\n",
      "    num_steps_trained: 4820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8456861972808838\n",
      "      kl: 0.01925099454820156\n",
      "      policy_loss: 0.00034910746035166085\n",
      "      total_loss: 774.4971923828125\n",
      "      vf_explained_var: 0.9658163189888\n",
      "      vf_loss: 774.4962158203125\n",
      "    sample_time_ms: 19976.682\n",
      "    update_time_ms: 5.15\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 464.9005234857757\n",
      "  time_since_restore: 11390.391099214554\n",
      "  time_this_iter_s: 24.066871166229248\n",
      "  time_total_s: 11390.391099214554\n",
      "  timestamp: 1553977170\n",
      "  timesteps_since_restore: 4820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4820000\n",
      "  training_iteration: 482\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11390 s, 482 iter, 4820000 ts, 930 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-19-54\n",
      "  done: false\n",
      "  episode_len_mean: 181.17\n",
      "  episode_reward_max: 1142.331845268229\n",
      "  episode_reward_mean: 935.2475763260154\n",
      "  episode_reward_min: -104.71374579089206\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 27888\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.153\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 4830000\n",
      "    num_steps_trained: 4830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7922926545143127\n",
      "      kl: 0.019918890669941902\n",
      "      policy_loss: -0.002629618626087904\n",
      "      total_loss: 618.8715209960938\n",
      "      vf_explained_var: 0.974309504032135\n",
      "      vf_loss: 618.8734130859375\n",
      "    sample_time_ms: 19983.561\n",
      "    update_time_ms: 5.166\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.6237881630077\n",
      "  time_since_restore: 11414.692126512527\n",
      "  time_this_iter_s: 24.301027297973633\n",
      "  time_total_s: 11414.692126512527\n",
      "  timestamp: 1553977194\n",
      "  timesteps_since_restore: 4830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4830000\n",
      "  training_iteration: 483\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11414 s, 483 iter, 4830000 ts, 935 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-20-19\n",
      "  done: false\n",
      "  episode_len_mean: 177.62\n",
      "  episode_reward_max: 1142.331845268229\n",
      "  episode_reward_mean: 977.3341181105387\n",
      "  episode_reward_min: 31.308585907327114\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 27948\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.56\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 4840000\n",
      "    num_steps_trained: 4840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7255322933197021\n",
      "      kl: 0.027880845591425896\n",
      "      policy_loss: -0.003429759293794632\n",
      "      total_loss: 388.1324157714844\n",
      "      vf_explained_var: 0.9841206669807434\n",
      "      vf_loss: 388.134765625\n",
      "    sample_time_ms: 20077.36\n",
      "    update_time_ms: 5.078\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.66705905526936\n",
      "  time_since_restore: 11439.13182592392\n",
      "  time_this_iter_s: 24.439699411392212\n",
      "  time_total_s: 11439.13182592392\n",
      "  timestamp: 1553977219\n",
      "  timesteps_since_restore: 4840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4840000\n",
      "  training_iteration: 484\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11439 s, 484 iter, 4840000 ts, 977 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-20-43\n",
      "  done: false\n",
      "  episode_len_mean: 168.69\n",
      "  episode_reward_max: 1151.7535630303582\n",
      "  episode_reward_mean: 954.7634326790302\n",
      "  episode_reward_min: -75.56402804794654\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 28006\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.455\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 4850000\n",
      "    num_steps_trained: 4850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7120863199234009\n",
      "      kl: 0.029018627479672432\n",
      "      policy_loss: -0.004158605355769396\n",
      "      total_loss: 845.584228515625\n",
      "      vf_explained_var: 0.9616016745567322\n",
      "      vf_loss: 845.5873413085938\n",
      "    sample_time_ms: 20127.686\n",
      "    update_time_ms: 5.068\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.381716339515\n",
      "  time_since_restore: 11463.755747318268\n",
      "  time_this_iter_s: 24.623921394348145\n",
      "  time_total_s: 11463.755747318268\n",
      "  timestamp: 1553977243\n",
      "  timesteps_since_restore: 4850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4850000\n",
      "  training_iteration: 485\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11463 s, 485 iter, 4850000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-21-07\n",
      "  done: false\n",
      "  episode_len_mean: 173.39\n",
      "  episode_reward_max: 1151.7535630303582\n",
      "  episode_reward_mean: 954.4110616449765\n",
      "  episode_reward_min: -98.39698639724372\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 28062\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.115\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 4860000\n",
      "    num_steps_trained: 4860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8761088252067566\n",
      "      kl: 0.027667393907904625\n",
      "      policy_loss: -0.0027002806309610605\n",
      "      total_loss: 446.09814453125\n",
      "      vf_explained_var: 0.9804345965385437\n",
      "      vf_loss: 446.0997619628906\n",
      "    sample_time_ms: 20142.595\n",
      "    update_time_ms: 5.119\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.20553082248824\n",
      "  time_since_restore: 11487.753976345062\n",
      "  time_this_iter_s: 23.998229026794434\n",
      "  time_total_s: 11487.753976345062\n",
      "  timestamp: 1553977267\n",
      "  timesteps_since_restore: 4860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4860000\n",
      "  training_iteration: 486\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11487 s, 486 iter, 4860000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-21-32\n",
      "  done: false\n",
      "  episode_len_mean: 183.36\n",
      "  episode_reward_max: 1137.1418877249341\n",
      "  episode_reward_mean: 936.0412891213529\n",
      "  episode_reward_min: -98.39698639724372\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 28115\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.788\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 4870000\n",
      "    num_steps_trained: 4870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9479446411132812\n",
      "      kl: 0.026410941034555435\n",
      "      policy_loss: -0.004013323690742254\n",
      "      total_loss: 1032.6790771484375\n",
      "      vf_explained_var: 0.9548377990722656\n",
      "      vf_loss: 1032.68212890625\n",
      "    sample_time_ms: 20131.107\n",
      "    update_time_ms: 5.324\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.02064456067643\n",
      "  time_since_restore: 11511.99975323677\n",
      "  time_this_iter_s: 24.245776891708374\n",
      "  time_total_s: 11511.99975323677\n",
      "  timestamp: 1553977292\n",
      "  timesteps_since_restore: 4870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4870000\n",
      "  training_iteration: 487\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11511 s, 487 iter, 4870000 ts, 936 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-21-56\n",
      "  done: false\n",
      "  episode_len_mean: 177.14\n",
      "  episode_reward_max: 1129.2639870775984\n",
      "  episode_reward_mean: 948.772731198852\n",
      "  episode_reward_min: -74.92580996370793\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 28172\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.12\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 4880000\n",
      "    num_steps_trained: 4880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037656936794519424\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8386803865432739\n",
      "      kl: 0.04113062843680382\n",
      "      policy_loss: 0.003948718775063753\n",
      "      total_loss: 703.9479370117188\n",
      "      vf_explained_var: 0.9696846008300781\n",
      "      vf_loss: 703.9423828125\n",
      "    sample_time_ms: 20196.329\n",
      "    update_time_ms: 5.303\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.386365599426\n",
      "  time_since_restore: 11536.078196048737\n",
      "  time_this_iter_s: 24.078442811965942\n",
      "  time_total_s: 11536.078196048737\n",
      "  timestamp: 1553977316\n",
      "  timesteps_since_restore: 4880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4880000\n",
      "  training_iteration: 488\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11536 s, 488 iter, 4880000 ts, 949 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-22-20\n",
      "  done: false\n",
      "  episode_len_mean: 176.12\n",
      "  episode_reward_max: 1139.543053368881\n",
      "  episode_reward_mean: 974.507806880882\n",
      "  episode_reward_min: -92.91521803792004\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 28231\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.849\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 4890000\n",
      "    num_steps_trained: 4890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7820128202438354\n",
      "      kl: 0.018018165603280067\n",
      "      policy_loss: -0.0017643627943471074\n",
      "      total_loss: 470.7867736816406\n",
      "      vf_explained_var: 0.9781621098518372\n",
      "      vf_loss: 470.7875061035156\n",
      "    sample_time_ms: 20197.157\n",
      "    update_time_ms: 5.189\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.2539034404409\n",
      "  time_since_restore: 11560.09181547165\n",
      "  time_this_iter_s: 24.013619422912598\n",
      "  time_total_s: 11560.09181547165\n",
      "  timestamp: 1553977340\n",
      "  timesteps_since_restore: 4890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4890000\n",
      "  training_iteration: 489\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11560 s, 489 iter, 4890000 ts, 975 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-22-44\n",
      "  done: false\n",
      "  episode_len_mean: 181.05\n",
      "  episode_reward_max: 1139.543053368881\n",
      "  episode_reward_mean: 973.1136689613697\n",
      "  episode_reward_min: -43.11211179050645\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 28284\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.163\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 4900000\n",
      "    num_steps_trained: 4900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9120293855667114\n",
      "      kl: 0.025941548869013786\n",
      "      policy_loss: -0.004527303855866194\n",
      "      total_loss: 915.4937744140625\n",
      "      vf_explained_var: 0.9582017064094543\n",
      "      vf_loss: 915.4967651367188\n",
      "    sample_time_ms: 20203.729\n",
      "    update_time_ms: 5.114\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.55683448068476\n",
      "  time_since_restore: 11584.016073226929\n",
      "  time_this_iter_s: 23.92425775527954\n",
      "  time_total_s: 11584.016073226929\n",
      "  timestamp: 1553977364\n",
      "  timesteps_since_restore: 4900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4900000\n",
      "  training_iteration: 490\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11584 s, 490 iter, 4900000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-23-08\n",
      "  done: false\n",
      "  episode_len_mean: 180.46\n",
      "  episode_reward_max: 1103.7401792569501\n",
      "  episode_reward_mean: 964.161457231231\n",
      "  episode_reward_min: -43.11211179050645\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 28341\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.456\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 4910000\n",
      "    num_steps_trained: 4910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8490656614303589\n",
      "      kl: 0.016961270943284035\n",
      "      policy_loss: -0.00039312586886808276\n",
      "      total_loss: 454.1075744628906\n",
      "      vf_explained_var: 0.9798892140388489\n",
      "      vf_loss: 454.1070861816406\n",
      "    sample_time_ms: 20236.832\n",
      "    update_time_ms: 5.255\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.0807286156155\n",
      "  time_since_restore: 11608.032847881317\n",
      "  time_this_iter_s: 24.016774654388428\n",
      "  time_total_s: 11608.032847881317\n",
      "  timestamp: 1553977388\n",
      "  timesteps_since_restore: 4910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4910000\n",
      "  training_iteration: 491\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11608 s, 491 iter, 4910000 ts, 964 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-23-32\n",
      "  done: false\n",
      "  episode_len_mean: 169.99\n",
      "  episode_reward_max: 1120.166048347298\n",
      "  episode_reward_mean: 949.6078163658365\n",
      "  episode_reward_min: -82.23358909190608\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 28400\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.65\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 4920000\n",
      "    num_steps_trained: 4920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7736450433731079\n",
      "      kl: 0.017856348305940628\n",
      "      policy_loss: -0.0013024009531363845\n",
      "      total_loss: 910.4381103515625\n",
      "      vf_explained_var: 0.9610098600387573\n",
      "      vf_loss: 910.4382934570312\n",
      "    sample_time_ms: 20206.708\n",
      "    update_time_ms: 5.143\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.80390818291824\n",
      "  time_since_restore: 11631.756968736649\n",
      "  time_this_iter_s: 23.72412085533142\n",
      "  time_total_s: 11631.756968736649\n",
      "  timestamp: 1553977412\n",
      "  timesteps_since_restore: 4920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4920000\n",
      "  training_iteration: 492\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11631 s, 492 iter, 4920000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-23-55\n",
      "  done: false\n",
      "  episode_len_mean: 182.11\n",
      "  episode_reward_max: 1164.6645320317398\n",
      "  episode_reward_mean: 937.4362528619561\n",
      "  episode_reward_min: -82.23358909190608\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 28450\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.767\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 4930000\n",
      "    num_steps_trained: 4930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1447440385818481\n",
      "      kl: 0.02064523659646511\n",
      "      policy_loss: -0.004136082250624895\n",
      "      total_loss: 461.48468017578125\n",
      "      vf_explained_var: 0.9788069128990173\n",
      "      vf_loss: 461.4876708984375\n",
      "    sample_time_ms: 20152.721\n",
      "    update_time_ms: 5.222\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.7181264309779\n",
      "  time_since_restore: 11655.55320763588\n",
      "  time_this_iter_s: 23.796238899230957\n",
      "  time_total_s: 11655.55320763588\n",
      "  timestamp: 1553977435\n",
      "  timesteps_since_restore: 4930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4930000\n",
      "  training_iteration: 493\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11655 s, 493 iter, 4930000 ts, 937 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-24-20\n",
      "  done: false\n",
      "  episode_len_mean: 179.64\n",
      "  episode_reward_max: 1164.6645320317398\n",
      "  episode_reward_mean: 952.2547016730167\n",
      "  episode_reward_min: -11.712937509546322\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 28508\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.966\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 4940000\n",
      "    num_steps_trained: 4940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8707461953163147\n",
      "      kl: 0.017060209065675735\n",
      "      policy_loss: -0.002838507993146777\n",
      "      total_loss: 981.255615234375\n",
      "      vf_explained_var: 0.9608580470085144\n",
      "      vf_loss: 981.2573852539062\n",
      "    sample_time_ms: 20113.962\n",
      "    update_time_ms: 5.262\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.12735083650847\n",
      "  time_since_restore: 11679.671713590622\n",
      "  time_this_iter_s: 24.11850595474243\n",
      "  time_total_s: 11679.671713590622\n",
      "  timestamp: 1553977460\n",
      "  timesteps_since_restore: 4940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4940000\n",
      "  training_iteration: 494\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11679 s, 494 iter, 4940000 ts, 952 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-24-44\n",
      "  done: false\n",
      "  episode_len_mean: 174.11\n",
      "  episode_reward_max: 1152.273514514229\n",
      "  episode_reward_mean: 952.0245876971119\n",
      "  episode_reward_min: -65.02766803045563\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 28567\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.944\n",
      "    load_time_ms: 1.594\n",
      "    num_steps_sampled: 4950000\n",
      "    num_steps_trained: 4950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7950710654258728\n",
      "      kl: 0.01916356198489666\n",
      "      policy_loss: -0.0015417310642078519\n",
      "      total_loss: 1180.5843505859375\n",
      "      vf_explained_var: 0.9496710300445557\n",
      "      vf_loss: 1180.5848388671875\n",
      "    sample_time_ms: 20050.465\n",
      "    update_time_ms: 5.313\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.012293848556\n",
      "  time_since_restore: 11703.651237726212\n",
      "  time_this_iter_s: 23.9795241355896\n",
      "  time_total_s: 11703.651237726212\n",
      "  timestamp: 1553977484\n",
      "  timesteps_since_restore: 4950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4950000\n",
      "  training_iteration: 495\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11703 s, 495 iter, 4950000 ts, 952 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-25-07\n",
      "  done: false\n",
      "  episode_len_mean: 175.6\n",
      "  episode_reward_max: 1147.7238496536074\n",
      "  episode_reward_mean: 930.7924562956673\n",
      "  episode_reward_min: -65.02766803045563\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 28623\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.736\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 4960000\n",
      "    num_steps_trained: 4960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9408336281776428\n",
      "      kl: 0.019152997061610222\n",
      "      policy_loss: -0.0011977071408182383\n",
      "      total_loss: 1094.390625\n",
      "      vf_explained_var: 0.9518063068389893\n",
      "      vf_loss: 1094.390625\n",
      "    sample_time_ms: 19988.533\n",
      "    update_time_ms: 5.338\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 465.39622814783377\n",
      "  time_since_restore: 11726.992132663727\n",
      "  time_this_iter_s: 23.34089493751526\n",
      "  time_total_s: 11726.992132663727\n",
      "  timestamp: 1553977507\n",
      "  timesteps_since_restore: 4960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4960000\n",
      "  training_iteration: 496\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11726 s, 496 iter, 4960000 ts, 931 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-25-31\n",
      "  done: false\n",
      "  episode_len_mean: 180.08\n",
      "  episode_reward_max: 1131.751810794342\n",
      "  episode_reward_mean: 936.7863652349666\n",
      "  episode_reward_min: -85.2147002672724\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 28679\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.497\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 4970000\n",
      "    num_steps_trained: 4970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9602620005607605\n",
      "      kl: 0.014893583953380585\n",
      "      policy_loss: -0.0004999903030693531\n",
      "      total_loss: 669.1055908203125\n",
      "      vf_explained_var: 0.9687107801437378\n",
      "      vf_loss: 669.1052856445312\n",
      "    sample_time_ms: 19981.399\n",
      "    update_time_ms: 5.431\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.3931826174833\n",
      "  time_since_restore: 11751.20597743988\n",
      "  time_this_iter_s: 24.213844776153564\n",
      "  time_total_s: 11751.20597743988\n",
      "  timestamp: 1553977531\n",
      "  timesteps_since_restore: 4970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4970000\n",
      "  training_iteration: 497\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11751 s, 497 iter, 4970000 ts, 937 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-25-55\n",
      "  done: false\n",
      "  episode_len_mean: 181.94\n",
      "  episode_reward_max: 1129.7392461541056\n",
      "  episode_reward_mean: 959.718661782095\n",
      "  episode_reward_min: -85.2147002672724\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 28733\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.177\n",
      "    load_time_ms: 1.594\n",
      "    num_steps_sampled: 4980000\n",
      "    num_steps_trained: 4980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9093345403671265\n",
      "      kl: 0.024045633152127266\n",
      "      policy_loss: -0.0026423041708767414\n",
      "      total_loss: 686.3267211914062\n",
      "      vf_explained_var: 0.9677916169166565\n",
      "      vf_loss: 686.3280029296875\n",
      "    sample_time_ms: 19950.794\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.8593308910476\n",
      "  time_since_restore: 11774.988470554352\n",
      "  time_this_iter_s: 23.782493114471436\n",
      "  time_total_s: 11774.988470554352\n",
      "  timestamp: 1553977555\n",
      "  timesteps_since_restore: 4980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4980000\n",
      "  training_iteration: 498\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11774 s, 498 iter, 4980000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-26-19\n",
      "  done: false\n",
      "  episode_len_mean: 176.47\n",
      "  episode_reward_max: 1129.7392461541056\n",
      "  episode_reward_mean: 939.8822888762895\n",
      "  episode_reward_min: -61.854383048874155\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 28792\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.804\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 4990000\n",
      "    num_steps_trained: 4990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8373218178749084\n",
      "      kl: 0.02270963229238987\n",
      "      policy_loss: -0.004478848539292812\n",
      "      total_loss: 707.7621459960938\n",
      "      vf_explained_var: 0.9708455204963684\n",
      "      vf_loss: 707.7654418945312\n",
      "    sample_time_ms: 19976.939\n",
      "    update_time_ms: 5.398\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.9411444381448\n",
      "  time_since_restore: 11799.299341201782\n",
      "  time_this_iter_s: 24.31087064743042\n",
      "  time_total_s: 11799.299341201782\n",
      "  timestamp: 1553977579\n",
      "  timesteps_since_restore: 4990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4990000\n",
      "  training_iteration: 499\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11799 s, 499 iter, 4990000 ts, 940 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 176.87\n",
      "  episode_reward_max: 1122.770319793716\n",
      "  episode_reward_mean: 967.7447612487814\n",
      "  episode_reward_min: -61.854383048874155\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 28847\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.782\n",
      "    load_time_ms: 1.664\n",
      "    num_steps_sampled: 5000000\n",
      "    num_steps_trained: 5000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05648540332913399\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8306481838226318\n",
      "      kl: 0.30185315012931824\n",
      "      policy_loss: 0.015732726082205772\n",
      "      total_loss: 88.97740936279297\n",
      "      vf_explained_var: 0.9957249760627747\n",
      "      vf_loss: 88.94462585449219\n",
      "    sample_time_ms: 20023.963\n",
      "    update_time_ms: 5.528\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.8723806243908\n",
      "  time_since_restore: 11823.665806293488\n",
      "  time_this_iter_s: 24.366465091705322\n",
      "  time_total_s: 11823.665806293488\n",
      "  timestamp: 1553977604\n",
      "  timesteps_since_restore: 5000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5000000\n",
      "  training_iteration: 500\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11823 s, 500 iter, 5000000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-27-08\n",
      "  done: false\n",
      "  episode_len_mean: 175.29\n",
      "  episode_reward_max: 1122.770319793716\n",
      "  episode_reward_mean: 961.4199201075318\n",
      "  episode_reward_min: -8.52452397905833\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 28907\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.205\n",
      "    load_time_ms: 1.652\n",
      "    num_steps_sampled: 5010000\n",
      "    num_steps_trained: 5010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08472812175750732\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8047667145729065\n",
      "      kl: 0.00510905496776104\n",
      "      policy_loss: -0.0016222441336140037\n",
      "      total_loss: 950.0657348632812\n",
      "      vf_explained_var: 0.9610154628753662\n",
      "      vf_loss: 950.0670166015625\n",
      "    sample_time_ms: 20048.911\n",
      "    update_time_ms: 5.53\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.7099600537658\n",
      "  time_since_restore: 11847.964163064957\n",
      "  time_this_iter_s: 24.298356771469116\n",
      "  time_total_s: 11847.964163064957\n",
      "  timestamp: 1553977628\n",
      "  timesteps_since_restore: 5010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5010000\n",
      "  training_iteration: 501\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11847 s, 501 iter, 5010000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-27-32\n",
      "  done: false\n",
      "  episode_len_mean: 167.22\n",
      "  episode_reward_max: 1140.0990807537858\n",
      "  episode_reward_mean: 946.6762223690706\n",
      "  episode_reward_min: -59.043939100726874\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 28968\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.087\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 5020000\n",
      "    num_steps_trained: 5020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04236406087875366\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7201696634292603\n",
      "      kl: 0.00845070369541645\n",
      "      policy_loss: -0.0011608856730163097\n",
      "      total_loss: 1047.8936767578125\n",
      "      vf_explained_var: 0.9533532857894897\n",
      "      vf_loss: 1047.8944091796875\n",
      "    sample_time_ms: 20057.747\n",
      "    update_time_ms: 5.47\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.3381111845353\n",
      "  time_since_restore: 11871.748538970947\n",
      "  time_this_iter_s: 23.7843759059906\n",
      "  time_total_s: 11871.748538970947\n",
      "  timestamp: 1553977652\n",
      "  timesteps_since_restore: 5020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5020000\n",
      "  training_iteration: 502\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11871 s, 502 iter, 5020000 ts, 947 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-27-57\n",
      "  done: false\n",
      "  episode_len_mean: 161.99\n",
      "  episode_reward_max: 1155.1252764298636\n",
      "  episode_reward_mean: 962.5875915008032\n",
      "  episode_reward_min: -59.043939100726874\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 29029\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.75\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 5030000\n",
      "    num_steps_trained: 5030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02118203043937683\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6666285991668701\n",
      "      kl: 0.016848169267177582\n",
      "      policy_loss: -0.002235395135357976\n",
      "      total_loss: 888.5634765625\n",
      "      vf_explained_var: 0.9610497951507568\n",
      "      vf_loss: 888.5654907226562\n",
      "    sample_time_ms: 20139.245\n",
      "    update_time_ms: 5.468\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.2937957504016\n",
      "  time_since_restore: 11896.323395252228\n",
      "  time_this_iter_s: 24.574856281280518\n",
      "  time_total_s: 11896.323395252228\n",
      "  timestamp: 1553977677\n",
      "  timesteps_since_restore: 5030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5030000\n",
      "  training_iteration: 503\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11896 s, 503 iter, 5030000 ts, 963 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-28-21\n",
      "  done: false\n",
      "  episode_len_mean: 171.68\n",
      "  episode_reward_max: 1163.4629370396015\n",
      "  episode_reward_mean: 1004.0951157106601\n",
      "  episode_reward_min: -41.34681048546824\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 29085\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.384\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 5040000\n",
      "    num_steps_trained: 5040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02118203043937683\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9901229739189148\n",
      "      kl: 0.026595449075102806\n",
      "      policy_loss: -0.0006870925426483154\n",
      "      total_loss: 339.2101745605469\n",
      "      vf_explained_var: 0.9853800535202026\n",
      "      vf_loss: 339.2102966308594\n",
      "    sample_time_ms: 20182.584\n",
      "    update_time_ms: 5.602\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 502.04755785533007\n",
      "  time_since_restore: 11920.83990573883\n",
      "  time_this_iter_s: 24.516510486602783\n",
      "  time_total_s: 11920.83990573883\n",
      "  timestamp: 1553977701\n",
      "  timesteps_since_restore: 5040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5040000\n",
      "  training_iteration: 504\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11920 s, 504 iter, 5040000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-28-46\n",
      "  done: false\n",
      "  episode_len_mean: 172.0\n",
      "  episode_reward_max: 1125.1149079240033\n",
      "  episode_reward_mean: 988.4611928097256\n",
      "  episode_reward_min: -60.77095471700915\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 29145\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.041\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 5050000\n",
      "    num_steps_trained: 5050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02118203043937683\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6820659637451172\n",
      "      kl: 0.04551561549305916\n",
      "      policy_loss: -0.0031762735452502966\n",
      "      total_loss: 782.1334838867188\n",
      "      vf_explained_var: 0.9654468894004822\n",
      "      vf_loss: 782.1358032226562\n",
      "    sample_time_ms: 20248.981\n",
      "    update_time_ms: 6.127\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.23059640486275\n",
      "  time_since_restore: 11945.522458314896\n",
      "  time_this_iter_s: 24.682552576065063\n",
      "  time_total_s: 11945.522458314896\n",
      "  timestamp: 1553977726\n",
      "  timesteps_since_restore: 5050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5050000\n",
      "  training_iteration: 505\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11945 s, 505 iter, 5050000 ts, 988 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-29-10\n",
      "  done: false\n",
      "  episode_len_mean: 177.68\n",
      "  episode_reward_max: 1133.703885852864\n",
      "  episode_reward_mean: 938.1489605077039\n",
      "  episode_reward_min: -60.77095471700915\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 29198\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.38\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 5060000\n",
      "    num_steps_trained: 5060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03177304193377495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2167327404022217\n",
      "      kl: 0.021577538922429085\n",
      "      policy_loss: -0.0033499812707304955\n",
      "      total_loss: 787.6063842773438\n",
      "      vf_explained_var: 0.963348388671875\n",
      "      vf_loss: 787.6090087890625\n",
      "    sample_time_ms: 20379.105\n",
      "    update_time_ms: 6.075\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.07448025385196\n",
      "  time_since_restore: 11970.177913665771\n",
      "  time_this_iter_s: 24.655455350875854\n",
      "  time_total_s: 11970.177913665771\n",
      "  timestamp: 1553977750\n",
      "  timesteps_since_restore: 5060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5060000\n",
      "  training_iteration: 506\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11970 s, 506 iter, 5060000 ts, 938 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-29-34\n",
      "  done: false\n",
      "  episode_len_mean: 182.6\n",
      "  episode_reward_max: 1133.703885852864\n",
      "  episode_reward_mean: 904.3238649934766\n",
      "  episode_reward_min: -94.51931812355625\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 29256\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.57\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 5070000\n",
      "    num_steps_trained: 5070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03177304193377495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.105281949043274\n",
      "      kl: 0.018660401925444603\n",
      "      policy_loss: -0.004373149946331978\n",
      "      total_loss: 1551.254150390625\n",
      "      vf_explained_var: 0.9321886897087097\n",
      "      vf_loss: 1551.2579345703125\n",
      "    sample_time_ms: 20323.537\n",
      "    update_time_ms: 5.739\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 452.16193249673836\n",
      "  time_since_restore: 11993.765283823013\n",
      "  time_this_iter_s: 23.58737015724182\n",
      "  time_total_s: 11993.765283823013\n",
      "  timestamp: 1553977774\n",
      "  timesteps_since_restore: 5070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5070000\n",
      "  training_iteration: 507\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 11993 s, 507 iter, 5070000 ts, 904 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-29-59\n",
      "  done: false\n",
      "  episode_len_mean: 178.62\n",
      "  episode_reward_max: 1113.8290355345928\n",
      "  episode_reward_mean: 898.9682070743294\n",
      "  episode_reward_min: -94.51931812355625\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 29310\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.507\n",
      "    load_time_ms: 1.438\n",
      "    num_steps_sampled: 5080000\n",
      "    num_steps_trained: 5080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03177304193377495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.991791844367981\n",
      "      kl: 0.016376174986362457\n",
      "      policy_loss: 0.0005964121082797647\n",
      "      total_loss: 920.13720703125\n",
      "      vf_explained_var: 0.9564785957336426\n",
      "      vf_loss: 920.1360473632812\n",
      "    sample_time_ms: 20389.726\n",
      "    update_time_ms: 5.786\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 449.4841035371648\n",
      "  time_since_restore: 12018.184774637222\n",
      "  time_this_iter_s: 24.419490814208984\n",
      "  time_total_s: 12018.184774637222\n",
      "  timestamp: 1553977799\n",
      "  timesteps_since_restore: 5080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5080000\n",
      "  training_iteration: 508\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12018 s, 508 iter, 5080000 ts, 899 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-30-23\n",
      "  done: false\n",
      "  episode_len_mean: 169.42\n",
      "  episode_reward_max: 1138.0617511785792\n",
      "  episode_reward_mean: 942.2656068375575\n",
      "  episode_reward_min: -69.1647451258483\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 29372\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.857\n",
      "    load_time_ms: 1.416\n",
      "    num_steps_sampled: 5090000\n",
      "    num_steps_trained: 5090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03177304193377495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6840095520019531\n",
      "      kl: 0.0330481231212616\n",
      "      policy_loss: -0.0040453411638736725\n",
      "      total_loss: 709.1809692382812\n",
      "      vf_explained_var: 0.970338761806488\n",
      "      vf_loss: 709.1839599609375\n",
      "    sample_time_ms: 20408.999\n",
      "    update_time_ms: 5.868\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.13280341877874\n",
      "  time_since_restore: 12042.682788610458\n",
      "  time_this_iter_s: 24.498013973236084\n",
      "  time_total_s: 12042.682788610458\n",
      "  timestamp: 1553977823\n",
      "  timesteps_since_restore: 5090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5090000\n",
      "  training_iteration: 509\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12042 s, 509 iter, 5090000 ts, 942 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-30-48\n",
      "  done: false\n",
      "  episode_len_mean: 167.95\n",
      "  episode_reward_max: 1153.37638887439\n",
      "  episode_reward_mean: 950.7972574194351\n",
      "  episode_reward_min: -69.1647451258483\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 29428\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.775\n",
      "    load_time_ms: 1.348\n",
      "    num_steps_sampled: 5100000\n",
      "    num_steps_trained: 5100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03177304193377495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8414096236228943\n",
      "      kl: 0.01672074757516384\n",
      "      policy_loss: 0.00024518274585716426\n",
      "      total_loss: 810.8587646484375\n",
      "      vf_explained_var: 0.961231529712677\n",
      "      vf_loss: 810.8579711914062\n",
      "    sample_time_ms: 20410.513\n",
      "    update_time_ms: 5.748\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.39862870971757\n",
      "  time_since_restore: 12067.060102939606\n",
      "  time_this_iter_s: 24.37731432914734\n",
      "  time_total_s: 12067.060102939606\n",
      "  timestamp: 1553977848\n",
      "  timesteps_since_restore: 5100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5100000\n",
      "  training_iteration: 510\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12067 s, 510 iter, 5100000 ts, 951 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-31-11\n",
      "  done: false\n",
      "  episode_len_mean: 174.51\n",
      "  episode_reward_max: 1153.37638887439\n",
      "  episode_reward_mean: 950.5422049684399\n",
      "  episode_reward_min: -52.06431843985868\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 29487\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.174\n",
      "    load_time_ms: 1.338\n",
      "    num_steps_sampled: 5110000\n",
      "    num_steps_trained: 5110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03177304193377495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6652451753616333\n",
      "      kl: 0.034443970769643784\n",
      "      policy_loss: -0.003290906548500061\n",
      "      total_loss: 426.63873291015625\n",
      "      vf_explained_var: 0.979762852191925\n",
      "      vf_loss: 426.64093017578125\n",
      "    sample_time_ms: 20384.919\n",
      "    update_time_ms: 5.651\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.27110248421997\n",
      "  time_since_restore: 12090.967364311218\n",
      "  time_this_iter_s: 23.90726137161255\n",
      "  time_total_s: 12090.967364311218\n",
      "  timestamp: 1553977871\n",
      "  timesteps_since_restore: 5110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5110000\n",
      "  training_iteration: 511\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12090 s, 511 iter, 5110000 ts, 951 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-31-35\n",
      "  done: false\n",
      "  episode_len_mean: 178.39\n",
      "  episode_reward_max: 1109.3133279105575\n",
      "  episode_reward_mean: 958.5478824542074\n",
      "  episode_reward_min: -15.937142171968446\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 29541\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.043\n",
      "    load_time_ms: 1.335\n",
      "    num_steps_sampled: 5120000\n",
      "    num_steps_trained: 5120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03177304193377495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9852578639984131\n",
      "      kl: 0.0187997967004776\n",
      "      policy_loss: -0.00011631043889792636\n",
      "      total_loss: 427.6427307128906\n",
      "      vf_explained_var: 0.9808697700500488\n",
      "      vf_loss: 427.64227294921875\n",
      "    sample_time_ms: 20386.482\n",
      "    update_time_ms: 5.693\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.27394122710376\n",
      "  time_since_restore: 12114.76233625412\n",
      "  time_this_iter_s: 23.79497194290161\n",
      "  time_total_s: 12114.76233625412\n",
      "  timestamp: 1553977895\n",
      "  timesteps_since_restore: 5120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5120000\n",
      "  training_iteration: 512\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12114 s, 512 iter, 5120000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-31-58\n",
      "  done: false\n",
      "  episode_len_mean: 180.35\n",
      "  episode_reward_max: 1128.2316347631877\n",
      "  episode_reward_mean: 963.8571200471479\n",
      "  episode_reward_min: 23.528067806416885\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 29595\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.9\n",
      "    load_time_ms: 1.323\n",
      "    num_steps_sampled: 5130000\n",
      "    num_steps_trained: 5130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03177304193377495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8452685475349426\n",
      "      kl: 0.04982446879148483\n",
      "      policy_loss: -0.004952622577548027\n",
      "      total_loss: 517.7179565429688\n",
      "      vf_explained_var: 0.9763603210449219\n",
      "      vf_loss: 517.7213745117188\n",
      "    sample_time_ms: 20195.462\n",
      "    update_time_ms: 5.579\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.92856002357394\n",
      "  time_since_restore: 12137.464765071869\n",
      "  time_this_iter_s: 22.702428817749023\n",
      "  time_total_s: 12137.464765071869\n",
      "  timestamp: 1553977918\n",
      "  timesteps_since_restore: 5130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5130000\n",
      "  training_iteration: 513\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12137 s, 513 iter, 5130000 ts, 964 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-32-22\n",
      "  done: false\n",
      "  episode_len_mean: 184.23\n",
      "  episode_reward_max: 1151.8069816789969\n",
      "  episode_reward_mean: 924.1181943269851\n",
      "  episode_reward_min: -94.20071025390838\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 29650\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.03\n",
      "    load_time_ms: 1.347\n",
      "    num_steps_sampled: 5140000\n",
      "    num_steps_trained: 5140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04765956476330757\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0699979066848755\n",
      "      kl: 0.014540961012244225\n",
      "      policy_loss: -0.002881815889850259\n",
      "      total_loss: 1444.6444091796875\n",
      "      vf_explained_var: 0.9345992803573608\n",
      "      vf_loss: 1444.6466064453125\n",
      "    sample_time_ms: 20172.127\n",
      "    update_time_ms: 5.557\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 462.05909716349254\n",
      "  time_since_restore: 12161.728885173798\n",
      "  time_this_iter_s: 24.26412010192871\n",
      "  time_total_s: 12161.728885173798\n",
      "  timestamp: 1553977942\n",
      "  timesteps_since_restore: 5140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5140000\n",
      "  training_iteration: 514\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12161 s, 514 iter, 5140000 ts, 924 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-32-46\n",
      "  done: false\n",
      "  episode_len_mean: 172.52\n",
      "  episode_reward_max: 1151.8069816789969\n",
      "  episode_reward_mean: 909.9406939708318\n",
      "  episode_reward_min: -94.20071025390838\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 29707\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.947\n",
      "    load_time_ms: 1.323\n",
      "    num_steps_sampled: 5150000\n",
      "    num_steps_trained: 5150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04765956476330757\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8891803026199341\n",
      "      kl: 0.02127629891037941\n",
      "      policy_loss: -0.0005980940186418593\n",
      "      total_loss: 836.7278442382812\n",
      "      vf_explained_var: 0.9661111235618591\n",
      "      vf_loss: 836.7274169921875\n",
      "    sample_time_ms: 20072.318\n",
      "    update_time_ms: 5.095\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 454.9703469854158\n",
      "  time_since_restore: 12185.35775566101\n",
      "  time_this_iter_s: 23.628870487213135\n",
      "  time_total_s: 12185.35775566101\n",
      "  timestamp: 1553977966\n",
      "  timesteps_since_restore: 5150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5150000\n",
      "  training_iteration: 515\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12185 s, 515 iter, 5150000 ts, 910 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-33-10\n",
      "  done: false\n",
      "  episode_len_mean: 170.18\n",
      "  episode_reward_max: 1131.1238808454868\n",
      "  episode_reward_mean: 880.0659472709692\n",
      "  episode_reward_min: -73.43163460648559\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 29767\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.052\n",
      "    load_time_ms: 1.344\n",
      "    num_steps_sampled: 5160000\n",
      "    num_steps_trained: 5160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04765956476330757\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9389265775680542\n",
      "      kl: 0.022648099809885025\n",
      "      policy_loss: -0.006968797650188208\n",
      "      total_loss: 1972.1253662109375\n",
      "      vf_explained_var: 0.9177756905555725\n",
      "      vf_loss: 1972.1312255859375\n",
      "    sample_time_ms: 20040.037\n",
      "    update_time_ms: 5.072\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 440.0329736354845\n",
      "  time_since_restore: 12209.644190788269\n",
      "  time_this_iter_s: 24.2864351272583\n",
      "  time_total_s: 12209.644190788269\n",
      "  timestamp: 1553977990\n",
      "  timesteps_since_restore: 5160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5160000\n",
      "  training_iteration: 516\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12209 s, 516 iter, 5160000 ts, 880 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-33-35\n",
      "  done: false\n",
      "  episode_len_mean: 168.38\n",
      "  episode_reward_max: 1131.5153966250439\n",
      "  episode_reward_mean: 910.1475976143198\n",
      "  episode_reward_min: -73.43163460648559\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 29824\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.297\n",
      "    load_time_ms: 1.343\n",
      "    num_steps_sampled: 5170000\n",
      "    num_steps_trained: 5170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04765956476330757\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7261096239089966\n",
      "      kl: 0.014666085131466389\n",
      "      policy_loss: 0.00031979955383576453\n",
      "      total_loss: 685.0442504882812\n",
      "      vf_explained_var: 0.9705191254615784\n",
      "      vf_loss: 685.0431518554688\n",
      "    sample_time_ms: 20109.162\n",
      "    update_time_ms: 5.055\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 455.07379880715996\n",
      "  time_since_restore: 12233.963303804398\n",
      "  time_this_iter_s: 24.31911301612854\n",
      "  time_total_s: 12233.963303804398\n",
      "  timestamp: 1553978015\n",
      "  timesteps_since_restore: 5170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5170000\n",
      "  training_iteration: 517\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12233 s, 517 iter, 5170000 ts, 910 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-33-58\n",
      "  done: false\n",
      "  episode_len_mean: 171.76\n",
      "  episode_reward_max: 1141.629186654448\n",
      "  episode_reward_mean: 991.314224955277\n",
      "  episode_reward_min: -25.364218531139784\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 29883\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.879\n",
      "    load_time_ms: 1.405\n",
      "    num_steps_sampled: 5180000\n",
      "    num_steps_trained: 5180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04765956476330757\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7361571788787842\n",
      "      kl: 0.09282764047384262\n",
      "      policy_loss: -0.002932394854724407\n",
      "      total_loss: 78.69525146484375\n",
      "      vf_explained_var: 0.9965147376060486\n",
      "      vf_loss: 78.6937484741211\n",
      "    sample_time_ms: 20026.278\n",
      "    update_time_ms: 5.096\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.6571124776386\n",
      "  time_since_restore: 12257.593521595001\n",
      "  time_this_iter_s: 23.630217790603638\n",
      "  time_total_s: 12257.593521595001\n",
      "  timestamp: 1553978038\n",
      "  timesteps_since_restore: 5180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5180000\n",
      "  training_iteration: 518\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12257 s, 518 iter, 5180000 ts, 991 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-34-22\n",
      "  done: false\n",
      "  episode_len_mean: 168.67\n",
      "  episode_reward_max: 1141.629186654448\n",
      "  episode_reward_mean: 977.6634530259994\n",
      "  episode_reward_min: -35.10910463382757\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 29942\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.482\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 5190000\n",
      "    num_steps_trained: 5190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7282264232635498\n",
      "      kl: 0.012582427822053432\n",
      "      policy_loss: -0.00234265998005867\n",
      "      total_loss: 1045.703369140625\n",
      "      vf_explained_var: 0.9543728828430176\n",
      "      vf_loss: 1045.7047119140625\n",
      "    sample_time_ms: 19975.876\n",
      "    update_time_ms: 5.177\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.8317265129997\n",
      "  time_since_restore: 12281.602860689163\n",
      "  time_this_iter_s: 24.009339094161987\n",
      "  time_total_s: 12281.602860689163\n",
      "  timestamp: 1553978062\n",
      "  timesteps_since_restore: 5190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5190000\n",
      "  training_iteration: 519\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12281 s, 519 iter, 5190000 ts, 978 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-34-47\n",
      "  done: false\n",
      "  episode_len_mean: 176.05\n",
      "  episode_reward_max: 1129.851526841647\n",
      "  episode_reward_mean: 967.1307563755295\n",
      "  episode_reward_min: 10.07541942989701\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 29998\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.353\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 5200000\n",
      "    num_steps_trained: 5200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8084473013877869\n",
      "      kl: 0.015419140458106995\n",
      "      policy_loss: -0.004295597318559885\n",
      "      total_loss: 418.5556335449219\n",
      "      vf_explained_var: 0.9813029170036316\n",
      "      vf_loss: 418.558837890625\n",
      "    sample_time_ms: 19979.993\n",
      "    update_time_ms: 5.238\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.56537818776474\n",
      "  time_since_restore: 12306.011698961258\n",
      "  time_this_iter_s: 24.408838272094727\n",
      "  time_total_s: 12306.011698961258\n",
      "  timestamp: 1553978087\n",
      "  timesteps_since_restore: 5200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5200000\n",
      "  training_iteration: 520\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12306 s, 520 iter, 5200000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-35-11\n",
      "  done: false\n",
      "  episode_len_mean: 182.0\n",
      "  episode_reward_max: 1126.3799816613373\n",
      "  episode_reward_mean: 942.1118401798641\n",
      "  episode_reward_min: -57.06048072651967\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 30053\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.31\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 5210000\n",
      "    num_steps_trained: 5210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9070223569869995\n",
      "      kl: 0.015941981226205826\n",
      "      policy_loss: -0.0007584364502690732\n",
      "      total_loss: 869.7173461914062\n",
      "      vf_explained_var: 0.9576165676116943\n",
      "      vf_loss: 869.7169189453125\n",
      "    sample_time_ms: 20001.093\n",
      "    update_time_ms: 5.165\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.0559200899321\n",
      "  time_since_restore: 12330.118040561676\n",
      "  time_this_iter_s: 24.10634160041809\n",
      "  time_total_s: 12330.118040561676\n",
      "  timestamp: 1553978111\n",
      "  timesteps_since_restore: 5210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5210000\n",
      "  training_iteration: 521\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12330 s, 521 iter, 5210000 ts, 942 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-35-35\n",
      "  done: false\n",
      "  episode_len_mean: 177.29\n",
      "  episode_reward_max: 1115.6523525047244\n",
      "  episode_reward_mean: 983.0757946606833\n",
      "  episode_reward_min: -38.758011944705885\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 30113\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.164\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 5220000\n",
      "    num_steps_trained: 5220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5868194699287415\n",
      "      kl: 0.021570757031440735\n",
      "      policy_loss: -0.004737397190183401\n",
      "      total_loss: 305.6642150878906\n",
      "      vf_explained_var: 0.9870187640190125\n",
      "      vf_loss: 305.66741943359375\n",
      "    sample_time_ms: 19995.519\n",
      "    update_time_ms: 5.219\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.53789733034165\n",
      "  time_since_restore: 12353.860521554947\n",
      "  time_this_iter_s: 23.742480993270874\n",
      "  time_total_s: 12353.860521554947\n",
      "  timestamp: 1553978135\n",
      "  timesteps_since_restore: 5220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5220000\n",
      "  training_iteration: 522\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12353 s, 522 iter, 5220000 ts, 983 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-35-59\n",
      "  done: false\n",
      "  episode_len_mean: 164.31\n",
      "  episode_reward_max: 1159.7941158543024\n",
      "  episode_reward_mean: 941.6029222573026\n",
      "  episode_reward_min: -80.60075215285605\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 30174\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.502\n",
      "    load_time_ms: 1.61\n",
      "    num_steps_sampled: 5230000\n",
      "    num_steps_trained: 5230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6824864149093628\n",
      "      kl: 0.014204121194779873\n",
      "      policy_loss: -0.0007167481235228479\n",
      "      total_loss: 1379.9803466796875\n",
      "      vf_explained_var: 0.9421731233596802\n",
      "      vf_loss: 1379.980224609375\n",
      "    sample_time_ms: 20138.586\n",
      "    update_time_ms: 5.211\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.8014611286513\n",
      "  time_since_restore: 12378.029320955276\n",
      "  time_this_iter_s: 24.16879940032959\n",
      "  time_total_s: 12378.029320955276\n",
      "  timestamp: 1553978159\n",
      "  timesteps_since_restore: 5230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5230000\n",
      "  training_iteration: 523\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12378 s, 523 iter, 5230000 ts, 942 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-36-22\n",
      "  done: false\n",
      "  episode_len_mean: 171.22\n",
      "  episode_reward_max: 1159.7941158543024\n",
      "  episode_reward_mean: 953.2238888023126\n",
      "  episode_reward_min: -82.5952090235712\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 30232\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.633\n",
      "    load_time_ms: 1.635\n",
      "    num_steps_sampled: 5240000\n",
      "    num_steps_trained: 5240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.744615912437439\n",
      "      kl: 0.01386594120413065\n",
      "      policy_loss: -0.00353759597055614\n",
      "      total_loss: 530.4613647460938\n",
      "      vf_explained_var: 0.9749462604522705\n",
      "      vf_loss: 530.4639282226562\n",
      "    sample_time_ms: 20015.025\n",
      "    update_time_ms: 5.062\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.6119444011563\n",
      "  time_since_restore: 12401.049436092377\n",
      "  time_this_iter_s: 23.02011513710022\n",
      "  time_total_s: 12401.049436092377\n",
      "  timestamp: 1553978182\n",
      "  timesteps_since_restore: 5240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5240000\n",
      "  training_iteration: 524\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12401 s, 524 iter, 5240000 ts, 953 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-36-46\n",
      "  done: false\n",
      "  episode_len_mean: 179.44\n",
      "  episode_reward_max: 1154.8895192872596\n",
      "  episode_reward_mean: 976.3648356979996\n",
      "  episode_reward_min: -82.5952090235712\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 30287\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.527\n",
      "    load_time_ms: 1.645\n",
      "    num_steps_sampled: 5250000\n",
      "    num_steps_trained: 5250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8151638507843018\n",
      "      kl: 0.017724255099892616\n",
      "      policy_loss: -0.006039956584572792\n",
      "      total_loss: 491.5791320800781\n",
      "      vf_explained_var: 0.9772841334342957\n",
      "      vf_loss: 491.58392333984375\n",
      "    sample_time_ms: 20051.825\n",
      "    update_time_ms: 5.057\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.18241784899976\n",
      "  time_since_restore: 12425.094398260117\n",
      "  time_this_iter_s: 24.044962167739868\n",
      "  time_total_s: 12425.094398260117\n",
      "  timestamp: 1553978206\n",
      "  timesteps_since_restore: 5250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5250000\n",
      "  training_iteration: 525\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12425 s, 525 iter, 5250000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-37-10\n",
      "  done: false\n",
      "  episode_len_mean: 182.45\n",
      "  episode_reward_max: 1154.8895192872596\n",
      "  episode_reward_mean: 966.5868526985857\n",
      "  episode_reward_min: -33.77373444391168\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 30344\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.981\n",
      "    load_time_ms: 1.664\n",
      "    num_steps_sampled: 5260000\n",
      "    num_steps_trained: 5260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9463905692100525\n",
      "      kl: 0.013535927049815655\n",
      "      policy_loss: -0.001719920546747744\n",
      "      total_loss: 487.44635009765625\n",
      "      vf_explained_var: 0.9794176816940308\n",
      "      vf_loss: 487.4471130371094\n",
      "    sample_time_ms: 19989.938\n",
      "    update_time_ms: 5.079\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.2934263492929\n",
      "  time_since_restore: 12448.80662894249\n",
      "  time_this_iter_s: 23.712230682373047\n",
      "  time_total_s: 12448.80662894249\n",
      "  timestamp: 1553978230\n",
      "  timesteps_since_restore: 5260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5260000\n",
      "  training_iteration: 526\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12448 s, 526 iter, 5260000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-37-34\n",
      "  done: false\n",
      "  episode_len_mean: 168.05\n",
      "  episode_reward_max: 1142.5208710384986\n",
      "  episode_reward_mean: 945.7345274099172\n",
      "  episode_reward_min: -66.87674778534739\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 30405\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.979\n",
      "    load_time_ms: 1.665\n",
      "    num_steps_sampled: 5270000\n",
      "    num_steps_trained: 5270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6534016728401184\n",
      "      kl: 0.01599639467895031\n",
      "      policy_loss: -0.0019170129671692848\n",
      "      total_loss: 794.5331420898438\n",
      "      vf_explained_var: 0.9654523134231567\n",
      "      vf_loss: 794.5338745117188\n",
      "    sample_time_ms: 19990.608\n",
      "    update_time_ms: 5.132\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.8672637049586\n",
      "  time_since_restore: 12473.110719442368\n",
      "  time_this_iter_s: 24.30409049987793\n",
      "  time_total_s: 12473.110719442368\n",
      "  timestamp: 1553978254\n",
      "  timesteps_since_restore: 5270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5270000\n",
      "  training_iteration: 527\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12473 s, 527 iter, 5270000 ts, 946 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-37-58\n",
      "  done: false\n",
      "  episode_len_mean: 167.59\n",
      "  episode_reward_max: 1142.5208710384986\n",
      "  episode_reward_mean: 978.9666557616206\n",
      "  episode_reward_min: -66.87674778534739\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 30464\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.911\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 5280000\n",
      "    num_steps_trained: 5280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5829845666885376\n",
      "      kl: 0.023420006036758423\n",
      "      policy_loss: -0.001290920889005065\n",
      "      total_loss: 101.34544372558594\n",
      "      vf_explained_var: 0.9957851767539978\n",
      "      vf_loss: 101.34506225585938\n",
      "    sample_time_ms: 20014.607\n",
      "    update_time_ms: 5.148\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.48332788081024\n",
      "  time_since_restore: 12496.936104774475\n",
      "  time_this_iter_s: 23.825385332107544\n",
      "  time_total_s: 12496.936104774475\n",
      "  timestamp: 1553978278\n",
      "  timesteps_since_restore: 5280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5280000\n",
      "  training_iteration: 528\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12496 s, 528 iter, 5280000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-38-23\n",
      "  done: false\n",
      "  episode_len_mean: 168.98\n",
      "  episode_reward_max: 1113.740883238602\n",
      "  episode_reward_mean: 976.1977292749098\n",
      "  episode_reward_min: -75.40074993986765\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 30521\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.3\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 5290000\n",
      "    num_steps_trained: 5290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6275466084480286\n",
      "      kl: 0.014751274138689041\n",
      "      policy_loss: -0.0019692571368068457\n",
      "      total_loss: 1083.8846435546875\n",
      "      vf_explained_var: 0.9511335492134094\n",
      "      vf_loss: 1083.8853759765625\n",
      "    sample_time_ms: 20093.871\n",
      "    update_time_ms: 4.991\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.0988646374549\n",
      "  time_since_restore: 12521.671523809433\n",
      "  time_this_iter_s: 24.735419034957886\n",
      "  time_total_s: 12521.671523809433\n",
      "  timestamp: 1553978303\n",
      "  timesteps_since_restore: 5290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5290000\n",
      "  training_iteration: 529\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12521 s, 529 iter, 5290000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-38-47\n",
      "  done: false\n",
      "  episode_len_mean: 171.28\n",
      "  episode_reward_max: 1125.8276714756628\n",
      "  episode_reward_mean: 968.8465708122058\n",
      "  episode_reward_min: -48.34062281472447\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 30582\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.531\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 5300000\n",
      "    num_steps_trained: 5300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6445344090461731\n",
      "      kl: 0.020630385726690292\n",
      "      policy_loss: -0.0054972851648926735\n",
      "      total_loss: 786.4434814453125\n",
      "      vf_explained_var: 0.9661098122596741\n",
      "      vf_loss: 786.447509765625\n",
      "    sample_time_ms: 20062.144\n",
      "    update_time_ms: 5.122\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.4232854061028\n",
      "  time_since_restore: 12545.80842590332\n",
      "  time_this_iter_s: 24.13690209388733\n",
      "  time_total_s: 12545.80842590332\n",
      "  timestamp: 1553978327\n",
      "  timesteps_since_restore: 5300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5300000\n",
      "  training_iteration: 530\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12545 s, 530 iter, 5300000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-39-11\n",
      "  done: false\n",
      "  episode_len_mean: 185.44\n",
      "  episode_reward_max: 1140.1218137435815\n",
      "  episode_reward_mean: 945.060779093147\n",
      "  episode_reward_min: -48.34062281472447\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 30630\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.627\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 5310000\n",
      "    num_steps_trained: 5310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.173270583152771\n",
      "      kl: 0.019085684791207314\n",
      "      policy_loss: -0.0008843487594276667\n",
      "      total_loss: 811.98583984375\n",
      "      vf_explained_var: 0.9592011570930481\n",
      "      vf_loss: 811.9852905273438\n",
      "    sample_time_ms: 19997.329\n",
      "    update_time_ms: 5.222\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.5303895465734\n",
      "  time_since_restore: 12569.413655757904\n",
      "  time_this_iter_s: 23.60522985458374\n",
      "  time_total_s: 12569.413655757904\n",
      "  timestamp: 1553978351\n",
      "  timesteps_since_restore: 5310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5310000\n",
      "  training_iteration: 531\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12569 s, 531 iter, 5310000 ts, 945 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-39-35\n",
      "  done: false\n",
      "  episode_len_mean: 190.12\n",
      "  episode_reward_max: 1142.7470183671487\n",
      "  episode_reward_mean: 930.1357513693886\n",
      "  episode_reward_min: -94.72938871804602\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 30688\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.42\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 5320000\n",
      "    num_steps_trained: 5320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6787649989128113\n",
      "      kl: 0.013744411990046501\n",
      "      policy_loss: -0.003194538177922368\n",
      "      total_loss: 1212.144287109375\n",
      "      vf_explained_var: 0.9450703263282776\n",
      "      vf_loss: 1212.146484375\n",
      "    sample_time_ms: 19997.859\n",
      "    update_time_ms: 5.235\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 465.0678756846943\n",
      "  time_since_restore: 12593.19836807251\n",
      "  time_this_iter_s: 23.784712314605713\n",
      "  time_total_s: 12593.19836807251\n",
      "  timestamp: 1553978375\n",
      "  timesteps_since_restore: 5320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5320000\n",
      "  training_iteration: 532\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12593 s, 532 iter, 5320000 ts, 930 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-39-59\n",
      "  done: false\n",
      "  episode_len_mean: 169.74\n",
      "  episode_reward_max: 1159.506573427343\n",
      "  episode_reward_mean: 959.9300908670573\n",
      "  episode_reward_min: -94.72938871804602\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 30747\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.695\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 5330000\n",
      "    num_steps_trained: 5330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6795336604118347\n",
      "      kl: 0.021196965128183365\n",
      "      policy_loss: -0.006359712220728397\n",
      "      total_loss: 420.2460021972656\n",
      "      vf_explained_var: 0.9800372123718262\n",
      "      vf_loss: 420.25079345703125\n",
      "    sample_time_ms: 20026.632\n",
      "    update_time_ms: 5.2\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.9650454335287\n",
      "  time_since_restore: 12617.615997552872\n",
      "  time_this_iter_s: 24.41762948036194\n",
      "  time_total_s: 12617.615997552872\n",
      "  timestamp: 1553978399\n",
      "  timesteps_since_restore: 5330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5330000\n",
      "  training_iteration: 533\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12617 s, 533 iter, 5330000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-40-23\n",
      "  done: false\n",
      "  episode_len_mean: 174.69\n",
      "  episode_reward_max: 1108.5480596680447\n",
      "  episode_reward_mean: 977.1480349640041\n",
      "  episode_reward_min: 20.58994586540439\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 30803\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.391\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 5340000\n",
      "    num_steps_trained: 5340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.731653094291687\n",
      "      kl: 0.017199967056512833\n",
      "      policy_loss: -0.004555941559374332\n",
      "      total_loss: 643.8423461914062\n",
      "      vf_explained_var: 0.9694659113883972\n",
      "      vf_loss: 643.8456420898438\n",
      "    sample_time_ms: 20113.338\n",
      "    update_time_ms: 5.207\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.5740174820021\n",
      "  time_since_restore: 12641.520419359207\n",
      "  time_this_iter_s: 23.90442180633545\n",
      "  time_total_s: 12641.520419359207\n",
      "  timestamp: 1553978423\n",
      "  timesteps_since_restore: 5340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5340000\n",
      "  training_iteration: 534\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12641 s, 534 iter, 5340000 ts, 977 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-40-47\n",
      "  done: false\n",
      "  episode_len_mean: 176.05\n",
      "  episode_reward_max: 1136.3275974950986\n",
      "  episode_reward_mean: 940.5900360493624\n",
      "  episode_reward_min: -96.32256821036128\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 30861\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.475\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 5350000\n",
      "    num_steps_trained: 5350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.706939697265625\n",
      "      kl: 0.017296113073825836\n",
      "      policy_loss: -0.002822378883138299\n",
      "      total_loss: 1247.5494384765625\n",
      "      vf_explained_var: 0.9405755996704102\n",
      "      vf_loss: 1247.551025390625\n",
      "    sample_time_ms: 20122.821\n",
      "    update_time_ms: 5.094\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.2950180246812\n",
      "  time_since_restore: 12665.63100886345\n",
      "  time_this_iter_s: 24.110589504241943\n",
      "  time_total_s: 12665.63100886345\n",
      "  timestamp: 1553978447\n",
      "  timesteps_since_restore: 5350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5350000\n",
      "  training_iteration: 535\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12665 s, 535 iter, 5350000 ts, 941 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-41-11\n",
      "  done: false\n",
      "  episode_len_mean: 175.57\n",
      "  episode_reward_max: 1136.3275974950986\n",
      "  episode_reward_mean: 937.8282704045342\n",
      "  episode_reward_min: -80.50879387441024\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 30917\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.105\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 5360000\n",
      "    num_steps_trained: 5360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8112112879753113\n",
      "      kl: 0.020728230476379395\n",
      "      policy_loss: -0.0006422580336220562\n",
      "      total_loss: 1056.0390625\n",
      "      vf_explained_var: 0.9527527093887329\n",
      "      vf_loss: 1056.0382080078125\n",
      "    sample_time_ms: 20135.126\n",
      "    update_time_ms: 5.123\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.91413520226706\n",
      "  time_since_restore: 12689.414330244064\n",
      "  time_this_iter_s: 23.783321380615234\n",
      "  time_total_s: 12689.414330244064\n",
      "  timestamp: 1553978471\n",
      "  timesteps_since_restore: 5360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5360000\n",
      "  training_iteration: 536\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12689 s, 536 iter, 5360000 ts, 938 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-41-36\n",
      "  done: false\n",
      "  episode_len_mean: 173.78\n",
      "  episode_reward_max: 1127.7838649097448\n",
      "  episode_reward_mean: 909.5955240848713\n",
      "  episode_reward_min: -98.57471725421159\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 30975\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.563\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 5370000\n",
      "    num_steps_trained: 5370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7704024314880371\n",
      "      kl: 0.015454170294106007\n",
      "      policy_loss: -0.0019001925829797983\n",
      "      total_loss: 1186.5850830078125\n",
      "      vf_explained_var: 0.9489561915397644\n",
      "      vf_loss: 1186.5859375\n",
      "    sample_time_ms: 20150.714\n",
      "    update_time_ms: 5.013\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 454.79776204243564\n",
      "  time_since_restore: 12713.939850330353\n",
      "  time_this_iter_s: 24.525520086288452\n",
      "  time_total_s: 12713.939850330353\n",
      "  timestamp: 1553978496\n",
      "  timesteps_since_restore: 5370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5370000\n",
      "  training_iteration: 537\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12713 s, 537 iter, 5370000 ts, 910 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-41-58\n",
      "  done: false\n",
      "  episode_len_mean: 174.6\n",
      "  episode_reward_max: 1169.5521102141618\n",
      "  episode_reward_mean: 926.3677071237253\n",
      "  episode_reward_min: -98.57471725421159\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 31032\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.903\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 5380000\n",
      "    num_steps_trained: 5380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9438652396202087\n",
      "      kl: 0.022445570677518845\n",
      "      policy_loss: -0.002832914935424924\n",
      "      total_loss: 567.5562133789062\n",
      "      vf_explained_var: 0.9747633337974548\n",
      "      vf_loss: 567.557373046875\n",
      "    sample_time_ms: 20062.433\n",
      "    update_time_ms: 5.021\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 463.1838535618626\n",
      "  time_since_restore: 12736.857961177826\n",
      "  time_this_iter_s: 22.918110847473145\n",
      "  time_total_s: 12736.857961177826\n",
      "  timestamp: 1553978518\n",
      "  timesteps_since_restore: 5380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5380000\n",
      "  training_iteration: 538\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12736 s, 538 iter, 5380000 ts, 926 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-42-22\n",
      "  done: false\n",
      "  episode_len_mean: 180.99\n",
      "  episode_reward_max: 1169.5521102141618\n",
      "  episode_reward_mean: 941.9737076446522\n",
      "  episode_reward_min: -94.00164727921879\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 31087\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.416\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 5390000\n",
      "    num_steps_trained: 5390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9609527587890625\n",
      "      kl: 0.014907638542354107\n",
      "      policy_loss: -0.004359141923487186\n",
      "      total_loss: 1275.1422119140625\n",
      "      vf_explained_var: 0.9401869177818298\n",
      "      vf_loss: 1275.1453857421875\n",
      "    sample_time_ms: 19949.185\n",
      "    update_time_ms: 5.029\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.986853822326\n",
      "  time_since_restore: 12760.47940325737\n",
      "  time_this_iter_s: 23.621442079544067\n",
      "  time_total_s: 12760.47940325737\n",
      "  timestamp: 1553978542\n",
      "  timesteps_since_restore: 5390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5390000\n",
      "  training_iteration: 539\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12760 s, 539 iter, 5390000 ts, 942 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-42-47\n",
      "  done: false\n",
      "  episode_len_mean: 175.84\n",
      "  episode_reward_max: 1141.5521709992577\n",
      "  episode_reward_mean: 932.43648834243\n",
      "  episode_reward_min: -40.701623163009344\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 31146\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.588\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 5400000\n",
      "    num_steps_trained: 5400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7683236598968506\n",
      "      kl: 0.013362583704292774\n",
      "      policy_loss: -0.0023615153040736914\n",
      "      total_loss: 881.3291015625\n",
      "      vf_explained_var: 0.965189516544342\n",
      "      vf_loss: 881.3305053710938\n",
      "    sample_time_ms: 20016.05\n",
      "    update_time_ms: 4.83\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.218244171215\n",
      "  time_since_restore: 12785.293806552887\n",
      "  time_this_iter_s: 24.814403295516968\n",
      "  time_total_s: 12785.293806552887\n",
      "  timestamp: 1553978567\n",
      "  timesteps_since_restore: 5400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5400000\n",
      "  training_iteration: 540\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12785 s, 540 iter, 5400000 ts, 932 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-43-11\n",
      "  done: false\n",
      "  episode_len_mean: 169.61\n",
      "  episode_reward_max: 1141.5521709992577\n",
      "  episode_reward_mean: 927.0926530063853\n",
      "  episode_reward_min: -40.701623163009344\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 31203\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.485\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 5410000\n",
      "    num_steps_trained: 5410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.719280481338501\n",
      "      kl: 0.014712593518197536\n",
      "      policy_loss: -0.0007142965332604945\n",
      "      total_loss: 1021.2431640625\n",
      "      vf_explained_var: 0.9552949070930481\n",
      "      vf_loss: 1021.2427978515625\n",
      "    sample_time_ms: 20079.083\n",
      "    update_time_ms: 4.798\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 463.5463265031927\n",
      "  time_since_restore: 12809.413986444473\n",
      "  time_this_iter_s: 24.120179891586304\n",
      "  time_total_s: 12809.413986444473\n",
      "  timestamp: 1553978591\n",
      "  timesteps_since_restore: 5410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5410000\n",
      "  training_iteration: 541\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12809 s, 541 iter, 5410000 ts, 927 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-43-34\n",
      "  done: false\n",
      "  episode_len_mean: 174.3\n",
      "  episode_reward_max: 1171.0516753467648\n",
      "  episode_reward_mean: 941.8754871887554\n",
      "  episode_reward_min: -24.565047206003612\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 31261\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.336\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 5420000\n",
      "    num_steps_trained: 5420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.698292076587677\n",
      "      kl: 0.01542881689965725\n",
      "      policy_loss: -0.004407346714287996\n",
      "      total_loss: 846.0498657226562\n",
      "      vf_explained_var: 0.9624351263046265\n",
      "      vf_loss: 846.0532836914062\n",
      "    sample_time_ms: 19982.849\n",
      "    update_time_ms: 4.702\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.93774359437754\n",
      "  time_since_restore: 12832.27227306366\n",
      "  time_this_iter_s: 22.8582866191864\n",
      "  time_total_s: 12832.27227306366\n",
      "  timestamp: 1553978614\n",
      "  timesteps_since_restore: 5420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5420000\n",
      "  training_iteration: 542\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12832 s, 542 iter, 5420000 ts, 942 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-43-58\n",
      "  done: false\n",
      "  episode_len_mean: 174.11\n",
      "  episode_reward_max: 1171.0516753467648\n",
      "  episode_reward_mean: 959.753697642303\n",
      "  episode_reward_min: -18.085711285943745\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 31320\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.256\n",
      "    load_time_ms: 1.621\n",
      "    num_steps_sampled: 5430000\n",
      "    num_steps_trained: 5430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6513167023658752\n",
      "      kl: 0.03569936007261276\n",
      "      policy_loss: -0.00035137758823111653\n",
      "      total_loss: 600.0277709960938\n",
      "      vf_explained_var: 0.9731307625770569\n",
      "      vf_loss: 600.0255126953125\n",
      "    sample_time_ms: 19928.274\n",
      "    update_time_ms: 4.998\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.87684882115144\n",
      "  time_since_restore: 12856.157706975937\n",
      "  time_this_iter_s: 23.88543391227722\n",
      "  time_total_s: 12856.157706975937\n",
      "  timestamp: 1553978638\n",
      "  timesteps_since_restore: 5430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5430000\n",
      "  training_iteration: 543\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12856 s, 543 iter, 5430000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-44-22\n",
      "  done: false\n",
      "  episode_len_mean: 173.06\n",
      "  episode_reward_max: 1171.1166167250728\n",
      "  episode_reward_mean: 989.5684689877406\n",
      "  episode_reward_min: -90.08934019361412\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 31378\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.833\n",
      "    load_time_ms: 1.631\n",
      "    num_steps_sampled: 5440000\n",
      "    num_steps_trained: 5440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6897554993629456\n",
      "      kl: 0.02088983915746212\n",
      "      policy_loss: -0.0015725638950243592\n",
      "      total_loss: 801.4764404296875\n",
      "      vf_explained_var: 0.9628456234931946\n",
      "      vf_loss: 801.4765625\n",
      "    sample_time_ms: 19941.337\n",
      "    update_time_ms: 5.336\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.7842344938704\n",
      "  time_since_restore: 12880.22050666809\n",
      "  time_this_iter_s: 24.06279969215393\n",
      "  time_total_s: 12880.22050666809\n",
      "  timestamp: 1553978662\n",
      "  timesteps_since_restore: 5440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5440000\n",
      "  training_iteration: 544\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12880 s, 544 iter, 5440000 ts, 990 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-44-46\n",
      "  done: false\n",
      "  episode_len_mean: 171.54\n",
      "  episode_reward_max: 1171.1166167250728\n",
      "  episode_reward_mean: 1001.0933053199124\n",
      "  episode_reward_min: 24.552283756078253\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 31436\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.469\n",
      "    load_time_ms: 1.676\n",
      "    num_steps_sampled: 5450000\n",
      "    num_steps_trained: 5450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.701120913028717\n",
      "      kl: 0.01618960127234459\n",
      "      policy_loss: -0.001952311722561717\n",
      "      total_loss: 257.2978820800781\n",
      "      vf_explained_var: 0.9892218112945557\n",
      "      vf_loss: 257.2986755371094\n",
      "    sample_time_ms: 19913.04\n",
      "    update_time_ms: 5.351\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 500.5466526599562\n",
      "  time_since_restore: 12904.05644106865\n",
      "  time_this_iter_s: 23.83593440055847\n",
      "  time_total_s: 12904.05644106865\n",
      "  timestamp: 1553978686\n",
      "  timesteps_since_restore: 5450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5450000\n",
      "  training_iteration: 545\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12904 s, 545 iter, 5450000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-45-10\n",
      "  done: false\n",
      "  episode_len_mean: 169.77\n",
      "  episode_reward_max: 1163.7737796418762\n",
      "  episode_reward_mean: 952.2251535589717\n",
      "  episode_reward_min: 10.807227079195144\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 31495\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.48\n",
      "    load_time_ms: 1.671\n",
      "    num_steps_sampled: 5460000\n",
      "    num_steps_trained: 5460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8143005967140198\n",
      "      kl: 0.021549245342612267\n",
      "      policy_loss: -0.005664071999490261\n",
      "      total_loss: 1130.5831298828125\n",
      "      vf_explained_var: 0.9540801644325256\n",
      "      vf_loss: 1130.5872802734375\n",
      "    sample_time_ms: 19947.512\n",
      "    update_time_ms: 5.546\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.11257677948566\n",
      "  time_since_restore: 12928.313111305237\n",
      "  time_this_iter_s: 24.256670236587524\n",
      "  time_total_s: 12928.313111305237\n",
      "  timestamp: 1553978710\n",
      "  timesteps_since_restore: 5460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5460000\n",
      "  training_iteration: 546\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12928 s, 546 iter, 5460000 ts, 952 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-45-34\n",
      "  done: false\n",
      "  episode_len_mean: 176.89\n",
      "  episode_reward_max: 1163.7737796418762\n",
      "  episode_reward_mean: 960.9223073238983\n",
      "  episode_reward_min: 23.675356442521547\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 31551\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.262\n",
      "    load_time_ms: 1.704\n",
      "    num_steps_sampled: 5470000\n",
      "    num_steps_trained: 5470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.861663818359375\n",
      "      kl: 0.019337497651576996\n",
      "      policy_loss: -0.005169140174984932\n",
      "      total_loss: 789.2628173828125\n",
      "      vf_explained_var: 0.9647569060325623\n",
      "      vf_loss: 789.2665405273438\n",
      "    sample_time_ms: 19838.72\n",
      "    update_time_ms: 5.662\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.4611536619491\n",
      "  time_since_restore: 12951.761718034744\n",
      "  time_this_iter_s: 23.448606729507446\n",
      "  time_total_s: 12951.761718034744\n",
      "  timestamp: 1553978734\n",
      "  timesteps_since_restore: 5470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5470000\n",
      "  training_iteration: 547\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12951 s, 547 iter, 5470000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-45-58\n",
      "  done: false\n",
      "  episode_len_mean: 165.67\n",
      "  episode_reward_max: 1093.5862196867085\n",
      "  episode_reward_mean: 965.4122618676344\n",
      "  episode_reward_min: -29.52889516230252\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 31612\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.317\n",
      "    load_time_ms: 1.767\n",
      "    num_steps_sampled: 5480000\n",
      "    num_steps_trained: 5480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.617622971534729\n",
      "      kl: 0.018564380705356598\n",
      "      policy_loss: -0.004163810517638922\n",
      "      total_loss: 545.0170288085938\n",
      "      vf_explained_var: 0.9754922389984131\n",
      "      vf_loss: 545.0198364257812\n",
      "    sample_time_ms: 19940.027\n",
      "    update_time_ms: 5.571\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.7061309338172\n",
      "  time_since_restore: 12975.68360710144\n",
      "  time_this_iter_s: 23.921889066696167\n",
      "  time_total_s: 12975.68360710144\n",
      "  timestamp: 1553978758\n",
      "  timesteps_since_restore: 5480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5480000\n",
      "  training_iteration: 548\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12975 s, 548 iter, 5480000 ts, 965 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-46-21\n",
      "  done: false\n",
      "  episode_len_mean: 170.21\n",
      "  episode_reward_max: 1132.1726645955\n",
      "  episode_reward_mean: 975.5274878158581\n",
      "  episode_reward_min: -16.951917143436333\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 31670\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3923.176\n",
      "    load_time_ms: 1.784\n",
      "    num_steps_sampled: 5490000\n",
      "    num_steps_trained: 5490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7231146693229675\n",
      "      kl: 0.018161822110414505\n",
      "      policy_loss: -0.0008306297240778804\n",
      "      total_loss: 610.2234497070312\n",
      "      vf_explained_var: 0.9716360569000244\n",
      "      vf_loss: 610.2229614257812\n",
      "    sample_time_ms: 19938.343\n",
      "    update_time_ms: 5.552\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.76374390792904\n",
      "  time_since_restore: 12999.345599412918\n",
      "  time_this_iter_s: 23.66199231147766\n",
      "  time_total_s: 12999.345599412918\n",
      "  timestamp: 1553978781\n",
      "  timesteps_since_restore: 5490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5490000\n",
      "  training_iteration: 549\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 12999 s, 549 iter, 5490000 ts, 976 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-46-45\n",
      "  done: false\n",
      "  episode_len_mean: 173.17\n",
      "  episode_reward_max: 1148.6159440159806\n",
      "  episode_reward_mean: 959.938608179448\n",
      "  episode_reward_min: -16.951917143436333\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 31726\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3920.823\n",
      "    load_time_ms: 1.756\n",
      "    num_steps_sampled: 5500000\n",
      "    num_steps_trained: 5500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8310970664024353\n",
      "      kl: 0.014824895188212395\n",
      "      policy_loss: -0.0021717739291489124\n",
      "      total_loss: 772.95263671875\n",
      "      vf_explained_var: 0.9647461175918579\n",
      "      vf_loss: 772.9537353515625\n",
      "    sample_time_ms: 19857.958\n",
      "    update_time_ms: 5.644\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.9693040897239\n",
      "  time_since_restore: 13023.332349538803\n",
      "  time_this_iter_s: 23.98675012588501\n",
      "  time_total_s: 13023.332349538803\n",
      "  timestamp: 1553978805\n",
      "  timesteps_since_restore: 5500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5500000\n",
      "  training_iteration: 550\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13023 s, 550 iter, 5500000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-47-10\n",
      "  done: false\n",
      "  episode_len_mean: 180.08\n",
      "  episode_reward_max: 1148.6159440159806\n",
      "  episode_reward_mean: 965.9585735955221\n",
      "  episode_reward_min: -47.981284061348845\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 31781\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3931.193\n",
      "    load_time_ms: 1.728\n",
      "    num_steps_sampled: 5510000\n",
      "    num_steps_trained: 5510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7313334941864014\n",
      "      kl: 0.01910524256527424\n",
      "      policy_loss: -0.0015242405934259295\n",
      "      total_loss: 467.8843078613281\n",
      "      vf_explained_var: 0.9779974222183228\n",
      "      vf_loss: 467.88446044921875\n",
      "    sample_time_ms: 19867.491\n",
      "    update_time_ms: 5.692\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.97928679776095\n",
      "  time_since_restore: 13047.650496959686\n",
      "  time_this_iter_s: 24.31814742088318\n",
      "  time_total_s: 13047.650496959686\n",
      "  timestamp: 1553978830\n",
      "  timesteps_since_restore: 5510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5510000\n",
      "  training_iteration: 551\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13047 s, 551 iter, 5510000 ts, 966 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 178.29\n",
      "  episode_reward_max: 1115.0827147288799\n",
      "  episode_reward_mean: 962.856955990311\n",
      "  episode_reward_min: -47.981284061348845\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 31839\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3926.518\n",
      "    load_time_ms: 1.727\n",
      "    num_steps_sampled: 5520000\n",
      "    num_steps_trained: 5520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7885271906852722\n",
      "      kl: 0.013185081072151661\n",
      "      policy_loss: -0.0014771834248676896\n",
      "      total_loss: 604.65771484375\n",
      "      vf_explained_var: 0.9740477204322815\n",
      "      vf_loss: 604.6582641601562\n",
      "    sample_time_ms: 19973.053\n",
      "    update_time_ms: 5.669\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.4284779951555\n",
      "  time_since_restore: 13071.517011404037\n",
      "  time_this_iter_s: 23.866514444351196\n",
      "  time_total_s: 13071.517011404037\n",
      "  timestamp: 1553978854\n",
      "  timesteps_since_restore: 5520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5520000\n",
      "  training_iteration: 552\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13071 s, 552 iter, 5520000 ts, 963 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-47-58\n",
      "  done: false\n",
      "  episode_len_mean: 163.86\n",
      "  episode_reward_max: 1115.0827147288799\n",
      "  episode_reward_mean: 889.687888047659\n",
      "  episode_reward_min: -80.33862141860388\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 31900\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3928.331\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 5530000\n",
      "    num_steps_trained: 5530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.769176185131073\n",
      "      kl: 0.016659589484333992\n",
      "      policy_loss: -0.0020829630084335804\n",
      "      total_loss: 2051.005126953125\n",
      "      vf_explained_var: 0.9169877171516418\n",
      "      vf_loss: 2051.006103515625\n",
      "    sample_time_ms: 20011.895\n",
      "    update_time_ms: 5.486\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 444.84394402382964\n",
      "  time_since_restore: 13095.804542303085\n",
      "  time_this_iter_s: 24.28753089904785\n",
      "  time_total_s: 13095.804542303085\n",
      "  timestamp: 1553978878\n",
      "  timesteps_since_restore: 5530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5530000\n",
      "  training_iteration: 553\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13095 s, 553 iter, 5530000 ts, 890 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-48-22\n",
      "  done: false\n",
      "  episode_len_mean: 166.49\n",
      "  episode_reward_max: 1130.5656486218072\n",
      "  episode_reward_mean: 934.8146540922585\n",
      "  episode_reward_min: -80.33862141860388\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 31958\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3925.187\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 5540000\n",
      "    num_steps_trained: 5540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6806817650794983\n",
      "      kl: 0.01802912726998329\n",
      "      policy_loss: -0.0025835095439106226\n",
      "      total_loss: 759.802001953125\n",
      "      vf_explained_var: 0.9662905931472778\n",
      "      vf_loss: 759.8032836914062\n",
      "    sample_time_ms: 19987.263\n",
      "    update_time_ms: 5.206\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.4073270461291\n",
      "  time_since_restore: 13119.586603403091\n",
      "  time_this_iter_s: 23.782061100006104\n",
      "  time_total_s: 13119.586603403091\n",
      "  timestamp: 1553978902\n",
      "  timesteps_since_restore: 5540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5540000\n",
      "  training_iteration: 554\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13119 s, 554 iter, 5540000 ts, 935 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-48-46\n",
      "  done: false\n",
      "  episode_len_mean: 167.13\n",
      "  episode_reward_max: 1130.5656486218072\n",
      "  episode_reward_mean: 946.7278663020369\n",
      "  episode_reward_min: -74.09701632966332\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 32020\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.248\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 5550000\n",
      "    num_steps_trained: 5550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49892744421958923\n",
      "      kl: 0.028700605034828186\n",
      "      policy_loss: -0.006360230036079884\n",
      "      total_loss: 1293.0244140625\n",
      "      vf_explained_var: 0.9476472735404968\n",
      "      vf_loss: 1293.02880859375\n",
      "    sample_time_ms: 20013.035\n",
      "    update_time_ms: 5.292\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.36393315101844\n",
      "  time_since_restore: 13143.670447826385\n",
      "  time_this_iter_s: 24.083844423294067\n",
      "  time_total_s: 13143.670447826385\n",
      "  timestamp: 1553978926\n",
      "  timesteps_since_restore: 5550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5550000\n",
      "  training_iteration: 555\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13143 s, 555 iter, 5550000 ts, 947 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-49-10\n",
      "  done: false\n",
      "  episode_len_mean: 168.92\n",
      "  episode_reward_max: 1134.5799095817717\n",
      "  episode_reward_mean: 982.6887075648615\n",
      "  episode_reward_min: -60.00991552977274\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 32076\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.366\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 5560000\n",
      "    num_steps_trained: 5560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5532268285751343\n",
      "      kl: 0.0161847285926342\n",
      "      policy_loss: -0.0008402747334912419\n",
      "      total_loss: 549.4679565429688\n",
      "      vf_explained_var: 0.974978506565094\n",
      "      vf_loss: 549.4676513671875\n",
      "    sample_time_ms: 19998.419\n",
      "    update_time_ms: 5.085\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.3443537824307\n",
      "  time_since_restore: 13167.70953822136\n",
      "  time_this_iter_s: 24.039090394973755\n",
      "  time_total_s: 13167.70953822136\n",
      "  timestamp: 1553978950\n",
      "  timesteps_since_restore: 5560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5560000\n",
      "  training_iteration: 556\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13167 s, 556 iter, 5560000 ts, 983 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-49-33\n",
      "  done: false\n",
      "  episode_len_mean: 180.76\n",
      "  episode_reward_max: 1143.724418169969\n",
      "  episode_reward_mean: 965.5449384063198\n",
      "  episode_reward_min: -107.50443560858969\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 32130\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.873\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 5570000\n",
      "    num_steps_trained: 5570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9754809141159058\n",
      "      kl: 0.02079862728714943\n",
      "      policy_loss: -0.0005836900090798736\n",
      "      total_loss: 1190.087158203125\n",
      "      vf_explained_var: 0.9474120736122131\n",
      "      vf_loss: 1190.0863037109375\n",
      "    sample_time_ms: 19973.162\n",
      "    update_time_ms: 4.981\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.77246920316\n",
      "  time_since_restore: 13190.858279466629\n",
      "  time_this_iter_s: 23.148741245269775\n",
      "  time_total_s: 13190.858279466629\n",
      "  timestamp: 1553978973\n",
      "  timesteps_since_restore: 5570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5570000\n",
      "  training_iteration: 557\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13190 s, 557 iter, 5570000 ts, 966 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-49-57\n",
      "  done: false\n",
      "  episode_len_mean: 173.54\n",
      "  episode_reward_max: 1138.2669858860652\n",
      "  episode_reward_mean: 968.6580809728506\n",
      "  episode_reward_min: -107.50443560858969\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 32189\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.316\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 5580000\n",
      "    num_steps_trained: 5580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.617711067199707\n",
      "      kl: 0.024679061025381088\n",
      "      policy_loss: -0.0013702129945158958\n",
      "      total_loss: 363.61041259765625\n",
      "      vf_explained_var: 0.9835354685783386\n",
      "      vf_loss: 363.6100158691406\n",
      "    sample_time_ms: 19917.846\n",
      "    update_time_ms: 5.106\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.32904048642536\n",
      "  time_since_restore: 13214.22115278244\n",
      "  time_this_iter_s: 23.362873315811157\n",
      "  time_total_s: 13214.22115278244\n",
      "  timestamp: 1553978997\n",
      "  timesteps_since_restore: 5580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5580000\n",
      "  training_iteration: 558\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13214 s, 558 iter, 5580000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-50-21\n",
      "  done: false\n",
      "  episode_len_mean: 165.32\n",
      "  episode_reward_max: 1122.961809134928\n",
      "  episode_reward_mean: 958.0559573171615\n",
      "  episode_reward_min: -95.7299999573379\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 32251\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.867\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 5590000\n",
      "    num_steps_trained: 5590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5515392422676086\n",
      "      kl: 0.015675606206059456\n",
      "      policy_loss: -0.002754220273345709\n",
      "      total_loss: 953.2171630859375\n",
      "      vf_explained_var: 0.958734929561615\n",
      "      vf_loss: 953.21875\n",
      "    sample_time_ms: 20025.49\n",
      "    update_time_ms: 5.175\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.0279786585808\n",
      "  time_since_restore: 13238.901480436325\n",
      "  time_this_iter_s: 24.680327653884888\n",
      "  time_total_s: 13238.901480436325\n",
      "  timestamp: 1553979021\n",
      "  timesteps_since_restore: 5590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5590000\n",
      "  training_iteration: 559\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13238 s, 559 iter, 5590000 ts, 958 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-50-46\n",
      "  done: false\n",
      "  episode_len_mean: 164.38\n",
      "  episode_reward_max: 1126.9277456585073\n",
      "  episode_reward_mean: 931.5145379926656\n",
      "  episode_reward_min: -95.7299999573379\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 32311\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.059\n",
      "    load_time_ms: 1.397\n",
      "    num_steps_sampled: 5600000\n",
      "    num_steps_trained: 5600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7188680768013\n",
      "      kl: 0.015016128309071064\n",
      "      policy_loss: -0.0005997308762744069\n",
      "      total_loss: 783.6337890625\n",
      "      vf_explained_var: 0.9665783643722534\n",
      "      vf_loss: 783.6332397460938\n",
      "    sample_time_ms: 20038.088\n",
      "    update_time_ms: 5.222\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 465.7572689963327\n",
      "  time_since_restore: 13263.028100967407\n",
      "  time_this_iter_s: 24.126620531082153\n",
      "  time_total_s: 13263.028100967407\n",
      "  timestamp: 1553979046\n",
      "  timesteps_since_restore: 5600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5600000\n",
      "  training_iteration: 560\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13263 s, 560 iter, 5600000 ts, 932 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-51-10\n",
      "  done: false\n",
      "  episode_len_mean: 170.51\n",
      "  episode_reward_max: 1146.9285242222286\n",
      "  episode_reward_mean: 967.8217649700011\n",
      "  episode_reward_min: -86.78134739875816\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 32367\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.337\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 5610000\n",
      "    num_steps_trained: 5610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6706960201263428\n",
      "      kl: 0.02924639731645584\n",
      "      policy_loss: -0.0019594146870076656\n",
      "      total_loss: 127.57511901855469\n",
      "      vf_explained_var: 0.9940803647041321\n",
      "      vf_loss: 127.57499694824219\n",
      "    sample_time_ms: 20028.325\n",
      "    update_time_ms: 5.256\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.9108824850006\n",
      "  time_since_restore: 13287.253586053848\n",
      "  time_this_iter_s: 24.22548508644104\n",
      "  time_total_s: 13287.253586053848\n",
      "  timestamp: 1553979070\n",
      "  timesteps_since_restore: 5610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5610000\n",
      "  training_iteration: 561\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13287 s, 561 iter, 5610000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-51-33\n",
      "  done: false\n",
      "  episode_len_mean: 179.73\n",
      "  episode_reward_max: 1146.9285242222286\n",
      "  episode_reward_mean: 988.5482241581868\n",
      "  episode_reward_min: -53.99293197935262\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 32422\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.433\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 5620000\n",
      "    num_steps_trained: 5620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8598678708076477\n",
      "      kl: 0.012849454768002033\n",
      "      policy_loss: -0.00043111637933179736\n",
      "      total_loss: 785.0115356445312\n",
      "      vf_explained_var: 0.9628346562385559\n",
      "      vf_loss: 785.0110473632812\n",
      "    sample_time_ms: 19986.12\n",
      "    update_time_ms: 5.288\n",
      "  iterations_since_restore: 562\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.2741120790935\n",
      "  time_since_restore: 13310.721472978592\n",
      "  time_this_iter_s: 23.467886924743652\n",
      "  time_total_s: 13310.721472978592\n",
      "  timestamp: 1553979093\n",
      "  timesteps_since_restore: 5620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5620000\n",
      "  training_iteration: 562\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13310 s, 562 iter, 5620000 ts, 989 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-51-57\n",
      "  done: false\n",
      "  episode_len_mean: 175.26\n",
      "  episode_reward_max: 1133.8513934357275\n",
      "  episode_reward_mean: 970.2972618556385\n",
      "  episode_reward_min: -33.78108359809485\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 32481\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.685\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 5630000\n",
      "    num_steps_trained: 5630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5997037291526794\n",
      "      kl: 0.023820241913199425\n",
      "      policy_loss: -0.004571837373077869\n",
      "      total_loss: 621.5755004882812\n",
      "      vf_explained_var: 0.9716305732727051\n",
      "      vf_loss: 621.578369140625\n",
      "    sample_time_ms: 19937.831\n",
      "    update_time_ms: 5.297\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.1486309278194\n",
      "  time_since_restore: 13334.538668870926\n",
      "  time_this_iter_s: 23.817195892333984\n",
      "  time_total_s: 13334.538668870926\n",
      "  timestamp: 1553979117\n",
      "  timesteps_since_restore: 5630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5630000\n",
      "  training_iteration: 563\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13334 s, 563 iter, 5630000 ts, 970 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-52-21\n",
      "  done: false\n",
      "  episode_len_mean: 170.53\n",
      "  episode_reward_max: 1116.9525857630013\n",
      "  episode_reward_mean: 917.1931031827553\n",
      "  episode_reward_min: -87.59459859097795\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 32540\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.17\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 5640000\n",
      "    num_steps_trained: 5640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.897913932800293\n",
      "      kl: 0.018512168899178505\n",
      "      policy_loss: -0.003625559387728572\n",
      "      total_loss: 1463.3194580078125\n",
      "      vf_explained_var: 0.9406002759933472\n",
      "      vf_loss: 1463.3218994140625\n",
      "    sample_time_ms: 19939.82\n",
      "    update_time_ms: 5.281\n",
      "  iterations_since_restore: 564\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 458.5965515913777\n",
      "  time_since_restore: 13358.312231302261\n",
      "  time_this_iter_s: 23.77356243133545\n",
      "  time_total_s: 13358.312231302261\n",
      "  timestamp: 1553979141\n",
      "  timesteps_since_restore: 5640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5640000\n",
      "  training_iteration: 564\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13358 s, 564 iter, 5640000 ts, 917 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-52-45\n",
      "  done: false\n",
      "  episode_len_mean: 167.72\n",
      "  episode_reward_max: 1116.9525857630013\n",
      "  episode_reward_mean: 938.6808061706115\n",
      "  episode_reward_min: -73.89057380357376\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 32601\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.471\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 5650000\n",
      "    num_steps_trained: 5650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6083418726921082\n",
      "      kl: 0.019504060968756676\n",
      "      policy_loss: -0.003082508686929941\n",
      "      total_loss: 496.984375\n",
      "      vf_explained_var: 0.9800280332565308\n",
      "      vf_loss: 496.98602294921875\n",
      "    sample_time_ms: 19891.728\n",
      "    update_time_ms: 5.259\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.34040308530575\n",
      "  time_since_restore: 13381.908471107483\n",
      "  time_this_iter_s: 23.596239805221558\n",
      "  time_total_s: 13381.908471107483\n",
      "  timestamp: 1553979165\n",
      "  timesteps_since_restore: 5650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5650000\n",
      "  training_iteration: 565\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13381 s, 565 iter, 5650000 ts, 939 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-53-09\n",
      "  done: false\n",
      "  episode_len_mean: 171.68\n",
      "  episode_reward_max: 1139.9853758490112\n",
      "  episode_reward_mean: 972.7991332127734\n",
      "  episode_reward_min: -43.97393208647233\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 32657\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.125\n",
      "    load_time_ms: 1.428\n",
      "    num_steps_sampled: 5660000\n",
      "    num_steps_trained: 5660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7176158428192139\n",
      "      kl: 0.018778976052999496\n",
      "      policy_loss: -0.002650189446285367\n",
      "      total_loss: 757.7962036132812\n",
      "      vf_explained_var: 0.9649198651313782\n",
      "      vf_loss: 757.7974853515625\n",
      "    sample_time_ms: 19924.066\n",
      "    update_time_ms: 5.22\n",
      "  iterations_since_restore: 566\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.39956660638666\n",
      "  time_since_restore: 13406.290007591248\n",
      "  time_this_iter_s: 24.38153648376465\n",
      "  time_total_s: 13406.290007591248\n",
      "  timestamp: 1553979189\n",
      "  timesteps_since_restore: 5660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5660000\n",
      "  training_iteration: 566\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13406 s, 566 iter, 5660000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-53-33\n",
      "  done: false\n",
      "  episode_len_mean: 180.08\n",
      "  episode_reward_max: 1139.9853758490112\n",
      "  episode_reward_mean: 995.1900543100284\n",
      "  episode_reward_min: 3.7411812178492028\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 32713\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.08\n",
      "    load_time_ms: 1.393\n",
      "    num_steps_sampled: 5670000\n",
      "    num_steps_trained: 5670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7072517275810242\n",
      "      kl: 0.022680018097162247\n",
      "      policy_loss: 0.0006157414754852653\n",
      "      total_loss: 179.3812255859375\n",
      "      vf_explained_var: 0.9925146102905273\n",
      "      vf_loss: 179.37899780273438\n",
      "    sample_time_ms: 20024.835\n",
      "    update_time_ms: 5.129\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.5950271550142\n",
      "  time_since_restore: 13430.432688474655\n",
      "  time_this_iter_s: 24.142680883407593\n",
      "  time_total_s: 13430.432688474655\n",
      "  timestamp: 1553979213\n",
      "  timesteps_since_restore: 5670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5670000\n",
      "  training_iteration: 567\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13430 s, 567 iter, 5670000 ts, 995 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-53-58\n",
      "  done: false\n",
      "  episode_len_mean: 167.93\n",
      "  episode_reward_max: 1133.3973775059374\n",
      "  episode_reward_mean: 949.8358161306828\n",
      "  episode_reward_min: -58.82643260101682\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 32775\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3920.598\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 5680000\n",
      "    num_steps_trained: 5680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.619866132736206\n",
      "      kl: 0.01417072955518961\n",
      "      policy_loss: -0.0007899169577285647\n",
      "      total_loss: 1480.1422119140625\n",
      "      vf_explained_var: 0.9411730766296387\n",
      "      vf_loss: 1480.1422119140625\n",
      "    sample_time_ms: 20108.069\n",
      "    update_time_ms: 5.123\n",
      "  iterations_since_restore: 568\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.91790806534146\n",
      "  time_since_restore: 13454.743903636932\n",
      "  time_this_iter_s: 24.31121516227722\n",
      "  time_total_s: 13454.743903636932\n",
      "  timestamp: 1553979238\n",
      "  timesteps_since_restore: 5680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5680000\n",
      "  training_iteration: 568\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13454 s, 568 iter, 5680000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-54-21\n",
      "  done: false\n",
      "  episode_len_mean: 167.89\n",
      "  episode_reward_max: 1133.6931062088163\n",
      "  episode_reward_mean: 936.1049781024315\n",
      "  episode_reward_min: -45.61647991891772\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 32833\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.648\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 5690000\n",
      "    num_steps_trained: 5690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7312225103378296\n",
      "      kl: 0.02289467304944992\n",
      "      policy_loss: -0.0022804553154855967\n",
      "      total_loss: 1275.2896728515625\n",
      "      vf_explained_var: 0.941121518611908\n",
      "      vf_loss: 1275.2904052734375\n",
      "    sample_time_ms: 20027.833\n",
      "    update_time_ms: 5.106\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.05248905121584\n",
      "  time_since_restore: 13478.607925653458\n",
      "  time_this_iter_s: 23.86402201652527\n",
      "  time_total_s: 13478.607925653458\n",
      "  timestamp: 1553979261\n",
      "  timesteps_since_restore: 5690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5690000\n",
      "  training_iteration: 569\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13478 s, 569 iter, 5690000 ts, 936 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 175.7\n",
      "  episode_reward_max: 1133.6931062088163\n",
      "  episode_reward_mean: 949.8048446174814\n",
      "  episode_reward_min: -90.19534277371825\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 32890\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.31\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 5700000\n",
      "    num_steps_trained: 5700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7724288702011108\n",
      "      kl: 0.025275321677327156\n",
      "      policy_loss: -0.0074371411465108395\n",
      "      total_loss: 765.4398803710938\n",
      "      vf_explained_var: 0.9677584767341614\n",
      "      vf_loss: 765.4456176757812\n",
      "    sample_time_ms: 20034.776\n",
      "    update_time_ms: 4.994\n",
      "  iterations_since_restore: 570\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.90242230874065\n",
      "  time_since_restore: 13502.800157785416\n",
      "  time_this_iter_s: 24.192232131958008\n",
      "  time_total_s: 13502.800157785416\n",
      "  timestamp: 1553979286\n",
      "  timesteps_since_restore: 5700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5700000\n",
      "  training_iteration: 570\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13502 s, 570 iter, 5700000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-55-10\n",
      "  done: false\n",
      "  episode_len_mean: 174.46\n",
      "  episode_reward_max: 1131.1825849726515\n",
      "  episode_reward_mean: 956.1165505227274\n",
      "  episode_reward_min: -90.19534277371825\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 32947\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3922.721\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 5710000\n",
      "    num_steps_trained: 5710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6874401569366455\n",
      "      kl: 0.017778053879737854\n",
      "      policy_loss: -0.0001558730291435495\n",
      "      total_loss: 587.5601196289062\n",
      "      vf_explained_var: 0.9751003980636597\n",
      "      vf_loss: 587.5590209960938\n",
      "    sample_time_ms: 20021.338\n",
      "    update_time_ms: 5.076\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.0582752613636\n",
      "  time_since_restore: 13526.935587644577\n",
      "  time_this_iter_s: 24.135429859161377\n",
      "  time_total_s: 13526.935587644577\n",
      "  timestamp: 1553979310\n",
      "  timesteps_since_restore: 5710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5710000\n",
      "  training_iteration: 571\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13526 s, 571 iter, 5710000 ts, 956 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-55-34\n",
      "  done: false\n",
      "  episode_len_mean: 178.53\n",
      "  episode_reward_max: 1131.1825849726515\n",
      "  episode_reward_mean: 945.4917499958729\n",
      "  episode_reward_min: -15.390927983722833\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 33003\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3916.859\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 5720000\n",
      "    num_steps_trained: 5720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8679466247558594\n",
      "      kl: 0.01774558052420616\n",
      "      policy_loss: 0.0011514092329889536\n",
      "      total_loss: 820.3170776367188\n",
      "      vf_explained_var: 0.9644849896430969\n",
      "      vf_loss: 820.3146362304688\n",
      "    sample_time_ms: 20096.997\n",
      "    update_time_ms: 5.265\n",
      "  iterations_since_restore: 572\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.7458749979364\n",
      "  time_since_restore: 13551.101590156555\n",
      "  time_this_iter_s: 24.16600251197815\n",
      "  time_total_s: 13551.101590156555\n",
      "  timestamp: 1553979334\n",
      "  timesteps_since_restore: 5720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5720000\n",
      "  training_iteration: 572\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13551 s, 572 iter, 5720000 ts, 945 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-55-58\n",
      "  done: false\n",
      "  episode_len_mean: 180.24\n",
      "  episode_reward_max: 1107.9686550193942\n",
      "  episode_reward_mean: 978.6690988488597\n",
      "  episode_reward_min: -15.390927983722833\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 33060\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.549\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 5730000\n",
      "    num_steps_trained: 5730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7882257103919983\n",
      "      kl: 0.023748250678181648\n",
      "      policy_loss: -0.002909097820520401\n",
      "      total_loss: 231.0927734375\n",
      "      vf_explained_var: 0.9902200698852539\n",
      "      vf_loss: 231.093994140625\n",
      "    sample_time_ms: 20080.273\n",
      "    update_time_ms: 5.841\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.33454942442984\n",
      "  time_since_restore: 13574.73900961876\n",
      "  time_this_iter_s: 23.63741946220398\n",
      "  time_total_s: 13574.73900961876\n",
      "  timestamp: 1553979358\n",
      "  timesteps_since_restore: 5730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5730000\n",
      "  training_iteration: 573\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13574 s, 573 iter, 5730000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-56-22\n",
      "  done: false\n",
      "  episode_len_mean: 170.06\n",
      "  episode_reward_max: 1123.8942739972879\n",
      "  episode_reward_mean: 991.5459778319648\n",
      "  episode_reward_min: -7.58528481931657\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 33118\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3916.102\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 5740000\n",
      "    num_steps_trained: 5740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6195138692855835\n",
      "      kl: 0.020424894988536835\n",
      "      policy_loss: -0.0030860567931085825\n",
      "      total_loss: 466.7841491699219\n",
      "      vf_explained_var: 0.9801266193389893\n",
      "      vf_loss: 466.7857666015625\n",
      "    sample_time_ms: 20112.434\n",
      "    update_time_ms: 5.824\n",
      "  iterations_since_restore: 574\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.7729889159824\n",
      "  time_since_restore: 13598.851774215698\n",
      "  time_this_iter_s: 24.112764596939087\n",
      "  time_total_s: 13598.851774215698\n",
      "  timestamp: 1553979382\n",
      "  timesteps_since_restore: 5740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5740000\n",
      "  training_iteration: 574\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13598 s, 574 iter, 5740000 ts, 992 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-56-46\n",
      "  done: false\n",
      "  episode_len_mean: 173.39\n",
      "  episode_reward_max: 1116.6012101566387\n",
      "  episode_reward_mean: 986.7956899133201\n",
      "  episode_reward_min: -69.79118861934654\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 33177\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.131\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 5750000\n",
      "    num_steps_trained: 5750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6724591255187988\n",
      "      kl: 0.02397891879081726\n",
      "      policy_loss: -0.0033816946670413017\n",
      "      total_loss: 969.0283203125\n",
      "      vf_explained_var: 0.9583603143692017\n",
      "      vf_loss: 969.030029296875\n",
      "    sample_time_ms: 20167.468\n",
      "    update_time_ms: 5.795\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.39784495666004\n",
      "  time_since_restore: 13623.027609586716\n",
      "  time_this_iter_s: 24.175835371017456\n",
      "  time_total_s: 13623.027609586716\n",
      "  timestamp: 1553979406\n",
      "  timesteps_since_restore: 5750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5750000\n",
      "  training_iteration: 575\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13623 s, 575 iter, 5750000 ts, 987 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-57-11\n",
      "  done: false\n",
      "  episode_len_mean: 173.69\n",
      "  episode_reward_max: 1134.0328738332898\n",
      "  episode_reward_mean: 937.6488153888164\n",
      "  episode_reward_min: -73.2670049597334\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 33234\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3922.365\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 5760000\n",
      "    num_steps_trained: 5760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.029886245727539\n",
      "      kl: 0.024547366425395012\n",
      "      policy_loss: -0.004209662321954966\n",
      "      total_loss: 899.9158935546875\n",
      "      vf_explained_var: 0.96492600440979\n",
      "      vf_loss: 899.9183959960938\n",
      "    sample_time_ms: 20189.693\n",
      "    update_time_ms: 5.807\n",
      "  iterations_since_restore: 576\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.8244076944083\n",
      "  time_since_restore: 13647.662932157516\n",
      "  time_this_iter_s: 24.63532257080078\n",
      "  time_total_s: 13647.662932157516\n",
      "  timestamp: 1553979431\n",
      "  timesteps_since_restore: 5760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5760000\n",
      "  training_iteration: 576\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13647 s, 576 iter, 5760000 ts, 938 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-57-36\n",
      "  done: false\n",
      "  episode_len_mean: 174.14\n",
      "  episode_reward_max: 1166.6772124766057\n",
      "  episode_reward_mean: 953.0653865756674\n",
      "  episode_reward_min: -73.2670049597334\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 33294\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.265\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 5770000\n",
      "    num_steps_trained: 5770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5582420825958252\n",
      "      kl: 0.017635902389883995\n",
      "      policy_loss: -0.0016943676164373755\n",
      "      total_loss: 623.1529541015625\n",
      "      vf_explained_var: 0.9728643894195557\n",
      "      vf_loss: 623.1533203125\n",
      "    sample_time_ms: 20245.696\n",
      "    update_time_ms: 5.98\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.53269328783375\n",
      "  time_since_restore: 13672.388183832169\n",
      "  time_this_iter_s: 24.7252516746521\n",
      "  time_total_s: 13672.388183832169\n",
      "  timestamp: 1553979456\n",
      "  timesteps_since_restore: 5770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5770000\n",
      "  training_iteration: 577\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13672 s, 577 iter, 5770000 ts, 953 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-57-59\n",
      "  done: false\n",
      "  episode_len_mean: 170.61\n",
      "  episode_reward_max: 1166.6772124766057\n",
      "  episode_reward_mean: 924.3014439597054\n",
      "  episode_reward_min: -87.31895803246785\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 33351\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.803\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 5780000\n",
      "    num_steps_trained: 5780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8912469148635864\n",
      "      kl: 0.02081749029457569\n",
      "      policy_loss: -0.0006708751316182315\n",
      "      total_loss: 1233.90087890625\n",
      "      vf_explained_var: 0.9486725926399231\n",
      "      vf_loss: 1233.9000244140625\n",
      "    sample_time_ms: 20181.462\n",
      "    update_time_ms: 6.14\n",
      "  iterations_since_restore: 578\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 462.1507219798527\n",
      "  time_since_restore: 13695.944169521332\n",
      "  time_this_iter_s: 23.555985689163208\n",
      "  time_total_s: 13695.944169521332\n",
      "  timestamp: 1553979479\n",
      "  timesteps_since_restore: 5780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5780000\n",
      "  training_iteration: 578\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13695 s, 578 iter, 5780000 ts, 924 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-58-24\n",
      "  done: false\n",
      "  episode_len_mean: 167.39\n",
      "  episode_reward_max: 1136.9382993738893\n",
      "  episode_reward_mean: 942.6625323952549\n",
      "  episode_reward_min: -40.217899330545805\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 33412\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.956\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 5790000\n",
      "    num_steps_trained: 5790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6193689107894897\n",
      "      kl: 0.020068584010004997\n",
      "      policy_loss: -0.001727743656374514\n",
      "      total_loss: 538.8965454101562\n",
      "      vf_explained_var: 0.9761280417442322\n",
      "      vf_loss: 538.896728515625\n",
      "    sample_time_ms: 20243.297\n",
      "    update_time_ms: 6.089\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.3312661976275\n",
      "  time_since_restore: 13720.473697900772\n",
      "  time_this_iter_s: 24.529528379440308\n",
      "  time_total_s: 13720.473697900772\n",
      "  timestamp: 1553979504\n",
      "  timesteps_since_restore: 5790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5790000\n",
      "  training_iteration: 579\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13720 s, 579 iter, 5790000 ts, 943 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-58-48\n",
      "  done: false\n",
      "  episode_len_mean: 169.6\n",
      "  episode_reward_max: 1169.324626556572\n",
      "  episode_reward_mean: 929.864036609725\n",
      "  episode_reward_min: -91.99307022638965\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 33470\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.68\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 5800000\n",
      "    num_steps_trained: 5800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.851546049118042\n",
      "      kl: 0.016802767291665077\n",
      "      policy_loss: -0.003311470150947571\n",
      "      total_loss: 1407.16650390625\n",
      "      vf_explained_var: 0.9387721419334412\n",
      "      vf_loss: 1407.168701171875\n",
      "    sample_time_ms: 20244.974\n",
      "    update_time_ms: 6.108\n",
      "  iterations_since_restore: 580\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 464.9320183048626\n",
      "  time_since_restore: 13744.681203365326\n",
      "  time_this_iter_s: 24.207505464553833\n",
      "  time_total_s: 13744.681203365326\n",
      "  timestamp: 1553979528\n",
      "  timesteps_since_restore: 5800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5800000\n",
      "  training_iteration: 580\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13744 s, 580 iter, 5800000 ts, 930 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-59-13\n",
      "  done: false\n",
      "  episode_len_mean: 168.81\n",
      "  episode_reward_max: 1135.7807001807919\n",
      "  episode_reward_mean: 951.3490736404101\n",
      "  episode_reward_min: -91.99307022638965\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 33528\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.555\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 5810000\n",
      "    num_steps_trained: 5810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6050161719322205\n",
      "      kl: 0.033390894532203674\n",
      "      policy_loss: -0.0005891636246815324\n",
      "      total_loss: 213.07363891601562\n",
      "      vf_explained_var: 0.9906332492828369\n",
      "      vf_loss: 213.07186889648438\n",
      "    sample_time_ms: 20303.019\n",
      "    update_time_ms: 5.972\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.67453682020505\n",
      "  time_since_restore: 13769.253039598465\n",
      "  time_this_iter_s: 24.571836233139038\n",
      "  time_total_s: 13769.253039598465\n",
      "  timestamp: 1553979553\n",
      "  timesteps_since_restore: 5810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5810000\n",
      "  training_iteration: 581\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13769 s, 581 iter, 5810000 ts, 951 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_21-59-37\n",
      "  done: false\n",
      "  episode_len_mean: 168.05\n",
      "  episode_reward_max: 1155.6174162541197\n",
      "  episode_reward_mean: 971.967724341154\n",
      "  episode_reward_min: -28.533599288182415\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 33587\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.802\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 5820000\n",
      "    num_steps_trained: 5820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8587701320648193\n",
      "      kl: 0.014586152508854866\n",
      "      policy_loss: -0.0006839956040494144\n",
      "      total_loss: 576.8286743164062\n",
      "      vf_explained_var: 0.9777583479881287\n",
      "      vf_loss: 576.8283081054688\n",
      "    sample_time_ms: 20294.15\n",
      "    update_time_ms: 5.774\n",
      "  iterations_since_restore: 582\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.983862170577\n",
      "  time_since_restore: 13793.396662473679\n",
      "  time_this_iter_s: 24.143622875213623\n",
      "  time_total_s: 13793.396662473679\n",
      "  timestamp: 1553979577\n",
      "  timesteps_since_restore: 5820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5820000\n",
      "  training_iteration: 582\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13793 s, 582 iter, 5820000 ts, 972 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-00-00\n",
      "  done: false\n",
      "  episode_len_mean: 169.54\n",
      "  episode_reward_max: 1178.4796608613626\n",
      "  episode_reward_mean: 941.8323214765202\n",
      "  episode_reward_min: -99.36250015223202\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 33646\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.268\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 5830000\n",
      "    num_steps_trained: 5830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9084791541099548\n",
      "      kl: 0.015225272625684738\n",
      "      policy_loss: -0.0012099260929971933\n",
      "      total_loss: 1084.5562744140625\n",
      "      vf_explained_var: 0.9571139812469482\n",
      "      vf_loss: 1084.5565185546875\n",
      "    sample_time_ms: 20297.079\n",
      "    update_time_ms: 7.105\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.9161607382601\n",
      "  time_since_restore: 13817.061789035797\n",
      "  time_this_iter_s: 23.66512656211853\n",
      "  time_total_s: 13817.061789035797\n",
      "  timestamp: 1553979600\n",
      "  timesteps_since_restore: 5830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5830000\n",
      "  training_iteration: 583\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13817 s, 583 iter, 5830000 ts, 942 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-00-25\n",
      "  done: false\n",
      "  episode_len_mean: 171.19\n",
      "  episode_reward_max: 1178.4796608613626\n",
      "  episode_reward_mean: 954.0931103849371\n",
      "  episode_reward_min: -42.64117221574824\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 33704\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.578\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 5840000\n",
      "    num_steps_trained: 5840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7581596374511719\n",
      "      kl: 0.018570417538285255\n",
      "      policy_loss: 0.00013896793825551867\n",
      "      total_loss: 714.1104125976562\n",
      "      vf_explained_var: 0.9687655568122864\n",
      "      vf_loss: 714.1089477539062\n",
      "    sample_time_ms: 20308.336\n",
      "    update_time_ms: 7.187\n",
      "  iterations_since_restore: 584\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.04655519246865\n",
      "  time_since_restore: 13841.281111001968\n",
      "  time_this_iter_s: 24.219321966171265\n",
      "  time_total_s: 13841.281111001968\n",
      "  timestamp: 1553979625\n",
      "  timesteps_since_restore: 5840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5840000\n",
      "  training_iteration: 584\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13841 s, 584 iter, 5840000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-00-49\n",
      "  done: false\n",
      "  episode_len_mean: 172.44\n",
      "  episode_reward_max: 1122.2726863037133\n",
      "  episode_reward_mean: 956.469001066051\n",
      "  episode_reward_min: -88.70021819836302\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 33761\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.686\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 5850000\n",
      "    num_steps_trained: 5850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9682879447937012\n",
      "      kl: 0.01970982737839222\n",
      "      policy_loss: -0.0006352261989377439\n",
      "      total_loss: 446.01470947265625\n",
      "      vf_explained_var: 0.9806115627288818\n",
      "      vf_loss: 446.013916015625\n",
      "    sample_time_ms: 20294.665\n",
      "    update_time_ms: 7.204\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.2345005330254\n",
      "  time_since_restore: 13865.281520843506\n",
      "  time_this_iter_s: 24.000409841537476\n",
      "  time_total_s: 13865.281520843506\n",
      "  timestamp: 1553979649\n",
      "  timesteps_since_restore: 5850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5850000\n",
      "  training_iteration: 585\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13865 s, 585 iter, 5850000 ts, 956 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-01-12\n",
      "  done: false\n",
      "  episode_len_mean: 177.84\n",
      "  episode_reward_max: 1160.8210779944677\n",
      "  episode_reward_mean: 976.9782333873345\n",
      "  episode_reward_min: -36.82294490697953\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 33820\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.029\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 5860000\n",
      "    num_steps_trained: 5860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6181446313858032\n",
      "      kl: 0.023480281233787537\n",
      "      policy_loss: -0.0020645936019718647\n",
      "      total_loss: 469.6953125\n",
      "      vf_explained_var: 0.9794018268585205\n",
      "      vf_loss: 469.69561767578125\n",
      "    sample_time_ms: 20213.682\n",
      "    update_time_ms: 7.269\n",
      "  iterations_since_restore: 586\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.4891166936673\n",
      "  time_since_restore: 13888.925039768219\n",
      "  time_this_iter_s: 23.643518924713135\n",
      "  time_total_s: 13888.925039768219\n",
      "  timestamp: 1553979672\n",
      "  timesteps_since_restore: 5860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5860000\n",
      "  training_iteration: 586\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13888 s, 586 iter, 5860000 ts, 977 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-01-36\n",
      "  done: false\n",
      "  episode_len_mean: 171.38\n",
      "  episode_reward_max: 1160.8210779944677\n",
      "  episode_reward_mean: 987.7793122263394\n",
      "  episode_reward_min: -97.49416133491331\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 33878\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.272\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 5870000\n",
      "    num_steps_trained: 5870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5596885681152344\n",
      "      kl: 0.01577026955783367\n",
      "      policy_loss: -0.0024418358225375414\n",
      "      total_loss: 664.6952514648438\n",
      "      vf_explained_var: 0.9713389277458191\n",
      "      vf_loss: 664.6966552734375\n",
      "    sample_time_ms: 20083.875\n",
      "    update_time_ms: 7.135\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.8896561131697\n",
      "  time_since_restore: 13912.322493314743\n",
      "  time_this_iter_s: 23.397453546524048\n",
      "  time_total_s: 13912.322493314743\n",
      "  timestamp: 1553979696\n",
      "  timesteps_since_restore: 5870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5870000\n",
      "  training_iteration: 587\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13912 s, 587 iter, 5870000 ts, 988 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-02-00\n",
      "  done: false\n",
      "  episode_len_mean: 168.65\n",
      "  episode_reward_max: 1132.3510661993762\n",
      "  episode_reward_mean: 986.5070690579688\n",
      "  episode_reward_min: -25.58281181580861\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 33939\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.794\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 5880000\n",
      "    num_steps_trained: 5880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6365586519241333\n",
      "      kl: 0.017297377809882164\n",
      "      policy_loss: -0.00074554025195539\n",
      "      total_loss: 702.2471923828125\n",
      "      vf_explained_var: 0.971472442150116\n",
      "      vf_loss: 702.2467651367188\n",
      "    sample_time_ms: 20108.75\n",
      "    update_time_ms: 7.708\n",
      "  iterations_since_restore: 588\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.25353452898446\n",
      "  time_since_restore: 13936.178895711899\n",
      "  time_this_iter_s: 23.85640239715576\n",
      "  time_total_s: 13936.178895711899\n",
      "  timestamp: 1553979720\n",
      "  timesteps_since_restore: 5880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5880000\n",
      "  training_iteration: 588\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13936 s, 588 iter, 5880000 ts, 987 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-02-24\n",
      "  done: false\n",
      "  episode_len_mean: 166.38\n",
      "  episode_reward_max: 1114.1039041750182\n",
      "  episode_reward_mean: 949.9334657991077\n",
      "  episode_reward_min: -59.46732312697671\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 33999\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.831\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 5890000\n",
      "    num_steps_trained: 5890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6777281165122986\n",
      "      kl: 0.0200783833861351\n",
      "      policy_loss: -0.003163107205182314\n",
      "      total_loss: 1056.1773681640625\n",
      "      vf_explained_var: 0.9567556977272034\n",
      "      vf_loss: 1056.1790771484375\n",
      "    sample_time_ms: 20062.028\n",
      "    update_time_ms: 7.719\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.96673289955385\n",
      "  time_since_restore: 13960.182224273682\n",
      "  time_this_iter_s: 24.003328561782837\n",
      "  time_total_s: 13960.182224273682\n",
      "  timestamp: 1553979744\n",
      "  timesteps_since_restore: 5890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5890000\n",
      "  training_iteration: 589\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13960 s, 589 iter, 5890000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-02-48\n",
      "  done: false\n",
      "  episode_len_mean: 168.2\n",
      "  episode_reward_max: 1114.1039041750182\n",
      "  episode_reward_mean: 959.957224726064\n",
      "  episode_reward_min: -84.31348259441404\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 34058\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.465\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 5900000\n",
      "    num_steps_trained: 5900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.82904052734375\n",
      "      kl: 0.016063427552580833\n",
      "      policy_loss: -0.0016543649835512042\n",
      "      total_loss: 497.1681823730469\n",
      "      vf_explained_var: 0.9786776304244995\n",
      "      vf_loss: 497.1686706542969\n",
      "    sample_time_ms: 20028.816\n",
      "    update_time_ms: 7.708\n",
      "  iterations_since_restore: 590\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.97861236303186\n",
      "  time_since_restore: 13984.002597808838\n",
      "  time_this_iter_s: 23.82037353515625\n",
      "  time_total_s: 13984.002597808838\n",
      "  timestamp: 1553979768\n",
      "  timesteps_since_restore: 5900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5900000\n",
      "  training_iteration: 590\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 13984 s, 590 iter, 5900000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-03-12\n",
      "  done: false\n",
      "  episode_len_mean: 164.77\n",
      "  episode_reward_max: 1136.3357971932542\n",
      "  episode_reward_mean: 989.7098748232731\n",
      "  episode_reward_min: -84.31348259441404\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 34120\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3870.298\n",
      "    load_time_ms: 1.729\n",
      "    num_steps_sampled: 5910000\n",
      "    num_steps_trained: 5910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.43725332617759705\n",
      "      kl: 0.03261374309659004\n",
      "      policy_loss: -0.007725272327661514\n",
      "      total_loss: 159.6857147216797\n",
      "      vf_explained_var: 0.9931323528289795\n",
      "      vf_loss: 159.69110107421875\n",
      "    sample_time_ms: 19977.318\n",
      "    update_time_ms: 7.744\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.8549374116366\n",
      "  time_since_restore: 14008.010655403137\n",
      "  time_this_iter_s: 24.008057594299316\n",
      "  time_total_s: 14008.010655403137\n",
      "  timestamp: 1553979792\n",
      "  timesteps_since_restore: 5910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5910000\n",
      "  training_iteration: 591\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14008 s, 591 iter, 5910000 ts, 990 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-03-34\n",
      "  done: false\n",
      "  episode_len_mean: 168.86\n",
      "  episode_reward_max: 1145.3934352721562\n",
      "  episode_reward_mean: 988.8147602711252\n",
      "  episode_reward_min: -81.59158626760703\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 34177\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3869.429\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 5920000\n",
      "    num_steps_trained: 5920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7640517950057983\n",
      "      kl: 0.016875358298420906\n",
      "      policy_loss: -0.002440318465232849\n",
      "      total_loss: 559.3405151367188\n",
      "      vf_explained_var: 0.9761680960655212\n",
      "      vf_loss: 559.3417358398438\n",
      "    sample_time_ms: 19831.858\n",
      "    update_time_ms: 7.779\n",
      "  iterations_since_restore: 592\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.40738013556273\n",
      "  time_since_restore: 14030.686151742935\n",
      "  time_this_iter_s: 22.675496339797974\n",
      "  time_total_s: 14030.686151742935\n",
      "  timestamp: 1553979814\n",
      "  timesteps_since_restore: 5920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5920000\n",
      "  training_iteration: 592\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14030 s, 592 iter, 5920000 ts, 989 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-03-58\n",
      "  done: false\n",
      "  episode_len_mean: 167.75\n",
      "  episode_reward_max: 1145.3934352721562\n",
      "  episode_reward_mean: 964.915736754953\n",
      "  episode_reward_min: -81.59158626760703\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 34239\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3872.86\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 5930000\n",
      "    num_steps_trained: 5930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5722312927246094\n",
      "      kl: 0.018372774124145508\n",
      "      policy_loss: -0.0017928439192473888\n",
      "      total_loss: 727.7180786132812\n",
      "      vf_explained_var: 0.9674870371818542\n",
      "      vf_loss: 727.7185668945312\n",
      "    sample_time_ms: 19787.7\n",
      "    update_time_ms: 6.157\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.45786837747653\n",
      "  time_since_restore: 14053.92389202118\n",
      "  time_this_iter_s: 23.23774027824402\n",
      "  time_total_s: 14053.92389202118\n",
      "  timestamp: 1553979838\n",
      "  timesteps_since_restore: 5930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5930000\n",
      "  training_iteration: 593\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14053 s, 593 iter, 5930000 ts, 965 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 166.94\n",
      "  episode_reward_max: 1173.0447846261816\n",
      "  episode_reward_mean: 986.3339760185015\n",
      "  episode_reward_min: -74.44453722051647\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 34297\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.154\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 5940000\n",
      "    num_steps_trained: 5940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7548006772994995\n",
      "      kl: 0.02145526185631752\n",
      "      policy_loss: -0.0003527738736011088\n",
      "      total_loss: 272.31298828125\n",
      "      vf_explained_var: 0.9875022768974304\n",
      "      vf_loss: 272.31182861328125\n",
      "    sample_time_ms: 19732.507\n",
      "    update_time_ms: 6.131\n",
      "  iterations_since_restore: 594\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.16698800925093\n",
      "  time_since_restore: 14077.635026216507\n",
      "  time_this_iter_s: 23.71113419532776\n",
      "  time_total_s: 14077.635026216507\n",
      "  timestamp: 1553979862\n",
      "  timesteps_since_restore: 5940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5940000\n",
      "  training_iteration: 594\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14077 s, 594 iter, 5940000 ts, 986 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-04-45\n",
      "  done: false\n",
      "  episode_len_mean: 171.64\n",
      "  episode_reward_max: 1151.400888067927\n",
      "  episode_reward_mean: 955.2265467653908\n",
      "  episode_reward_min: -33.560763726279106\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 34356\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.988\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 5950000\n",
      "    num_steps_trained: 5950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8464566469192505\n",
      "      kl: 0.017580343410372734\n",
      "      policy_loss: -0.001369866426102817\n",
      "      total_loss: 829.1039428710938\n",
      "      vf_explained_var: 0.9659873843193054\n",
      "      vf_loss: 829.1041259765625\n",
      "    sample_time_ms: 19661.144\n",
      "    update_time_ms: 6.185\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.61327338269535\n",
      "  time_since_restore: 14100.919986248016\n",
      "  time_this_iter_s: 23.2849600315094\n",
      "  time_total_s: 14100.919986248016\n",
      "  timestamp: 1553979885\n",
      "  timesteps_since_restore: 5950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5950000\n",
      "  training_iteration: 595\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14100 s, 595 iter, 5950000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-05-08\n",
      "  done: false\n",
      "  episode_len_mean: 166.75\n",
      "  episode_reward_max: 1151.400888067927\n",
      "  episode_reward_mean: 946.3934868905261\n",
      "  episode_reward_min: -88.67530214495171\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 34416\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.05\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 5960000\n",
      "    num_steps_trained: 5960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7328509092330933\n",
      "      kl: 0.02148621343076229\n",
      "      policy_loss: -0.0034843110479414463\n",
      "      total_loss: 814.27734375\n",
      "      vf_explained_var: 0.9652885794639587\n",
      "      vf_loss: 814.2793579101562\n",
      "    sample_time_ms: 19606.859\n",
      "    update_time_ms: 6.086\n",
      "  iterations_since_restore: 596\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.196743445263\n",
      "  time_since_restore: 14124.172123670578\n",
      "  time_this_iter_s: 23.252137422561646\n",
      "  time_total_s: 14124.172123670578\n",
      "  timestamp: 1553979908\n",
      "  timesteps_since_restore: 5960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5960000\n",
      "  training_iteration: 596\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14124 s, 596 iter, 5960000 ts, 946 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-05-32\n",
      "  done: false\n",
      "  episode_len_mean: 170.06\n",
      "  episode_reward_max: 1118.4304370384116\n",
      "  episode_reward_mean: 970.8797024045052\n",
      "  episode_reward_min: -23.847321592142862\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 34474\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.387\n",
      "    load_time_ms: 1.7\n",
      "    num_steps_sampled: 5970000\n",
      "    num_steps_trained: 5970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.912510097026825\n",
      "      kl: 0.0174422450363636\n",
      "      policy_loss: -5.4138210543897e-05\n",
      "      total_loss: 882.9763793945312\n",
      "      vf_explained_var: 0.961359977722168\n",
      "      vf_loss: 882.9751586914062\n",
      "    sample_time_ms: 19669.059\n",
      "    update_time_ms: 6.079\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.4398512022526\n",
      "  time_since_restore: 14148.231090068817\n",
      "  time_this_iter_s: 24.058966398239136\n",
      "  time_total_s: 14148.231090068817\n",
      "  timestamp: 1553979932\n",
      "  timesteps_since_restore: 5970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5970000\n",
      "  training_iteration: 597\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14148 s, 597 iter, 5970000 ts, 971 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-05-56\n",
      "  done: false\n",
      "  episode_len_mean: 171.29\n",
      "  episode_reward_max: 1118.4304370384116\n",
      "  episode_reward_mean: 988.1245562846\n",
      "  episode_reward_min: 40.741490747208076\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 34532\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.448\n",
      "    load_time_ms: 1.745\n",
      "    num_steps_sampled: 5980000\n",
      "    num_steps_trained: 5980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6244996786117554\n",
      "      kl: 0.02339913882315159\n",
      "      policy_loss: -0.003423175774514675\n",
      "      total_loss: 730.2225341796875\n",
      "      vf_explained_var: 0.9651520848274231\n",
      "      vf_loss: 730.2241821289062\n",
      "    sample_time_ms: 19672.578\n",
      "    update_time_ms: 5.496\n",
      "  iterations_since_restore: 598\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.06227814229993\n",
      "  time_since_restore: 14172.089596748352\n",
      "  time_this_iter_s: 23.858506679534912\n",
      "  time_total_s: 14172.089596748352\n",
      "  timestamp: 1553979956\n",
      "  timesteps_since_restore: 5980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5980000\n",
      "  training_iteration: 598\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14172 s, 598 iter, 5980000 ts, 988 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-06-20\n",
      "  done: false\n",
      "  episode_len_mean: 173.02\n",
      "  episode_reward_max: 1137.8011784982098\n",
      "  episode_reward_mean: 995.6209922355953\n",
      "  episode_reward_min: 40.741490747208076\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 34589\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.68\n",
      "    load_time_ms: 1.685\n",
      "    num_steps_sampled: 5990000\n",
      "    num_steps_trained: 5990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.886185348033905\n",
      "      kl: 0.018494265154004097\n",
      "      policy_loss: -0.0017036967910826206\n",
      "      total_loss: 371.99139404296875\n",
      "      vf_explained_var: 0.984235405921936\n",
      "      vf_loss: 371.9917907714844\n",
      "    sample_time_ms: 19636.219\n",
      "    update_time_ms: 5.534\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.8104961177976\n",
      "  time_since_restore: 14195.76225399971\n",
      "  time_this_iter_s: 23.672657251358032\n",
      "  time_total_s: 14195.76225399971\n",
      "  timestamp: 1553979980\n",
      "  timesteps_since_restore: 5990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5990000\n",
      "  training_iteration: 599\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14195 s, 599 iter, 5990000 ts, 996 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-06-43\n",
      "  done: false\n",
      "  episode_len_mean: 171.21\n",
      "  episode_reward_max: 1137.8011784982098\n",
      "  episode_reward_mean: 970.4702024419194\n",
      "  episode_reward_min: -58.628106322897764\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 34648\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.163\n",
      "    load_time_ms: 1.643\n",
      "    num_steps_sampled: 6000000\n",
      "    num_steps_trained: 6000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8492396473884583\n",
      "      kl: 0.019660986959934235\n",
      "      policy_loss: -0.0019399983575567603\n",
      "      total_loss: 674.4421997070312\n",
      "      vf_explained_var: 0.9696928262710571\n",
      "      vf_loss: 674.4426879882812\n",
      "    sample_time_ms: 19612.348\n",
      "    update_time_ms: 5.592\n",
      "  iterations_since_restore: 600\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.2351012209598\n",
      "  time_since_restore: 14219.358975887299\n",
      "  time_this_iter_s: 23.5967218875885\n",
      "  time_total_s: 14219.358975887299\n",
      "  timestamp: 1553980003\n",
      "  timesteps_since_restore: 6000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6000000\n",
      "  training_iteration: 600\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14219 s, 600 iter, 6000000 ts, 970 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-07-08\n",
      "  done: false\n",
      "  episode_len_mean: 168.95\n",
      "  episode_reward_max: 1108.5012944528285\n",
      "  episode_reward_mean: 975.4828067652177\n",
      "  episode_reward_min: -44.31597045539479\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 34709\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3916.418\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 6010000\n",
      "    num_steps_trained: 6010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5595671534538269\n",
      "      kl: 0.015564353205263615\n",
      "      policy_loss: -0.0030229012481868267\n",
      "      total_loss: 446.228515625\n",
      "      vf_explained_var: 0.9807823300361633\n",
      "      vf_loss: 446.23046875\n",
      "    sample_time_ms: 19632.614\n",
      "    update_time_ms: 5.524\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.74140338260884\n",
      "  time_since_restore: 14243.759202718735\n",
      "  time_this_iter_s: 24.400226831436157\n",
      "  time_total_s: 14243.759202718735\n",
      "  timestamp: 1553980028\n",
      "  timesteps_since_restore: 6010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6010000\n",
      "  training_iteration: 601\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14243 s, 601 iter, 6010000 ts, 975 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-07-31\n",
      "  done: false\n",
      "  episode_len_mean: 171.07\n",
      "  episode_reward_max: 1103.232423019782\n",
      "  episode_reward_mean: 1009.3523961909132\n",
      "  episode_reward_min: 15.8418574747366\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 34765\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3916.757\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 6020000\n",
      "    num_steps_trained: 6020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6815807819366455\n",
      "      kl: 0.02470044605433941\n",
      "      policy_loss: -0.0031408765353262424\n",
      "      total_loss: 338.160400390625\n",
      "      vf_explained_var: 0.9858067631721497\n",
      "      vf_loss: 338.1617736816406\n",
      "    sample_time_ms: 19691.859\n",
      "    update_time_ms: 5.414\n",
      "  iterations_since_restore: 602\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.6761980954564\n",
      "  time_since_restore: 14267.028715848923\n",
      "  time_this_iter_s: 23.26951313018799\n",
      "  time_total_s: 14267.028715848923\n",
      "  timestamp: 1553980051\n",
      "  timesteps_since_restore: 6020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6020000\n",
      "  training_iteration: 602\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14267 s, 602 iter, 6020000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-07-55\n",
      "  done: false\n",
      "  episode_len_mean: 169.26\n",
      "  episode_reward_max: 1144.305712680502\n",
      "  episode_reward_mean: 997.5928042381743\n",
      "  episode_reward_min: -13.538774196599434\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 34827\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.228\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 6030000\n",
      "    num_steps_trained: 6030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5090605616569519\n",
      "      kl: 0.02222980372607708\n",
      "      policy_loss: -0.0024406409356743097\n",
      "      total_loss: 572.1448364257812\n",
      "      vf_explained_var: 0.9748114347457886\n",
      "      vf_loss: 572.145751953125\n",
      "    sample_time_ms: 19730.184\n",
      "    update_time_ms: 5.558\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.79640211908713\n",
      "  time_since_restore: 14290.65754532814\n",
      "  time_this_iter_s: 23.62882947921753\n",
      "  time_total_s: 14290.65754532814\n",
      "  timestamp: 1553980075\n",
      "  timesteps_since_restore: 6030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6030000\n",
      "  training_iteration: 603\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14290 s, 603 iter, 6030000 ts, 998 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-08-19\n",
      "  done: false\n",
      "  episode_len_mean: 168.3\n",
      "  episode_reward_max: 1144.305712680502\n",
      "  episode_reward_mean: 970.0225218781623\n",
      "  episode_reward_min: -29.968695685141284\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 34885\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.708\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 6040000\n",
      "    num_steps_trained: 6040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7591120600700378\n",
      "      kl: 0.02286524884402752\n",
      "      policy_loss: -0.0017914535710588098\n",
      "      total_loss: 399.4714660644531\n",
      "      vf_explained_var: 0.9837732315063477\n",
      "      vf_loss: 399.47161865234375\n",
      "    sample_time_ms: 19785.087\n",
      "    update_time_ms: 5.591\n",
      "  iterations_since_restore: 604\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.0112609390811\n",
      "  time_since_restore: 14314.896476984024\n",
      "  time_this_iter_s: 24.23893165588379\n",
      "  time_total_s: 14314.896476984024\n",
      "  timestamp: 1553980099\n",
      "  timesteps_since_restore: 6040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6040000\n",
      "  training_iteration: 604\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14314 s, 604 iter, 6040000 ts, 970 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-08-43\n",
      "  done: false\n",
      "  episode_len_mean: 172.17\n",
      "  episode_reward_max: 1145.7541071866265\n",
      "  episode_reward_mean: 968.6924834982849\n",
      "  episode_reward_min: -36.30192528293077\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 34943\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.917\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 6050000\n",
      "    num_steps_trained: 6050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7050668597221375\n",
      "      kl: 0.01881120726466179\n",
      "      policy_loss: 0.0010182175319641829\n",
      "      total_loss: 569.6756591796875\n",
      "      vf_explained_var: 0.9765225052833557\n",
      "      vf_loss: 569.6734008789062\n",
      "    sample_time_ms: 19857.003\n",
      "    update_time_ms: 5.538\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.34624174914234\n",
      "  time_since_restore: 14338.90483546257\n",
      "  time_this_iter_s: 24.008358478546143\n",
      "  time_total_s: 14338.90483546257\n",
      "  timestamp: 1553980123\n",
      "  timesteps_since_restore: 6050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6050000\n",
      "  training_iteration: 605\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14338 s, 605 iter, 6050000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-09-08\n",
      "  done: false\n",
      "  episode_len_mean: 177.38\n",
      "  episode_reward_max: 1143.4135310893348\n",
      "  episode_reward_mean: 964.2506932187165\n",
      "  episode_reward_min: -44.33114324052062\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 34999\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.973\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 6060000\n",
      "    num_steps_trained: 6060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.960002601146698\n",
      "      kl: 0.02228686213493347\n",
      "      policy_loss: 6.95721828378737e-05\n",
      "      total_loss: 677.8327026367188\n",
      "      vf_explained_var: 0.9700571894645691\n",
      "      vf_loss: 677.8310546875\n",
      "    sample_time_ms: 19995.833\n",
      "    update_time_ms: 5.585\n",
      "  iterations_since_restore: 606\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.12534660935825\n",
      "  time_since_restore: 14363.59146976471\n",
      "  time_this_iter_s: 24.686634302139282\n",
      "  time_total_s: 14363.59146976471\n",
      "  timestamp: 1553980148\n",
      "  timesteps_since_restore: 6060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6060000\n",
      "  training_iteration: 606\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14363 s, 606 iter, 6060000 ts, 964 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-09-32\n",
      "  done: false\n",
      "  episode_len_mean: 181.57\n",
      "  episode_reward_max: 1143.4135310893348\n",
      "  episode_reward_mean: 945.2865120641497\n",
      "  episode_reward_min: -71.76344305344199\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 35054\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.502\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 6070000\n",
      "    num_steps_trained: 6070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.094704508781433\n",
      "      kl: 0.01588454842567444\n",
      "      policy_loss: -0.0019393006805330515\n",
      "      total_loss: 800.5379638671875\n",
      "      vf_explained_var: 0.9650233387947083\n",
      "      vf_loss: 800.5386962890625\n",
      "    sample_time_ms: 19946.155\n",
      "    update_time_ms: 5.593\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.64325603207493\n",
      "  time_since_restore: 14387.097242593765\n",
      "  time_this_iter_s: 23.505772829055786\n",
      "  time_total_s: 14387.097242593765\n",
      "  timestamp: 1553980172\n",
      "  timesteps_since_restore: 6070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6070000\n",
      "  training_iteration: 607\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14387 s, 607 iter, 6070000 ts, 945 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-09-55\n",
      "  done: false\n",
      "  episode_len_mean: 172.86\n",
      "  episode_reward_max: 1111.7466275362433\n",
      "  episode_reward_mean: 927.1864480938789\n",
      "  episode_reward_min: -83.60833933831726\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 35115\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.134\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 6080000\n",
      "    num_steps_trained: 6080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6557989120483398\n",
      "      kl: 0.025548746809363365\n",
      "      policy_loss: -0.0033670924603939056\n",
      "      total_loss: 855.2861328125\n",
      "      vf_explained_var: 0.965587317943573\n",
      "      vf_loss: 855.2876586914062\n",
      "    sample_time_ms: 19858.168\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 608\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 463.59322404693944\n",
      "  time_since_restore: 14410.116958856583\n",
      "  time_this_iter_s: 23.019716262817383\n",
      "  time_total_s: 14410.116958856583\n",
      "  timestamp: 1553980195\n",
      "  timesteps_since_restore: 6080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6080000\n",
      "  training_iteration: 608\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14410 s, 608 iter, 6080000 ts, 927 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-10-18\n",
      "  done: false\n",
      "  episode_len_mean: 164.02\n",
      "  episode_reward_max: 1128.6821999343674\n",
      "  episode_reward_mean: 956.6556218523626\n",
      "  episode_reward_min: -83.60833933831726\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 35176\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.345\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 6090000\n",
      "    num_steps_trained: 6090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4865398406982422\n",
      "      kl: 0.02294127456843853\n",
      "      policy_loss: -0.006107859779149294\n",
      "      total_loss: 439.43115234375\n",
      "      vf_explained_var: 0.9803410172462463\n",
      "      vf_loss: 439.4356384277344\n",
      "    sample_time_ms: 19853.449\n",
      "    update_time_ms: 5.624\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.3278109261813\n",
      "  time_since_restore: 14433.698040246964\n",
      "  time_this_iter_s: 23.58108139038086\n",
      "  time_total_s: 14433.698040246964\n",
      "  timestamp: 1553980218\n",
      "  timesteps_since_restore: 6090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6090000\n",
      "  training_iteration: 609\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14433 s, 609 iter, 6090000 ts, 957 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 166.95\n",
      "  episode_reward_max: 1128.6821999343674\n",
      "  episode_reward_mean: 999.0010438566943\n",
      "  episode_reward_min: -43.18608437603396\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 35235\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.362\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 6100000\n",
      "    num_steps_trained: 6100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.47858282923698425\n",
      "      kl: 0.02170826494693756\n",
      "      policy_loss: -0.007318682502955198\n",
      "      total_loss: 692.8301391601562\n",
      "      vf_explained_var: 0.9685714840888977\n",
      "      vf_loss: 692.8359375\n",
      "    sample_time_ms: 19918.351\n",
      "    update_time_ms: 5.575\n",
      "  iterations_since_restore: 610\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 499.50052192834715\n",
      "  time_since_restore: 14457.95205616951\n",
      "  time_this_iter_s: 24.254015922546387\n",
      "  time_total_s: 14457.95205616951\n",
      "  timestamp: 1553980242\n",
      "  timesteps_since_restore: 6100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6100000\n",
      "  training_iteration: 610\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14457 s, 610 iter, 6100000 ts, 999 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 172.33\n",
      "  episode_reward_max: 1126.257144418672\n",
      "  episode_reward_mean: 996.0677951149037\n",
      "  episode_reward_min: -11.765068461748854\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 35293\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.05\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 6110000\n",
      "    num_steps_trained: 6110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.475970059633255\n",
      "      kl: 0.0295211561024189\n",
      "      policy_loss: 0.0012138593010604382\n",
      "      total_loss: 131.29808044433594\n",
      "      vf_explained_var: 0.9945684671401978\n",
      "      vf_loss: 131.2947540283203\n",
      "    sample_time_ms: 19938.721\n",
      "    update_time_ms: 5.652\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.03389755745184\n",
      "  time_since_restore: 14482.50015592575\n",
      "  time_this_iter_s: 24.548099756240845\n",
      "  time_total_s: 14482.50015592575\n",
      "  timestamp: 1553980267\n",
      "  timesteps_since_restore: 6110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6110000\n",
      "  training_iteration: 611\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14482 s, 611 iter, 6110000 ts, 996 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-11-32\n",
      "  done: false\n",
      "  episode_len_mean: 168.56\n",
      "  episode_reward_max: 1126.257144418672\n",
      "  episode_reward_mean: 971.11874599147\n",
      "  episode_reward_min: -64.36828229914806\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 35355\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.574\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 6120000\n",
      "    num_steps_trained: 6120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5080563426017761\n",
      "      kl: 0.019275521859526634\n",
      "      policy_loss: 0.00038930794107727706\n",
      "      total_loss: 459.53265380859375\n",
      "      vf_explained_var: 0.9807359576225281\n",
      "      vf_loss: 459.5308532714844\n",
      "    sample_time_ms: 20089.225\n",
      "    update_time_ms: 6.312\n",
      "  iterations_since_restore: 612\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.55937299573486\n",
      "  time_since_restore: 14507.267140626907\n",
      "  time_this_iter_s: 24.766984701156616\n",
      "  time_total_s: 14507.267140626907\n",
      "  timestamp: 1553980292\n",
      "  timesteps_since_restore: 6120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6120000\n",
      "  training_iteration: 612\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14507 s, 612 iter, 6120000 ts, 971 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-11-56\n",
      "  done: false\n",
      "  episode_len_mean: 166.53\n",
      "  episode_reward_max: 1111.479044464146\n",
      "  episode_reward_mean: 920.4402753287676\n",
      "  episode_reward_min: -81.13319459285175\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 35414\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.929\n",
      "    load_time_ms: 1.61\n",
      "    num_steps_sampled: 6130000\n",
      "    num_steps_trained: 6130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8138805627822876\n",
      "      kl: 0.017522327601909637\n",
      "      policy_loss: -0.0017778774490579963\n",
      "      total_loss: 1107.1458740234375\n",
      "      vf_explained_var: 0.9531725645065308\n",
      "      vf_loss: 1107.146240234375\n",
      "    sample_time_ms: 20141.213\n",
      "    update_time_ms: 5.744\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 460.22013766438397\n",
      "  time_since_restore: 14531.473394155502\n",
      "  time_this_iter_s: 24.20625352859497\n",
      "  time_total_s: 14531.473394155502\n",
      "  timestamp: 1553980316\n",
      "  timesteps_since_restore: 6130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6130000\n",
      "  training_iteration: 613\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14531 s, 613 iter, 6130000 ts, 920 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-12-20\n",
      "  done: false\n",
      "  episode_len_mean: 161.86\n",
      "  episode_reward_max: 1130.5969214235379\n",
      "  episode_reward_mean: 914.0264687535183\n",
      "  episode_reward_min: -81.13319459285175\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 35477\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.028\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 6140000\n",
      "    num_steps_trained: 6140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4214515686035156\n",
      "      kl: 0.02186853438615799\n",
      "      policy_loss: -0.0018516015261411667\n",
      "      total_loss: 1363.092529296875\n",
      "      vf_explained_var: 0.9434718489646912\n",
      "      vf_loss: 1363.0928955078125\n",
      "    sample_time_ms: 20115.213\n",
      "    update_time_ms: 5.788\n",
      "  iterations_since_restore: 614\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 457.0132343767592\n",
      "  time_since_restore: 14555.46095252037\n",
      "  time_this_iter_s: 23.987558364868164\n",
      "  time_total_s: 14555.46095252037\n",
      "  timestamp: 1553980340\n",
      "  timesteps_since_restore: 6140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6140000\n",
      "  training_iteration: 614\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14555 s, 614 iter, 6140000 ts, 914 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-12-44\n",
      "  done: false\n",
      "  episode_len_mean: 160.13\n",
      "  episode_reward_max: 1139.3053475394065\n",
      "  episode_reward_mean: 941.2012774744476\n",
      "  episode_reward_min: -84.29079223369679\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 35538\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.023\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 6150000\n",
      "    num_steps_trained: 6150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.39391884207725525\n",
      "      kl: 0.021876612678170204\n",
      "      policy_loss: -0.0009433199884369969\n",
      "      total_loss: 648.6984252929688\n",
      "      vf_explained_var: 0.9720925688743591\n",
      "      vf_loss: 648.69775390625\n",
      "    sample_time_ms: 20102.083\n",
      "    update_time_ms: 5.765\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.6006387372238\n",
      "  time_since_restore: 14579.366787672043\n",
      "  time_this_iter_s: 23.905835151672363\n",
      "  time_total_s: 14579.366787672043\n",
      "  timestamp: 1553980364\n",
      "  timesteps_since_restore: 6150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6150000\n",
      "  training_iteration: 615\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14579 s, 615 iter, 6150000 ts, 941 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-13-08\n",
      "  done: false\n",
      "  episode_len_mean: 169.35\n",
      "  episode_reward_max: 1139.3053475394065\n",
      "  episode_reward_mean: 967.6908120978994\n",
      "  episode_reward_min: -84.29079223369679\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 35595\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.307\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 6160000\n",
      "    num_steps_trained: 6160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6995112895965576\n",
      "      kl: 0.020542645826935768\n",
      "      policy_loss: -0.0009857771219685674\n",
      "      total_loss: 651.708251953125\n",
      "      vf_explained_var: 0.9739114046096802\n",
      "      vf_loss: 651.707763671875\n",
      "    sample_time_ms: 19983.04\n",
      "    update_time_ms: 5.743\n",
      "  iterations_since_restore: 616\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.8454060489497\n",
      "  time_since_restore: 14602.806295394897\n",
      "  time_this_iter_s: 23.439507722854614\n",
      "  time_total_s: 14602.806295394897\n",
      "  timestamp: 1553980388\n",
      "  timesteps_since_restore: 6160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6160000\n",
      "  training_iteration: 616\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14602 s, 616 iter, 6160000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-13-31\n",
      "  done: false\n",
      "  episode_len_mean: 170.24\n",
      "  episode_reward_max: 1127.3179260489137\n",
      "  episode_reward_mean: 979.0134910672139\n",
      "  episode_reward_min: -14.5485334842503\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 35655\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.031\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 6170000\n",
      "    num_steps_trained: 6170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5883731245994568\n",
      "      kl: 0.018664048984646797\n",
      "      policy_loss: -0.0014038800727576017\n",
      "      total_loss: 368.6997985839844\n",
      "      vf_explained_var: 0.9836279153823853\n",
      "      vf_loss: 368.6998596191406\n",
      "    sample_time_ms: 19963.639\n",
      "    update_time_ms: 5.718\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.50674553360705\n",
      "  time_since_restore: 14626.122507333755\n",
      "  time_this_iter_s: 23.316211938858032\n",
      "  time_total_s: 14626.122507333755\n",
      "  timestamp: 1553980411\n",
      "  timesteps_since_restore: 6170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6170000\n",
      "  training_iteration: 617\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14626 s, 617 iter, 6170000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-13-55\n",
      "  done: false\n",
      "  episode_len_mean: 174.05\n",
      "  episode_reward_max: 1150.256991423941\n",
      "  episode_reward_mean: 943.4325224639152\n",
      "  episode_reward_min: -65.11865043388639\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 35711\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.33\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 6180000\n",
      "    num_steps_trained: 6180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.162542700767517\n",
      "      kl: 0.01924046128988266\n",
      "      policy_loss: -0.0023240314330905676\n",
      "      total_loss: 933.0947265625\n",
      "      vf_explained_var: 0.9602971076965332\n",
      "      vf_loss: 933.0955810546875\n",
      "    sample_time_ms: 20022.138\n",
      "    update_time_ms: 5.562\n",
      "  iterations_since_restore: 618\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.7162612319577\n",
      "  time_since_restore: 14649.72177195549\n",
      "  time_this_iter_s: 23.59926462173462\n",
      "  time_total_s: 14649.72177195549\n",
      "  timestamp: 1553980435\n",
      "  timesteps_since_restore: 6180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6180000\n",
      "  training_iteration: 618\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14649 s, 618 iter, 6180000 ts, 943 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-14-19\n",
      "  done: false\n",
      "  episode_len_mean: 170.57\n",
      "  episode_reward_max: 1150.256991423941\n",
      "  episode_reward_mean: 960.6743784625992\n",
      "  episode_reward_min: -65.11865043388639\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 35768\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3920.394\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 6190000\n",
      "    num_steps_trained: 6190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.514752209186554\n",
      "      kl: 0.029265131801366806\n",
      "      policy_loss: -0.0010557585628703237\n",
      "      total_loss: 330.94085693359375\n",
      "      vf_explained_var: 0.984815239906311\n",
      "      vf_loss: 330.9397888183594\n",
      "    sample_time_ms: 20091.459\n",
      "    update_time_ms: 5.566\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.3371892312996\n",
      "  time_since_restore: 14674.073048591614\n",
      "  time_this_iter_s: 24.351276636123657\n",
      "  time_total_s: 14674.073048591614\n",
      "  timestamp: 1553980459\n",
      "  timesteps_since_restore: 6190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6190000\n",
      "  training_iteration: 619\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14674 s, 619 iter, 6190000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-14-43\n",
      "  done: false\n",
      "  episode_len_mean: 174.97\n",
      "  episode_reward_max: 1116.1035870120038\n",
      "  episode_reward_mean: 988.2917814022622\n",
      "  episode_reward_min: -82.42339926086663\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 35826\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3922.518\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 6200000\n",
      "    num_steps_trained: 6200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7497918605804443\n",
      "      kl: 0.01902547851204872\n",
      "      policy_loss: -0.002148591447621584\n",
      "      total_loss: 447.0514831542969\n",
      "      vf_explained_var: 0.9805503487586975\n",
      "      vf_loss: 447.0522766113281\n",
      "    sample_time_ms: 20078.453\n",
      "    update_time_ms: 6.13\n",
      "  iterations_since_restore: 620\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.1458907011311\n",
      "  time_since_restore: 14698.22346496582\n",
      "  time_this_iter_s: 24.150416374206543\n",
      "  time_total_s: 14698.22346496582\n",
      "  timestamp: 1553980483\n",
      "  timesteps_since_restore: 6200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6200000\n",
      "  training_iteration: 620\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14698 s, 620 iter, 6200000 ts, 988 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-15-07\n",
      "  done: false\n",
      "  episode_len_mean: 168.52\n",
      "  episode_reward_max: 1119.2826978029411\n",
      "  episode_reward_mean: 997.8540692703771\n",
      "  episode_reward_min: -82.42339926086663\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 35886\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.662\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 6210000\n",
      "    num_steps_trained: 6210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5520110726356506\n",
      "      kl: 0.021233299747109413\n",
      "      policy_loss: 4.527192504610866e-05\n",
      "      total_loss: 506.7784423828125\n",
      "      vf_explained_var: 0.9767616391181946\n",
      "      vf_loss: 506.77685546875\n",
      "    sample_time_ms: 19965.417\n",
      "    update_time_ms: 6.126\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.9270346351885\n",
      "  time_since_restore: 14721.560128688812\n",
      "  time_this_iter_s: 23.336663722991943\n",
      "  time_total_s: 14721.560128688812\n",
      "  timestamp: 1553980507\n",
      "  timesteps_since_restore: 6210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6210000\n",
      "  training_iteration: 621\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14721 s, 621 iter, 6210000 ts, 998 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 168.81\n",
      "  episode_reward_max: 1118.365689473805\n",
      "  episode_reward_mean: 997.1122088169647\n",
      "  episode_reward_min: -49.65019062247086\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 35944\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.634\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 6220000\n",
      "    num_steps_trained: 6220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5379127860069275\n",
      "      kl: 0.01817254163324833\n",
      "      policy_loss: -0.00037585897371172905\n",
      "      total_loss: 471.7701416015625\n",
      "      vf_explained_var: 0.9778880476951599\n",
      "      vf_loss: 471.76922607421875\n",
      "    sample_time_ms: 19897.151\n",
      "    update_time_ms: 5.573\n",
      "  iterations_since_restore: 622\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.55610440848244\n",
      "  time_since_restore: 14745.639698266983\n",
      "  time_this_iter_s: 24.079569578170776\n",
      "  time_total_s: 14745.639698266983\n",
      "  timestamp: 1553980531\n",
      "  timesteps_since_restore: 6220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6220000\n",
      "  training_iteration: 622\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14745 s, 622 iter, 6220000 ts, 997 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-15-55\n",
      "  done: false\n",
      "  episode_len_mean: 169.47\n",
      "  episode_reward_max: 1121.9282071438042\n",
      "  episode_reward_mean: 953.5930721724699\n",
      "  episode_reward_min: -49.65019062247086\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 36004\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.324\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 6230000\n",
      "    num_steps_trained: 6230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.751781702041626\n",
      "      kl: 0.018893934786319733\n",
      "      policy_loss: -0.0009643590310588479\n",
      "      total_loss: 1044.814697265625\n",
      "      vf_explained_var: 0.9588670134544373\n",
      "      vf_loss: 1044.8143310546875\n",
      "    sample_time_ms: 19865.684\n",
      "    update_time_ms: 5.646\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.796536086235\n",
      "  time_since_restore: 14769.481781721115\n",
      "  time_this_iter_s: 23.84208345413208\n",
      "  time_total_s: 14769.481781721115\n",
      "  timestamp: 1553980555\n",
      "  timesteps_since_restore: 6230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6230000\n",
      "  training_iteration: 623\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14769 s, 623 iter, 6230000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-16-19\n",
      "  done: false\n",
      "  episode_len_mean: 164.63\n",
      "  episode_reward_max: 1157.7014952715008\n",
      "  episode_reward_mean: 958.0569823742778\n",
      "  episode_reward_min: -24.048624644249713\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 36063\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.795\n",
      "    load_time_ms: 1.562\n",
      "    num_steps_sampled: 6240000\n",
      "    num_steps_trained: 6240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07148934155702591\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4611596465110779\n",
      "      kl: 0.043409138917922974\n",
      "      policy_loss: -0.0033622432965785265\n",
      "      total_loss: 551.61181640625\n",
      "      vf_explained_var: 0.9764256477355957\n",
      "      vf_loss: 551.6121215820312\n",
      "    sample_time_ms: 19921.347\n",
      "    update_time_ms: 5.493\n",
      "  iterations_since_restore: 624\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.02849118713885\n",
      "  time_since_restore: 14794.027163028717\n",
      "  time_this_iter_s: 24.54538130760193\n",
      "  time_total_s: 14794.027163028717\n",
      "  timestamp: 1553980579\n",
      "  timesteps_since_restore: 6240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6240000\n",
      "  training_iteration: 624\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14794 s, 624 iter, 6240000 ts, 958 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-16-43\n",
      "  done: false\n",
      "  episode_len_mean: 164.54\n",
      "  episode_reward_max: 1157.7014952715008\n",
      "  episode_reward_mean: 969.6480061939666\n",
      "  episode_reward_min: -66.4008619592062\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 36125\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.072\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 6250000\n",
      "    num_steps_trained: 6250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.37168455123901367\n",
      "      kl: 0.0175455454736948\n",
      "      policy_loss: -0.0006760479300282896\n",
      "      total_loss: 769.874755859375\n",
      "      vf_explained_var: 0.9685477018356323\n",
      "      vf_loss: 769.87353515625\n",
      "    sample_time_ms: 19943.496\n",
      "    update_time_ms: 5.515\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.82400309698323\n",
      "  time_since_restore: 14818.166717767715\n",
      "  time_this_iter_s: 24.139554738998413\n",
      "  time_total_s: 14818.166717767715\n",
      "  timestamp: 1553980603\n",
      "  timesteps_since_restore: 6250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6250000\n",
      "  training_iteration: 625\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14818 s, 625 iter, 6250000 ts, 970 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-17-07\n",
      "  done: false\n",
      "  episode_len_mean: 160.57\n",
      "  episode_reward_max: 1126.4653502420524\n",
      "  episode_reward_mean: 934.3718216698429\n",
      "  episode_reward_min: -85.03137789787715\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 36188\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.777\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 6260000\n",
      "    num_steps_trained: 6260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5373359322547913\n",
      "      kl: 0.01907849684357643\n",
      "      policy_loss: -0.0007181710097938776\n",
      "      total_loss: 1106.6943359375\n",
      "      vf_explained_var: 0.9579698443412781\n",
      "      vf_loss: 1106.693115234375\n",
      "    sample_time_ms: 19996.356\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 626\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.1859108349214\n",
      "  time_since_restore: 14842.170291423798\n",
      "  time_this_iter_s: 24.003573656082153\n",
      "  time_total_s: 14842.170291423798\n",
      "  timestamp: 1553980627\n",
      "  timesteps_since_restore: 6260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6260000\n",
      "  training_iteration: 626\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14842 s, 626 iter, 6260000 ts, 934 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-17-31\n",
      "  done: false\n",
      "  episode_len_mean: 164.92\n",
      "  episode_reward_max: 1126.4653502420524\n",
      "  episode_reward_mean: 954.6377759153617\n",
      "  episode_reward_min: -85.03137789787715\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 36248\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.612\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 6270000\n",
      "    num_steps_trained: 6270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4154627025127411\n",
      "      kl: 0.021416492760181427\n",
      "      policy_loss: -0.0002167287893826142\n",
      "      total_loss: 407.5095520019531\n",
      "      vf_explained_var: 0.9832898378372192\n",
      "      vf_loss: 407.50750732421875\n",
      "    sample_time_ms: 20058.39\n",
      "    update_time_ms: 5.475\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.31888795768083\n",
      "  time_since_restore: 14866.146540641785\n",
      "  time_this_iter_s: 23.97624921798706\n",
      "  time_total_s: 14866.146540641785\n",
      "  timestamp: 1553980651\n",
      "  timesteps_since_restore: 6270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6270000\n",
      "  training_iteration: 627\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14866 s, 627 iter, 6270000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-17-55\n",
      "  done: false\n",
      "  episode_len_mean: 172.85\n",
      "  episode_reward_max: 1114.6137634612605\n",
      "  episode_reward_mean: 986.1072723555772\n",
      "  episode_reward_min: -31.6949043800916\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 36304\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3916.109\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 6280000\n",
      "    num_steps_trained: 6280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8979265093803406\n",
      "      kl: 0.01703738234937191\n",
      "      policy_loss: -0.0004958896315656602\n",
      "      total_loss: 707.506591796875\n",
      "      vf_explained_var: 0.9710188508033752\n",
      "      vf_loss: 707.5053100585938\n",
      "    sample_time_ms: 20089.293\n",
      "    update_time_ms: 5.458\n",
      "  iterations_since_restore: 628\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.0536361777885\n",
      "  time_since_restore: 14890.029819965363\n",
      "  time_this_iter_s: 23.88327932357788\n",
      "  time_total_s: 14890.029819965363\n",
      "  timestamp: 1553980675\n",
      "  timesteps_since_restore: 6280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6280000\n",
      "  training_iteration: 628\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14890 s, 628 iter, 6280000 ts, 986 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-18-19\n",
      "  done: false\n",
      "  episode_len_mean: 176.54\n",
      "  episode_reward_max: 1113.4955373884613\n",
      "  episode_reward_mean: 971.4566684087348\n",
      "  episode_reward_min: -31.6949043800916\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 36362\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.064\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 6290000\n",
      "    num_steps_trained: 6290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6712208390235901\n",
      "      kl: 0.02326950989663601\n",
      "      policy_loss: -0.0024798435624688864\n",
      "      total_loss: 224.94956970214844\n",
      "      vf_explained_var: 0.9906706213951111\n",
      "      vf_loss: 224.9495391845703\n",
      "    sample_time_ms: 20059.833\n",
      "    update_time_ms: 5.202\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.7283342043675\n",
      "  time_since_restore: 14914.056746959686\n",
      "  time_this_iter_s: 24.02692699432373\n",
      "  time_total_s: 14914.056746959686\n",
      "  timestamp: 1553980699\n",
      "  timesteps_since_restore: 6290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6290000\n",
      "  training_iteration: 629\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14914 s, 629 iter, 6290000 ts, 971 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-18-44\n",
      "  done: false\n",
      "  episode_len_mean: 170.64\n",
      "  episode_reward_max: 1111.149047341202\n",
      "  episode_reward_mean: 981.5703402184553\n",
      "  episode_reward_min: 18.99174374123251\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 36422\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.003\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 6300000\n",
      "    num_steps_trained: 6300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5183269381523132\n",
      "      kl: 0.018530188128352165\n",
      "      policy_loss: -0.0006052206153981388\n",
      "      total_loss: 507.9142761230469\n",
      "      vf_explained_var: 0.9786108732223511\n",
      "      vf_loss: 507.9128723144531\n",
      "    sample_time_ms: 20067.03\n",
      "    update_time_ms: 4.613\n",
      "  iterations_since_restore: 630\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.78517010922764\n",
      "  time_since_restore: 14938.247520923615\n",
      "  time_this_iter_s: 24.190773963928223\n",
      "  time_total_s: 14938.247520923615\n",
      "  timestamp: 1553980724\n",
      "  timesteps_since_restore: 6300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6300000\n",
      "  training_iteration: 630\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14938 s, 630 iter, 6300000 ts, 982 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-19-08\n",
      "  done: false\n",
      "  episode_len_mean: 167.53\n",
      "  episode_reward_max: 1111.9649341370912\n",
      "  episode_reward_mean: 980.3008448233736\n",
      "  episode_reward_min: -111.7387022920669\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 36482\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.691\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 6310000\n",
      "    num_steps_trained: 6310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5011973977088928\n",
      "      kl: 0.023637833073735237\n",
      "      policy_loss: -0.007276608608663082\n",
      "      total_loss: 672.4019165039062\n",
      "      vf_explained_var: 0.9710137844085693\n",
      "      vf_loss: 672.4066772460938\n",
      "    sample_time_ms: 20134.814\n",
      "    update_time_ms: 4.579\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.15042241168675\n",
      "  time_since_restore: 14962.374806642532\n",
      "  time_this_iter_s: 24.127285718917847\n",
      "  time_total_s: 14962.374806642532\n",
      "  timestamp: 1553980748\n",
      "  timesteps_since_restore: 6310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6310000\n",
      "  training_iteration: 631\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14962 s, 631 iter, 6310000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-19-32\n",
      "  done: false\n",
      "  episode_len_mean: 166.52\n",
      "  episode_reward_max: 1145.548416728813\n",
      "  episode_reward_mean: 969.9554271395808\n",
      "  episode_reward_min: -111.7387022920669\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 36541\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3927.422\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 6320000\n",
      "    num_steps_trained: 6320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5753862261772156\n",
      "      kl: 0.017098916694521904\n",
      "      policy_loss: -0.0018790587782859802\n",
      "      total_loss: 944.2828369140625\n",
      "      vf_explained_var: 0.9594810605049133\n",
      "      vf_loss: 944.282958984375\n",
      "    sample_time_ms: 20100.811\n",
      "    update_time_ms: 4.582\n",
      "  iterations_since_restore: 632\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.97771356979035\n",
      "  time_since_restore: 14986.172827720642\n",
      "  time_this_iter_s: 23.79802107810974\n",
      "  time_total_s: 14986.172827720642\n",
      "  timestamp: 1553980772\n",
      "  timesteps_since_restore: 6320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6320000\n",
      "  training_iteration: 632\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 14986 s, 632 iter, 6320000 ts, 970 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-19-56\n",
      "  done: false\n",
      "  episode_len_mean: 169.95\n",
      "  episode_reward_max: 1145.548416728813\n",
      "  episode_reward_mean: 949.6790518869243\n",
      "  episode_reward_min: -28.08169376557578\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 36601\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.844\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 6330000\n",
      "    num_steps_trained: 6330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6049908399581909\n",
      "      kl: 0.01813165470957756\n",
      "      policy_loss: -0.000411611283197999\n",
      "      total_loss: 356.06158447265625\n",
      "      vf_explained_var: 0.9843429923057556\n",
      "      vf_loss: 356.06005859375\n",
      "    sample_time_ms: 20159.703\n",
      "    update_time_ms: 4.995\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.8395259434621\n",
      "  time_since_restore: 15010.57923078537\n",
      "  time_this_iter_s: 24.406403064727783\n",
      "  time_total_s: 15010.57923078537\n",
      "  timestamp: 1553980796\n",
      "  timesteps_since_restore: 6330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6330000\n",
      "  training_iteration: 633\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15010 s, 633 iter, 6330000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-20-20\n",
      "  done: false\n",
      "  episode_len_mean: 173.02\n",
      "  episode_reward_max: 1116.3440650617413\n",
      "  episode_reward_mean: 960.8173959443754\n",
      "  episode_reward_min: -70.84619474233222\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 36657\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3923.878\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 6340000\n",
      "    num_steps_trained: 6340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8851060271263123\n",
      "      kl: 0.016164103522896767\n",
      "      policy_loss: -0.002331554889678955\n",
      "      total_loss: 694.726318359375\n",
      "      vf_explained_var: 0.9705176949501038\n",
      "      vf_loss: 694.7269897460938\n",
      "    sample_time_ms: 20061.11\n",
      "    update_time_ms: 5.15\n",
      "  iterations_since_restore: 634\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.40869797218767\n",
      "  time_since_restore: 15034.13181424141\n",
      "  time_this_iter_s: 23.55258345603943\n",
      "  time_total_s: 15034.13181424141\n",
      "  timestamp: 1553980820\n",
      "  timesteps_since_restore: 6340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6340000\n",
      "  training_iteration: 634\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15034 s, 634 iter, 6340000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-20-44\n",
      "  done: false\n",
      "  episode_len_mean: 167.82\n",
      "  episode_reward_max: 1116.3440650617413\n",
      "  episode_reward_mean: 957.2210008325069\n",
      "  episode_reward_min: -70.84619474233222\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 36718\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3923.265\n",
      "    load_time_ms: 1.633\n",
      "    num_steps_sampled: 6350000\n",
      "    num_steps_trained: 6350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.508366584777832\n",
      "      kl: 0.01945655234158039\n",
      "      policy_loss: -0.001419711159542203\n",
      "      total_loss: 627.0447387695312\n",
      "      vf_explained_var: 0.9741445779800415\n",
      "      vf_loss: 627.0440673828125\n",
      "    sample_time_ms: 20068.079\n",
      "    update_time_ms: 5.095\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.61050041625333\n",
      "  time_since_restore: 15058.336102485657\n",
      "  time_this_iter_s: 24.204288244247437\n",
      "  time_total_s: 15058.336102485657\n",
      "  timestamp: 1553980844\n",
      "  timesteps_since_restore: 6350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6350000\n",
      "  training_iteration: 635\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15058 s, 635 iter, 6350000 ts, 957 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-21-08\n",
      "  done: false\n",
      "  episode_len_mean: 165.89\n",
      "  episode_reward_max: 1098.8058731802985\n",
      "  episode_reward_mean: 997.8943536597268\n",
      "  episode_reward_min: -47.85098297913302\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 36778\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.241\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 6360000\n",
      "    num_steps_trained: 6360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4322594404220581\n",
      "      kl: 0.023355644196271896\n",
      "      policy_loss: -0.0021242243237793446\n",
      "      total_loss: 161.24063110351562\n",
      "      vf_explained_var: 0.993144690990448\n",
      "      vf_loss: 161.240234375\n",
      "    sample_time_ms: 20076.588\n",
      "    update_time_ms: 5.116\n",
      "  iterations_since_restore: 636\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.94717682986345\n",
      "  time_since_restore: 15082.407262802124\n",
      "  time_this_iter_s: 24.071160316467285\n",
      "  time_total_s: 15082.407262802124\n",
      "  timestamp: 1553980868\n",
      "  timesteps_since_restore: 6360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6360000\n",
      "  training_iteration: 636\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15082 s, 636 iter, 6360000 ts, 998 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-21-32\n",
      "  done: false\n",
      "  episode_len_mean: 165.78\n",
      "  episode_reward_max: 1122.1804872137222\n",
      "  episode_reward_mean: 989.1364531472293\n",
      "  episode_reward_min: -64.79075372818971\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 36839\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3922.466\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 6370000\n",
      "    num_steps_trained: 6370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3985457718372345\n",
      "      kl: 0.016277149319648743\n",
      "      policy_loss: 0.0001746925263432786\n",
      "      total_loss: 242.0996551513672\n",
      "      vf_explained_var: 0.9901004433631897\n",
      "      vf_loss: 242.0977020263672\n",
      "    sample_time_ms: 20046.781\n",
      "    update_time_ms: 5.147\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.56822657361465\n",
      "  time_since_restore: 15106.094517469406\n",
      "  time_this_iter_s: 23.687254667282104\n",
      "  time_total_s: 15106.094517469406\n",
      "  timestamp: 1553980892\n",
      "  timesteps_since_restore: 6370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6370000\n",
      "  training_iteration: 637\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15106 s, 637 iter, 6370000 ts, 989 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-21-55\n",
      "  done: false\n",
      "  episode_len_mean: 171.88\n",
      "  episode_reward_max: 1114.5758936545533\n",
      "  episode_reward_mean: 961.3463134259608\n",
      "  episode_reward_min: -64.79075372818971\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 36895\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3920.254\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 6380000\n",
      "    num_steps_trained: 6380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8879398703575134\n",
      "      kl: 0.01962554082274437\n",
      "      policy_loss: 0.000814775237813592\n",
      "      total_loss: 471.1528015136719\n",
      "      vf_explained_var: 0.9823796153068542\n",
      "      vf_loss: 471.14984130859375\n",
      "    sample_time_ms: 20034.86\n",
      "    update_time_ms: 5.102\n",
      "  iterations_since_restore: 638\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.6731567129804\n",
      "  time_since_restore: 15129.834187984467\n",
      "  time_this_iter_s: 23.739670515060425\n",
      "  time_total_s: 15129.834187984467\n",
      "  timestamp: 1553980915\n",
      "  timesteps_since_restore: 6380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6380000\n",
      "  training_iteration: 638\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15129 s, 638 iter, 6380000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-22-20\n",
      "  done: false\n",
      "  episode_len_mean: 173.79\n",
      "  episode_reward_max: 1114.5758936545533\n",
      "  episode_reward_mean: 1006.0869624503044\n",
      "  episode_reward_min: 29.601417106083574\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 36954\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.854\n",
      "    load_time_ms: 1.664\n",
      "    num_steps_sampled: 6390000\n",
      "    num_steps_trained: 6390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.404497891664505\n",
      "      kl: 0.040402963757514954\n",
      "      policy_loss: 0.0020203073509037495\n",
      "      total_loss: 151.5724334716797\n",
      "      vf_explained_var: 0.9933775663375854\n",
      "      vf_loss: 151.5660858154297\n",
      "    sample_time_ms: 20031.054\n",
      "    update_time_ms: 5.193\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 503.0434812251522\n",
      "  time_since_restore: 15153.82206773758\n",
      "  time_this_iter_s: 23.987879753112793\n",
      "  time_total_s: 15153.82206773758\n",
      "  timestamp: 1553980940\n",
      "  timesteps_since_restore: 6390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6390000\n",
      "  training_iteration: 639\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15153 s, 639 iter, 6390000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-22-43\n",
      "  done: false\n",
      "  episode_len_mean: 170.12\n",
      "  episode_reward_max: 1138.6234230474251\n",
      "  episode_reward_mean: 1008.7587912031307\n",
      "  episode_reward_min: 648.5819773183745\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 37013\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.896\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 6400000\n",
      "    num_steps_trained: 6400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16085103154182434\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.55364990234375\n",
      "      kl: 0.024578005075454712\n",
      "      policy_loss: -0.00015171464474406093\n",
      "      total_loss: 67.69084167480469\n",
      "      vf_explained_var: 0.9970347285270691\n",
      "      vf_loss: 67.68704986572266\n",
      "    sample_time_ms: 19958.573\n",
      "    update_time_ms: 5.179\n",
      "  iterations_since_restore: 640\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.37939560156536\n",
      "  time_since_restore: 15177.277765512466\n",
      "  time_this_iter_s: 23.455697774887085\n",
      "  time_total_s: 15177.277765512466\n",
      "  timestamp: 1553980963\n",
      "  timesteps_since_restore: 6400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6400000\n",
      "  training_iteration: 640\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15177 s, 640 iter, 6400000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-23-07\n",
      "  done: false\n",
      "  episode_len_mean: 171.07\n",
      "  episode_reward_max: 1145.8196387545186\n",
      "  episode_reward_mean: 974.3066884656686\n",
      "  episode_reward_min: -77.47897152684357\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 37072\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.857\n",
      "    load_time_ms: 1.657\n",
      "    num_steps_sampled: 6410000\n",
      "    num_steps_trained: 6410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16085103154182434\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7221251130104065\n",
      "      kl: 0.01177717000246048\n",
      "      policy_loss: -0.002132546855136752\n",
      "      total_loss: 789.0604858398438\n",
      "      vf_explained_var: 0.9677801132202148\n",
      "      vf_loss: 789.0607299804688\n",
      "    sample_time_ms: 19960.616\n",
      "    update_time_ms: 5.231\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.1533442328343\n",
      "  time_since_restore: 15201.43963599205\n",
      "  time_this_iter_s: 24.16187047958374\n",
      "  time_total_s: 15201.43963599205\n",
      "  timestamp: 1553980987\n",
      "  timesteps_since_restore: 6410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6410000\n",
      "  training_iteration: 641\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15201 s, 641 iter, 6410000 ts, 974 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-23-31\n",
      "  done: false\n",
      "  episode_len_mean: 166.27\n",
      "  episode_reward_max: 1125.4095530462127\n",
      "  episode_reward_mean: 954.9505417887709\n",
      "  episode_reward_min: -77.47897152684357\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 37132\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.398\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 6420000\n",
      "    num_steps_trained: 6420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16085103154182434\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.561029851436615\n",
      "      kl: 0.011904253624379635\n",
      "      policy_loss: -0.0018290349980816245\n",
      "      total_loss: 576.752197265625\n",
      "      vf_explained_var: 0.9731550812721252\n",
      "      vf_loss: 576.7520751953125\n",
      "    sample_time_ms: 19958.973\n",
      "    update_time_ms: 5.375\n",
      "  iterations_since_restore: 642\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.4752708943855\n",
      "  time_since_restore: 15225.17707657814\n",
      "  time_this_iter_s: 23.737440586090088\n",
      "  time_total_s: 15225.17707657814\n",
      "  timestamp: 1553981011\n",
      "  timesteps_since_restore: 6420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6420000\n",
      "  training_iteration: 642\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15225 s, 642 iter, 6420000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-23-54\n",
      "  done: false\n",
      "  episode_len_mean: 165.01\n",
      "  episode_reward_max: 1122.8115370345986\n",
      "  episode_reward_mean: 958.9584961716312\n",
      "  episode_reward_min: -48.943779312904354\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 37192\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.993\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 6430000\n",
      "    num_steps_trained: 6430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16085103154182434\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5017396807670593\n",
      "      kl: 0.0164197888225317\n",
      "      policy_loss: -0.00041032256558537483\n",
      "      total_loss: 563.8905029296875\n",
      "      vf_explained_var: 0.9744177460670471\n",
      "      vf_loss: 563.8883056640625\n",
      "    sample_time_ms: 19813.337\n",
      "    update_time_ms: 4.938\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.4792480858156\n",
      "  time_since_restore: 15248.12842965126\n",
      "  time_this_iter_s: 22.951353073120117\n",
      "  time_total_s: 15248.12842965126\n",
      "  timestamp: 1553981034\n",
      "  timesteps_since_restore: 6430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6430000\n",
      "  training_iteration: 643\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15248 s, 643 iter, 6430000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-24-18\n",
      "  done: false\n",
      "  episode_len_mean: 169.38\n",
      "  episode_reward_max: 1122.8115370345986\n",
      "  episode_reward_mean: 978.6349579743919\n",
      "  episode_reward_min: -53.66592432003313\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 37250\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.381\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 6440000\n",
      "    num_steps_trained: 6440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16085103154182434\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6374092698097229\n",
      "      kl: 0.022969717159867287\n",
      "      policy_loss: 0.0001787687506293878\n",
      "      total_loss: 471.6134948730469\n",
      "      vf_explained_var: 0.9801075458526611\n",
      "      vf_loss: 471.6095886230469\n",
      "    sample_time_ms: 19806.878\n",
      "    update_time_ms: 4.923\n",
      "  iterations_since_restore: 644\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.31747898719595\n",
      "  time_since_restore: 15271.598536014557\n",
      "  time_this_iter_s: 23.47010636329651\n",
      "  time_total_s: 15271.598536014557\n",
      "  timestamp: 1553981058\n",
      "  timesteps_since_restore: 6440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6440000\n",
      "  training_iteration: 644\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15271 s, 644 iter, 6440000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-24-42\n",
      "  done: false\n",
      "  episode_len_mean: 175.74\n",
      "  episode_reward_max: 1127.1407372351225\n",
      "  episode_reward_mean: 981.5290259015711\n",
      "  episode_reward_min: -53.66592432003313\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 37307\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.975\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 6450000\n",
      "    num_steps_trained: 6450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16085103154182434\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8351403474807739\n",
      "      kl: 0.011430607177317142\n",
      "      policy_loss: -0.0006606754614040256\n",
      "      total_loss: 322.7237243652344\n",
      "      vf_explained_var: 0.9862596392631531\n",
      "      vf_loss: 322.7225646972656\n",
      "    sample_time_ms: 19853.025\n",
      "    update_time_ms: 4.921\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.7645129507855\n",
      "  time_since_restore: 15296.280113697052\n",
      "  time_this_iter_s: 24.681577682495117\n",
      "  time_total_s: 15296.280113697052\n",
      "  timestamp: 1553981082\n",
      "  timesteps_since_restore: 6450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6450000\n",
      "  training_iteration: 645\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15296 s, 645 iter, 6450000 ts, 982 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-25-06\n",
      "  done: false\n",
      "  episode_len_mean: 180.8\n",
      "  episode_reward_max: 1121.6884265660692\n",
      "  episode_reward_mean: 959.9965529159766\n",
      "  episode_reward_min: -36.334477845313245\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 37364\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.759\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 6460000\n",
      "    num_steps_trained: 6460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16085103154182434\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8172081112861633\n",
      "      kl: 0.009889191947877407\n",
      "      policy_loss: -0.00024023823789320886\n",
      "      total_loss: 774.3414916992188\n",
      "      vf_explained_var: 0.9680995345115662\n",
      "      vf_loss: 774.3401489257812\n",
      "    sample_time_ms: 19838.378\n",
      "    update_time_ms: 5.084\n",
      "  iterations_since_restore: 646\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.99827645798837\n",
      "  time_since_restore: 15320.081985473633\n",
      "  time_this_iter_s: 23.80187177658081\n",
      "  time_total_s: 15320.081985473633\n",
      "  timestamp: 1553981106\n",
      "  timesteps_since_restore: 6460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6460000\n",
      "  training_iteration: 646\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15320 s, 646 iter, 6460000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-25-30\n",
      "  done: false\n",
      "  episode_len_mean: 170.61\n",
      "  episode_reward_max: 1116.1863301100764\n",
      "  episode_reward_mean: 957.9159594744356\n",
      "  episode_reward_min: -10.89007452766711\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 37421\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.901\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 6470000\n",
      "    num_steps_trained: 6470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6691064238548279\n",
      "      kl: 0.018725447356700897\n",
      "      policy_loss: -0.0029734144918620586\n",
      "      total_loss: 442.52825927734375\n",
      "      vf_explained_var: 0.9800186157226562\n",
      "      vf_loss: 442.5297546386719\n",
      "    sample_time_ms: 19840.412\n",
      "    update_time_ms: 5.526\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.9579797372178\n",
      "  time_since_restore: 15343.757577419281\n",
      "  time_this_iter_s: 23.675591945648193\n",
      "  time_total_s: 15343.757577419281\n",
      "  timestamp: 1553981130\n",
      "  timesteps_since_restore: 6470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6470000\n",
      "  training_iteration: 647\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15343 s, 647 iter, 6470000 ts, 958 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-25-53\n",
      "  done: false\n",
      "  episode_len_mean: 174.83\n",
      "  episode_reward_max: 1116.1863301100764\n",
      "  episode_reward_mean: 969.4586523134852\n",
      "  episode_reward_min: 11.724180405692692\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 37479\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.8\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 6480000\n",
      "    num_steps_trained: 6480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7962111234664917\n",
      "      kl: 0.02131524682044983\n",
      "      policy_loss: -0.004070209339261055\n",
      "      total_loss: 368.14703369140625\n",
      "      vf_explained_var: 0.984075665473938\n",
      "      vf_loss: 368.1493835449219\n",
      "    sample_time_ms: 19784.993\n",
      "    update_time_ms: 5.843\n",
      "  iterations_since_restore: 648\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.7293261567426\n",
      "  time_since_restore: 15366.965115785599\n",
      "  time_this_iter_s: 23.20753836631775\n",
      "  time_total_s: 15366.965115785599\n",
      "  timestamp: 1553981153\n",
      "  timesteps_since_restore: 6480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6480000\n",
      "  training_iteration: 648\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15366 s, 648 iter, 6480000 ts, 969 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-26-17\n",
      "  done: false\n",
      "  episode_len_mean: 176.36\n",
      "  episode_reward_max: 1105.1164839353505\n",
      "  episode_reward_mean: 934.5912254526506\n",
      "  episode_reward_min: -82.2487149844317\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 37536\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.585\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 6490000\n",
      "    num_steps_trained: 6490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0528661012649536\n",
      "      kl: 0.01751549355685711\n",
      "      policy_loss: -0.0006772329797968268\n",
      "      total_loss: 1180.0733642578125\n",
      "      vf_explained_var: 0.953252911567688\n",
      "      vf_loss: 1180.0726318359375\n",
      "    sample_time_ms: 19742.965\n",
      "    update_time_ms: 5.766\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.2956127263253\n",
      "  time_since_restore: 15390.49862074852\n",
      "  time_this_iter_s: 23.533504962921143\n",
      "  time_total_s: 15390.49862074852\n",
      "  timestamp: 1553981177\n",
      "  timesteps_since_restore: 6490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6490000\n",
      "  training_iteration: 649\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15390 s, 649 iter, 6490000 ts, 935 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-26-41\n",
      "  done: false\n",
      "  episode_len_mean: 176.79\n",
      "  episode_reward_max: 1127.2941723571514\n",
      "  episode_reward_mean: 961.0678726096653\n",
      "  episode_reward_min: -82.2487149844317\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 37594\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3922.092\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 6500000\n",
      "    num_steps_trained: 6500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6307381987571716\n",
      "      kl: 0.024992290884256363\n",
      "      policy_loss: -0.0008048022864386439\n",
      "      total_loss: 323.0426330566406\n",
      "      vf_explained_var: 0.9855362176895142\n",
      "      vf_loss: 323.0414123535156\n",
      "    sample_time_ms: 19782.662\n",
      "    update_time_ms: 5.835\n",
      "  iterations_since_restore: 650\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.53393630483276\n",
      "  time_since_restore: 15414.585772514343\n",
      "  time_this_iter_s: 24.087151765823364\n",
      "  time_total_s: 15414.585772514343\n",
      "  timestamp: 1553981201\n",
      "  timesteps_since_restore: 6500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6500000\n",
      "  training_iteration: 650\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15414 s, 650 iter, 6500000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-27-05\n",
      "  done: false\n",
      "  episode_len_mean: 168.96\n",
      "  episode_reward_max: 1127.2941723571514\n",
      "  episode_reward_mean: 981.7516974227171\n",
      "  episode_reward_min: -51.994540464935994\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 37655\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.587\n",
      "    load_time_ms: 1.687\n",
      "    num_steps_sampled: 6510000\n",
      "    num_steps_trained: 6510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.45353516936302185\n",
      "      kl: 0.02486540377140045\n",
      "      policy_loss: -0.002134239301085472\n",
      "      total_loss: 486.3227233886719\n",
      "      vf_explained_var: 0.9802125096321106\n",
      "      vf_loss: 486.32281494140625\n",
      "    sample_time_ms: 19824.118\n",
      "    update_time_ms: 5.982\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.87584871135857\n",
      "  time_since_restore: 15439.035261392593\n",
      "  time_this_iter_s: 24.449488878250122\n",
      "  time_total_s: 15439.035261392593\n",
      "  timestamp: 1553981225\n",
      "  timesteps_since_restore: 6510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6510000\n",
      "  training_iteration: 651\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15439 s, 651 iter, 6510000 ts, 982 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-27-29\n",
      "  done: false\n",
      "  episode_len_mean: 167.53\n",
      "  episode_reward_max: 1125.4899179764645\n",
      "  episode_reward_mean: 954.2455877180935\n",
      "  episode_reward_min: -57.68345800606846\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 37713\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.678\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 6520000\n",
      "    num_steps_trained: 6520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5867295861244202\n",
      "      kl: 0.026793895289301872\n",
      "      policy_loss: -0.008012166246771812\n",
      "      total_loss: 527.9217529296875\n",
      "      vf_explained_var: 0.9762275815010071\n",
      "      vf_loss: 527.9276123046875\n",
      "    sample_time_ms: 19843.061\n",
      "    update_time_ms: 5.912\n",
      "  iterations_since_restore: 652\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.1227938590468\n",
      "  time_since_restore: 15462.943017244339\n",
      "  time_this_iter_s: 23.907755851745605\n",
      "  time_total_s: 15462.943017244339\n",
      "  timestamp: 1553981249\n",
      "  timesteps_since_restore: 6520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6520000\n",
      "  training_iteration: 652\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15462 s, 652 iter, 6520000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-27-53\n",
      "  done: false\n",
      "  episode_len_mean: 166.06\n",
      "  episode_reward_max: 1124.0021895490534\n",
      "  episode_reward_mean: 970.2670347147296\n",
      "  episode_reward_min: -57.68345800606846\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 37774\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.387\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 6530000\n",
      "    num_steps_trained: 6530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4366111755371094\n",
      "      kl: 0.02401147410273552\n",
      "      policy_loss: -0.0016807934734970331\n",
      "      total_loss: 393.3410339355469\n",
      "      vf_explained_var: 0.9833868145942688\n",
      "      vf_loss: 393.34075927734375\n",
      "    sample_time_ms: 19949.762\n",
      "    update_time_ms: 5.919\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.1335173573646\n",
      "  time_since_restore: 15487.001105070114\n",
      "  time_this_iter_s: 24.058087825775146\n",
      "  time_total_s: 15487.001105070114\n",
      "  timestamp: 1553981273\n",
      "  timesteps_since_restore: 6530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6530000\n",
      "  training_iteration: 653\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15487 s, 653 iter, 6530000 ts, 970 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-28-17\n",
      "  done: false\n",
      "  episode_len_mean: 168.8\n",
      "  episode_reward_max: 1129.8729630440039\n",
      "  episode_reward_mean: 987.4590069410724\n",
      "  episode_reward_min: -28.464814784884368\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 37834\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.495\n",
      "    load_time_ms: 1.686\n",
      "    num_steps_sampled: 6540000\n",
      "    num_steps_trained: 6540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5652357935905457\n",
      "      kl: 0.026132024824619293\n",
      "      policy_loss: -0.003045962657779455\n",
      "      total_loss: 221.32843017578125\n",
      "      vf_explained_var: 0.9907891750335693\n",
      "      vf_loss: 221.32937622070312\n",
      "    sample_time_ms: 19961.052\n",
      "    update_time_ms: 5.849\n",
      "  iterations_since_restore: 654\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.72950347053614\n",
      "  time_since_restore: 15510.588012218475\n",
      "  time_this_iter_s: 23.586907148361206\n",
      "  time_total_s: 15510.588012218475\n",
      "  timestamp: 1553981297\n",
      "  timesteps_since_restore: 6540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6540000\n",
      "  training_iteration: 654\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15510 s, 654 iter, 6540000 ts, 987 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-28-41\n",
      "  done: false\n",
      "  episode_len_mean: 173.52\n",
      "  episode_reward_max: 1129.8729630440039\n",
      "  episode_reward_mean: 996.2336359584829\n",
      "  episode_reward_min: 168.9654590692732\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 37890\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3927.534\n",
      "    load_time_ms: 1.691\n",
      "    num_steps_sampled: 6550000\n",
      "    num_steps_trained: 6550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7277498245239258\n",
      "      kl: 0.021115342155098915\n",
      "      policy_loss: -0.0009319762466475368\n",
      "      total_loss: 229.6717071533203\n",
      "      vf_explained_var: 0.9907962083816528\n",
      "      vf_loss: 229.67092895507812\n",
      "    sample_time_ms: 19861.045\n",
      "    update_time_ms: 5.882\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.11681797924143\n",
      "  time_since_restore: 15534.427932739258\n",
      "  time_this_iter_s: 23.83992052078247\n",
      "  time_total_s: 15534.427932739258\n",
      "  timestamp: 1553981321\n",
      "  timesteps_since_restore: 6550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6550000\n",
      "  training_iteration: 655\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15534 s, 655 iter, 6550000 ts, 996 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-29-04\n",
      "  done: false\n",
      "  episode_len_mean: 163.72\n",
      "  episode_reward_max: 1155.2544127650754\n",
      "  episode_reward_mean: 972.0365442195439\n",
      "  episode_reward_min: -85.15783718531502\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 37952\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.918\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 6560000\n",
      "    num_steps_trained: 6560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5070120096206665\n",
      "      kl: 0.020432420074939728\n",
      "      policy_loss: -0.002564941765740514\n",
      "      total_loss: 1082.2652587890625\n",
      "      vf_explained_var: 0.9559087753295898\n",
      "      vf_loss: 1082.2662353515625\n",
      "    sample_time_ms: 19843.43\n",
      "    update_time_ms: 5.832\n",
      "  iterations_since_restore: 656\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.0182721097718\n",
      "  time_since_restore: 15558.027508020401\n",
      "  time_this_iter_s: 23.59957528114319\n",
      "  time_total_s: 15558.027508020401\n",
      "  timestamp: 1553981344\n",
      "  timesteps_since_restore: 6560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6560000\n",
      "  training_iteration: 656\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15558 s, 656 iter, 6560000 ts, 972 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-29-28\n",
      "  done: false\n",
      "  episode_len_mean: 162.49\n",
      "  episode_reward_max: 1155.2544127650754\n",
      "  episode_reward_mean: 969.3594278979762\n",
      "  episode_reward_min: -85.15783718531502\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 38013\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3927.837\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 6570000\n",
      "    num_steps_trained: 6570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4209699034690857\n",
      "      kl: 0.023061752319335938\n",
      "      policy_loss: -0.0013715169625356793\n",
      "      total_loss: 321.68157958984375\n",
      "      vf_explained_var: 0.9862884283065796\n",
      "      vf_loss: 321.68109130859375\n",
      "    sample_time_ms: 19874.276\n",
      "    update_time_ms: 5.49\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.67971394898797\n",
      "  time_since_restore: 15582.035987615585\n",
      "  time_this_iter_s: 24.008479595184326\n",
      "  time_total_s: 15582.035987615585\n",
      "  timestamp: 1553981368\n",
      "  timesteps_since_restore: 6570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6570000\n",
      "  training_iteration: 657\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15582 s, 657 iter, 6570000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-29-52\n",
      "  done: false\n",
      "  episode_len_mean: 168.51\n",
      "  episode_reward_max: 1136.975524427069\n",
      "  episode_reward_mean: 979.9612363971296\n",
      "  episode_reward_min: -27.184443642725\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 38071\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.905\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 6580000\n",
      "    num_steps_trained: 6580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6318566799163818\n",
      "      kl: 0.02425527013838291\n",
      "      policy_loss: -9.834651427809149e-05\n",
      "      total_loss: 364.018310546875\n",
      "      vf_explained_var: 0.9849591255187988\n",
      "      vf_loss: 364.0164489746094\n",
      "    sample_time_ms: 19945.489\n",
      "    update_time_ms: 5.327\n",
      "  iterations_since_restore: 658\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.9806181985649\n",
      "  time_since_restore: 15605.923525571823\n",
      "  time_this_iter_s: 23.887537956237793\n",
      "  time_total_s: 15605.923525571823\n",
      "  timestamp: 1553981392\n",
      "  timesteps_since_restore: 6580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6580000\n",
      "  training_iteration: 658\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15605 s, 658 iter, 6580000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-30-16\n",
      "  done: false\n",
      "  episode_len_mean: 168.57\n",
      "  episode_reward_max: 1107.08717226462\n",
      "  episode_reward_mean: 961.6488124457247\n",
      "  episode_reward_min: -55.59546531179461\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 38130\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3925.391\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 6590000\n",
      "    num_steps_trained: 6590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7907707691192627\n",
      "      kl: 0.026797771453857422\n",
      "      policy_loss: -0.0008618527790531516\n",
      "      total_loss: 606.6957397460938\n",
      "      vf_explained_var: 0.9735242128372192\n",
      "      vf_loss: 606.6943969726562\n",
      "    sample_time_ms: 19989.328\n",
      "    update_time_ms: 5.309\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.8244062228623\n",
      "  time_since_restore: 15629.895641326904\n",
      "  time_this_iter_s: 23.972115755081177\n",
      "  time_total_s: 15629.895641326904\n",
      "  timestamp: 1553981416\n",
      "  timesteps_since_restore: 6590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6590000\n",
      "  training_iteration: 659\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15629 s, 659 iter, 6590000 ts, 962 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-30-41\n",
      "  done: false\n",
      "  episode_len_mean: 163.53\n",
      "  episode_reward_max: 1114.4488915275479\n",
      "  episode_reward_mean: 964.7332260357856\n",
      "  episode_reward_min: -55.59546531179461\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 38192\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.724\n",
      "    load_time_ms: 1.454\n",
      "    num_steps_sampled: 6600000\n",
      "    num_steps_trained: 6600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49933066964149475\n",
      "      kl: 0.02115127071738243\n",
      "      policy_loss: -0.0011597839184105396\n",
      "      total_loss: 637.33984375\n",
      "      vf_explained_var: 0.9730693101882935\n",
      "      vf_loss: 637.33935546875\n",
      "    sample_time_ms: 20054.644\n",
      "    update_time_ms: 5.201\n",
      "  iterations_since_restore: 660\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.3666130178927\n",
      "  time_since_restore: 15654.464486837387\n",
      "  time_this_iter_s: 24.568845510482788\n",
      "  time_total_s: 15654.464486837387\n",
      "  timestamp: 1553981441\n",
      "  timesteps_since_restore: 6600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6600000\n",
      "  training_iteration: 660\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15654 s, 660 iter, 6600000 ts, 965 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-31-05\n",
      "  done: false\n",
      "  episode_len_mean: 167.88\n",
      "  episode_reward_max: 1131.001687378238\n",
      "  episode_reward_mean: 980.9792635466443\n",
      "  episode_reward_min: -21.5032223888754\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 38250\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.768\n",
      "    load_time_ms: 1.434\n",
      "    num_steps_sampled: 6610000\n",
      "    num_steps_trained: 6610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.766335129737854\n",
      "      kl: 0.03308197110891342\n",
      "      policy_loss: -0.006072103511542082\n",
      "      total_loss: 533.7085571289062\n",
      "      vf_explained_var: 0.9789889454841614\n",
      "      vf_loss: 533.7119140625\n",
      "    sample_time_ms: 19983.132\n",
      "    update_time_ms: 4.903\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.4896317733222\n",
      "  time_since_restore: 15678.117102622986\n",
      "  time_this_iter_s: 23.652615785598755\n",
      "  time_total_s: 15678.117102622986\n",
      "  timestamp: 1553981465\n",
      "  timesteps_since_restore: 6610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6610000\n",
      "  training_iteration: 661\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15678 s, 661 iter, 6610000 ts, 981 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-31-29\n",
      "  done: false\n",
      "  episode_len_mean: 172.94\n",
      "  episode_reward_max: 1133.2206823249217\n",
      "  episode_reward_mean: 941.0242546759359\n",
      "  episode_reward_min: -14.925654433389923\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 38309\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.453\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 6620000\n",
      "    num_steps_trained: 6620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8325082659721375\n",
      "      kl: 0.028125561773777008\n",
      "      policy_loss: -0.0007214603247120976\n",
      "      total_loss: 715.369140625\n",
      "      vf_explained_var: 0.9733585715293884\n",
      "      vf_loss: 715.3675537109375\n",
      "    sample_time_ms: 19997.215\n",
      "    update_time_ms: 4.842\n",
      "  iterations_since_restore: 662\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.51212733796797\n",
      "  time_since_restore: 15702.20298910141\n",
      "  time_this_iter_s: 24.085886478424072\n",
      "  time_total_s: 15702.20298910141\n",
      "  timestamp: 1553981489\n",
      "  timesteps_since_restore: 6620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6620000\n",
      "  training_iteration: 662\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15702 s, 662 iter, 6620000 ts, 941 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-31-52\n",
      "  done: false\n",
      "  episode_len_mean: 171.6\n",
      "  episode_reward_max: 1133.2206823249217\n",
      "  episode_reward_mean: 963.791041060668\n",
      "  episode_reward_min: -14.925654433389923\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 38365\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.743\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 6630000\n",
      "    num_steps_trained: 6630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6611281037330627\n",
      "      kl: 0.026381902396678925\n",
      "      policy_loss: -0.0032359259203076363\n",
      "      total_loss: 668.4537963867188\n",
      "      vf_explained_var: 0.9699215292930603\n",
      "      vf_loss: 668.4548950195312\n",
      "    sample_time_ms: 19946.679\n",
      "    update_time_ms: 5.06\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.895520530334\n",
      "  time_since_restore: 15725.706903934479\n",
      "  time_this_iter_s: 23.503914833068848\n",
      "  time_total_s: 15725.706903934479\n",
      "  timestamp: 1553981512\n",
      "  timesteps_since_restore: 6630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6630000\n",
      "  training_iteration: 663\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15725 s, 663 iter, 6630000 ts, 964 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-32-16\n",
      "  done: false\n",
      "  episode_len_mean: 176.77\n",
      "  episode_reward_max: 1146.7617364267871\n",
      "  episode_reward_mean: 982.7267618474027\n",
      "  episode_reward_min: -9.49614482847798\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 38421\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.127\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 6640000\n",
      "    num_steps_trained: 6640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8159077763557434\n",
      "      kl: 0.029408058151602745\n",
      "      policy_loss: -0.002819531597197056\n",
      "      total_loss: 467.97344970703125\n",
      "      vf_explained_var: 0.9809034466743469\n",
      "      vf_loss: 467.9739074707031\n",
      "    sample_time_ms: 19992.599\n",
      "    update_time_ms: 5.061\n",
      "  iterations_since_restore: 664\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.36338092370136\n",
      "  time_since_restore: 15749.776512145996\n",
      "  time_this_iter_s: 24.069608211517334\n",
      "  time_total_s: 15749.776512145996\n",
      "  timestamp: 1553981536\n",
      "  timesteps_since_restore: 6640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6640000\n",
      "  training_iteration: 664\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15749 s, 664 iter, 6640000 ts, 983 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-32-41\n",
      "  done: false\n",
      "  episode_len_mean: 170.5\n",
      "  episode_reward_max: 1146.7617364267871\n",
      "  episode_reward_mean: 1009.2155355378712\n",
      "  episode_reward_min: 61.46159579801059\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 38481\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.874\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 6650000\n",
      "    num_steps_trained: 6650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08042551577091217\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6990801095962524\n",
      "      kl: 0.1267116516828537\n",
      "      policy_loss: -0.00025677221128717065\n",
      "      total_loss: 207.8430633544922\n",
      "      vf_explained_var: 0.9913293123245239\n",
      "      vf_loss: 207.8331298828125\n",
      "    sample_time_ms: 20072.387\n",
      "    update_time_ms: 5.068\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.6077677689356\n",
      "  time_since_restore: 15774.311720132828\n",
      "  time_this_iter_s: 24.535207986831665\n",
      "  time_total_s: 15774.311720132828\n",
      "  timestamp: 1553981561\n",
      "  timesteps_since_restore: 6650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6650000\n",
      "  training_iteration: 665\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15774 s, 665 iter, 6650000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-33-04\n",
      "  done: false\n",
      "  episode_len_mean: 169.14\n",
      "  episode_reward_max: 1112.8999577698194\n",
      "  episode_reward_mean: 993.5625896069508\n",
      "  episode_reward_min: -93.62181725435788\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 38540\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.3\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 6660000\n",
      "    num_steps_trained: 6660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.633350670337677\n",
      "      kl: 0.011681118048727512\n",
      "      policy_loss: -0.0027863860595971346\n",
      "      total_loss: 637.5084838867188\n",
      "      vf_explained_var: 0.9716370701789856\n",
      "      vf_loss: 637.5099487304688\n",
      "    sample_time_ms: 20012.49\n",
      "    update_time_ms: 5.09\n",
      "  iterations_since_restore: 666\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.7812948034753\n",
      "  time_since_restore: 15797.313750982285\n",
      "  time_this_iter_s: 23.002030849456787\n",
      "  time_total_s: 15797.313750982285\n",
      "  timestamp: 1553981584\n",
      "  timesteps_since_restore: 6660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6660000\n",
      "  training_iteration: 666\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15797 s, 666 iter, 6660000 ts, 994 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-33-28\n",
      "  done: false\n",
      "  episode_len_mean: 166.89\n",
      "  episode_reward_max: 1112.8999577698194\n",
      "  episode_reward_mean: 980.5327396108485\n",
      "  episode_reward_min: -93.62181725435788\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 38599\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.995\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 6670000\n",
      "    num_steps_trained: 6670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8391226530075073\n",
      "      kl: 0.012958786450326443\n",
      "      policy_loss: -0.001059203059412539\n",
      "      total_loss: 500.1447448730469\n",
      "      vf_explained_var: 0.9772958755493164\n",
      "      vf_loss: 500.144287109375\n",
      "    sample_time_ms: 19994.662\n",
      "    update_time_ms: 5.041\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.26636980542423\n",
      "  time_since_restore: 15821.130449533463\n",
      "  time_this_iter_s: 23.81669855117798\n",
      "  time_total_s: 15821.130449533463\n",
      "  timestamp: 1553981608\n",
      "  timesteps_since_restore: 6670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6670000\n",
      "  training_iteration: 667\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15821 s, 667 iter, 6670000 ts, 981 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-33-52\n",
      "  done: false\n",
      "  episode_len_mean: 170.99\n",
      "  episode_reward_max: 1112.9356140303782\n",
      "  episode_reward_mean: 1008.2154628998983\n",
      "  episode_reward_min: -60.99922223159342\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 38658\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.044\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 6680000\n",
      "    num_steps_trained: 6680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3674427568912506\n",
      "      kl: 0.030276760458946228\n",
      "      policy_loss: 0.001988505246117711\n",
      "      total_loss: 102.79566955566406\n",
      "      vf_explained_var: 0.9954448342323303\n",
      "      vf_loss: 102.7900390625\n",
      "    sample_time_ms: 19964.807\n",
      "    update_time_ms: 4.97\n",
      "  iterations_since_restore: 668\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.1077314499492\n",
      "  time_since_restore: 15844.749243021011\n",
      "  time_this_iter_s: 23.618793487548828\n",
      "  time_total_s: 15844.749243021011\n",
      "  timestamp: 1553981632\n",
      "  timesteps_since_restore: 6680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6680000\n",
      "  training_iteration: 668\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15844 s, 668 iter, 6680000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-34-16\n",
      "  done: false\n",
      "  episode_len_mean: 170.82\n",
      "  episode_reward_max: 1145.154942548716\n",
      "  episode_reward_mean: 984.2997831628053\n",
      "  episode_reward_min: -90.70283905897169\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 38716\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.934\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 6690000\n",
      "    num_steps_trained: 6690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.842863142490387\n",
      "      kl: 0.012723291292786598\n",
      "      policy_loss: -0.0008761760545894504\n",
      "      total_loss: 593.9636840820312\n",
      "      vf_explained_var: 0.9736515879631042\n",
      "      vf_loss: 593.9630126953125\n",
      "    sample_time_ms: 19958.729\n",
      "    update_time_ms: 5.081\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.14989158140247\n",
      "  time_since_restore: 15868.634687423706\n",
      "  time_this_iter_s: 23.885444402694702\n",
      "  time_total_s: 15868.634687423706\n",
      "  timestamp: 1553981656\n",
      "  timesteps_since_restore: 6690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6690000\n",
      "  training_iteration: 669\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15868 s, 669 iter, 6690000 ts, 984 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-34-39\n",
      "  done: false\n",
      "  episode_len_mean: 163.33\n",
      "  episode_reward_max: 1167.3235064214127\n",
      "  episode_reward_mean: 953.0576325031404\n",
      "  episode_reward_min: -90.70283905897169\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 38776\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3916.179\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 6700000\n",
      "    num_steps_trained: 6700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5921601057052612\n",
      "      kl: 0.01569366082549095\n",
      "      policy_loss: -0.004050367511808872\n",
      "      total_loss: 1079.0147705078125\n",
      "      vf_explained_var: 0.9540491104125977\n",
      "      vf_loss: 1079.0169677734375\n",
      "    sample_time_ms: 19861.986\n",
      "    update_time_ms: 5.129\n",
      "  iterations_since_restore: 670\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.5288162515702\n",
      "  time_since_restore: 15892.48905491829\n",
      "  time_this_iter_s: 23.85436749458313\n",
      "  time_total_s: 15892.48905491829\n",
      "  timestamp: 1553981679\n",
      "  timesteps_since_restore: 6700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6700000\n",
      "  training_iteration: 670\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15892 s, 670 iter, 6700000 ts, 953 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-35-04\n",
      "  done: false\n",
      "  episode_len_mean: 162.18\n",
      "  episode_reward_max: 1136.2259184032746\n",
      "  episode_reward_mean: 935.01186889042\n",
      "  episode_reward_min: -62.79495694125498\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 38835\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3926.827\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 6710000\n",
      "    num_steps_trained: 6710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8409253358840942\n",
      "      kl: 0.01640009880065918\n",
      "      policy_loss: -0.000115954338980373\n",
      "      total_loss: 729.2007446289062\n",
      "      vf_explained_var: 0.9710720777511597\n",
      "      vf_loss: 729.1989135742188\n",
      "    sample_time_ms: 19894.236\n",
      "    update_time_ms: 5.155\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.50593444521\n",
      "  time_since_restore: 15916.568839550018\n",
      "  time_this_iter_s: 24.079784631729126\n",
      "  time_total_s: 15916.568839550018\n",
      "  timestamp: 1553981704\n",
      "  timesteps_since_restore: 6710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6710000\n",
      "  training_iteration: 671\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15916 s, 671 iter, 6710000 ts, 935 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-35-28\n",
      "  done: false\n",
      "  episode_len_mean: 168.9\n",
      "  episode_reward_max: 1145.8534604745823\n",
      "  episode_reward_mean: 946.5036564351349\n",
      "  episode_reward_min: -62.28945034376477\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 38893\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.008\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 6720000\n",
      "    num_steps_trained: 6720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7265239357948303\n",
      "      kl: 0.010982530191540718\n",
      "      policy_loss: -0.000745865807402879\n",
      "      total_loss: 399.60321044921875\n",
      "      vf_explained_var: 0.9823536276817322\n",
      "      vf_loss: 399.6026306152344\n",
      "    sample_time_ms: 19917.318\n",
      "    update_time_ms: 5.148\n",
      "  iterations_since_restore: 672\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.2518282175674\n",
      "  time_since_restore: 15940.853357553482\n",
      "  time_this_iter_s: 24.284518003463745\n",
      "  time_total_s: 15940.853357553482\n",
      "  timestamp: 1553981728\n",
      "  timesteps_since_restore: 6720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6720000\n",
      "  training_iteration: 672\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15940 s, 672 iter, 6720000 ts, 947 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-35-52\n",
      "  done: false\n",
      "  episode_len_mean: 158.22\n",
      "  episode_reward_max: 1145.8534604745823\n",
      "  episode_reward_mean: 962.2189729796382\n",
      "  episode_reward_min: -65.90879703436354\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 38957\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3923.106\n",
      "    load_time_ms: 1.387\n",
      "    num_steps_sampled: 6730000\n",
      "    num_steps_trained: 6730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.382504940032959\n",
      "      kl: 0.018575098365545273\n",
      "      policy_loss: -0.0005817590281367302\n",
      "      total_loss: 830.0963745117188\n",
      "      vf_explained_var: 0.9685760140419006\n",
      "      vf_loss: 830.0947875976562\n",
      "    sample_time_ms: 19950.321\n",
      "    update_time_ms: 4.979\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.1094864898191\n",
      "  time_since_restore: 15964.674489974976\n",
      "  time_this_iter_s: 23.82113242149353\n",
      "  time_total_s: 15964.674489974976\n",
      "  timestamp: 1553981752\n",
      "  timesteps_since_restore: 6730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6730000\n",
      "  training_iteration: 673\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15964 s, 673 iter, 6730000 ts, 962 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-36-16\n",
      "  done: false\n",
      "  episode_len_mean: 157.45\n",
      "  episode_reward_max: 1116.2504014023727\n",
      "  episode_reward_mean: 917.4500147528404\n",
      "  episode_reward_min: -100.34270289440467\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 39021\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3923.431\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 6740000\n",
      "    num_steps_trained: 6740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6132409572601318\n",
      "      kl: 0.02365214005112648\n",
      "      policy_loss: -0.0024801993276923895\n",
      "      total_loss: 1284.366943359375\n",
      "      vf_explained_var: 0.9501447677612305\n",
      "      vf_loss: 1284.36669921875\n",
      "    sample_time_ms: 19935.497\n",
      "    update_time_ms: 4.94\n",
      "  iterations_since_restore: 674\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 458.72500737642025\n",
      "  time_since_restore: 15988.595370054245\n",
      "  time_this_iter_s: 23.92088007926941\n",
      "  time_total_s: 15988.595370054245\n",
      "  timestamp: 1553981776\n",
      "  timesteps_since_restore: 6740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6740000\n",
      "  training_iteration: 674\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 15988 s, 674 iter, 6740000 ts, 917 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-36-39\n",
      "  done: false\n",
      "  episode_len_mean: 164.52\n",
      "  episode_reward_max: 1119.5550717795256\n",
      "  episode_reward_mean: 974.5846389495715\n",
      "  episode_reward_min: -72.07753426011584\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 39080\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3949.75\n",
      "    load_time_ms: 1.382\n",
      "    num_steps_sampled: 6750000\n",
      "    num_steps_trained: 6750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4834184944629669\n",
      "      kl: 0.016473833471536636\n",
      "      policy_loss: -0.002360104350373149\n",
      "      total_loss: 394.1422424316406\n",
      "      vf_explained_var: 0.9830960035324097\n",
      "      vf_loss: 394.1426086425781\n",
      "    sample_time_ms: 19775.458\n",
      "    update_time_ms: 4.959\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.29231947478576\n",
      "  time_since_restore: 16011.796643972397\n",
      "  time_this_iter_s: 23.201273918151855\n",
      "  time_total_s: 16011.796643972397\n",
      "  timestamp: 1553981799\n",
      "  timesteps_since_restore: 6750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6750000\n",
      "  training_iteration: 675\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16011 s, 675 iter, 6750000 ts, 975 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-37-03\n",
      "  done: false\n",
      "  episode_len_mean: 175.35\n",
      "  episode_reward_max: 1121.39651139402\n",
      "  episode_reward_mean: 992.126882915309\n",
      "  episode_reward_min: -72.07753426011584\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 39135\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3952.183\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 6760000\n",
      "    num_steps_trained: 6760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8681922554969788\n",
      "      kl: 0.014915259554982185\n",
      "      policy_loss: -0.002304240595549345\n",
      "      total_loss: 348.5309143066406\n",
      "      vf_explained_var: 0.9848240613937378\n",
      "      vf_loss: 348.5314025878906\n",
      "    sample_time_ms: 19831.098\n",
      "    update_time_ms: 4.872\n",
      "  iterations_since_restore: 676\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.06344145765456\n",
      "  time_since_restore: 16035.382257699966\n",
      "  time_this_iter_s: 23.58561372756958\n",
      "  time_total_s: 16035.382257699966\n",
      "  timestamp: 1553981823\n",
      "  timesteps_since_restore: 6760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6760000\n",
      "  training_iteration: 676\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16035 s, 676 iter, 6760000 ts, 992 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-37-26\n",
      "  done: false\n",
      "  episode_len_mean: 170.72\n",
      "  episode_reward_max: 1123.5103945320047\n",
      "  episode_reward_mean: 989.5457960207946\n",
      "  episode_reward_min: -55.10809631355369\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 39195\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3953.696\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 6770000\n",
      "    num_steps_trained: 6770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5688751339912415\n",
      "      kl: 0.01534150168299675\n",
      "      policy_loss: 0.00038495106855407357\n",
      "      total_loss: 358.0611877441406\n",
      "      vf_explained_var: 0.9849951267242432\n",
      "      vf_loss: 358.0589294433594\n",
      "    sample_time_ms: 19748.147\n",
      "    update_time_ms: 5.007\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.77289801039717\n",
      "  time_since_restore: 16058.387480258942\n",
      "  time_this_iter_s: 23.00522255897522\n",
      "  time_total_s: 16058.387480258942\n",
      "  timestamp: 1553981846\n",
      "  timesteps_since_restore: 6770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6770000\n",
      "  training_iteration: 677\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16058 s, 677 iter, 6770000 ts, 990 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-37-49\n",
      "  done: false\n",
      "  episode_len_mean: 165.0\n",
      "  episode_reward_max: 1123.5103945320047\n",
      "  episode_reward_mean: 983.6939988804567\n",
      "  episode_reward_min: -85.6227981581149\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 39256\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3953.292\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 6780000\n",
      "    num_steps_trained: 6780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5507129430770874\n",
      "      kl: 0.013058674521744251\n",
      "      policy_loss: -0.0014384281821548939\n",
      "      total_loss: 601.6598510742188\n",
      "      vf_explained_var: 0.9761946201324463\n",
      "      vf_loss: 601.65966796875\n",
      "    sample_time_ms: 19674.119\n",
      "    update_time_ms: 5.095\n",
      "  iterations_since_restore: 678\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.84699944022833\n",
      "  time_since_restore: 16081.266627073288\n",
      "  time_this_iter_s: 22.879146814346313\n",
      "  time_total_s: 16081.266627073288\n",
      "  timestamp: 1553981869\n",
      "  timesteps_since_restore: 6780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6780000\n",
      "  training_iteration: 678\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16081 s, 678 iter, 6780000 ts, 984 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-38-12\n",
      "  done: false\n",
      "  episode_len_mean: 164.85\n",
      "  episode_reward_max: 1113.4999967231583\n",
      "  episode_reward_mean: 993.5734743727278\n",
      "  episode_reward_min: -85.6227981581149\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 39316\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3990.273\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 6790000\n",
      "    num_steps_trained: 6790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4789075553417206\n",
      "      kl: 0.021313754841685295\n",
      "      policy_loss: -0.0023688192013651133\n",
      "      total_loss: 362.2224426269531\n",
      "      vf_explained_var: 0.9839764833450317\n",
      "      vf_loss: 362.2222595214844\n",
      "    sample_time_ms: 19592.668\n",
      "    update_time_ms: 5.16\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.78673718636384\n",
      "  time_since_restore: 16104.705323457718\n",
      "  time_this_iter_s: 23.43869638442993\n",
      "  time_total_s: 16104.705323457718\n",
      "  timestamp: 1553981892\n",
      "  timesteps_since_restore: 6790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6790000\n",
      "  training_iteration: 679\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16104 s, 679 iter, 6790000 ts, 994 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-38-36\n",
      "  done: false\n",
      "  episode_len_mean: 173.5\n",
      "  episode_reward_max: 1117.186133127489\n",
      "  episode_reward_mean: 990.4045252431669\n",
      "  episode_reward_min: -93.15131629377584\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 39373\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3963.59\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 6800000\n",
      "    num_steps_trained: 6800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.836535632610321\n",
      "      kl: 0.014483332633972168\n",
      "      policy_loss: -0.0030002340208739042\n",
      "      total_loss: 747.7858276367188\n",
      "      vf_explained_var: 0.9676873683929443\n",
      "      vf_loss: 747.7871704101562\n",
      "    sample_time_ms: 19591.409\n",
      "    update_time_ms: 5.26\n",
      "  iterations_since_restore: 680\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.2022626215835\n",
      "  time_since_restore: 16128.28402709961\n",
      "  time_this_iter_s: 23.57870364189148\n",
      "  time_total_s: 16128.28402709961\n",
      "  timestamp: 1553981916\n",
      "  timesteps_since_restore: 6800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6800000\n",
      "  training_iteration: 680\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16128 s, 680 iter, 6800000 ts, 990 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-39-00\n",
      "  done: false\n",
      "  episode_len_mean: 170.54\n",
      "  episode_reward_max: 1129.0864053807168\n",
      "  episode_reward_mean: 960.1214773731607\n",
      "  episode_reward_min: -93.15131629377584\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 39432\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3954.631\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 6810000\n",
      "    num_steps_trained: 6810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9016181826591492\n",
      "      kl: 0.01599910669028759\n",
      "      policy_loss: 6.262996612349525e-05\n",
      "      total_loss: 640.1004638671875\n",
      "      vf_explained_var: 0.972805917263031\n",
      "      vf_loss: 640.0984497070312\n",
      "    sample_time_ms: 19595.972\n",
      "    update_time_ms: 5.446\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.06073868658046\n",
      "  time_since_restore: 16152.324987411499\n",
      "  time_this_iter_s: 24.04096031188965\n",
      "  time_total_s: 16152.324987411499\n",
      "  timestamp: 1553981940\n",
      "  timesteps_since_restore: 6810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6810000\n",
      "  training_iteration: 681\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16152 s, 681 iter, 6810000 ts, 960 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-39-24\n",
      "  done: false\n",
      "  episode_len_mean: 165.59\n",
      "  episode_reward_max: 1129.0864053807168\n",
      "  episode_reward_mean: 989.4567750839341\n",
      "  episode_reward_min: -37.62424940308509\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 39493\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3960.287\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 6820000\n",
      "    num_steps_trained: 6820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5114169120788574\n",
      "      kl: 0.020510215312242508\n",
      "      policy_loss: -0.0013842005282640457\n",
      "      total_loss: 225.588134765625\n",
      "      vf_explained_var: 0.9902688264846802\n",
      "      vf_loss: 225.5870361328125\n",
      "    sample_time_ms: 19580.711\n",
      "    update_time_ms: 5.456\n",
      "  iterations_since_restore: 682\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.7283875419671\n",
      "  time_since_restore: 16176.519390106201\n",
      "  time_this_iter_s: 24.19440269470215\n",
      "  time_total_s: 16176.519390106201\n",
      "  timestamp: 1553981964\n",
      "  timesteps_since_restore: 6820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6820000\n",
      "  training_iteration: 682\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16176 s, 682 iter, 6820000 ts, 989 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-39-48\n",
      "  done: false\n",
      "  episode_len_mean: 158.69\n",
      "  episode_reward_max: 1106.8198857287703\n",
      "  episode_reward_mean: 982.9912383293666\n",
      "  episode_reward_min: -51.38534504763493\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 39556\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3962.833\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 6830000\n",
      "    num_steps_trained: 6830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.43253806233406067\n",
      "      kl: 0.016265103593468666\n",
      "      policy_loss: -0.0046106502413749695\n",
      "      total_loss: 780.0656127929688\n",
      "      vf_explained_var: 0.9693615436553955\n",
      "      vf_loss: 780.0682373046875\n",
      "    sample_time_ms: 19615.007\n",
      "    update_time_ms: 5.363\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.4956191646834\n",
      "  time_since_restore: 16200.713048934937\n",
      "  time_this_iter_s: 24.19365882873535\n",
      "  time_total_s: 16200.713048934937\n",
      "  timestamp: 1553981988\n",
      "  timesteps_since_restore: 6830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6830000\n",
      "  training_iteration: 683\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16200 s, 683 iter, 6830000 ts, 983 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-40-12\n",
      "  done: false\n",
      "  episode_len_mean: 166.09\n",
      "  episode_reward_max: 1121.7462088828377\n",
      "  episode_reward_mean: 971.783772655067\n",
      "  episode_reward_min: -44.09563306052533\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 39614\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3965.919\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 6840000\n",
      "    num_steps_trained: 6840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8199145793914795\n",
      "      kl: 0.016122911125421524\n",
      "      policy_loss: -0.0013907310785725713\n",
      "      total_loss: 706.6643676757812\n",
      "      vf_explained_var: 0.9675717353820801\n",
      "      vf_loss: 706.6636962890625\n",
      "    sample_time_ms: 19615.246\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 684\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.8918863275336\n",
      "  time_since_restore: 16224.665956735611\n",
      "  time_this_iter_s: 23.95290780067444\n",
      "  time_total_s: 16224.665956735611\n",
      "  timestamp: 1553982012\n",
      "  timesteps_since_restore: 6840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6840000\n",
      "  training_iteration: 684\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16224 s, 684 iter, 6840000 ts, 972 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-40-36\n",
      "  done: false\n",
      "  episode_len_mean: 165.26\n",
      "  episode_reward_max: 1117.8237397363318\n",
      "  episode_reward_mean: 928.4649558218564\n",
      "  episode_reward_min: -95.01427856729171\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 39676\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3941.892\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 6850000\n",
      "    num_steps_trained: 6850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5442051291465759\n",
      "      kl: 0.017557019367814064\n",
      "      policy_loss: -0.0022294186055660248\n",
      "      total_loss: 1324.676025390625\n",
      "      vf_explained_var: 0.9450314044952393\n",
      "      vf_loss: 1324.67626953125\n",
      "    sample_time_ms: 19693.781\n",
      "    update_time_ms: 5.358\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 464.2324779109282\n",
      "  time_since_restore: 16248.41313958168\n",
      "  time_this_iter_s: 23.747182846069336\n",
      "  time_total_s: 16248.41313958168\n",
      "  timestamp: 1553982036\n",
      "  timesteps_since_restore: 6850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6850000\n",
      "  training_iteration: 685\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16248 s, 685 iter, 6850000 ts, 928 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-40-59\n",
      "  done: false\n",
      "  episode_len_mean: 161.94\n",
      "  episode_reward_max: 1168.6845933556924\n",
      "  episode_reward_mean: 946.7871405438939\n",
      "  episode_reward_min: -95.01427856729171\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 39737\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3937.466\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 6860000\n",
      "    num_steps_trained: 6860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3210865557193756\n",
      "      kl: 0.01789526827633381\n",
      "      policy_loss: -0.006945888977497816\n",
      "      total_loss: 437.066162109375\n",
      "      vf_explained_var: 0.98147052526474\n",
      "      vf_loss: 437.0709228515625\n",
      "    sample_time_ms: 19668.499\n",
      "    update_time_ms: 5.354\n",
      "  iterations_since_restore: 686\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.3935702719468\n",
      "  time_since_restore: 16271.699440002441\n",
      "  time_this_iter_s: 23.28630042076111\n",
      "  time_total_s: 16271.699440002441\n",
      "  timestamp: 1553982059\n",
      "  timesteps_since_restore: 6860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6860000\n",
      "  training_iteration: 686\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16271 s, 686 iter, 6860000 ts, 947 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-41-22\n",
      "  done: false\n",
      "  episode_len_mean: 168.27\n",
      "  episode_reward_max: 1168.6845933556924\n",
      "  episode_reward_mean: 1000.7123800204243\n",
      "  episode_reward_min: -70.65655243121614\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 39797\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3933.929\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 6870000\n",
      "    num_steps_trained: 6870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5125486254692078\n",
      "      kl: 0.022363362833857536\n",
      "      policy_loss: -0.007646357174962759\n",
      "      total_loss: 215.68499755859375\n",
      "      vf_explained_var: 0.9911317229270935\n",
      "      vf_loss: 215.68995666503906\n",
      "    sample_time_ms: 19662.92\n",
      "    update_time_ms: 5.095\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 500.3561900102122\n",
      "  time_since_restore: 16294.609588861465\n",
      "  time_this_iter_s: 22.910148859024048\n",
      "  time_total_s: 16294.609588861465\n",
      "  timestamp: 1553982082\n",
      "  timesteps_since_restore: 6870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6870000\n",
      "  training_iteration: 687\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16294 s, 687 iter, 6870000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-41-46\n",
      "  done: false\n",
      "  episode_len_mean: 166.14\n",
      "  episode_reward_max: 1133.3400669286116\n",
      "  episode_reward_mean: 985.5017530555186\n",
      "  episode_reward_min: -70.65655243121614\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 39857\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3933.161\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 6880000\n",
      "    num_steps_trained: 6880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.692179799079895\n",
      "      kl: 0.015874389559030533\n",
      "      policy_loss: -0.00012671909644268453\n",
      "      total_loss: 405.81964111328125\n",
      "      vf_explained_var: 0.9834344387054443\n",
      "      vf_loss: 405.81787109375\n",
      "    sample_time_ms: 19762.044\n",
      "    update_time_ms: 5.074\n",
      "  iterations_since_restore: 688\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.7508765277594\n",
      "  time_since_restore: 16318.467995643616\n",
      "  time_this_iter_s: 23.85840678215027\n",
      "  time_total_s: 16318.467995643616\n",
      "  timestamp: 1553982106\n",
      "  timesteps_since_restore: 6880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6880000\n",
      "  training_iteration: 688\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16318 s, 688 iter, 6880000 ts, 986 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-42-10\n",
      "  done: false\n",
      "  episode_len_mean: 164.79\n",
      "  episode_reward_max: 1133.3400669286116\n",
      "  episode_reward_mean: 954.161621905219\n",
      "  episode_reward_min: -91.92891668676715\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 39919\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.371\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 6890000\n",
      "    num_steps_trained: 6890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3928598463535309\n",
      "      kl: 0.019410930573940277\n",
      "      policy_loss: -0.00015648931730538607\n",
      "      total_loss: 915.5690307617188\n",
      "      vf_explained_var: 0.9651299715042114\n",
      "      vf_loss: 915.5668334960938\n",
      "    sample_time_ms: 19819.724\n",
      "    update_time_ms: 5.038\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.0808109526097\n",
      "  time_since_restore: 16342.254328012466\n",
      "  time_this_iter_s: 23.786332368850708\n",
      "  time_total_s: 16342.254328012466\n",
      "  timestamp: 1553982130\n",
      "  timesteps_since_restore: 6890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6890000\n",
      "  training_iteration: 689\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16342 s, 689 iter, 6890000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-42-33\n",
      "  done: false\n",
      "  episode_len_mean: 162.8\n",
      "  episode_reward_max: 1149.5258067502277\n",
      "  episode_reward_mean: 940.0697502889594\n",
      "  episode_reward_min: -91.92891668676715\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 39981\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.87\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 6900000\n",
      "    num_steps_trained: 6900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4966559410095215\n",
      "      kl: 0.022935660555958748\n",
      "      policy_loss: -0.002769282553344965\n",
      "      total_loss: 1210.935546875\n",
      "      vf_explained_var: 0.9505298137664795\n",
      "      vf_loss: 1210.935546875\n",
      "    sample_time_ms: 19793.822\n",
      "    update_time_ms: 4.892\n",
      "  iterations_since_restore: 690\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.03487514447966\n",
      "  time_since_restore: 16365.508577108383\n",
      "  time_this_iter_s: 23.254249095916748\n",
      "  time_total_s: 16365.508577108383\n",
      "  timestamp: 1553982153\n",
      "  timesteps_since_restore: 6900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6900000\n",
      "  training_iteration: 690\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16365 s, 690 iter, 6900000 ts, 940 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-42-58\n",
      "  done: false\n",
      "  episode_len_mean: 160.08\n",
      "  episode_reward_max: 1118.4397799995907\n",
      "  episode_reward_mean: 929.689656219405\n",
      "  episode_reward_min: -76.75742394645512\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 40041\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.47\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 6910000\n",
      "    num_steps_trained: 6910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.40281832218170166\n",
      "      kl: 0.016078392043709755\n",
      "      policy_loss: 9.827563917497173e-05\n",
      "      total_loss: 710.3966064453125\n",
      "      vf_explained_var: 0.9724069237709045\n",
      "      vf_loss: 710.3946533203125\n",
      "    sample_time_ms: 19876.688\n",
      "    update_time_ms: 5.47\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 464.8448281097025\n",
      "  time_since_restore: 16390.399003744125\n",
      "  time_this_iter_s: 24.890426635742188\n",
      "  time_total_s: 16390.399003744125\n",
      "  timestamp: 1553982178\n",
      "  timesteps_since_restore: 6910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6910000\n",
      "  training_iteration: 691\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16390 s, 691 iter, 6910000 ts, 930 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-43-22\n",
      "  done: false\n",
      "  episode_len_mean: 168.51\n",
      "  episode_reward_max: 1137.1359299112064\n",
      "  episode_reward_mean: 972.3596827656338\n",
      "  episode_reward_min: -55.937109179495536\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 40100\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.152\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 6920000\n",
      "    num_steps_trained: 6920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.619247555732727\n",
      "      kl: 0.013490798883140087\n",
      "      policy_loss: -0.002612643176689744\n",
      "      total_loss: 663.6340942382812\n",
      "      vf_explained_var: 0.9715063571929932\n",
      "      vf_loss: 663.6350708007812\n",
      "    sample_time_ms: 19817.612\n",
      "    update_time_ms: 5.436\n",
      "  iterations_since_restore: 692\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.1798413828168\n",
      "  time_since_restore: 16413.96525812149\n",
      "  time_this_iter_s: 23.566254377365112\n",
      "  time_total_s: 16413.96525812149\n",
      "  timestamp: 1553982202\n",
      "  timesteps_since_restore: 6920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6920000\n",
      "  training_iteration: 692\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16413 s, 692 iter, 6920000 ts, 972 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-43-46\n",
      "  done: false\n",
      "  episode_len_mean: 172.33\n",
      "  episode_reward_max: 1143.6155311482532\n",
      "  episode_reward_mean: 977.2316166360149\n",
      "  episode_reward_min: -68.57326427622797\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 40157\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.243\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 6930000\n",
      "    num_steps_trained: 6930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9391546249389648\n",
      "      kl: 0.022707000374794006\n",
      "      policy_loss: -0.0008892267942428589\n",
      "      total_loss: 559.6679077148438\n",
      "      vf_explained_var: 0.9783012270927429\n",
      "      vf_loss: 559.6660766601562\n",
      "    sample_time_ms: 19828.311\n",
      "    update_time_ms: 5.447\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.6158083180074\n",
      "  time_since_restore: 16438.263862133026\n",
      "  time_this_iter_s: 24.298604011535645\n",
      "  time_total_s: 16438.263862133026\n",
      "  timestamp: 1553982226\n",
      "  timesteps_since_restore: 6930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6930000\n",
      "  training_iteration: 693\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16438 s, 693 iter, 6930000 ts, 977 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-44-11\n",
      "  done: false\n",
      "  episode_len_mean: 169.63\n",
      "  episode_reward_max: 1144.5665152354563\n",
      "  episode_reward_mean: 940.5457331307683\n",
      "  episode_reward_min: -68.57326427622797\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 40217\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.147\n",
      "    load_time_ms: 1.454\n",
      "    num_steps_sampled: 6940000\n",
      "    num_steps_trained: 6940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5326759219169617\n",
      "      kl: 0.015384374186396599\n",
      "      policy_loss: 0.00039247775566764176\n",
      "      total_loss: 765.2125244140625\n",
      "      vf_explained_var: 0.9670034646987915\n",
      "      vf_loss: 765.2102661132812\n",
      "    sample_time_ms: 19870.011\n",
      "    update_time_ms: 5.463\n",
      "  iterations_since_restore: 694\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.2728665653841\n",
      "  time_since_restore: 16462.75691151619\n",
      "  time_this_iter_s: 24.493049383163452\n",
      "  time_total_s: 16462.75691151619\n",
      "  timestamp: 1553982251\n",
      "  timesteps_since_restore: 6940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6940000\n",
      "  training_iteration: 694\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16462 s, 694 iter, 6940000 ts, 941 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-44-35\n",
      "  done: false\n",
      "  episode_len_mean: 167.44\n",
      "  episode_reward_max: 1150.659519731775\n",
      "  episode_reward_mean: 932.8550074228261\n",
      "  episode_reward_min: -63.29485039916281\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 40276\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3905.727\n",
      "    load_time_ms: 1.445\n",
      "    num_steps_sampled: 6950000\n",
      "    num_steps_trained: 6950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.70989590883255\n",
      "      kl: 0.021231118589639664\n",
      "      policy_loss: -0.0016524714883416891\n",
      "      total_loss: 909.0527954101562\n",
      "      vf_explained_var: 0.9608607888221741\n",
      "      vf_loss: 909.0518798828125\n",
      "    sample_time_ms: 19889.432\n",
      "    update_time_ms: 5.394\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.4275037114132\n",
      "  time_since_restore: 16486.609982967377\n",
      "  time_this_iter_s: 23.853071451187134\n",
      "  time_total_s: 16486.609982967377\n",
      "  timestamp: 1553982275\n",
      "  timesteps_since_restore: 6950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6950000\n",
      "  training_iteration: 695\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16486 s, 695 iter, 6950000 ts, 933 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-44-59\n",
      "  done: false\n",
      "  episode_len_mean: 167.74\n",
      "  episode_reward_max: 1103.1786325944186\n",
      "  episode_reward_mean: 958.6306170315015\n",
      "  episode_reward_min: -73.99706919317636\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 40337\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.693\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 6960000\n",
      "    num_steps_trained: 6960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6049603223800659\n",
      "      kl: 0.01766389235854149\n",
      "      policy_loss: -0.0007667262689210474\n",
      "      total_loss: 894.6312255859375\n",
      "      vf_explained_var: 0.9635291695594788\n",
      "      vf_loss: 894.6298217773438\n",
      "    sample_time_ms: 19989.944\n",
      "    update_time_ms: 5.902\n",
      "  iterations_since_restore: 696\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.31530851575064\n",
      "  time_since_restore: 16510.9381608963\n",
      "  time_this_iter_s: 24.32817792892456\n",
      "  time_total_s: 16510.9381608963\n",
      "  timestamp: 1553982299\n",
      "  timesteps_since_restore: 6960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6960000\n",
      "  training_iteration: 696\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16510 s, 696 iter, 6960000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-45-23\n",
      "  done: false\n",
      "  episode_len_mean: 165.09\n",
      "  episode_reward_max: 1096.5378222549975\n",
      "  episode_reward_mean: 954.8115310804195\n",
      "  episode_reward_min: -73.99706919317636\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 40398\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.216\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 6970000\n",
      "    num_steps_trained: 6970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3696627914905548\n",
      "      kl: 0.020932955667376518\n",
      "      policy_loss: -0.0005651259562000632\n",
      "      total_loss: 502.3841247558594\n",
      "      vf_explained_var: 0.9780361652374268\n",
      "      vf_loss: 502.3822021484375\n",
      "    sample_time_ms: 20082.96\n",
      "    update_time_ms: 5.991\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.4057655402099\n",
      "  time_since_restore: 16534.775951623917\n",
      "  time_this_iter_s: 23.837790727615356\n",
      "  time_total_s: 16534.775951623917\n",
      "  timestamp: 1553982323\n",
      "  timesteps_since_restore: 6970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6970000\n",
      "  training_iteration: 697\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16534 s, 697 iter, 6970000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-45-47\n",
      "  done: false\n",
      "  episode_len_mean: 176.89\n",
      "  episode_reward_max: 1128.362131225022\n",
      "  episode_reward_mean: 983.5489665049357\n",
      "  episode_reward_min: -51.569766968007656\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 40451\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.092\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 6980000\n",
      "    num_steps_trained: 6980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1423664093017578\n",
      "      kl: 0.02098672278225422\n",
      "      policy_loss: -0.0002223589544882998\n",
      "      total_loss: 358.40521240234375\n",
      "      vf_explained_var: 0.9864764213562012\n",
      "      vf_loss: 358.40289306640625\n",
      "    sample_time_ms: 20095.175\n",
      "    update_time_ms: 6.122\n",
      "  iterations_since_restore: 698\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.7744832524679\n",
      "  time_since_restore: 16558.744981765747\n",
      "  time_this_iter_s: 23.969030141830444\n",
      "  time_total_s: 16558.744981765747\n",
      "  timestamp: 1553982347\n",
      "  timesteps_since_restore: 6980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6980000\n",
      "  training_iteration: 698\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16558 s, 698 iter, 6980000 ts, 984 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-46-11\n",
      "  done: false\n",
      "  episode_len_mean: 172.37\n",
      "  episode_reward_max: 1132.4282917199255\n",
      "  episode_reward_mean: 980.2164323685014\n",
      "  episode_reward_min: -63.36967623560264\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 40513\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.237\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 6990000\n",
      "    num_steps_trained: 6990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49504631757736206\n",
      "      kl: 0.01785573922097683\n",
      "      policy_loss: -0.002835226710885763\n",
      "      total_loss: 589.2032470703125\n",
      "      vf_explained_var: 0.9759888052940369\n",
      "      vf_loss: 589.2039184570312\n",
      "    sample_time_ms: 20125.642\n",
      "    update_time_ms: 6.029\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.10821618425075\n",
      "  time_since_restore: 16582.797333478928\n",
      "  time_this_iter_s: 24.052351713180542\n",
      "  time_total_s: 16582.797333478928\n",
      "  timestamp: 1553982371\n",
      "  timesteps_since_restore: 6990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6990000\n",
      "  training_iteration: 699\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16582 s, 699 iter, 6990000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 164.25\n",
      "  episode_reward_max: 1136.1358087072988\n",
      "  episode_reward_mean: 939.4985337309098\n",
      "  episode_reward_min: -87.24124423103498\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 40574\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.922\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 7000000\n",
      "    num_steps_trained: 7000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7487236857414246\n",
      "      kl: 0.02268983982503414\n",
      "      policy_loss: -0.0008434626506641507\n",
      "      total_loss: 1121.0587158203125\n",
      "      vf_explained_var: 0.9556636214256287\n",
      "      vf_loss: 1121.056640625\n",
      "    sample_time_ms: 20232.594\n",
      "    update_time_ms: 6.019\n",
      "  iterations_since_restore: 700\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.74926686545484\n",
      "  time_since_restore: 16607.18554353714\n",
      "  time_this_iter_s: 24.38821005821228\n",
      "  time_total_s: 16607.18554353714\n",
      "  timestamp: 1553982395\n",
      "  timesteps_since_restore: 7000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7000000\n",
      "  training_iteration: 700\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16607 s, 700 iter, 7000000 ts, 939 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-46-59\n",
      "  done: false\n",
      "  episode_len_mean: 170.71\n",
      "  episode_reward_max: 1136.1358087072988\n",
      "  episode_reward_mean: 947.403078767611\n",
      "  episode_reward_min: -87.24124423103498\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 40632\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.866\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 7010000\n",
      "    num_steps_trained: 7010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.974096417427063\n",
      "      kl: 0.018320541828870773\n",
      "      policy_loss: -0.002479074988514185\n",
      "      total_loss: 790.3742065429688\n",
      "      vf_explained_var: 0.9630915522575378\n",
      "      vf_loss: 790.3743896484375\n",
      "    sample_time_ms: 20123.266\n",
      "    update_time_ms: 5.306\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.7015393838055\n",
      "  time_since_restore: 16630.964296340942\n",
      "  time_this_iter_s: 23.77875280380249\n",
      "  time_total_s: 16630.964296340942\n",
      "  timestamp: 1553982419\n",
      "  timesteps_since_restore: 7010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7010000\n",
      "  training_iteration: 701\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16630 s, 701 iter, 7010000 ts, 947 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-47-23\n",
      "  done: false\n",
      "  episode_len_mean: 170.6\n",
      "  episode_reward_max: 1119.812599537947\n",
      "  episode_reward_mean: 997.2037002722105\n",
      "  episode_reward_min: -56.167971151415344\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 40690\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.226\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 7020000\n",
      "    num_steps_trained: 7020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5022633075714111\n",
      "      kl: 0.026298364624381065\n",
      "      policy_loss: -0.002685014856979251\n",
      "      total_loss: 289.4978332519531\n",
      "      vf_explained_var: 0.9879383444786072\n",
      "      vf_loss: 289.4973449707031\n",
      "    sample_time_ms: 20171.239\n",
      "    update_time_ms: 5.255\n",
      "  iterations_since_restore: 702\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.6018501361053\n",
      "  time_since_restore: 16654.995448350906\n",
      "  time_this_iter_s: 24.03115200996399\n",
      "  time_total_s: 16654.995448350906\n",
      "  timestamp: 1553982443\n",
      "  timesteps_since_restore: 7020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7020000\n",
      "  training_iteration: 702\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16654 s, 702 iter, 7020000 ts, 997 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-47-47\n",
      "  done: false\n",
      "  episode_len_mean: 169.24\n",
      "  episode_reward_max: 1124.1532159241176\n",
      "  episode_reward_mean: 975.8497967918134\n",
      "  episode_reward_min: -77.18808947901759\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 40751\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.938\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 7030000\n",
      "    num_steps_trained: 7030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6945233345031738\n",
      "      kl: 0.018351703882217407\n",
      "      policy_loss: -0.0036698132753372192\n",
      "      total_loss: 1028.0093994140625\n",
      "      vf_explained_var: 0.9565754532814026\n",
      "      vf_loss: 1028.0108642578125\n",
      "    sample_time_ms: 20133.395\n",
      "    update_time_ms: 5.358\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.92489839590667\n",
      "  time_since_restore: 16678.922285556793\n",
      "  time_this_iter_s: 23.92683720588684\n",
      "  time_total_s: 16678.922285556793\n",
      "  timestamp: 1553982467\n",
      "  timesteps_since_restore: 7030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7030000\n",
      "  training_iteration: 703\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16678 s, 703 iter, 7030000 ts, 976 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-48-11\n",
      "  done: false\n",
      "  episode_len_mean: 168.04\n",
      "  episode_reward_max: 1155.8024787203597\n",
      "  episode_reward_mean: 973.1747982197188\n",
      "  episode_reward_min: -77.18808947901759\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 40809\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.575\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 7040000\n",
      "    num_steps_trained: 7040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12063825875520706\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4953848421573639\n",
      "      kl: 0.050459329038858414\n",
      "      policy_loss: 0.0012214595917612314\n",
      "      total_loss: 174.2916717529297\n",
      "      vf_explained_var: 0.9931020736694336\n",
      "      vf_loss: 174.2843780517578\n",
      "    sample_time_ms: 20071.74\n",
      "    update_time_ms: 5.42\n",
      "  iterations_since_restore: 704\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.5873991098595\n",
      "  time_since_restore: 16702.703971385956\n",
      "  time_this_iter_s: 23.781685829162598\n",
      "  time_total_s: 16702.703971385956\n",
      "  timestamp: 1553982491\n",
      "  timesteps_since_restore: 7040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7040000\n",
      "  training_iteration: 704\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16702 s, 704 iter, 7040000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-48-35\n",
      "  done: false\n",
      "  episode_len_mean: 170.38\n",
      "  episode_reward_max: 1155.8024787203597\n",
      "  episode_reward_mean: 998.8961929187562\n",
      "  episode_reward_min: 46.85973839493789\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 40868\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.584\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 7050000\n",
      "    num_steps_trained: 7050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6854672431945801\n",
      "      kl: 0.014393899589776993\n",
      "      policy_loss: -0.00591861130669713\n",
      "      total_loss: 545.036865234375\n",
      "      vf_explained_var: 0.9782487750053406\n",
      "      vf_loss: 545.0401611328125\n",
      "    sample_time_ms: 20109.008\n",
      "    update_time_ms: 5.443\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 499.4480964593783\n",
      "  time_since_restore: 16726.934128284454\n",
      "  time_this_iter_s: 24.230156898498535\n",
      "  time_total_s: 16726.934128284454\n",
      "  timestamp: 1553982515\n",
      "  timesteps_since_restore: 7050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7050000\n",
      "  training_iteration: 705\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16726 s, 705 iter, 7050000 ts, 999 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-48-59\n",
      "  done: false\n",
      "  episode_len_mean: 168.09\n",
      "  episode_reward_max: 1156.7135290619897\n",
      "  episode_reward_mean: 993.9730337379074\n",
      "  episode_reward_min: -23.815902217744252\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 40930\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.416\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 7060000\n",
      "    num_steps_trained: 7060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.41141676902770996\n",
      "      kl: 0.01377079077064991\n",
      "      policy_loss: -0.0008161675650626421\n",
      "      total_loss: 611.7555541992188\n",
      "      vf_explained_var: 0.9733348488807678\n",
      "      vf_loss: 611.75390625\n",
      "    sample_time_ms: 20089.066\n",
      "    update_time_ms: 5.466\n",
      "  iterations_since_restore: 706\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.9865168689537\n",
      "  time_since_restore: 16751.01902937889\n",
      "  time_this_iter_s: 24.084901094436646\n",
      "  time_total_s: 16751.01902937889\n",
      "  timestamp: 1553982539\n",
      "  timesteps_since_restore: 7060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7060000\n",
      "  training_iteration: 706\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16751 s, 706 iter, 7060000 ts, 994 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-49-22\n",
      "  done: false\n",
      "  episode_len_mean: 162.5\n",
      "  episode_reward_max: 1122.9859464094168\n",
      "  episode_reward_mean: 1017.1333025821962\n",
      "  episode_reward_min: -35.921150547826414\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 40991\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.833\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 7070000\n",
      "    num_steps_trained: 7070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5021811127662659\n",
      "      kl: 0.023019475862383842\n",
      "      policy_loss: -0.002168057719245553\n",
      "      total_loss: 319.19024658203125\n",
      "      vf_explained_var: 0.9857060313224792\n",
      "      vf_loss: 319.1882629394531\n",
      "    sample_time_ms: 19988.932\n",
      "    update_time_ms: 5.884\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 508.5666512910981\n",
      "  time_since_restore: 16773.861989974976\n",
      "  time_this_iter_s: 22.842960596084595\n",
      "  time_total_s: 16773.861989974976\n",
      "  timestamp: 1553982562\n",
      "  timesteps_since_restore: 7070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7070000\n",
      "  training_iteration: 707\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16773 s, 707 iter, 7070000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-49-46\n",
      "  done: false\n",
      "  episode_len_mean: 167.75\n",
      "  episode_reward_max: 1130.6356120084365\n",
      "  episode_reward_mean: 986.074415040552\n",
      "  episode_reward_min: -35.921150547826414\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 41050\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.123\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 7080000\n",
      "    num_steps_trained: 7080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8916701078414917\n",
      "      kl: 0.012326793745160103\n",
      "      policy_loss: -0.0019311002688482404\n",
      "      total_loss: 678.2796630859375\n",
      "      vf_explained_var: 0.9713261723518372\n",
      "      vf_loss: 678.2793579101562\n",
      "    sample_time_ms: 19981.267\n",
      "    update_time_ms: 5.708\n",
      "  iterations_since_restore: 708\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.037207520276\n",
      "  time_since_restore: 16797.767576932907\n",
      "  time_this_iter_s: 23.90558695793152\n",
      "  time_total_s: 16797.767576932907\n",
      "  timestamp: 1553982586\n",
      "  timesteps_since_restore: 7080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7080000\n",
      "  training_iteration: 708\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16797 s, 708 iter, 7080000 ts, 986 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-50-10\n",
      "  done: false\n",
      "  episode_len_mean: 175.57\n",
      "  episode_reward_max: 1130.6356120084365\n",
      "  episode_reward_mean: 931.868839779709\n",
      "  episode_reward_min: -62.14124261121191\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 41104\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.571\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 7090000\n",
      "    num_steps_trained: 7090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3206385374069214\n",
      "      kl: 0.015406021848320961\n",
      "      policy_loss: -0.0003655249020084739\n",
      "      total_loss: 847.9354858398438\n",
      "      vf_explained_var: 0.9652757048606873\n",
      "      vf_loss: 847.93310546875\n",
      "    sample_time_ms: 19927.071\n",
      "    update_time_ms: 5.713\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 465.9344198898545\n",
      "  time_since_restore: 16821.313161849976\n",
      "  time_this_iter_s: 23.54558491706848\n",
      "  time_total_s: 16821.313161849976\n",
      "  timestamp: 1553982610\n",
      "  timesteps_since_restore: 7090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7090000\n",
      "  training_iteration: 709\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16821 s, 709 iter, 7090000 ts, 932 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-50-34\n",
      "  done: false\n",
      "  episode_len_mean: 176.76\n",
      "  episode_reward_max: 1162.8818832320806\n",
      "  episode_reward_mean: 919.0560732321447\n",
      "  episode_reward_min: -51.1513928316472\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 41163\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.756\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 7100000\n",
      "    num_steps_trained: 7100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6596737504005432\n",
      "      kl: 0.017344921827316284\n",
      "      policy_loss: -0.0016699368134140968\n",
      "      total_loss: 1081.822265625\n",
      "      vf_explained_var: 0.9538604617118835\n",
      "      vf_loss: 1081.8206787109375\n",
      "    sample_time_ms: 19878.958\n",
      "    update_time_ms: 5.792\n",
      "  iterations_since_restore: 710\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 459.52803661607237\n",
      "  time_since_restore: 16845.145129919052\n",
      "  time_this_iter_s: 23.831968069076538\n",
      "  time_total_s: 16845.145129919052\n",
      "  timestamp: 1553982634\n",
      "  timesteps_since_restore: 7100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7100000\n",
      "  training_iteration: 710\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16845 s, 710 iter, 7100000 ts, 919 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-50-58\n",
      "  done: false\n",
      "  episode_len_mean: 176.18\n",
      "  episode_reward_max: 1133.638338880732\n",
      "  episode_reward_mean: 975.3924838068045\n",
      "  episode_reward_min: -51.1513928316472\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 41219\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.621\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 7110000\n",
      "    num_steps_trained: 7110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8254510760307312\n",
      "      kl: 0.015042963437736034\n",
      "      policy_loss: -0.0029488694854080677\n",
      "      total_loss: 193.85182189941406\n",
      "      vf_explained_var: 0.9913707375526428\n",
      "      vf_loss: 193.85206604003906\n",
      "    sample_time_ms: 19907.165\n",
      "    update_time_ms: 5.86\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.69624190340227\n",
      "  time_since_restore: 16869.226045370102\n",
      "  time_this_iter_s: 24.080915451049805\n",
      "  time_total_s: 16869.226045370102\n",
      "  timestamp: 1553982658\n",
      "  timesteps_since_restore: 7110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7110000\n",
      "  training_iteration: 711\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16869 s, 711 iter, 7110000 ts, 975 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-51-22\n",
      "  done: false\n",
      "  episode_len_mean: 176.25\n",
      "  episode_reward_max: 1133.8006372998207\n",
      "  episode_reward_mean: 991.335166421509\n",
      "  episode_reward_min: -31.28395178011405\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 41274\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.175\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 7120000\n",
      "    num_steps_trained: 7120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.956652820110321\n",
      "      kl: 0.010421703569591045\n",
      "      policy_loss: -0.0022113057784736156\n",
      "      total_loss: 402.0921325683594\n",
      "      vf_explained_var: 0.9836438298225403\n",
      "      vf_loss: 402.09246826171875\n",
      "    sample_time_ms: 19951.432\n",
      "    update_time_ms: 5.95\n",
      "  iterations_since_restore: 712\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.6675832107545\n",
      "  time_since_restore: 16893.661355257034\n",
      "  time_this_iter_s: 24.435309886932373\n",
      "  time_total_s: 16893.661355257034\n",
      "  timestamp: 1553982682\n",
      "  timesteps_since_restore: 7120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7120000\n",
      "  training_iteration: 712\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16893 s, 712 iter, 7120000 ts, 991 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-51-46\n",
      "  done: false\n",
      "  episode_len_mean: 169.29\n",
      "  episode_reward_max: 1135.9228268171573\n",
      "  episode_reward_mean: 986.9105381883761\n",
      "  episode_reward_min: -31.28395178011405\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 41336\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.381\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 7130000\n",
      "    num_steps_trained: 7130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.42880454659461975\n",
      "      kl: 0.014733209274709225\n",
      "      policy_loss: -0.001449273549951613\n",
      "      total_loss: 541.1414184570312\n",
      "      vf_explained_var: 0.9764615297317505\n",
      "      vf_loss: 541.1402587890625\n",
      "    sample_time_ms: 19958.5\n",
      "    update_time_ms: 5.993\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.4552690941881\n",
      "  time_since_restore: 16917.638036251068\n",
      "  time_this_iter_s: 23.976680994033813\n",
      "  time_total_s: 16917.638036251068\n",
      "  timestamp: 1553982706\n",
      "  timesteps_since_restore: 7130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7130000\n",
      "  training_iteration: 713\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16917 s, 713 iter, 7130000 ts, 987 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-52-11\n",
      "  done: false\n",
      "  episode_len_mean: 159.09\n",
      "  episode_reward_max: 1133.8914215527404\n",
      "  episode_reward_mean: 981.7066658654604\n",
      "  episode_reward_min: -74.30934733733069\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 41399\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.126\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 7140000\n",
      "    num_steps_trained: 7140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5042905807495117\n",
      "      kl: 0.014556343667209148\n",
      "      policy_loss: -0.004160112235695124\n",
      "      total_loss: 913.6646728515625\n",
      "      vf_explained_var: 0.9620203971862793\n",
      "      vf_loss: 913.666259765625\n",
      "    sample_time_ms: 19987.231\n",
      "    update_time_ms: 6.329\n",
      "  iterations_since_restore: 714\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.85333293273027\n",
      "  time_since_restore: 16941.769815444946\n",
      "  time_this_iter_s: 24.131779193878174\n",
      "  time_total_s: 16941.769815444946\n",
      "  timestamp: 1553982731\n",
      "  timesteps_since_restore: 7140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7140000\n",
      "  training_iteration: 714\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16941 s, 714 iter, 7140000 ts, 982 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-52-35\n",
      "  done: false\n",
      "  episode_len_mean: 157.73\n",
      "  episode_reward_max: 1133.8914215527404\n",
      "  episode_reward_mean: 953.3604219233048\n",
      "  episode_reward_min: -73.85766866129005\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 41462\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.914\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 7150000\n",
      "    num_steps_trained: 7150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4587228298187256\n",
      "      kl: 0.012159609235823154\n",
      "      policy_loss: -0.002219034591689706\n",
      "      total_loss: 927.2155151367188\n",
      "      vf_explained_var: 0.9633462429046631\n",
      "      vf_loss: 927.2157592773438\n",
      "    sample_time_ms: 19959.479\n",
      "    update_time_ms: 6.31\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.6802109616524\n",
      "  time_since_restore: 16965.71039915085\n",
      "  time_this_iter_s: 23.9405837059021\n",
      "  time_total_s: 16965.71039915085\n",
      "  timestamp: 1553982755\n",
      "  timesteps_since_restore: 7150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7150000\n",
      "  training_iteration: 715\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16965 s, 715 iter, 7150000 ts, 953 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 161.83\n",
      "  episode_reward_max: 1123.0121477942973\n",
      "  episode_reward_mean: 984.5809492867579\n",
      "  episode_reward_min: -37.58809979523585\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 41523\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.708\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 7160000\n",
      "    num_steps_trained: 7160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48411139845848083\n",
      "      kl: 0.016672290861606598\n",
      "      policy_loss: -0.000900411861948669\n",
      "      total_loss: 322.68798828125\n",
      "      vf_explained_var: 0.9856706261634827\n",
      "      vf_loss: 322.6858825683594\n",
      "    sample_time_ms: 19945.516\n",
      "    update_time_ms: 6.457\n",
      "  iterations_since_restore: 716\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.2904746433789\n",
      "  time_since_restore: 16989.688440084457\n",
      "  time_this_iter_s: 23.97804093360901\n",
      "  time_total_s: 16989.688440084457\n",
      "  timestamp: 1553982779\n",
      "  timesteps_since_restore: 7160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7160000\n",
      "  training_iteration: 716\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 16989 s, 716 iter, 7160000 ts, 985 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 167.84\n",
      "  episode_reward_max: 1148.8232851830066\n",
      "  episode_reward_mean: 969.1161470521417\n",
      "  episode_reward_min: -68.65065133705573\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 41582\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.229\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 7170000\n",
      "    num_steps_trained: 7170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7299737334251404\n",
      "      kl: 0.015318936668336391\n",
      "      policy_loss: -0.0012794873910024762\n",
      "      total_loss: 519.111572265625\n",
      "      vf_explained_var: 0.9786112904548645\n",
      "      vf_loss: 519.1100463867188\n",
      "    sample_time_ms: 20027.799\n",
      "    update_time_ms: 6.092\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.5580735260709\n",
      "  time_since_restore: 17013.3084897995\n",
      "  time_this_iter_s: 23.620049715042114\n",
      "  time_total_s: 17013.3084897995\n",
      "  timestamp: 1553982802\n",
      "  timesteps_since_restore: 7170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7170000\n",
      "  training_iteration: 717\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17013 s, 717 iter, 7170000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-53-46\n",
      "  done: false\n",
      "  episode_len_mean: 164.63\n",
      "  episode_reward_max: 1166.4828095943367\n",
      "  episode_reward_mean: 939.8538003622759\n",
      "  episode_reward_min: -94.15377221344382\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 41644\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.559\n",
      "    load_time_ms: 1.708\n",
      "    num_steps_sampled: 7180000\n",
      "    num_steps_trained: 7180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4519663453102112\n",
      "      kl: 0.0156528502702713\n",
      "      policy_loss: -0.0032062947284430265\n",
      "      total_loss: 1079.646484375\n",
      "      vf_explained_var: 0.9559216499328613\n",
      "      vf_loss: 1079.6468505859375\n",
      "    sample_time_ms: 20002.645\n",
      "    update_time_ms: 6.163\n",
      "  iterations_since_restore: 718\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.926900181138\n",
      "  time_since_restore: 17036.980924606323\n",
      "  time_this_iter_s: 23.67243480682373\n",
      "  time_total_s: 17036.980924606323\n",
      "  timestamp: 1553982826\n",
      "  timesteps_since_restore: 7180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7180000\n",
      "  training_iteration: 718\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17036 s, 718 iter, 7180000 ts, 940 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-54-10\n",
      "  done: false\n",
      "  episode_len_mean: 166.54\n",
      "  episode_reward_max: 1166.4828095943367\n",
      "  episode_reward_mean: 954.7113931841269\n",
      "  episode_reward_min: -94.15377221344382\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 41703\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.167\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 7190000\n",
      "    num_steps_trained: 7190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6147651672363281\n",
      "      kl: 0.0137897664681077\n",
      "      policy_loss: -0.00032120561809279025\n",
      "      total_loss: 601.0546875\n",
      "      vf_explained_var: 0.9755067229270935\n",
      "      vf_loss: 601.052490234375\n",
      "    sample_time_ms: 19997.899\n",
      "    update_time_ms: 6.115\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.3556965920634\n",
      "  time_since_restore: 17060.584822177887\n",
      "  time_this_iter_s: 23.60389757156372\n",
      "  time_total_s: 17060.584822177887\n",
      "  timestamp: 1553982850\n",
      "  timesteps_since_restore: 7190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7190000\n",
      "  training_iteration: 719\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17060 s, 719 iter, 7190000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-54-34\n",
      "  done: false\n",
      "  episode_len_mean: 174.18\n",
      "  episode_reward_max: 1149.9910599505906\n",
      "  episode_reward_mean: 998.0066951506564\n",
      "  episode_reward_min: -41.53331764725351\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 41758\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.401\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 7200000\n",
      "    num_steps_trained: 7200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9475443959236145\n",
      "      kl: 0.02057955227792263\n",
      "      policy_loss: -0.0013059438206255436\n",
      "      total_loss: 379.06524658203125\n",
      "      vf_explained_var: 0.9846482872962952\n",
      "      vf_loss: 379.0628356933594\n",
      "    sample_time_ms: 20023.109\n",
      "    update_time_ms: 6.114\n",
      "  iterations_since_restore: 720\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 499.00334757532823\n",
      "  time_since_restore: 17084.738370895386\n",
      "  time_this_iter_s: 24.15354871749878\n",
      "  time_total_s: 17084.738370895386\n",
      "  timestamp: 1553982874\n",
      "  timesteps_since_restore: 7200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7200000\n",
      "  training_iteration: 720\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17084 s, 720 iter, 7200000 ts, 998 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-54-58\n",
      "  done: false\n",
      "  episode_len_mean: 169.54\n",
      "  episode_reward_max: 1154.3934385551954\n",
      "  episode_reward_mean: 1003.320665850899\n",
      "  episode_reward_min: -37.77479682409796\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 41818\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.417\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 7210000\n",
      "    num_steps_trained: 7210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49333906173706055\n",
      "      kl: 0.01015227846801281\n",
      "      policy_loss: -0.0005661942414008081\n",
      "      total_loss: 670.8712768554688\n",
      "      vf_explained_var: 0.9691537618637085\n",
      "      vf_loss: 670.8701171875\n",
      "    sample_time_ms: 20010.531\n",
      "    update_time_ms: 5.97\n",
      "  iterations_since_restore: 721\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 501.6603329254495\n",
      "  time_since_restore: 17108.672815084457\n",
      "  time_this_iter_s: 23.934444189071655\n",
      "  time_total_s: 17108.672815084457\n",
      "  timestamp: 1553982898\n",
      "  timesteps_since_restore: 7210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7210000\n",
      "  training_iteration: 721\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17108 s, 721 iter, 7210000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-55-22\n",
      "  done: false\n",
      "  episode_len_mean: 170.86\n",
      "  episode_reward_max: 1154.3934385551954\n",
      "  episode_reward_mean: 994.6055174620094\n",
      "  episode_reward_min: -37.77479682409796\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 41875\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.953\n",
      "    load_time_ms: 1.726\n",
      "    num_steps_sampled: 7220000\n",
      "    num_steps_trained: 7220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7933641076087952\n",
      "      kl: 0.01440302561968565\n",
      "      policy_loss: -0.004487981088459492\n",
      "      total_loss: 465.0538330078125\n",
      "      vf_explained_var: 0.980840802192688\n",
      "      vf_loss: 465.0556945800781\n",
      "    sample_time_ms: 19943.549\n",
      "    update_time_ms: 6.059\n",
      "  iterations_since_restore: 722\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.3027587310047\n",
      "  time_since_restore: 17132.446064710617\n",
      "  time_this_iter_s: 23.773249626159668\n",
      "  time_total_s: 17132.446064710617\n",
      "  timestamp: 1553982922\n",
      "  timesteps_since_restore: 7220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7220000\n",
      "  training_iteration: 722\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17132 s, 722 iter, 7220000 ts, 995 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-55-46\n",
      "  done: false\n",
      "  episode_len_mean: 174.77\n",
      "  episode_reward_max: 1149.015533149883\n",
      "  episode_reward_mean: 957.3676337047409\n",
      "  episode_reward_min: -35.758868239422924\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 41934\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.956\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 7230000\n",
      "    num_steps_trained: 7230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9304353594779968\n",
      "      kl: 0.011813473887741566\n",
      "      policy_loss: -0.0007294428651221097\n",
      "      total_loss: 1344.94091796875\n",
      "      vf_explained_var: 0.9502561688423157\n",
      "      vf_loss: 1344.9393310546875\n",
      "    sample_time_ms: 19942.255\n",
      "    update_time_ms: 5.891\n",
      "  iterations_since_restore: 723\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.68381685237034\n",
      "  time_since_restore: 17156.401127815247\n",
      "  time_this_iter_s: 23.955063104629517\n",
      "  time_total_s: 17156.401127815247\n",
      "  timestamp: 1553982946\n",
      "  timesteps_since_restore: 7230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7230000\n",
      "  training_iteration: 723\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17156 s, 723 iter, 7230000 ts, 957 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-56-09\n",
      "  done: false\n",
      "  episode_len_mean: 165.17\n",
      "  episode_reward_max: 1151.2034904088887\n",
      "  episode_reward_mean: 958.794543034782\n",
      "  episode_reward_min: -96.65687804494037\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 41996\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.12\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 7240000\n",
      "    num_steps_trained: 7240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4506012499332428\n",
      "      kl: 0.013795445673167706\n",
      "      policy_loss: -0.0012702560052275658\n",
      "      total_loss: 798.7699584960938\n",
      "      vf_explained_var: 0.9661779999732971\n",
      "      vf_loss: 798.7687377929688\n",
      "    sample_time_ms: 19914.23\n",
      "    update_time_ms: 5.447\n",
      "  iterations_since_restore: 724\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.39727151739106\n",
      "  time_since_restore: 17180.280817747116\n",
      "  time_this_iter_s: 23.879689931869507\n",
      "  time_total_s: 17180.280817747116\n",
      "  timestamp: 1553982969\n",
      "  timesteps_since_restore: 7240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7240000\n",
      "  training_iteration: 724\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17180 s, 724 iter, 7240000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-56-34\n",
      "  done: false\n",
      "  episode_len_mean: 169.75\n",
      "  episode_reward_max: 1151.2034904088887\n",
      "  episode_reward_mean: 985.5430045718912\n",
      "  episode_reward_min: -96.65687804494037\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 42054\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.224\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 7250000\n",
      "    num_steps_trained: 7250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7373307347297668\n",
      "      kl: 0.017360538244247437\n",
      "      policy_loss: -0.001690433593466878\n",
      "      total_loss: 279.16680908203125\n",
      "      vf_explained_var: 0.9878538250923157\n",
      "      vf_loss: 279.1653747558594\n",
      "    sample_time_ms: 19943.664\n",
      "    update_time_ms: 5.488\n",
      "  iterations_since_restore: 725\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.7715022859457\n",
      "  time_since_restore: 17204.534321784973\n",
      "  time_this_iter_s: 24.253504037857056\n",
      "  time_total_s: 17204.534321784973\n",
      "  timestamp: 1553982994\n",
      "  timesteps_since_restore: 7250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7250000\n",
      "  training_iteration: 725\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17204 s, 725 iter, 7250000 ts, 986 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-56-58\n",
      "  done: false\n",
      "  episode_len_mean: 171.64\n",
      "  episode_reward_max: 1135.9159066379873\n",
      "  episode_reward_mean: 972.9588995342118\n",
      "  episode_reward_min: -68.33841742338728\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 42113\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.709\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 7260000\n",
      "    num_steps_trained: 7260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6397736668586731\n",
      "      kl: 0.011630004271864891\n",
      "      policy_loss: -0.0008209309307858348\n",
      "      total_loss: 440.3726501464844\n",
      "      vf_explained_var: 0.9816299676895142\n",
      "      vf_loss: 440.371337890625\n",
      "    sample_time_ms: 19978.196\n",
      "    update_time_ms: 4.998\n",
      "  iterations_since_restore: 726\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.47944976710585\n",
      "  time_since_restore: 17228.87482070923\n",
      "  time_this_iter_s: 24.34049892425537\n",
      "  time_total_s: 17228.87482070923\n",
      "  timestamp: 1553983018\n",
      "  timesteps_since_restore: 7260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7260000\n",
      "  training_iteration: 726\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17228 s, 726 iter, 7260000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-57-23\n",
      "  done: false\n",
      "  episode_len_mean: 163.26\n",
      "  episode_reward_max: 1120.1514575436815\n",
      "  episode_reward_mean: 969.9004144406604\n",
      "  episode_reward_min: -68.33841742338728\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 42175\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3920.337\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 7270000\n",
      "    num_steps_trained: 7270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.46594879031181335\n",
      "      kl: 0.015211627818644047\n",
      "      policy_loss: -0.001890909974463284\n",
      "      total_loss: 613.2598876953125\n",
      "      vf_explained_var: 0.9733720421791077\n",
      "      vf_loss: 613.2590942382812\n",
      "    sample_time_ms: 20053.537\n",
      "    update_time_ms: 5.04\n",
      "  iterations_since_restore: 727\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.9502072203302\n",
      "  time_since_restore: 17253.298397541046\n",
      "  time_this_iter_s: 24.423576831817627\n",
      "  time_total_s: 17253.298397541046\n",
      "  timestamp: 1553983043\n",
      "  timesteps_since_restore: 7270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7270000\n",
      "  training_iteration: 727\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17253 s, 727 iter, 7270000 ts, 970 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-57-47\n",
      "  done: false\n",
      "  episode_len_mean: 162.19\n",
      "  episode_reward_max: 1143.588560126867\n",
      "  episode_reward_mean: 962.4970912328773\n",
      "  episode_reward_min: -9.185892859087232\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 42237\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.279\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 7280000\n",
      "    num_steps_trained: 7280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5201651453971863\n",
      "      kl: 0.01524819154292345\n",
      "      policy_loss: -0.002142871031537652\n",
      "      total_loss: 1080.0321044921875\n",
      "      vf_explained_var: 0.9575369358062744\n",
      "      vf_loss: 1080.0313720703125\n",
      "    sample_time_ms: 20109.967\n",
      "    update_time_ms: 4.939\n",
      "  iterations_since_restore: 728\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.24854561643866\n",
      "  time_since_restore: 17277.509722948074\n",
      "  time_this_iter_s: 24.2113254070282\n",
      "  time_total_s: 17277.509722948074\n",
      "  timestamp: 1553983067\n",
      "  timesteps_since_restore: 7280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7280000\n",
      "  training_iteration: 728\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17277 s, 728 iter, 7280000 ts, 962 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-58-11\n",
      "  done: false\n",
      "  episode_len_mean: 157.34\n",
      "  episode_reward_max: 1144.0974044042398\n",
      "  episode_reward_mean: 956.2948773849726\n",
      "  episode_reward_min: -21.942709432472327\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 42299\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.513\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 7290000\n",
      "    num_steps_trained: 7290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5055069923400879\n",
      "      kl: 0.016635650768876076\n",
      "      policy_loss: -0.0016214504139497876\n",
      "      total_loss: 867.4985961914062\n",
      "      vf_explained_var: 0.9639992117881775\n",
      "      vf_loss: 867.4971923828125\n",
      "    sample_time_ms: 20198.003\n",
      "    update_time_ms: 5.301\n",
      "  iterations_since_restore: 729\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.14743869248633\n",
      "  time_since_restore: 17301.809051036835\n",
      "  time_this_iter_s: 24.299328088760376\n",
      "  time_total_s: 17301.809051036835\n",
      "  timestamp: 1553983091\n",
      "  timesteps_since_restore: 7290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7290000\n",
      "  training_iteration: 729\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17301 s, 729 iter, 7290000 ts, 956 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-58-35\n",
      "  done: false\n",
      "  episode_len_mean: 163.29\n",
      "  episode_reward_max: 1144.0974044042398\n",
      "  episode_reward_mean: 966.7215688096009\n",
      "  episode_reward_min: -62.435543206239885\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 42361\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.735\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 7300000\n",
      "    num_steps_trained: 7300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5011564493179321\n",
      "      kl: 0.010595685802400112\n",
      "      policy_loss: -0.0015666538383811712\n",
      "      total_loss: 959.3060913085938\n",
      "      vf_explained_var: 0.9598960876464844\n",
      "      vf_loss: 959.3056640625\n",
      "    sample_time_ms: 20114.173\n",
      "    update_time_ms: 5.636\n",
      "  iterations_since_restore: 730\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.36078440480037\n",
      "  time_since_restore: 17325.071724653244\n",
      "  time_this_iter_s: 23.2626736164093\n",
      "  time_total_s: 17325.071724653244\n",
      "  timestamp: 1553983115\n",
      "  timesteps_since_restore: 7300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7300000\n",
      "  training_iteration: 730\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17325 s, 730 iter, 7300000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-58-58\n",
      "  done: false\n",
      "  episode_len_mean: 173.22\n",
      "  episode_reward_max: 1131.427342795749\n",
      "  episode_reward_mean: 962.4994740648295\n",
      "  episode_reward_min: -62.435543206239885\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 42415\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.41\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 7310000\n",
      "    num_steps_trained: 7310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.18095742166042328\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0704212188720703\n",
      "      kl: 0.009552047587931156\n",
      "      policy_loss: -0.0012524941703304648\n",
      "      total_loss: 825.097412109375\n",
      "      vf_explained_var: 0.9655981063842773\n",
      "      vf_loss: 825.096923828125\n",
      "    sample_time_ms: 20030.787\n",
      "    update_time_ms: 6.345\n",
      "  iterations_since_restore: 731\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.2497370324148\n",
      "  time_since_restore: 17348.195161819458\n",
      "  time_this_iter_s: 23.12343716621399\n",
      "  time_total_s: 17348.195161819458\n",
      "  timestamp: 1553983138\n",
      "  timesteps_since_restore: 7310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7310000\n",
      "  training_iteration: 731\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17348 s, 731 iter, 7310000 ts, 962 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-59-21\n",
      "  done: false\n",
      "  episode_len_mean: 169.57\n",
      "  episode_reward_max: 1129.9322414520582\n",
      "  episode_reward_mean: 961.6085688866019\n",
      "  episode_reward_min: -17.516136526718043\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 42477\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.951\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 7320000\n",
      "    num_steps_trained: 7320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09047871083021164\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4349183440208435\n",
      "      kl: 0.020343247801065445\n",
      "      policy_loss: 0.0006830355850979686\n",
      "      total_loss: 814.1178588867188\n",
      "      vf_explained_var: 0.9677742123603821\n",
      "      vf_loss: 814.115234375\n",
      "    sample_time_ms: 19965.685\n",
      "    update_time_ms: 6.267\n",
      "  iterations_since_restore: 732\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.80428444330084\n",
      "  time_since_restore: 17371.311012506485\n",
      "  time_this_iter_s: 23.115850687026978\n",
      "  time_total_s: 17371.311012506485\n",
      "  timestamp: 1553983161\n",
      "  timesteps_since_restore: 7320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7320000\n",
      "  training_iteration: 732\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17371 s, 732 iter, 7320000 ts, 962 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_22-59-44\n",
      "  done: false\n",
      "  episode_len_mean: 172.09\n",
      "  episode_reward_max: 1122.5448815133118\n",
      "  episode_reward_mean: 973.6035104648392\n",
      "  episode_reward_min: -80.0838360036679\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 42533\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.516\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 7330000\n",
      "    num_steps_trained: 7330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09047871083021164\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9153227210044861\n",
      "      kl: 0.02580646425485611\n",
      "      policy_loss: -0.003905880032107234\n",
      "      total_loss: 526.4387817382812\n",
      "      vf_explained_var: 0.980610191822052\n",
      "      vf_loss: 526.4403076171875\n",
      "    sample_time_ms: 19856.273\n",
      "    update_time_ms: 6.412\n",
      "  iterations_since_restore: 733\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.8017552324197\n",
      "  time_since_restore: 17394.183795452118\n",
      "  time_this_iter_s: 22.872782945632935\n",
      "  time_total_s: 17394.183795452118\n",
      "  timestamp: 1553983184\n",
      "  timesteps_since_restore: 7330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7330000\n",
      "  training_iteration: 733\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17394 s, 733 iter, 7330000 ts, 974 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-00-08\n",
      "  done: false\n",
      "  episode_len_mean: 171.35\n",
      "  episode_reward_max: 1128.6651414917026\n",
      "  episode_reward_mean: 964.2060985139688\n",
      "  episode_reward_min: -80.0838360036679\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 42595\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.813\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 7340000\n",
      "    num_steps_trained: 7340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09047871083021164\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.476581335067749\n",
      "      kl: 0.022339867427945137\n",
      "      policy_loss: -0.001841141958720982\n",
      "      total_loss: 701.861572265625\n",
      "      vf_explained_var: 0.9716902375221252\n",
      "      vf_loss: 701.8613891601562\n",
      "    sample_time_ms: 19842.294\n",
      "    update_time_ms: 6.617\n",
      "  iterations_since_restore: 734\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.1030492569844\n",
      "  time_since_restore: 17417.8754029274\n",
      "  time_this_iter_s: 23.69160747528076\n",
      "  time_total_s: 17417.8754029274\n",
      "  timestamp: 1553983208\n",
      "  timesteps_since_restore: 7340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7340000\n",
      "  training_iteration: 734\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17417 s, 734 iter, 7340000 ts, 964 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-00-31\n",
      "  done: false\n",
      "  episode_len_mean: 167.42\n",
      "  episode_reward_max: 1128.6651414917026\n",
      "  episode_reward_mean: 973.1822331028997\n",
      "  episode_reward_min: -79.41701701621518\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 42653\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.62\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 7350000\n",
      "    num_steps_trained: 7350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09047871083021164\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7186160087585449\n",
      "      kl: 0.029382964596152306\n",
      "      policy_loss: -0.005995729472488165\n",
      "      total_loss: 1055.181640625\n",
      "      vf_explained_var: 0.9546979069709778\n",
      "      vf_loss: 1055.1849365234375\n",
      "    sample_time_ms: 19787.145\n",
      "    update_time_ms: 6.756\n",
      "  iterations_since_restore: 735\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.59111655144966\n",
      "  time_since_restore: 17441.559397935867\n",
      "  time_this_iter_s: 23.683995008468628\n",
      "  time_total_s: 17441.559397935867\n",
      "  timestamp: 1553983231\n",
      "  timesteps_since_restore: 7350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7350000\n",
      "  training_iteration: 735\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17441 s, 735 iter, 7350000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-00-55\n",
      "  done: false\n",
      "  episode_len_mean: 167.03\n",
      "  episode_reward_max: 1150.1258889234896\n",
      "  episode_reward_mean: 983.6694275606591\n",
      "  episode_reward_min: -72.38909579310224\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 42713\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.585\n",
      "    load_time_ms: 1.734\n",
      "    num_steps_sampled: 7360000\n",
      "    num_steps_trained: 7360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09047871083021164\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5892574787139893\n",
      "      kl: 0.02132253535091877\n",
      "      policy_loss: -0.002065315842628479\n",
      "      total_loss: 701.4130859375\n",
      "      vf_explained_var: 0.9705168604850769\n",
      "      vf_loss: 701.4131469726562\n",
      "    sample_time_ms: 19731.774\n",
      "    update_time_ms: 6.883\n",
      "  iterations_since_restore: 736\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.8347137803295\n",
      "  time_since_restore: 17465.327605962753\n",
      "  time_this_iter_s: 23.768208026885986\n",
      "  time_total_s: 17465.327605962753\n",
      "  timestamp: 1553983255\n",
      "  timesteps_since_restore: 7360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7360000\n",
      "  training_iteration: 736\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17465 s, 736 iter, 7360000 ts, 984 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-01-19\n",
      "  done: false\n",
      "  episode_len_mean: 163.2\n",
      "  episode_reward_max: 1150.1258889234896\n",
      "  episode_reward_mean: 967.9524313893413\n",
      "  episode_reward_min: -72.38909579310224\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 42775\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.16\n",
      "    load_time_ms: 1.686\n",
      "    num_steps_sampled: 7370000\n",
      "    num_steps_trained: 7370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09047871083021164\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.50569748878479\n",
      "      kl: 0.048608992248773575\n",
      "      policy_loss: -0.00033809131127782166\n",
      "      total_loss: 688.7011108398438\n",
      "      vf_explained_var: 0.9739975333213806\n",
      "      vf_loss: 688.6971435546875\n",
      "    sample_time_ms: 19667.712\n",
      "    update_time_ms: 6.89\n",
      "  iterations_since_restore: 737\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.97621569467066\n",
      "  time_since_restore: 17489.070868253708\n",
      "  time_this_iter_s: 23.74326229095459\n",
      "  time_total_s: 17489.070868253708\n",
      "  timestamp: 1553983279\n",
      "  timesteps_since_restore: 7370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7370000\n",
      "  training_iteration: 737\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17489 s, 737 iter, 7370000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-01-43\n",
      "  done: false\n",
      "  episode_len_mean: 167.33\n",
      "  episode_reward_max: 1133.087682647863\n",
      "  episode_reward_mean: 975.8114722535048\n",
      "  episode_reward_min: -29.19459639436667\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 42834\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.642\n",
      "    load_time_ms: 1.67\n",
      "    num_steps_sampled: 7380000\n",
      "    num_steps_trained: 7380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49992212653160095\n",
      "      kl: 0.015582540072500706\n",
      "      policy_loss: -0.0012063747271895409\n",
      "      total_loss: 529.985595703125\n",
      "      vf_explained_var: 0.9779140949249268\n",
      "      vf_loss: 529.9846801757812\n",
      "    sample_time_ms: 19615.754\n",
      "    update_time_ms: 6.893\n",
      "  iterations_since_restore: 738\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.9057361267524\n",
      "  time_since_restore: 17512.725155353546\n",
      "  time_this_iter_s: 23.654287099838257\n",
      "  time_total_s: 17512.725155353546\n",
      "  timestamp: 1553983303\n",
      "  timesteps_since_restore: 7380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7380000\n",
      "  training_iteration: 738\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17512 s, 738 iter, 7380000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-02-05\n",
      "  done: false\n",
      "  episode_len_mean: 167.72\n",
      "  episode_reward_max: 1123.9560304966851\n",
      "  episode_reward_mean: 995.9510869802708\n",
      "  episode_reward_min: -2.764499483230992\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 42893\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.886\n",
      "    load_time_ms: 1.703\n",
      "    num_steps_sampled: 7390000\n",
      "    num_steps_trained: 7390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5187891721725464\n",
      "      kl: 0.02496262826025486\n",
      "      policy_loss: -0.004124775994569063\n",
      "      total_loss: 251.69781494140625\n",
      "      vf_explained_var: 0.9905897974967957\n",
      "      vf_loss: 251.6985626220703\n",
      "    sample_time_ms: 19477.718\n",
      "    update_time_ms: 6.532\n",
      "  iterations_since_restore: 739\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.9755434901353\n",
      "  time_since_restore: 17535.623007059097\n",
      "  time_this_iter_s: 22.897851705551147\n",
      "  time_total_s: 17535.623007059097\n",
      "  timestamp: 1553983325\n",
      "  timesteps_since_restore: 7390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7390000\n",
      "  training_iteration: 739\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17535 s, 739 iter, 7390000 ts, 996 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-02-28\n",
      "  done: false\n",
      "  episode_len_mean: 175.45\n",
      "  episode_reward_max: 1111.126162930745\n",
      "  episode_reward_mean: 980.4250950609378\n",
      "  episode_reward_min: -68.47815530071662\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 42949\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.605\n",
      "    load_time_ms: 1.687\n",
      "    num_steps_sampled: 7400000\n",
      "    num_steps_trained: 7400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7842811346054077\n",
      "      kl: 0.018404146656394005\n",
      "      policy_loss: -0.003618309972807765\n",
      "      total_loss: 569.5151977539062\n",
      "      vf_explained_var: 0.9744077920913696\n",
      "      vf_loss: 569.5164184570312\n",
      "    sample_time_ms: 19414.312\n",
      "    update_time_ms: 6.112\n",
      "  iterations_since_restore: 740\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.212547530469\n",
      "  time_since_restore: 17558.31369948387\n",
      "  time_this_iter_s: 22.69069242477417\n",
      "  time_total_s: 17558.31369948387\n",
      "  timestamp: 1553983348\n",
      "  timesteps_since_restore: 7400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7400000\n",
      "  training_iteration: 740\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17558 s, 740 iter, 7400000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-02-51\n",
      "  done: false\n",
      "  episode_len_mean: 181.58\n",
      "  episode_reward_max: 1148.7717335730995\n",
      "  episode_reward_mean: 971.6896964842781\n",
      "  episode_reward_min: -68.47815530071662\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 43004\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.795\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 7410000\n",
      "    num_steps_trained: 7410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.054065465927124\n",
      "      kl: 0.014968049712479115\n",
      "      policy_loss: -0.0011872604954987764\n",
      "      total_loss: 446.9949951171875\n",
      "      vf_explained_var: 0.9816399812698364\n",
      "      vf_loss: 446.994140625\n",
      "    sample_time_ms: 19419.872\n",
      "    update_time_ms: 5.57\n",
      "  iterations_since_restore: 741\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.8448482421391\n",
      "  time_since_restore: 17581.46750998497\n",
      "  time_this_iter_s: 23.153810501098633\n",
      "  time_total_s: 17581.46750998497\n",
      "  timestamp: 1553983371\n",
      "  timesteps_since_restore: 7410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7410000\n",
      "  training_iteration: 741\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17581 s, 741 iter, 7410000 ts, 972 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-03-14\n",
      "  done: false\n",
      "  episode_len_mean: 178.42\n",
      "  episode_reward_max: 1143.6636304666504\n",
      "  episode_reward_mean: 961.2077685679832\n",
      "  episode_reward_min: -57.39151466305188\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 43061\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.29\n",
      "    load_time_ms: 1.763\n",
      "    num_steps_sampled: 7420000\n",
      "    num_steps_trained: 7420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2058534622192383\n",
      "      kl: 0.016306186094880104\n",
      "      policy_loss: -0.003509323112666607\n",
      "      total_loss: 706.5399780273438\n",
      "      vf_explained_var: 0.9717076420783997\n",
      "      vf_loss: 706.541259765625\n",
      "    sample_time_ms: 19398.187\n",
      "    update_time_ms: 5.571\n",
      "  iterations_since_restore: 742\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.60388428399165\n",
      "  time_since_restore: 17604.32691502571\n",
      "  time_this_iter_s: 22.859405040740967\n",
      "  time_total_s: 17604.32691502571\n",
      "  timestamp: 1553983394\n",
      "  timesteps_since_restore: 7420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7420000\n",
      "  training_iteration: 742\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17604 s, 742 iter, 7420000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-03-37\n",
      "  done: false\n",
      "  episode_len_mean: 167.2\n",
      "  episode_reward_max: 1142.8243435447291\n",
      "  episode_reward_mean: 974.194848602299\n",
      "  episode_reward_min: -69.67008117847286\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 43121\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.122\n",
      "    load_time_ms: 1.722\n",
      "    num_steps_sampled: 7430000\n",
      "    num_steps_trained: 7430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.47688108682632446\n",
      "      kl: 0.022211147472262383\n",
      "      policy_loss: -0.0034004212357103825\n",
      "      total_loss: 540.2567138671875\n",
      "      vf_explained_var: 0.9752631783485413\n",
      "      vf_loss: 540.2571411132812\n",
      "    sample_time_ms: 19399.391\n",
      "    update_time_ms: 5.586\n",
      "  iterations_since_restore: 743\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.0974243011496\n",
      "  time_since_restore: 17627.30784010887\n",
      "  time_this_iter_s: 22.9809250831604\n",
      "  time_total_s: 17627.30784010887\n",
      "  timestamp: 1553983417\n",
      "  timesteps_since_restore: 7430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7430000\n",
      "  training_iteration: 743\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17627 s, 743 iter, 7430000 ts, 974 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-04-00\n",
      "  done: false\n",
      "  episode_len_mean: 166.49\n",
      "  episode_reward_max: 1140.5743282720362\n",
      "  episode_reward_mean: 969.5223565616338\n",
      "  episode_reward_min: -87.77566023710665\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 43182\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.37\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 7440000\n",
      "    num_steps_trained: 7440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6330253481864929\n",
      "      kl: 0.017450490966439247\n",
      "      policy_loss: -0.002689954126253724\n",
      "      total_loss: 705.0107421875\n",
      "      vf_explained_var: 0.9714094996452332\n",
      "      vf_loss: 705.0110473632812\n",
      "    sample_time_ms: 19285.828\n",
      "    update_time_ms: 5.532\n",
      "  iterations_since_restore: 744\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.761178280817\n",
      "  time_since_restore: 17649.764806747437\n",
      "  time_this_iter_s: 22.456966638565063\n",
      "  time_total_s: 17649.764806747437\n",
      "  timestamp: 1553983440\n",
      "  timesteps_since_restore: 7440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7440000\n",
      "  training_iteration: 744\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17649 s, 744 iter, 7440000 ts, 970 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-04-23\n",
      "  done: false\n",
      "  episode_len_mean: 165.72\n",
      "  episode_reward_max: 1143.5726817822995\n",
      "  episode_reward_mean: 961.4341538643733\n",
      "  episode_reward_min: -87.93106223369631\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 43241\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.992\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 7450000\n",
      "    num_steps_trained: 7450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7821834087371826\n",
      "      kl: 0.015695558860898018\n",
      "      policy_loss: 0.0007460124907083809\n",
      "      total_loss: 778.4761352539062\n",
      "      vf_explained_var: 0.9718022346496582\n",
      "      vf_loss: 778.4732666015625\n",
      "    sample_time_ms: 19282.367\n",
      "    update_time_ms: 5.36\n",
      "  iterations_since_restore: 745\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.7170769321866\n",
      "  time_since_restore: 17673.393746614456\n",
      "  time_this_iter_s: 23.628939867019653\n",
      "  time_total_s: 17673.393746614456\n",
      "  timestamp: 1553983463\n",
      "  timesteps_since_restore: 7450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7450000\n",
      "  training_iteration: 745\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17673 s, 745 iter, 7450000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-04-47\n",
      "  done: false\n",
      "  episode_len_mean: 164.99\n",
      "  episode_reward_max: 1143.5726817822995\n",
      "  episode_reward_mean: 939.4607094925337\n",
      "  episode_reward_min: -87.93106223369631\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 43303\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3874.103\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 7460000\n",
      "    num_steps_trained: 7460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5368986129760742\n",
      "      kl: 0.01703091897070408\n",
      "      policy_loss: -0.0009703634423203766\n",
      "      total_loss: 659.2374267578125\n",
      "      vf_explained_var: 0.971987783908844\n",
      "      vf_loss: 659.2362060546875\n",
      "    sample_time_ms: 19283.307\n",
      "    update_time_ms: 5.099\n",
      "  iterations_since_restore: 746\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.7303547462668\n",
      "  time_since_restore: 17697.14288687706\n",
      "  time_this_iter_s: 23.74914026260376\n",
      "  time_total_s: 17697.14288687706\n",
      "  timestamp: 1553983487\n",
      "  timesteps_since_restore: 7460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7460000\n",
      "  training_iteration: 746\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17697 s, 746 iter, 7460000 ts, 939 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-05-11\n",
      "  done: false\n",
      "  episode_len_mean: 171.64\n",
      "  episode_reward_max: 1160.243359013133\n",
      "  episode_reward_mean: 977.5174216426318\n",
      "  episode_reward_min: -97.51426607553454\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 43360\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.449\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 7470000\n",
      "    num_steps_trained: 7470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8919026255607605\n",
      "      kl: 0.01355251856148243\n",
      "      policy_loss: -0.0008894504862837493\n",
      "      total_loss: 674.3648071289062\n",
      "      vf_explained_var: 0.9702433943748474\n",
      "      vf_loss: 674.36376953125\n",
      "    sample_time_ms: 19278.195\n",
      "    update_time_ms: 5.026\n",
      "  iterations_since_restore: 747\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.7587108213159\n",
      "  time_since_restore: 17720.900460481644\n",
      "  time_this_iter_s: 23.75757360458374\n",
      "  time_total_s: 17720.900460481644\n",
      "  timestamp: 1553983511\n",
      "  timesteps_since_restore: 7470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7470000\n",
      "  training_iteration: 747\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17720 s, 747 iter, 7470000 ts, 978 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-05-35\n",
      "  done: false\n",
      "  episode_len_mean: 164.13\n",
      "  episode_reward_max: 1160.243359013133\n",
      "  episode_reward_mean: 954.652968032279\n",
      "  episode_reward_min: -97.51426607553454\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 43422\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.75\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 7480000\n",
      "    num_steps_trained: 7480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4538857936859131\n",
      "      kl: 0.015314903110265732\n",
      "      policy_loss: -0.0008967824396677315\n",
      "      total_loss: 830.839111328125\n",
      "      vf_explained_var: 0.9649321436882019\n",
      "      vf_loss: 830.837890625\n",
      "    sample_time_ms: 19271.647\n",
      "    update_time_ms: 5.153\n",
      "  iterations_since_restore: 748\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.32648401613943\n",
      "  time_since_restore: 17744.53515100479\n",
      "  time_this_iter_s: 23.634690523147583\n",
      "  time_total_s: 17744.53515100479\n",
      "  timestamp: 1553983535\n",
      "  timesteps_since_restore: 7480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7480000\n",
      "  training_iteration: 748\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17744 s, 748 iter, 7480000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-05-58\n",
      "  done: false\n",
      "  episode_len_mean: 160.43\n",
      "  episode_reward_max: 1155.8231252155558\n",
      "  episode_reward_mean: 954.2942045860632\n",
      "  episode_reward_min: -69.56640572806259\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 43484\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.521\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 7490000\n",
      "    num_steps_trained: 7490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5774997472763062\n",
      "      kl: 0.019899530336260796\n",
      "      policy_loss: -0.00350583135150373\n",
      "      total_loss: 1050.8922119140625\n",
      "      vf_explained_var: 0.955775260925293\n",
      "      vf_loss: 1050.89306640625\n",
      "    sample_time_ms: 19338.612\n",
      "    update_time_ms: 5.155\n",
      "  iterations_since_restore: 749\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.1471022930315\n",
      "  time_since_restore: 17768.08069372177\n",
      "  time_this_iter_s: 23.54554271697998\n",
      "  time_total_s: 17768.08069372177\n",
      "  timestamp: 1553983558\n",
      "  timesteps_since_restore: 7490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7490000\n",
      "  training_iteration: 749\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17768 s, 749 iter, 7490000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-06-22\n",
      "  done: false\n",
      "  episode_len_mean: 159.05\n",
      "  episode_reward_max: 1155.8231252155558\n",
      "  episode_reward_mean: 962.2111437265526\n",
      "  episode_reward_min: -26.08126007147382\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 43548\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.34\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 7500000\n",
      "    num_steps_trained: 7500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.38649189472198486\n",
      "      kl: 0.016967305913567543\n",
      "      policy_loss: 0.0007860903278924525\n",
      "      total_loss: 666.0684204101562\n",
      "      vf_explained_var: 0.9727217555046082\n",
      "      vf_loss: 666.0653076171875\n",
      "    sample_time_ms: 19424.669\n",
      "    update_time_ms: 5.199\n",
      "  iterations_since_restore: 750\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.1055718632761\n",
      "  time_since_restore: 17791.58204817772\n",
      "  time_this_iter_s: 23.501354455947876\n",
      "  time_total_s: 17791.58204817772\n",
      "  timestamp: 1553983582\n",
      "  timesteps_since_restore: 7500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7500000\n",
      "  training_iteration: 750\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17791 s, 750 iter, 7500000 ts, 962 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-06-46\n",
      "  done: false\n",
      "  episode_len_mean: 159.46\n",
      "  episode_reward_max: 1112.889399584837\n",
      "  episode_reward_mean: 967.413323901997\n",
      "  episode_reward_min: -53.64949173034239\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 43611\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3874.839\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 7510000\n",
      "    num_steps_trained: 7510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.35559675097465515\n",
      "      kl: 0.015886716544628143\n",
      "      policy_loss: 0.00027250632410869\n",
      "      total_loss: 786.3617553710938\n",
      "      vf_explained_var: 0.9699869155883789\n",
      "      vf_loss: 786.3592529296875\n",
      "    sample_time_ms: 19517.963\n",
      "    update_time_ms: 5.256\n",
      "  iterations_since_restore: 751\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.7066619509985\n",
      "  time_since_restore: 17815.64317703247\n",
      "  time_this_iter_s: 24.061128854751587\n",
      "  time_total_s: 17815.64317703247\n",
      "  timestamp: 1553983606\n",
      "  timesteps_since_restore: 7510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7510000\n",
      "  training_iteration: 751\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17815 s, 751 iter, 7510000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-07-10\n",
      "  done: false\n",
      "  episode_len_mean: 160.35\n",
      "  episode_reward_max: 1121.8728073980365\n",
      "  episode_reward_mean: 937.8966438975283\n",
      "  episode_reward_min: -93.77164768721812\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 43673\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.494\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 7520000\n",
      "    num_steps_trained: 7520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.578144371509552\n",
      "      kl: 0.023321261629462242\n",
      "      policy_loss: -0.0024364166893064976\n",
      "      total_loss: 1014.5042114257812\n",
      "      vf_explained_var: 0.9613183736801147\n",
      "      vf_loss: 1014.50341796875\n",
      "    sample_time_ms: 19619.002\n",
      "    update_time_ms: 5.323\n",
      "  iterations_since_restore: 752\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.9483219487642\n",
      "  time_since_restore: 17839.7587788105\n",
      "  time_this_iter_s: 24.115601778030396\n",
      "  time_total_s: 17839.7587788105\n",
      "  timestamp: 1553983630\n",
      "  timesteps_since_restore: 7520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7520000\n",
      "  training_iteration: 752\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17839 s, 752 iter, 7520000 ts, 938 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-07-34\n",
      "  done: false\n",
      "  episode_len_mean: 165.05\n",
      "  episode_reward_max: 1137.8917306228366\n",
      "  episode_reward_mean: 942.6513132673962\n",
      "  episode_reward_min: -93.77164768721812\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 43732\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.244\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 7530000\n",
      "    num_steps_trained: 7530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8997456431388855\n",
      "      kl: 0.016622338443994522\n",
      "      policy_loss: -0.0022136669140309095\n",
      "      total_loss: 825.8109130859375\n",
      "      vf_explained_var: 0.9716888666152954\n",
      "      vf_loss: 825.810791015625\n",
      "    sample_time_ms: 19668.217\n",
      "    update_time_ms: 5.293\n",
      "  iterations_since_restore: 753\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.3256566336981\n",
      "  time_since_restore: 17863.098937273026\n",
      "  time_this_iter_s: 23.340158462524414\n",
      "  time_total_s: 17863.098937273026\n",
      "  timestamp: 1553983654\n",
      "  timesteps_since_restore: 7530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7530000\n",
      "  training_iteration: 753\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17863 s, 753 iter, 7530000 ts, 943 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-07-58\n",
      "  done: false\n",
      "  episode_len_mean: 169.56\n",
      "  episode_reward_max: 1137.8917306228366\n",
      "  episode_reward_mean: 962.3879537455448\n",
      "  episode_reward_min: 1.1349565091538807\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 43789\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.016\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 7540000\n",
      "    num_steps_trained: 7540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.753372073173523\n",
      "      kl: 0.023899218067526817\n",
      "      policy_loss: -0.0018069794168695807\n",
      "      total_loss: 441.4508361816406\n",
      "      vf_explained_var: 0.9817474484443665\n",
      "      vf_loss: 441.4493713378906\n",
      "    sample_time_ms: 19855.145\n",
      "    update_time_ms: 5.359\n",
      "  iterations_since_restore: 754\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.19397687277234\n",
      "  time_since_restore: 17887.46132993698\n",
      "  time_this_iter_s: 24.36239266395569\n",
      "  time_total_s: 17887.46132993698\n",
      "  timestamp: 1553983678\n",
      "  timesteps_since_restore: 7540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7540000\n",
      "  training_iteration: 754\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17887 s, 754 iter, 7540000 ts, 962 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-08-23\n",
      "  done: false\n",
      "  episode_len_mean: 170.91\n",
      "  episode_reward_max: 1141.2341157515557\n",
      "  episode_reward_mean: 973.4093496941257\n",
      "  episode_reward_min: -92.24424534761451\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 43849\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.733\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 7550000\n",
      "    num_steps_trained: 7550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8356712460517883\n",
      "      kl: 0.018331218510866165\n",
      "      policy_loss: -0.0019157505594193935\n",
      "      total_loss: 774.5316772460938\n",
      "      vf_explained_var: 0.9682498574256897\n",
      "      vf_loss: 774.5311279296875\n",
      "    sample_time_ms: 19943.025\n",
      "    update_time_ms: 5.386\n",
      "  iterations_since_restore: 755\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.70467484706285\n",
      "  time_since_restore: 17912.02753186226\n",
      "  time_this_iter_s: 24.56620192527771\n",
      "  time_total_s: 17912.02753186226\n",
      "  timestamp: 1553983703\n",
      "  timesteps_since_restore: 7550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7550000\n",
      "  training_iteration: 755\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17912 s, 755 iter, 7550000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-08-46\n",
      "  done: false\n",
      "  episode_len_mean: 162.04\n",
      "  episode_reward_max: 1120.8340765138448\n",
      "  episode_reward_mean: 941.8663030275926\n",
      "  episode_reward_min: -51.74926128867722\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 43914\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.522\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 7560000\n",
      "    num_steps_trained: 7560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4246884882450104\n",
      "      kl: 0.0158200953155756\n",
      "      policy_loss: -0.0019538020715117455\n",
      "      total_loss: 1094.8756103515625\n",
      "      vf_explained_var: 0.9562135338783264\n",
      "      vf_loss: 1094.8753662109375\n",
      "    sample_time_ms: 19915.26\n",
      "    update_time_ms: 5.375\n",
      "  iterations_since_restore: 756\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.9331515137963\n",
      "  time_since_restore: 17935.545353889465\n",
      "  time_this_iter_s: 23.51782202720642\n",
      "  time_total_s: 17935.545353889465\n",
      "  timestamp: 1553983726\n",
      "  timesteps_since_restore: 7560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7560000\n",
      "  training_iteration: 756\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17935 s, 756 iter, 7560000 ts, 942 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-09-10\n",
      "  done: false\n",
      "  episode_len_mean: 160.72\n",
      "  episode_reward_max: 1114.2869922462132\n",
      "  episode_reward_mean: 934.0525610582937\n",
      "  episode_reward_min: -83.0002814499672\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 43974\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.438\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 7570000\n",
      "    num_steps_trained: 7570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4885427951812744\n",
      "      kl: 0.020398365333676338\n",
      "      policy_loss: -0.0012457054108381271\n",
      "      total_loss: 558.1776123046875\n",
      "      vf_explained_var: 0.9771870374679565\n",
      "      vf_loss: 558.1759643554688\n",
      "    sample_time_ms: 19921.087\n",
      "    update_time_ms: 5.318\n",
      "  iterations_since_restore: 757\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.0262805291469\n",
      "  time_since_restore: 17959.446999549866\n",
      "  time_this_iter_s: 23.90164566040039\n",
      "  time_total_s: 17959.446999549866\n",
      "  timestamp: 1553983750\n",
      "  timesteps_since_restore: 7570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7570000\n",
      "  training_iteration: 757\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17959 s, 757 iter, 7570000 ts, 934 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-09-34\n",
      "  done: false\n",
      "  episode_len_mean: 171.1\n",
      "  episode_reward_max: 1152.3096598317636\n",
      "  episode_reward_mean: 942.1600143500068\n",
      "  episode_reward_min: -83.0002814499672\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 44030\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.788\n",
      "    load_time_ms: 1.671\n",
      "    num_steps_sampled: 7580000\n",
      "    num_steps_trained: 7580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1655828952789307\n",
      "      kl: 0.01419277023524046\n",
      "      policy_loss: 2.2525779058923945e-05\n",
      "      total_loss: 1305.734375\n",
      "      vf_explained_var: 0.9484481811523438\n",
      "      vf_loss: 1305.732421875\n",
      "    sample_time_ms: 19957.397\n",
      "    update_time_ms: 5.234\n",
      "  iterations_since_restore: 758\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.0800071750033\n",
      "  time_since_restore: 17983.449635267258\n",
      "  time_this_iter_s: 24.002635717391968\n",
      "  time_total_s: 17983.449635267258\n",
      "  timestamp: 1553983774\n",
      "  timesteps_since_restore: 7580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7580000\n",
      "  training_iteration: 758\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 17983 s, 758 iter, 7580000 ts, 942 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-09-58\n",
      "  done: false\n",
      "  episode_len_mean: 175.75\n",
      "  episode_reward_max: 1152.3096598317636\n",
      "  episode_reward_mean: 966.7595684453848\n",
      "  episode_reward_min: -66.79625393757553\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 44088\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.576\n",
      "    load_time_ms: 1.734\n",
      "    num_steps_sampled: 7590000\n",
      "    num_steps_trained: 7590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8216590881347656\n",
      "      kl: 0.019470397382974625\n",
      "      policy_loss: -0.0011968910694122314\n",
      "      total_loss: 398.5935974121094\n",
      "      vf_explained_var: 0.9841907024383545\n",
      "      vf_loss: 398.5921630859375\n",
      "    sample_time_ms: 19968.825\n",
      "    update_time_ms: 5.255\n",
      "  iterations_since_restore: 759\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.3797842226924\n",
      "  time_since_restore: 18007.170471191406\n",
      "  time_this_iter_s: 23.72083592414856\n",
      "  time_total_s: 18007.170471191406\n",
      "  timestamp: 1553983798\n",
      "  timesteps_since_restore: 7590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7590000\n",
      "  training_iteration: 759\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18007 s, 759 iter, 7590000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-10-21\n",
      "  done: false\n",
      "  episode_len_mean: 167.45\n",
      "  episode_reward_max: 1154.7850851553405\n",
      "  episode_reward_mean: 977.7104874223868\n",
      "  episode_reward_min: -52.24561036720783\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 44149\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.331\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 7600000\n",
      "    num_steps_trained: 7600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4974062144756317\n",
      "      kl: 0.018932897597551346\n",
      "      policy_loss: 0.0005876143695786595\n",
      "      total_loss: 758.7470092773438\n",
      "      vf_explained_var: 0.9687241911888123\n",
      "      vf_loss: 758.743896484375\n",
      "    sample_time_ms: 19941.523\n",
      "    update_time_ms: 5.427\n",
      "  iterations_since_restore: 760\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.85524371119334\n",
      "  time_since_restore: 18030.40568304062\n",
      "  time_this_iter_s: 23.235211849212646\n",
      "  time_total_s: 18030.40568304062\n",
      "  timestamp: 1553983821\n",
      "  timesteps_since_restore: 7600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7600000\n",
      "  training_iteration: 760\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18030 s, 760 iter, 7600000 ts, 978 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-10-45\n",
      "  done: false\n",
      "  episode_len_mean: 161.88\n",
      "  episode_reward_max: 1138.2685249645883\n",
      "  episode_reward_mean: 940.5303759631657\n",
      "  episode_reward_min: -86.70187643002444\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 44211\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.436\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 7610000\n",
      "    num_steps_trained: 7610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6776962280273438\n",
      "      kl: 0.03642471507191658\n",
      "      policy_loss: -0.00267519848421216\n",
      "      total_loss: 567.5333862304688\n",
      "      vf_explained_var: 0.978706955909729\n",
      "      vf_loss: 567.5311279296875\n",
      "    sample_time_ms: 19921.634\n",
      "    update_time_ms: 5.313\n",
      "  iterations_since_restore: 761\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.2651879815829\n",
      "  time_since_restore: 18054.261268377304\n",
      "  time_this_iter_s: 23.85558533668518\n",
      "  time_total_s: 18054.261268377304\n",
      "  timestamp: 1553983845\n",
      "  timesteps_since_restore: 7610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7610000\n",
      "  training_iteration: 761\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18054 s, 761 iter, 7610000 ts, 941 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-11-09\n",
      "  done: false\n",
      "  episode_len_mean: 170.92\n",
      "  episode_reward_max: 1142.6866472189415\n",
      "  episode_reward_mean: 954.9488162576595\n",
      "  episode_reward_min: -17.311827678560746\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 44267\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.579\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 7620000\n",
      "    num_steps_trained: 7620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8513461351394653\n",
      "      kl: 0.013437324203550816\n",
      "      policy_loss: -0.0006531326216645539\n",
      "      total_loss: 664.842041015625\n",
      "      vf_explained_var: 0.9725175499916077\n",
      "      vf_loss: 664.8409423828125\n",
      "    sample_time_ms: 19913.975\n",
      "    update_time_ms: 5.173\n",
      "  iterations_since_restore: 762\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.4744081288298\n",
      "  time_since_restore: 18078.227486133575\n",
      "  time_this_iter_s: 23.966217756271362\n",
      "  time_total_s: 18078.227486133575\n",
      "  timestamp: 1553983869\n",
      "  timesteps_since_restore: 7620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7620000\n",
      "  training_iteration: 762\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18078 s, 762 iter, 7620000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-11-32\n",
      "  done: false\n",
      "  episode_len_mean: 178.8\n",
      "  episode_reward_max: 1142.6866472189415\n",
      "  episode_reward_mean: 960.9018777384692\n",
      "  episode_reward_min: -100.01094171989912\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 44324\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.297\n",
      "    load_time_ms: 1.75\n",
      "    num_steps_sampled: 7630000\n",
      "    num_steps_trained: 7630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.234476923942566\n",
      "      kl: 0.0153159499168396\n",
      "      policy_loss: -0.003112742444500327\n",
      "      total_loss: 1062.4423828125\n",
      "      vf_explained_var: 0.955682635307312\n",
      "      vf_loss: 1062.4434814453125\n",
      "    sample_time_ms: 19880.785\n",
      "    update_time_ms: 5.088\n",
      "  iterations_since_restore: 763\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.4509388692347\n",
      "  time_since_restore: 18101.23377943039\n",
      "  time_this_iter_s: 23.006293296813965\n",
      "  time_total_s: 18101.23377943039\n",
      "  timestamp: 1553983892\n",
      "  timesteps_since_restore: 7630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7630000\n",
      "  training_iteration: 763\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18101 s, 763 iter, 7630000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-11-56\n",
      "  done: false\n",
      "  episode_len_mean: 170.9\n",
      "  episode_reward_max: 1129.7406772735876\n",
      "  episode_reward_mean: 966.9129908715798\n",
      "  episode_reward_min: -69.53740388199759\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 44382\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.452\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 7640000\n",
      "    num_steps_trained: 7640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7441794276237488\n",
      "      kl: 0.020170029252767563\n",
      "      policy_loss: -0.004150110296905041\n",
      "      total_loss: 740.2908935546875\n",
      "      vf_explained_var: 0.9740078449249268\n",
      "      vf_loss: 740.2922973632812\n",
      "    sample_time_ms: 19881.675\n",
      "    update_time_ms: 4.899\n",
      "  iterations_since_restore: 764\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.45649543579\n",
      "  time_since_restore: 18125.597674369812\n",
      "  time_this_iter_s: 24.363894939422607\n",
      "  time_total_s: 18125.597674369812\n",
      "  timestamp: 1553983916\n",
      "  timesteps_since_restore: 7640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7640000\n",
      "  training_iteration: 764\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18125 s, 764 iter, 7640000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-12-21\n",
      "  done: false\n",
      "  episode_len_mean: 175.59\n",
      "  episode_reward_max: 1166.7786604341584\n",
      "  episode_reward_mean: 933.1288567434311\n",
      "  episode_reward_min: -76.68522332520614\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 44439\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.499\n",
      "    load_time_ms: 1.652\n",
      "    num_steps_sampled: 7650000\n",
      "    num_steps_trained: 7650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9878206253051758\n",
      "      kl: 0.016991648823022842\n",
      "      policy_loss: -0.001074630650691688\n",
      "      total_loss: 638.3868408203125\n",
      "      vf_explained_var: 0.975852370262146\n",
      "      vf_loss: 638.3855590820312\n",
      "    sample_time_ms: 19824.847\n",
      "    update_time_ms: 4.889\n",
      "  iterations_since_restore: 765\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.56442837171545\n",
      "  time_since_restore: 18149.598065137863\n",
      "  time_this_iter_s: 24.000390768051147\n",
      "  time_total_s: 18149.598065137863\n",
      "  timestamp: 1553983941\n",
      "  timesteps_since_restore: 7650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7650000\n",
      "  training_iteration: 765\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18149 s, 765 iter, 7650000 ts, 933 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-12-45\n",
      "  done: false\n",
      "  episode_len_mean: 171.51\n",
      "  episode_reward_max: 1166.7786604341584\n",
      "  episode_reward_mean: 933.5164033646167\n",
      "  episode_reward_min: -76.68522332520614\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 44497\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.347\n",
      "    load_time_ms: 1.635\n",
      "    num_steps_sampled: 7660000\n",
      "    num_steps_trained: 7660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.741266131401062\n",
      "      kl: 0.01838119886815548\n",
      "      policy_loss: -0.0007544576073996723\n",
      "      total_loss: 916.3126220703125\n",
      "      vf_explained_var: 0.9634488224983215\n",
      "      vf_loss: 916.3106689453125\n",
      "    sample_time_ms: 19918.983\n",
      "    update_time_ms: 4.866\n",
      "  iterations_since_restore: 766\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.75820168230837\n",
      "  time_since_restore: 18174.02819800377\n",
      "  time_this_iter_s: 24.43013286590576\n",
      "  time_total_s: 18174.02819800377\n",
      "  timestamp: 1553983965\n",
      "  timesteps_since_restore: 7660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7660000\n",
      "  training_iteration: 766\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18174 s, 766 iter, 7660000 ts, 934 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-13-09\n",
      "  done: false\n",
      "  episode_len_mean: 173.16\n",
      "  episode_reward_max: 1130.227500220405\n",
      "  episode_reward_mean: 966.6238027561351\n",
      "  episode_reward_min: -27.346530788520255\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 44555\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.277\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 7670000\n",
      "    num_steps_trained: 7670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7969344854354858\n",
      "      kl: 0.019944261759519577\n",
      "      policy_loss: -0.0021598897874355316\n",
      "      total_loss: 423.6726379394531\n",
      "      vf_explained_var: 0.9846754670143127\n",
      "      vf_loss: 423.672119140625\n",
      "    sample_time_ms: 19937.205\n",
      "    update_time_ms: 4.9\n",
      "  iterations_since_restore: 767\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.31190137806755\n",
      "  time_since_restore: 18198.133523225784\n",
      "  time_this_iter_s: 24.10532522201538\n",
      "  time_total_s: 18198.133523225784\n",
      "  timestamp: 1553983989\n",
      "  timesteps_since_restore: 7670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7670000\n",
      "  training_iteration: 767\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18198 s, 767 iter, 7670000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-13-33\n",
      "  done: false\n",
      "  episode_len_mean: 169.85\n",
      "  episode_reward_max: 1139.5505338780845\n",
      "  episode_reward_mean: 981.5406248754505\n",
      "  episode_reward_min: -56.846637002306124\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 44615\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.061\n",
      "    load_time_ms: 1.641\n",
      "    num_steps_sampled: 7680000\n",
      "    num_steps_trained: 7680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5975416898727417\n",
      "      kl: 0.015963781625032425\n",
      "      policy_loss: -0.001069117453880608\n",
      "      total_loss: 550.5112915039062\n",
      "      vf_explained_var: 0.9762725830078125\n",
      "      vf_loss: 550.51025390625\n",
      "    sample_time_ms: 19883.32\n",
      "    update_time_ms: 4.845\n",
      "  iterations_since_restore: 768\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.77031243772524\n",
      "  time_since_restore: 18221.604097127914\n",
      "  time_this_iter_s: 23.470573902130127\n",
      "  time_total_s: 18221.604097127914\n",
      "  timestamp: 1553984013\n",
      "  timesteps_since_restore: 7680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7680000\n",
      "  training_iteration: 768\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18221 s, 768 iter, 7680000 ts, 982 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-13-57\n",
      "  done: false\n",
      "  episode_len_mean: 170.64\n",
      "  episode_reward_max: 1132.8085458137164\n",
      "  episode_reward_mean: 967.0541525033955\n",
      "  episode_reward_min: 3.8208114748513253\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 44673\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.123\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 7690000\n",
      "    num_steps_trained: 7690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9949446320533752\n",
      "      kl: 0.015904411673545837\n",
      "      policy_loss: -0.0039281174540519714\n",
      "      total_loss: 1106.8741455078125\n",
      "      vf_explained_var: 0.9567432999610901\n",
      "      vf_loss: 1106.8759765625\n",
      "    sample_time_ms: 19938.599\n",
      "    update_time_ms: 5.329\n",
      "  iterations_since_restore: 769\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.52707625169785\n",
      "  time_since_restore: 18245.85148048401\n",
      "  time_this_iter_s: 24.24738335609436\n",
      "  time_total_s: 18245.85148048401\n",
      "  timestamp: 1553984037\n",
      "  timesteps_since_restore: 7690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7690000\n",
      "  training_iteration: 769\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18245 s, 769 iter, 7690000 ts, 967 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-14-20\n",
      "  done: false\n",
      "  episode_len_mean: 171.72\n",
      "  episode_reward_max: 1124.1750099779163\n",
      "  episode_reward_mean: 961.2199444546819\n",
      "  episode_reward_min: -15.829286413873461\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 44731\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.775\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 7700000\n",
      "    num_steps_trained: 7700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8732696771621704\n",
      "      kl: 0.013317260891199112\n",
      "      policy_loss: -0.0033034582156687975\n",
      "      total_loss: 1129.3677978515625\n",
      "      vf_explained_var: 0.9531727433204651\n",
      "      vf_loss: 1129.369140625\n",
      "    sample_time_ms: 19963.716\n",
      "    update_time_ms: 5.197\n",
      "  iterations_since_restore: 770\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.60997222734096\n",
      "  time_since_restore: 18269.344094514847\n",
      "  time_this_iter_s: 23.492614030838013\n",
      "  time_total_s: 18269.344094514847\n",
      "  timestamp: 1553984060\n",
      "  timesteps_since_restore: 7700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7700000\n",
      "  training_iteration: 770\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18269 s, 770 iter, 7700000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 173.77\n",
      "  episode_reward_max: 1136.314965065295\n",
      "  episode_reward_mean: 978.5784003218407\n",
      "  episode_reward_min: -15.829286413873461\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 44788\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.859\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 7710000\n",
      "    num_steps_trained: 7710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.866568922996521\n",
      "      kl: 0.017700405791401863\n",
      "      policy_loss: 0.00113172538112849\n",
      "      total_loss: 545.1318969726562\n",
      "      vf_explained_var: 0.979695737361908\n",
      "      vf_loss: 545.12841796875\n",
      "    sample_time_ms: 19934.887\n",
      "    update_time_ms: 5.226\n",
      "  iterations_since_restore: 771\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.2892001609205\n",
      "  time_since_restore: 18292.942259788513\n",
      "  time_this_iter_s: 23.598165273666382\n",
      "  time_total_s: 18292.942259788513\n",
      "  timestamp: 1553984084\n",
      "  timesteps_since_restore: 7710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7710000\n",
      "  training_iteration: 771\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18292 s, 771 iter, 7710000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-15-08\n",
      "  done: false\n",
      "  episode_len_mean: 172.0\n",
      "  episode_reward_max: 1149.4883923151483\n",
      "  episode_reward_mean: 979.5027902541078\n",
      "  episode_reward_min: 7.143648762846965\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 44845\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.679\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 7720000\n",
      "    num_steps_trained: 7720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8752496242523193\n",
      "      kl: 0.016805380582809448\n",
      "      policy_loss: -0.0003965615469496697\n",
      "      total_loss: 562.4984130859375\n",
      "      vf_explained_var: 0.9781774878501892\n",
      "      vf_loss: 562.4965209960938\n",
      "    sample_time_ms: 19937.686\n",
      "    update_time_ms: 5.191\n",
      "  iterations_since_restore: 772\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.75139512705397\n",
      "  time_since_restore: 18317.002895593643\n",
      "  time_this_iter_s: 24.060635805130005\n",
      "  time_total_s: 18317.002895593643\n",
      "  timestamp: 1553984108\n",
      "  timesteps_since_restore: 7720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7720000\n",
      "  training_iteration: 772\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18317 s, 772 iter, 7720000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-15-32\n",
      "  done: false\n",
      "  episode_len_mean: 177.74\n",
      "  episode_reward_max: 1149.4883923151483\n",
      "  episode_reward_mean: 931.6760105984266\n",
      "  episode_reward_min: -52.79724718240681\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 44900\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.229\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 7730000\n",
      "    num_steps_trained: 7730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2647838592529297\n",
      "      kl: 0.015322086401283741\n",
      "      policy_loss: -0.000790346646681428\n",
      "      total_loss: 1321.730224609375\n",
      "      vf_explained_var: 0.9522695541381836\n",
      "      vf_loss: 1321.72900390625\n",
      "    sample_time_ms: 20058.042\n",
      "    update_time_ms: 5.204\n",
      "  iterations_since_restore: 773\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 465.83800529921325\n",
      "  time_since_restore: 18341.246309041977\n",
      "  time_this_iter_s: 24.24341344833374\n",
      "  time_total_s: 18341.246309041977\n",
      "  timestamp: 1553984132\n",
      "  timesteps_since_restore: 7730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7730000\n",
      "  training_iteration: 773\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18341 s, 773 iter, 7730000 ts, 932 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-15-57\n",
      "  done: false\n",
      "  episode_len_mean: 172.53\n",
      "  episode_reward_max: 1136.5955595970295\n",
      "  episode_reward_mean: 966.1428395873742\n",
      "  episode_reward_min: -63.15578573348935\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 44961\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.501\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 7740000\n",
      "    num_steps_trained: 7740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6378421187400818\n",
      "      kl: 0.02021208591759205\n",
      "      policy_loss: -0.001511284033767879\n",
      "      total_loss: 571.1079711914062\n",
      "      vf_explained_var: 0.9754650592803955\n",
      "      vf_loss: 571.106689453125\n",
      "    sample_time_ms: 20040.205\n",
      "    update_time_ms: 5.954\n",
      "  iterations_since_restore: 774\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.07141979368714\n",
      "  time_since_restore: 18365.382855653763\n",
      "  time_this_iter_s: 24.13654661178589\n",
      "  time_total_s: 18365.382855653763\n",
      "  timestamp: 1553984157\n",
      "  timesteps_since_restore: 7740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7740000\n",
      "  training_iteration: 774\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18365 s, 774 iter, 7740000 ts, 966 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-16-20\n",
      "  done: false\n",
      "  episode_len_mean: 166.01\n",
      "  episode_reward_max: 1137.1171207337431\n",
      "  episode_reward_mean: 975.5791799365095\n",
      "  episode_reward_min: -78.32810428389817\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 45021\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.275\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 7750000\n",
      "    num_steps_trained: 7750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7172892689704895\n",
      "      kl: 0.01326453872025013\n",
      "      policy_loss: -0.001526379375718534\n",
      "      total_loss: 1138.0672607421875\n",
      "      vf_explained_var: 0.9531509280204773\n",
      "      vf_loss: 1138.067138671875\n",
      "    sample_time_ms: 20006.874\n",
      "    update_time_ms: 5.958\n",
      "  iterations_since_restore: 775\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.78958996825475\n",
      "  time_since_restore: 18388.995889663696\n",
      "  time_this_iter_s: 23.61303400993347\n",
      "  time_total_s: 18388.995889663696\n",
      "  timestamp: 1553984180\n",
      "  timesteps_since_restore: 7750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7750000\n",
      "  training_iteration: 775\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18388 s, 775 iter, 7750000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-16-45\n",
      "  done: false\n",
      "  episode_len_mean: 166.82\n",
      "  episode_reward_max: 1149.2773830158387\n",
      "  episode_reward_mean: 918.3207566556978\n",
      "  episode_reward_min: -78.32810428389817\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 45083\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.027\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 7760000\n",
      "    num_steps_trained: 7760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6449313759803772\n",
      "      kl: 0.02109653875231743\n",
      "      policy_loss: -0.0019633807241916656\n",
      "      total_loss: 1252.334716796875\n",
      "      vf_explained_var: 0.9512133598327637\n",
      "      vf_loss: 1252.333740234375\n",
      "    sample_time_ms: 20004.089\n",
      "    update_time_ms: 5.936\n",
      "  iterations_since_restore: 776\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 459.1603783278489\n",
      "  time_since_restore: 18413.45395231247\n",
      "  time_this_iter_s: 24.458062648773193\n",
      "  time_total_s: 18413.45395231247\n",
      "  timestamp: 1553984205\n",
      "  timesteps_since_restore: 7760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7760000\n",
      "  training_iteration: 776\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18413 s, 776 iter, 7760000 ts, 918 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 174.96\n",
      "  episode_reward_max: 1145.1590350626634\n",
      "  episode_reward_mean: 917.5422971511591\n",
      "  episode_reward_min: -82.87414655737757\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 45137\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.748\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 7770000\n",
      "    num_steps_trained: 7770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3514275550842285\n",
      "      kl: 0.019345635548233986\n",
      "      policy_loss: -0.0010764021426439285\n",
      "      total_loss: 1294.4908447265625\n",
      "      vf_explained_var: 0.9522161483764648\n",
      "      vf_loss: 1294.4892578125\n",
      "    sample_time_ms: 20034.914\n",
      "    update_time_ms: 5.885\n",
      "  iterations_since_restore: 777\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 458.77114857557945\n",
      "  time_since_restore: 18437.883213996887\n",
      "  time_this_iter_s: 24.429261684417725\n",
      "  time_total_s: 18437.883213996887\n",
      "  timestamp: 1553984229\n",
      "  timesteps_since_restore: 7770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7770000\n",
      "  training_iteration: 777\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18437 s, 777 iter, 7770000 ts, 918 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-17-33\n",
      "  done: false\n",
      "  episode_len_mean: 178.15\n",
      "  episode_reward_max: 1156.636118960276\n",
      "  episode_reward_mean: 933.9361311484063\n",
      "  episode_reward_min: -82.87414655737757\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 45195\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.968\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 7780000\n",
      "    num_steps_trained: 7780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8141573667526245\n",
      "      kl: 0.02119399420917034\n",
      "      policy_loss: 0.0002463299606461078\n",
      "      total_loss: 786.9262084960938\n",
      "      vf_explained_var: 0.9691275358200073\n",
      "      vf_loss: 786.923095703125\n",
      "    sample_time_ms: 20075.109\n",
      "    update_time_ms: 5.887\n",
      "  iterations_since_restore: 778\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.9680655742032\n",
      "  time_since_restore: 18461.793007850647\n",
      "  time_this_iter_s: 23.909793853759766\n",
      "  time_total_s: 18461.793007850647\n",
      "  timestamp: 1553984253\n",
      "  timesteps_since_restore: 7780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7780000\n",
      "  training_iteration: 778\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18461 s, 778 iter, 7780000 ts, 934 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-17-57\n",
      "  done: false\n",
      "  episode_len_mean: 178.14\n",
      "  episode_reward_max: 1156.636118960276\n",
      "  episode_reward_mean: 973.1207082284219\n",
      "  episode_reward_min: -80.03876243721297\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 45249\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.255\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 7790000\n",
      "    num_steps_trained: 7790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.254525065422058\n",
      "      kl: 0.011638211086392403\n",
      "      policy_loss: -0.001102164387702942\n",
      "      total_loss: 825.6262817382812\n",
      "      vf_explained_var: 0.9692720174789429\n",
      "      vf_loss: 825.625732421875\n",
      "    sample_time_ms: 20048.445\n",
      "    update_time_ms: 5.661\n",
      "  iterations_since_restore: 779\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.56035411421095\n",
      "  time_since_restore: 18485.77432179451\n",
      "  time_this_iter_s: 23.981313943862915\n",
      "  time_total_s: 18485.77432179451\n",
      "  timestamp: 1553984277\n",
      "  timesteps_since_restore: 7790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7790000\n",
      "  training_iteration: 779\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18485 s, 779 iter, 7790000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-18-21\n",
      "  done: false\n",
      "  episode_len_mean: 170.24\n",
      "  episode_reward_max: 1138.830585667475\n",
      "  episode_reward_mean: 934.2234841986442\n",
      "  episode_reward_min: -67.06656971127785\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 45310\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.841\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 7800000\n",
      "    num_steps_trained: 7800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8592286705970764\n",
      "      kl: 0.015379035845398903\n",
      "      policy_loss: -0.0023528635501861572\n",
      "      total_loss: 1382.685302734375\n",
      "      vf_explained_var: 0.9422023296356201\n",
      "      vf_loss: 1382.685546875\n",
      "    sample_time_ms: 20034.6\n",
      "    update_time_ms: 5.683\n",
      "  iterations_since_restore: 780\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.11174209932216\n",
      "  time_since_restore: 18509.076050519943\n",
      "  time_this_iter_s: 23.30172872543335\n",
      "  time_total_s: 18509.076050519943\n",
      "  timestamp: 1553984301\n",
      "  timesteps_since_restore: 7800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7800000\n",
      "  training_iteration: 780\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18509 s, 780 iter, 7800000 ts, 934 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-18-45\n",
      "  done: false\n",
      "  episode_len_mean: 164.56\n",
      "  episode_reward_max: 1125.2354926563123\n",
      "  episode_reward_mean: 921.1488587800665\n",
      "  episode_reward_min: -57.811762097128366\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 45372\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.423\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 7810000\n",
      "    num_steps_trained: 7810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7284398078918457\n",
      "      kl: 0.016411276534199715\n",
      "      policy_loss: -0.0014272744301706553\n",
      "      total_loss: 893.25\n",
      "      vf_explained_var: 0.9636813402175903\n",
      "      vf_loss: 893.2492065429688\n",
      "    sample_time_ms: 20091.076\n",
      "    update_time_ms: 5.584\n",
      "  iterations_since_restore: 781\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 460.57442939003334\n",
      "  time_since_restore: 18533.222477674484\n",
      "  time_this_iter_s: 24.146427154541016\n",
      "  time_total_s: 18533.222477674484\n",
      "  timestamp: 1553984325\n",
      "  timesteps_since_restore: 7810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7810000\n",
      "  training_iteration: 781\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18533 s, 781 iter, 7810000 ts, 921 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-19-09\n",
      "  done: false\n",
      "  episode_len_mean: 163.33\n",
      "  episode_reward_max: 1161.0405699219232\n",
      "  episode_reward_mean: 930.4077655535167\n",
      "  episode_reward_min: -80.30725475114335\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 45432\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.634\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 7820000\n",
      "    num_steps_trained: 7820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7566142082214355\n",
      "      kl: 0.01387846190482378\n",
      "      policy_loss: -0.0008335625752806664\n",
      "      total_loss: 659.3287963867188\n",
      "      vf_explained_var: 0.9735175967216492\n",
      "      vf_loss: 659.3278198242188\n",
      "    sample_time_ms: 20104.552\n",
      "    update_time_ms: 5.858\n",
      "  iterations_since_restore: 782\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 465.2038827767584\n",
      "  time_since_restore: 18557.355937480927\n",
      "  time_this_iter_s: 24.13345980644226\n",
      "  time_total_s: 18557.355937480927\n",
      "  timestamp: 1553984349\n",
      "  timesteps_since_restore: 7820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7820000\n",
      "  training_iteration: 782\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18557 s, 782 iter, 7820000 ts, 930 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-19-32\n",
      "  done: false\n",
      "  episode_len_mean: 167.32\n",
      "  episode_reward_max: 1161.0405699219232\n",
      "  episode_reward_mean: 954.135890513035\n",
      "  episode_reward_min: -76.95636720614732\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 45492\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.434\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 7830000\n",
      "    num_steps_trained: 7830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8858079314231873\n",
      "      kl: 0.014582586474716663\n",
      "      policy_loss: -0.002054467797279358\n",
      "      total_loss: 1216.7000732421875\n",
      "      vf_explained_var: 0.9477840065956116\n",
      "      vf_loss: 1216.7000732421875\n",
      "    sample_time_ms: 20019.038\n",
      "    update_time_ms: 5.808\n",
      "  iterations_since_restore: 783\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.06794525651753\n",
      "  time_since_restore: 18580.663686275482\n",
      "  time_this_iter_s: 23.307748794555664\n",
      "  time_total_s: 18580.663686275482\n",
      "  timestamp: 1553984372\n",
      "  timesteps_since_restore: 7830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7830000\n",
      "  training_iteration: 783\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18580 s, 783 iter, 7830000 ts, 954 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-19-57\n",
      "  done: false\n",
      "  episode_len_mean: 165.17\n",
      "  episode_reward_max: 1141.798130600733\n",
      "  episode_reward_mean: 963.9651012488907\n",
      "  episode_reward_min: -76.95636720614732\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 45552\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.888\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 7840000\n",
      "    num_steps_trained: 7840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5985762476921082\n",
      "      kl: 0.02048368565738201\n",
      "      policy_loss: -0.0011336043244227767\n",
      "      total_loss: 716.6648559570312\n",
      "      vf_explained_var: 0.9685654044151306\n",
      "      vf_loss: 716.6632080078125\n",
      "    sample_time_ms: 20042.935\n",
      "    update_time_ms: 5.238\n",
      "  iterations_since_restore: 784\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.9825506244452\n",
      "  time_since_restore: 18605.070756196976\n",
      "  time_this_iter_s: 24.40706992149353\n",
      "  time_total_s: 18605.070756196976\n",
      "  timestamp: 1553984397\n",
      "  timesteps_since_restore: 7840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7840000\n",
      "  training_iteration: 784\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18605 s, 784 iter, 7840000 ts, 964 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-20-21\n",
      "  done: false\n",
      "  episode_len_mean: 173.3\n",
      "  episode_reward_max: 1141.798130600733\n",
      "  episode_reward_mean: 978.900800462966\n",
      "  episode_reward_min: -58.93608127935428\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 45608\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.382\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 7850000\n",
      "    num_steps_trained: 7850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6689340472221375\n",
      "      kl: 0.022298473864793777\n",
      "      policy_loss: -0.003703756257891655\n",
      "      total_loss: 565.1552734375\n",
      "      vf_explained_var: 0.9762446880340576\n",
      "      vf_loss: 565.1559448242188\n",
      "    sample_time_ms: 20105.447\n",
      "    update_time_ms: 5.419\n",
      "  iterations_since_restore: 785\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.45040023148306\n",
      "  time_since_restore: 18629.354071378708\n",
      "  time_this_iter_s: 24.283315181732178\n",
      "  time_total_s: 18629.354071378708\n",
      "  timestamp: 1553984421\n",
      "  timesteps_since_restore: 7850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7850000\n",
      "  training_iteration: 785\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18629 s, 785 iter, 7850000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-20-45\n",
      "  done: false\n",
      "  episode_len_mean: 173.42\n",
      "  episode_reward_max: 1160.6329089511778\n",
      "  episode_reward_mean: 980.2788631388066\n",
      "  episode_reward_min: -22.674583321973756\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 45665\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.126\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 7860000\n",
      "    num_steps_trained: 7860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8945886492729187\n",
      "      kl: 0.01783525012433529\n",
      "      policy_loss: -0.0018075353000313044\n",
      "      total_loss: 539.4072265625\n",
      "      vf_explained_var: 0.9773998856544495\n",
      "      vf_loss: 539.4066772460938\n",
      "    sample_time_ms: 20084.534\n",
      "    update_time_ms: 5.431\n",
      "  iterations_since_restore: 786\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.1394315694033\n",
      "  time_since_restore: 18653.55747294426\n",
      "  time_this_iter_s: 24.203401565551758\n",
      "  time_total_s: 18653.55747294426\n",
      "  timestamp: 1553984445\n",
      "  timesteps_since_restore: 7860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7860000\n",
      "  training_iteration: 786\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18653 s, 786 iter, 7860000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-21-09\n",
      "  done: false\n",
      "  episode_len_mean: 171.78\n",
      "  episode_reward_max: 1159.3007002548397\n",
      "  episode_reward_mean: 980.4525839575276\n",
      "  episode_reward_min: -70.93060783128388\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 45725\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.834\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 7870000\n",
      "    num_steps_trained: 7870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5699033737182617\n",
      "      kl: 0.0189043041318655\n",
      "      policy_loss: -0.006063870619982481\n",
      "      total_loss: 869.1887817382812\n",
      "      vf_explained_var: 0.961884617805481\n",
      "      vf_loss: 869.1923217773438\n",
      "    sample_time_ms: 20018.595\n",
      "    update_time_ms: 5.543\n",
      "  iterations_since_restore: 787\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.22629197876375\n",
      "  time_since_restore: 18677.31703209877\n",
      "  time_this_iter_s: 23.759559154510498\n",
      "  time_total_s: 18677.31703209877\n",
      "  timestamp: 1553984469\n",
      "  timesteps_since_restore: 7870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7870000\n",
      "  training_iteration: 787\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18677 s, 787 iter, 7870000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-21-34\n",
      "  done: false\n",
      "  episode_len_mean: 166.1\n",
      "  episode_reward_max: 1159.3007002548397\n",
      "  episode_reward_mean: 1006.9979929507072\n",
      "  episode_reward_min: -70.93060783128388\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 45786\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.187\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 7880000\n",
      "    num_steps_trained: 7880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.503669798374176\n",
      "      kl: 0.03079128824174404\n",
      "      policy_loss: -0.001713882084004581\n",
      "      total_loss: 143.82594299316406\n",
      "      vf_explained_var: 0.9945874214172363\n",
      "      vf_loss: 143.823486328125\n",
      "    sample_time_ms: 20064.383\n",
      "    update_time_ms: 5.518\n",
      "  iterations_since_restore: 788\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 503.49899647535347\n",
      "  time_since_restore: 18701.66151213646\n",
      "  time_this_iter_s: 24.34448003768921\n",
      "  time_total_s: 18701.66151213646\n",
      "  timestamp: 1553984494\n",
      "  timesteps_since_restore: 7880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7880000\n",
      "  training_iteration: 788\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18701 s, 788 iter, 7880000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-21-57\n",
      "  done: false\n",
      "  episode_len_mean: 167.41\n",
      "  episode_reward_max: 1146.1532897551378\n",
      "  episode_reward_mean: 1000.3691201260959\n",
      "  episode_reward_min: -46.29272347379603\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 45847\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.413\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 7890000\n",
      "    num_steps_trained: 7890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4900003969669342\n",
      "      kl: 0.011687535792589188\n",
      "      policy_loss: -0.0023638650309294462\n",
      "      total_loss: 474.5565490722656\n",
      "      vf_explained_var: 0.9823108315467834\n",
      "      vf_loss: 474.5572814941406\n",
      "    sample_time_ms: 20061.997\n",
      "    update_time_ms: 5.352\n",
      "  iterations_since_restore: 789\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 500.18456006304797\n",
      "  time_since_restore: 18725.558985948563\n",
      "  time_this_iter_s: 23.89747381210327\n",
      "  time_total_s: 18725.558985948563\n",
      "  timestamp: 1553984517\n",
      "  timesteps_since_restore: 7890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7890000\n",
      "  training_iteration: 789\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18725 s, 789 iter, 7890000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-22-21\n",
      "  done: false\n",
      "  episode_len_mean: 171.4\n",
      "  episode_reward_max: 1181.4366693060256\n",
      "  episode_reward_mean: 987.3472763659599\n",
      "  episode_reward_min: -46.29272347379603\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 45902\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.143\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 7900000\n",
      "    num_steps_trained: 7900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9670944213867188\n",
      "      kl: 0.017379280179739\n",
      "      policy_loss: -0.004257600754499435\n",
      "      total_loss: 607.7504272460938\n",
      "      vf_explained_var: 0.9739489555358887\n",
      "      vf_loss: 607.7523193359375\n",
      "    sample_time_ms: 20099.501\n",
      "    update_time_ms: 5.395\n",
      "  iterations_since_restore: 790\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.67363818297997\n",
      "  time_since_restore: 18749.29117512703\n",
      "  time_this_iter_s: 23.732189178466797\n",
      "  time_total_s: 18749.29117512703\n",
      "  timestamp: 1553984541\n",
      "  timesteps_since_restore: 7900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7900000\n",
      "  training_iteration: 790\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18749 s, 790 iter, 7900000 ts, 987 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-22-45\n",
      "  done: false\n",
      "  episode_len_mean: 179.67\n",
      "  episode_reward_max: 1181.4366693060256\n",
      "  episode_reward_mean: 966.3125359033494\n",
      "  episode_reward_min: -66.9890674889584\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 45958\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.121\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 7910000\n",
      "    num_steps_trained: 7910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0285415649414062\n",
      "      kl: 0.01308479718863964\n",
      "      policy_loss: -0.0020909251179546118\n",
      "      total_loss: 775.9098510742188\n",
      "      vf_explained_var: 0.9675541520118713\n",
      "      vf_loss: 775.9102783203125\n",
      "    sample_time_ms: 20084.871\n",
      "    update_time_ms: 5.458\n",
      "  iterations_since_restore: 791\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.1562679516747\n",
      "  time_since_restore: 18773.291587352753\n",
      "  time_this_iter_s: 24.000412225723267\n",
      "  time_total_s: 18773.291587352753\n",
      "  timestamp: 1553984565\n",
      "  timesteps_since_restore: 7910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7910000\n",
      "  training_iteration: 791\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18773 s, 791 iter, 7910000 ts, 966 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-23-10\n",
      "  done: false\n",
      "  episode_len_mean: 177.64\n",
      "  episode_reward_max: 1137.565582757131\n",
      "  episode_reward_mean: 970.7265708797829\n",
      "  episode_reward_min: -3.5615082743080393\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 46015\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.514\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 7920000\n",
      "    num_steps_trained: 7920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7925058007240295\n",
      "      kl: 0.014465325511991978\n",
      "      policy_loss: -6.535878583235899e-06\n",
      "      total_loss: 808.0029296875\n",
      "      vf_explained_var: 0.964493989944458\n",
      "      vf_loss: 808.0009765625\n",
      "    sample_time_ms: 20109.056\n",
      "    update_time_ms: 5.258\n",
      "  iterations_since_restore: 792\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.36328543989134\n",
      "  time_since_restore: 18797.73765707016\n",
      "  time_this_iter_s: 24.446069717407227\n",
      "  time_total_s: 18797.73765707016\n",
      "  timestamp: 1553984590\n",
      "  timesteps_since_restore: 7920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7920000\n",
      "  training_iteration: 792\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18797 s, 792 iter, 7920000 ts, 971 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-23-33\n",
      "  done: false\n",
      "  episode_len_mean: 171.62\n",
      "  episode_reward_max: 1141.8504566615732\n",
      "  episode_reward_mean: 959.2589124586898\n",
      "  episode_reward_min: -15.301660012208174\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 46074\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.178\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 7930000\n",
      "    num_steps_trained: 7930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8000759482383728\n",
      "      kl: 0.011430173180997372\n",
      "      policy_loss: -0.0009161705966107547\n",
      "      total_loss: 664.114501953125\n",
      "      vf_explained_var: 0.9723443984985352\n",
      "      vf_loss: 664.1138916015625\n",
      "    sample_time_ms: 20138.194\n",
      "    update_time_ms: 5.313\n",
      "  iterations_since_restore: 793\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.6294562293448\n",
      "  time_since_restore: 18821.380777835846\n",
      "  time_this_iter_s: 23.643120765686035\n",
      "  time_total_s: 18821.380777835846\n",
      "  timestamp: 1553984613\n",
      "  timesteps_since_restore: 7930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7930000\n",
      "  training_iteration: 793\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18821 s, 793 iter, 7930000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-23-57\n",
      "  done: false\n",
      "  episode_len_mean: 169.07\n",
      "  episode_reward_max: 1141.8504566615732\n",
      "  episode_reward_mean: 985.3125296939295\n",
      "  episode_reward_min: -60.22435717182489\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 46134\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3909.475\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 7940000\n",
      "    num_steps_trained: 7940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7673447132110596\n",
      "      kl: 0.01285255141556263\n",
      "      policy_loss: -0.000531584199052304\n",
      "      total_loss: 586.7033081054688\n",
      "      vf_explained_var: 0.9743490219116211\n",
      "      vf_loss: 586.7021484375\n",
      "    sample_time_ms: 20015.635\n",
      "    update_time_ms: 5.613\n",
      "  iterations_since_restore: 794\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.65626484696475\n",
      "  time_since_restore: 18844.56623506546\n",
      "  time_this_iter_s: 23.185457229614258\n",
      "  time_total_s: 18844.56623506546\n",
      "  timestamp: 1553984637\n",
      "  timesteps_since_restore: 7940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7940000\n",
      "  training_iteration: 794\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18844 s, 794 iter, 7940000 ts, 985 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-24-20\n",
      "  done: false\n",
      "  episode_len_mean: 168.3\n",
      "  episode_reward_max: 1168.0760319720043\n",
      "  episode_reward_mean: 995.7169979975208\n",
      "  episode_reward_min: -101.0711714905581\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 46195\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.898\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 7950000\n",
      "    num_steps_trained: 7950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5403994917869568\n",
      "      kl: 0.01803109608590603\n",
      "      policy_loss: -0.0018172978889197111\n",
      "      total_loss: 334.3082580566406\n",
      "      vf_explained_var: 0.9864327907562256\n",
      "      vf_loss: 334.3075866699219\n",
      "    sample_time_ms: 19953.037\n",
      "    update_time_ms: 5.452\n",
      "  iterations_since_restore: 795\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.85849899876035\n",
      "  time_since_restore: 18868.216727256775\n",
      "  time_this_iter_s: 23.650492191314697\n",
      "  time_total_s: 18868.216727256775\n",
      "  timestamp: 1553984660\n",
      "  timesteps_since_restore: 7950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7950000\n",
      "  training_iteration: 795\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18868 s, 795 iter, 7950000 ts, 996 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-24-45\n",
      "  done: false\n",
      "  episode_len_mean: 169.58\n",
      "  episode_reward_max: 1168.0760319720043\n",
      "  episode_reward_mean: 968.4859145648264\n",
      "  episode_reward_min: -101.0711714905581\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 46251\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.737\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 7960000\n",
      "    num_steps_trained: 7960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8707537651062012\n",
      "      kl: 0.011748056858778\n",
      "      policy_loss: -0.0016901898197829723\n",
      "      total_loss: 534.193359375\n",
      "      vf_explained_var: 0.9765343070030212\n",
      "      vf_loss: 534.1934814453125\n",
      "    sample_time_ms: 19947.533\n",
      "    update_time_ms: 5.391\n",
      "  iterations_since_restore: 796\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.2429572824133\n",
      "  time_since_restore: 18892.345563173294\n",
      "  time_this_iter_s: 24.128835916519165\n",
      "  time_total_s: 18892.345563173294\n",
      "  timestamp: 1553984685\n",
      "  timesteps_since_restore: 7960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7960000\n",
      "  training_iteration: 796\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18892 s, 796 iter, 7960000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 173.27\n",
      "  episode_reward_max: 1120.2384262649541\n",
      "  episode_reward_mean: 962.5016692138732\n",
      "  episode_reward_min: -109.20550207666378\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 46312\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.025\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 7970000\n",
      "    num_steps_trained: 7970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8749554753303528\n",
      "      kl: 0.0178989227861166\n",
      "      policy_loss: -0.002955556148663163\n",
      "      total_loss: 604.0823974609375\n",
      "      vf_explained_var: 0.9758275151252747\n",
      "      vf_loss: 604.0828857421875\n",
      "    sample_time_ms: 19978.04\n",
      "    update_time_ms: 5.484\n",
      "  iterations_since_restore: 797\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.2508346069367\n",
      "  time_since_restore: 18916.402641296387\n",
      "  time_this_iter_s: 24.05707812309265\n",
      "  time_total_s: 18916.402641296387\n",
      "  timestamp: 1553984709\n",
      "  timesteps_since_restore: 7970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7970000\n",
      "  training_iteration: 797\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18916 s, 797 iter, 7970000 ts, 963 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-25-33\n",
      "  done: false\n",
      "  episode_len_mean: 172.46\n",
      "  episode_reward_max: 1133.1088036249744\n",
      "  episode_reward_mean: 976.2355842809865\n",
      "  episode_reward_min: -109.20550207666378\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 46366\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.493\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 7980000\n",
      "    num_steps_trained: 7980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0792956352233887\n",
      "      kl: 0.012423207052052021\n",
      "      policy_loss: -0.0003360674309078604\n",
      "      total_loss: 392.54046630859375\n",
      "      vf_explained_var: 0.9840176701545715\n",
      "      vf_loss: 392.53912353515625\n",
      "    sample_time_ms: 19939.272\n",
      "    update_time_ms: 5.596\n",
      "  iterations_since_restore: 798\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.11779214049324\n",
      "  time_since_restore: 18940.365103006363\n",
      "  time_this_iter_s: 23.962461709976196\n",
      "  time_total_s: 18940.365103006363\n",
      "  timestamp: 1553984733\n",
      "  timesteps_since_restore: 7980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7980000\n",
      "  training_iteration: 798\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18940 s, 798 iter, 7980000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-25-57\n",
      "  done: false\n",
      "  episode_len_mean: 170.14\n",
      "  episode_reward_max: 1133.1088036249744\n",
      "  episode_reward_mean: 1015.4097584422229\n",
      "  episode_reward_min: 149.41089466386842\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 46425\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.126\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 7990000\n",
      "    num_steps_trained: 7990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6476158499717712\n",
      "      kl: 0.014784137718379498\n",
      "      policy_loss: 0.0008294727304019034\n",
      "      total_loss: 211.31199645996094\n",
      "      vf_explained_var: 0.9903689622879028\n",
      "      vf_loss: 211.30917358398438\n",
      "    sample_time_ms: 19997.763\n",
      "    update_time_ms: 5.685\n",
      "  iterations_since_restore: 799\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 507.7048792211115\n",
      "  time_since_restore: 18964.86407995224\n",
      "  time_this_iter_s: 24.498976945877075\n",
      "  time_total_s: 18964.86407995224\n",
      "  timestamp: 1553984757\n",
      "  timesteps_since_restore: 7990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7990000\n",
      "  training_iteration: 799\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18964 s, 799 iter, 7990000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-26-21\n",
      "  done: false\n",
      "  episode_len_mean: 170.48\n",
      "  episode_reward_max: 1134.286217968589\n",
      "  episode_reward_mean: 972.7311039667085\n",
      "  episode_reward_min: -83.99979063907506\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 46483\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.603\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 8000000\n",
      "    num_steps_trained: 8000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9473663568496704\n",
      "      kl: 0.010641303844749928\n",
      "      policy_loss: -0.001271150424145162\n",
      "      total_loss: 995.4649658203125\n",
      "      vf_explained_var: 0.9584323167800903\n",
      "      vf_loss: 995.46484375\n",
      "    sample_time_ms: 19980.576\n",
      "    update_time_ms: 5.574\n",
      "  iterations_since_restore: 800\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.36555198335424\n",
      "  time_since_restore: 18988.37807893753\n",
      "  time_this_iter_s: 23.513998985290527\n",
      "  time_total_s: 18988.37807893753\n",
      "  timestamp: 1553984781\n",
      "  timesteps_since_restore: 8000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8000000\n",
      "  training_iteration: 800\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 18988 s, 800 iter, 8000000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-26-45\n",
      "  done: false\n",
      "  episode_len_mean: 166.28\n",
      "  episode_reward_max: 1130.2817210529763\n",
      "  episode_reward_mean: 962.7185151111967\n",
      "  episode_reward_min: -83.99979063907506\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 46544\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.853\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 8010000\n",
      "    num_steps_trained: 8010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49479302763938904\n",
      "      kl: 0.01675838977098465\n",
      "      policy_loss: -0.007759389001876116\n",
      "      total_loss: 446.19500732421875\n",
      "      vf_explained_var: 0.980327308177948\n",
      "      vf_loss: 446.2005310058594\n",
      "    sample_time_ms: 19962.564\n",
      "    update_time_ms: 5.629\n",
      "  iterations_since_restore: 801\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.35925755559833\n",
      "  time_since_restore: 19012.18979883194\n",
      "  time_this_iter_s: 23.81171989440918\n",
      "  time_total_s: 19012.18979883194\n",
      "  timestamp: 1553984805\n",
      "  timesteps_since_restore: 8010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8010000\n",
      "  training_iteration: 801\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19012 s, 801 iter, 8010000 ts, 963 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-27-09\n",
      "  done: false\n",
      "  episode_len_mean: 167.0\n",
      "  episode_reward_max: 1130.2817210529763\n",
      "  episode_reward_mean: 1012.8695182639323\n",
      "  episode_reward_min: 55.42139789606969\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 46603\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.868\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 8020000\n",
      "    num_steps_trained: 8020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.39168426394462585\n",
      "      kl: 0.020329566672444344\n",
      "      policy_loss: -0.0018969345837831497\n",
      "      total_loss: 54.2212028503418\n",
      "      vf_explained_var: 0.9976204037666321\n",
      "      vf_loss: 54.220333099365234\n",
      "    sample_time_ms: 19966.061\n",
      "    update_time_ms: 5.637\n",
      "  iterations_since_restore: 802\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 506.4347591319661\n",
      "  time_since_restore: 19036.56293106079\n",
      "  time_this_iter_s: 24.37313222885132\n",
      "  time_total_s: 19036.56293106079\n",
      "  timestamp: 1553984829\n",
      "  timesteps_since_restore: 8020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8020000\n",
      "  training_iteration: 802\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19036 s, 802 iter, 8020000 ts, 1.01e+03 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-27-33\n",
      "  done: false\n",
      "  episode_len_mean: 164.86\n",
      "  episode_reward_max: 1169.505928097205\n",
      "  episode_reward_mean: 1029.8412812499146\n",
      "  episode_reward_min: 887.2123919637107\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 46665\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.166\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 8030000\n",
      "    num_steps_trained: 8030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.13571806252002716\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.33443570137023926\n",
      "      kl: 0.04377644136548042\n",
      "      policy_loss: 0.00141542823985219\n",
      "      total_loss: 34.724727630615234\n",
      "      vf_explained_var: 0.9985140562057495\n",
      "      vf_loss: 34.717369079589844\n",
      "    sample_time_ms: 19968.356\n",
      "    update_time_ms: 5.633\n",
      "  iterations_since_restore: 803\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 514.9206406249574\n",
      "  time_since_restore: 19060.341544151306\n",
      "  time_this_iter_s: 23.778613090515137\n",
      "  time_total_s: 19060.341544151306\n",
      "  timestamp: 1553984853\n",
      "  timesteps_since_restore: 8030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8030000\n",
      "  training_iteration: 803\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19060 s, 803 iter, 8030000 ts, 1.03e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-27-56\n",
      "  done: false\n",
      "  episode_len_mean: 164.01\n",
      "  episode_reward_max: 1131.7739783944965\n",
      "  episode_reward_mean: 972.4190090240929\n",
      "  episode_reward_min: -22.645079180854395\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 46725\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.485\n",
      "    load_time_ms: 1.416\n",
      "    num_steps_sampled: 8040000\n",
      "    num_steps_trained: 8040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20357707142829895\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8806166052818298\n",
      "      kl: 0.008270088583230972\n",
      "      policy_loss: -0.0017034077318385243\n",
      "      total_loss: 1120.9302978515625\n",
      "      vf_explained_var: 0.9563224911689758\n",
      "      vf_loss: 1120.9302978515625\n",
      "    sample_time_ms: 20016.996\n",
      "    update_time_ms: 5.329\n",
      "  iterations_since_restore: 804\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.2095045120466\n",
      "  time_since_restore: 19084.00232577324\n",
      "  time_this_iter_s: 23.660781621932983\n",
      "  time_total_s: 19084.00232577324\n",
      "  timestamp: 1553984876\n",
      "  timesteps_since_restore: 8040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8040000\n",
      "  training_iteration: 804\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19084 s, 804 iter, 8040000 ts, 972 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-28-20\n",
      "  done: false\n",
      "  episode_len_mean: 173.8\n",
      "  episode_reward_max: 1125.5995861059457\n",
      "  episode_reward_mean: 943.4864968156594\n",
      "  episode_reward_min: -22.645079180854395\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 46780\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.96\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 8050000\n",
      "    num_steps_trained: 8050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10178853571414948\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1728816032409668\n",
      "      kl: 0.017817936837673187\n",
      "      policy_loss: -0.006142336875200272\n",
      "      total_loss: 475.8277282714844\n",
      "      vf_explained_var: 0.9787926077842712\n",
      "      vf_loss: 475.83203125\n",
      "    sample_time_ms: 20044.994\n",
      "    update_time_ms: 5.441\n",
      "  iterations_since_restore: 805\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.7432484078296\n",
      "  time_since_restore: 19107.92895102501\n",
      "  time_this_iter_s: 23.92662525177002\n",
      "  time_total_s: 19107.92895102501\n",
      "  timestamp: 1553984900\n",
      "  timesteps_since_restore: 8050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8050000\n",
      "  training_iteration: 805\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19107 s, 805 iter, 8050000 ts, 943 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-28-44\n",
      "  done: false\n",
      "  episode_len_mean: 175.23\n",
      "  episode_reward_max: 1152.5227372476966\n",
      "  episode_reward_mean: 971.2337658074496\n",
      "  episode_reward_min: -53.3713430338162\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 46839\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.397\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 8060000\n",
      "    num_steps_trained: 8060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10178853571414948\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6331387758255005\n",
      "      kl: 0.01445241179317236\n",
      "      policy_loss: -0.00028257109806872904\n",
      "      total_loss: 397.929931640625\n",
      "      vf_explained_var: 0.9840318560600281\n",
      "      vf_loss: 397.9287414550781\n",
      "    sample_time_ms: 20011.655\n",
      "    update_time_ms: 5.707\n",
      "  iterations_since_restore: 806\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.6168829037248\n",
      "  time_since_restore: 19131.749801397324\n",
      "  time_this_iter_s: 23.820850372314453\n",
      "  time_total_s: 19131.749801397324\n",
      "  timestamp: 1553984924\n",
      "  timesteps_since_restore: 8060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8060000\n",
      "  training_iteration: 806\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19131 s, 806 iter, 8060000 ts, 971 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-29-08\n",
      "  done: false\n",
      "  episode_len_mean: 169.52\n",
      "  episode_reward_max: 1152.5227372476966\n",
      "  episode_reward_mean: 997.421733205851\n",
      "  episode_reward_min: -62.082143408877414\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 46899\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3908.1\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 8070000\n",
      "    num_steps_trained: 8070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10178853571414948\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.552794337272644\n",
      "      kl: 0.01611926220357418\n",
      "      policy_loss: -0.0008597689447924495\n",
      "      total_loss: 142.88531494140625\n",
      "      vf_explained_var: 0.9939976334571838\n",
      "      vf_loss: 142.88453674316406\n",
      "    sample_time_ms: 19994.223\n",
      "    update_time_ms: 5.527\n",
      "  iterations_since_restore: 807\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.71086660292553\n",
      "  time_since_restore: 19155.66975903511\n",
      "  time_this_iter_s: 23.919957637786865\n",
      "  time_total_s: 19155.66975903511\n",
      "  timestamp: 1553984948\n",
      "  timesteps_since_restore: 8070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8070000\n",
      "  training_iteration: 807\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19155 s, 807 iter, 8070000 ts, 997 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-29-32\n",
      "  done: false\n",
      "  episode_len_mean: 168.11\n",
      "  episode_reward_max: 1124.2616702491282\n",
      "  episode_reward_mean: 1031.3972481797855\n",
      "  episode_reward_min: 892.7229854857321\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 46958\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.235\n",
      "    load_time_ms: 1.435\n",
      "    num_steps_sampled: 8080000\n",
      "    num_steps_trained: 8080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10178853571414948\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4419134557247162\n",
      "      kl: 0.026413101702928543\n",
      "      policy_loss: 0.0015169160906225443\n",
      "      total_loss: 51.68293762207031\n",
      "      vf_explained_var: 0.9976460337638855\n",
      "      vf_loss: 51.67873764038086\n",
      "    sample_time_ms: 19972.944\n",
      "    update_time_ms: 5.508\n",
      "  iterations_since_restore: 808\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 515.6986240898929\n",
      "  time_since_restore: 19179.399833202362\n",
      "  time_this_iter_s: 23.730074167251587\n",
      "  time_total_s: 19179.399833202362\n",
      "  timestamp: 1553984972\n",
      "  timesteps_since_restore: 8080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8080000\n",
      "  training_iteration: 808\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19179 s, 808 iter, 8080000 ts, 1.03e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 168.27\n",
      "  episode_reward_max: 1145.0273576121865\n",
      "  episode_reward_mean: 1016.821050780465\n",
      "  episode_reward_min: -0.7011334140485417\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 47017\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3907.698\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 8090000\n",
      "    num_steps_trained: 8090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10178853571414948\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7571077346801758\n",
      "      kl: 0.009912127628922462\n",
      "      policy_loss: -0.0004272881196811795\n",
      "      total_loss: 501.68475341796875\n",
      "      vf_explained_var: 0.9796664714813232\n",
      "      vf_loss: 501.6842041015625\n",
      "    sample_time_ms: 19842.437\n",
      "    update_time_ms: 5.506\n",
      "  iterations_since_restore: 809\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 508.4105253902325\n",
      "  time_since_restore: 19202.610498666763\n",
      "  time_this_iter_s: 23.210665464401245\n",
      "  time_total_s: 19202.610498666763\n",
      "  timestamp: 1553984995\n",
      "  timesteps_since_restore: 8090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8090000\n",
      "  training_iteration: 809\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19202 s, 809 iter, 8090000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-30-18\n",
      "  done: false\n",
      "  episode_len_mean: 171.55\n",
      "  episode_reward_max: 1142.7869682220578\n",
      "  episode_reward_mean: 971.7776375438721\n",
      "  episode_reward_min: -56.17703920446402\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 47076\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.845\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 8100000\n",
      "    num_steps_trained: 8100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05089426785707474\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9483253359794617\n",
      "      kl: 0.02043960988521576\n",
      "      policy_loss: -0.0009939050069078803\n",
      "      total_loss: 931.7728271484375\n",
      "      vf_explained_var: 0.9641075134277344\n",
      "      vf_loss: 931.7728271484375\n",
      "    sample_time_ms: 19774.184\n",
      "    update_time_ms: 5.598\n",
      "  iterations_since_restore: 810\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.88881877193603\n",
      "  time_since_restore: 19225.402470350266\n",
      "  time_this_iter_s: 22.791971683502197\n",
      "  time_total_s: 19225.402470350266\n",
      "  timestamp: 1553985018\n",
      "  timesteps_since_restore: 8100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8100000\n",
      "  training_iteration: 810\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19225 s, 810 iter, 8100000 ts, 972 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-30-42\n",
      "  done: false\n",
      "  episode_len_mean: 169.14\n",
      "  episode_reward_max: 1134.103340658534\n",
      "  episode_reward_mean: 997.5168113604781\n",
      "  episode_reward_min: -20.686086929656796\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 47135\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.211\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 8110000\n",
      "    num_steps_trained: 8110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05089426785707474\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4817918539047241\n",
      "      kl: 0.0436578169465065\n",
      "      policy_loss: -0.0019165277481079102\n",
      "      total_loss: 109.74829864501953\n",
      "      vf_explained_var: 0.9955618381500244\n",
      "      vf_loss: 109.74798583984375\n",
      "    sample_time_ms: 19785.232\n",
      "    update_time_ms: 5.692\n",
      "  iterations_since_restore: 811\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.75840568023904\n",
      "  time_since_restore: 19249.311729431152\n",
      "  time_this_iter_s: 23.90925908088684\n",
      "  time_total_s: 19249.311729431152\n",
      "  timestamp: 1553985042\n",
      "  timesteps_since_restore: 8110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8110000\n",
      "  training_iteration: 811\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19249 s, 811 iter, 8110000 ts, 998 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-31-06\n",
      "  done: false\n",
      "  episode_len_mean: 162.59\n",
      "  episode_reward_max: 1120.8930606692131\n",
      "  episode_reward_mean: 948.9114764619745\n",
      "  episode_reward_min: -91.71705114678707\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 47200\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.425\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 8120000\n",
      "    num_steps_trained: 8120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6862887144088745\n",
      "      kl: 0.020555006340146065\n",
      "      policy_loss: -0.006223224103450775\n",
      "      total_loss: 1863.795654296875\n",
      "      vf_explained_var: 0.9258770942687988\n",
      "      vf_loss: 1863.800048828125\n",
      "    sample_time_ms: 19719.244\n",
      "    update_time_ms: 5.717\n",
      "  iterations_since_restore: 812\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.4557382309872\n",
      "  time_since_restore: 19272.90563941002\n",
      "  time_this_iter_s: 23.593909978866577\n",
      "  time_total_s: 19272.90563941002\n",
      "  timestamp: 1553985066\n",
      "  timesteps_since_restore: 8120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8120000\n",
      "  training_iteration: 812\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19272 s, 812 iter, 8120000 ts, 949 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-31-30\n",
      "  done: false\n",
      "  episode_len_mean: 162.37\n",
      "  episode_reward_max: 1149.6468645618284\n",
      "  episode_reward_mean: 935.5089169052738\n",
      "  episode_reward_min: -91.71705114678707\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 47260\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.399\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 8130000\n",
      "    num_steps_trained: 8130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7847388982772827\n",
      "      kl: 0.01855449192225933\n",
      "      policy_loss: -0.0032993187196552753\n",
      "      total_loss: 1217.4677734375\n",
      "      vf_explained_var: 0.9452475309371948\n",
      "      vf_loss: 1217.4696044921875\n",
      "    sample_time_ms: 19739.942\n",
      "    update_time_ms: 5.746\n",
      "  iterations_since_restore: 813\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.754458452637\n",
      "  time_since_restore: 19296.812749624252\n",
      "  time_this_iter_s: 23.9071102142334\n",
      "  time_total_s: 19296.812749624252\n",
      "  timestamp: 1553985090\n",
      "  timesteps_since_restore: 8130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8130000\n",
      "  training_iteration: 813\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19296 s, 813 iter, 8130000 ts, 936 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-31-53\n",
      "  done: false\n",
      "  episode_len_mean: 168.81\n",
      "  episode_reward_max: 1149.6468645618284\n",
      "  episode_reward_mean: 977.8651902691868\n",
      "  episode_reward_min: -76.86769228058517\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 47318\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.006\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 8140000\n",
      "    num_steps_trained: 8140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6306630373001099\n",
      "      kl: 0.019300952553749084\n",
      "      policy_loss: -0.0008967587491497397\n",
      "      total_loss: 307.3997497558594\n",
      "      vf_explained_var: 0.9870432615280151\n",
      "      vf_loss: 307.399169921875\n",
      "    sample_time_ms: 19733.204\n",
      "    update_time_ms: 5.799\n",
      "  iterations_since_restore: 814\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.93259513459344\n",
      "  time_since_restore: 19320.444885015488\n",
      "  time_this_iter_s: 23.63213539123535\n",
      "  time_total_s: 19320.444885015488\n",
      "  timestamp: 1553985113\n",
      "  timesteps_since_restore: 8140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8140000\n",
      "  training_iteration: 814\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19320 s, 814 iter, 8140000 ts, 978 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-32-17\n",
      "  done: false\n",
      "  episode_len_mean: 165.82\n",
      "  episode_reward_max: 1126.16238365061\n",
      "  episode_reward_mean: 984.4299651177109\n",
      "  episode_reward_min: -90.0380350546056\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 47381\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.034\n",
      "    load_time_ms: 1.643\n",
      "    num_steps_sampled: 8150000\n",
      "    num_steps_trained: 8150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.524695098400116\n",
      "      kl: 0.02231084369122982\n",
      "      policy_loss: -0.004614267963916063\n",
      "      total_loss: 505.1239929199219\n",
      "      vf_explained_var: 0.9806146621704102\n",
      "      vf_loss: 505.12689208984375\n",
      "    sample_time_ms: 19713.364\n",
      "    update_time_ms: 5.682\n",
      "  iterations_since_restore: 815\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.2149825588556\n",
      "  time_since_restore: 19344.15732693672\n",
      "  time_this_iter_s: 23.71244192123413\n",
      "  time_total_s: 19344.15732693672\n",
      "  timestamp: 1553985137\n",
      "  timesteps_since_restore: 8150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8150000\n",
      "  training_iteration: 815\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19344 s, 815 iter, 8150000 ts, 984 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-32-41\n",
      "  done: false\n",
      "  episode_len_mean: 161.85\n",
      "  episode_reward_max: 1126.16238365061\n",
      "  episode_reward_mean: 966.2342224182839\n",
      "  episode_reward_min: -77.07706968562142\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 47442\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.76\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 8160000\n",
      "    num_steps_trained: 8160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.495699942111969\n",
      "      kl: 0.020719949156045914\n",
      "      policy_loss: -0.005361251998692751\n",
      "      total_loss: 544.6327514648438\n",
      "      vf_explained_var: 0.9782065153121948\n",
      "      vf_loss: 544.6365356445312\n",
      "    sample_time_ms: 19725.905\n",
      "    update_time_ms: 5.458\n",
      "  iterations_since_restore: 816\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.117111209142\n",
      "  time_since_restore: 19368.158468961716\n",
      "  time_this_iter_s: 24.001142024993896\n",
      "  time_total_s: 19368.158468961716\n",
      "  timestamp: 1553985161\n",
      "  timesteps_since_restore: 8160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8160000\n",
      "  training_iteration: 816\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19368 s, 816 iter, 8160000 ts, 966 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-33-04\n",
      "  done: false\n",
      "  episode_len_mean: 161.75\n",
      "  episode_reward_max: 1168.0580481276625\n",
      "  episode_reward_mean: 975.8183051875714\n",
      "  episode_reward_min: -51.57578251457335\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 47504\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3874.829\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 8170000\n",
      "    num_steps_trained: 8170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5961878895759583\n",
      "      kl: 0.015329482033848763\n",
      "      policy_loss: -0.0009499566513113678\n",
      "      total_loss: 688.6085815429688\n",
      "      vf_explained_var: 0.9700824022293091\n",
      "      vf_loss: 688.6083984375\n",
      "    sample_time_ms: 19675.406\n",
      "    update_time_ms: 5.427\n",
      "  iterations_since_restore: 817\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.9091525937857\n",
      "  time_since_restore: 19391.422159433365\n",
      "  time_this_iter_s: 23.26369047164917\n",
      "  time_total_s: 19391.422159433365\n",
      "  timestamp: 1553985184\n",
      "  timesteps_since_restore: 8170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8170000\n",
      "  training_iteration: 817\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19391 s, 817 iter, 8170000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-33-29\n",
      "  done: false\n",
      "  episode_len_mean: 171.84\n",
      "  episode_reward_max: 1168.0580481276625\n",
      "  episode_reward_mean: 993.5868646617132\n",
      "  episode_reward_min: -72.31701224253713\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 47560\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.154\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 8180000\n",
      "    num_steps_trained: 8180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7440692186355591\n",
      "      kl: 0.021929088979959488\n",
      "      policy_loss: -0.003514211857691407\n",
      "      total_loss: 345.1106262207031\n",
      "      vf_explained_var: 0.9847905039787292\n",
      "      vf_loss: 345.11248779296875\n",
      "    sample_time_ms: 19707.459\n",
      "    update_time_ms: 5.505\n",
      "  iterations_since_restore: 818\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.7934323308566\n",
      "  time_since_restore: 19415.520793676376\n",
      "  time_this_iter_s: 24.098634243011475\n",
      "  time_total_s: 19415.520793676376\n",
      "  timestamp: 1553985209\n",
      "  timesteps_since_restore: 8180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8180000\n",
      "  training_iteration: 818\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19415 s, 818 iter, 8180000 ts, 994 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-33-52\n",
      "  done: false\n",
      "  episode_len_mean: 173.9\n",
      "  episode_reward_max: 1147.6325930852388\n",
      "  episode_reward_mean: 991.6985515249719\n",
      "  episode_reward_min: 88.64999814458827\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 47618\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.61\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 8190000\n",
      "    num_steps_trained: 8190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9176774621009827\n",
      "      kl: 0.025128290057182312\n",
      "      policy_loss: -0.00529415812343359\n",
      "      total_loss: 673.8662109375\n",
      "      vf_explained_var: 0.9749581813812256\n",
      "      vf_loss: 673.8695678710938\n",
      "    sample_time_ms: 19711.606\n",
      "    update_time_ms: 5.364\n",
      "  iterations_since_restore: 819\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.84927576248583\n",
      "  time_since_restore: 19438.754615068436\n",
      "  time_this_iter_s: 23.233821392059326\n",
      "  time_total_s: 19438.754615068436\n",
      "  timestamp: 1553985232\n",
      "  timesteps_since_restore: 8190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8190000\n",
      "  training_iteration: 819\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19438 s, 819 iter, 8190000 ts, 992 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-34-16\n",
      "  done: false\n",
      "  episode_len_mean: 167.18\n",
      "  episode_reward_max: 1149.432370608754\n",
      "  episode_reward_mean: 976.8612857472026\n",
      "  episode_reward_min: -4.877431743308847\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 47678\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.489\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 8200000\n",
      "    num_steps_trained: 8200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5204561948776245\n",
      "      kl: 0.02198840118944645\n",
      "      policy_loss: -0.005923790857195854\n",
      "      total_loss: 373.3089294433594\n",
      "      vf_explained_var: 0.9840208888053894\n",
      "      vf_loss: 373.3132019042969\n",
      "    sample_time_ms: 19787.939\n",
      "    update_time_ms: 5.555\n",
      "  iterations_since_restore: 820\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.4306428736013\n",
      "  time_since_restore: 19462.39372420311\n",
      "  time_this_iter_s: 23.639109134674072\n",
      "  time_total_s: 19462.39372420311\n",
      "  timestamp: 1553985256\n",
      "  timesteps_since_restore: 8200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8200000\n",
      "  training_iteration: 820\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19462 s, 820 iter, 8200000 ts, 977 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-34-39\n",
      "  done: false\n",
      "  episode_len_mean: 166.98\n",
      "  episode_reward_max: 1151.8543587043469\n",
      "  episode_reward_mean: 952.4361843631181\n",
      "  episode_reward_min: -30.658123476003453\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 47738\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.214\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 8210000\n",
      "    num_steps_trained: 8210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.923399806022644\n",
      "      kl: 0.020149823278188705\n",
      "      policy_loss: 0.0007738350541330874\n",
      "      total_loss: 744.2941284179688\n",
      "      vf_explained_var: 0.9726282954216003\n",
      "      vf_loss: 744.291748046875\n",
      "    sample_time_ms: 19752.279\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 821\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.2180921815589\n",
      "  time_since_restore: 19486.301285028458\n",
      "  time_this_iter_s: 23.9075608253479\n",
      "  time_total_s: 19486.301285028458\n",
      "  timestamp: 1553985279\n",
      "  timesteps_since_restore: 8210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8210000\n",
      "  training_iteration: 821\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19486 s, 821 iter, 8210000 ts, 952 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-35-02\n",
      "  done: false\n",
      "  episode_len_mean: 165.59\n",
      "  episode_reward_max: 1151.8543587043469\n",
      "  episode_reward_mean: 946.3264492026876\n",
      "  episode_reward_min: -40.33240148884164\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 47799\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3925.077\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 8220000\n",
      "    num_steps_trained: 8220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5193568468093872\n",
      "      kl: 0.019299782812595367\n",
      "      policy_loss: -0.001963273622095585\n",
      "      total_loss: 596.8123779296875\n",
      "      vf_explained_var: 0.9725866317749023\n",
      "      vf_loss: 596.8128051757812\n",
      "    sample_time_ms: 19642.185\n",
      "    update_time_ms: 5.354\n",
      "  iterations_since_restore: 822\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 473.1632246013438\n",
      "  time_since_restore: 19508.831790685654\n",
      "  time_this_iter_s: 22.530505657196045\n",
      "  time_total_s: 19508.831790685654\n",
      "  timestamp: 1553985302\n",
      "  timesteps_since_restore: 8220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8220000\n",
      "  training_iteration: 822\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19508 s, 822 iter, 8220000 ts, 946 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-35-27\n",
      "  done: false\n",
      "  episode_len_mean: 170.94\n",
      "  episode_reward_max: 1130.048437447833\n",
      "  episode_reward_mean: 967.5088684670201\n",
      "  episode_reward_min: -58.39242333502702\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 47856\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3923.198\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 8230000\n",
      "    num_steps_trained: 8230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9885776042938232\n",
      "      kl: 0.01419754046946764\n",
      "      policy_loss: -0.0008469379390589893\n",
      "      total_loss: 815.1873779296875\n",
      "      vf_explained_var: 0.9656540155410767\n",
      "      vf_loss: 815.1870727539062\n",
      "    sample_time_ms: 19700.42\n",
      "    update_time_ms: 5.635\n",
      "  iterations_since_restore: 823\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.7544342335101\n",
      "  time_since_restore: 19533.307262182236\n",
      "  time_this_iter_s: 24.47547149658203\n",
      "  time_total_s: 19533.307262182236\n",
      "  timestamp: 1553985327\n",
      "  timesteps_since_restore: 8230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8230000\n",
      "  training_iteration: 823\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19533 s, 823 iter, 8230000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-35-50\n",
      "  done: false\n",
      "  episode_len_mean: 172.35\n",
      "  episode_reward_max: 1132.964203976741\n",
      "  episode_reward_mean: 984.3387638746378\n",
      "  episode_reward_min: -58.39242333502702\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 47915\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.066\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 8240000\n",
      "    num_steps_trained: 8240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.505334198474884\n",
      "      kl: 0.02186807058751583\n",
      "      policy_loss: -0.0006207497790455818\n",
      "      total_loss: 206.0330352783203\n",
      "      vf_explained_var: 0.9904972910881042\n",
      "      vf_loss: 206.031982421875\n",
      "    sample_time_ms: 19723.005\n",
      "    update_time_ms: 5.483\n",
      "  iterations_since_restore: 824\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.1693819373189\n",
      "  time_since_restore: 19557.109804153442\n",
      "  time_this_iter_s: 23.802541971206665\n",
      "  time_total_s: 19557.109804153442\n",
      "  timestamp: 1553985350\n",
      "  timesteps_since_restore: 8240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8240000\n",
      "  training_iteration: 824\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19557 s, 824 iter, 8240000 ts, 984 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-36-14\n",
      "  done: false\n",
      "  episode_len_mean: 173.11\n",
      "  episode_reward_max: 1132.964203976741\n",
      "  episode_reward_mean: 994.8408611342242\n",
      "  episode_reward_min: -35.66795367158639\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 47972\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.564\n",
      "    load_time_ms: 1.435\n",
      "    num_steps_sampled: 8250000\n",
      "    num_steps_trained: 8250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.945371687412262\n",
      "      kl: 0.017482982948422432\n",
      "      policy_loss: -0.0019800434820353985\n",
      "      total_loss: 564.1319580078125\n",
      "      vf_explained_var: 0.9772099256515503\n",
      "      vf_loss: 564.1326293945312\n",
      "    sample_time_ms: 19753.838\n",
      "    update_time_ms: 5.507\n",
      "  iterations_since_restore: 825\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.4204305671121\n",
      "  time_since_restore: 19581.140047311783\n",
      "  time_this_iter_s: 24.030243158340454\n",
      "  time_total_s: 19581.140047311783\n",
      "  timestamp: 1553985374\n",
      "  timesteps_since_restore: 8250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8250000\n",
      "  training_iteration: 825\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19581 s, 825 iter, 8250000 ts, 995 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-36-38\n",
      "  done: false\n",
      "  episode_len_mean: 177.61\n",
      "  episode_reward_max: 1141.7403897578322\n",
      "  episode_reward_mean: 967.4071206663342\n",
      "  episode_reward_min: -87.40829176794148\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 48029\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3939.899\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 8260000\n",
      "    num_steps_trained: 8260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7877212762832642\n",
      "      kl: 0.026112284511327744\n",
      "      policy_loss: -0.006287659052759409\n",
      "      total_loss: 630.8212280273438\n",
      "      vf_explained_var: 0.9734200835227966\n",
      "      vf_loss: 630.8255004882812\n",
      "    sample_time_ms: 19723.522\n",
      "    update_time_ms: 5.521\n",
      "  iterations_since_restore: 826\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.7035603331671\n",
      "  time_since_restore: 19605.04135608673\n",
      "  time_this_iter_s: 23.90130877494812\n",
      "  time_total_s: 19605.04135608673\n",
      "  timestamp: 1553985398\n",
      "  timesteps_since_restore: 8260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8260000\n",
      "  training_iteration: 826\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19605 s, 826 iter, 8260000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-37-03\n",
      "  done: false\n",
      "  episode_len_mean: 175.56\n",
      "  episode_reward_max: 1124.0578463902273\n",
      "  episode_reward_mean: 989.3851762840998\n",
      "  episode_reward_min: -87.40829176794148\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 48086\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3937.63\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 8270000\n",
      "    num_steps_trained: 8270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.715809166431427\n",
      "      kl: 0.02166460081934929\n",
      "      policy_loss: -0.002857103943824768\n",
      "      total_loss: 300.88690185546875\n",
      "      vf_explained_var: 0.9871366620063782\n",
      "      vf_loss: 300.8880615234375\n",
      "    sample_time_ms: 19839.405\n",
      "    update_time_ms: 5.568\n",
      "  iterations_since_restore: 827\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.6925881420498\n",
      "  time_since_restore: 19629.443544626236\n",
      "  time_this_iter_s: 24.402188539505005\n",
      "  time_total_s: 19629.443544626236\n",
      "  timestamp: 1553985423\n",
      "  timesteps_since_restore: 8270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8270000\n",
      "  training_iteration: 827\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19629 s, 827 iter, 8270000 ts, 989 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-37-27\n",
      "  done: false\n",
      "  episode_len_mean: 173.06\n",
      "  episode_reward_max: 1142.7275512734875\n",
      "  episode_reward_mean: 990.7523372984517\n",
      "  episode_reward_min: -44.18421713686823\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 48146\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3929.518\n",
      "    load_time_ms: 1.407\n",
      "    num_steps_sampled: 8280000\n",
      "    num_steps_trained: 8280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7591965794563293\n",
      "      kl: 0.018081793561577797\n",
      "      policy_loss: -0.0018832091009244323\n",
      "      total_loss: 682.5476684570312\n",
      "      vf_explained_var: 0.9703155755996704\n",
      "      vf_loss: 682.5481567382812\n",
      "    sample_time_ms: 19870.321\n",
      "    update_time_ms: 5.555\n",
      "  iterations_since_restore: 828\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.37616864922586\n",
      "  time_since_restore: 19653.765694141388\n",
      "  time_this_iter_s: 24.322149515151978\n",
      "  time_total_s: 19653.765694141388\n",
      "  timestamp: 1553985447\n",
      "  timesteps_since_restore: 8280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8280000\n",
      "  training_iteration: 828\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19653 s, 828 iter, 8280000 ts, 991 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-37-51\n",
      "  done: false\n",
      "  episode_len_mean: 171.08\n",
      "  episode_reward_max: 1142.7275512734875\n",
      "  episode_reward_mean: 993.2424532103312\n",
      "  episode_reward_min: -78.47232091588182\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 48204\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3931.132\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 8290000\n",
      "    num_steps_trained: 8290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6297873258590698\n",
      "      kl: 0.019418654963374138\n",
      "      policy_loss: -0.0025664896238595247\n",
      "      total_loss: 266.80792236328125\n",
      "      vf_explained_var: 0.9891042709350586\n",
      "      vf_loss: 266.8090515136719\n",
      "    sample_time_ms: 19943.452\n",
      "    update_time_ms: 5.557\n",
      "  iterations_since_restore: 829\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.62122660516565\n",
      "  time_since_restore: 19677.748845100403\n",
      "  time_this_iter_s: 23.983150959014893\n",
      "  time_total_s: 19677.748845100403\n",
      "  timestamp: 1553985471\n",
      "  timesteps_since_restore: 8290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8290000\n",
      "  training_iteration: 829\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19677 s, 829 iter, 8290000 ts, 993 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-38-15\n",
      "  done: false\n",
      "  episode_len_mean: 169.89\n",
      "  episode_reward_max: 1142.1083310516128\n",
      "  episode_reward_mean: 1005.6316649748593\n",
      "  episode_reward_min: -9.913036375592355\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 48261\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3929.749\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 8300000\n",
      "    num_steps_trained: 8300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8924139142036438\n",
      "      kl: 0.019249338656663895\n",
      "      policy_loss: -0.0027303285896778107\n",
      "      total_loss: 486.4750671386719\n",
      "      vf_explained_var: 0.9783088564872742\n",
      "      vf_loss: 486.47625732421875\n",
      "    sample_time_ms: 19978.958\n",
      "    update_time_ms: 5.349\n",
      "  iterations_since_restore: 830\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 502.8158324874296\n",
      "  time_since_restore: 19701.732057094574\n",
      "  time_this_iter_s: 23.983211994171143\n",
      "  time_total_s: 19701.732057094574\n",
      "  timestamp: 1553985495\n",
      "  timesteps_since_restore: 8300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8300000\n",
      "  training_iteration: 830\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19701 s, 830 iter, 8300000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-38-39\n",
      "  done: false\n",
      "  episode_len_mean: 164.8\n",
      "  episode_reward_max: 1103.4291499779517\n",
      "  episode_reward_mean: 955.5515885364771\n",
      "  episode_reward_min: -67.63308246116657\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 48324\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.733\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 8310000\n",
      "    num_steps_trained: 8310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6152089238166809\n",
      "      kl: 0.01895187236368656\n",
      "      policy_loss: -0.0008464486454613507\n",
      "      total_loss: 1042.6790771484375\n",
      "      vf_explained_var: 0.9584019780158997\n",
      "      vf_loss: 1042.6787109375\n",
      "    sample_time_ms: 19996.807\n",
      "    update_time_ms: 5.471\n",
      "  iterations_since_restore: 831\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.77579426823854\n",
      "  time_since_restore: 19725.7197368145\n",
      "  time_this_iter_s: 23.987679719924927\n",
      "  time_total_s: 19725.7197368145\n",
      "  timestamp: 1553985519\n",
      "  timesteps_since_restore: 8310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8310000\n",
      "  training_iteration: 831\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19725 s, 831 iter, 8310000 ts, 956 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-39-03\n",
      "  done: false\n",
      "  episode_len_mean: 169.51\n",
      "  episode_reward_max: 1115.6296958612847\n",
      "  episode_reward_mean: 968.9119071800887\n",
      "  episode_reward_min: -67.63308246116657\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 48384\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.531\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 8320000\n",
      "    num_steps_trained: 8320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5405762791633606\n",
      "      kl: 0.02280706912279129\n",
      "      policy_loss: -0.003360084956511855\n",
      "      total_loss: 330.6311340332031\n",
      "      vf_explained_var: 0.9864523410797119\n",
      "      vf_loss: 330.63275146484375\n",
      "    sample_time_ms: 20090.534\n",
      "    update_time_ms: 5.443\n",
      "  iterations_since_restore: 832\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.4559535900444\n",
      "  time_since_restore: 19749.167620182037\n",
      "  time_this_iter_s: 23.447883367538452\n",
      "  time_total_s: 19749.167620182037\n",
      "  timestamp: 1553985543\n",
      "  timesteps_since_restore: 8320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8320000\n",
      "  training_iteration: 832\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19749 s, 832 iter, 8320000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-39-26\n",
      "  done: false\n",
      "  episode_len_mean: 166.34\n",
      "  episode_reward_max: 1123.0401520993382\n",
      "  episode_reward_mean: 955.4256972559283\n",
      "  episode_reward_min: -74.94801765646437\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 48444\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3922.023\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 8330000\n",
      "    num_steps_trained: 8330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5388466119766235\n",
      "      kl: 0.01770949736237526\n",
      "      policy_loss: -0.00015268989955075085\n",
      "      total_loss: 557.6068725585938\n",
      "      vf_explained_var: 0.977541983127594\n",
      "      vf_loss: 557.6055908203125\n",
      "    sample_time_ms: 19991.171\n",
      "    update_time_ms: 5.338\n",
      "  iterations_since_restore: 833\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.7128486279642\n",
      "  time_since_restore: 19772.6926817894\n",
      "  time_this_iter_s: 23.52506160736084\n",
      "  time_total_s: 19772.6926817894\n",
      "  timestamp: 1553985566\n",
      "  timesteps_since_restore: 8330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8330000\n",
      "  training_iteration: 833\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19772 s, 833 iter, 8330000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-39-50\n",
      "  done: false\n",
      "  episode_len_mean: 168.51\n",
      "  episode_reward_max: 1156.040652687608\n",
      "  episode_reward_mean: 961.1147075429726\n",
      "  episode_reward_min: -74.94801765646437\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 48503\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.926\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 8340000\n",
      "    num_steps_trained: 8340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7459582090377808\n",
      "      kl: 0.014434936456382275\n",
      "      policy_loss: -0.0013797684805467725\n",
      "      total_loss: 452.0625\n",
      "      vf_explained_var: 0.9808887839317322\n",
      "      vf_loss: 452.062744140625\n",
      "    sample_time_ms: 19982.967\n",
      "    update_time_ms: 5.325\n",
      "  iterations_since_restore: 834\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.55735377148625\n",
      "  time_since_restore: 19796.384435415268\n",
      "  time_this_iter_s: 23.69175362586975\n",
      "  time_total_s: 19796.384435415268\n",
      "  timestamp: 1553985590\n",
      "  timesteps_since_restore: 8340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8340000\n",
      "  training_iteration: 834\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19796 s, 834 iter, 8340000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 164.01\n",
      "  episode_reward_max: 1119.4174750340776\n",
      "  episode_reward_mean: 974.3530840017945\n",
      "  episode_reward_min: -13.868301104718256\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 48564\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.564\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 8350000\n",
      "    num_steps_trained: 8350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3581080436706543\n",
      "      kl: 0.020795688033103943\n",
      "      policy_loss: -0.002266908995807171\n",
      "      total_loss: 493.0849304199219\n",
      "      vf_explained_var: 0.9799910187721252\n",
      "      vf_loss: 493.0855407714844\n",
      "    sample_time_ms: 19973.185\n",
      "    update_time_ms: 5.313\n",
      "  iterations_since_restore: 835\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.17654200089726\n",
      "  time_since_restore: 19820.244470834732\n",
      "  time_this_iter_s: 23.86003541946411\n",
      "  time_total_s: 19820.244470834732\n",
      "  timestamp: 1553985614\n",
      "  timesteps_since_restore: 8350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8350000\n",
      "  training_iteration: 835\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19820 s, 835 iter, 8350000 ts, 974 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-40-38\n",
      "  done: false\n",
      "  episode_len_mean: 163.85\n",
      "  episode_reward_max: 1143.9502410371301\n",
      "  episode_reward_mean: 969.2311112468877\n",
      "  episode_reward_min: -26.997091832818967\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 48624\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.751\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 8360000\n",
      "    num_steps_trained: 8360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7227953672409058\n",
      "      kl: 0.01820722036063671\n",
      "      policy_loss: 4.697495387517847e-05\n",
      "      total_loss: 805.267822265625\n",
      "      vf_explained_var: 0.9694461226463318\n",
      "      vf_loss: 805.2664184570312\n",
      "    sample_time_ms: 19994.987\n",
      "    update_time_ms: 5.241\n",
      "  iterations_since_restore: 836\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.6155556234438\n",
      "  time_since_restore: 19844.300035238266\n",
      "  time_this_iter_s: 24.055564403533936\n",
      "  time_total_s: 19844.300035238266\n",
      "  timestamp: 1553985638\n",
      "  timesteps_since_restore: 8360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8360000\n",
      "  training_iteration: 836\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19844 s, 836 iter, 8360000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-41-02\n",
      "  done: false\n",
      "  episode_len_mean: 165.1\n",
      "  episode_reward_max: 1143.9502410371301\n",
      "  episode_reward_mean: 949.8708276237678\n",
      "  episode_reward_min: -42.15125944980514\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 48687\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.45\n",
      "    load_time_ms: 1.661\n",
      "    num_steps_sampled: 8370000\n",
      "    num_steps_trained: 8370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5070348978042603\n",
      "      kl: 0.0251784548163414\n",
      "      policy_loss: -0.001894960063509643\n",
      "      total_loss: 735.6640014648438\n",
      "      vf_explained_var: 0.9698893427848816\n",
      "      vf_loss: 735.6639404296875\n",
      "    sample_time_ms: 19942.813\n",
      "    update_time_ms: 5.476\n",
      "  iterations_since_restore: 837\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.9354138118839\n",
      "  time_since_restore: 19868.252948999405\n",
      "  time_this_iter_s: 23.952913761138916\n",
      "  time_total_s: 19868.252948999405\n",
      "  timestamp: 1553985662\n",
      "  timesteps_since_restore: 8370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8370000\n",
      "  training_iteration: 837\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19868 s, 837 iter, 8370000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-41-26\n",
      "  done: false\n",
      "  episode_len_mean: 164.78\n",
      "  episode_reward_max: 1121.3579536384325\n",
      "  episode_reward_mean: 955.91067922837\n",
      "  episode_reward_min: -48.4596882560831\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 48746\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.16\n",
      "    load_time_ms: 1.665\n",
      "    num_steps_sampled: 8380000\n",
      "    num_steps_trained: 8380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.526228666305542\n",
      "      kl: 0.02209901064634323\n",
      "      policy_loss: -0.0031339330598711967\n",
      "      total_loss: 734.8630981445312\n",
      "      vf_explained_var: 0.9689363241195679\n",
      "      vf_loss: 734.8645629882812\n",
      "    sample_time_ms: 19844.487\n",
      "    update_time_ms: 5.513\n",
      "  iterations_since_restore: 838\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.95533961418505\n",
      "  time_since_restore: 19891.69030690193\n",
      "  time_this_iter_s: 23.437357902526855\n",
      "  time_total_s: 19891.69030690193\n",
      "  timestamp: 1553985686\n",
      "  timesteps_since_restore: 8380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8380000\n",
      "  training_iteration: 838\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19891 s, 838 iter, 8380000 ts, 956 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-41-49\n",
      "  done: false\n",
      "  episode_len_mean: 173.86\n",
      "  episode_reward_max: 1108.8377951121977\n",
      "  episode_reward_mean: 966.856099280787\n",
      "  episode_reward_min: -48.4596882560831\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 48802\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.541\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 8390000\n",
      "    num_steps_trained: 8390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6879808306694031\n",
      "      kl: 0.018348990008234978\n",
      "      policy_loss: -0.003477594116702676\n",
      "      total_loss: 485.51788330078125\n",
      "      vf_explained_var: 0.9781349301338196\n",
      "      vf_loss: 485.5199279785156\n",
      "    sample_time_ms: 19798.741\n",
      "    update_time_ms: 5.504\n",
      "  iterations_since_restore: 839\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.42804964039357\n",
      "  time_since_restore: 19915.216902256012\n",
      "  time_this_iter_s: 23.5265953540802\n",
      "  time_total_s: 19915.216902256012\n",
      "  timestamp: 1553985709\n",
      "  timesteps_since_restore: 8390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8390000\n",
      "  training_iteration: 839\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19915 s, 839 iter, 8390000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-42-13\n",
      "  done: false\n",
      "  episode_len_mean: 163.87\n",
      "  episode_reward_max: 1132.8363386406497\n",
      "  episode_reward_mean: 960.4521258537179\n",
      "  episode_reward_min: -89.19663939861266\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 48865\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.94\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 8400000\n",
      "    num_steps_trained: 8400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5273041725158691\n",
      "      kl: 0.017218252643942833\n",
      "      policy_loss: -0.000463354866951704\n",
      "      total_loss: 662.1575317382812\n",
      "      vf_explained_var: 0.9737681746482849\n",
      "      vf_loss: 662.1566772460938\n",
      "    sample_time_ms: 19826.835\n",
      "    update_time_ms: 5.483\n",
      "  iterations_since_restore: 840\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.22606292685896\n",
      "  time_since_restore: 19939.480506896973\n",
      "  time_this_iter_s: 24.263604640960693\n",
      "  time_total_s: 19939.480506896973\n",
      "  timestamp: 1553985733\n",
      "  timesteps_since_restore: 8400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8400000\n",
      "  training_iteration: 840\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19939 s, 840 iter, 8400000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-42-38\n",
      "  done: false\n",
      "  episode_len_mean: 165.47\n",
      "  episode_reward_max: 1167.8740617740225\n",
      "  episode_reward_mean: 968.8820868857374\n",
      "  episode_reward_min: -89.19663939861266\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 48923\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3929.632\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 8410000\n",
      "    num_steps_trained: 8410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4004521369934082\n",
      "      kl: 0.027010926976799965\n",
      "      policy_loss: -0.0026109479367733\n",
      "      total_loss: 699.2791748046875\n",
      "      vf_explained_var: 0.9726651310920715\n",
      "      vf_loss: 699.2796630859375\n",
      "    sample_time_ms: 19855.197\n",
      "    update_time_ms: 5.453\n",
      "  iterations_since_restore: 841\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.4410434428686\n",
      "  time_since_restore: 19963.82787680626\n",
      "  time_this_iter_s: 24.3473699092865\n",
      "  time_total_s: 19963.82787680626\n",
      "  timestamp: 1553985758\n",
      "  timesteps_since_restore: 8410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8410000\n",
      "  training_iteration: 841\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19963 s, 841 iter, 8410000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-43-01\n",
      "  done: false\n",
      "  episode_len_mean: 167.95\n",
      "  episode_reward_max: 1167.8740617740225\n",
      "  episode_reward_mean: 963.1834744350344\n",
      "  episode_reward_min: -35.74149293701359\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 48984\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3933.675\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 8420000\n",
      "    num_steps_trained: 8420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7044068574905396\n",
      "      kl: 0.0208185575902462\n",
      "      policy_loss: 0.0003446027112659067\n",
      "      total_loss: 834.5157470703125\n",
      "      vf_explained_var: 0.9659909009933472\n",
      "      vf_loss: 834.5138549804688\n",
      "    sample_time_ms: 19865.147\n",
      "    update_time_ms: 5.485\n",
      "  iterations_since_restore: 842\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 481.59173721751716\n",
      "  time_since_restore: 19987.413382530212\n",
      "  time_this_iter_s: 23.585505723953247\n",
      "  time_total_s: 19987.413382530212\n",
      "  timestamp: 1553985781\n",
      "  timesteps_since_restore: 8420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8420000\n",
      "  training_iteration: 842\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 19987 s, 842 iter, 8420000 ts, 963 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-43-26\n",
      "  done: false\n",
      "  episode_len_mean: 169.21\n",
      "  episode_reward_max: 1113.913576375682\n",
      "  episode_reward_mean: 976.7090556094004\n",
      "  episode_reward_min: -36.912236481997354\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 49044\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3936.554\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 8430000\n",
      "    num_steps_trained: 8430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5107240676879883\n",
      "      kl: 0.02413640357553959\n",
      "      policy_loss: -0.0008176584960892797\n",
      "      total_loss: 626.8502197265625\n",
      "      vf_explained_var: 0.9720916748046875\n",
      "      vf_loss: 626.8492431640625\n",
      "    sample_time_ms: 19916.679\n",
      "    update_time_ms: 5.244\n",
      "  iterations_since_restore: 843\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.35452780470035\n",
      "  time_since_restore: 20011.478563308716\n",
      "  time_this_iter_s: 24.065180778503418\n",
      "  time_total_s: 20011.478563308716\n",
      "  timestamp: 1553985806\n",
      "  timesteps_since_restore: 8430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8430000\n",
      "  training_iteration: 843\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20011 s, 843 iter, 8430000 ts, 977 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 164.61\n",
      "  episode_reward_max: 1109.3277050605539\n",
      "  episode_reward_mean: 995.2264044285181\n",
      "  episode_reward_min: -21.306243093523676\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 49105\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3941.865\n",
      "    load_time_ms: 1.618\n",
      "    num_steps_sampled: 8440000\n",
      "    num_steps_trained: 8440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.29996681213378906\n",
      "      kl: 0.02302880771458149\n",
      "      policy_loss: -0.0011952075874432921\n",
      "      total_loss: 398.7557678222656\n",
      "      vf_explained_var: 0.9828384518623352\n",
      "      vf_loss: 398.7552185058594\n",
      "    sample_time_ms: 19900.849\n",
      "    update_time_ms: 5.201\n",
      "  iterations_since_restore: 844\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.613202214259\n",
      "  time_since_restore: 20035.063853263855\n",
      "  time_this_iter_s: 23.58528995513916\n",
      "  time_total_s: 20035.063853263855\n",
      "  timestamp: 1553985829\n",
      "  timesteps_since_restore: 8440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8440000\n",
      "  training_iteration: 844\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20035 s, 844 iter, 8440000 ts, 995 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-44-12\n",
      "  done: false\n",
      "  episode_len_mean: 164.33\n",
      "  episode_reward_max: 1161.6240085340103\n",
      "  episode_reward_mean: 972.2436174671276\n",
      "  episode_reward_min: -32.3709465335983\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 49165\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3952.813\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 8450000\n",
      "    num_steps_trained: 8450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.65380859375\n",
      "      kl: 0.023671016097068787\n",
      "      policy_loss: -0.004263974726200104\n",
      "      total_loss: 815.7765502929688\n",
      "      vf_explained_var: 0.9667385816574097\n",
      "      vf_loss: 815.7789306640625\n",
      "    sample_time_ms: 19819.174\n",
      "    update_time_ms: 5.209\n",
      "  iterations_since_restore: 845\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.1218087335638\n",
      "  time_since_restore: 20058.218330144882\n",
      "  time_this_iter_s: 23.15447688102722\n",
      "  time_total_s: 20058.218330144882\n",
      "  timestamp: 1553985852\n",
      "  timesteps_since_restore: 8450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8450000\n",
      "  training_iteration: 845\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20058 s, 845 iter, 8450000 ts, 972 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-44-36\n",
      "  done: false\n",
      "  episode_len_mean: 165.55\n",
      "  episode_reward_max: 1161.6240085340103\n",
      "  episode_reward_mean: 965.8025261168124\n",
      "  episode_reward_min: -32.3709465335983\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 49226\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3940.994\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 8460000\n",
      "    num_steps_trained: 8460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3579236567020416\n",
      "      kl: 0.03583060950040817\n",
      "      policy_loss: -0.004209051840007305\n",
      "      total_loss: 266.2170104980469\n",
      "      vf_explained_var: 0.988919198513031\n",
      "      vf_loss: 266.218505859375\n",
      "    sample_time_ms: 19806.638\n",
      "    update_time_ms: 5.3\n",
      "  iterations_since_restore: 846\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.9012630584062\n",
      "  time_since_restore: 20082.028111696243\n",
      "  time_this_iter_s: 23.809781551361084\n",
      "  time_total_s: 20082.028111696243\n",
      "  timestamp: 1553985876\n",
      "  timesteps_since_restore: 8460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8460000\n",
      "  training_iteration: 846\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20082 s, 846 iter, 8460000 ts, 966 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-45-00\n",
      "  done: false\n",
      "  episode_len_mean: 165.71\n",
      "  episode_reward_max: 1125.345982888905\n",
      "  episode_reward_mean: 998.1644034811336\n",
      "  episode_reward_min: 1.91385998087884\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 49286\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3939.775\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 8470000\n",
      "    num_steps_trained: 8470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5980193018913269\n",
      "      kl: 0.02438313141465187\n",
      "      policy_loss: -0.0018101743189617991\n",
      "      total_loss: 434.788818359375\n",
      "      vf_explained_var: 0.9817610383033752\n",
      "      vf_loss: 434.788818359375\n",
      "    sample_time_ms: 19774.198\n",
      "    update_time_ms: 5.159\n",
      "  iterations_since_restore: 847\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 499.0822017405668\n",
      "  time_since_restore: 20105.63668370247\n",
      "  time_this_iter_s: 23.608572006225586\n",
      "  time_total_s: 20105.63668370247\n",
      "  timestamp: 1553985900\n",
      "  timesteps_since_restore: 8470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8470000\n",
      "  training_iteration: 847\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20105 s, 847 iter, 8470000 ts, 998 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-45-23\n",
      "  done: false\n",
      "  episode_len_mean: 165.04\n",
      "  episode_reward_max: 1125.345982888905\n",
      "  episode_reward_mean: 992.85090909393\n",
      "  episode_reward_min: 1.91385998087884\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 49346\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3934.883\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 8480000\n",
      "    num_steps_trained: 8480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5013473033905029\n",
      "      kl: 0.02478322945535183\n",
      "      policy_loss: 0.0002702757192309946\n",
      "      total_loss: 477.33258056640625\n",
      "      vf_explained_var: 0.9786204695701599\n",
      "      vf_loss: 477.3304138183594\n",
      "    sample_time_ms: 19788.404\n",
      "    update_time_ms: 6.113\n",
      "  iterations_since_restore: 848\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.42545454696506\n",
      "  time_since_restore: 20129.175889968872\n",
      "  time_this_iter_s: 23.5392062664032\n",
      "  time_total_s: 20129.175889968872\n",
      "  timestamp: 1553985923\n",
      "  timesteps_since_restore: 8480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8480000\n",
      "  training_iteration: 848\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20129 s, 848 iter, 8480000 ts, 993 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-45-47\n",
      "  done: false\n",
      "  episode_len_mean: 166.06\n",
      "  episode_reward_max: 1116.4701694874732\n",
      "  episode_reward_mean: 984.3883806373454\n",
      "  episode_reward_min: -33.18800633753867\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 49406\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3937.55\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 8490000\n",
      "    num_steps_trained: 8490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3034816086292267\n",
      "      kl: 0.021272383630275726\n",
      "      policy_loss: -0.0005487707676365972\n",
      "      total_loss: 491.1561584472656\n",
      "      vf_explained_var: 0.9790084958076477\n",
      "      vf_loss: 491.1549987792969\n",
      "    sample_time_ms: 19738.248\n",
      "    update_time_ms: 6.078\n",
      "  iterations_since_restore: 849\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.1941903186727\n",
      "  time_since_restore: 20152.227237701416\n",
      "  time_this_iter_s: 23.051347732543945\n",
      "  time_total_s: 20152.227237701416\n",
      "  timestamp: 1553985947\n",
      "  timesteps_since_restore: 8490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8490000\n",
      "  training_iteration: 849\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20152 s, 849 iter, 8490000 ts, 984 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-46-10\n",
      "  done: false\n",
      "  episode_len_mean: 170.02\n",
      "  episode_reward_max: 1156.4106627114945\n",
      "  episode_reward_mean: 950.0433361790475\n",
      "  episode_reward_min: -70.05991864657318\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 49463\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3951.396\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 8500000\n",
      "    num_steps_trained: 8500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9246176481246948\n",
      "      kl: 0.03458138927817345\n",
      "      policy_loss: -0.0073060835711658\n",
      "      total_loss: 869.9657592773438\n",
      "      vf_explained_var: 0.9658750891685486\n",
      "      vf_loss: 869.9703369140625\n",
      "    sample_time_ms: 19688.889\n",
      "    update_time_ms: 6.071\n",
      "  iterations_since_restore: 850\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.0216680895238\n",
      "  time_since_restore: 20176.134682178497\n",
      "  time_this_iter_s: 23.9074444770813\n",
      "  time_total_s: 20176.134682178497\n",
      "  timestamp: 1553985970\n",
      "  timesteps_since_restore: 8500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8500000\n",
      "  training_iteration: 850\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20176 s, 850 iter, 8500000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-46-34\n",
      "  done: false\n",
      "  episode_len_mean: 177.53\n",
      "  episode_reward_max: 1178.4563818492434\n",
      "  episode_reward_mean: 978.7723184292547\n",
      "  episode_reward_min: -70.05991864657318\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 49520\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3923.88\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 8510000\n",
      "    num_steps_trained: 8510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7734575271606445\n",
      "      kl: 0.03070163168013096\n",
      "      policy_loss: -0.005092427600175142\n",
      "      total_loss: 505.349365234375\n",
      "      vf_explained_var: 0.9780629277229309\n",
      "      vf_loss: 505.3521728515625\n",
      "    sample_time_ms: 19656.867\n",
      "    update_time_ms: 6.003\n",
      "  iterations_since_restore: 851\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.38615921462736\n",
      "  time_since_restore: 20199.88725543022\n",
      "  time_this_iter_s: 23.752573251724243\n",
      "  time_total_s: 20199.88725543022\n",
      "  timestamp: 1553985994\n",
      "  timesteps_since_restore: 8510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8510000\n",
      "  training_iteration: 851\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20199 s, 851 iter, 8510000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-46-58\n",
      "  done: false\n",
      "  episode_len_mean: 169.14\n",
      "  episode_reward_max: 1178.4563818492434\n",
      "  episode_reward_mean: 993.2410262354382\n",
      "  episode_reward_min: -76.70102365317149\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 49582\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3922.009\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 8520000\n",
      "    num_steps_trained: 8520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.46044930815696716\n",
      "      kl: 0.030928760766983032\n",
      "      policy_loss: -0.0028927624225616455\n",
      "      total_loss: 368.7488098144531\n",
      "      vf_explained_var: 0.9842478632926941\n",
      "      vf_loss: 368.7493591308594\n",
      "    sample_time_ms: 19625.453\n",
      "    update_time_ms: 6.088\n",
      "  iterations_since_restore: 852\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.6205131177191\n",
      "  time_since_restore: 20223.141659975052\n",
      "  time_this_iter_s: 23.254404544830322\n",
      "  time_total_s: 20223.141659975052\n",
      "  timestamp: 1553986018\n",
      "  timesteps_since_restore: 8520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8520000\n",
      "  training_iteration: 852\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20223 s, 852 iter, 8520000 ts, 993 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-47-21\n",
      "  done: false\n",
      "  episode_len_mean: 167.93\n",
      "  episode_reward_max: 1136.7065668235205\n",
      "  episode_reward_mean: 958.3114553584917\n",
      "  episode_reward_min: -87.86465354326356\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 49640\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.754\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 8530000\n",
      "    num_steps_trained: 8530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8686307072639465\n",
      "      kl: 0.029049444943666458\n",
      "      policy_loss: 0.005588230676949024\n",
      "      total_loss: 1001.0785522460938\n",
      "      vf_explained_var: 0.9598150849342346\n",
      "      vf_loss: 1001.0707397460938\n",
      "    sample_time_ms: 19514.023\n",
      "    update_time_ms: 6.088\n",
      "  iterations_since_restore: 853\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.15572767924584\n",
      "  time_since_restore: 20246.050939559937\n",
      "  time_this_iter_s: 22.909279584884644\n",
      "  time_total_s: 20246.050939559937\n",
      "  timestamp: 1553986041\n",
      "  timesteps_since_restore: 8530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8530000\n",
      "  training_iteration: 853\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20246 s, 853 iter, 8530000 ts, 958 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-47-44\n",
      "  done: false\n",
      "  episode_len_mean: 169.63\n",
      "  episode_reward_max: 1134.9022365021706\n",
      "  episode_reward_mean: 960.7850642373052\n",
      "  episode_reward_min: -87.86465354326356\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 49700\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.707\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 8540000\n",
      "    num_steps_trained: 8540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.655795156955719\n",
      "      kl: 0.022229162976145744\n",
      "      policy_loss: -0.0019228003220632672\n",
      "      total_loss: 466.677490234375\n",
      "      vf_explained_var: 0.9804826378822327\n",
      "      vf_loss: 466.67767333984375\n",
      "    sample_time_ms: 19498.174\n",
      "    update_time_ms: 6.145\n",
      "  iterations_since_restore: 854\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.3925321186526\n",
      "  time_since_restore: 20269.476820230484\n",
      "  time_this_iter_s: 23.425880670547485\n",
      "  time_total_s: 20269.476820230484\n",
      "  timestamp: 1553986064\n",
      "  timesteps_since_restore: 8540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8540000\n",
      "  training_iteration: 854\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20269 s, 854 iter, 8540000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-48-08\n",
      "  done: false\n",
      "  episode_len_mean: 166.35\n",
      "  episode_reward_max: 1136.206398826623\n",
      "  episode_reward_mean: 1007.4222560100457\n",
      "  episode_reward_min: 8.097410376512755\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 49761\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3931.901\n",
      "    load_time_ms: 1.423\n",
      "    num_steps_sampled: 8550000\n",
      "    num_steps_trained: 8550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3605744242668152\n",
      "      kl: 0.030860258266329765\n",
      "      policy_loss: -0.0009367871098220348\n",
      "      total_loss: 318.61041259765625\n",
      "      vf_explained_var: 0.985846221446991\n",
      "      vf_loss: 318.6089782714844\n",
      "    sample_time_ms: 19548.481\n",
      "    update_time_ms: 6.12\n",
      "  iterations_since_restore: 855\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 503.7111280050228\n",
      "  time_since_restore: 20293.275772571564\n",
      "  time_this_iter_s: 23.798952341079712\n",
      "  time_total_s: 20293.275772571564\n",
      "  timestamp: 1553986088\n",
      "  timesteps_since_restore: 8550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8550000\n",
      "  training_iteration: 855\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20293 s, 855 iter, 8550000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-48-32\n",
      "  done: false\n",
      "  episode_len_mean: 164.65\n",
      "  episode_reward_max: 1141.7800614823673\n",
      "  episode_reward_mean: 981.4520182310282\n",
      "  episode_reward_min: -83.25173024754028\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 49822\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3927.776\n",
      "    load_time_ms: 1.386\n",
      "    num_steps_sampled: 8560000\n",
      "    num_steps_trained: 8560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6290857195854187\n",
      "      kl: 0.01863560825586319\n",
      "      policy_loss: -0.0018420416163280606\n",
      "      total_loss: 740.6157836914062\n",
      "      vf_explained_var: 0.9684138894081116\n",
      "      vf_loss: 740.6162109375\n",
      "    sample_time_ms: 19587.561\n",
      "    update_time_ms: 6.134\n",
      "  iterations_since_restore: 856\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.72600911551416\n",
      "  time_since_restore: 20317.43066382408\n",
      "  time_this_iter_s: 24.1548912525177\n",
      "  time_total_s: 20317.43066382408\n",
      "  timestamp: 1553986112\n",
      "  timesteps_since_restore: 8560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8560000\n",
      "  training_iteration: 856\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20317 s, 856 iter, 8560000 ts, 981 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-48-56\n",
      "  done: false\n",
      "  episode_len_mean: 166.06\n",
      "  episode_reward_max: 1141.7800614823673\n",
      "  episode_reward_mean: 1008.077216073564\n",
      "  episode_reward_min: -59.436640262409185\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 49883\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3926.495\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 8570000\n",
      "    num_steps_trained: 8570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.18649505078792572\n",
      "      kl: 0.03371625766158104\n",
      "      policy_loss: -0.0011477071093395352\n",
      "      total_loss: 336.67962646484375\n",
      "      vf_explained_var: 0.9858173727989197\n",
      "      vf_loss: 336.6781921386719\n",
      "    sample_time_ms: 19644.45\n",
      "    update_time_ms: 6.218\n",
      "  iterations_since_restore: 857\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.038608036782\n",
      "  time_since_restore: 20341.595868587494\n",
      "  time_this_iter_s: 24.165204763412476\n",
      "  time_total_s: 20341.595868587494\n",
      "  timestamp: 1553986136\n",
      "  timesteps_since_restore: 8570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8570000\n",
      "  training_iteration: 857\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20341 s, 857 iter, 8570000 ts, 1.01e+03 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-49-20\n",
      "  done: false\n",
      "  episode_len_mean: 165.09\n",
      "  episode_reward_max: 1131.6902625795126\n",
      "  episode_reward_mean: 970.816137218563\n",
      "  episode_reward_min: -59.436640262409185\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 49942\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3928.116\n",
      "    load_time_ms: 1.395\n",
      "    num_steps_sampled: 8580000\n",
      "    num_steps_trained: 8580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5441147089004517\n",
      "      kl: 0.021873220801353455\n",
      "      policy_loss: -0.0011783813824877143\n",
      "      total_loss: 488.4789733886719\n",
      "      vf_explained_var: 0.980609118938446\n",
      "      vf_loss: 488.4784240722656\n",
      "    sample_time_ms: 19653.286\n",
      "    update_time_ms: 5.131\n",
      "  iterations_since_restore: 858\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.4080686092815\n",
      "  time_since_restore: 20365.23168206215\n",
      "  time_this_iter_s: 23.63581347465515\n",
      "  time_total_s: 20365.23168206215\n",
      "  timestamp: 1553986160\n",
      "  timesteps_since_restore: 8580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8580000\n",
      "  training_iteration: 858\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20365 s, 858 iter, 8580000 ts, 971 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-49-43\n",
      "  done: false\n",
      "  episode_len_mean: 162.13\n",
      "  episode_reward_max: 1147.0716135789487\n",
      "  episode_reward_mean: 956.49952373768\n",
      "  episode_reward_min: -90.53167420013897\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 50005\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3927.164\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 8590000\n",
      "    num_steps_trained: 8590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5298394560813904\n",
      "      kl: 0.03413354605436325\n",
      "      policy_loss: -0.005676926113665104\n",
      "      total_loss: 1154.43212890625\n",
      "      vf_explained_var: 0.9529870748519897\n",
      "      vf_loss: 1154.435302734375\n",
      "    sample_time_ms: 19669.442\n",
      "    update_time_ms: 5.303\n",
      "  iterations_since_restore: 859\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.24976186884\n",
      "  time_since_restore: 20388.438819885254\n",
      "  time_this_iter_s: 23.20713782310486\n",
      "  time_total_s: 20388.438819885254\n",
      "  timestamp: 1553986183\n",
      "  timesteps_since_restore: 8590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8590000\n",
      "  training_iteration: 859\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20388 s, 859 iter, 8590000 ts, 956 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-50-07\n",
      "  done: false\n",
      "  episode_len_mean: 164.19\n",
      "  episode_reward_max: 1142.1999732210272\n",
      "  episode_reward_mean: 965.2037486768725\n",
      "  episode_reward_min: -90.25767674478521\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 50066\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.887\n",
      "    load_time_ms: 1.449\n",
      "    num_steps_sampled: 8600000\n",
      "    num_steps_trained: 8600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6694520115852356\n",
      "      kl: 0.019762437790632248\n",
      "      policy_loss: -0.0007935285684652627\n",
      "      total_loss: 552.79638671875\n",
      "      vf_explained_var: 0.9767454266548157\n",
      "      vf_loss: 552.7957153320312\n",
      "    sample_time_ms: 19635.643\n",
      "    update_time_ms: 5.37\n",
      "  iterations_since_restore: 860\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.6018743384362\n",
      "  time_since_restore: 20411.895933151245\n",
      "  time_this_iter_s: 23.45711326599121\n",
      "  time_total_s: 20411.895933151245\n",
      "  timestamp: 1553986207\n",
      "  timesteps_since_restore: 8600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8600000\n",
      "  training_iteration: 860\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20411 s, 860 iter, 8600000 ts, 965 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-50-30\n",
      "  done: false\n",
      "  episode_len_mean: 162.51\n",
      "  episode_reward_max: 1141.5933323231334\n",
      "  episode_reward_mean: 973.55076484634\n",
      "  episode_reward_min: -90.25767674478521\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 50127\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3922.002\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 8610000\n",
      "    num_steps_trained: 8610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3273896276950836\n",
      "      kl: 0.025089140981435776\n",
      "      policy_loss: -0.002158853691071272\n",
      "      total_loss: 802.7008056640625\n",
      "      vf_explained_var: 0.964455246925354\n",
      "      vf_loss: 802.7010498046875\n",
      "    sample_time_ms: 19606.55\n",
      "    update_time_ms: 5.253\n",
      "  iterations_since_restore: 861\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.7753824231701\n",
      "  time_since_restore: 20435.418231487274\n",
      "  time_this_iter_s: 23.522298336029053\n",
      "  time_total_s: 20435.418231487274\n",
      "  timestamp: 1553986230\n",
      "  timesteps_since_restore: 8610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8610000\n",
      "  training_iteration: 861\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20435 s, 861 iter, 8610000 ts, 974 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 169.06\n",
      "  episode_reward_max: 1141.5933323231334\n",
      "  episode_reward_mean: 972.7596574850709\n",
      "  episode_reward_min: -72.27407453497828\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 50184\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.149\n",
      "    load_time_ms: 1.408\n",
      "    num_steps_sampled: 8620000\n",
      "    num_steps_trained: 8620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7622308135032654\n",
      "      kl: 0.03248383477330208\n",
      "      policy_loss: -1.7970800399780273e-05\n",
      "      total_loss: 330.2013854980469\n",
      "      vf_explained_var: 0.9866843819618225\n",
      "      vf_loss: 330.1988830566406\n",
      "    sample_time_ms: 19639.44\n",
      "    update_time_ms: 5.2\n",
      "  iterations_since_restore: 862\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.37982874253544\n",
      "  time_since_restore: 20459.024752616882\n",
      "  time_this_iter_s: 23.606521129608154\n",
      "  time_total_s: 20459.024752616882\n",
      "  timestamp: 1553986254\n",
      "  timesteps_since_restore: 8620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8620000\n",
      "  training_iteration: 862\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20459 s, 862 iter, 8620000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-51-17\n",
      "  done: false\n",
      "  episode_len_mean: 165.09\n",
      "  episode_reward_max: 1135.3987334876103\n",
      "  episode_reward_mean: 1011.0688083550034\n",
      "  episode_reward_min: -49.120275717125025\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 50244\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.477\n",
      "    load_time_ms: 1.403\n",
      "    num_steps_sampled: 8630000\n",
      "    num_steps_trained: 8630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3792862594127655\n",
      "      kl: 0.020746756345033646\n",
      "      policy_loss: -0.0019462238997220993\n",
      "      total_loss: 483.0313415527344\n",
      "      vf_explained_var: 0.9773669242858887\n",
      "      vf_loss: 483.03173828125\n",
      "    sample_time_ms: 19709.494\n",
      "    update_time_ms: 5.247\n",
      "  iterations_since_restore: 863\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 505.53440417750164\n",
      "  time_since_restore: 20482.60525918007\n",
      "  time_this_iter_s: 23.580506563186646\n",
      "  time_total_s: 20482.60525918007\n",
      "  timestamp: 1553986277\n",
      "  timesteps_since_restore: 8630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8630000\n",
      "  training_iteration: 863\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20482 s, 863 iter, 8630000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-51-41\n",
      "  done: false\n",
      "  episode_len_mean: 169.82\n",
      "  episode_reward_max: 1124.6709367405977\n",
      "  episode_reward_mean: 1017.3694671611457\n",
      "  episode_reward_min: 414.7523784745796\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 50303\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3918.349\n",
      "    load_time_ms: 1.402\n",
      "    num_steps_sampled: 8640000\n",
      "    num_steps_trained: 8640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5692613124847412\n",
      "      kl: 0.039728276431560516\n",
      "      policy_loss: 0.0012402355205267668\n",
      "      total_loss: 97.7802505493164\n",
      "      vf_explained_var: 0.9959855675697327\n",
      "      vf_loss: 97.77596282958984\n",
      "    sample_time_ms: 19760.585\n",
      "    update_time_ms: 5.229\n",
      "  iterations_since_restore: 864\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 508.6847335805728\n",
      "  time_since_restore: 20506.509076833725\n",
      "  time_this_iter_s: 23.903817653656006\n",
      "  time_total_s: 20506.509076833725\n",
      "  timestamp: 1553986301\n",
      "  timesteps_since_restore: 8640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8640000\n",
      "  training_iteration: 864\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20506 s, 864 iter, 8640000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-52-06\n",
      "  done: false\n",
      "  episode_len_mean: 172.17\n",
      "  episode_reward_max: 1170.5352779553891\n",
      "  episode_reward_mean: 1010.4161481580887\n",
      "  episode_reward_min: -89.94647337204879\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 50363\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.472\n",
      "    load_time_ms: 1.41\n",
      "    num_steps_sampled: 8650000\n",
      "    num_steps_trained: 8650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3124983310699463\n",
      "      kl: 0.02887047827243805\n",
      "      policy_loss: 0.0009555084980092943\n",
      "      total_loss: 238.71304321289062\n",
      "      vf_explained_var: 0.9899069666862488\n",
      "      vf_loss: 238.7098388671875\n",
      "    sample_time_ms: 19804.524\n",
      "    update_time_ms: 5.206\n",
      "  iterations_since_restore: 865\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 505.20807407904437\n",
      "  time_since_restore: 20530.576630592346\n",
      "  time_this_iter_s: 24.067553758621216\n",
      "  time_total_s: 20530.576630592346\n",
      "  timestamp: 1553986326\n",
      "  timesteps_since_restore: 8650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8650000\n",
      "  training_iteration: 865\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20530 s, 865 iter, 8650000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-52-29\n",
      "  done: false\n",
      "  episode_len_mean: 163.19\n",
      "  episode_reward_max: 1170.5352779553891\n",
      "  episode_reward_mean: 991.4165429776311\n",
      "  episode_reward_min: -89.94647337204879\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 50424\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.938\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 8660000\n",
      "    num_steps_trained: 8660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4238021969795227\n",
      "      kl: 0.022496184334158897\n",
      "      policy_loss: -0.0032775509171187878\n",
      "      total_loss: 397.1819763183594\n",
      "      vf_explained_var: 0.9832462668418884\n",
      "      vf_loss: 397.18353271484375\n",
      "    sample_time_ms: 19720.436\n",
      "    update_time_ms: 5.251\n",
      "  iterations_since_restore: 866\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.7082714888155\n",
      "  time_since_restore: 20553.82756614685\n",
      "  time_this_iter_s: 23.250935554504395\n",
      "  time_total_s: 20553.82756614685\n",
      "  timestamp: 1553986349\n",
      "  timesteps_since_restore: 8660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8660000\n",
      "  training_iteration: 866\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20553 s, 866 iter, 8660000 ts, 991 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-52-53\n",
      "  done: false\n",
      "  episode_len_mean: 163.36\n",
      "  episode_reward_max: 1102.492470246763\n",
      "  episode_reward_mean: 973.7471118572219\n",
      "  episode_reward_min: -87.49153315834756\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 50485\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.358\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 8670000\n",
      "    num_steps_trained: 8670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.616959810256958\n",
      "      kl: 0.02669425867497921\n",
      "      policy_loss: -0.003314053872600198\n",
      "      total_loss: 397.91705322265625\n",
      "      vf_explained_var: 0.9825846552848816\n",
      "      vf_loss: 397.9183349609375\n",
      "    sample_time_ms: 19761.71\n",
      "    update_time_ms: 5.284\n",
      "  iterations_since_restore: 867\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.87355592861104\n",
      "  time_since_restore: 20578.412053108215\n",
      "  time_this_iter_s: 24.584486961364746\n",
      "  time_total_s: 20578.412053108215\n",
      "  timestamp: 1553986373\n",
      "  timesteps_since_restore: 8670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8670000\n",
      "  training_iteration: 867\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20578 s, 867 iter, 8670000 ts, 974 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-53-18\n",
      "  done: false\n",
      "  episode_len_mean: 161.93\n",
      "  episode_reward_max: 1141.9267068283036\n",
      "  episode_reward_mean: 975.1871255057928\n",
      "  episode_reward_min: -106.28888310813846\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 50547\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.998\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 8680000\n",
      "    num_steps_trained: 8680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.29155248403549194\n",
      "      kl: 0.032552897930145264\n",
      "      policy_loss: -0.007698022294789553\n",
      "      total_loss: 921.7838745117188\n",
      "      vf_explained_var: 0.9638491868972778\n",
      "      vf_loss: 921.7889404296875\n",
      "    sample_time_ms: 19811.563\n",
      "    update_time_ms: 5.252\n",
      "  iterations_since_restore: 868\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.59356275289656\n",
      "  time_since_restore: 20602.562967061996\n",
      "  time_this_iter_s: 24.150913953781128\n",
      "  time_total_s: 20602.562967061996\n",
      "  timestamp: 1553986398\n",
      "  timesteps_since_restore: 8680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8680000\n",
      "  training_iteration: 868\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20602 s, 868 iter, 8680000 ts, 975 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-53-42\n",
      "  done: false\n",
      "  episode_len_mean: 166.17\n",
      "  episode_reward_max: 1137.943555330165\n",
      "  episode_reward_mean: 982.4036324779433\n",
      "  episode_reward_min: -106.28888310813846\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 50606\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.472\n",
      "    load_time_ms: 1.354\n",
      "    num_steps_sampled: 8690000\n",
      "    num_steps_trained: 8690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7006295323371887\n",
      "      kl: 0.02535966970026493\n",
      "      policy_loss: -0.0026682065799832344\n",
      "      total_loss: 343.45147705078125\n",
      "      vf_explained_var: 0.9860188364982605\n",
      "      vf_loss: 343.45220947265625\n",
      "    sample_time_ms: 19879.355\n",
      "    update_time_ms: 5.327\n",
      "  iterations_since_restore: 869\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.2018162389717\n",
      "  time_since_restore: 20626.480370521545\n",
      "  time_this_iter_s: 23.91740345954895\n",
      "  time_total_s: 20626.480370521545\n",
      "  timestamp: 1553986422\n",
      "  timesteps_since_restore: 8690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8690000\n",
      "  training_iteration: 869\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20626 s, 869 iter, 8690000 ts, 982 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-54-05\n",
      "  done: false\n",
      "  episode_len_mean: 169.69\n",
      "  episode_reward_max: 1137.943555330165\n",
      "  episode_reward_mean: 991.5857466335932\n",
      "  episode_reward_min: 70.96339658338394\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 50664\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.465\n",
      "    load_time_ms: 1.438\n",
      "    num_steps_sampled: 8700000\n",
      "    num_steps_trained: 8700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8215325474739075\n",
      "      kl: 0.02449110895395279\n",
      "      policy_loss: -0.0010659852996468544\n",
      "      total_loss: 555.6156616210938\n",
      "      vf_explained_var: 0.9778680205345154\n",
      "      vf_loss: 555.6149291992188\n",
      "    sample_time_ms: 19908.382\n",
      "    update_time_ms: 5.253\n",
      "  iterations_since_restore: 870\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.7928733167966\n",
      "  time_since_restore: 20650.1791100502\n",
      "  time_this_iter_s: 23.698739528656006\n",
      "  time_total_s: 20650.1791100502\n",
      "  timestamp: 1553986445\n",
      "  timesteps_since_restore: 8700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8700000\n",
      "  training_iteration: 870\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20650 s, 870 iter, 8700000 ts, 992 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-54-28\n",
      "  done: false\n",
      "  episode_len_mean: 162.07\n",
      "  episode_reward_max: 1123.610992593531\n",
      "  episode_reward_mean: 1001.6638789643004\n",
      "  episode_reward_min: -56.31650187899925\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 50726\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.337\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 8710000\n",
      "    num_steps_trained: 8710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.32113099098205566\n",
      "      kl: 0.023128561675548553\n",
      "      policy_loss: -0.004352021496742964\n",
      "      total_loss: 457.9258728027344\n",
      "      vf_explained_var: 0.9806007742881775\n",
      "      vf_loss: 457.9284973144531\n",
      "    sample_time_ms: 19869.872\n",
      "    update_time_ms: 5.448\n",
      "  iterations_since_restore: 871\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 500.8319394821502\n",
      "  time_since_restore: 20673.264508485794\n",
      "  time_this_iter_s: 23.08539843559265\n",
      "  time_total_s: 20673.264508485794\n",
      "  timestamp: 1553986468\n",
      "  timesteps_since_restore: 8710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8710000\n",
      "  training_iteration: 871\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20673 s, 871 iter, 8710000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-54-52\n",
      "  done: false\n",
      "  episode_len_mean: 163.73\n",
      "  episode_reward_max: 1147.7851658071775\n",
      "  episode_reward_mean: 1014.8362717401671\n",
      "  episode_reward_min: -56.31650187899925\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 50787\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.792\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 8720000\n",
      "    num_steps_trained: 8720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0763414055109024\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.42217329144477844\n",
      "      kl: 0.0715726986527443\n",
      "      policy_loss: 0.002755424939095974\n",
      "      total_loss: 123.0204849243164\n",
      "      vf_explained_var: 0.994760274887085\n",
      "      vf_loss: 123.01226806640625\n",
      "    sample_time_ms: 19895.162\n",
      "    update_time_ms: 5.33\n",
      "  iterations_since_restore: 872\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 507.4181358700836\n",
      "  time_since_restore: 20697.056284189224\n",
      "  time_this_iter_s: 23.791775703430176\n",
      "  time_total_s: 20697.056284189224\n",
      "  timestamp: 1553986492\n",
      "  timesteps_since_restore: 8720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8720000\n",
      "  training_iteration: 872\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20697 s, 872 iter, 8720000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-55-16\n",
      "  done: false\n",
      "  episode_len_mean: 173.53\n",
      "  episode_reward_max: 1147.7851658071775\n",
      "  episode_reward_mean: 996.5226431439463\n",
      "  episode_reward_min: 45.160706037698304\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 50842\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3879.941\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 8730000\n",
      "    num_steps_trained: 8730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9493387937545776\n",
      "      kl: 0.016451092436909676\n",
      "      policy_loss: -6.669754657195881e-05\n",
      "      total_loss: 616.5599975585938\n",
      "      vf_explained_var: 0.9748722910881042\n",
      "      vf_loss: 616.55810546875\n",
      "    sample_time_ms: 19917.367\n",
      "    update_time_ms: 5.206\n",
      "  iterations_since_restore: 873\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.2613215719732\n",
      "  time_since_restore: 20720.822189092636\n",
      "  time_this_iter_s: 23.765904903411865\n",
      "  time_total_s: 20720.822189092636\n",
      "  timestamp: 1553986516\n",
      "  timesteps_since_restore: 8730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8730000\n",
      "  training_iteration: 873\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20720 s, 873 iter, 8730000 ts, 997 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-55-40\n",
      "  done: false\n",
      "  episode_len_mean: 177.38\n",
      "  episode_reward_max: 1113.9410779396521\n",
      "  episode_reward_mean: 974.4365644918789\n",
      "  episode_reward_min: -39.2397061144855\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 50901\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.972\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 8740000\n",
      "    num_steps_trained: 8740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6881272792816162\n",
      "      kl: 0.0182840246707201\n",
      "      policy_loss: -0.0012049104552716017\n",
      "      total_loss: 624.0173950195312\n",
      "      vf_explained_var: 0.9737697243690491\n",
      "      vf_loss: 624.0164794921875\n",
      "    sample_time_ms: 19852.799\n",
      "    update_time_ms: 5.263\n",
      "  iterations_since_restore: 874\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.21828224593946\n",
      "  time_since_restore: 20744.20276451111\n",
      "  time_this_iter_s: 23.38057541847229\n",
      "  time_total_s: 20744.20276451111\n",
      "  timestamp: 1553986540\n",
      "  timesteps_since_restore: 8740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8740000\n",
      "  training_iteration: 874\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20744 s, 874 iter, 8740000 ts, 974 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-56-03\n",
      "  done: false\n",
      "  episode_len_mean: 172.01\n",
      "  episode_reward_max: 1124.5137385041535\n",
      "  episode_reward_mean: 980.1097615464386\n",
      "  episode_reward_min: -39.2397061144855\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 50959\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.942\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 8750000\n",
      "    num_steps_trained: 8750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7042169570922852\n",
      "      kl: 0.017933307215571404\n",
      "      policy_loss: -0.003367523429915309\n",
      "      total_loss: 417.86865234375\n",
      "      vf_explained_var: 0.982202410697937\n",
      "      vf_loss: 417.86993408203125\n",
      "    sample_time_ms: 19840.188\n",
      "    update_time_ms: 5.346\n",
      "  iterations_since_restore: 875\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.05488077321917\n",
      "  time_since_restore: 20768.0949985981\n",
      "  time_this_iter_s: 23.892234086990356\n",
      "  time_total_s: 20768.0949985981\n",
      "  timestamp: 1553986563\n",
      "  timesteps_since_restore: 8750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8750000\n",
      "  training_iteration: 875\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20768 s, 875 iter, 8750000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-56-27\n",
      "  done: false\n",
      "  episode_len_mean: 169.98\n",
      "  episode_reward_max: 1136.8603514546714\n",
      "  episode_reward_mean: 997.1011718020362\n",
      "  episode_reward_min: 76.27307121945444\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 51020\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.658\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 8760000\n",
      "    num_steps_trained: 8760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5077243447303772\n",
      "      kl: 0.019020570442080498\n",
      "      policy_loss: -0.0008783520315773785\n",
      "      total_loss: 260.9931335449219\n",
      "      vf_explained_var: 0.9894019961357117\n",
      "      vf_loss: 260.9918518066406\n",
      "    sample_time_ms: 19883.94\n",
      "    update_time_ms: 5.314\n",
      "  iterations_since_restore: 876\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.55058590101805\n",
      "  time_since_restore: 20791.842889547348\n",
      "  time_this_iter_s: 23.747890949249268\n",
      "  time_total_s: 20791.842889547348\n",
      "  timestamp: 1553986587\n",
      "  timesteps_since_restore: 8760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8760000\n",
      "  training_iteration: 876\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20791 s, 876 iter, 8760000 ts, 997 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-56-51\n",
      "  done: false\n",
      "  episode_len_mean: 160.24\n",
      "  episode_reward_max: 1136.8603514546714\n",
      "  episode_reward_mean: 958.5202369767399\n",
      "  episode_reward_min: -105.86948104423628\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 51082\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.246\n",
      "    load_time_ms: 1.562\n",
      "    num_steps_sampled: 8770000\n",
      "    num_steps_trained: 8770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5884153842926025\n",
      "      kl: 0.021546682342886925\n",
      "      policy_loss: -0.0024892836809158325\n",
      "      total_loss: 995.3634033203125\n",
      "      vf_explained_var: 0.9611794948577881\n",
      "      vf_loss: 995.3634033203125\n",
      "    sample_time_ms: 19831.812\n",
      "    update_time_ms: 5.219\n",
      "  iterations_since_restore: 877\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.26011848836987\n",
      "  time_since_restore: 20815.85977435112\n",
      "  time_this_iter_s: 24.016884803771973\n",
      "  time_total_s: 20815.85977435112\n",
      "  timestamp: 1553986611\n",
      "  timesteps_since_restore: 8770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8770000\n",
      "  training_iteration: 877\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20815 s, 877 iter, 8770000 ts, 959 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 165.5\n",
      "  episode_reward_max: 1113.071171431641\n",
      "  episode_reward_mean: 932.1627626973085\n",
      "  episode_reward_min: -105.86948104423628\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 51139\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.469\n",
      "    load_time_ms: 1.583\n",
      "    num_steps_sampled: 8780000\n",
      "    num_steps_trained: 8780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9143014550209045\n",
      "      kl: 0.025705328211188316\n",
      "      policy_loss: -0.0023773047141730785\n",
      "      total_loss: 305.36688232421875\n",
      "      vf_explained_var: 0.987286388874054\n",
      "      vf_loss: 305.36627197265625\n",
      "    sample_time_ms: 19812.115\n",
      "    update_time_ms: 5.266\n",
      "  iterations_since_restore: 878\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 466.0813813486543\n",
      "  time_since_restore: 20839.75349712372\n",
      "  time_this_iter_s: 23.893722772598267\n",
      "  time_total_s: 20839.75349712372\n",
      "  timestamp: 1553986635\n",
      "  timesteps_since_restore: 8780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8780000\n",
      "  training_iteration: 878\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20839 s, 878 iter, 8780000 ts, 932 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-57-40\n",
      "  done: false\n",
      "  episode_len_mean: 168.77\n",
      "  episode_reward_max: 1113.604959604768\n",
      "  episode_reward_mean: 1010.4375204249885\n",
      "  episode_reward_min: -27.374503638747484\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 51200\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.541\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 8790000\n",
      "    num_steps_trained: 8790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.26442670822143555\n",
      "      kl: 0.02960331365466118\n",
      "      policy_loss: 0.0015745124546810985\n",
      "      total_loss: 169.5715789794922\n",
      "      vf_explained_var: 0.9927606582641602\n",
      "      vf_loss: 169.5666046142578\n",
      "    sample_time_ms: 19828.327\n",
      "    update_time_ms: 5.024\n",
      "  iterations_since_restore: 879\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 505.2187602124943\n",
      "  time_since_restore: 20863.951799869537\n",
      "  time_this_iter_s: 24.198302745819092\n",
      "  time_total_s: 20863.951799869537\n",
      "  timestamp: 1553986660\n",
      "  timesteps_since_restore: 8790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8790000\n",
      "  training_iteration: 879\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20863 s, 879 iter, 8790000 ts, 1.01e+03 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-58-03\n",
      "  done: false\n",
      "  episode_len_mean: 161.4\n",
      "  episode_reward_max: 1128.859177163455\n",
      "  episode_reward_mean: 994.7474962892721\n",
      "  episode_reward_min: -27.374503638747484\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 51262\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.374\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 8800000\n",
      "    num_steps_trained: 8800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.25214728713035583\n",
      "      kl: 0.02029796503484249\n",
      "      policy_loss: -0.003179114544764161\n",
      "      total_loss: 529.9653930664062\n",
      "      vf_explained_var: 0.9782423377037048\n",
      "      vf_loss: 529.9661865234375\n",
      "    sample_time_ms: 19778.625\n",
      "    update_time_ms: 5.021\n",
      "  iterations_since_restore: 880\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.3737481446359\n",
      "  time_since_restore: 20887.217832565308\n",
      "  time_this_iter_s: 23.266032695770264\n",
      "  time_total_s: 20887.217832565308\n",
      "  timestamp: 1553986683\n",
      "  timesteps_since_restore: 8800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8800000\n",
      "  training_iteration: 880\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20887 s, 880 iter, 8800000 ts, 995 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-58-26\n",
      "  done: false\n",
      "  episode_len_mean: 169.88\n",
      "  episode_reward_max: 1128.859177163455\n",
      "  episode_reward_mean: 989.9894999649907\n",
      "  episode_reward_min: 39.02504684221546\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 51319\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.535\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 8810000\n",
      "    num_steps_trained: 8810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8091424703598022\n",
      "      kl: 0.019058678299188614\n",
      "      policy_loss: -0.0024437762331217527\n",
      "      total_loss: 336.41766357421875\n",
      "      vf_explained_var: 0.9857082962989807\n",
      "      vf_loss: 336.4179382324219\n",
      "    sample_time_ms: 19821.491\n",
      "    update_time_ms: 4.961\n",
      "  iterations_since_restore: 881\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.99474998249525\n",
      "  time_since_restore: 20910.69321870804\n",
      "  time_this_iter_s: 23.475386142730713\n",
      "  time_total_s: 20910.69321870804\n",
      "  timestamp: 1553986706\n",
      "  timesteps_since_restore: 8810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8810000\n",
      "  training_iteration: 881\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20910 s, 881 iter, 8810000 ts, 990 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-58-50\n",
      "  done: false\n",
      "  episode_len_mean: 167.07\n",
      "  episode_reward_max: 1126.4364973658378\n",
      "  episode_reward_mean: 996.7635949414222\n",
      "  episode_reward_min: -61.635733294324325\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 51379\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.647\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 8820000\n",
      "    num_steps_trained: 8820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4850659966468811\n",
      "      kl: 0.018746746703982353\n",
      "      policy_loss: -0.00019840795721393079\n",
      "      total_loss: 378.306396484375\n",
      "      vf_explained_var: 0.9842891097068787\n",
      "      vf_loss: 378.304443359375\n",
      "    sample_time_ms: 19808.945\n",
      "    update_time_ms: 5.147\n",
      "  iterations_since_restore: 882\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.38179747071104\n",
      "  time_since_restore: 20934.37860560417\n",
      "  time_this_iter_s: 23.685386896133423\n",
      "  time_total_s: 20934.37860560417\n",
      "  timestamp: 1553986730\n",
      "  timesteps_since_restore: 8820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8820000\n",
      "  training_iteration: 882\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20934 s, 882 iter, 8820000 ts, 997 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-59-14\n",
      "  done: false\n",
      "  episode_len_mean: 168.94\n",
      "  episode_reward_max: 1139.0366704764208\n",
      "  episode_reward_mean: 1003.1020696691824\n",
      "  episode_reward_min: -11.73480102739677\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 51439\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.626\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 8830000\n",
      "    num_steps_trained: 8830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.541844367980957\n",
      "      kl: 0.0290555227547884\n",
      "      policy_loss: -0.004926392808556557\n",
      "      total_loss: 354.187255859375\n",
      "      vf_explained_var: 0.9845482110977173\n",
      "      vf_loss: 354.1888427734375\n",
      "    sample_time_ms: 19775.55\n",
      "    update_time_ms: 5.258\n",
      "  iterations_since_restore: 883\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 501.55103483459135\n",
      "  time_since_restore: 20957.83246922493\n",
      "  time_this_iter_s: 23.453863620758057\n",
      "  time_total_s: 20957.83246922493\n",
      "  timestamp: 1553986754\n",
      "  timesteps_since_restore: 8830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8830000\n",
      "  training_iteration: 883\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20957 s, 883 iter, 8830000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-30_23-59-37\n",
      "  done: false\n",
      "  episode_len_mean: 164.19\n",
      "  episode_reward_max: 1139.6823740420284\n",
      "  episode_reward_mean: 988.3723129795231\n",
      "  episode_reward_min: -78.52499493988465\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 51500\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.066\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 8840000\n",
      "    num_steps_trained: 8840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.47133415937423706\n",
      "      kl: 0.018166692927479744\n",
      "      policy_loss: -0.0025575493928045034\n",
      "      total_loss: 787.3099975585938\n",
      "      vf_explained_var: 0.9675918817520142\n",
      "      vf_loss: 787.3103637695312\n",
      "    sample_time_ms: 19795.635\n",
      "    update_time_ms: 5.214\n",
      "  iterations_since_restore: 884\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.1861564897616\n",
      "  time_since_restore: 20981.439910888672\n",
      "  time_this_iter_s: 23.607441663742065\n",
      "  time_total_s: 20981.439910888672\n",
      "  timestamp: 1553986777\n",
      "  timesteps_since_restore: 8840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8840000\n",
      "  training_iteration: 884\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 20981 s, 884 iter, 8840000 ts, 988 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-00-00\n",
      "  done: false\n",
      "  episode_len_mean: 162.33\n",
      "  episode_reward_max: 1136.4108702273136\n",
      "  episode_reward_mean: 1021.4868503558005\n",
      "  episode_reward_min: -7.504889149443727\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 51561\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.243\n",
      "    load_time_ms: 1.434\n",
      "    num_steps_sampled: 8850000\n",
      "    num_steps_trained: 8850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.36522915959358215\n",
      "      kl: 0.024595588445663452\n",
      "      policy_loss: -0.0014286377700045705\n",
      "      total_loss: 164.1486358642578\n",
      "      vf_explained_var: 0.9933514595031738\n",
      "      vf_loss: 164.1472625732422\n",
      "    sample_time_ms: 19735.297\n",
      "    update_time_ms: 5.204\n",
      "  iterations_since_restore: 885\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 510.7434251779003\n",
      "  time_since_restore: 21004.700360298157\n",
      "  time_this_iter_s: 23.260449409484863\n",
      "  time_total_s: 21004.700360298157\n",
      "  timestamp: 1553986800\n",
      "  timesteps_since_restore: 8850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8850000\n",
      "  training_iteration: 885\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21004 s, 885 iter, 8850000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-00-24\n",
      "  done: false\n",
      "  episode_len_mean: 168.04\n",
      "  episode_reward_max: 1141.8625392990918\n",
      "  episode_reward_mean: 985.9826118703288\n",
      "  episode_reward_min: -20.76374010437101\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 51620\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.518\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 8860000\n",
      "    num_steps_trained: 8860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6262328028678894\n",
      "      kl: 0.017989879474043846\n",
      "      policy_loss: 0.0006769713363610208\n",
      "      total_loss: 472.08203125\n",
      "      vf_explained_var: 0.9827438592910767\n",
      "      vf_loss: 472.07928466796875\n",
      "    sample_time_ms: 19747.085\n",
      "    update_time_ms: 5.089\n",
      "  iterations_since_restore: 886\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.9913059351644\n",
      "  time_since_restore: 21028.526769161224\n",
      "  time_this_iter_s: 23.826408863067627\n",
      "  time_total_s: 21028.526769161224\n",
      "  timestamp: 1553986824\n",
      "  timesteps_since_restore: 8860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8860000\n",
      "  training_iteration: 886\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21028 s, 886 iter, 8860000 ts, 986 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-00-49\n",
      "  done: false\n",
      "  episode_len_mean: 164.01\n",
      "  episode_reward_max: 1135.9540838011392\n",
      "  episode_reward_mean: 975.5329348291017\n",
      "  episode_reward_min: -67.90530931111809\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 51681\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.967\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 8870000\n",
      "    num_steps_trained: 8870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5930041670799255\n",
      "      kl: 0.022782299667596817\n",
      "      policy_loss: -0.005501279607415199\n",
      "      total_loss: 626.1050415039062\n",
      "      vf_explained_var: 0.9757380485534668\n",
      "      vf_loss: 626.1078491210938\n",
      "    sample_time_ms: 19767.122\n",
      "    update_time_ms: 4.913\n",
      "  iterations_since_restore: 887\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.76646741455085\n",
      "  time_since_restore: 21052.777660369873\n",
      "  time_this_iter_s: 24.25089120864868\n",
      "  time_total_s: 21052.777660369873\n",
      "  timestamp: 1553986849\n",
      "  timesteps_since_restore: 8870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8870000\n",
      "  training_iteration: 887\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21052 s, 887 iter, 8870000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-01-12\n",
      "  done: false\n",
      "  episode_len_mean: 167.62\n",
      "  episode_reward_max: 1141.277074423866\n",
      "  episode_reward_mean: 999.3816581947801\n",
      "  episode_reward_min: -67.90530931111809\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 51740\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3903.343\n",
      "    load_time_ms: 1.381\n",
      "    num_steps_sampled: 8880000\n",
      "    num_steps_trained: 8880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3775443434715271\n",
      "      kl: 0.027332428842782974\n",
      "      policy_loss: 0.0005990731297060847\n",
      "      total_loss: 118.7813491821289\n",
      "      vf_explained_var: 0.9951171875\n",
      "      vf_loss: 118.77761840820312\n",
      "    sample_time_ms: 19746.196\n",
      "    update_time_ms: 4.851\n",
      "  iterations_since_restore: 888\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 499.69082909739006\n",
      "  time_since_restore: 21076.486403226852\n",
      "  time_this_iter_s: 23.70874285697937\n",
      "  time_total_s: 21076.486403226852\n",
      "  timestamp: 1553986872\n",
      "  timesteps_since_restore: 8880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8880000\n",
      "  training_iteration: 888\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21076 s, 888 iter, 8880000 ts, 999 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-01-36\n",
      "  done: false\n",
      "  episode_len_mean: 167.35\n",
      "  episode_reward_max: 1136.9834189784103\n",
      "  episode_reward_mean: 1032.3895356808896\n",
      "  episode_reward_min: 662.7344411619334\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 51801\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.53\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 8890000\n",
      "    num_steps_trained: 8890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.39285412430763245\n",
      "      kl: 0.032471392303705215\n",
      "      policy_loss: -0.0005753433797508478\n",
      "      total_loss: 70.09683990478516\n",
      "      vf_explained_var: 0.9969503879547119\n",
      "      vf_loss: 70.09369659423828\n",
      "    sample_time_ms: 19692.029\n",
      "    update_time_ms: 4.933\n",
      "  iterations_since_restore: 889\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 516.1947678404448\n",
      "  time_since_restore: 21099.99898481369\n",
      "  time_this_iter_s: 23.51258158683777\n",
      "  time_total_s: 21099.99898481369\n",
      "  timestamp: 1553986896\n",
      "  timesteps_since_restore: 8890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8890000\n",
      "  training_iteration: 889\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21099 s, 889 iter, 8890000 ts, 1.03e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-02-00\n",
      "  done: false\n",
      "  episode_len_mean: 168.52\n",
      "  episode_reward_max: 1136.9834189784103\n",
      "  episode_reward_mean: 983.6675301041927\n",
      "  episode_reward_min: -80.84230985602196\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 51860\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.643\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 8900000\n",
      "    num_steps_trained: 8900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6731451749801636\n",
      "      kl: 0.029276037588715553\n",
      "      policy_loss: -0.0011387844569981098\n",
      "      total_loss: 483.22344970703125\n",
      "      vf_explained_var: 0.9819253087043762\n",
      "      vf_loss: 483.22125244140625\n",
      "    sample_time_ms: 19729.524\n",
      "    update_time_ms: 5.291\n",
      "  iterations_since_restore: 890\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.8337650520964\n",
      "  time_since_restore: 21123.642148017883\n",
      "  time_this_iter_s: 23.643163204193115\n",
      "  time_total_s: 21123.642148017883\n",
      "  timestamp: 1553986920\n",
      "  timesteps_since_restore: 8900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8900000\n",
      "  training_iteration: 890\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21123 s, 890 iter, 8900000 ts, 984 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-02-23\n",
      "  done: false\n",
      "  episode_len_mean: 165.55\n",
      "  episode_reward_max: 1126.741483820145\n",
      "  episode_reward_mean: 980.889447998623\n",
      "  episode_reward_min: -80.84230985602196\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 51920\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.732\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 8910000\n",
      "    num_steps_trained: 8910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.37094244360923767\n",
      "      kl: 0.022992637008428574\n",
      "      policy_loss: -0.0022267948370426893\n",
      "      total_loss: 470.29412841796875\n",
      "      vf_explained_var: 0.9792593121528625\n",
      "      vf_loss: 470.29376220703125\n",
      "    sample_time_ms: 19731.783\n",
      "    update_time_ms: 5.216\n",
      "  iterations_since_restore: 891\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.44472399931146\n",
      "  time_since_restore: 21147.101367473602\n",
      "  time_this_iter_s: 23.459219455718994\n",
      "  time_total_s: 21147.101367473602\n",
      "  timestamp: 1553986943\n",
      "  timesteps_since_restore: 8910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8910000\n",
      "  training_iteration: 891\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21147 s, 891 iter, 8910000 ts, 981 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-02-46\n",
      "  done: false\n",
      "  episode_len_mean: 166.06\n",
      "  episode_reward_max: 1105.2113322550204\n",
      "  episode_reward_mean: 972.5576391492202\n",
      "  episode_reward_min: -80.54998188027272\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 51980\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.992\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 8920000\n",
      "    num_steps_trained: 8920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5957882404327393\n",
      "      kl: 0.026915788650512695\n",
      "      policy_loss: -0.001037932699546218\n",
      "      total_loss: 796.07666015625\n",
      "      vf_explained_var: 0.9683566093444824\n",
      "      vf_loss: 796.0746459960938\n",
      "    sample_time_ms: 19681.925\n",
      "    update_time_ms: 5.129\n",
      "  iterations_since_restore: 892\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.2788195746101\n",
      "  time_since_restore: 21170.29326415062\n",
      "  time_this_iter_s: 23.191896677017212\n",
      "  time_total_s: 21170.29326415062\n",
      "  timestamp: 1553986966\n",
      "  timesteps_since_restore: 8920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8920000\n",
      "  training_iteration: 892\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21170 s, 892 iter, 8920000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-03-10\n",
      "  done: false\n",
      "  episode_len_mean: 164.81\n",
      "  episode_reward_max: 1118.4673149222426\n",
      "  episode_reward_mean: 988.2315214085913\n",
      "  episode_reward_min: -60.01962996300796\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 52039\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.354\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 8930000\n",
      "    num_steps_trained: 8930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4806373715400696\n",
      "      kl: 0.0329686738550663\n",
      "      policy_loss: -0.0011536183301359415\n",
      "      total_loss: 379.0146179199219\n",
      "      vf_explained_var: 0.9837270975112915\n",
      "      vf_loss: 379.0119934082031\n",
      "    sample_time_ms: 19648.826\n",
      "    update_time_ms: 5.103\n",
      "  iterations_since_restore: 893\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.11576070429567\n",
      "  time_since_restore: 21193.50590491295\n",
      "  time_this_iter_s: 23.2126407623291\n",
      "  time_total_s: 21193.50590491295\n",
      "  timestamp: 1553986990\n",
      "  timesteps_since_restore: 8930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8930000\n",
      "  training_iteration: 893\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21193 s, 893 iter, 8930000 ts, 988 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-03-33\n",
      "  done: false\n",
      "  episode_len_mean: 161.58\n",
      "  episode_reward_max: 1125.044044876061\n",
      "  episode_reward_mean: 1002.1948668865937\n",
      "  episode_reward_min: -24.797818284370237\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 52103\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3874.818\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 8940000\n",
      "    num_steps_trained: 8940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.31681904196739197\n",
      "      kl: 0.026187114417552948\n",
      "      policy_loss: -0.0049843923188745975\n",
      "      total_loss: 358.75750732421875\n",
      "      vf_explained_var: 0.9843088984489441\n",
      "      vf_loss: 358.7595520019531\n",
      "    sample_time_ms: 19678.849\n",
      "    update_time_ms: 5.458\n",
      "  iterations_since_restore: 894\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 501.0974334432968\n",
      "  time_since_restore: 21217.22873568535\n",
      "  time_this_iter_s: 23.722830772399902\n",
      "  time_total_s: 21217.22873568535\n",
      "  timestamp: 1553987013\n",
      "  timesteps_since_restore: 8940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8940000\n",
      "  training_iteration: 894\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21217 s, 894 iter, 8940000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-03-57\n",
      "  done: false\n",
      "  episode_len_mean: 170.35\n",
      "  episode_reward_max: 1113.0213925218382\n",
      "  episode_reward_mean: 978.759935632277\n",
      "  episode_reward_min: -9.251276226408578\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 52157\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.035\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 8950000\n",
      "    num_steps_trained: 8950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9410672187805176\n",
      "      kl: 0.0175376757979393\n",
      "      policy_loss: -0.0002705412916839123\n",
      "      total_loss: 298.74334716796875\n",
      "      vf_explained_var: 0.9878090023994446\n",
      "      vf_loss: 298.7415771484375\n",
      "    sample_time_ms: 19701.841\n",
      "    update_time_ms: 5.405\n",
      "  iterations_since_restore: 895\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.37996781613845\n",
      "  time_since_restore: 21240.820234298706\n",
      "  time_this_iter_s: 23.591498613357544\n",
      "  time_total_s: 21240.820234298706\n",
      "  timestamp: 1553987037\n",
      "  timesteps_since_restore: 8950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8950000\n",
      "  training_iteration: 895\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21240 s, 895 iter, 8950000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-04-21\n",
      "  done: false\n",
      "  episode_len_mean: 174.48\n",
      "  episode_reward_max: 1120.867519327417\n",
      "  episode_reward_mean: 996.3299537875994\n",
      "  episode_reward_min: -8.407829354550017\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 52214\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.41\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 8960000\n",
      "    num_steps_trained: 8960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6715297102928162\n",
      "      kl: 0.019982460886240005\n",
      "      policy_loss: -0.0024830508045852184\n",
      "      total_loss: 224.92762756347656\n",
      "      vf_explained_var: 0.9913586378097534\n",
      "      vf_loss: 224.92784118652344\n",
      "    sample_time_ms: 19728.84\n",
      "    update_time_ms: 5.554\n",
      "  iterations_since_restore: 896\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.16497689379963\n",
      "  time_since_restore: 21264.89950609207\n",
      "  time_this_iter_s: 24.07927179336548\n",
      "  time_total_s: 21264.89950609207\n",
      "  timestamp: 1553987061\n",
      "  timesteps_since_restore: 8960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8960000\n",
      "  training_iteration: 896\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21264 s, 896 iter, 8960000 ts, 996 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-04-44\n",
      "  done: false\n",
      "  episode_len_mean: 168.48\n",
      "  episode_reward_max: 1120.867519327417\n",
      "  episode_reward_mean: 1001.1721797520347\n",
      "  episode_reward_min: -68.1600863894528\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 52274\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.94\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 8970000\n",
      "    num_steps_trained: 8970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.37893766164779663\n",
      "      kl: 0.024232307448983192\n",
      "      policy_loss: -0.0026455740444362164\n",
      "      total_loss: 145.67117309570312\n",
      "      vf_explained_var: 0.9945663213729858\n",
      "      vf_loss: 145.67103576660156\n",
      "    sample_time_ms: 19620.875\n",
      "    update_time_ms: 5.652\n",
      "  iterations_since_restore: 897\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 500.58608987601735\n",
      "  time_since_restore: 21288.06679725647\n",
      "  time_this_iter_s: 23.167291164398193\n",
      "  time_total_s: 21288.06679725647\n",
      "  timestamp: 1553987084\n",
      "  timesteps_since_restore: 8970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8970000\n",
      "  training_iteration: 897\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21288 s, 897 iter, 8970000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-05-09\n",
      "  done: false\n",
      "  episode_len_mean: 168.13\n",
      "  episode_reward_max: 1144.178052236842\n",
      "  episode_reward_mean: 970.024834781327\n",
      "  episode_reward_min: -56.645678590575244\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 52334\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.462\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 8980000\n",
      "    num_steps_trained: 8980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7923394441604614\n",
      "      kl: 0.021145949140191078\n",
      "      policy_loss: -0.0038141554687172174\n",
      "      total_loss: 1007.58154296875\n",
      "      vf_explained_var: 0.9675228595733643\n",
      "      vf_loss: 1007.5829467773438\n",
      "    sample_time_ms: 19669.74\n",
      "    update_time_ms: 5.663\n",
      "  iterations_since_restore: 898\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.0124173906633\n",
      "  time_since_restore: 21312.416902542114\n",
      "  time_this_iter_s: 24.35010528564453\n",
      "  time_total_s: 21312.416902542114\n",
      "  timestamp: 1553987109\n",
      "  timesteps_since_restore: 8980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8980000\n",
      "  training_iteration: 898\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21312 s, 898 iter, 8980000 ts, 970 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-05-33\n",
      "  done: false\n",
      "  episode_len_mean: 173.34\n",
      "  episode_reward_max: 1144.178052236842\n",
      "  episode_reward_mean: 944.3355804620732\n",
      "  episode_reward_min: -72.10402029430847\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 52391\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.313\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 8990000\n",
      "    num_steps_trained: 8990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7526774406433105\n",
      "      kl: 0.023710152134299278\n",
      "      policy_loss: -0.0030470038764178753\n",
      "      total_loss: 325.0626525878906\n",
      "      vf_explained_var: 0.988580584526062\n",
      "      vf_loss: 325.0630187988281\n",
      "    sample_time_ms: 19734.146\n",
      "    update_time_ms: 5.604\n",
      "  iterations_since_restore: 899\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.16779023103646\n",
      "  time_since_restore: 21336.53892469406\n",
      "  time_this_iter_s: 24.12202215194702\n",
      "  time_total_s: 21336.53892469406\n",
      "  timestamp: 1553987133\n",
      "  timesteps_since_restore: 8990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8990000\n",
      "  training_iteration: 899\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21336 s, 899 iter, 8990000 ts, 944 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-05-57\n",
      "  done: false\n",
      "  episode_len_mean: 170.13\n",
      "  episode_reward_max: 1132.1152561389295\n",
      "  episode_reward_mean: 979.7055167150169\n",
      "  episode_reward_min: -79.48761717495029\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 52452\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.192\n",
      "    load_time_ms: 1.33\n",
      "    num_steps_sampled: 9000000\n",
      "    num_steps_trained: 9000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2754986584186554\n",
      "      kl: 0.02282678708434105\n",
      "      policy_loss: -0.0063208225183188915\n",
      "      total_loss: 473.8231201171875\n",
      "      vf_explained_var: 0.9793252944946289\n",
      "      vf_loss: 473.8268127441406\n",
      "    sample_time_ms: 19810.54\n",
      "    update_time_ms: 5.667\n",
      "  iterations_since_restore: 900\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.85275835750843\n",
      "  time_since_restore: 21360.907963752747\n",
      "  time_this_iter_s: 24.369039058685303\n",
      "  time_total_s: 21360.907963752747\n",
      "  timestamp: 1553987157\n",
      "  timesteps_since_restore: 9000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9000000\n",
      "  training_iteration: 900\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21360 s, 900 iter, 9000000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-06-21\n",
      "  done: false\n",
      "  episode_len_mean: 165.77\n",
      "  episode_reward_max: 1113.2491560570456\n",
      "  episode_reward_mean: 966.7784555634776\n",
      "  episode_reward_min: -83.90699619413546\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 52512\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.537\n",
      "    load_time_ms: 1.317\n",
      "    num_steps_sampled: 9010000\n",
      "    num_steps_trained: 9010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7707225680351257\n",
      "      kl: 0.02743026614189148\n",
      "      policy_loss: -0.0044284057803452015\n",
      "      total_loss: 718.8280029296875\n",
      "      vf_explained_var: 0.9713088870048523\n",
      "      vf_loss: 718.8292236328125\n",
      "    sample_time_ms: 19860.412\n",
      "    update_time_ms: 5.757\n",
      "  iterations_since_restore: 901\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.38922778173895\n",
      "  time_since_restore: 21384.928372383118\n",
      "  time_this_iter_s: 24.020408630371094\n",
      "  time_total_s: 21384.928372383118\n",
      "  timestamp: 1553987181\n",
      "  timesteps_since_restore: 9010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9010000\n",
      "  training_iteration: 901\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21384 s, 901 iter, 9010000 ts, 967 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-06-45\n",
      "  done: false\n",
      "  episode_len_mean: 170.01\n",
      "  episode_reward_max: 1111.4550008363674\n",
      "  episode_reward_mean: 984.2034317407329\n",
      "  episode_reward_min: -83.90699619413546\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 52571\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.025\n",
      "    load_time_ms: 1.38\n",
      "    num_steps_sampled: 9020000\n",
      "    num_steps_trained: 9020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11451210081577301\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.17517036199569702\n",
      "      kl: 0.06388194859027863\n",
      "      policy_loss: -0.0002865775895770639\n",
      "      total_loss: 60.56697082519531\n",
      "      vf_explained_var: 0.9977162480354309\n",
      "      vf_loss: 60.55994415283203\n",
      "    sample_time_ms: 19923.885\n",
      "    update_time_ms: 5.648\n",
      "  iterations_since_restore: 902\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.1017158703663\n",
      "  time_since_restore: 21408.730469942093\n",
      "  time_this_iter_s: 23.80209755897522\n",
      "  time_total_s: 21408.730469942093\n",
      "  timestamp: 1553987205\n",
      "  timesteps_since_restore: 9020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9020000\n",
      "  training_iteration: 902\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21408 s, 902 iter, 9020000 ts, 984 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-07-09\n",
      "  done: false\n",
      "  episode_len_mean: 166.8\n",
      "  episode_reward_max: 1154.0895048552202\n",
      "  episode_reward_mean: 985.7896295222382\n",
      "  episode_reward_min: -19.920110489331677\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 52630\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.207\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 9030000\n",
      "    num_steps_trained: 9030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5823594331741333\n",
      "      kl: 0.01102698314934969\n",
      "      policy_loss: -0.00019724822777789086\n",
      "      total_loss: 703.3855590820312\n",
      "      vf_explained_var: 0.9713589549064636\n",
      "      vf_loss: 703.3837890625\n",
      "    sample_time_ms: 19987.541\n",
      "    update_time_ms: 5.648\n",
      "  iterations_since_restore: 903\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.894814761119\n",
      "  time_since_restore: 21432.663086414337\n",
      "  time_this_iter_s: 23.932616472244263\n",
      "  time_total_s: 21432.663086414337\n",
      "  timestamp: 1553987229\n",
      "  timesteps_since_restore: 9030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9030000\n",
      "  training_iteration: 903\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21432 s, 903 iter, 9030000 ts, 986 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-07-32\n",
      "  done: false\n",
      "  episode_len_mean: 174.69\n",
      "  episode_reward_max: 1136.9623304294566\n",
      "  episode_reward_mean: 967.2900253168768\n",
      "  episode_reward_min: -19.920110489331677\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 52684\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.476\n",
      "    load_time_ms: 1.403\n",
      "    num_steps_sampled: 9040000\n",
      "    num_steps_trained: 9040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1264957189559937\n",
      "      kl: 0.016465405002236366\n",
      "      policy_loss: -0.0033045427408069372\n",
      "      total_loss: 438.30999755859375\n",
      "      vf_explained_var: 0.9825761318206787\n",
      "      vf_loss: 438.3104553222656\n",
      "    sample_time_ms: 19929.798\n",
      "    update_time_ms: 5.173\n",
      "  iterations_since_restore: 904\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.64501265843836\n",
      "  time_since_restore: 21455.867063760757\n",
      "  time_this_iter_s: 23.203977346420288\n",
      "  time_total_s: 21455.867063760757\n",
      "  timestamp: 1553987252\n",
      "  timesteps_since_restore: 9040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9040000\n",
      "  training_iteration: 904\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21455 s, 904 iter, 9040000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-07-56\n",
      "  done: false\n",
      "  episode_len_mean: 178.43\n",
      "  episode_reward_max: 1128.1528283509444\n",
      "  episode_reward_mean: 980.8470661003018\n",
      "  episode_reward_min: -93.05832607481449\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 52742\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.147\n",
      "    load_time_ms: 1.449\n",
      "    num_steps_sampled: 9050000\n",
      "    num_steps_trained: 9050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8615167140960693\n",
      "      kl: 0.019016867503523827\n",
      "      policy_loss: -0.0009101732284761965\n",
      "      total_loss: 483.7475891113281\n",
      "      vf_explained_var: 0.9814081192016602\n",
      "      vf_loss: 483.7452392578125\n",
      "    sample_time_ms: 19938.633\n",
      "    update_time_ms: 5.347\n",
      "  iterations_since_restore: 905\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.42353305015104\n",
      "  time_since_restore: 21479.460377454758\n",
      "  time_this_iter_s: 23.593313694000244\n",
      "  time_total_s: 21479.460377454758\n",
      "  timestamp: 1553987276\n",
      "  timesteps_since_restore: 9050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9050000\n",
      "  training_iteration: 905\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21479 s, 905 iter, 9050000 ts, 981 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-08-20\n",
      "  done: false\n",
      "  episode_len_mean: 167.76\n",
      "  episode_reward_max: 1159.5968731418304\n",
      "  episode_reward_mean: 954.8351744318118\n",
      "  episode_reward_min: -93.05832607481449\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 52803\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.321\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 9060000\n",
      "    num_steps_trained: 9060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7425822615623474\n",
      "      kl: 0.015531790442764759\n",
      "      policy_loss: -0.005069067236036062\n",
      "      total_loss: 859.4708251953125\n",
      "      vf_explained_var: 0.9675915241241455\n",
      "      vf_loss: 859.4733276367188\n",
      "    sample_time_ms: 19895.955\n",
      "    update_time_ms: 5.319\n",
      "  iterations_since_restore: 906\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.4175872159059\n",
      "  time_since_restore: 21503.069952726364\n",
      "  time_this_iter_s: 23.609575271606445\n",
      "  time_total_s: 21503.069952726364\n",
      "  timestamp: 1553987300\n",
      "  timesteps_since_restore: 9060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9060000\n",
      "  training_iteration: 906\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21503 s, 906 iter, 9060000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-08-44\n",
      "  done: false\n",
      "  episode_len_mean: 166.48\n",
      "  episode_reward_max: 1159.5968731418304\n",
      "  episode_reward_mean: 951.8219306844969\n",
      "  episode_reward_min: -89.30789450881613\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 52863\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.489\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 9070000\n",
      "    num_steps_trained: 9070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6813229918479919\n",
      "      kl: 0.01350795291364193\n",
      "      policy_loss: -0.0027234952431172132\n",
      "      total_loss: 445.058837890625\n",
      "      vf_explained_var: 0.9811520576477051\n",
      "      vf_loss: 445.0592041015625\n",
      "    sample_time_ms: 20006.554\n",
      "    update_time_ms: 5.252\n",
      "  iterations_since_restore: 907\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.9109653422485\n",
      "  time_since_restore: 21527.332821130753\n",
      "  time_this_iter_s: 24.262868404388428\n",
      "  time_total_s: 21527.332821130753\n",
      "  timestamp: 1553987324\n",
      "  timesteps_since_restore: 9070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9070000\n",
      "  training_iteration: 907\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21527 s, 907 iter, 9070000 ts, 952 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-09-07\n",
      "  done: false\n",
      "  episode_len_mean: 168.36\n",
      "  episode_reward_max: 1148.2327388009633\n",
      "  episode_reward_mean: 972.6488671592434\n",
      "  episode_reward_min: -14.973602077284909\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 52922\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.555\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 9080000\n",
      "    num_steps_trained: 9080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5501440763473511\n",
      "      kl: 0.02125297300517559\n",
      "      policy_loss: -0.004723032936453819\n",
      "      total_loss: 328.6822814941406\n",
      "      vf_explained_var: 0.987633228302002\n",
      "      vf_loss: 328.683349609375\n",
      "    sample_time_ms: 19916.167\n",
      "    update_time_ms: 5.459\n",
      "  iterations_since_restore: 908\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.3244335796217\n",
      "  time_since_restore: 21550.770097970963\n",
      "  time_this_iter_s: 23.43727684020996\n",
      "  time_total_s: 21550.770097970963\n",
      "  timestamp: 1553987347\n",
      "  timesteps_since_restore: 9080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9080000\n",
      "  training_iteration: 908\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21550 s, 908 iter, 9080000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-09-32\n",
      "  done: false\n",
      "  episode_len_mean: 168.51\n",
      "  episode_reward_max: 1148.2327388009633\n",
      "  episode_reward_mean: 1003.5282080012212\n",
      "  episode_reward_min: 3.9510245691237458\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 52982\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.561\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 9090000\n",
      "    num_steps_trained: 9090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.43994492292404175\n",
      "      kl: 0.02195618860423565\n",
      "      policy_loss: -0.001447346294298768\n",
      "      total_loss: 114.71701049804688\n",
      "      vf_explained_var: 0.9953454732894897\n",
      "      vf_loss: 114.71468353271484\n",
      "    sample_time_ms: 19927.623\n",
      "    update_time_ms: 5.468\n",
      "  iterations_since_restore: 909\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 501.76410400061053\n",
      "  time_since_restore: 21575.03664970398\n",
      "  time_this_iter_s: 24.266551733016968\n",
      "  time_total_s: 21575.03664970398\n",
      "  timestamp: 1553987372\n",
      "  timesteps_since_restore: 9090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9090000\n",
      "  training_iteration: 909\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21575 s, 909 iter, 9090000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-09-56\n",
      "  done: false\n",
      "  episode_len_mean: 170.15\n",
      "  episode_reward_max: 1114.4052075367738\n",
      "  episode_reward_mean: 993.2378950118243\n",
      "  episode_reward_min: -86.40963898295065\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 53040\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.571\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 9100000\n",
      "    num_steps_trained: 9100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.652500331401825\n",
      "      kl: 0.01724196784198284\n",
      "      policy_loss: -0.0030876961536705494\n",
      "      total_loss: 524.4946899414062\n",
      "      vf_explained_var: 0.9805882573127747\n",
      "      vf_loss: 524.4948120117188\n",
      "    sample_time_ms: 19907.812\n",
      "    update_time_ms: 5.723\n",
      "  iterations_since_restore: 910\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.6189475059122\n",
      "  time_since_restore: 21599.212827205658\n",
      "  time_this_iter_s: 24.176177501678467\n",
      "  time_total_s: 21599.212827205658\n",
      "  timestamp: 1553987396\n",
      "  timesteps_since_restore: 9100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9100000\n",
      "  training_iteration: 910\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21599 s, 910 iter, 9100000 ts, 993 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-10-20\n",
      "  done: false\n",
      "  episode_len_mean: 174.49\n",
      "  episode_reward_max: 1119.731297251457\n",
      "  episode_reward_mean: 960.0534183410319\n",
      "  episode_reward_min: -86.40963898295065\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 53097\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.824\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 9110000\n",
      "    num_steps_trained: 9110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9867489337921143\n",
      "      kl: 0.017728324979543686\n",
      "      policy_loss: -0.0015256151091307402\n",
      "      total_loss: 582.2982788085938\n",
      "      vf_explained_var: 0.9775433540344238\n",
      "      vf_loss: 582.2967529296875\n",
      "    sample_time_ms: 19880.94\n",
      "    update_time_ms: 6.602\n",
      "  iterations_since_restore: 911\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.02670917051614\n",
      "  time_since_restore: 21622.924580335617\n",
      "  time_this_iter_s: 23.711753129959106\n",
      "  time_total_s: 21622.924580335617\n",
      "  timestamp: 1553987420\n",
      "  timesteps_since_restore: 9110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9110000\n",
      "  training_iteration: 911\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21622 s, 911 iter, 9110000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-10-44\n",
      "  done: false\n",
      "  episode_len_mean: 176.25\n",
      "  episode_reward_max: 1147.003136099148\n",
      "  episode_reward_mean: 945.3179642640174\n",
      "  episode_reward_min: -56.89272999017166\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 53154\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.033\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 9120000\n",
      "    num_steps_trained: 9120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7800405621528625\n",
      "      kl: 0.012350575067102909\n",
      "      policy_loss: -0.0009581599733792245\n",
      "      total_loss: 817.7509155273438\n",
      "      vf_explained_var: 0.966566801071167\n",
      "      vf_loss: 817.7498168945312\n",
      "    sample_time_ms: 19932.038\n",
      "    update_time_ms: 6.801\n",
      "  iterations_since_restore: 912\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 472.6589821320088\n",
      "  time_since_restore: 21647.242878437042\n",
      "  time_this_iter_s: 24.31829810142517\n",
      "  time_total_s: 21647.242878437042\n",
      "  timestamp: 1553987444\n",
      "  timesteps_since_restore: 9120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9120000\n",
      "  training_iteration: 912\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21647 s, 912 iter, 9120000 ts, 945 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-11-08\n",
      "  done: false\n",
      "  episode_len_mean: 171.13\n",
      "  episode_reward_max: 1147.003136099148\n",
      "  episode_reward_mean: 960.3376964164286\n",
      "  episode_reward_min: -60.809531410524045\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 53214\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.819\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 9130000\n",
      "    num_steps_trained: 9130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.833781898021698\n",
      "      kl: 0.025036433711647987\n",
      "      policy_loss: -0.003856681752949953\n",
      "      total_loss: 353.0917053222656\n",
      "      vf_explained_var: 0.9872283935546875\n",
      "      vf_loss: 353.09124755859375\n",
      "    sample_time_ms: 19937.642\n",
      "    update_time_ms: 6.817\n",
      "  iterations_since_restore: 913\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.1688482082143\n",
      "  time_since_restore: 21671.26234483719\n",
      "  time_this_iter_s: 24.019466400146484\n",
      "  time_total_s: 21671.26234483719\n",
      "  timestamp: 1553987468\n",
      "  timesteps_since_restore: 9130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9130000\n",
      "  training_iteration: 913\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21671 s, 913 iter, 9130000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-11-32\n",
      "  done: false\n",
      "  episode_len_mean: 173.82\n",
      "  episode_reward_max: 1100.1932758768137\n",
      "  episode_reward_mean: 950.0803432260799\n",
      "  episode_reward_min: -60.809531410524045\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 53270\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.825\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 9140000\n",
      "    num_steps_trained: 9140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9082272052764893\n",
      "      kl: 0.014949352480471134\n",
      "      policy_loss: 5.0422855565557256e-05\n",
      "      total_loss: 675.1605224609375\n",
      "      vf_explained_var: 0.9721980690956116\n",
      "      vf_loss: 675.157958984375\n",
      "    sample_time_ms: 20024.713\n",
      "    update_time_ms: 6.909\n",
      "  iterations_since_restore: 914\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.04017161303983\n",
      "  time_since_restore: 21695.347974538803\n",
      "  time_this_iter_s: 24.08562970161438\n",
      "  time_total_s: 21695.347974538803\n",
      "  timestamp: 1553987492\n",
      "  timesteps_since_restore: 9140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9140000\n",
      "  training_iteration: 914\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21695 s, 914 iter, 9140000 ts, 950 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-11-56\n",
      "  done: false\n",
      "  episode_len_mean: 178.17\n",
      "  episode_reward_max: 1156.5654551898342\n",
      "  episode_reward_mean: 968.0625059197641\n",
      "  episode_reward_min: -96.93910025906541\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 53327\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.593\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 9150000\n",
      "    num_steps_trained: 9150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.953372061252594\n",
      "      kl: 0.02162138558924198\n",
      "      policy_loss: -0.004879803862422705\n",
      "      total_loss: 319.01031494140625\n",
      "      vf_explained_var: 0.9873846769332886\n",
      "      vf_loss: 319.011474609375\n",
      "    sample_time_ms: 20013.594\n",
      "    update_time_ms: 7.066\n",
      "  iterations_since_restore: 915\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.03125295988207\n",
      "  time_since_restore: 21718.84708237648\n",
      "  time_this_iter_s: 23.499107837677002\n",
      "  time_total_s: 21718.84708237648\n",
      "  timestamp: 1553987516\n",
      "  timesteps_since_restore: 9150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9150000\n",
      "  training_iteration: 915\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21718 s, 915 iter, 9150000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-12-19\n",
      "  done: false\n",
      "  episode_len_mean: 169.05\n",
      "  episode_reward_max: 1156.5654551898342\n",
      "  episode_reward_mean: 979.5290897622549\n",
      "  episode_reward_min: -96.93910025906541\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 53388\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.447\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 9160000\n",
      "    num_steps_trained: 9160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5007113218307495\n",
      "      kl: 0.01939372532069683\n",
      "      policy_loss: -0.004667549394071102\n",
      "      total_loss: 445.6436767578125\n",
      "      vf_explained_var: 0.9830324053764343\n",
      "      vf_loss: 445.6449890136719\n",
      "    sample_time_ms: 19996.293\n",
      "    update_time_ms: 6.962\n",
      "  iterations_since_restore: 916\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.7645448811274\n",
      "  time_since_restore: 21742.318553686142\n",
      "  time_this_iter_s: 23.471471309661865\n",
      "  time_total_s: 21742.318553686142\n",
      "  timestamp: 1553987539\n",
      "  timesteps_since_restore: 9160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9160000\n",
      "  training_iteration: 916\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21742 s, 916 iter, 9160000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-12-44\n",
      "  done: false\n",
      "  episode_len_mean: 175.21\n",
      "  episode_reward_max: 1111.445500323362\n",
      "  episode_reward_mean: 960.7049283516417\n",
      "  episode_reward_min: -60.70282641902298\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 53442\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3898.887\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 9170000\n",
      "    num_steps_trained: 9170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4466941356658936\n",
      "      kl: 0.015443745069205761\n",
      "      policy_loss: -0.002435613190755248\n",
      "      total_loss: 1070.62744140625\n",
      "      vf_explained_var: 0.9605063199996948\n",
      "      vf_loss: 1070.627197265625\n",
      "    sample_time_ms: 19997.822\n",
      "    update_time_ms: 7.082\n",
      "  iterations_since_restore: 917\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.35246417582096\n",
      "  time_since_restore: 21766.57266020775\n",
      "  time_this_iter_s: 24.254106521606445\n",
      "  time_total_s: 21766.57266020775\n",
      "  timestamp: 1553987564\n",
      "  timesteps_since_restore: 9170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9170000\n",
      "  training_iteration: 917\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21766 s, 917 iter, 9170000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-13-08\n",
      "  done: false\n",
      "  episode_len_mean: 165.58\n",
      "  episode_reward_max: 1119.8028460793892\n",
      "  episode_reward_mean: 937.5827255630919\n",
      "  episode_reward_min: -87.0929044944059\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 53503\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.393\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 9180000\n",
      "    num_steps_trained: 9180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48271453380584717\n",
      "      kl: 0.013543743640184402\n",
      "      policy_loss: -0.0018000612035393715\n",
      "      total_loss: 930.3203125\n",
      "      vf_explained_var: 0.9603228569030762\n",
      "      vf_loss: 930.3197021484375\n",
      "    sample_time_ms: 20041.677\n",
      "    update_time_ms: 6.905\n",
      "  iterations_since_restore: 918\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 468.7913627815459\n",
      "  time_since_restore: 21790.497391462326\n",
      "  time_this_iter_s: 23.924731254577637\n",
      "  time_total_s: 21790.497391462326\n",
      "  timestamp: 1553987588\n",
      "  timesteps_since_restore: 9180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9180000\n",
      "  training_iteration: 918\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21790 s, 918 iter, 9180000 ts, 938 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-13-32\n",
      "  done: false\n",
      "  episode_len_mean: 170.4\n",
      "  episode_reward_max: 1130.5679735215845\n",
      "  episode_reward_mean: 942.588483454521\n",
      "  episode_reward_min: -87.0929044944059\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 53560\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.349\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 9190000\n",
      "    num_steps_trained: 9190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9938539266586304\n",
      "      kl: 0.014626726508140564\n",
      "      policy_loss: -0.004020890220999718\n",
      "      total_loss: 1288.5496826171875\n",
      "      vf_explained_var: 0.9489683508872986\n",
      "      vf_loss: 1288.551025390625\n",
      "    sample_time_ms: 20011.2\n",
      "    update_time_ms: 7.075\n",
      "  iterations_since_restore: 919\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 471.2942417272605\n",
      "  time_since_restore: 21814.463368415833\n",
      "  time_this_iter_s: 23.96597695350647\n",
      "  time_total_s: 21814.463368415833\n",
      "  timestamp: 1553987612\n",
      "  timesteps_since_restore: 9190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9190000\n",
      "  training_iteration: 919\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21814 s, 919 iter, 9190000 ts, 943 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-13-55\n",
      "  done: false\n",
      "  episode_len_mean: 170.04\n",
      "  episode_reward_max: 1130.5679735215845\n",
      "  episode_reward_mean: 976.2898575436049\n",
      "  episode_reward_min: -58.46773955306949\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 53619\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.717\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 9200000\n",
      "    num_steps_trained: 9200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6089209318161011\n",
      "      kl: 0.019540058448910713\n",
      "      policy_loss: -0.0009530805400572717\n",
      "      total_loss: 411.31109619140625\n",
      "      vf_explained_var: 0.9829584956169128\n",
      "      vf_loss: 411.3087158203125\n",
      "    sample_time_ms: 19927.056\n",
      "    update_time_ms: 6.383\n",
      "  iterations_since_restore: 920\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.14492877180254\n",
      "  time_since_restore: 21837.79405283928\n",
      "  time_this_iter_s: 23.330684423446655\n",
      "  time_total_s: 21837.79405283928\n",
      "  timestamp: 1553987635\n",
      "  timesteps_since_restore: 9200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9200000\n",
      "  training_iteration: 920\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21837 s, 920 iter, 9200000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-14-19\n",
      "  done: false\n",
      "  episode_len_mean: 173.47\n",
      "  episode_reward_max: 1157.111757175599\n",
      "  episode_reward_mean: 987.03194522896\n",
      "  episode_reward_min: -88.46839804669303\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 53675\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.771\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 9210000\n",
      "    num_steps_trained: 9210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9220700263977051\n",
      "      kl: 0.01562611572444439\n",
      "      policy_loss: -0.0014244435587897897\n",
      "      total_loss: 561.5499267578125\n",
      "      vf_explained_var: 0.9779269695281982\n",
      "      vf_loss: 561.5486450195312\n",
      "    sample_time_ms: 19965.857\n",
      "    update_time_ms: 5.496\n",
      "  iterations_since_restore: 921\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.51597261448\n",
      "  time_since_restore: 21861.870911836624\n",
      "  time_this_iter_s: 24.07685899734497\n",
      "  time_total_s: 21861.870911836624\n",
      "  timestamp: 1553987659\n",
      "  timesteps_since_restore: 9210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9210000\n",
      "  training_iteration: 921\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21861 s, 921 iter, 9210000 ts, 987 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-14-43\n",
      "  done: false\n",
      "  episode_len_mean: 169.7\n",
      "  episode_reward_max: 1157.111757175599\n",
      "  episode_reward_mean: 992.0956052432379\n",
      "  episode_reward_min: -88.46839804669303\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 53737\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3904.362\n",
      "    load_time_ms: 1.696\n",
      "    num_steps_sampled: 9220000\n",
      "    num_steps_trained: 9220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4507399797439575\n",
      "      kl: 0.019896937534213066\n",
      "      policy_loss: -0.0005018000374548137\n",
      "      total_loss: 582.28173828125\n",
      "      vf_explained_var: 0.9739891290664673\n",
      "      vf_loss: 582.2788696289062\n",
      "    sample_time_ms: 19931.953\n",
      "    update_time_ms: 5.301\n",
      "  iterations_since_restore: 922\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.0478026216189\n",
      "  time_since_restore: 21885.861108779907\n",
      "  time_this_iter_s: 23.99019694328308\n",
      "  time_total_s: 21885.861108779907\n",
      "  timestamp: 1553987683\n",
      "  timesteps_since_restore: 9220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9220000\n",
      "  training_iteration: 922\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21885 s, 922 iter, 9220000 ts, 992 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 162.26\n",
      "  episode_reward_max: 1131.6345190852003\n",
      "  episode_reward_mean: 934.0146353211421\n",
      "  episode_reward_min: -72.74417950386137\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 53800\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.072\n",
      "    load_time_ms: 1.72\n",
      "    num_steps_sampled: 9230000\n",
      "    num_steps_trained: 9230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5589471459388733\n",
      "      kl: 0.0164851825684309\n",
      "      policy_loss: 0.0018480477156117558\n",
      "      total_loss: 963.5414428710938\n",
      "      vf_explained_var: 0.9659379124641418\n",
      "      vf_loss: 963.536865234375\n",
      "    sample_time_ms: 19853.99\n",
      "    update_time_ms: 5.317\n",
      "  iterations_since_restore: 923\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 467.007317660571\n",
      "  time_since_restore: 21908.926813602448\n",
      "  time_this_iter_s: 23.065704822540283\n",
      "  time_total_s: 21908.926813602448\n",
      "  timestamp: 1553987706\n",
      "  timesteps_since_restore: 9230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9230000\n",
      "  training_iteration: 923\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21908 s, 923 iter, 9230000 ts, 934 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-15-30\n",
      "  done: false\n",
      "  episode_len_mean: 160.79\n",
      "  episode_reward_max: 1129.0204199652385\n",
      "  episode_reward_mean: 940.8454536864627\n",
      "  episode_reward_min: -72.80085646040591\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 53861\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.515\n",
      "    load_time_ms: 1.731\n",
      "    num_steps_sampled: 9240000\n",
      "    num_steps_trained: 9240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.30202943086624146\n",
      "      kl: 0.016587356105446815\n",
      "      policy_loss: -0.0031632829923182726\n",
      "      total_loss: 579.1061401367188\n",
      "      vf_explained_var: 0.9748852252960205\n",
      "      vf_loss: 579.1064453125\n",
      "    sample_time_ms: 19851.237\n",
      "    update_time_ms: 5.473\n",
      "  iterations_since_restore: 924\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 470.4227268432312\n",
      "  time_since_restore: 21932.921687602997\n",
      "  time_this_iter_s: 23.994874000549316\n",
      "  time_total_s: 21932.921687602997\n",
      "  timestamp: 1553987730\n",
      "  timesteps_since_restore: 9240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9240000\n",
      "  training_iteration: 924\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21932 s, 924 iter, 9240000 ts, 941 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-15-54\n",
      "  done: false\n",
      "  episode_len_mean: 168.39\n",
      "  episode_reward_max: 1174.037315283155\n",
      "  episode_reward_mean: 958.3403680814064\n",
      "  episode_reward_min: -72.80085646040591\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 53918\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.87\n",
      "    load_time_ms: 1.763\n",
      "    num_steps_sampled: 9250000\n",
      "    num_steps_trained: 9250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9776937961578369\n",
      "      kl: 0.019404273480176926\n",
      "      policy_loss: -0.004282363690435886\n",
      "      total_loss: 742.5574951171875\n",
      "      vf_explained_var: 0.9714184999465942\n",
      "      vf_loss: 742.5584716796875\n",
      "    sample_time_ms: 19870.736\n",
      "    update_time_ms: 5.289\n",
      "  iterations_since_restore: 925\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 479.1701840407032\n",
      "  time_since_restore: 21956.617973089218\n",
      "  time_this_iter_s: 23.696285486221313\n",
      "  time_total_s: 21956.617973089218\n",
      "  timestamp: 1553987754\n",
      "  timesteps_since_restore: 9250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9250000\n",
      "  training_iteration: 925\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21956 s, 925 iter, 9250000 ts, 958 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-16-18\n",
      "  done: false\n",
      "  episode_len_mean: 168.37\n",
      "  episode_reward_max: 1174.037315283155\n",
      "  episode_reward_mean: 984.1408210323372\n",
      "  episode_reward_min: -65.1282381647666\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 53978\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.161\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 9260000\n",
      "    num_steps_trained: 9260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4049299955368042\n",
      "      kl: 0.02162742242217064\n",
      "      policy_loss: -0.0013036018935963511\n",
      "      total_loss: 267.8976745605469\n",
      "      vf_explained_var: 0.9883503317832947\n",
      "      vf_loss: 267.8952941894531\n",
      "    sample_time_ms: 19915.338\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 926\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.07041051616847\n",
      "  time_since_restore: 21980.498814344406\n",
      "  time_this_iter_s: 23.88084125518799\n",
      "  time_total_s: 21980.498814344406\n",
      "  timestamp: 1553987778\n",
      "  timesteps_since_restore: 9260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9260000\n",
      "  training_iteration: 926\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 21980 s, 926 iter, 9260000 ts, 984 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-16-42\n",
      "  done: false\n",
      "  episode_len_mean: 167.53\n",
      "  episode_reward_max: 1185.5575530222798\n",
      "  episode_reward_mean: 1002.9949363333478\n",
      "  episode_reward_min: -65.1282381647666\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 54038\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.748\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 9270000\n",
      "    num_steps_trained: 9270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4103829264640808\n",
      "      kl: 0.021290861070156097\n",
      "      policy_loss: -0.0037360494025051594\n",
      "      total_loss: 320.178466796875\n",
      "      vf_explained_var: 0.9869896173477173\n",
      "      vf_loss: 320.17852783203125\n",
      "    sample_time_ms: 19898.791\n",
      "    update_time_ms: 5.598\n",
      "  iterations_since_restore: 927\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 501.4974681666739\n",
      "  time_since_restore: 22004.578429460526\n",
      "  time_this_iter_s: 24.079615116119385\n",
      "  time_total_s: 22004.578429460526\n",
      "  timestamp: 1553987802\n",
      "  timesteps_since_restore: 9270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9270000\n",
      "  training_iteration: 927\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22004 s, 927 iter, 9270000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-17-06\n",
      "  done: false\n",
      "  episode_len_mean: 171.92\n",
      "  episode_reward_max: 1158.756940307883\n",
      "  episode_reward_mean: 973.323905346303\n",
      "  episode_reward_min: -97.37901797736744\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 54092\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3860.613\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 9280000\n",
      "    num_steps_trained: 9280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2016223669052124\n",
      "      kl: 0.011748206801712513\n",
      "      policy_loss: 0.0009923893958330154\n",
      "      total_loss: 699.3493041992188\n",
      "      vf_explained_var: 0.9731478691101074\n",
      "      vf_loss: 699.3462524414062\n",
      "    sample_time_ms: 19908.172\n",
      "    update_time_ms: 5.64\n",
      "  iterations_since_restore: 928\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.6619526731515\n",
      "  time_since_restore: 22028.444918632507\n",
      "  time_this_iter_s: 23.86648917198181\n",
      "  time_total_s: 22028.444918632507\n",
      "  timestamp: 1553987826\n",
      "  timesteps_since_restore: 9280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9280000\n",
      "  training_iteration: 928\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22028 s, 928 iter, 9280000 ts, 973 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-17-30\n",
      "  done: false\n",
      "  episode_len_mean: 183.83\n",
      "  episode_reward_max: 1113.9915617194645\n",
      "  episode_reward_mean: 938.9628507908284\n",
      "  episode_reward_min: -97.37901797736744\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 54146\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3861.658\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 9290000\n",
      "    num_steps_trained: 9290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.113756775856018\n",
      "      kl: 0.01854095421731472\n",
      "      policy_loss: -0.0034437619615346193\n",
      "      total_loss: 545.5123291015625\n",
      "      vf_explained_var: 0.980194091796875\n",
      "      vf_loss: 545.5125122070312\n",
      "    sample_time_ms: 19862.123\n",
      "    update_time_ms: 5.673\n",
      "  iterations_since_restore: 929\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 469.48142539541413\n",
      "  time_since_restore: 22051.959225654602\n",
      "  time_this_iter_s: 23.514307022094727\n",
      "  time_total_s: 22051.959225654602\n",
      "  timestamp: 1553987850\n",
      "  timesteps_since_restore: 9290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9290000\n",
      "  training_iteration: 929\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22051 s, 929 iter, 9290000 ts, 939 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-17-54\n",
      "  done: false\n",
      "  episode_len_mean: 175.91\n",
      "  episode_reward_max: 1123.7011447057992\n",
      "  episode_reward_mean: 967.722163382752\n",
      "  episode_reward_min: -67.24323719864276\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 54206\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3865.04\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 9300000\n",
      "    num_steps_trained: 9300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.574245810508728\n",
      "      kl: 0.02106541022658348\n",
      "      policy_loss: -0.002189286984503269\n",
      "      total_loss: 264.0747375488281\n",
      "      vf_explained_var: 0.9894875884056091\n",
      "      vf_loss: 264.07330322265625\n",
      "    sample_time_ms: 19929.726\n",
      "    update_time_ms: 5.673\n",
      "  iterations_since_restore: 930\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.86108169137594\n",
      "  time_since_restore: 22076.000791549683\n",
      "  time_this_iter_s: 24.041565895080566\n",
      "  time_total_s: 22076.000791549683\n",
      "  timestamp: 1553987874\n",
      "  timesteps_since_restore: 9300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9300000\n",
      "  training_iteration: 930\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22076 s, 930 iter, 9300000 ts, 968 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-18-17\n",
      "  done: false\n",
      "  episode_len_mean: 177.01\n",
      "  episode_reward_max: 1123.7011447057992\n",
      "  episode_reward_mean: 994.3146774970351\n",
      "  episode_reward_min: 51.023614141571954\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 54260\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3867.941\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 9310000\n",
      "    num_steps_trained: 9310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.192487120628357\n",
      "      kl: 0.018131209537386894\n",
      "      policy_loss: -0.001795298419892788\n",
      "      total_loss: 323.017578125\n",
      "      vf_explained_var: 0.98752760887146\n",
      "      vf_loss: 323.0162658691406\n",
      "    sample_time_ms: 19874.079\n",
      "    update_time_ms: 5.736\n",
      "  iterations_since_restore: 931\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.1573387485176\n",
      "  time_since_restore: 22099.548089504242\n",
      "  time_this_iter_s: 23.547297954559326\n",
      "  time_total_s: 22099.548089504242\n",
      "  timestamp: 1553987897\n",
      "  timesteps_since_restore: 9310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9310000\n",
      "  training_iteration: 931\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22099 s, 931 iter, 9310000 ts, 994 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-18-41\n",
      "  done: false\n",
      "  episode_len_mean: 173.5\n",
      "  episode_reward_max: 1146.252856126399\n",
      "  episode_reward_mean: 997.5795744816841\n",
      "  episode_reward_min: -98.31163349190864\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 54321\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.193\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 9320000\n",
      "    num_steps_trained: 9320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4194163680076599\n",
      "      kl: 0.01553089078515768\n",
      "      policy_loss: -0.0008874198538251221\n",
      "      total_loss: 332.4045104980469\n",
      "      vf_explained_var: 0.9861708283424377\n",
      "      vf_loss: 332.4027404785156\n",
      "    sample_time_ms: 19834.899\n",
      "    update_time_ms: 5.911\n",
      "  iterations_since_restore: 932\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 498.78978724084203\n",
      "  time_since_restore: 22123.30169224739\n",
      "  time_this_iter_s: 23.753602743148804\n",
      "  time_total_s: 22123.30169224739\n",
      "  timestamp: 1553987921\n",
      "  timesteps_since_restore: 9320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9320000\n",
      "  training_iteration: 932\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22123 s, 932 iter, 9320000 ts, 998 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-19-04\n",
      "  done: false\n",
      "  episode_len_mean: 162.7\n",
      "  episode_reward_max: 1142.102614593664\n",
      "  episode_reward_mean: 995.3739699406351\n",
      "  episode_reward_min: -98.31163349190864\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 54381\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.56\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 9330000\n",
      "    num_steps_trained: 9330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5401422381401062\n",
      "      kl: 0.016849413514137268\n",
      "      policy_loss: -0.0016202429542317986\n",
      "      total_loss: 279.3479919433594\n",
      "      vf_explained_var: 0.9879410862922668\n",
      "      vf_loss: 279.3467102050781\n",
      "    sample_time_ms: 19868.371\n",
      "    update_time_ms: 5.877\n",
      "  iterations_since_restore: 933\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 497.68698497031767\n",
      "  time_since_restore: 22146.734001398087\n",
      "  time_this_iter_s: 23.4323091506958\n",
      "  time_total_s: 22146.734001398087\n",
      "  timestamp: 1553987944\n",
      "  timesteps_since_restore: 9330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9330000\n",
      "  training_iteration: 933\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22146 s, 933 iter, 9330000 ts, 995 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-19-28\n",
      "  done: false\n",
      "  episode_len_mean: 167.36\n",
      "  episode_reward_max: 1139.5101947868354\n",
      "  episode_reward_mean: 948.7595198599228\n",
      "  episode_reward_min: -92.87831066334252\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 54440\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.366\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 9340000\n",
      "    num_steps_trained: 9340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9114465117454529\n",
      "      kl: 0.015636371448636055\n",
      "      policy_loss: -0.002124089514836669\n",
      "      total_loss: 1058.0537109375\n",
      "      vf_explained_var: 0.957692563533783\n",
      "      vf_loss: 1058.05322265625\n",
      "    sample_time_ms: 19788.074\n",
      "    update_time_ms: 5.778\n",
      "  iterations_since_restore: 934\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 474.37975992996144\n",
      "  time_since_restore: 22170.004385709763\n",
      "  time_this_iter_s: 23.270384311676025\n",
      "  time_total_s: 22170.004385709763\n",
      "  timestamp: 1553987968\n",
      "  timesteps_since_restore: 9340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9340000\n",
      "  training_iteration: 934\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22170 s, 934 iter, 9340000 ts, 949 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-19-51\n",
      "  done: false\n",
      "  episode_len_mean: 166.95\n",
      "  episode_reward_max: 1139.9107008312587\n",
      "  episode_reward_mean: 983.3241920543705\n",
      "  episode_reward_min: -35.68619411807009\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 54498\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.091\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 9350000\n",
      "    num_steps_trained: 9350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.733148455619812\n",
      "      kl: 0.018214449286460876\n",
      "      policy_loss: -0.001590574043802917\n",
      "      total_loss: 348.7069396972656\n",
      "      vf_explained_var: 0.986057698726654\n",
      "      vf_loss: 348.70538330078125\n",
      "    sample_time_ms: 19746.151\n",
      "    update_time_ms: 5.683\n",
      "  iterations_since_restore: 935\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.66209602718527\n",
      "  time_since_restore: 22193.235787391663\n",
      "  time_this_iter_s: 23.231401681900024\n",
      "  time_total_s: 22193.235787391663\n",
      "  timestamp: 1553987991\n",
      "  timesteps_since_restore: 9350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9350000\n",
      "  training_iteration: 935\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22193 s, 935 iter, 9350000 ts, 983 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-20-15\n",
      "  done: false\n",
      "  episode_len_mean: 170.44\n",
      "  episode_reward_max: 1149.078652963761\n",
      "  episode_reward_mean: 974.585881090382\n",
      "  episode_reward_min: -40.27830258544358\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 54558\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.975\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 9360000\n",
      "    num_steps_trained: 9360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8248089551925659\n",
      "      kl: 0.020819611847400665\n",
      "      policy_loss: -0.0036285847891122103\n",
      "      total_loss: 717.790771484375\n",
      "      vf_explained_var: 0.9726938009262085\n",
      "      vf_loss: 717.7908935546875\n",
      "    sample_time_ms: 19715.31\n",
      "    update_time_ms: 5.703\n",
      "  iterations_since_restore: 936\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.2929405451911\n",
      "  time_since_restore: 22216.848904132843\n",
      "  time_this_iter_s: 23.61311674118042\n",
      "  time_total_s: 22216.848904132843\n",
      "  timestamp: 1553988015\n",
      "  timesteps_since_restore: 9360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9360000\n",
      "  training_iteration: 936\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22216 s, 936 iter, 9360000 ts, 975 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-20-38\n",
      "  done: false\n",
      "  episode_len_mean: 167.2\n",
      "  episode_reward_max: 1120.5495202722996\n",
      "  episode_reward_mean: 991.1938873072667\n",
      "  episode_reward_min: -1.8059786974821748\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 54621\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3921.07\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 9370000\n",
      "    num_steps_trained: 9370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.33866119384765625\n",
      "      kl: 0.022834040224552155\n",
      "      policy_loss: -0.000870398769620806\n",
      "      total_loss: 763.0096435546875\n",
      "      vf_explained_var: 0.9681918621063232\n",
      "      vf_loss: 763.0065307617188\n",
      "    sample_time_ms: 19642.792\n",
      "    update_time_ms: 5.335\n",
      "  iterations_since_restore: 937\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.5969436536335\n",
      "  time_since_restore: 22240.468113660812\n",
      "  time_this_iter_s: 23.61920952796936\n",
      "  time_total_s: 22240.468113660812\n",
      "  timestamp: 1553988038\n",
      "  timesteps_since_restore: 9370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9370000\n",
      "  training_iteration: 937\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22240 s, 937 iter, 9370000 ts, 991 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 159.31\n",
      "  episode_reward_max: 1113.3443810834237\n",
      "  episode_reward_mean: 971.1351632148097\n",
      "  episode_reward_min: -78.86003269563831\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 54684\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.18\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 9380000\n",
      "    num_steps_trained: 9380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.32179349660873413\n",
      "      kl: 0.016299473121762276\n",
      "      policy_loss: -0.0005200843443162739\n",
      "      total_loss: 403.4178161621094\n",
      "      vf_explained_var: 0.9834485054016113\n",
      "      vf_loss: 403.4154968261719\n",
      "    sample_time_ms: 19613.257\n",
      "    update_time_ms: 5.338\n",
      "  iterations_since_restore: 938\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.5675816074049\n",
      "  time_since_restore: 22263.980914592743\n",
      "  time_this_iter_s: 23.512800931930542\n",
      "  time_total_s: 22263.980914592743\n",
      "  timestamp: 1553988062\n",
      "  timesteps_since_restore: 9380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9380000\n",
      "  training_iteration: 938\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22263 s, 938 iter, 9380000 ts, 971 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-21-26\n",
      "  done: false\n",
      "  episode_len_mean: 161.56\n",
      "  episode_reward_max: 1128.6530617461337\n",
      "  episode_reward_mean: 1016.7424132536102\n",
      "  episode_reward_min: -78.86003269563831\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 54745\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3914.111\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 9390000\n",
      "    num_steps_trained: 9390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.23511788249015808\n",
      "      kl: 0.026998348534107208\n",
      "      policy_loss: -0.0012570337858051062\n",
      "      total_loss: 90.10365295410156\n",
      "      vf_explained_var: 0.9963383078575134\n",
      "      vf_loss: 90.10028076171875\n",
      "    sample_time_ms: 19636.274\n",
      "    update_time_ms: 5.174\n",
      "  iterations_since_restore: 939\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 508.3712066268051\n",
      "  time_since_restore: 22287.714775800705\n",
      "  time_this_iter_s: 23.733861207962036\n",
      "  time_total_s: 22287.714775800705\n",
      "  timestamp: 1553988086\n",
      "  timesteps_since_restore: 9390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9390000\n",
      "  training_iteration: 939\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22287 s, 939 iter, 9390000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-21-49\n",
      "  done: false\n",
      "  episode_len_mean: 164.76\n",
      "  episode_reward_max: 1131.1183199820234\n",
      "  episode_reward_mean: 1022.0963458610277\n",
      "  episode_reward_min: 66.69240057773953\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 54804\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3910.005\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 9400000\n",
      "    num_steps_trained: 9400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6034297347068787\n",
      "      kl: 0.014908220618963242\n",
      "      policy_loss: -0.002702031284570694\n",
      "      total_loss: 401.90826416015625\n",
      "      vf_explained_var: 0.9827553033828735\n",
      "      vf_loss: 401.9084167480469\n",
      "    sample_time_ms: 19574.723\n",
      "    update_time_ms: 5.208\n",
      "  iterations_since_restore: 940\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 511.04817293051383\n",
      "  time_since_restore: 22311.099841594696\n",
      "  time_this_iter_s: 23.38506579399109\n",
      "  time_total_s: 22311.099841594696\n",
      "  timestamp: 1553988109\n",
      "  timesteps_since_restore: 9400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9400000\n",
      "  training_iteration: 940\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22311 s, 940 iter, 9400000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-22-12\n",
      "  done: false\n",
      "  episode_len_mean: 173.05\n",
      "  episode_reward_max: 1138.8299512894298\n",
      "  episode_reward_mean: 1003.6509680719182\n",
      "  episode_reward_min: -35.82005815243048\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 54861\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3911.247\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 9410000\n",
      "    num_steps_trained: 9410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6683480143547058\n",
      "      kl: 0.016087356954813004\n",
      "      policy_loss: -0.0028677748050540686\n",
      "      total_loss: 296.974853515625\n",
      "      vf_explained_var: 0.9872984290122986\n",
      "      vf_loss: 296.9749755859375\n",
      "    sample_time_ms: 19538.579\n",
      "    update_time_ms: 5.299\n",
      "  iterations_since_restore: 941\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 501.8254840359591\n",
      "  time_since_restore: 22334.296060323715\n",
      "  time_this_iter_s: 23.196218729019165\n",
      "  time_total_s: 22334.296060323715\n",
      "  timestamp: 1553988132\n",
      "  timesteps_since_restore: 9410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9410000\n",
      "  training_iteration: 941\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22334 s, 941 iter, 9410000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-22-36\n",
      "  done: false\n",
      "  episode_len_mean: 176.6\n",
      "  episode_reward_max: 1138.8299512894298\n",
      "  episode_reward_mean: 982.4007982363298\n",
      "  episode_reward_min: -44.42405442416867\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 54919\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.461\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 9420000\n",
      "    num_steps_trained: 9420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8912063837051392\n",
      "      kl: 0.016322355717420578\n",
      "      policy_loss: -0.00410128990188241\n",
      "      total_loss: 561.294189453125\n",
      "      vf_explained_var: 0.978403627872467\n",
      "      vf_loss: 561.29541015625\n",
      "    sample_time_ms: 19505.872\n",
      "    update_time_ms: 5.186\n",
      "  iterations_since_restore: 942\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.200399118165\n",
      "  time_since_restore: 22357.56275987625\n",
      "  time_this_iter_s: 23.26669955253601\n",
      "  time_total_s: 22357.56275987625\n",
      "  timestamp: 1553988156\n",
      "  timesteps_since_restore: 9420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9420000\n",
      "  training_iteration: 942\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22357 s, 942 iter, 9420000 ts, 982 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-22-59\n",
      "  done: false\n",
      "  episode_len_mean: 171.08\n",
      "  episode_reward_max: 1124.9653071596192\n",
      "  episode_reward_mean: 973.8719637281263\n",
      "  episode_reward_min: -72.15352185069197\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 54977\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.13\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 9430000\n",
      "    num_steps_trained: 9430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6492501497268677\n",
      "      kl: 0.014391467906534672\n",
      "      policy_loss: -0.0033423067070543766\n",
      "      total_loss: 568.4745483398438\n",
      "      vf_explained_var: 0.9752729535102844\n",
      "      vf_loss: 568.4754638671875\n",
      "    sample_time_ms: 19512.931\n",
      "    update_time_ms: 6.214\n",
      "  iterations_since_restore: 943\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.93598186406314\n",
      "  time_since_restore: 22380.98438024521\n",
      "  time_this_iter_s: 23.42162036895752\n",
      "  time_total_s: 22380.98438024521\n",
      "  timestamp: 1553988179\n",
      "  timesteps_since_restore: 9430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9430000\n",
      "  training_iteration: 943\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22380 s, 943 iter, 9430000 ts, 974 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-23-23\n",
      "  done: false\n",
      "  episode_len_mean: 171.34\n",
      "  episode_reward_max: 1164.927880512267\n",
      "  episode_reward_mean: 975.6083239162144\n",
      "  episode_reward_min: -72.15352185069197\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 55034\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3882.004\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 9440000\n",
      "    num_steps_trained: 9440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0393747091293335\n",
      "      kl: 0.014926641248166561\n",
      "      policy_loss: -0.001845578313805163\n",
      "      total_loss: 970.1926879882812\n",
      "      vf_explained_var: 0.9601350426673889\n",
      "      vf_loss: 970.1920776367188\n",
      "    sample_time_ms: 19528.454\n",
      "    update_time_ms: 6.1\n",
      "  iterations_since_restore: 944\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.8041619581074\n",
      "  time_since_restore: 22404.368604898453\n",
      "  time_this_iter_s: 23.38422465324402\n",
      "  time_total_s: 22404.368604898453\n",
      "  timestamp: 1553988203\n",
      "  timesteps_since_restore: 9440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9440000\n",
      "  training_iteration: 944\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22404 s, 944 iter, 9440000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-23-46\n",
      "  done: false\n",
      "  episode_len_mean: 168.59\n",
      "  episode_reward_max: 1164.927880512267\n",
      "  episode_reward_mean: 969.8488612444428\n",
      "  episode_reward_min: -52.7960100414644\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 55096\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.783\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 9450000\n",
      "    num_steps_trained: 9450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3814240097999573\n",
      "      kl: 0.019384542480111122\n",
      "      policy_loss: -0.0009043877944350243\n",
      "      total_loss: 382.0716247558594\n",
      "      vf_explained_var: 0.9841066002845764\n",
      "      vf_loss: 382.0692138671875\n",
      "    sample_time_ms: 19546.136\n",
      "    update_time_ms: 6.066\n",
      "  iterations_since_restore: 945\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.9244306222214\n",
      "  time_since_restore: 22427.82614183426\n",
      "  time_this_iter_s: 23.457536935806274\n",
      "  time_total_s: 22427.82614183426\n",
      "  timestamp: 1553988226\n",
      "  timesteps_since_restore: 9450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9450000\n",
      "  training_iteration: 945\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22427 s, 945 iter, 9450000 ts, 970 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-24-10\n",
      "  done: false\n",
      "  episode_len_mean: 162.5\n",
      "  episode_reward_max: 1157.2933390994922\n",
      "  episode_reward_mean: 982.1992276624135\n",
      "  episode_reward_min: -52.7960100414644\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 55157\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3906.335\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 9460000\n",
      "    num_steps_trained: 9460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.45133912563323975\n",
      "      kl: 0.015032238326966763\n",
      "      policy_loss: -0.0032471157610416412\n",
      "      total_loss: 734.7161254882812\n",
      "      vf_explained_var: 0.9677501320838928\n",
      "      vf_loss: 734.716796875\n",
      "    sample_time_ms: 19513.562\n",
      "    update_time_ms: 6.256\n",
      "  iterations_since_restore: 946\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.0996138312067\n",
      "  time_since_restore: 22451.30760216713\n",
      "  time_this_iter_s: 23.481460332870483\n",
      "  time_total_s: 22451.30760216713\n",
      "  timestamp: 1553988250\n",
      "  timesteps_since_restore: 9460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9460000\n",
      "  training_iteration: 946\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22451 s, 946 iter, 9460000 ts, 982 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-24-33\n",
      "  done: false\n",
      "  episode_len_mean: 167.42\n",
      "  episode_reward_max: 1157.2933390994922\n",
      "  episode_reward_mean: 989.4038088887422\n",
      "  episode_reward_min: 33.57873366672089\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 55215\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3884.023\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 9470000\n",
      "    num_steps_trained: 9470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5504652857780457\n",
      "      kl: 0.01671561785042286\n",
      "      policy_loss: -0.002427763771265745\n",
      "      total_loss: 361.7257080078125\n",
      "      vf_explained_var: 0.9846552610397339\n",
      "      vf_loss: 361.7252502441406\n",
      "    sample_time_ms: 19549.206\n",
      "    update_time_ms: 6.273\n",
      "  iterations_since_restore: 947\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 494.70190444437105\n",
      "  time_since_restore: 22475.06152868271\n",
      "  time_this_iter_s: 23.753926515579224\n",
      "  time_total_s: 22475.06152868271\n",
      "  timestamp: 1553988273\n",
      "  timesteps_since_restore: 9470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9470000\n",
      "  training_iteration: 947\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22475 s, 947 iter, 9470000 ts, 989 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-24-57\n",
      "  done: false\n",
      "  episode_len_mean: 167.79\n",
      "  episode_reward_max: 1147.9099595114767\n",
      "  episode_reward_mean: 1014.1531138824962\n",
      "  episode_reward_min: 53.72941130254256\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 55275\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.907\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 9480000\n",
      "    num_steps_trained: 9480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.1717681735754013\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3672267198562622\n",
      "      kl: 0.044822294265031815\n",
      "      policy_loss: 0.002805251395329833\n",
      "      total_loss: 66.05537414550781\n",
      "      vf_explained_var: 0.9971577525138855\n",
      "      vf_loss: 66.04486846923828\n",
      "    sample_time_ms: 19525.514\n",
      "    update_time_ms: 6.241\n",
      "  iterations_since_restore: 948\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 507.0765569412481\n",
      "  time_since_restore: 22498.318603992462\n",
      "  time_this_iter_s: 23.257075309753418\n",
      "  time_total_s: 22498.318603992462\n",
      "  timestamp: 1553988297\n",
      "  timesteps_since_restore: 9480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9480000\n",
      "  training_iteration: 948\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22498 s, 948 iter, 9480000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-25-21\n",
      "  done: false\n",
      "  episode_len_mean: 168.07\n",
      "  episode_reward_max: 1130.9872545147684\n",
      "  episode_reward_mean: 1005.9779648148228\n",
      "  episode_reward_min: -93.1305580637679\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 55334\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.331\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 9490000\n",
      "    num_steps_trained: 9490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5665819048881531\n",
      "      kl: 0.012204269878566265\n",
      "      policy_loss: -0.0017598753329366446\n",
      "      total_loss: 226.41812133789062\n",
      "      vf_explained_var: 0.9901042580604553\n",
      "      vf_loss: 226.41676330566406\n",
      "    sample_time_ms: 19531.467\n",
      "    update_time_ms: 6.31\n",
      "  iterations_since_restore: 949\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 502.9889824074114\n",
      "  time_since_restore: 22522.103603363037\n",
      "  time_this_iter_s: 23.78499937057495\n",
      "  time_total_s: 22522.103603363037\n",
      "  timestamp: 1553988321\n",
      "  timesteps_since_restore: 9490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9490000\n",
      "  training_iteration: 949\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22522 s, 949 iter, 9490000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-25-44\n",
      "  done: false\n",
      "  episode_len_mean: 168.9\n",
      "  episode_reward_max: 1137.2915747342543\n",
      "  episode_reward_mean: 957.7344018583436\n",
      "  episode_reward_min: -93.1305580637679\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 55392\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.23\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 9500000\n",
      "    num_steps_trained: 9500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8971129059791565\n",
      "      kl: 0.014212993904948235\n",
      "      policy_loss: -0.0017289695097133517\n",
      "      total_loss: 859.811279296875\n",
      "      vf_explained_var: 0.9693360924720764\n",
      "      vf_loss: 859.8092651367188\n",
      "    sample_time_ms: 19581.607\n",
      "    update_time_ms: 6.449\n",
      "  iterations_since_restore: 950\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 478.867200929172\n",
      "  time_since_restore: 22545.989812135696\n",
      "  time_this_iter_s: 23.8862087726593\n",
      "  time_total_s: 22545.989812135696\n",
      "  timestamp: 1553988344\n",
      "  timesteps_since_restore: 9500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9500000\n",
      "  training_iteration: 950\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22545 s, 950 iter, 9500000 ts, 958 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-26-08\n",
      "  done: false\n",
      "  episode_len_mean: 174.6\n",
      "  episode_reward_max: 1137.2915747342543\n",
      "  episode_reward_mean: 975.3189634418918\n",
      "  episode_reward_min: -53.79564276402519\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 55450\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.455\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 9510000\n",
      "    num_steps_trained: 9510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8613001704216003\n",
      "      kl: 0.010599343106150627\n",
      "      policy_loss: -0.004106690641492605\n",
      "      total_loss: 466.4609375\n",
      "      vf_explained_var: 0.9823901057243347\n",
      "      vf_loss: 466.46234130859375\n",
      "    sample_time_ms: 19645.767\n",
      "    update_time_ms: 6.298\n",
      "  iterations_since_restore: 951\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.6594817209459\n",
      "  time_since_restore: 22569.982505083084\n",
      "  time_this_iter_s: 23.992692947387695\n",
      "  time_total_s: 22569.982505083084\n",
      "  timestamp: 1553988368\n",
      "  timesteps_since_restore: 9510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9510000\n",
      "  training_iteration: 951\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22569 s, 951 iter, 9510000 ts, 975 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-26-32\n",
      "  done: false\n",
      "  episode_len_mean: 169.76\n",
      "  episode_reward_max: 1134.003825338268\n",
      "  episode_reward_mean: 976.2698369552776\n",
      "  episode_reward_min: -43.50201579164323\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 55510\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.804\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 9520000\n",
      "    num_steps_trained: 9520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.690679132938385\n",
      "      kl: 0.014462902210652828\n",
      "      policy_loss: -0.00170620228163898\n",
      "      total_loss: 624.1047973632812\n",
      "      vf_explained_var: 0.9748768210411072\n",
      "      vf_loss: 624.102783203125\n",
      "    sample_time_ms: 19672.31\n",
      "    update_time_ms: 6.395\n",
      "  iterations_since_restore: 952\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.13491847763885\n",
      "  time_since_restore: 22593.499680280685\n",
      "  time_this_iter_s: 23.51717519760132\n",
      "  time_total_s: 22593.499680280685\n",
      "  timestamp: 1553988392\n",
      "  timesteps_since_restore: 9520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9520000\n",
      "  training_iteration: 952\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22593 s, 952 iter, 9520000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-26-56\n",
      "  done: false\n",
      "  episode_len_mean: 170.73\n",
      "  episode_reward_max: 1135.8426523363605\n",
      "  episode_reward_mean: 960.3063761666275\n",
      "  episode_reward_min: -68.84853323088959\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 55567\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.646\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 9530000\n",
      "    num_steps_trained: 9530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9890326261520386\n",
      "      kl: 0.010603608563542366\n",
      "      policy_loss: -0.0009226699476130307\n",
      "      total_loss: 623.7938232421875\n",
      "      vf_explained_var: 0.9765744209289551\n",
      "      vf_loss: 623.7920532226562\n",
      "    sample_time_ms: 19759.65\n",
      "    update_time_ms: 5.545\n",
      "  iterations_since_restore: 953\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.15318808331375\n",
      "  time_since_restore: 22617.81303334236\n",
      "  time_this_iter_s: 24.313353061676025\n",
      "  time_total_s: 22617.81303334236\n",
      "  timestamp: 1553988416\n",
      "  timesteps_since_restore: 9530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9530000\n",
      "  training_iteration: 953\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22617 s, 953 iter, 9530000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-27-20\n",
      "  done: false\n",
      "  episode_len_mean: 176.96\n",
      "  episode_reward_max: 1145.8308590138931\n",
      "  episode_reward_mean: 950.8802726906953\n",
      "  episode_reward_min: -68.84853323088959\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 55624\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.154\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 9540000\n",
      "    num_steps_trained: 9540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.086573839187622\n",
      "      kl: 0.013056617230176926\n",
      "      policy_loss: -0.0010272457730025053\n",
      "      total_loss: 687.6629638671875\n",
      "      vf_explained_var: 0.9710803031921387\n",
      "      vf_loss: 687.66064453125\n",
      "    sample_time_ms: 19758.332\n",
      "    update_time_ms: 5.534\n",
      "  iterations_since_restore: 954\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 475.4401363453477\n",
      "  time_since_restore: 22641.16747021675\n",
      "  time_this_iter_s: 23.35443687438965\n",
      "  time_total_s: 22641.16747021675\n",
      "  timestamp: 1553988440\n",
      "  timesteps_since_restore: 9540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9540000\n",
      "  training_iteration: 954\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22641 s, 954 iter, 9540000 ts, 951 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-27-44\n",
      "  done: false\n",
      "  episode_len_mean: 169.89\n",
      "  episode_reward_max: 1136.8626169843503\n",
      "  episode_reward_mean: 960.6204807516364\n",
      "  episode_reward_min: -61.697562918800315\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 55684\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.424\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 9550000\n",
      "    num_steps_trained: 9550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.42719724774360657\n",
      "      kl: 0.010080216452479362\n",
      "      policy_loss: -0.0013868537498638034\n",
      "      total_loss: 409.0968933105469\n",
      "      vf_explained_var: 0.9812244772911072\n",
      "      vf_loss: 409.095703125\n",
      "    sample_time_ms: 19818.045\n",
      "    update_time_ms: 5.641\n",
      "  iterations_since_restore: 955\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.3102403758182\n",
      "  time_since_restore: 22665.19295024872\n",
      "  time_this_iter_s: 24.025480031967163\n",
      "  time_total_s: 22665.19295024872\n",
      "  timestamp: 1553988464\n",
      "  timesteps_since_restore: 9550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9550000\n",
      "  training_iteration: 955\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22665 s, 955 iter, 9550000 ts, 961 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-28-08\n",
      "  done: false\n",
      "  episode_len_mean: 164.81\n",
      "  episode_reward_max: 1145.0266474321406\n",
      "  episode_reward_mean: 986.8188413671951\n",
      "  episode_reward_min: -94.56986757121915\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 55746\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.229\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 9560000\n",
      "    num_steps_trained: 9560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4496508836746216\n",
      "      kl: 0.016236813738942146\n",
      "      policy_loss: -0.0012744814157485962\n",
      "      total_loss: 515.044677734375\n",
      "      vf_explained_var: 0.9809391498565674\n",
      "      vf_loss: 515.041748046875\n",
      "    sample_time_ms: 19845.578\n",
      "    update_time_ms: 5.496\n",
      "  iterations_since_restore: 956\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.40942068359755\n",
      "  time_since_restore: 22688.89580988884\n",
      "  time_this_iter_s: 23.70285964012146\n",
      "  time_total_s: 22688.89580988884\n",
      "  timestamp: 1553988488\n",
      "  timesteps_since_restore: 9560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9560000\n",
      "  training_iteration: 956\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22688 s, 956 iter, 9560000 ts, 987 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-28-31\n",
      "  done: false\n",
      "  episode_len_mean: 165.37\n",
      "  episode_reward_max: 1145.0266474321406\n",
      "  episode_reward_mean: 977.3653517063153\n",
      "  episode_reward_min: -89.19605328587598\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 55807\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.955\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 9570000\n",
      "    num_steps_trained: 9570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7102014422416687\n",
      "      kl: 0.013209037482738495\n",
      "      policy_loss: -0.0013995659537613392\n",
      "      total_loss: 752.287353515625\n",
      "      vf_explained_var: 0.9720107913017273\n",
      "      vf_loss: 752.2853393554688\n",
      "    sample_time_ms: 19830.602\n",
      "    update_time_ms: 5.496\n",
      "  iterations_since_restore: 957\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.68267585315755\n",
      "  time_since_restore: 22712.487256765366\n",
      "  time_this_iter_s: 23.59144687652588\n",
      "  time_total_s: 22712.487256765366\n",
      "  timestamp: 1553988511\n",
      "  timesteps_since_restore: 9570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9570000\n",
      "  training_iteration: 957\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22712 s, 957 iter, 9570000 ts, 977 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-28-55\n",
      "  done: false\n",
      "  episode_len_mean: 166.47\n",
      "  episode_reward_max: 1120.2553047353285\n",
      "  episode_reward_mean: 985.1517975619712\n",
      "  episode_reward_min: -89.19605328587598\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 55863\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.917\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 9580000\n",
      "    num_steps_trained: 9580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8758155703544617\n",
      "      kl: 0.012451966293156147\n",
      "      policy_loss: -0.0007384194759652019\n",
      "      total_loss: 156.17628479003906\n",
      "      vf_explained_var: 0.9937977194786072\n",
      "      vf_loss: 156.17379760742188\n",
      "    sample_time_ms: 19903.149\n",
      "    update_time_ms: 5.535\n",
      "  iterations_since_restore: 958\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.5758987809856\n",
      "  time_since_restore: 22736.490471839905\n",
      "  time_this_iter_s: 24.003215074539185\n",
      "  time_total_s: 22736.490471839905\n",
      "  timestamp: 1553988535\n",
      "  timesteps_since_restore: 9580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9580000\n",
      "  training_iteration: 958\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22736 s, 958 iter, 9580000 ts, 985 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-29-19\n",
      "  done: false\n",
      "  episode_len_mean: 177.78\n",
      "  episode_reward_max: 1155.540163272442\n",
      "  episode_reward_mean: 993.3302424236655\n",
      "  episode_reward_min: -16.52078643356856\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 55920\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3886.468\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 9590000\n",
      "    num_steps_trained: 9590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9018902778625488\n",
      "      kl: 0.01161162368953228\n",
      "      policy_loss: -0.002813289873301983\n",
      "      total_loss: 538.6787719726562\n",
      "      vf_explained_var: 0.9791792035102844\n",
      "      vf_loss: 538.6786499023438\n",
      "    sample_time_ms: 19913.75\n",
      "    update_time_ms: 5.544\n",
      "  iterations_since_restore: 959\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.66512121183274\n",
      "  time_since_restore: 22760.357879161835\n",
      "  time_this_iter_s: 23.86740732192993\n",
      "  time_total_s: 22760.357879161835\n",
      "  timestamp: 1553988559\n",
      "  timesteps_since_restore: 9590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9590000\n",
      "  training_iteration: 959\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22760 s, 959 iter, 9590000 ts, 993 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-29-42\n",
      "  done: false\n",
      "  episode_len_mean: 173.36\n",
      "  episode_reward_max: 1173.1571766135594\n",
      "  episode_reward_mean: 1006.3620271535533\n",
      "  episode_reward_min: -16.52078643356856\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 55978\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.803\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 9600000\n",
      "    num_steps_trained: 9600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6160748600959778\n",
      "      kl: 0.0141171645373106\n",
      "      policy_loss: -0.002426876686513424\n",
      "      total_loss: 128.8188018798828\n",
      "      vf_explained_var: 0.9941855072975159\n",
      "      vf_loss: 128.81759643554688\n",
      "    sample_time_ms: 19831.414\n",
      "    update_time_ms: 5.46\n",
      "  iterations_since_restore: 960\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 503.1810135767766\n",
      "  time_since_restore: 22783.44413948059\n",
      "  time_this_iter_s: 23.086260318756104\n",
      "  time_total_s: 22783.44413948059\n",
      "  timestamp: 1553988582\n",
      "  timesteps_since_restore: 9600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9600000\n",
      "  training_iteration: 960\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22783 s, 960 iter, 9600000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-30-06\n",
      "  done: false\n",
      "  episode_len_mean: 173.51\n",
      "  episode_reward_max: 1173.1571766135594\n",
      "  episode_reward_mean: 1009.3658354562446\n",
      "  episode_reward_min: 4.749968960907722\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 56036\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.532\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 9610000\n",
      "    num_steps_trained: 9610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.25765225291252136\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.729325532913208\n",
      "      kl: 0.008930407464504242\n",
      "      policy_loss: -0.0019135135225951672\n",
      "      total_loss: 406.0828857421875\n",
      "      vf_explained_var: 0.9827449321746826\n",
      "      vf_loss: 406.08251953125\n",
      "    sample_time_ms: 19814.454\n",
      "    update_time_ms: 5.348\n",
      "  iterations_since_restore: 961\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.6829177281223\n",
      "  time_since_restore: 22807.15203976631\n",
      "  time_this_iter_s: 23.707900285720825\n",
      "  time_total_s: 22807.15203976631\n",
      "  timestamp: 1553988606\n",
      "  timesteps_since_restore: 9610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9610000\n",
      "  training_iteration: 961\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22807 s, 961 iter, 9610000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-30-30\n",
      "  done: false\n",
      "  episode_len_mean: 177.83\n",
      "  episode_reward_max: 1119.4311049332168\n",
      "  episode_reward_mean: 990.1525103200154\n",
      "  episode_reward_min: 4.749968960907722\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 56088\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.273\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 9620000\n",
      "    num_steps_trained: 9620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2969043254852295\n",
      "      kl: 0.016841033473610878\n",
      "      policy_loss: -0.00040975978481583297\n",
      "      total_loss: 275.73406982421875\n",
      "      vf_explained_var: 0.9893496632575989\n",
      "      vf_loss: 275.7323303222656\n",
      "    sample_time_ms: 19815.133\n",
      "    update_time_ms: 5.251\n",
      "  iterations_since_restore: 962\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 495.07625516000763\n",
      "  time_since_restore: 22830.728816747665\n",
      "  time_this_iter_s: 23.57677698135376\n",
      "  time_total_s: 22830.728816747665\n",
      "  timestamp: 1553988630\n",
      "  timesteps_since_restore: 9620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9620000\n",
      "  training_iteration: 962\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22830 s, 962 iter, 9620000 ts, 990 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-30-53\n",
      "  done: false\n",
      "  episode_len_mean: 180.5\n",
      "  episode_reward_max: 1137.5590349907895\n",
      "  episode_reward_mean: 965.8382566256365\n",
      "  episode_reward_min: -95.43477767036632\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 56145\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.456\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 9630000\n",
      "    num_steps_trained: 9630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1464630365371704\n",
      "      kl: 0.02116253413259983\n",
      "      policy_loss: -0.0031289749313145876\n",
      "      total_loss: 430.230712890625\n",
      "      vf_explained_var: 0.9841353297233582\n",
      "      vf_loss: 430.2311096191406\n",
      "    sample_time_ms: 19729.265\n",
      "    update_time_ms: 5.204\n",
      "  iterations_since_restore: 963\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.9191283128184\n",
      "  time_since_restore: 22854.154574632645\n",
      "  time_this_iter_s: 23.425757884979248\n",
      "  time_total_s: 22854.154574632645\n",
      "  timestamp: 1553988653\n",
      "  timesteps_since_restore: 9630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9630000\n",
      "  training_iteration: 963\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22854 s, 963 iter, 9630000 ts, 966 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-31-17\n",
      "  done: false\n",
      "  episode_len_mean: 167.48\n",
      "  episode_reward_max: 1115.4709078335786\n",
      "  episode_reward_mean: 986.0329379153268\n",
      "  episode_reward_min: -95.43477767036632\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 56205\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.937\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 9640000\n",
      "    num_steps_trained: 9640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5070189237594604\n",
      "      kl: 0.02428179793059826\n",
      "      policy_loss: -0.0016869973624125123\n",
      "      total_loss: 143.6869659423828\n",
      "      vf_explained_var: 0.9942634701728821\n",
      "      vf_loss: 143.68551635742188\n",
      "    sample_time_ms: 19736.569\n",
      "    update_time_ms: 5.337\n",
      "  iterations_since_restore: 964\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.01646895766345\n",
      "  time_since_restore: 22877.557725429535\n",
      "  time_this_iter_s: 23.40315079689026\n",
      "  time_total_s: 22877.557725429535\n",
      "  timestamp: 1553988677\n",
      "  timesteps_since_restore: 9640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9640000\n",
      "  training_iteration: 964\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22877 s, 964 iter, 9640000 ts, 986 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-31-40\n",
      "  done: false\n",
      "  episode_len_mean: 174.76\n",
      "  episode_reward_max: 1134.7930996187945\n",
      "  episode_reward_mean: 1001.1208835695812\n",
      "  episode_reward_min: 141.4943752984035\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 56260\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.054\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 9650000\n",
      "    num_steps_trained: 9650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.890950620174408\n",
      "      kl: 0.01704310066998005\n",
      "      policy_loss: -0.0013198822271078825\n",
      "      total_loss: 294.7033386230469\n",
      "      vf_explained_var: 0.9884402751922607\n",
      "      vf_loss: 294.7024841308594\n",
      "    sample_time_ms: 19692.743\n",
      "    update_time_ms: 5.298\n",
      "  iterations_since_restore: 965\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 500.56044178479067\n",
      "  time_since_restore: 22901.307705402374\n",
      "  time_this_iter_s: 23.749979972839355\n",
      "  time_total_s: 22901.307705402374\n",
      "  timestamp: 1553988700\n",
      "  timesteps_since_restore: 9650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9650000\n",
      "  training_iteration: 965\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22901 s, 965 iter, 9650000 ts, 1e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-32-03\n",
      "  done: false\n",
      "  episode_len_mean: 174.84\n",
      "  episode_reward_max: 1148.831957081278\n",
      "  episode_reward_mean: 1022.7135012226298\n",
      "  episode_reward_min: -9.949666990668078\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 56319\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.302\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 9660000\n",
      "    num_steps_trained: 9660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7056863903999329\n",
      "      kl: 0.01376375462859869\n",
      "      policy_loss: 0.001594925532117486\n",
      "      total_loss: 516.9019165039062\n",
      "      vf_explained_var: 0.977103590965271\n",
      "      vf_loss: 516.8985595703125\n",
      "    sample_time_ms: 19575.091\n",
      "    update_time_ms: 5.653\n",
      "  iterations_since_restore: 966\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 511.3567506113149\n",
      "  time_since_restore: 22923.710970640182\n",
      "  time_this_iter_s: 22.403265237808228\n",
      "  time_total_s: 22923.710970640182\n",
      "  timestamp: 1553988723\n",
      "  timesteps_since_restore: 9660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9660000\n",
      "  training_iteration: 966\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22923 s, 966 iter, 9660000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-32-27\n",
      "  done: false\n",
      "  episode_len_mean: 171.13\n",
      "  episode_reward_max: 1121.435920350336\n",
      "  episode_reward_mean: 998.0895236377593\n",
      "  episode_reward_min: -24.224144413995248\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 56378\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.399\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 9670000\n",
      "    num_steps_trained: 9670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7816326022148132\n",
      "      kl: 0.01607745699584484\n",
      "      policy_loss: -0.003761401167139411\n",
      "      total_loss: 542.6019897460938\n",
      "      vf_explained_var: 0.9783900380134583\n",
      "      vf_loss: 542.6036376953125\n",
      "    sample_time_ms: 19584.131\n",
      "    update_time_ms: 6.338\n",
      "  iterations_since_restore: 967\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 499.0447618188796\n",
      "  time_since_restore: 22947.371353149414\n",
      "  time_this_iter_s: 23.660382509231567\n",
      "  time_total_s: 22947.371353149414\n",
      "  timestamp: 1553988747\n",
      "  timesteps_since_restore: 9670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9670000\n",
      "  training_iteration: 967\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22947 s, 967 iter, 9670000 ts, 998 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-32-50\n",
      "  done: false\n",
      "  episode_len_mean: 164.91\n",
      "  episode_reward_max: 1121.2063949099902\n",
      "  episode_reward_mean: 984.2798525269665\n",
      "  episode_reward_min: -62.17529070213999\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 56439\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.783\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 9680000\n",
      "    num_steps_trained: 9680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5445531606674194\n",
      "      kl: 0.018785754218697548\n",
      "      policy_loss: -0.000620033300947398\n",
      "      total_loss: 790.2498168945312\n",
      "      vf_explained_var: 0.9663702249526978\n",
      "      vf_loss: 790.2479858398438\n",
      "    sample_time_ms: 19493.831\n",
      "    update_time_ms: 6.435\n",
      "  iterations_since_restore: 968\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.13992626348306\n",
      "  time_since_restore: 22970.450911283493\n",
      "  time_this_iter_s: 23.07955813407898\n",
      "  time_total_s: 22970.450911283493\n",
      "  timestamp: 1553988770\n",
      "  timesteps_since_restore: 9680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9680000\n",
      "  training_iteration: 968\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22970 s, 968 iter, 9680000 ts, 984 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-33-13\n",
      "  done: false\n",
      "  episode_len_mean: 168.14\n",
      "  episode_reward_max: 1155.3711191826476\n",
      "  episode_reward_mean: 982.0761191899805\n",
      "  episode_reward_min: -44.514561282347444\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 56497\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.166\n",
      "    load_time_ms: 1.447\n",
      "    num_steps_sampled: 9690000\n",
      "    num_steps_trained: 9690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9279331564903259\n",
      "      kl: 0.01902049593627453\n",
      "      policy_loss: -0.0008591111400164664\n",
      "      total_loss: 690.8260498046875\n",
      "      vf_explained_var: 0.9741209745407104\n",
      "      vf_loss: 690.8244018554688\n",
      "    sample_time_ms: 19423.652\n",
      "    update_time_ms: 6.292\n",
      "  iterations_since_restore: 969\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.0380595949902\n",
      "  time_since_restore: 22993.601119041443\n",
      "  time_this_iter_s: 23.15020775794983\n",
      "  time_total_s: 22993.601119041443\n",
      "  timestamp: 1553988793\n",
      "  timesteps_since_restore: 9690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9690000\n",
      "  training_iteration: 969\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 22993 s, 969 iter, 9690000 ts, 982 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-33-37\n",
      "  done: false\n",
      "  episode_len_mean: 173.25\n",
      "  episode_reward_max: 1166.0791048753442\n",
      "  episode_reward_mean: 968.7077821275175\n",
      "  episode_reward_min: -72.30503114482006\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 56556\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.676\n",
      "    load_time_ms: 1.375\n",
      "    num_steps_sampled: 9700000\n",
      "    num_steps_trained: 9700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.801762044429779\n",
      "      kl: 0.015014934353530407\n",
      "      policy_loss: -0.002063499530777335\n",
      "      total_loss: 899.9403076171875\n",
      "      vf_explained_var: 0.9628738760948181\n",
      "      vf_loss: 899.9404296875\n",
      "    sample_time_ms: 19522.378\n",
      "    update_time_ms: 6.28\n",
      "  iterations_since_restore: 970\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 484.3538910637588\n",
      "  time_since_restore: 23017.710461854935\n",
      "  time_this_iter_s: 24.10934281349182\n",
      "  time_total_s: 23017.710461854935\n",
      "  timestamp: 1553988817\n",
      "  timesteps_since_restore: 9700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9700000\n",
      "  training_iteration: 970\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23017 s, 970 iter, 9700000 ts, 969 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-34-00\n",
      "  done: false\n",
      "  episode_len_mean: 169.54\n",
      "  episode_reward_max: 1120.508940399986\n",
      "  episode_reward_mean: 954.7241612475877\n",
      "  episode_reward_min: -72.30503114482006\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 56614\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.869\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 9710000\n",
      "    num_steps_trained: 9710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7437782287597656\n",
      "      kl: 0.019436558708548546\n",
      "      policy_loss: -0.0010573171311989427\n",
      "      total_loss: 329.6536560058594\n",
      "      vf_explained_var: 0.9873226881027222\n",
      "      vf_loss: 329.6521911621094\n",
      "    sample_time_ms: 19478.747\n",
      "    update_time_ms: 6.923\n",
      "  iterations_since_restore: 971\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.36208062379393\n",
      "  time_since_restore: 23040.98171234131\n",
      "  time_this_iter_s: 23.2712504863739\n",
      "  time_total_s: 23040.98171234131\n",
      "  timestamp: 1553988840\n",
      "  timesteps_since_restore: 9710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9710000\n",
      "  training_iteration: 971\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23040 s, 971 iter, 9710000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-34-25\n",
      "  done: false\n",
      "  episode_len_mean: 164.74\n",
      "  episode_reward_max: 1121.4271888265519\n",
      "  episode_reward_mean: 987.446195855072\n",
      "  episode_reward_min: -76.21772464294696\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 56675\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3875.243\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 9720000\n",
      "    num_steps_trained: 9720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6856886744499207\n",
      "      kl: 0.01683245226740837\n",
      "      policy_loss: -0.0007677727262489498\n",
      "      total_loss: 484.70501708984375\n",
      "      vf_explained_var: 0.9809669852256775\n",
      "      vf_loss: 484.70361328125\n",
      "    sample_time_ms: 19575.087\n",
      "    update_time_ms: 6.986\n",
      "  iterations_since_restore: 972\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.723097927536\n",
      "  time_since_restore: 23065.497949123383\n",
      "  time_this_iter_s: 24.516236782073975\n",
      "  time_total_s: 23065.497949123383\n",
      "  timestamp: 1553988865\n",
      "  timesteps_since_restore: 9720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9720000\n",
      "  training_iteration: 972\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23065 s, 972 iter, 9720000 ts, 987 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-34-49\n",
      "  done: false\n",
      "  episode_len_mean: 177.71\n",
      "  episode_reward_max: 1161.5810492301728\n",
      "  episode_reward_mean: 978.9030181418993\n",
      "  episode_reward_min: -76.21772464294696\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 56728\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3876.218\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 9730000\n",
      "    num_steps_trained: 9730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3881077766418457\n",
      "      kl: 0.020657867193222046\n",
      "      policy_loss: -0.0019966799300163984\n",
      "      total_loss: 482.4598388671875\n",
      "      vf_explained_var: 0.9802799820899963\n",
      "      vf_loss: 482.4591369628906\n",
      "    sample_time_ms: 19605.291\n",
      "    update_time_ms: 6.926\n",
      "  iterations_since_restore: 973\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.4515090709498\n",
      "  time_since_restore: 23089.23770594597\n",
      "  time_this_iter_s: 23.73975682258606\n",
      "  time_total_s: 23089.23770594597\n",
      "  timestamp: 1553988889\n",
      "  timesteps_since_restore: 9730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9730000\n",
      "  training_iteration: 973\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23089 s, 973 iter, 9730000 ts, 979 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-35-12\n",
      "  done: false\n",
      "  episode_len_mean: 178.84\n",
      "  episode_reward_max: 1161.5810492301728\n",
      "  episode_reward_mean: 1009.8286656459869\n",
      "  episode_reward_min: -65.634468916678\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 56787\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.579\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 9740000\n",
      "    num_steps_trained: 9740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6592408418655396\n",
      "      kl: 0.01969488337635994\n",
      "      policy_loss: -0.0023281376343220472\n",
      "      total_loss: 164.54200744628906\n",
      "      vf_explained_var: 0.9937589764595032\n",
      "      vf_loss: 164.5417938232422\n",
      "    sample_time_ms: 19636.988\n",
      "    update_time_ms: 6.807\n",
      "  iterations_since_restore: 974\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.9143328229935\n",
      "  time_since_restore: 23112.980947494507\n",
      "  time_this_iter_s: 23.743241548538208\n",
      "  time_total_s: 23112.980947494507\n",
      "  timestamp: 1553988912\n",
      "  timesteps_since_restore: 9740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9740000\n",
      "  training_iteration: 974\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23112 s, 974 iter, 9740000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-35-36\n",
      "  done: false\n",
      "  episode_len_mean: 173.54\n",
      "  episode_reward_max: 1151.0154263168106\n",
      "  episode_reward_mean: 999.3970129505502\n",
      "  episode_reward_min: -65.634468916678\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 56842\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3867.912\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 9750000\n",
      "    num_steps_trained: 9750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.131433367729187\n",
      "      kl: 0.018024446442723274\n",
      "      policy_loss: -0.0010682936990633607\n",
      "      total_loss: 645.2944946289062\n",
      "      vf_explained_var: 0.9741523861885071\n",
      "      vf_loss: 645.2931518554688\n",
      "    sample_time_ms: 19605.158\n",
      "    update_time_ms: 6.853\n",
      "  iterations_since_restore: 975\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 499.6985064752751\n",
      "  time_since_restore: 23136.30603981018\n",
      "  time_this_iter_s: 23.325092315673828\n",
      "  time_total_s: 23136.30603981018\n",
      "  timestamp: 1553988936\n",
      "  timesteps_since_restore: 9750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9750000\n",
      "  training_iteration: 975\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23136 s, 975 iter, 9750000 ts, 999 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-35-59\n",
      "  done: false\n",
      "  episode_len_mean: 174.7\n",
      "  episode_reward_max: 1142.230317818092\n",
      "  episode_reward_mean: 979.5407715179853\n",
      "  episode_reward_min: -67.46090964443431\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 56901\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3862.05\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 9760000\n",
      "    num_steps_trained: 9760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9332103133201599\n",
      "      kl: 0.012723940424621105\n",
      "      policy_loss: -0.0007899036863818765\n",
      "      total_loss: 667.1810302734375\n",
      "      vf_explained_var: 0.9715185165405273\n",
      "      vf_loss: 667.18017578125\n",
      "    sample_time_ms: 19702.741\n",
      "    update_time_ms: 6.58\n",
      "  iterations_since_restore: 976\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 489.77038575899263\n",
      "  time_since_restore: 23159.625689983368\n",
      "  time_this_iter_s: 23.319650173187256\n",
      "  time_total_s: 23159.625689983368\n",
      "  timestamp: 1553988959\n",
      "  timesteps_since_restore: 9760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9760000\n",
      "  training_iteration: 976\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23159 s, 976 iter, 9760000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-36-23\n",
      "  done: false\n",
      "  episode_len_mean: 162.36\n",
      "  episode_reward_max: 1142.230317818092\n",
      "  episode_reward_mean: 967.440154230947\n",
      "  episode_reward_min: -94.74437099738734\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 56964\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3863.972\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 9770000\n",
      "    num_steps_trained: 9770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5162113904953003\n",
      "      kl: 0.01963217742741108\n",
      "      policy_loss: -0.00025128686684183776\n",
      "      total_loss: 673.1356201171875\n",
      "      vf_explained_var: 0.9741543531417847\n",
      "      vf_loss: 673.1332397460938\n",
      "    sample_time_ms: 19705.947\n",
      "    update_time_ms: 5.844\n",
      "  iterations_since_restore: 977\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 483.7200771154735\n",
      "  time_since_restore: 23183.337901115417\n",
      "  time_this_iter_s: 23.71221113204956\n",
      "  time_total_s: 23183.337901115417\n",
      "  timestamp: 1553988983\n",
      "  timesteps_since_restore: 9770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9770000\n",
      "  training_iteration: 977\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23183 s, 977 iter, 9770000 ts, 967 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-36-47\n",
      "  done: false\n",
      "  episode_len_mean: 167.29\n",
      "  episode_reward_max: 1162.9196071294193\n",
      "  episode_reward_mean: 1009.4794460296055\n",
      "  episode_reward_min: -35.00209960290812\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 57022\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3865.139\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 9780000\n",
      "    num_steps_trained: 9780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7196410298347473\n",
      "      kl: 0.021549133583903313\n",
      "      policy_loss: -0.0037353564985096455\n",
      "      total_loss: 369.894775390625\n",
      "      vf_explained_var: 0.9840631484985352\n",
      "      vf_loss: 369.8957214355469\n",
      "    sample_time_ms: 19789.538\n",
      "    update_time_ms: 6.077\n",
      "  iterations_since_restore: 978\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.73972301480273\n",
      "  time_since_restore: 23207.267350912094\n",
      "  time_this_iter_s: 23.929449796676636\n",
      "  time_total_s: 23207.267350912094\n",
      "  timestamp: 1553989007\n",
      "  timesteps_since_restore: 9780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9780000\n",
      "  training_iteration: 978\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23207 s, 978 iter, 9780000 ts, 1.01e+03 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-37-11\n",
      "  done: false\n",
      "  episode_len_mean: 170.69\n",
      "  episode_reward_max: 1162.9196071294193\n",
      "  episode_reward_mean: 1008.9673813009562\n",
      "  episode_reward_min: 53.433188997279416\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 57081\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3883.737\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 9790000\n",
      "    num_steps_trained: 9790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7407231330871582\n",
      "      kl: 0.015120946802198887\n",
      "      policy_loss: -0.003001484554260969\n",
      "      total_loss: 437.1906433105469\n",
      "      vf_explained_var: 0.9822737574577332\n",
      "      vf_loss: 437.19171142578125\n",
      "    sample_time_ms: 19826.41\n",
      "    update_time_ms: 6.088\n",
      "  iterations_since_restore: 979\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.483690650478\n",
      "  time_since_restore: 23230.969356298447\n",
      "  time_this_iter_s: 23.70200538635254\n",
      "  time_total_s: 23230.969356298447\n",
      "  timestamp: 1553989031\n",
      "  timesteps_since_restore: 9790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9790000\n",
      "  training_iteration: 979\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23230 s, 979 iter, 9790000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-37-35\n",
      "  done: false\n",
      "  episode_len_mean: 172.32\n",
      "  episode_reward_max: 1135.3113658535005\n",
      "  episode_reward_mean: 970.7387524441527\n",
      "  episode_reward_min: -9.306670553521286\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 57139\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3878.367\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 9800000\n",
      "    num_steps_trained: 9800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9405781626701355\n",
      "      kl: 0.017597192898392677\n",
      "      policy_loss: -0.003195208264514804\n",
      "      total_loss: 723.6092529296875\n",
      "      vf_explained_var: 0.9704615473747253\n",
      "      vf_loss: 723.6101684570312\n",
      "    sample_time_ms: 19832.702\n",
      "    update_time_ms: 6.167\n",
      "  iterations_since_restore: 980\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 485.36937622207637\n",
      "  time_since_restore: 23255.08610367775\n",
      "  time_this_iter_s: 24.11674737930298\n",
      "  time_total_s: 23255.08610367775\n",
      "  timestamp: 1553989055\n",
      "  timesteps_since_restore: 9800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9800000\n",
      "  training_iteration: 980\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23255 s, 980 iter, 9800000 ts, 971 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-37-59\n",
      "  done: false\n",
      "  episode_len_mean: 174.37\n",
      "  episode_reward_max: 1109.1330975007525\n",
      "  episode_reward_mean: 973.8750552791463\n",
      "  episode_reward_min: -19.94637079072902\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 57196\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3877.817\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 9810000\n",
      "    num_steps_trained: 9810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7183908224105835\n",
      "      kl: 0.02064603753387928\n",
      "      policy_loss: -0.004369291011244059\n",
      "      total_loss: 499.0519714355469\n",
      "      vf_explained_var: 0.9801875352859497\n",
      "      vf_loss: 499.05377197265625\n",
      "    sample_time_ms: 19947.178\n",
      "    update_time_ms: 5.613\n",
      "  iterations_since_restore: 981\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 486.93752763957315\n",
      "  time_since_restore: 23279.490164518356\n",
      "  time_this_iter_s: 24.40406084060669\n",
      "  time_total_s: 23279.490164518356\n",
      "  timestamp: 1553989079\n",
      "  timesteps_since_restore: 9810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9810000\n",
      "  training_iteration: 981\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23279 s, 981 iter, 9810000 ts, 974 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-38-23\n",
      "  done: false\n",
      "  episode_len_mean: 171.38\n",
      "  episode_reward_max: 1117.4961790268965\n",
      "  episode_reward_mean: 981.3789523707176\n",
      "  episode_reward_min: -76.76820350738761\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 57255\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3880.666\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 9820000\n",
      "    num_steps_trained: 9820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.743127703666687\n",
      "      kl: 0.020021267235279083\n",
      "      policy_loss: -0.0007906474056653678\n",
      "      total_loss: 430.6422424316406\n",
      "      vf_explained_var: 0.9820809960365295\n",
      "      vf_loss: 430.6405334472656\n",
      "    sample_time_ms: 19863.993\n",
      "    update_time_ms: 5.595\n",
      "  iterations_since_restore: 982\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.6894761853587\n",
      "  time_since_restore: 23303.20212841034\n",
      "  time_this_iter_s: 23.711963891983032\n",
      "  time_total_s: 23303.20212841034\n",
      "  timestamp: 1553989103\n",
      "  timesteps_since_restore: 9820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9820000\n",
      "  training_iteration: 982\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23303 s, 982 iter, 9820000 ts, 981 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-38-47\n",
      "  done: false\n",
      "  episode_len_mean: 179.95\n",
      "  episode_reward_max: 1146.040647307655\n",
      "  episode_reward_mean: 954.9867930562743\n",
      "  episode_reward_min: -76.76820350738761\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 57310\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3881.08\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 9830000\n",
      "    num_steps_trained: 9830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4659861326217651\n",
      "      kl: 0.020917853340506554\n",
      "      policy_loss: -0.0008912860066629946\n",
      "      total_loss: 1049.7681884765625\n",
      "      vf_explained_var: 0.958515465259552\n",
      "      vf_loss: 1049.7664794921875\n",
      "    sample_time_ms: 19909.255\n",
      "    update_time_ms: 5.6\n",
      "  iterations_since_restore: 983\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 477.49339652813717\n",
      "  time_since_restore: 23327.396399259567\n",
      "  time_this_iter_s: 24.194270849227905\n",
      "  time_total_s: 23327.396399259567\n",
      "  timestamp: 1553989127\n",
      "  timesteps_since_restore: 9830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9830000\n",
      "  training_iteration: 983\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23327 s, 983 iter, 9830000 ts, 955 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-39-11\n",
      "  done: false\n",
      "  episode_len_mean: 164.76\n",
      "  episode_reward_max: 1146.040647307655\n",
      "  episode_reward_mean: 998.715138656968\n",
      "  episode_reward_min: -65.12621023927525\n",
      "  episodes_this_iter: 62\n",
      "  episodes_total: 57372\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3899.168\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 9840000\n",
      "    num_steps_trained: 9840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2706157863140106\n",
      "      kl: 0.021425774320960045\n",
      "      policy_loss: -0.0010712718358263373\n",
      "      total_loss: 673.4337158203125\n",
      "      vf_explained_var: 0.9728034734725952\n",
      "      vf_loss: 673.4319458007812\n",
      "    sample_time_ms: 19869.069\n",
      "    update_time_ms: 5.668\n",
      "  iterations_since_restore: 984\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 499.357569328484\n",
      "  time_since_restore: 23350.92051911354\n",
      "  time_this_iter_s: 23.52411985397339\n",
      "  time_total_s: 23350.92051911354\n",
      "  timestamp: 1553989151\n",
      "  timesteps_since_restore: 9840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9840000\n",
      "  training_iteration: 984\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23350 s, 984 iter, 9840000 ts, 999 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-39-34\n",
      "  done: false\n",
      "  episode_len_mean: 166.95\n",
      "  episode_reward_max: 1128.7375414523162\n",
      "  episode_reward_mean: 982.6853723999925\n",
      "  episode_reward_min: -65.12621023927525\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 57430\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.278\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 9850000\n",
      "    num_steps_trained: 9850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.929443359375\n",
      "      kl: 0.02421778254210949\n",
      "      policy_loss: -0.001430330565199256\n",
      "      total_loss: 546.2055053710938\n",
      "      vf_explained_var: 0.9783334136009216\n",
      "      vf_loss: 546.2037963867188\n",
      "    sample_time_ms: 19884.169\n",
      "    update_time_ms: 5.639\n",
      "  iterations_since_restore: 985\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 491.3426861999963\n",
      "  time_since_restore: 23374.347915410995\n",
      "  time_this_iter_s: 23.427396297454834\n",
      "  time_total_s: 23374.347915410995\n",
      "  timestamp: 1553989174\n",
      "  timesteps_since_restore: 9850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9850000\n",
      "  training_iteration: 985\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23374 s, 985 iter, 9850000 ts, 983 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-39-58\n",
      "  done: false\n",
      "  episode_len_mean: 172.91\n",
      "  episode_reward_max: 1163.9227721887914\n",
      "  episode_reward_mean: 960.2476122197835\n",
      "  episode_reward_min: -51.95523504932112\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 57488\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3897.822\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 9860000\n",
      "    num_steps_trained: 9860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9343963861465454\n",
      "      kl: 0.015223298221826553\n",
      "      policy_loss: -0.0014874134212732315\n",
      "      total_loss: 963.3848266601562\n",
      "      vf_explained_var: 0.9626896977424622\n",
      "      vf_loss: 963.3842163085938\n",
      "    sample_time_ms: 19884.074\n",
      "    update_time_ms: 6.205\n",
      "  iterations_since_restore: 986\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 480.1238061098918\n",
      "  time_since_restore: 23397.704238414764\n",
      "  time_this_iter_s: 23.35632300376892\n",
      "  time_total_s: 23397.704238414764\n",
      "  timestamp: 1553989198\n",
      "  timesteps_since_restore: 9860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9860000\n",
      "  training_iteration: 986\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23397 s, 986 iter, 9860000 ts, 960 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-40-21\n",
      "  done: false\n",
      "  episode_len_mean: 167.21\n",
      "  episode_reward_max: 1164.7089282576317\n",
      "  episode_reward_mean: 985.3357883075904\n",
      "  episode_reward_min: -51.95523504932112\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 57547\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.568\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 9870000\n",
      "    num_steps_trained: 9870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5159667730331421\n",
      "      kl: 0.023936403915286064\n",
      "      policy_loss: 0.0005148719064891338\n",
      "      total_loss: 205.93603515625\n",
      "      vf_explained_var: 0.991255521774292\n",
      "      vf_loss: 205.9324493408203\n",
      "    sample_time_ms: 19860.147\n",
      "    update_time_ms: 6.207\n",
      "  iterations_since_restore: 987\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.6678941537952\n",
      "  time_since_restore: 23421.128499507904\n",
      "  time_this_iter_s: 23.42426109313965\n",
      "  time_total_s: 23421.128499507904\n",
      "  timestamp: 1553989221\n",
      "  timesteps_since_restore: 9870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9870000\n",
      "  training_iteration: 987\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23421 s, 987 iter, 9870000 ts, 985 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-40-45\n",
      "  done: false\n",
      "  episode_len_mean: 168.62\n",
      "  episode_reward_max: 1175.8269474873753\n",
      "  episode_reward_mean: 1008.0049454209712\n",
      "  episode_reward_min: 24.17766258404032\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 57604\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.837\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 9880000\n",
      "    num_steps_trained: 9880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8558955788612366\n",
      "      kl: 0.01772957108914852\n",
      "      policy_loss: 0.0007329033105634153\n",
      "      total_loss: 283.2560729980469\n",
      "      vf_explained_var: 0.9874627590179443\n",
      "      vf_loss: 283.25299072265625\n",
      "    sample_time_ms: 19867.948\n",
      "    update_time_ms: 5.734\n",
      "  iterations_since_restore: 988\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 504.0024727104855\n",
      "  time_since_restore: 23445.098316669464\n",
      "  time_this_iter_s: 23.96981716156006\n",
      "  time_total_s: 23445.098316669464\n",
      "  timestamp: 1553989245\n",
      "  timesteps_since_restore: 9880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9880000\n",
      "  training_iteration: 988\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23445 s, 988 iter, 9880000 ts, 1.01e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-41-10\n",
      "  done: false\n",
      "  episode_len_mean: 171.67\n",
      "  episode_reward_max: 1144.310014597209\n",
      "  episode_reward_mean: 1000.0100366109211\n",
      "  episode_reward_min: 58.72786890338932\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 57664\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.878\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 9890000\n",
      "    num_steps_trained: 9890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6945945620536804\n",
      "      kl: 0.020132623612880707\n",
      "      policy_loss: -0.0044965846464037895\n",
      "      total_loss: 249.4266357421875\n",
      "      vf_explained_var: 0.9897810816764832\n",
      "      vf_loss: 249.4285430908203\n",
      "    sample_time_ms: 19942.538\n",
      "    update_time_ms: 5.712\n",
      "  iterations_since_restore: 989\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 500.00501830546057\n",
      "  time_since_restore: 23469.55961894989\n",
      "  time_this_iter_s: 24.461302280426025\n",
      "  time_total_s: 23469.55961894989\n",
      "  timestamp: 1553989270\n",
      "  timesteps_since_restore: 9890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9890000\n",
      "  training_iteration: 989\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23469 s, 989 iter, 9890000 ts, 1e+03 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-41-33\n",
      "  done: false\n",
      "  episode_len_mean: 187.21\n",
      "  episode_reward_max: 1125.3407439612251\n",
      "  episode_reward_mean: 987.5414882351419\n",
      "  episode_reward_min: 67.76582654437601\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 57713\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3892.186\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 9900000\n",
      "    num_steps_trained: 9900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.9097716808319092\n",
      "      kl: 0.014920528046786785\n",
      "      policy_loss: -0.00010753957758424804\n",
      "      total_loss: 586.8517456054688\n",
      "      vf_explained_var: 0.9784074425697327\n",
      "      vf_loss: 586.8500366210938\n",
      "    sample_time_ms: 19867.417\n",
      "    update_time_ms: 5.573\n",
      "  iterations_since_restore: 990\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 493.7707441175709\n",
      "  time_since_restore: 23492.936470270157\n",
      "  time_this_iter_s: 23.376851320266724\n",
      "  time_total_s: 23492.936470270157\n",
      "  timestamp: 1553989293\n",
      "  timesteps_since_restore: 9900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9900000\n",
      "  training_iteration: 990\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23492 s, 990 iter, 9900000 ts, 988 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-41-57\n",
      "  done: false\n",
      "  episode_len_mean: 192.6\n",
      "  episode_reward_max: 1138.5130627693827\n",
      "  episode_reward_mean: 980.4413675716314\n",
      "  episode_reward_min: 83.59217160175103\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 57769\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3894.459\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 9910000\n",
      "    num_steps_trained: 9910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1340618133544922\n",
      "      kl: 0.025163082405924797\n",
      "      policy_loss: -0.002222704468294978\n",
      "      total_loss: 339.96649169921875\n",
      "      vf_explained_var: 0.9856320023536682\n",
      "      vf_loss: 339.9654846191406\n",
      "    sample_time_ms: 19831.648\n",
      "    update_time_ms: 5.686\n",
      "  iterations_since_restore: 991\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 490.22068378581565\n",
      "  time_since_restore: 23517.008409023285\n",
      "  time_this_iter_s: 24.07193875312805\n",
      "  time_total_s: 23517.008409023285\n",
      "  timestamp: 1553989317\n",
      "  timesteps_since_restore: 9910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9910000\n",
      "  training_iteration: 991\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23517 s, 991 iter, 9910000 ts, 980 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-42-22\n",
      "  done: false\n",
      "  episode_len_mean: 171.37\n",
      "  episode_reward_max: 1125.1779460661778\n",
      "  episode_reward_mean: 964.3939651880532\n",
      "  episode_reward_min: -90.38092319866506\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 57829\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.085\n",
      "    load_time_ms: 1.661\n",
      "    num_steps_sampled: 9920000\n",
      "    num_steps_trained: 9920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9245362877845764\n",
      "      kl: 0.016497069969773293\n",
      "      policy_loss: -0.00023495234199799597\n",
      "      total_loss: 705.3506469726562\n",
      "      vf_explained_var: 0.9732633829116821\n",
      "      vf_loss: 705.3487548828125\n",
      "    sample_time_ms: 19925.664\n",
      "    update_time_ms: 5.663\n",
      "  iterations_since_restore: 992\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 482.1969825940266\n",
      "  time_since_restore: 23541.633055210114\n",
      "  time_this_iter_s: 24.624646186828613\n",
      "  time_total_s: 23541.633055210114\n",
      "  timestamp: 1553989342\n",
      "  timesteps_since_restore: 9920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9920000\n",
      "  training_iteration: 992\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23541 s, 992 iter, 9920000 ts, 964 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-42-46\n",
      "  done: false\n",
      "  episode_len_mean: 160.18\n",
      "  episode_reward_max: 1125.1779460661778\n",
      "  episode_reward_mean: 975.4275635277122\n",
      "  episode_reward_min: -90.38092319866506\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 57890\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.066\n",
      "    load_time_ms: 1.665\n",
      "    num_steps_sampled: 9930000\n",
      "    num_steps_trained: 9930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6907002925872803\n",
      "      kl: 0.021774010732769966\n",
      "      policy_loss: -0.004767408594489098\n",
      "      total_loss: 985.3678588867188\n",
      "      vf_explained_var: 0.9590878486633301\n",
      "      vf_loss: 985.3698120117188\n",
      "    sample_time_ms: 19935.112\n",
      "    update_time_ms: 5.565\n",
      "  iterations_since_restore: 993\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 487.7137817638561\n",
      "  time_since_restore: 23565.94340991974\n",
      "  time_this_iter_s: 24.310354709625244\n",
      "  time_total_s: 23565.94340991974\n",
      "  timestamp: 1553989366\n",
      "  timesteps_since_restore: 9930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9930000\n",
      "  training_iteration: 993\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23565 s, 993 iter, 9930000 ts, 975 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-43-09\n",
      "  done: false\n",
      "  episode_len_mean: 172.89\n",
      "  episode_reward_max: 1134.983570786186\n",
      "  episode_reward_mean: 952.9709436402994\n",
      "  episode_reward_min: -63.05688971541875\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 57946\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.583\n",
      "    load_time_ms: 1.689\n",
      "    num_steps_sampled: 9940000\n",
      "    num_steps_trained: 9940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0328174829483032\n",
      "      kl: 0.018987687304615974\n",
      "      policy_loss: 0.0003942992480006069\n",
      "      total_loss: 755.7701416015625\n",
      "      vf_explained_var: 0.9695882797241211\n",
      "      vf_loss: 755.7673950195312\n",
      "    sample_time_ms: 19886.679\n",
      "    update_time_ms: 5.472\n",
      "  iterations_since_restore: 994\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.4854718201496\n",
      "  time_since_restore: 23588.94663953781\n",
      "  time_this_iter_s: 23.00322961807251\n",
      "  time_total_s: 23588.94663953781\n",
      "  timestamp: 1553989389\n",
      "  timesteps_since_restore: 9940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9940000\n",
      "  training_iteration: 994\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23588 s, 994 iter, 9940000 ts, 953 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-43-32\n",
      "  done: false\n",
      "  episode_len_mean: 177.99\n",
      "  episode_reward_max: 1152.8783422174968\n",
      "  episode_reward_mean: 976.4618182732869\n",
      "  episode_reward_min: -63.05688971541875\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 58004\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3890.93\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 9950000\n",
      "    num_steps_trained: 9950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7280481457710266\n",
      "      kl: 0.020686550065875053\n",
      "      policy_loss: -0.007501243147999048\n",
      "      total_loss: 647.45751953125\n",
      "      vf_explained_var: 0.9730023145675659\n",
      "      vf_loss: 647.4623413085938\n",
      "    sample_time_ms: 19866.616\n",
      "    update_time_ms: 5.387\n",
      "  iterations_since_restore: 995\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 488.23090913664345\n",
      "  time_since_restore: 23612.185065746307\n",
      "  time_this_iter_s: 23.238426208496094\n",
      "  time_total_s: 23612.185065746307\n",
      "  timestamp: 1553989412\n",
      "  timesteps_since_restore: 9950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9950000\n",
      "  training_iteration: 995\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23612 s, 995 iter, 9950000 ts, 976 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-43-57\n",
      "  done: false\n",
      "  episode_len_mean: 168.25\n",
      "  episode_reward_max: 1160.7607466008942\n",
      "  episode_reward_mean: 1017.6002274137028\n",
      "  episode_reward_min: 0.888733226812576\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 58064\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3891.972\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 9960000\n",
      "    num_steps_trained: 9960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.12882612645626068\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.33415332436561584\n",
      "      kl: 0.05998612567782402\n",
      "      policy_loss: -0.001205137581564486\n",
      "      total_loss: 121.03105926513672\n",
      "      vf_explained_var: 0.9950717091560364\n",
      "      vf_loss: 121.0245361328125\n",
      "    sample_time_ms: 19957.237\n",
      "    update_time_ms: 5.26\n",
      "  iterations_since_restore: 996\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 508.8001137068514\n",
      "  time_since_restore: 23636.45730161667\n",
      "  time_this_iter_s: 24.272235870361328\n",
      "  time_total_s: 23636.45730161667\n",
      "  timestamp: 1553989437\n",
      "  timesteps_since_restore: 9960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9960000\n",
      "  training_iteration: 996\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23636 s, 996 iter, 9960000 ts, 1.02e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-44-20\n",
      "  done: false\n",
      "  episode_len_mean: 167.47\n",
      "  episode_reward_max: 1141.4757460189533\n",
      "  episode_reward_mean: 1035.7555118118705\n",
      "  episode_reward_min: 783.0873025271037\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 58123\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3900.49\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 9970000\n",
      "    num_steps_trained: 9970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.19323918223381042\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5477222800254822\n",
      "      kl: 0.018895121291279793\n",
      "      policy_loss: -0.0028835658449679613\n",
      "      total_loss: 126.92753601074219\n",
      "      vf_explained_var: 0.994208812713623\n",
      "      vf_loss: 126.9267578125\n",
      "    sample_time_ms: 19963.852\n",
      "    update_time_ms: 5.31\n",
      "  iterations_since_restore: 997\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 517.8777559059351\n",
      "  time_since_restore: 23660.03005671501\n",
      "  time_this_iter_s: 23.572755098342896\n",
      "  time_total_s: 23660.03005671501\n",
      "  timestamp: 1553989460\n",
      "  timesteps_since_restore: 9970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9970000\n",
      "  training_iteration: 997\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23660 s, 997 iter, 9970000 ts, 1.04e+03 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-44-45\n",
      "  done: false\n",
      "  episode_len_mean: 179.23\n",
      "  episode_reward_max: 1141.4757460189533\n",
      "  episode_reward_mean: 992.224099830833\n",
      "  episode_reward_min: 140.02861750174895\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 58175\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.454\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 9980000\n",
      "    num_steps_trained: 9980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.19323918223381042\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6604681015014648\n",
      "      kl: 0.012449245899915695\n",
      "      policy_loss: -0.0015838033286854625\n",
      "      total_loss: 436.9562683105469\n",
      "      vf_explained_var: 0.9823803901672363\n",
      "      vf_loss: 436.9554748535156\n",
      "    sample_time_ms: 19984.725\n",
      "    update_time_ms: 5.375\n",
      "  iterations_since_restore: 998\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 496.11204991541655\n",
      "  time_since_restore: 23684.214991092682\n",
      "  time_this_iter_s: 24.184934377670288\n",
      "  time_total_s: 23684.214991092682\n",
      "  timestamp: 1553989485\n",
      "  timesteps_since_restore: 9980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9980000\n",
      "  training_iteration: 998\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23684 s, 998 iter, 9980000 ts, 992 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-45-08\n",
      "  done: false\n",
      "  episode_len_mean: 178.3\n",
      "  episode_reward_max: 1141.7991951948748\n",
      "  episode_reward_mean: 985.3971515316539\n",
      "  episode_reward_min: -51.33103600108751\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 58233\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3902.388\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 9990000\n",
      "    num_steps_trained: 9990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.19323918223381042\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6715813875198364\n",
      "      kl: 0.01439371146261692\n",
      "      policy_loss: -0.0011475227074697614\n",
      "      total_loss: 347.1733703613281\n",
      "      vf_explained_var: 0.9859104752540588\n",
      "      vf_loss: 347.1717834472656\n",
      "    sample_time_ms: 19913.204\n",
      "    update_time_ms: 5.33\n",
      "  iterations_since_restore: 999\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 492.69857576582706\n",
      "  time_since_restore: 23707.970217227936\n",
      "  time_this_iter_s: 23.755226135253906\n",
      "  time_total_s: 23707.970217227936\n",
      "  timestamp: 1553989508\n",
      "  timesteps_since_restore: 9990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9990000\n",
      "  training_iteration: 999\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=7681], 23707 s, 999 iter, 9990000 ts, 985 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-31_00-45-33\n",
      "  done: true\n",
      "  episode_len_mean: 173.81\n",
      "  episode_reward_max: 1146.0689661175065\n",
      "  episode_reward_mean: 952.4440363352329\n",
      "  episode_reward_min: -89.35267398395267\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 58291\n",
      "  experiment_id: 317c3905198e469ea331d85175f15b15\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3901.698\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 10000000\n",
      "    num_steps_trained: 10000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.19323918223381042\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3872579336166382\n",
      "      kl: 0.015218219719827175\n",
      "      policy_loss: -0.005368832964450121\n",
      "      total_loss: 1061.6793212890625\n",
      "      vf_explained_var: 0.9615878462791443\n",
      "      vf_loss: 1061.6817626953125\n",
      "    sample_time_ms: 19980.404\n",
      "    update_time_ms: 5.43\n",
      "  iterations_since_restore: 1000\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 7681\n",
      "  policy_reward_mean:\n",
      "    rl_0: 476.22201816761645\n",
      "  time_since_restore: 23732.01470732689\n",
      "  time_this_iter_s: 24.044490098953247\n",
      "  time_total_s: 23732.01470732689\n",
      "  timestamp: 1553989533\n",
      "  timesteps_since_restore: 10000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000000\n",
      "  training_iteration: 1000\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tTERMINATED [pid=7681], 23732 s, 1000 iter, 10000000 ts, 952 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tTERMINATED [pid=7681], 23732 s, 1000 iter, 10000000 ts, 952 rew\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,  # RL algorithm to run\n",
    "        \"env\": gym_name,  # environment name generated earlier\n",
    "        \"config\": {  # configuration params (must match \"run\" value)\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 1,  # number of iterations between checkpoints\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 1000,  # number of iterations to stop after\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flow_2)",
   "language": "python",
   "name": "flow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
