{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING I3W\n",
    "\n",
    "\n",
    "# A) Create Envorinment, Vehicles etc\n",
    "\n",
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scenarios:\n",
      "['Scenario', 'BayBridgeScenario', 'BayBridgeTollScenario', 'BottleneckScenario', 'Figure8Scenario', 'SimpleGridScenario', 'HighwayScenario', 'LoopScenario', 'MergeScenario', 'TwoLoopsOneMergingScenario', 'MultiLoopScenario', 'IntersectionScenarioTW']\n",
      "\n",
      "Available environments:\n",
      "['MultiEnv', 'MultiAgentAccelEnv', 'MultiWaveAttenuationPOEnv', 'MultiAgentIntersectionEnv', 'MultiAgentTeamSpiritIntersectionEnv', 'MultiAgentIntersectionEnv_baseline_1', 'MultiAgentIntersectionEnv_baseline_2', 'MultiAgentIntersectionEnv_baseline_3', 'MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit']\n"
     ]
    }
   ],
   "source": [
    "# Define horizon as a variable to ensure consistent use across notebook (length of one rollout)\n",
    "HORIZON=500                                 #103 max Horizon, wenn es vor verlassen abbrechen soll!, default war 500\n",
    "\n",
    "# name of the experiment\n",
    "experiment_name = \"IntersectionExample\"\n",
    "\n",
    "# scenario class\n",
    "import flow.scenarios as scenarios\n",
    "print(\"Available scenarios:\")\n",
    "print(scenarios.__all__)\n",
    "scenario_name = \"IntersectionTWScenario\"\n",
    "\n",
    "# environment class\n",
    "import flow.multiagent_envs as flowenvs\n",
    "print(\"\\nAvailable environments:\")\n",
    "print(flowenvs.__all__)\n",
    "env_name = \"MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import NetParams\n",
    "from flow.scenarios.intersection import ADDITIONAL_NET_PARAMS\n",
    "\n",
    "additionalNetParams = {\n",
    "            \"edge_length\": 40,\n",
    "            \"lanes\": 1,\n",
    "            \"speed_limit\": 30\n",
    "        }\n",
    "\n",
    "net_params = NetParams( no_internal_links=False,                  #default: True   !! damit Kreuzungen nicht Ã¼berspr. werden\n",
    "                        inflows=None,                             #default: None\n",
    "                        osm_path=None,                            #default: None\n",
    "                        netfile=None,                             #default: None\n",
    "                        additional_params=additionalNetParams     #default: None   !!\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitialConfig Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import InitialConfig\n",
    "\n",
    "initial_config = InitialConfig( shuffle=True,                            #default: False         !!\n",
    "                                spacing=\"custom\",                        #default: \"uniform\"     !!\n",
    "                                min_gap=10,                              #default: 0\n",
    "                                perturbation=29.99,                      #default: 0.0            !!        \n",
    "                                x0=0,                                    #default: 0\n",
    "                                bunching=0,                              #default: 0\n",
    "                                lanes_distribution=float(\"inf\"),         #default: float(\"inf\")\n",
    "                                edges_distribution=\"all\",                #default: \"all\"\n",
    "                                additional_params=None )                 #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMO Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sumo_params = SumoParams( port = None,                  #default: None\n",
    "                          sim_step=0.1,                 #default: 0.1\n",
    "                          emission_path=None,           #default: None\n",
    "                          lateral_resolution=None,      #default: None\n",
    "                          no_step_log=True,             #default: True\n",
    "                          render=False,                 #default: False\n",
    "                          save_render=False,            #default: False\n",
    "                          sight_radius=25,              #default: 25\n",
    "                          show_radius=False,            #default: False\n",
    "                          pxpm=2,                       #default: 2\n",
    "                          overtake_right=False,         #default: False    \n",
    "                          seed=None,                    #default: None\n",
    "                          restart_instance=False,       #default: False\n",
    "                          print_warnings=True,          #default: True\n",
    "                          teleport_time=-1,             #default: -1\n",
    "                          num_clients=1,                #default: 1\n",
    "                          sumo_binary=None )            #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "additionalEnvParams = {\n",
    "        # maximum acceleration of autonomous vehicles\n",
    "        \"max_accel\": 3,\n",
    "        # maximum deceleration of autonomous vehicles\n",
    "        \"max_decel\": 3,\n",
    "        \"target_velocity\": 30\n",
    "    }\n",
    "\n",
    "env_params = EnvParams( additional_params=additionalEnvParams, #default: None    !!\n",
    "                        horizon=HORIZON,                       #default: 500     !!\n",
    "                        warmup_steps=0,                        #default: 0       \n",
    "                        sims_per_step=1,                       #default: 1\n",
    "                        evaluate=False )                       #default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import VehicleParams\n",
    "\n",
    "# import vehicles dynamics models\n",
    "#from flow.controllers import SumoCarFollowingController\n",
    "from flow.controllers import ContinuousRouter\n",
    "#from flow.controllers.lane_change_controllers import SumoLaneChangeController\n",
    "from flow.controllers.lane_change_controllers import StaticLaneChanger\n",
    "from flow.controllers import RLController\n",
    "from flow.core.params import SumoLaneChangeParams\n",
    "from flow.core.params import SumoCarFollowingParams\n",
    "from random import *\n",
    "\n",
    "vehicles = VehicleParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add RL-Agent controlled vehicles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car following parameters, default: None\n",
    "cf_parameter = SumoCarFollowingParams(\n",
    "                speed_mode=\"aggressive\")\n",
    "# lane change parameters, default: None\n",
    "lc_parameter =  None\n",
    "\n",
    "vehicles.add( # name of the vehicle\n",
    "                veh_id = \"rl\",\n",
    "              # acceleration controller, default: (SumoCarFollowingController, {})\n",
    "                acceleration_controller=(RLController, {}),\n",
    "              # lane_change_controller, default: (SumoLaneChangeController, {})\n",
    "                lane_change_controller=(StaticLaneChanger,{}),\n",
    "              # routing controller, default: None\n",
    "                routing_controller=(ContinuousRouter, {}),\n",
    "              # initial speed, default: 0\n",
    "                initial_speed=0,\n",
    "              # number of vehicles, default: 1 \n",
    "                num_vehicles=2,\n",
    "                \n",
    "                car_following_params=cf_parameter\n",
    "              # speed mode, default: \"right_of_way\"\n",
    "                #speed_mode=\"aggressive\",\n",
    "              # lane change mode, default: \"no_lat_collide\"\n",
    "                #lane_change_mode=\"aggressive\", \n",
    "              # car following parameter, default: None\n",
    "                #sumo_car_following_params=cf_parameter,\n",
    "              # lane change parameter, default: None\n",
    "                #sumo_lc_params=lc_parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict( # name of the experiment\n",
    "                      exp_tag=experiment_name,\n",
    "                    # name of the flow environment the experiment is running on\n",
    "                      env_name=env_name,\n",
    "                    # name of the scenario class the experiment uses\n",
    "                      scenario=scenario_name,\n",
    "                    # simulator that is used by the experiment\n",
    "                      simulator='traci',\n",
    "                    # sumo-related parameters (see flow.core.params.SumoParams)\n",
    "                      sim=sumo_params,\n",
    "                    # environment related parameters (see flow.core.params.EnvParams)\n",
    "                      env=env_params,\n",
    "                    # network-related parameters (see flow.core.params.NetParams and\n",
    "                    # the scenario's documentation or ADDITIONAL_NET_PARAMS component)\n",
    "                      net=net_params,\n",
    "                    # vehicles to be placed in the network at the start of a rollout \n",
    "                    # (see flow.core.vehicles.Vehicles)\n",
    "                      veh=vehicles,\n",
    "                   # (optional) parameters affecting the positioning of vehicles upon \n",
    "                   # initialization/reset (see flow.core.params.InitialConfig)\n",
    "                      initial=initial_config\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo.ppo_policy_graph import PPOPolicyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-03-27_18-49-37_3993/logs.\n",
      "Waiting for redis server at 127.0.0.1:18844 to respond...\n",
      "Waiting for redis server at 127.0.0.1:41057 to respond...\n",
      "Starting the Plasma object store with 6.554658406 GB memory using /dev/shm.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=0909cc23ad45c470113c14675027e7445175df12c7b32da8\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.2.102',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-03-27_18-49-37_3993/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-03-27_18-49-37_3993/sockets/raylet'],\n",
       " 'redis_address': '192.168.2.102:18844',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui.ipynb?token=0909cc23ad45c470113c14675027e7445175df12c7b32da8'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "N_CPUS = 2\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 20\n",
    "\n",
    "ray.init(redirect_output=True, num_cpus=N_CPUS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm or model to train. This may refer to \"\n",
    "#      \"the name of a built-on algorithm (e.g. RLLib's DQN \"\n",
    "#      \"or PPO), or a user-defined trainable function or \"\n",
    "#      \"class registered in the tune registry.\")\n",
    "alg_run = \"PPO\"\n",
    "\n",
    "agent_cls = get_agent_class(alg_run)\n",
    "config = agent_cls._default_config.copy()\n",
    "config[\"num_workers\"] = N_CPUS  # number of parallel workers\n",
    "config[\"train_batch_size\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.999  # discount rate default 0.999\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [100, 50, 25]})  # size of hidden layers in network defaule 64 32\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "#config[\"sgd_minibatch_size\"] = min(16 * 1024, config[\"train_batch_size\"])  # stochastic gradient descent\n",
    "#config[\"sample_batch_size\"] = config[\"train_batch_size\"]/config[\"num_workers\"] # 200 default, trotzdem zu hoch?\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "config['env_config']['run'] = alg_run\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, gym_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(gym_name, create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Starting SUMO on port 44139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.553154398181952\n",
      "18.504479839823905\n"
     ]
    }
   ],
   "source": [
    "# multi agent policy mapping\n",
    "test_env = create_env()\n",
    "obs_space = test_env.observation_space\n",
    "act_space = test_env.action_space\n",
    "\n",
    "def gen_policy():\n",
    "    return (PPOPolicyGraph, obs_space, act_space, {})\n",
    "\n",
    "# Setup PG with an ensemble of `num_policies` different policy graphs\n",
    "policy_graphs = {'rl_0': gen_policy()}\n",
    "    \n",
    "def policy_mapping_fn(agent_id):\n",
    "    return 'rl_0'\n",
    "\n",
    "config.update({\n",
    "        'multiagent': {\n",
    "            'policy_graphs': policy_graphs,\n",
    "            'policy_mapping_fn': tune.function(policy_mapping_fn),\n",
    "            'policies_to_train': ['rl_0']\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 2.5/16.4 GB\n",
      "\n",
      "Created LogSyncer for /home/thorsten/ray_results/IntersectionExample/PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0_2019-03-27_18-49-39vs4d3yjp -> \n",
      "WARNING: Falling back to serializing objects of type <class 'numpy.dtype'> by using pickle. This may be inefficient.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 2.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-50-34\n",
      "  done: false\n",
      "  episode_len_mean: 436.27272727272725\n",
      "  episode_reward_max: 426.82213129389606\n",
      "  episode_reward_mean: 106.97591505808391\n",
      "  episode_reward_min: -115.22056416182052\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 22\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4421.822\n",
      "    load_time_ms: 48.539\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20000004768371582\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4186389446258545\n",
      "      kl: 0.0030684478115290403\n",
      "      policy_loss: -0.002238248474895954\n",
      "      total_loss: 167.68809509277344\n",
      "      vf_explained_var: 0.07738766074180603\n",
      "      vf_loss: 167.68972778320312\n",
      "    sample_time_ms: 20865.071\n",
      "    update_time_ms: 577.178\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.48795752904195\n",
      "  time_since_restore: 25.97406578063965\n",
      "  time_this_iter_s: 25.97406578063965\n",
      "  time_total_s: 25.97406578063965\n",
      "  timestamp: 1553709034\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 25 s, 1 iter, 10000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-50-56\n",
      "  done: false\n",
      "  episode_len_mean: 449.25\n",
      "  episode_reward_max: 484.22844059865025\n",
      "  episode_reward_mean: 185.4146597287573\n",
      "  episode_reward_min: -115.22056416182052\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 44\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4164.442\n",
      "    load_time_ms: 25.271\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10000002384185791\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4191635847091675\n",
      "      kl: 0.004276239778846502\n",
      "      policy_loss: -0.002554349834099412\n",
      "      total_loss: 117.72740173339844\n",
      "      vf_explained_var: 0.033994950354099274\n",
      "      vf_loss: 117.72954559326172\n",
      "    sample_time_ms: 19819.784\n",
      "    update_time_ms: 293.282\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.70732986437866\n",
      "  time_since_restore: 48.68514084815979\n",
      "  time_this_iter_s: 22.71107506752014\n",
      "  time_total_s: 48.68514084815979\n",
      "  timestamp: 1553709056\n",
      "  timesteps_since_restore: 20000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 48 s, 2 iter, 20000 ts, 185 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-51-19\n",
      "  done: false\n",
      "  episode_len_mean: 427.3142857142857\n",
      "  episode_reward_max: 579.8392728030524\n",
      "  episode_reward_mean: 237.32256754473465\n",
      "  episode_reward_min: -115.22056416182052\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 70\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4084.33\n",
      "    load_time_ms: 17.313\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.050000011920928955\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4124523401260376\n",
      "      kl: 0.00897839106619358\n",
      "      policy_loss: -0.004086148459464312\n",
      "      total_loss: 276.34625244140625\n",
      "      vf_explained_var: 0.10456151515245438\n",
      "      vf_loss: 276.349853515625\n",
      "    sample_time_ms: 19551.403\n",
      "    update_time_ms: 197.834\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 118.6612837723673\n",
      "  time_since_restore: 71.64970707893372\n",
      "  time_this_iter_s: 22.964566230773926\n",
      "  time_total_s: 71.64970707893372\n",
      "  timestamp: 1553709079\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 3\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 71 s, 3 iter, 30000 ts, 237 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-51-42\n",
      "  done: false\n",
      "  episode_len_mean: 409.4742268041237\n",
      "  episode_reward_max: 579.8392728030524\n",
      "  episode_reward_mean: 301.61742317319033\n",
      "  episode_reward_min: -115.22056416182052\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 97\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4035.209\n",
      "    load_time_ms: 13.331\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025000005960464478\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4216399192810059\n",
      "      kl: 0.008881017565727234\n",
      "      policy_loss: -0.004084281623363495\n",
      "      total_loss: 379.84259033203125\n",
      "      vf_explained_var: 0.025438427925109863\n",
      "      vf_loss: 379.8464660644531\n",
      "    sample_time_ms: 19363.708\n",
      "    update_time_ms: 150.018\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 150.80871158659517\n",
      "  time_since_restore: 94.36350560188293\n",
      "  time_this_iter_s: 22.71379852294922\n",
      "  time_total_s: 94.36350560188293\n",
      "  timestamp: 1553709102\n",
      "  timesteps_since_restore: 40000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 4\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 94 s, 4 iter, 40000 ts, 302 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-52-05\n",
      "  done: false\n",
      "  episode_len_mean: 364.75\n",
      "  episode_reward_max: 704.4184270418435\n",
      "  episode_reward_mean: 401.7736814858727\n",
      "  episode_reward_min: -124.29876912235675\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 130\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4005.704\n",
      "    load_time_ms: 10.947\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 50000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.012500002980232239\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4155309200286865\n",
      "      kl: 0.004200597759336233\n",
      "      policy_loss: -0.0023207408376038074\n",
      "      total_loss: 554.90625\n",
      "      vf_explained_var: 0.04257660731673241\n",
      "      vf_loss: 554.908447265625\n",
      "    sample_time_ms: 19247.358\n",
      "    update_time_ms: 121.126\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 200.8868407429364\n",
      "  time_since_restore: 117.05864429473877\n",
      "  time_this_iter_s: 22.695138692855835\n",
      "  time_total_s: 117.05864429473877\n",
      "  timestamp: 1553709125\n",
      "  timesteps_since_restore: 50000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 5\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 117 s, 5 iter, 50000 ts, 402 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-52-28\n",
      "  done: false\n",
      "  episode_len_mean: 318.89\n",
      "  episode_reward_max: 704.4184270418435\n",
      "  episode_reward_mean: 467.9996323150662\n",
      "  episode_reward_min: -124.29876912235675\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 166\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3991.273\n",
      "    load_time_ms: 9.38\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.006250001490116119\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4083789587020874\n",
      "      kl: 0.0065506016835570335\n",
      "      policy_loss: -0.0018383318092674017\n",
      "      total_loss: 713.6946411132812\n",
      "      vf_explained_var: 0.04621487855911255\n",
      "      vf_loss: 713.6964111328125\n",
      "    sample_time_ms: 19213.368\n",
      "    update_time_ms: 101.681\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 233.99981615753305\n",
      "  time_since_restore: 140.04441666603088\n",
      "  time_this_iter_s: 22.985772371292114\n",
      "  time_total_s: 140.04441666603088\n",
      "  timestamp: 1553709148\n",
      "  timesteps_since_restore: 60000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 6\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 140 s, 6 iter, 60000 ts, 468 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-52-51\n",
      "  done: false\n",
      "  episode_len_mean: 276.62\n",
      "  episode_reward_max: 725.7247032741352\n",
      "  episode_reward_mean: 467.08896804415747\n",
      "  episode_reward_min: -128.27920916513597\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 206\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3976.177\n",
      "    load_time_ms: 8.266\n",
      "    num_steps_sampled: 70000\n",
      "    num_steps_trained: 70000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0031250007450580597\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4228006601333618\n",
      "      kl: 0.003563842037692666\n",
      "      policy_loss: -0.0010653423378244042\n",
      "      total_loss: 875.6796875\n",
      "      vf_explained_var: 0.05754270777106285\n",
      "      vf_loss: 875.6806640625\n",
      "    sample_time_ms: 19205.952\n",
      "    update_time_ms: 87.824\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 233.54448402207868\n",
      "  time_since_restore: 163.11689615249634\n",
      "  time_this_iter_s: 23.072479486465454\n",
      "  time_total_s: 163.11689615249634\n",
      "  timestamp: 1553709171\n",
      "  timesteps_since_restore: 70000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 70000\n",
      "  training_iteration: 7\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 163 s, 7 iter, 70000 ts, 467 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-53-14\n",
      "  done: false\n",
      "  episode_len_mean: 247.73\n",
      "  episode_reward_max: 725.7247032741352\n",
      "  episode_reward_mean: 443.8056202565169\n",
      "  episode_reward_min: -128.27920916513597\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 248\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3966.105\n",
      "    load_time_ms: 7.41\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0015625003725290298\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.420965313911438\n",
      "      kl: 0.004601502791047096\n",
      "      policy_loss: -0.0011023209663107991\n",
      "      total_loss: 912.8743286132812\n",
      "      vf_explained_var: 0.08256784826517105\n",
      "      vf_loss: 912.8754272460938\n",
      "    sample_time_ms: 19172.656\n",
      "    update_time_ms: 77.496\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 221.90281012825847\n",
      "  time_since_restore: 185.97577452659607\n",
      "  time_this_iter_s: 22.85887837409973\n",
      "  time_total_s: 185.97577452659607\n",
      "  timestamp: 1553709194\n",
      "  timesteps_since_restore: 80000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 8\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 185 s, 8 iter, 80000 ts, 444 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-53-37\n",
      "  done: false\n",
      "  episode_len_mean: 231.5\n",
      "  episode_reward_max: 703.8047163316189\n",
      "  episode_reward_mean: 459.38965872008754\n",
      "  episode_reward_min: -137.14523450074736\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 294\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3956.177\n",
      "    load_time_ms: 6.812\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0007812501862645149\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4299219846725464\n",
      "      kl: 0.011639357544481754\n",
      "      policy_loss: -0.003163591492921114\n",
      "      total_loss: 1102.625\n",
      "      vf_explained_var: 0.06456678360700607\n",
      "      vf_loss: 1102.6280517578125\n",
      "    sample_time_ms: 19183.479\n",
      "    update_time_ms: 69.523\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 229.6948293600438\n",
      "  time_since_restore: 209.15018510818481\n",
      "  time_this_iter_s: 23.174410581588745\n",
      "  time_total_s: 209.15018510818481\n",
      "  timestamp: 1553709217\n",
      "  timesteps_since_restore: 90000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 9\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 209 s, 9 iter, 90000 ts, 459 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-54-00\n",
      "  done: false\n",
      "  episode_len_mean: 207.66\n",
      "  episode_reward_max: 722.2168823420557\n",
      "  episode_reward_mean: 424.21588456298406\n",
      "  episode_reward_min: -137.14523450074736\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 345\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3947.491\n",
      "    load_time_ms: 6.297\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0007812501862645149\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.426088809967041\n",
      "      kl: 0.006796757224947214\n",
      "      policy_loss: -0.0017963395221158862\n",
      "      total_loss: 1170.46533203125\n",
      "      vf_explained_var: 0.09798017889261246\n",
      "      vf_loss: 1170.4671630859375\n",
      "    sample_time_ms: 19177.469\n",
      "    update_time_ms: 63.171\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 212.10794228149206\n",
      "  time_since_restore: 232.16835236549377\n",
      "  time_this_iter_s: 23.01816725730896\n",
      "  time_total_s: 232.16835236549377\n",
      "  timestamp: 1553709240\n",
      "  timesteps_since_restore: 100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 10\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 232 s, 10 iter, 100000 ts, 424 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-54-24\n",
      "  done: false\n",
      "  episode_len_mean: 195.31\n",
      "  episode_reward_max: 722.2168823420557\n",
      "  episode_reward_mean: 429.1218085063419\n",
      "  episode_reward_min: -133.64956861302542\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 397\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.224\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 110000\n",
      "    num_steps_trained: 110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00039062509313225746\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.41211998462677\n",
      "      kl: 0.004875446669757366\n",
      "      policy_loss: -0.00132059957832098\n",
      "      total_loss: 1263.8843994140625\n",
      "      vf_explained_var: 0.06937707215547562\n",
      "      vf_loss: 1263.8858642578125\n",
      "    sample_time_ms: 19023.591\n",
      "    update_time_ms: 5.947\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 214.560904253171\n",
      "  time_since_restore: 255.43005442619324\n",
      "  time_this_iter_s: 23.261702060699463\n",
      "  time_total_s: 255.43005442619324\n",
      "  timestamp: 1553709264\n",
      "  timesteps_since_restore: 110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 110000\n",
      "  training_iteration: 11\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 255 s, 11 iter, 110000 ts, 429 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-54-47\n",
      "  done: false\n",
      "  episode_len_mean: 190.96\n",
      "  episode_reward_max: 722.5069973967327\n",
      "  episode_reward_mean: 473.8336096407514\n",
      "  episode_reward_min: -122.99835937953029\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 450\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3893.156\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00019531254656612873\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.398789405822754\n",
      "      kl: 0.007129775360226631\n",
      "      policy_loss: -0.0024031384382396936\n",
      "      total_loss: 1514.4849853515625\n",
      "      vf_explained_var: 0.039721451699733734\n",
      "      vf_loss: 1514.4874267578125\n",
      "    sample_time_ms: 19045.765\n",
      "    update_time_ms: 5.484\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 236.9168048203757\n",
      "  time_since_restore: 278.3285586833954\n",
      "  time_this_iter_s: 22.89850425720215\n",
      "  time_total_s: 278.3285586833954\n",
      "  timestamp: 1553709287\n",
      "  timesteps_since_restore: 120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 12\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 278 s, 12 iter, 120000 ts, 474 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-55-10\n",
      "  done: false\n",
      "  episode_len_mean: 176.22\n",
      "  episode_reward_max: 728.9976907491517\n",
      "  episode_reward_mean: 446.3496596593888\n",
      "  episode_reward_min: -118.16920765877015\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 510\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3887.918\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 130000\n",
      "    num_steps_trained: 130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.765627328306437e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3968532085418701\n",
      "      kl: 0.0036704789381474257\n",
      "      policy_loss: -0.001937607885338366\n",
      "      total_loss: 1624.9534912109375\n",
      "      vf_explained_var: 0.021359069272875786\n",
      "      vf_loss: 1624.9552001953125\n",
      "    sample_time_ms: 19058.857\n",
      "    update_time_ms: 5.434\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 223.1748298296944\n",
      "  time_since_restore: 301.37389063835144\n",
      "  time_this_iter_s: 23.045331954956055\n",
      "  time_total_s: 301.37389063835144\n",
      "  timestamp: 1553709310\n",
      "  timesteps_since_restore: 130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 130000\n",
      "  training_iteration: 13\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 301 s, 13 iter, 130000 ts, 446 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-55-33\n",
      "  done: false\n",
      "  episode_len_mean: 164.63\n",
      "  episode_reward_max: 730.6442966442866\n",
      "  episode_reward_mean: 391.9212058090849\n",
      "  episode_reward_min: -130.15374703347538\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 574\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.371\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.882813664153218e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4031109809875488\n",
      "      kl: 0.005056922324001789\n",
      "      policy_loss: -0.001414140104316175\n",
      "      total_loss: 1729.03369140625\n",
      "      vf_explained_var: 0.027750572189688683\n",
      "      vf_loss: 1729.0352783203125\n",
      "    sample_time_ms: 19105.47\n",
      "    update_time_ms: 5.3\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 195.96060290454244\n",
      "  time_since_restore: 324.5589461326599\n",
      "  time_this_iter_s: 23.18505549430847\n",
      "  time_total_s: 324.5589461326599\n",
      "  timestamp: 1553709333\n",
      "  timesteps_since_restore: 140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 14\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 324 s, 14 iter, 140000 ts, 392 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-55-56\n",
      "  done: false\n",
      "  episode_len_mean: 160.99\n",
      "  episode_reward_max: 716.5063599347711\n",
      "  episode_reward_mean: 394.41287160711136\n",
      "  episode_reward_min: -135.4487268888107\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 632\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.869\n",
      "    load_time_ms: 1.675\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.400213599205017\n",
      "      kl: 0.0036793816834688187\n",
      "      policy_loss: -0.0011843893444165587\n",
      "      total_loss: 1652.304931640625\n",
      "      vf_explained_var: 0.059161823242902756\n",
      "      vf_loss: 1652.3060302734375\n",
      "    sample_time_ms: 19137.939\n",
      "    update_time_ms: 5.339\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 197.20643580355573\n",
      "  time_since_restore: 347.59469270706177\n",
      "  time_this_iter_s: 23.035746574401855\n",
      "  time_total_s: 347.59469270706177\n",
      "  timestamp: 1553709356\n",
      "  timesteps_since_restore: 150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 15\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 347 s, 15 iter, 150000 ts, 394 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-56-21\n",
      "  done: false\n",
      "  episode_len_mean: 167.1\n",
      "  episode_reward_max: 716.5063599347711\n",
      "  episode_reward_mean: 464.6743421407693\n",
      "  episode_reward_min: -135.4487268888107\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 692\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3929.808\n",
      "    load_time_ms: 1.732\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2207034160383046e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3936996459960938\n",
      "      kl: 0.004914384800940752\n",
      "      policy_loss: -0.002226155251264572\n",
      "      total_loss: 1710.25\n",
      "      vf_explained_var: 0.04532614350318909\n",
      "      vf_loss: 1710.252197265625\n",
      "    sample_time_ms: 19302.436\n",
      "    update_time_ms: 5.346\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 232.33717107038464\n",
      "  time_since_restore: 372.6280541419983\n",
      "  time_this_iter_s: 25.033361434936523\n",
      "  time_total_s: 372.6280541419983\n",
      "  timestamp: 1553709381\n",
      "  timesteps_since_restore: 160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 16\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 372 s, 16 iter, 160000 ts, 465 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-56-47\n",
      "  done: false\n",
      "  episode_len_mean: 167.29\n",
      "  episode_reward_max: 717.0755032543003\n",
      "  episode_reward_mean: 474.66708026984185\n",
      "  episode_reward_min: -112.35038403251906\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 752\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3972.516\n",
      "    load_time_ms: 1.748\n",
      "    num_steps_sampled: 170000\n",
      "    num_steps_trained: 170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.103517080191523e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3909573554992676\n",
      "      kl: 0.004349222406744957\n",
      "      policy_loss: -0.0021451611537486315\n",
      "      total_loss: 1834.3521728515625\n",
      "      vf_explained_var: 0.05735917016863823\n",
      "      vf_loss: 1834.3541259765625\n",
      "    sample_time_ms: 19499.399\n",
      "    update_time_ms: 5.413\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 237.33354013492092\n",
      "  time_since_restore: 398.09718799591064\n",
      "  time_this_iter_s: 25.469133853912354\n",
      "  time_total_s: 398.09718799591064\n",
      "  timestamp: 1553709407\n",
      "  timesteps_since_restore: 170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 170000\n",
      "  training_iteration: 17\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 398 s, 17 iter, 170000 ts, 475 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-57-17\n",
      "  done: false\n",
      "  episode_len_mean: 150.42\n",
      "  episode_reward_max: 730.6667371106788\n",
      "  episode_reward_mean: 389.49952299645497\n",
      "  episode_reward_min: -129.31626056286524\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 822\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4108.297\n",
      "    load_time_ms: 1.81\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3863489627838135\n",
      "      kl: 0.006132601760327816\n",
      "      policy_loss: -0.0026705432683229446\n",
      "      total_loss: 1952.4647216796875\n",
      "      vf_explained_var: 0.05784684047102928\n",
      "      vf_loss: 1952.4674072265625\n",
      "    sample_time_ms: 20093.112\n",
      "    update_time_ms: 5.317\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 194.74976149822746\n",
      "  time_since_restore: 428.2518517971039\n",
      "  time_this_iter_s: 30.154663801193237\n",
      "  time_total_s: 428.2518517971039\n",
      "  timestamp: 1553709437\n",
      "  timesteps_since_restore: 180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 18\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 428 s, 18 iter, 180000 ts, 389 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-57-43\n",
      "  done: false\n",
      "  episode_len_mean: 156.38\n",
      "  episode_reward_max: 758.0305954755961\n",
      "  episode_reward_mean: 448.21279869323286\n",
      "  episode_reward_min: -129.31626056286524\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 885\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4129.924\n",
      "    load_time_ms: 1.742\n",
      "    num_steps_sampled: 190000\n",
      "    num_steps_trained: 190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5258792700478807e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3789676427841187\n",
      "      kl: 0.0042306953109800816\n",
      "      policy_loss: -0.001424213289283216\n",
      "      total_loss: 1957.7371826171875\n",
      "      vf_explained_var: 0.10464901477098465\n",
      "      vf_loss: 1957.73876953125\n",
      "    sample_time_ms: 20346.129\n",
      "    update_time_ms: 5.332\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 224.1063993466163\n",
      "  time_since_restore: 454.1685440540314\n",
      "  time_this_iter_s: 25.91669225692749\n",
      "  time_total_s: 454.1685440540314\n",
      "  timestamp: 1553709463\n",
      "  timesteps_since_restore: 190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 190000\n",
      "  training_iteration: 19\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 454 s, 19 iter, 190000 ts, 448 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-58-07\n",
      "  done: false\n",
      "  episode_len_mean: 145.54\n",
      "  episode_reward_max: 758.0305954755961\n",
      "  episode_reward_mean: 408.10452914392874\n",
      "  episode_reward_min: -129.8709265911329\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 957\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4149.769\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.629396350239404e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.387325406074524\n",
      "      kl: 0.006841291207820177\n",
      "      policy_loss: -0.002796859247609973\n",
      "      total_loss: 2002.85595703125\n",
      "      vf_explained_var: 0.12497781217098236\n",
      "      vf_loss: 2002.8585205078125\n",
      "    sample_time_ms: 20440.874\n",
      "    update_time_ms: 5.277\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 204.0522645719644\n",
      "  time_since_restore: 478.3328425884247\n",
      "  time_this_iter_s: 24.16429853439331\n",
      "  time_total_s: 478.3328425884247\n",
      "  timestamp: 1553709487\n",
      "  timesteps_since_restore: 200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 20\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 478 s, 20 iter, 200000 ts, 408 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-58-31\n",
      "  done: false\n",
      "  episode_len_mean: 146.28\n",
      "  episode_reward_max: 707.2048169168594\n",
      "  episode_reward_mean: 442.3679700701285\n",
      "  episode_reward_min: -129.8709265911329\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 1024\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4164.347\n",
      "    load_time_ms: 1.749\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.814698175119702e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3675594329833984\n",
      "      kl: 0.005981595255434513\n",
      "      policy_loss: -0.002467624144628644\n",
      "      total_loss: 2126.352294921875\n",
      "      vf_explained_var: 0.06819209456443787\n",
      "      vf_loss: 2126.35498046875\n",
      "    sample_time_ms: 20542.782\n",
      "    update_time_ms: 5.328\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 221.18398503506432\n",
      "  time_since_restore: 502.7576804161072\n",
      "  time_this_iter_s: 24.424837827682495\n",
      "  time_total_s: 502.7576804161072\n",
      "  timestamp: 1553709511\n",
      "  timesteps_since_restore: 210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 21\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 502 s, 21 iter, 210000 ts, 442 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-58-55\n",
      "  done: false\n",
      "  episode_len_mean: 133.63\n",
      "  episode_reward_max: 707.2048169168594\n",
      "  episode_reward_mean: 395.8934197377254\n",
      "  episode_reward_min: -133.8188883367481\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 1101\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4162.892\n",
      "    load_time_ms: 1.773\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.907349087559851e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.379974603652954\n",
      "      kl: 0.004213887732475996\n",
      "      policy_loss: -0.0016978237545117736\n",
      "      total_loss: 2292.095458984375\n",
      "      vf_explained_var: 0.10830944031476974\n",
      "      vf_loss: 2292.096923828125\n",
      "    sample_time_ms: 20580.121\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 197.94670986886268\n",
      "  time_since_restore: 526.0166783332825\n",
      "  time_this_iter_s: 23.258997917175293\n",
      "  time_total_s: 526.0166783332825\n",
      "  timestamp: 1553709535\n",
      "  timesteps_since_restore: 220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 22\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 526 s, 22 iter, 220000 ts, 396 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-59-18\n",
      "  done: false\n",
      "  episode_len_mean: 135.77\n",
      "  episode_reward_max: 724.989968674645\n",
      "  episode_reward_mean: 417.72355531460227\n",
      "  episode_reward_min: -134.63897756742244\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 1174\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4161.453\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 230000\n",
      "    num_steps_trained: 230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.536745437799254e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3649425506591797\n",
      "      kl: 0.005657185334712267\n",
      "      policy_loss: -0.002379455603659153\n",
      "      total_loss: 2218.49267578125\n",
      "      vf_explained_var: 0.11984924226999283\n",
      "      vf_loss: 2218.494873046875\n",
      "    sample_time_ms: 20598.028\n",
      "    update_time_ms: 5.386\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 208.86177765730113\n",
      "  time_since_restore: 549.224879026413\n",
      "  time_this_iter_s: 23.208200693130493\n",
      "  time_total_s: 549.224879026413\n",
      "  timestamp: 1553709558\n",
      "  timesteps_since_restore: 230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 230000\n",
      "  training_iteration: 23\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 549 s, 23 iter, 230000 ts, 418 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_18-59-41\n",
      "  done: false\n",
      "  episode_len_mean: 135.15\n",
      "  episode_reward_max: 710.0445719032666\n",
      "  episode_reward_mean: 422.0900281710034\n",
      "  episode_reward_min: -134.63897756742244\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 1249\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4161.585\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.768372718899627e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3675154447555542\n",
      "      kl: 0.0031731631606817245\n",
      "      policy_loss: -0.0012248334242030978\n",
      "      total_loss: 2243.862548828125\n",
      "      vf_explained_var: 0.18257607519626617\n",
      "      vf_loss: 2243.86376953125\n",
      "    sample_time_ms: 20605.982\n",
      "    update_time_ms: 5.474\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 211.0450140855017\n",
      "  time_since_restore: 572.4920122623444\n",
      "  time_this_iter_s: 23.267133235931396\n",
      "  time_total_s: 572.4920122623444\n",
      "  timestamp: 1553709581\n",
      "  timesteps_since_restore: 240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 24\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 572 s, 24 iter, 240000 ts, 422 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-00-06\n",
      "  done: false\n",
      "  episode_len_mean: 127.99\n",
      "  episode_reward_max: 701.8987190182689\n",
      "  episode_reward_mean: 373.3424879965374\n",
      "  episode_reward_min: -132.89336695028683\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 1326\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4180.86\n",
      "    load_time_ms: 1.732\n",
      "    num_steps_sampled: 250000\n",
      "    num_steps_trained: 250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3841863594498136e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3652126789093018\n",
      "      kl: 0.00525289261713624\n",
      "      policy_loss: -0.002698643831536174\n",
      "      total_loss: 2389.7861328125\n",
      "      vf_explained_var: 0.1741791069507599\n",
      "      vf_loss: 2389.78857421875\n",
      "    sample_time_ms: 20771.041\n",
      "    update_time_ms: 5.44\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 186.67124399826872\n",
      "  time_since_restore: 597.3696727752686\n",
      "  time_this_iter_s: 24.877660512924194\n",
      "  time_total_s: 597.3696727752686\n",
      "  timestamp: 1553709606\n",
      "  timesteps_since_restore: 250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 250000\n",
      "  training_iteration: 25\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 597 s, 25 iter, 250000 ts, 373 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-00-31\n",
      "  done: false\n",
      "  episode_len_mean: 137.74\n",
      "  episode_reward_max: 704.4600282047999\n",
      "  episode_reward_mean: 455.25406224007975\n",
      "  episode_reward_min: -132.89336695028683\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1398\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4170.698\n",
      "    load_time_ms: 1.69\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1920931797249068e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3486086130142212\n",
      "      kl: 0.0039062961004674435\n",
      "      policy_loss: -0.00103323208168149\n",
      "      total_loss: 2411.21435546875\n",
      "      vf_explained_var: 0.10399938374757767\n",
      "      vf_loss: 2411.215087890625\n",
      "    sample_time_ms: 20806.792\n",
      "    update_time_ms: 5.648\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 227.6270311200399\n",
      "  time_since_restore: 622.6571497917175\n",
      "  time_this_iter_s: 25.287477016448975\n",
      "  time_total_s: 622.6571497917175\n",
      "  timestamp: 1553709631\n",
      "  timesteps_since_restore: 260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 26\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 622 s, 26 iter, 260000 ts, 455 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-00-55\n",
      "  done: false\n",
      "  episode_len_mean: 140.52\n",
      "  episode_reward_max: 730.2079272014522\n",
      "  episode_reward_mean: 492.46186563447003\n",
      "  episode_reward_min: -128.48078177786863\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 1472\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4140.205\n",
      "    load_time_ms: 1.664\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.960465898624534e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3438892364501953\n",
      "      kl: 0.004366246517747641\n",
      "      policy_loss: -0.002817105036228895\n",
      "      total_loss: 2403.70947265625\n",
      "      vf_explained_var: 0.1669815331697464\n",
      "      vf_loss: 2403.71240234375\n",
      "    sample_time_ms: 20653.011\n",
      "    update_time_ms: 5.704\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 246.23093281723507\n",
      "  time_since_restore: 646.2847158908844\n",
      "  time_this_iter_s: 23.62756609916687\n",
      "  time_total_s: 646.2847158908844\n",
      "  timestamp: 1553709655\n",
      "  timesteps_since_restore: 270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 27\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 646 s, 27 iter, 270000 ts, 492 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-01-20\n",
      "  done: false\n",
      "  episode_len_mean: 138.03\n",
      "  episode_reward_max: 727.707713371789\n",
      "  episode_reward_mean: 491.9277383391769\n",
      "  episode_reward_min: -123.90021808561823\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 1543\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4052.083\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.980232949312267e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3333371877670288\n",
      "      kl: 0.006693415343761444\n",
      "      policy_loss: -0.0021439946722239256\n",
      "      total_loss: 2476.849853515625\n",
      "      vf_explained_var: 0.08790915459394455\n",
      "      vf_loss: 2476.851806640625\n",
      "    sample_time_ms: 20201.994\n",
      "    update_time_ms: 5.881\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 245.96386916958852\n",
      "  time_since_restore: 671.0501816272736\n",
      "  time_this_iter_s: 24.76546573638916\n",
      "  time_total_s: 671.0501816272736\n",
      "  timestamp: 1553709680\n",
      "  timesteps_since_restore: 280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 28\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 671 s, 28 iter, 280000 ts, 492 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-01-44\n",
      "  done: false\n",
      "  episode_len_mean: 132.85\n",
      "  episode_reward_max: 736.8502062414697\n",
      "  episode_reward_mean: 443.7558187135348\n",
      "  episode_reward_min: -114.76603428020493\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 1620\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4068.946\n",
      "    load_time_ms: 1.671\n",
      "    num_steps_sampled: 290000\n",
      "    num_steps_trained: 290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4901164746561335e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.346569538116455\n",
      "      kl: 0.004825102165341377\n",
      "      policy_loss: -0.00230320543050766\n",
      "      total_loss: 2335.3076171875\n",
      "      vf_explained_var: 0.265637069940567\n",
      "      vf_loss: 2335.310302734375\n",
      "    sample_time_ms: 20032.413\n",
      "    update_time_ms: 5.872\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 221.8779093567673\n",
      "  time_since_restore: 695.4431643486023\n",
      "  time_this_iter_s: 24.392982721328735\n",
      "  time_total_s: 695.4431643486023\n",
      "  timestamp: 1553709704\n",
      "  timesteps_since_restore: 290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 290000\n",
      "  training_iteration: 29\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 695 s, 29 iter, 290000 ts, 444 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-02-11\n",
      "  done: false\n",
      "  episode_len_mean: 127.6\n",
      "  episode_reward_max: 762.2281204943552\n",
      "  episode_reward_mean: 408.0367685894578\n",
      "  episode_reward_min: -130.85051641726312\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 1696\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4116.75\n",
      "    load_time_ms: 1.634\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.450582373280668e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3384697437286377\n",
      "      kl: 0.003315624548122287\n",
      "      policy_loss: -0.001548656146042049\n",
      "      total_loss: 2489.140380859375\n",
      "      vf_explained_var: 0.15588589012622833\n",
      "      vf_loss: 2489.141845703125\n",
      "    sample_time_ms: 20216.809\n",
      "    update_time_ms: 5.83\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 204.01838429472892\n",
      "  time_since_restore: 721.9323463439941\n",
      "  time_this_iter_s: 26.489181995391846\n",
      "  time_total_s: 721.9323463439941\n",
      "  timestamp: 1553709731\n",
      "  timesteps_since_restore: 300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 30\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 721 s, 30 iter, 300000 ts, 408 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-02-37\n",
      "  done: false\n",
      "  episode_len_mean: 128.08\n",
      "  episode_reward_max: 713.1037261553691\n",
      "  episode_reward_mean: 420.86404755268563\n",
      "  episode_reward_min: -130.43910102040743\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 1774\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4126.425\n",
      "    load_time_ms: 1.67\n",
      "    num_steps_sampled: 310000\n",
      "    num_steps_trained: 310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.725291186640334e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3456332683563232\n",
      "      kl: 0.004308030474931002\n",
      "      policy_loss: -0.0024588804226368666\n",
      "      total_loss: 2508.85888671875\n",
      "      vf_explained_var: 0.17395877838134766\n",
      "      vf_loss: 2508.861328125\n",
      "    sample_time_ms: 20365.328\n",
      "    update_time_ms: 5.941\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 210.4320237763429\n",
      "  time_since_restore: 747.9429230690002\n",
      "  time_this_iter_s: 26.010576725006104\n",
      "  time_total_s: 747.9429230690002\n",
      "  timestamp: 1553709757\n",
      "  timesteps_since_restore: 310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 310000\n",
      "  training_iteration: 31\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 747 s, 31 iter, 310000 ts, 421 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-03-00\n",
      "  done: false\n",
      "  episode_len_mean: 134.1\n",
      "  episode_reward_max: 723.0972708662501\n",
      "  episode_reward_mean: 464.30649293869385\n",
      "  episode_reward_min: -121.7899142678809\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 1849\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4130.428\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.862645593320167e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.344096064567566\n",
      "      kl: 0.005527939181774855\n",
      "      policy_loss: -0.0031831329688429832\n",
      "      total_loss: 2477.631103515625\n",
      "      vf_explained_var: 0.23061503469944\n",
      "      vf_loss: 2477.634521484375\n",
      "    sample_time_ms: 20381.946\n",
      "    update_time_ms: 6.094\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 232.15324646934684\n",
      "  time_since_restore: 771.4088003635406\n",
      "  time_this_iter_s: 23.465877294540405\n",
      "  time_total_s: 771.4088003635406\n",
      "  timestamp: 1553709780\n",
      "  timesteps_since_restore: 320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 32\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 771 s, 32 iter, 320000 ts, 464 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-03-24\n",
      "  done: false\n",
      "  episode_len_mean: 126.29\n",
      "  episode_reward_max: 730.781161650334\n",
      "  episode_reward_mean: 400.30971741689876\n",
      "  episode_reward_min: -124.73604874002572\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 1927\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4135.479\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.313227966600834e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3414212465286255\n",
      "      kl: 0.005076657515019178\n",
      "      policy_loss: -0.0013022655621170998\n",
      "      total_loss: 2648.21484375\n",
      "      vf_explained_var: 0.12282726168632507\n",
      "      vf_loss: 2648.216064453125\n",
      "    sample_time_ms: 20384.186\n",
      "    update_time_ms: 5.912\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 200.15485870844938\n",
      "  time_since_restore: 794.6862990856171\n",
      "  time_this_iter_s: 23.277498722076416\n",
      "  time_total_s: 794.6862990856171\n",
      "  timestamp: 1553709804\n",
      "  timesteps_since_restore: 330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 33\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 794 s, 33 iter, 330000 ts, 400 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-03-47\n",
      "  done: false\n",
      "  episode_len_mean: 138.08\n",
      "  episode_reward_max: 714.2413004808823\n",
      "  episode_reward_mean: 489.122594607624\n",
      "  episode_reward_min: -125.55141349102571\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 2000\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4150.017\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.656613983300417e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3339693546295166\n",
      "      kl: 0.011726717464625835\n",
      "      policy_loss: -0.005008336156606674\n",
      "      total_loss: 2505.270751953125\n",
      "      vf_explained_var: 0.22918982803821564\n",
      "      vf_loss: 2505.275634765625\n",
      "    sample_time_ms: 20360.916\n",
      "    update_time_ms: 5.845\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 244.561297303812\n",
      "  time_since_restore: 817.8655455112457\n",
      "  time_this_iter_s: 23.179246425628662\n",
      "  time_total_s: 817.8655455112457\n",
      "  timestamp: 1553709827\n",
      "  timesteps_since_restore: 340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 34\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 817 s, 34 iter, 340000 ts, 489 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-04-10\n",
      "  done: false\n",
      "  episode_len_mean: 134.9\n",
      "  episode_reward_max: 716.5084233783863\n",
      "  episode_reward_mean: 485.43811676836805\n",
      "  episode_reward_min: -124.87893379867836\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 2075\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4133.793\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 350000\n",
      "    num_steps_trained: 350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.656613983300417e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.315513253211975\n",
      "      kl: 0.004126613959670067\n",
      "      policy_loss: -0.00106504384893924\n",
      "      total_loss: 2496.32080078125\n",
      "      vf_explained_var: 0.15363167226314545\n",
      "      vf_loss: 2496.32177734375\n",
      "    sample_time_ms: 20218.798\n",
      "    update_time_ms: 5.775\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 242.71905838418402\n",
      "  time_since_restore: 841.1596636772156\n",
      "  time_this_iter_s: 23.29411816596985\n",
      "  time_total_s: 841.1596636772156\n",
      "  timestamp: 1553709850\n",
      "  timesteps_since_restore: 350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 350000\n",
      "  training_iteration: 35\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 841 s, 35 iter, 350000 ts, 485 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-04-34\n",
      "  done: false\n",
      "  episode_len_mean: 133.28\n",
      "  episode_reward_max: 713.6996419441447\n",
      "  episode_reward_mean: 472.0702341894797\n",
      "  episode_reward_min: -124.87893379867836\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 2151\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4100.777\n",
      "    load_time_ms: 1.618\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3283069916502086e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3085132837295532\n",
      "      kl: 0.00498906010761857\n",
      "      policy_loss: -0.0017361222999170423\n",
      "      total_loss: 2551.864990234375\n",
      "      vf_explained_var: 0.2144719660282135\n",
      "      vf_loss: 2551.866943359375\n",
      "    sample_time_ms: 20043.566\n",
      "    update_time_ms: 5.655\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 236.03511709473983\n",
      "  time_since_restore: 864.3670506477356\n",
      "  time_this_iter_s: 23.20738697052002\n",
      "  time_total_s: 864.3670506477356\n",
      "  timestamp: 1553709874\n",
      "  timesteps_since_restore: 360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 36\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 864 s, 36 iter, 360000 ts, 472 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-04-57\n",
      "  done: false\n",
      "  episode_len_mean: 126.92\n",
      "  episode_reward_max: 687.0531439243897\n",
      "  episode_reward_mean: 440.0981595254489\n",
      "  episode_reward_min: -130.38178985600464\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 2231\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4090.354\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 370000\n",
      "    num_steps_trained: 370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1641534958251043e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3106931447982788\n",
      "      kl: 0.006823603063821793\n",
      "      policy_loss: -0.0025480585172772408\n",
      "      total_loss: 2724.37939453125\n",
      "      vf_explained_var: 0.13465912640094757\n",
      "      vf_loss: 2724.382080078125\n",
      "    sample_time_ms: 20012.095\n",
      "    update_time_ms: 5.602\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 220.04907976272443\n",
      "  time_since_restore: 887.5738396644592\n",
      "  time_this_iter_s: 23.206789016723633\n",
      "  time_total_s: 887.5738396644592\n",
      "  timestamp: 1553709897\n",
      "  timesteps_since_restore: 370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 370000\n",
      "  training_iteration: 37\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 887 s, 37 iter, 370000 ts, 440 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-05-20\n",
      "  done: false\n",
      "  episode_len_mean: 119.65\n",
      "  episode_reward_max: 709.6074538633757\n",
      "  episode_reward_mean: 391.96705815297247\n",
      "  episode_reward_min: -134.26803910498816\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 2316\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4044.632\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.8207674791255215e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3184036016464233\n",
      "      kl: 0.004462313372641802\n",
      "      policy_loss: -0.0031370543874800205\n",
      "      total_loss: 2861.1572265625\n",
      "      vf_explained_var: 0.1591426134109497\n",
      "      vf_loss: 2861.16015625\n",
      "    sample_time_ms: 19880.604\n",
      "    update_time_ms: 5.521\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 195.98352907648623\n",
      "  time_since_restore: 910.5670857429504\n",
      "  time_this_iter_s: 22.99324607849121\n",
      "  time_total_s: 910.5670857429504\n",
      "  timestamp: 1553709920\n",
      "  timesteps_since_restore: 380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 38\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 910 s, 38 iter, 380000 ts, 392 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-05-43\n",
      "  done: false\n",
      "  episode_len_mean: 132.04\n",
      "  episode_reward_max: 737.6240069446736\n",
      "  episode_reward_mean: 490.20152329211464\n",
      "  episode_reward_min: -126.80648404056944\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 2389\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4007.964\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9103837395627608e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.303122639656067\n",
      "      kl: 0.02174977771937847\n",
      "      policy_loss: -0.007262902334332466\n",
      "      total_loss: 2493.99609375\n",
      "      vf_explained_var: 0.18655990064144135\n",
      "      vf_loss: 2494.003662109375\n",
      "    sample_time_ms: 19778.931\n",
      "    update_time_ms: 5.503\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 245.10076164605732\n",
      "  time_since_restore: 933.5749320983887\n",
      "  time_this_iter_s: 23.007846355438232\n",
      "  time_total_s: 933.5749320983887\n",
      "  timestamp: 1553709943\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 39\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 933 s, 39 iter, 390000 ts, 490 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-06-06\n",
      "  done: false\n",
      "  episode_len_mean: 127.43\n",
      "  episode_reward_max: 765.0819638444409\n",
      "  episode_reward_mean: 442.22696675209926\n",
      "  episode_reward_min: -116.20982517603605\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 2468\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3943.376\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9103837395627608e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2994996309280396\n",
      "      kl: 0.0047079576179385185\n",
      "      policy_loss: -0.001865274622105062\n",
      "      total_loss: 2800.6826171875\n",
      "      vf_explained_var: 0.15536902844905853\n",
      "      vf_loss: 2800.684814453125\n",
      "    sample_time_ms: 19545.603\n",
      "    update_time_ms: 5.581\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 221.11348337604963\n",
      "  time_since_restore: 957.0812442302704\n",
      "  time_this_iter_s: 23.506312131881714\n",
      "  time_total_s: 957.0812442302704\n",
      "  timestamp: 1553709966\n",
      "  timesteps_since_restore: 400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 40\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 957 s, 40 iter, 400000 ts, 442 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-06-31\n",
      "  done: false\n",
      "  episode_len_mean: 127.88\n",
      "  episode_reward_max: 686.7240162643748\n",
      "  episode_reward_mean: 439.8855016977106\n",
      "  episode_reward_min: -127.69219945612467\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 2548\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3915.981\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 410000\n",
      "    num_steps_trained: 410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4551918697813804e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3232572078704834\n",
      "      kl: 0.007009959314018488\n",
      "      policy_loss: -0.00318842101842165\n",
      "      total_loss: 2670.00732421875\n",
      "      vf_explained_var: 0.1792502999305725\n",
      "      vf_loss: 2670.010498046875\n",
      "    sample_time_ms: 19416.705\n",
      "    update_time_ms: 5.379\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 219.9427508488553\n",
      "  time_since_restore: 981.5265481472015\n",
      "  time_this_iter_s: 24.445303916931152\n",
      "  time_total_s: 981.5265481472015\n",
      "  timestamp: 1553709991\n",
      "  timesteps_since_restore: 410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 410000\n",
      "  training_iteration: 41\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 981 s, 41 iter, 410000 ts, 440 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-06-54\n",
      "  done: false\n",
      "  episode_len_mean: 134.03\n",
      "  episode_reward_max: 730.6348500700313\n",
      "  episode_reward_mean: 476.0003997507525\n",
      "  episode_reward_min: -96.36198365998655\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 2624\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3913.33\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.275959348906902e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3035980463027954\n",
      "      kl: 0.007059160619974136\n",
      "      policy_loss: -0.0026914896443486214\n",
      "      total_loss: 2563.987060546875\n",
      "      vf_explained_var: 0.1852651685476303\n",
      "      vf_loss: 2563.989990234375\n",
      "    sample_time_ms: 19388.069\n",
      "    update_time_ms: 5.362\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 238.00019987537627\n",
      "  time_since_restore: 1004.679212808609\n",
      "  time_this_iter_s: 23.15266466140747\n",
      "  time_total_s: 1004.679212808609\n",
      "  timestamp: 1553710014\n",
      "  timesteps_since_restore: 420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 42\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1004 s, 42 iter, 420000 ts, 476 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-07-17\n",
      "  done: false\n",
      "  episode_len_mean: 132.78\n",
      "  episode_reward_max: 743.9093424686085\n",
      "  episode_reward_mean: 477.5102589148579\n",
      "  episode_reward_min: -129.48757133710615\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 2697\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3912.77\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 430000\n",
      "    num_steps_trained: 430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.637979674453451e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.295699954032898\n",
      "      kl: 0.005025557707995176\n",
      "      policy_loss: -0.0017113593639805913\n",
      "      total_loss: 2524.302001953125\n",
      "      vf_explained_var: 0.13473643362522125\n",
      "      vf_loss: 2524.3037109375\n",
      "    sample_time_ms: 19387.874\n",
      "    update_time_ms: 5.453\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 238.75512945742892\n",
      "  time_since_restore: 1027.953242778778\n",
      "  time_this_iter_s: 23.274029970169067\n",
      "  time_total_s: 1027.953242778778\n",
      "  timestamp: 1553710037\n",
      "  timesteps_since_restore: 430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 430000\n",
      "  training_iteration: 43\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1027 s, 43 iter, 430000 ts, 478 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-07-41\n",
      "  done: false\n",
      "  episode_len_mean: 132.96\n",
      "  episode_reward_max: 722.0946339316317\n",
      "  episode_reward_mean: 482.1821206965112\n",
      "  episode_reward_min: -101.58232899073377\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 2774\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.905\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8189898372267255e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3018484115600586\n",
      "      kl: 0.007025898899883032\n",
      "      policy_loss: -0.002009426709264517\n",
      "      total_loss: 2645.56982421875\n",
      "      vf_explained_var: 0.27791959047317505\n",
      "      vf_loss: 2645.57177734375\n",
      "    sample_time_ms: 19424.379\n",
      "    update_time_ms: 5.405\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 241.09106034825555\n",
      "  time_since_restore: 1051.3381021022797\n",
      "  time_this_iter_s: 23.384859323501587\n",
      "  time_total_s: 1051.3381021022797\n",
      "  timestamp: 1553710061\n",
      "  timesteps_since_restore: 440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 44\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1051 s, 44 iter, 440000 ts, 482 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-08-05\n",
      "  done: false\n",
      "  episode_len_mean: 131.6\n",
      "  episode_reward_max: 695.9207121658435\n",
      "  episode_reward_mean: 461.9621139659859\n",
      "  episode_reward_min: -135.43312077054014\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 2849\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3895.44\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.094949186133627e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3045005798339844\n",
      "      kl: 0.006307125091552734\n",
      "      policy_loss: -0.0032462324015796185\n",
      "      total_loss: 2610.394287109375\n",
      "      vf_explained_var: 0.18622815608978271\n",
      "      vf_loss: 2610.3974609375\n",
      "    sample_time_ms: 19463.237\n",
      "    update_time_ms: 5.36\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 230.98105698299295\n",
      "  time_since_restore: 1075.0067598819733\n",
      "  time_this_iter_s: 23.668657779693604\n",
      "  time_total_s: 1075.0067598819733\n",
      "  timestamp: 1553710085\n",
      "  timesteps_since_restore: 450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 45\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1075 s, 45 iter, 450000 ts, 462 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-08-29\n",
      "  done: false\n",
      "  episode_len_mean: 130.58\n",
      "  episode_reward_max: 715.6559532783464\n",
      "  episode_reward_mean: 456.5536709925324\n",
      "  episode_reward_min: -135.49707665787162\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 2926\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3931.032\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.5474745930668137e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3035367727279663\n",
      "      kl: 0.00948671530932188\n",
      "      policy_loss: -0.004032130353152752\n",
      "      total_loss: 2770.953857421875\n",
      "      vf_explained_var: 0.0866338312625885\n",
      "      vf_loss: 2770.9580078125\n",
      "    sample_time_ms: 19525.529\n",
      "    update_time_ms: 5.257\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 228.27683549626622\n",
      "  time_since_restore: 1099.190013408661\n",
      "  time_this_iter_s: 24.183253526687622\n",
      "  time_total_s: 1099.190013408661\n",
      "  timestamp: 1553710109\n",
      "  timesteps_since_restore: 460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 46\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1099 s, 46 iter, 460000 ts, 457 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-08-56\n",
      "  done: false\n",
      "  episode_len_mean: 138.64\n",
      "  episode_reward_max: 725.1772806611514\n",
      "  episode_reward_mean: 529.1153018280087\n",
      "  episode_reward_min: -127.1094298833508\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 2999\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4007.707\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 470000\n",
      "    num_steps_trained: 470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2737372965334068e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2928242683410645\n",
      "      kl: 0.00824538990855217\n",
      "      policy_loss: -0.0026921152602881193\n",
      "      total_loss: 2623.126708984375\n",
      "      vf_explained_var: 0.06437323987483978\n",
      "      vf_loss: 2623.129638671875\n",
      "    sample_time_ms: 19797.207\n",
      "    update_time_ms: 5.173\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 264.5576509140044\n",
      "  time_since_restore: 1125.880520582199\n",
      "  time_this_iter_s: 26.690507173538208\n",
      "  time_total_s: 1125.880520582199\n",
      "  timestamp: 1553710136\n",
      "  timesteps_since_restore: 470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 470000\n",
      "  training_iteration: 47\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1125 s, 47 iter, 470000 ts, 529 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-09-21\n",
      "  done: false\n",
      "  episode_len_mean: 133.97\n",
      "  episode_reward_max: 707.7541856785032\n",
      "  episode_reward_mean: 498.94024491841975\n",
      "  episode_reward_min: -124.44992196712356\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 3075\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4026.751\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1368686482667034e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3061801195144653\n",
      "      kl: 0.01776071824133396\n",
      "      policy_loss: -0.005919204093515873\n",
      "      total_loss: 2707.55859375\n",
      "      vf_explained_var: 0.08284465968608856\n",
      "      vf_loss: 2707.564453125\n",
      "    sample_time_ms: 19986.84\n",
      "    update_time_ms: 5.274\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 249.47012245920988\n",
      "  time_since_restore: 1150.9626824855804\n",
      "  time_this_iter_s: 25.082161903381348\n",
      "  time_total_s: 1150.9626824855804\n",
      "  timestamp: 1553710161\n",
      "  timesteps_since_restore: 480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 48\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1150 s, 48 iter, 480000 ts, 499 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-09-45\n",
      "  done: false\n",
      "  episode_len_mean: 136.1\n",
      "  episode_reward_max: 714.5755474450382\n",
      "  episode_reward_mean: 512.4909851295939\n",
      "  episode_reward_min: -122.43492463429585\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 3148\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4038.901\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 490000\n",
      "    num_steps_trained: 490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1368686482667034e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2990121841430664\n",
      "      kl: 0.006125777028501034\n",
      "      policy_loss: -0.0031429000664502382\n",
      "      total_loss: 2690.846435546875\n",
      "      vf_explained_var: 0.013382547535002232\n",
      "      vf_loss: 2690.849853515625\n",
      "    sample_time_ms: 20104.316\n",
      "    update_time_ms: 5.542\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 256.24549256479696\n",
      "  time_since_restore: 1175.2689497470856\n",
      "  time_this_iter_s: 24.306267261505127\n",
      "  time_total_s: 1175.2689497470856\n",
      "  timestamp: 1553710185\n",
      "  timesteps_since_restore: 490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 490000\n",
      "  training_iteration: 49\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1175 s, 49 iter, 490000 ts, 512 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-10-09\n",
      "  done: false\n",
      "  episode_len_mean: 137.52\n",
      "  episode_reward_max: 730.6449464202245\n",
      "  episode_reward_mean: 523.9062620174074\n",
      "  episode_reward_min: -118.61261929475377\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 3222\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4043.741\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.684343241333517e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.288338303565979\n",
      "      kl: 0.014501417055726051\n",
      "      policy_loss: -0.005703396629542112\n",
      "      total_loss: 2747.9794921875\n",
      "      vf_explained_var: 0.008733673021197319\n",
      "      vf_loss: 2747.9853515625\n",
      "    sample_time_ms: 20185.007\n",
      "    update_time_ms: 5.532\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 261.95313100870374\n",
      "  time_since_restore: 1199.6329262256622\n",
      "  time_this_iter_s: 24.36397647857666\n",
      "  time_total_s: 1199.6329262256622\n",
      "  timestamp: 1553710209\n",
      "  timesteps_since_restore: 500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 50\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1199 s, 50 iter, 500000 ts, 524 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-10-33\n",
      "  done: false\n",
      "  episode_len_mean: 133.24\n",
      "  episode_reward_max: 746.7032016681628\n",
      "  episode_reward_mean: 493.4028922697118\n",
      "  episode_reward_min: -131.5152900186305\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 3299\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4042.092\n",
      "    load_time_ms: 1.698\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.684343241333517e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.288209319114685\n",
      "      kl: 0.010686201974749565\n",
      "      policy_loss: -0.0036168487276881933\n",
      "      total_loss: 2932.39697265625\n",
      "      vf_explained_var: 0.018453245982527733\n",
      "      vf_loss: 2932.401123046875\n",
      "    sample_time_ms: 20127.8\n",
      "    update_time_ms: 5.57\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 246.70144613485593\n",
      "  time_since_restore: 1223.4914157390594\n",
      "  time_this_iter_s: 23.858489513397217\n",
      "  time_total_s: 1223.4914157390594\n",
      "  timestamp: 1553710233\n",
      "  timesteps_since_restore: 510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 51\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1223 s, 51 iter, 510000 ts, 493 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-10-57\n",
      "  done: false\n",
      "  episode_len_mean: 137.22\n",
      "  episode_reward_max: 738.5582085096108\n",
      "  episode_reward_mean: 522.5657811254688\n",
      "  episode_reward_min: -127.98973472322376\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 3373\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4078.438\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.684343241333517e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2873010635375977\n",
      "      kl: 0.01885336823761463\n",
      "      policy_loss: -0.005138660315424204\n",
      "      total_loss: 2831.51806640625\n",
      "      vf_explained_var: 0.09385790675878525\n",
      "      vf_loss: 2831.523193359375\n",
      "    sample_time_ms: 20175.399\n",
      "    update_time_ms: 5.475\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 261.28289056273445\n",
      "  time_since_restore: 1247.4825563430786\n",
      "  time_this_iter_s: 23.991140604019165\n",
      "  time_total_s: 1247.4825563430786\n",
      "  timestamp: 1553710257\n",
      "  timesteps_since_restore: 520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 52\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1247 s, 52 iter, 520000 ts, 523 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 137.65\n",
      "  episode_reward_max: 708.8518944875369\n",
      "  episode_reward_mean: 527.1118191367983\n",
      "  episode_reward_min: -101.46626850064047\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 3447\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4140.504\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 530000\n",
      "    num_steps_trained: 530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.684343241333517e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2936547994613647\n",
      "      kl: 0.0068856156431138515\n",
      "      policy_loss: -0.002897507743909955\n",
      "      total_loss: 2705.585205078125\n",
      "      vf_explained_var: 0.16027526557445526\n",
      "      vf_loss: 2705.587890625\n",
      "    sample_time_ms: 20643.644\n",
      "    update_time_ms: 5.431\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 263.5559095683991\n",
      "  time_since_restore: 1276.0593621730804\n",
      "  time_this_iter_s: 28.57680583000183\n",
      "  time_total_s: 1276.0593621730804\n",
      "  timestamp: 1553710286\n",
      "  timesteps_since_restore: 530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 530000\n",
      "  training_iteration: 53\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1276 s, 53 iter, 530000 ts, 527 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-11-53\n",
      "  done: false\n",
      "  episode_len_mean: 140.87\n",
      "  episode_reward_max: 744.6586005870003\n",
      "  episode_reward_mean: 542.8647216109296\n",
      "  episode_reward_min: -126.60037338774016\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3519\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4151.855\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.8421716206667585e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2877068519592285\n",
      "      kl: 0.009397830814123154\n",
      "      policy_loss: -0.002548698103055358\n",
      "      total_loss: 2375.29638671875\n",
      "      vf_explained_var: 0.28303253650665283\n",
      "      vf_loss: 2375.29931640625\n",
      "    sample_time_ms: 21028.221\n",
      "    update_time_ms: 5.396\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 271.4323608054647\n",
      "  time_since_restore: 1303.4011240005493\n",
      "  time_this_iter_s: 27.341761827468872\n",
      "  time_total_s: 1303.4011240005493\n",
      "  timestamp: 1553710313\n",
      "  timesteps_since_restore: 540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 54\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1303 s, 54 iter, 540000 ts, 543 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-12-22\n",
      "  done: false\n",
      "  episode_len_mean: 131.03\n",
      "  episode_reward_max: 730.8351528587153\n",
      "  episode_reward_mean: 465.28660533257323\n",
      "  episode_reward_min: -117.08008895655836\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 3596\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4206.337\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 550000\n",
      "    num_steps_trained: 550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4210858103333793e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2815877199172974\n",
      "      kl: 0.003790856571868062\n",
      "      policy_loss: -0.0017686894861981273\n",
      "      total_loss: 2672.393798828125\n",
      "      vf_explained_var: 0.2620638906955719\n",
      "      vf_loss: 2672.395751953125\n",
      "    sample_time_ms: 21442.259\n",
      "    update_time_ms: 5.429\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 232.64330266628662\n",
      "  time_since_restore: 1331.7554020881653\n",
      "  time_this_iter_s: 28.354278087615967\n",
      "  time_total_s: 1331.7554020881653\n",
      "  timestamp: 1553710342\n",
      "  timesteps_since_restore: 550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 550000\n",
      "  training_iteration: 55\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1331 s, 55 iter, 550000 ts, 465 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-12-52\n",
      "  done: false\n",
      "  episode_len_mean: 138.83\n",
      "  episode_reward_max: 776.2021854377076\n",
      "  episode_reward_mean: 519.6527883986976\n",
      "  episode_reward_min: -122.87852793855211\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 3669\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4339.47\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.105429051666896e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.290065884590149\n",
      "      kl: 0.009701447561383247\n",
      "      policy_loss: -0.004041298758238554\n",
      "      total_loss: 2161.96923828125\n",
      "      vf_explained_var: 0.3699873983860016\n",
      "      vf_loss: 2161.97314453125\n",
      "    sample_time_ms: 21928.349\n",
      "    update_time_ms: 5.668\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 259.8263941993487\n",
      "  time_since_restore: 1362.1404733657837\n",
      "  time_this_iter_s: 30.385071277618408\n",
      "  time_total_s: 1362.1404733657837\n",
      "  timestamp: 1553710372\n",
      "  timesteps_since_restore: 560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 56\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1362 s, 56 iter, 560000 ts, 520 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-13-26\n",
      "  done: false\n",
      "  episode_len_mean: 135.08\n",
      "  episode_reward_max: 735.0237567456005\n",
      "  episode_reward_mean: 506.34222307997175\n",
      "  episode_reward_min: -111.12956172845011\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 3744\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4339.68\n",
      "    load_time_ms: 1.631\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.552714525833448e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2446321249008179\n",
      "      kl: 0.006839171517640352\n",
      "      policy_loss: -0.002169049810618162\n",
      "      total_loss: 2185.9169921875\n",
      "      vf_explained_var: 0.41395410895347595\n",
      "      vf_loss: 2185.919189453125\n",
      "    sample_time_ms: 22600.009\n",
      "    update_time_ms: 6.129\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 253.17111153998593\n",
      "  time_since_restore: 1395.554407119751\n",
      "  time_this_iter_s: 33.413933753967285\n",
      "  time_total_s: 1395.554407119751\n",
      "  timestamp: 1553710406\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 57\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1395 s, 57 iter, 570000 ts, 506 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-13-54\n",
      "  done: false\n",
      "  episode_len_mean: 136.5\n",
      "  episode_reward_max: 746.9878725714024\n",
      "  episode_reward_mean: 532.6362912878848\n",
      "  episode_reward_min: -119.3384558510266\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 3818\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4332.634\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.776357262916724e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2340024709701538\n",
      "      kl: 0.009868071414530277\n",
      "      policy_loss: -0.0024006885942071676\n",
      "      total_loss: 2074.973388671875\n",
      "      vf_explained_var: 0.47201117873191833\n",
      "      vf_loss: 2074.9755859375\n",
      "    sample_time_ms: 22890.65\n",
      "    update_time_ms: 6.128\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 266.3181456439424\n",
      "  time_since_restore: 1423.469419002533\n",
      "  time_this_iter_s: 27.915011882781982\n",
      "  time_total_s: 1423.469419002533\n",
      "  timestamp: 1553710434\n",
      "  timesteps_since_restore: 580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 58\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1423 s, 58 iter, 580000 ts, 533 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-14-22\n",
      "  done: false\n",
      "  episode_len_mean: 133.2\n",
      "  episode_reward_max: 763.941606843343\n",
      "  episode_reward_mean: 507.00160501896374\n",
      "  episode_reward_min: -106.81249170534129\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 3895\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4327.807\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 590000\n",
      "    num_steps_trained: 590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.88178631458362e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2456003427505493\n",
      "      kl: 0.009861390106379986\n",
      "      policy_loss: -0.0037871534004807472\n",
      "      total_loss: 2244.50830078125\n",
      "      vf_explained_var: 0.472116619348526\n",
      "      vf_loss: 2244.511962890625\n",
      "    sample_time_ms: 23263.3\n",
      "    update_time_ms: 6.229\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 253.50080250948187\n",
      "  time_since_restore: 1451.4542453289032\n",
      "  time_this_iter_s: 27.98482632637024\n",
      "  time_total_s: 1451.4542453289032\n",
      "  timestamp: 1553710462\n",
      "  timesteps_since_restore: 590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 590000\n",
      "  training_iteration: 59\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1451 s, 59 iter, 590000 ts, 507 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-14-52\n",
      "  done: false\n",
      "  episode_len_mean: 134.97\n",
      "  episode_reward_max: 709.1704793719219\n",
      "  episode_reward_mean: 526.3800879455856\n",
      "  episode_reward_min: -111.88753975796229\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 3969\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4439.612\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.44089315729181e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2205227613449097\n",
      "      kl: 0.0061202263459563255\n",
      "      policy_loss: -0.0015937632415443659\n",
      "      total_loss: 1921.581298828125\n",
      "      vf_explained_var: 0.5541018843650818\n",
      "      vf_loss: 1921.5828857421875\n",
      "    sample_time_ms: 23772.266\n",
      "    update_time_ms: 6.136\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 263.1900439727928\n",
      "  time_since_restore: 1482.023598909378\n",
      "  time_this_iter_s: 30.569353580474854\n",
      "  time_total_s: 1482.023598909378\n",
      "  timestamp: 1553710492\n",
      "  timesteps_since_restore: 600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 60\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1482 s, 60 iter, 600000 ts, 526 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-15-22\n",
      "  done: false\n",
      "  episode_len_mean: 138.5\n",
      "  episode_reward_max: 718.1260118151561\n",
      "  episode_reward_mean: 559.8879390559836\n",
      "  episode_reward_min: -126.34626970956595\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 4042\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4544.268\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 610000\n",
      "    num_steps_trained: 610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.246590256690979\n",
      "      kl: 0.007956204004585743\n",
      "      policy_loss: -0.0012521090684458613\n",
      "      total_loss: 1585.4210205078125\n",
      "      vf_explained_var: 0.6592633128166199\n",
      "      vf_loss: 1585.4222412109375\n",
      "    sample_time_ms: 24298.794\n",
      "    update_time_ms: 6.519\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 279.9439695279918\n",
      "  time_since_restore: 1512.1999425888062\n",
      "  time_this_iter_s: 30.1763436794281\n",
      "  time_total_s: 1512.1999425888062\n",
      "  timestamp: 1553710522\n",
      "  timesteps_since_restore: 610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 610000\n",
      "  training_iteration: 61\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1512 s, 61 iter, 610000 ts, 560 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-15-59\n",
      "  done: false\n",
      "  episode_len_mean: 135.61\n",
      "  episode_reward_max: 709.7065607621986\n",
      "  episode_reward_mean: 530.1414558134219\n",
      "  episode_reward_min: -129.63676596881146\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 4117\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4609.768\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1102232893229526e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2536494731903076\n",
      "      kl: 0.012855052947998047\n",
      "      policy_loss: -0.003233549417927861\n",
      "      total_loss: 1838.7764892578125\n",
      "      vf_explained_var: 0.5794536471366882\n",
      "      vf_loss: 1838.7796630859375\n",
      "    sample_time_ms: 25493.416\n",
      "    update_time_ms: 6.514\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 265.07072790671094\n",
      "  time_since_restore: 1548.7910513877869\n",
      "  time_this_iter_s: 36.59110879898071\n",
      "  time_total_s: 1548.7910513877869\n",
      "  timestamp: 1553710559\n",
      "  timesteps_since_restore: 620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 62\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1548 s, 62 iter, 620000 ts, 530 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-16-26\n",
      "  done: false\n",
      "  episode_len_mean: 136.04\n",
      "  episode_reward_max: 724.3488202345718\n",
      "  episode_reward_mean: 536.6526728637778\n",
      "  episode_reward_min: -124.83154449385843\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 4191\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4601.079\n",
      "    load_time_ms: 1.583\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1102232893229526e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2284821271896362\n",
      "      kl: 0.006996081210672855\n",
      "      policy_loss: -0.002338126767426729\n",
      "      total_loss: 1761.734130859375\n",
      "      vf_explained_var: 0.6220200061798096\n",
      "      vf_loss: 1761.736328125\n",
      "    sample_time_ms: 25301.264\n",
      "    update_time_ms: 6.584\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 268.3263364318889\n",
      "  time_since_restore: 1575.3644909858704\n",
      "  time_this_iter_s: 26.573439598083496\n",
      "  time_total_s: 1575.3644909858704\n",
      "  timestamp: 1553710586\n",
      "  timesteps_since_restore: 630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 63\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1575 s, 63 iter, 630000 ts, 537 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-16-59\n",
      "  done: false\n",
      "  episode_len_mean: 135.33\n",
      "  episode_reward_max: 735.4963700380885\n",
      "  episode_reward_mean: 543.82897604669\n",
      "  episode_reward_min: -116.11802324605776\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 4267\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4824.871\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 640000\n",
      "    num_steps_trained: 640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.551116446614763e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2044658660888672\n",
      "      kl: 0.005800274200737476\n",
      "      policy_loss: -0.0013987383572384715\n",
      "      total_loss: 1836.011962890625\n",
      "      vf_explained_var: 0.6134364604949951\n",
      "      vf_loss: 1836.01318359375\n",
      "    sample_time_ms: 25658.674\n",
      "    update_time_ms: 6.813\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 271.914488023345\n",
      "  time_since_restore: 1608.5486896038055\n",
      "  time_this_iter_s: 33.18419861793518\n",
      "  time_total_s: 1608.5486896038055\n",
      "  timestamp: 1553710619\n",
      "  timesteps_since_restore: 640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 640000\n",
      "  training_iteration: 64\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1608 s, 64 iter, 640000 ts, 544 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-18-02\n",
      "  done: false\n",
      "  episode_len_mean: 133.26\n",
      "  episode_reward_max: 727.1131612903165\n",
      "  episode_reward_mean: 530.0924886391821\n",
      "  episode_reward_min: -117.05670889339268\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 4342\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5818.698\n",
      "    load_time_ms: 1.696\n",
      "    num_steps_sampled: 650000\n",
      "    num_steps_trained: 650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7755582233073814e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2031058073043823\n",
      "      kl: 0.005196805112063885\n",
      "      policy_loss: -0.0016600104281678796\n",
      "      total_loss: 1857.992431640625\n",
      "      vf_explained_var: 0.5975186228752136\n",
      "      vf_loss: 1857.9940185546875\n",
      "    sample_time_ms: 28169.824\n",
      "    update_time_ms: 8.152\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 265.04624431959104\n",
      "  time_since_restore: 1671.9967756271362\n",
      "  time_this_iter_s: 63.44808602333069\n",
      "  time_total_s: 1671.9967756271362\n",
      "  timestamp: 1553710682\n",
      "  timesteps_since_restore: 650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 650000\n",
      "  training_iteration: 65\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1671 s, 65 iter, 650000 ts, 530 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-19-18\n",
      "  done: false\n",
      "  episode_len_mean: 138.8\n",
      "  episode_reward_max: 728.9603722521238\n",
      "  episode_reward_mean: 574.6670751516037\n",
      "  episode_reward_min: -120.35729629392601\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4414\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6959.386\n",
      "    load_time_ms: 1.823\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2100332975387573\n",
      "      kl: 0.022487882524728775\n",
      "      policy_loss: -0.002044690540060401\n",
      "      total_loss: 1558.114013671875\n",
      "      vf_explained_var: 0.7018845677375793\n",
      "      vf_loss: 1558.115966796875\n",
      "    sample_time_ms: 31497.125\n",
      "    update_time_ms: 9.146\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 287.33353757580187\n",
      "  time_since_restore: 1747.08860373497\n",
      "  time_this_iter_s: 75.09182810783386\n",
      "  time_total_s: 1747.08860373497\n",
      "  timestamp: 1553710758\n",
      "  timesteps_since_restore: 660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 66\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1747 s, 66 iter, 660000 ts, 575 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-19-53\n",
      "  done: false\n",
      "  episode_len_mean: 136.17\n",
      "  episode_reward_max: 730.5730140855251\n",
      "  episode_reward_mean: 559.8893534942079\n",
      "  episode_reward_min: -124.85174468691298\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 4489\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6908.375\n",
      "    load_time_ms: 1.84\n",
      "    num_steps_sampled: 670000\n",
      "    num_steps_trained: 670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2088171243667603\n",
      "      kl: 0.0066755833104252815\n",
      "      policy_loss: -0.0026048081927001476\n",
      "      total_loss: 1701.214111328125\n",
      "      vf_explained_var: 0.6708303689956665\n",
      "      vf_loss: 1701.216796875\n",
      "    sample_time_ms: 31688.965\n",
      "    update_time_ms: 10.827\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 279.94467674710404\n",
      "  time_since_restore: 1781.9296462535858\n",
      "  time_this_iter_s: 34.84104251861572\n",
      "  time_total_s: 1781.9296462535858\n",
      "  timestamp: 1553710793\n",
      "  timesteps_since_restore: 670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 670000\n",
      "  training_iteration: 67\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1781 s, 67 iter, 670000 ts, 560 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-20-24\n",
      "  done: false\n",
      "  episode_len_mean: 136.52\n",
      "  episode_reward_max: 733.3627681310624\n",
      "  episode_reward_mean: 558.4810341454585\n",
      "  episode_reward_min: -105.51222720421745\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 4562\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7093.451\n",
      "    load_time_ms: 1.859\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2125216722488403\n",
      "      kl: 0.0191176850348711\n",
      "      policy_loss: -0.005749277770519257\n",
      "      total_loss: 1728.068115234375\n",
      "      vf_explained_var: 0.6703701615333557\n",
      "      vf_loss: 1728.0740966796875\n",
      "    sample_time_ms: 31889.933\n",
      "    update_time_ms: 10.71\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 279.2405170727293\n",
      "  time_since_restore: 1813.722557067871\n",
      "  time_this_iter_s: 31.79291081428528\n",
      "  time_total_s: 1813.722557067871\n",
      "  timestamp: 1553710824\n",
      "  timesteps_since_restore: 680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 68\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1813 s, 68 iter, 680000 ts, 558 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 127.52\n",
      "  episode_reward_max: 726.7050532459759\n",
      "  episode_reward_mean: 480.9390364234335\n",
      "  episode_reward_min: -115.63720369008023\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 4641\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8080.972\n",
      "    load_time_ms: 2.23\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2021801471710205\n",
      "      kl: 0.009218933060765266\n",
      "      policy_loss: -0.0032008581329137087\n",
      "      total_loss: 2576.120361328125\n",
      "      vf_explained_var: 0.45685645937919617\n",
      "      vf_loss: 2576.12353515625\n",
      "    sample_time_ms: 33124.002\n",
      "    update_time_ms: 12.799\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 240.46951821171675\n",
      "  time_since_restore: 1863.97815823555\n",
      "  time_this_iter_s: 50.25560116767883\n",
      "  time_total_s: 1863.97815823555\n",
      "  timestamp: 1553710875\n",
      "  timesteps_since_restore: 690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 69\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1863 s, 69 iter, 690000 ts, 481 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-22-36\n",
      "  done: false\n",
      "  episode_len_mean: 133.32\n",
      "  episode_reward_max: 752.522615364225\n",
      "  episode_reward_mean: 533.8794902155919\n",
      "  episode_reward_min: -133.983435831779\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 4718\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9203.41\n",
      "    load_time_ms: 2.338\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1595999002456665\n",
      "      kl: 0.01217215321958065\n",
      "      policy_loss: -0.002915699500590563\n",
      "      total_loss: 2096.34814453125\n",
      "      vf_explained_var: 0.5674381852149963\n",
      "      vf_loss: 2096.35107421875\n",
      "    sample_time_ms: 37051.706\n",
      "    update_time_ms: 14.896\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 266.93974510779594\n",
      "  time_since_restore: 1945.1047015190125\n",
      "  time_this_iter_s: 81.12654328346252\n",
      "  time_total_s: 1945.1047015190125\n",
      "  timestamp: 1553710956\n",
      "  timesteps_since_restore: 700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 70\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 1945 s, 70 iter, 700000 ts, 534 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-23-37\n",
      "  done: false\n",
      "  episode_len_mean: 137.36\n",
      "  episode_reward_max: 732.9129356818225\n",
      "  episode_reward_mean: 554.7886005809905\n",
      "  episode_reward_min: -105.9985037054452\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 4792\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9210.963\n",
      "    load_time_ms: 2.331\n",
      "    num_steps_sampled: 710000\n",
      "    num_steps_trained: 710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2056784629821777\n",
      "      kl: 0.007312970235943794\n",
      "      policy_loss: -0.0019492071587592363\n",
      "      total_loss: 1772.8602294921875\n",
      "      vf_explained_var: 0.6594380140304565\n",
      "      vf_loss: 1772.8621826171875\n",
      "    sample_time_ms: 40071.221\n",
      "    update_time_ms: 16.382\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 277.3943002904953\n",
      "  time_since_restore: 2005.5616102218628\n",
      "  time_this_iter_s: 60.45690870285034\n",
      "  time_total_s: 2005.5616102218628\n",
      "  timestamp: 1553711017\n",
      "  timesteps_since_restore: 710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 710000\n",
      "  training_iteration: 71\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2005 s, 71 iter, 710000 ts, 555 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-24-03\n",
      "  done: false\n",
      "  episode_len_mean: 138.37\n",
      "  episode_reward_max: 741.2946019373073\n",
      "  episode_reward_mean: 565.615636263831\n",
      "  episode_reward_min: -127.91589213921151\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4864\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9241.756\n",
      "    load_time_ms: 2.336\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1567919254302979\n",
      "      kl: 0.007869076915085316\n",
      "      policy_loss: -0.0011044811690226197\n",
      "      total_loss: 1711.8369140625\n",
      "      vf_explained_var: 0.6646925806999207\n",
      "      vf_loss: 1711.838134765625\n",
      "    sample_time_ms: 39014.237\n",
      "    update_time_ms: 16.421\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 282.8078181319155\n",
      "  time_since_restore: 2031.8933305740356\n",
      "  time_this_iter_s: 26.33172035217285\n",
      "  time_total_s: 2031.8933305740356\n",
      "  timestamp: 1553711043\n",
      "  timesteps_since_restore: 720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 72\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2031 s, 72 iter, 720000 ts, 566 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-24-30\n",
      "  done: false\n",
      "  episode_len_mean: 138.9\n",
      "  episode_reward_max: 751.4541811434684\n",
      "  episode_reward_mean: 559.0456326338466\n",
      "  episode_reward_min: -110.8704975090319\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 4938\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9277.651\n",
      "    load_time_ms: 2.317\n",
      "    num_steps_sampled: 730000\n",
      "    num_steps_trained: 730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1782641410827637\n",
      "      kl: 0.00923644844442606\n",
      "      policy_loss: -0.0017881104722619057\n",
      "      total_loss: 1818.5784912109375\n",
      "      vf_explained_var: 0.6323711276054382\n",
      "      vf_loss: 1818.58056640625\n",
      "    sample_time_ms: 39030.556\n",
      "    update_time_ms: 16.495\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 279.5228163169233\n",
      "  time_since_restore: 2058.9850912094116\n",
      "  time_this_iter_s: 27.091760635375977\n",
      "  time_total_s: 2058.9850912094116\n",
      "  timestamp: 1553711070\n",
      "  timesteps_since_restore: 730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 730000\n",
      "  training_iteration: 73\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2058 s, 73 iter, 730000 ts, 559 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-24-59\n",
      "  done: false\n",
      "  episode_len_mean: 137.59\n",
      "  episode_reward_max: 760.1559303312523\n",
      "  episode_reward_mean: 555.3393703547331\n",
      "  episode_reward_min: -117.62781939091057\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 5012\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9080.009\n",
      "    load_time_ms: 2.336\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1453578472137451\n",
      "      kl: 0.01034204475581646\n",
      "      policy_loss: -0.000746441597584635\n",
      "      total_loss: 1780.781005859375\n",
      "      vf_explained_var: 0.6435324549674988\n",
      "      vf_loss: 1780.7816162109375\n",
      "    sample_time_ms: 38749.677\n",
      "    update_time_ms: 16.604\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 277.66968517736655\n",
      "  time_since_restore: 2087.3569781780243\n",
      "  time_this_iter_s: 28.37188696861267\n",
      "  time_total_s: 2087.3569781780243\n",
      "  timestamp: 1553711099\n",
      "  timesteps_since_restore: 740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 74\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2087 s, 74 iter, 740000 ts, 555 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-25-29\n",
      "  done: false\n",
      "  episode_len_mean: 136.06\n",
      "  episode_reward_max: 777.4864504075716\n",
      "  episode_reward_mean: 531.5533557068445\n",
      "  episode_reward_min: -110.41330315351736\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 5086\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8248.426\n",
      "    load_time_ms: 2.213\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1299669742584229\n",
      "      kl: 0.020440157502889633\n",
      "      policy_loss: -0.004224653821438551\n",
      "      total_loss: 2006.5068359375\n",
      "      vf_explained_var: 0.5845597386360168\n",
      "      vf_loss: 2006.51123046875\n",
      "    sample_time_ms: 36310.074\n",
      "    update_time_ms: 15.403\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 265.7766778534222\n",
      "  time_since_restore: 2118.0485486984253\n",
      "  time_this_iter_s: 30.691570520401\n",
      "  time_total_s: 2118.0485486984253\n",
      "  timestamp: 1553711129\n",
      "  timesteps_since_restore: 750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 75\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2118 s, 75 iter, 750000 ts, 532 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-26-14\n",
      "  done: false\n",
      "  episode_len_mean: 138.74\n",
      "  episode_reward_max: 749.7877897954511\n",
      "  episode_reward_mean: 564.3278435644086\n",
      "  episode_reward_min: -134.6070309667619\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 5159\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7754.014\n",
      "    load_time_ms: 2.13\n",
      "    num_steps_sampled: 760000\n",
      "    num_steps_trained: 760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1031866073608398\n",
      "      kl: 0.0075791082344949245\n",
      "      policy_loss: 0.0002845189592335373\n",
      "      total_loss: 1681.8875732421875\n",
      "      vf_explained_var: 0.6824955344200134\n",
      "      vf_loss: 1681.887451171875\n",
      "    sample_time_ms: 33708.461\n",
      "    update_time_ms: 14.273\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 282.1639217822043\n",
      "  time_since_restore: 2162.161064386368\n",
      "  time_this_iter_s: 44.112515687942505\n",
      "  time_total_s: 2162.161064386368\n",
      "  timestamp: 1553711174\n",
      "  timesteps_since_restore: 760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 760000\n",
      "  training_iteration: 76\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2162 s, 76 iter, 760000 ts, 564 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-27-24\n",
      "  done: false\n",
      "  episode_len_mean: 130.42\n",
      "  episode_reward_max: 760.5484417199244\n",
      "  episode_reward_mean: 499.7252428757641\n",
      "  episode_reward_min: -130.75422284496221\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 5237\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9007.892\n",
      "    load_time_ms: 2.313\n",
      "    num_steps_sampled: 770000\n",
      "    num_steps_trained: 770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1684048619588917e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0947487354278564\n",
      "      kl: 0.008725745603442192\n",
      "      policy_loss: -0.002129650441929698\n",
      "      total_loss: 2255.991943359375\n",
      "      vf_explained_var: 0.5526216626167297\n",
      "      vf_loss: 2255.994384765625\n",
      "    sample_time_ms: 35981.875\n",
      "    update_time_ms: 13.32\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 249.86262143788207\n",
      "  time_since_restore: 2232.3067247867584\n",
      "  time_this_iter_s: 70.14566040039062\n",
      "  time_total_s: 2232.3067247867584\n",
      "  timestamp: 1553711244\n",
      "  timesteps_since_restore: 770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 770000\n",
      "  training_iteration: 77\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2232 s, 77 iter, 770000 ts, 500 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-28-31\n",
      "  done: false\n",
      "  episode_len_mean: 137.08\n",
      "  episode_reward_max: 726.9655429629169\n",
      "  episode_reward_mean: 552.5910108841684\n",
      "  episode_reward_min: -111.40240949289432\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 5311\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9224.714\n",
      "    load_time_ms: 2.41\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1440597772598267\n",
      "      kl: 0.026105165481567383\n",
      "      policy_loss: -0.0027963321190327406\n",
      "      total_loss: 1714.66064453125\n",
      "      vf_explained_var: 0.6718382239341736\n",
      "      vf_loss: 1714.6632080078125\n",
      "    sample_time_ms: 39306.734\n",
      "    update_time_ms: 15.925\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 276.2955054420843\n",
      "  time_since_restore: 2299.537430524826\n",
      "  time_this_iter_s: 67.23070573806763\n",
      "  time_total_s: 2299.537430524826\n",
      "  timestamp: 1553711311\n",
      "  timesteps_since_restore: 780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 78\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2299 s, 78 iter, 780000 ts, 553 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-29-00\n",
      "  done: false\n",
      "  episode_len_mean: 145.41\n",
      "  episode_reward_max: 726.110943134274\n",
      "  episode_reward_mean: 619.3526196838143\n",
      "  episode_reward_min: -111.6494754660373\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 5379\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8218.164\n",
      "    load_time_ms: 2.066\n",
      "    num_steps_sampled: 790000\n",
      "    num_steps_trained: 790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1418414115905762\n",
      "      kl: 0.03473983705043793\n",
      "      policy_loss: -0.004301664885133505\n",
      "      total_loss: 1165.793212890625\n",
      "      vf_explained_var: 0.8225286602973938\n",
      "      vf_loss: 1165.797607421875\n",
      "    sample_time_ms: 38213.248\n",
      "    update_time_ms: 14.006\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 309.67630984190714\n",
      "  time_since_restore: 2328.7407224178314\n",
      "  time_this_iter_s: 29.20329189300537\n",
      "  time_total_s: 2328.7407224178314\n",
      "  timestamp: 1553711340\n",
      "  timesteps_since_restore: 790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 790000\n",
      "  training_iteration: 79\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2328 s, 79 iter, 790000 ts, 619 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-29-23\n",
      "  done: false\n",
      "  episode_len_mean: 138.13\n",
      "  episode_reward_max: 742.1964066391954\n",
      "  episode_reward_mean: 566.2811608850969\n",
      "  episode_reward_min: -124.18713208735356\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 5453\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6967.875\n",
      "    load_time_ms: 1.919\n",
      "    num_steps_sampled: 800000\n",
      "    num_steps_trained: 800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1258652210235596\n",
      "      kl: 0.010468421503901482\n",
      "      policy_loss: 0.0006958621670491993\n",
      "      total_loss: 1894.9737548828125\n",
      "      vf_explained_var: 0.6483286619186401\n",
      "      vf_loss: 1894.97314453125\n",
      "    sample_time_ms: 33631.792\n",
      "    update_time_ms: 11.884\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 283.14058044254847\n",
      "  time_since_restore: 2351.4928472042084\n",
      "  time_this_iter_s: 22.752124786376953\n",
      "  time_total_s: 2351.4928472042084\n",
      "  timestamp: 1553711363\n",
      "  timesteps_since_restore: 800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 800000\n",
      "  training_iteration: 80\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2351 s, 80 iter, 800000 ts, 566 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-29-48\n",
      "  done: false\n",
      "  episode_len_mean: 132.9\n",
      "  episode_reward_max: 743.1666126145171\n",
      "  episode_reward_mean: 529.8665547703177\n",
      "  episode_reward_min: -140.8589837003493\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 5531\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6932.531\n",
      "    load_time_ms: 1.872\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1568845510482788\n",
      "      kl: 0.01067142654210329\n",
      "      policy_loss: -0.003535510739311576\n",
      "      total_loss: 2061.241943359375\n",
      "      vf_explained_var: 0.6129416227340698\n",
      "      vf_loss: 2061.24560546875\n",
      "    sample_time_ms: 30151.55\n",
      "    update_time_ms: 10.097\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 264.9332773851588\n",
      "  time_since_restore: 2376.7743577957153\n",
      "  time_this_iter_s: 25.281510591506958\n",
      "  time_total_s: 2376.7743577957153\n",
      "  timestamp: 1553711388\n",
      "  timesteps_since_restore: 810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 81\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2376 s, 81 iter, 810000 ts, 530 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-30-12\n",
      "  done: false\n",
      "  episode_len_mean: 136.14\n",
      "  episode_reward_max: 739.6515853226455\n",
      "  episode_reward_mean: 548.4027014339422\n",
      "  episode_reward_min: -118.96963614528177\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 5606\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6839.654\n",
      "    load_time_ms: 1.865\n",
      "    num_steps_sampled: 820000\n",
      "    num_steps_trained: 820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1604845523834229\n",
      "      kl: 0.011922995559871197\n",
      "      policy_loss: -0.00017020221275743097\n",
      "      total_loss: 1799.8802490234375\n",
      "      vf_explained_var: 0.6745275259017944\n",
      "      vf_loss: 1799.8802490234375\n",
      "    sample_time_ms: 29983.614\n",
      "    update_time_ms: 10.049\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 274.20135071697104\n",
      "  time_since_restore: 2400.495725631714\n",
      "  time_this_iter_s: 23.721367835998535\n",
      "  time_total_s: 2400.495725631714\n",
      "  timestamp: 1553711412\n",
      "  timesteps_since_restore: 820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 820000\n",
      "  training_iteration: 82\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2400 s, 82 iter, 820000 ts, 548 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 140.72\n",
      "  episode_reward_max: 733.5608019301513\n",
      "  episode_reward_mean: 584.399075373658\n",
      "  episode_reward_min: -97.33927973245109\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5678\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6737.482\n",
      "    load_time_ms: 1.849\n",
      "    num_steps_sampled: 830000\n",
      "    num_steps_trained: 830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1293915510177612\n",
      "      kl: 0.01673899032175541\n",
      "      policy_loss: 0.0007887448300607502\n",
      "      total_loss: 1519.63720703125\n",
      "      vf_explained_var: 0.7368647456169128\n",
      "      vf_loss: 1519.6363525390625\n",
      "    sample_time_ms: 29730.726\n",
      "    update_time_ms: 9.828\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.19953768682905\n",
      "  time_since_restore: 2424.032526254654\n",
      "  time_this_iter_s: 23.536800622940063\n",
      "  time_total_s: 2424.032526254654\n",
      "  timestamp: 1553711436\n",
      "  timesteps_since_restore: 830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 830000\n",
      "  training_iteration: 83\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2424 s, 83 iter, 830000 ts, 584 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-30-58\n",
      "  done: false\n",
      "  episode_len_mean: 137.75\n",
      "  episode_reward_max: 774.7931816856599\n",
      "  episode_reward_mean: 567.7572945355902\n",
      "  episode_reward_min: -114.46607958410598\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 5751\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6690.215\n",
      "    load_time_ms: 1.841\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1134454011917114\n",
      "      kl: 0.011268296279013157\n",
      "      policy_loss: 0.0006115822470746934\n",
      "      total_loss: 1813.2569580078125\n",
      "      vf_explained_var: 0.677794873714447\n",
      "      vf_loss: 1813.2562255859375\n",
      "    sample_time_ms: 29202.058\n",
      "    update_time_ms: 9.537\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 283.8786472677951\n",
      "  time_since_restore: 2446.641240119934\n",
      "  time_this_iter_s: 22.60871386528015\n",
      "  time_total_s: 2446.641240119934\n",
      "  timestamp: 1553711458\n",
      "  timesteps_since_restore: 840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 84\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2446 s, 84 iter, 840000 ts, 568 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-31-21\n",
      "  done: false\n",
      "  episode_len_mean: 137.17\n",
      "  episode_reward_max: 740.2292278948644\n",
      "  episode_reward_mean: 561.9399917860203\n",
      "  episode_reward_min: -122.29325775138743\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 5826\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6465.26\n",
      "    load_time_ms: 1.858\n",
      "    num_steps_sampled: 850000\n",
      "    num_steps_trained: 850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1148935556411743\n",
      "      kl: 0.01561629306524992\n",
      "      policy_loss: -0.00037960917688906193\n",
      "      total_loss: 1934.4896240234375\n",
      "      vf_explained_var: 0.665511429309845\n",
      "      vf_loss: 1934.489990234375\n",
      "    sample_time_ms: 28637.769\n",
      "    update_time_ms: 9.391\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.9699958930102\n",
      "  time_since_restore: 2469.4402294158936\n",
      "  time_this_iter_s: 22.798989295959473\n",
      "  time_total_s: 2469.4402294158936\n",
      "  timestamp: 1553711481\n",
      "  timesteps_since_restore: 850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 850000\n",
      "  training_iteration: 85\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2469 s, 85 iter, 850000 ts, 562 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-31-44\n",
      "  done: false\n",
      "  episode_len_mean: 131.57\n",
      "  episode_reward_max: 761.458237004189\n",
      "  episode_reward_mean: 521.520940001116\n",
      "  episode_reward_min: -116.87038873090628\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 5904\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5645.728\n",
      "    load_time_ms: 1.842\n",
      "    num_steps_sampled: 860000\n",
      "    num_steps_trained: 860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0821017026901245\n",
      "      kl: 0.011413480155169964\n",
      "      policy_loss: -0.00022405348136089742\n",
      "      total_loss: 2164.264404296875\n",
      "      vf_explained_var: 0.6216900944709778\n",
      "      vf_loss: 2164.264892578125\n",
      "    sample_time_ms: 27312.697\n",
      "    update_time_ms: 9.365\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 260.760470000558\n",
      "  time_since_restore: 2492.0910828113556\n",
      "  time_this_iter_s: 22.650853395462036\n",
      "  time_total_s: 2492.0910828113556\n",
      "  timestamp: 1553711504\n",
      "  timesteps_since_restore: 860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 860000\n",
      "  training_iteration: 86\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2492 s, 86 iter, 860000 ts, 522 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-32-07\n",
      "  done: false\n",
      "  episode_len_mean: 133.15\n",
      "  episode_reward_max: 748.1537433729409\n",
      "  episode_reward_mean: 534.1274649543714\n",
      "  episode_reward_min: -130.47203207174488\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 5981\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4351.257\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1079622507095337\n",
      "      kl: 0.011829884722828865\n",
      "      policy_loss: 0.003503280458971858\n",
      "      total_loss: 2203.503173828125\n",
      "      vf_explained_var: 0.6262325644493103\n",
      "      vf_loss: 2203.499755859375\n",
      "    sample_time_ms: 23865.615\n",
      "    update_time_ms: 8.175\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 267.0637324771858\n",
      "  time_since_restore: 2514.764402627945\n",
      "  time_this_iter_s: 22.673319816589355\n",
      "  time_total_s: 2514.764402627945\n",
      "  timestamp: 1553711527\n",
      "  timesteps_since_restore: 870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 87\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2514 s, 87 iter, 870000 ts, 534 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-32-30\n",
      "  done: false\n",
      "  episode_len_mean: 134.47\n",
      "  episode_reward_max: 747.4109617931597\n",
      "  episode_reward_mean: 538.8142706466095\n",
      "  episode_reward_min: -121.59634382463258\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 6057\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3924.117\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1064794063568115\n",
      "      kl: 0.011164417490363121\n",
      "      policy_loss: 0.0017999721458181739\n",
      "      total_loss: 1954.5364990234375\n",
      "      vf_explained_var: 0.6644344925880432\n",
      "      vf_loss: 1954.534912109375\n",
      "    sample_time_ms: 19882.664\n",
      "    update_time_ms: 5.61\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 269.4071353233048\n",
      "  time_since_restore: 2537.8547103405\n",
      "  time_this_iter_s: 23.09030771255493\n",
      "  time_total_s: 2537.8547103405\n",
      "  timestamp: 1553711550\n",
      "  timesteps_since_restore: 880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 88\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2537 s, 88 iter, 880000 ts, 539 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-32-53\n",
      "  done: false\n",
      "  episode_len_mean: 134.54\n",
      "  episode_reward_max: 755.4100432765608\n",
      "  episode_reward_mean: 536.6724675871562\n",
      "  episode_reward_min: -115.11088406874305\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 6131\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3919.492\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 890000\n",
      "    num_steps_trained: 890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0946106910705566\n",
      "      kl: 0.016250109300017357\n",
      "      policy_loss: -0.0003966570657212287\n",
      "      total_loss: 1881.68505859375\n",
      "      vf_explained_var: 0.6844525337219238\n",
      "      vf_loss: 1881.685546875\n",
      "    sample_time_ms: 19236.189\n",
      "    update_time_ms: 5.029\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 268.3362337935781\n",
      "  time_since_restore: 2560.538197994232\n",
      "  time_this_iter_s: 22.6834876537323\n",
      "  time_total_s: 2560.538197994232\n",
      "  timestamp: 1553711573\n",
      "  timesteps_since_restore: 890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 890000\n",
      "  training_iteration: 89\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2560 s, 89 iter, 890000 ts, 537 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-33-15\n",
      "  done: false\n",
      "  episode_len_mean: 133.92\n",
      "  episode_reward_max: 742.7599080478841\n",
      "  episode_reward_mean: 537.6374162712086\n",
      "  episode_reward_min: -114.44791790814065\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 6205\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3917.052\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0781649351119995\n",
      "      kl: 0.01276583131402731\n",
      "      policy_loss: 0.0024095545522868633\n",
      "      total_loss: 1726.5718994140625\n",
      "      vf_explained_var: 0.7119868397712708\n",
      "      vf_loss: 1726.5694580078125\n",
      "    sample_time_ms: 19230.486\n",
      "    update_time_ms: 5.039\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 268.8187081356043\n",
      "  time_since_restore: 2583.2072916030884\n",
      "  time_this_iter_s: 22.6690936088562\n",
      "  time_total_s: 2583.2072916030884\n",
      "  timestamp: 1553711595\n",
      "  timesteps_since_restore: 900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 90\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2583 s, 90 iter, 900000 ts, 538 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-33-38\n",
      "  done: false\n",
      "  episode_len_mean: 135.0\n",
      "  episode_reward_max: 739.4194290312121\n",
      "  episode_reward_mean: 552.1664361037753\n",
      "  episode_reward_min: -127.45025797654758\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 6282\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3827.314\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 910000\n",
      "    num_steps_trained: 910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.079695463180542\n",
      "      kl: 0.025976529344916344\n",
      "      policy_loss: 0.0028281626291573048\n",
      "      total_loss: 2104.8388671875\n",
      "      vf_explained_var: 0.6511529088020325\n",
      "      vf_loss: 2104.836181640625\n",
      "    sample_time_ms: 19099.253\n",
      "    update_time_ms: 5.013\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 276.08321805188757\n",
      "  time_since_restore: 2606.281330347061\n",
      "  time_this_iter_s: 23.07403874397278\n",
      "  time_total_s: 2606.281330347061\n",
      "  timestamp: 1553711618\n",
      "  timesteps_since_restore: 910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 910000\n",
      "  training_iteration: 91\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2606 s, 91 iter, 910000 ts, 552 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-34-01\n",
      "  done: false\n",
      "  episode_len_mean: 135.26\n",
      "  episode_reward_max: 742.1495211482389\n",
      "  episode_reward_mean: 555.6602553775648\n",
      "  episode_reward_min: -117.17437400863952\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 6357\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3777.329\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0414496660232544\n",
      "      kl: 0.015937412157654762\n",
      "      policy_loss: 0.0019715477246791124\n",
      "      total_loss: 1872.3297119140625\n",
      "      vf_explained_var: 0.6848546266555786\n",
      "      vf_loss: 1872.327880859375\n",
      "    sample_time_ms: 19080.261\n",
      "    update_time_ms: 4.985\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 277.83012768878234\n",
      "  time_since_restore: 2629.312756538391\n",
      "  time_this_iter_s: 23.031426191329956\n",
      "  time_total_s: 2629.312756538391\n",
      "  timestamp: 1553711641\n",
      "  timesteps_since_restore: 920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 92\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2629 s, 92 iter, 920000 ts, 556 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-34-24\n",
      "  done: false\n",
      "  episode_len_mean: 128.11\n",
      "  episode_reward_max: 737.3443549734557\n",
      "  episode_reward_mean: 499.1423162014939\n",
      "  episode_reward_min: -120.64509100857877\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 6438\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.403\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.061769962310791\n",
      "      kl: 0.011145311407744884\n",
      "      policy_loss: 0.0026728289667516947\n",
      "      total_loss: 2636.038818359375\n",
      "      vf_explained_var: 0.5843539237976074\n",
      "      vf_loss: 2636.03564453125\n",
      "    sample_time_ms: 18985.455\n",
      "    update_time_ms: 4.992\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 249.57115810074694\n",
      "  time_since_restore: 2651.8922476768494\n",
      "  time_this_iter_s: 22.579491138458252\n",
      "  time_total_s: 2651.8922476768494\n",
      "  timestamp: 1553711664\n",
      "  timesteps_since_restore: 930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 93\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2651 s, 93 iter, 930000 ts, 499 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-34-47\n",
      "  done: false\n",
      "  episode_len_mean: 132.13\n",
      "  episode_reward_max: 751.1650618889585\n",
      "  episode_reward_mean: 533.1952726155291\n",
      "  episode_reward_min: -133.3943069678915\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 6514\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3771.349\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 940000\n",
      "    num_steps_trained: 940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0529531240463257\n",
      "      kl: 0.016595153138041496\n",
      "      policy_loss: 0.0010483467485755682\n",
      "      total_loss: 2043.2459716796875\n",
      "      vf_explained_var: 0.6695019602775574\n",
      "      vf_loss: 2043.2452392578125\n",
      "    sample_time_ms: 18988.564\n",
      "    update_time_ms: 5.05\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 266.5976363077646\n",
      "  time_since_restore: 2674.4814434051514\n",
      "  time_this_iter_s: 22.589195728302002\n",
      "  time_total_s: 2674.4814434051514\n",
      "  timestamp: 1553711687\n",
      "  timesteps_since_restore: 940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 940000\n",
      "  training_iteration: 94\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2674 s, 94 iter, 940000 ts, 533 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-35-10\n",
      "  done: false\n",
      "  episode_len_mean: 138.15\n",
      "  episode_reward_max: 752.0202821493305\n",
      "  episode_reward_mean: 576.0424044236752\n",
      "  episode_reward_min: -110.00878942850072\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 6587\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.864\n",
      "    load_time_ms: 1.477\n",
      "    num_steps_sampled: 950000\n",
      "    num_steps_trained: 950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.073693871498108\n",
      "      kl: 0.026883238926529884\n",
      "      policy_loss: 0.0029803498182445765\n",
      "      total_loss: 1364.7135009765625\n",
      "      vf_explained_var: 0.795333743095398\n",
      "      vf_loss: 1364.71044921875\n",
      "    sample_time_ms: 19023.627\n",
      "    update_time_ms: 5.028\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 288.0212022118376\n",
      "  time_since_restore: 2697.543442964554\n",
      "  time_this_iter_s: 23.061999559402466\n",
      "  time_total_s: 2697.543442964554\n",
      "  timestamp: 1553711710\n",
      "  timesteps_since_restore: 950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 950000\n",
      "  training_iteration: 95\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2697 s, 95 iter, 950000 ts, 576 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-35-33\n",
      "  done: false\n",
      "  episode_len_mean: 132.87\n",
      "  episode_reward_max: 729.9420309893815\n",
      "  episode_reward_mean: 524.3155475491545\n",
      "  episode_reward_min: -125.10330487198691\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 6662\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3769.341\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0758718252182007\n",
      "      kl: 0.020871400833129883\n",
      "      policy_loss: 0.0017498981906101108\n",
      "      total_loss: 1940.0606689453125\n",
      "      vf_explained_var: 0.6791171431541443\n",
      "      vf_loss: 1940.058837890625\n",
      "    sample_time_ms: 19048.748\n",
      "    update_time_ms: 4.967\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 262.15777377457727\n",
      "  time_since_restore: 2720.5080456733704\n",
      "  time_this_iter_s: 22.96460270881653\n",
      "  time_total_s: 2720.5080456733704\n",
      "  timestamp: 1553711733\n",
      "  timesteps_since_restore: 960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 96\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2720 s, 96 iter, 960000 ts, 524 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-35-56\n",
      "  done: false\n",
      "  episode_len_mean: 140.79\n",
      "  episode_reward_max: 775.2724803952505\n",
      "  episode_reward_mean: 581.3802522496937\n",
      "  episode_reward_min: -71.5099913138348\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6734\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3771.24\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 970000\n",
      "    num_steps_trained: 970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1043202877044678\n",
      "      kl: 0.02456613816320896\n",
      "      policy_loss: 0.0062625291757285595\n",
      "      total_loss: 1579.152099609375\n",
      "      vf_explained_var: 0.7537074685096741\n",
      "      vf_loss: 1579.1458740234375\n",
      "    sample_time_ms: 19068.864\n",
      "    update_time_ms: 4.977\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.69012612484687\n",
      "  time_since_restore: 2743.4015879631042\n",
      "  time_this_iter_s: 22.893542289733887\n",
      "  time_total_s: 2743.4015879631042\n",
      "  timestamp: 1553711756\n",
      "  timesteps_since_restore: 970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 970000\n",
      "  training_iteration: 97\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2743 s, 97 iter, 970000 ts, 581 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-36-19\n",
      "  done: false\n",
      "  episode_len_mean: 129.95\n",
      "  episode_reward_max: 728.5470666679662\n",
      "  episode_reward_mean: 499.4085683534914\n",
      "  episode_reward_min: -138.14362517024068\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 6814\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.289\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 980000\n",
      "    num_steps_trained: 980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.094804048538208\n",
      "      kl: 0.021916428580880165\n",
      "      policy_loss: 0.0024978509172797203\n",
      "      total_loss: 2511.413330078125\n",
      "      vf_explained_var: 0.610711395740509\n",
      "      vf_loss: 2511.41064453125\n",
      "    sample_time_ms: 19064.667\n",
      "    update_time_ms: 5.051\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 249.70428417674572\n",
      "  time_since_restore: 2766.4213683605194\n",
      "  time_this_iter_s: 23.01978039741516\n",
      "  time_total_s: 2766.4213683605194\n",
      "  timestamp: 1553711779\n",
      "  timesteps_since_restore: 980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 980000\n",
      "  training_iteration: 98\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2766 s, 98 iter, 980000 ts, 499 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-36-41\n",
      "  done: false\n",
      "  episode_len_mean: 138.23\n",
      "  episode_reward_max: 768.6911228862381\n",
      "  episode_reward_mean: 578.4868234630108\n",
      "  episode_reward_min: -125.99355961598447\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 6887\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3772.158\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0158644914627075\n",
      "      kl: 0.028880229219794273\n",
      "      policy_loss: 0.006119837984442711\n",
      "      total_loss: 1707.9130859375\n",
      "      vf_explained_var: 0.7412115931510925\n",
      "      vf_loss: 1707.9068603515625\n",
      "    sample_time_ms: 19059.68\n",
      "    update_time_ms: 5.162\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 289.2434117315053\n",
      "  time_since_restore: 2789.096443414688\n",
      "  time_this_iter_s: 22.6750750541687\n",
      "  time_total_s: 2789.096443414688\n",
      "  timestamp: 1553711801\n",
      "  timesteps_since_restore: 990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 99\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2789 s, 99 iter, 990000 ts, 578 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-37-04\n",
      "  done: false\n",
      "  episode_len_mean: 137.24\n",
      "  episode_reward_max: 773.9773380722572\n",
      "  episode_reward_mean: 573.8830715340396\n",
      "  episode_reward_min: -133.8383184112471\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 6961\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3771.625\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.074442982673645\n",
      "      kl: 0.6294276714324951\n",
      "      policy_loss: 0.004953357391059399\n",
      "      total_loss: 1731.24755859375\n",
      "      vf_explained_var: 0.7382522225379944\n",
      "      vf_loss: 1731.2425537109375\n",
      "    sample_time_ms: 19077.999\n",
      "    update_time_ms: 5.188\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 286.9415357670198\n",
      "  time_since_restore: 2811.9444675445557\n",
      "  time_this_iter_s: 22.848024129867554\n",
      "  time_total_s: 2811.9444675445557\n",
      "  timestamp: 1553711824\n",
      "  timesteps_since_restore: 1000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 100\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2811 s, 100 iter, 1000000 ts, 574 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-37-27\n",
      "  done: false\n",
      "  episode_len_mean: 134.44\n",
      "  episode_reward_max: 753.8629457360754\n",
      "  episode_reward_mean: 546.9348444970317\n",
      "  episode_reward_min: -120.67288049965285\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 7037\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3774.064\n",
      "    load_time_ms: 1.435\n",
      "    num_steps_sampled: 1010000\n",
      "    num_steps_trained: 1010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6263031617930286e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.090592384338379\n",
      "      kl: 0.037724245339632034\n",
      "      policy_loss: 0.007945855148136616\n",
      "      total_loss: 2317.972412109375\n",
      "      vf_explained_var: 0.6511779427528381\n",
      "      vf_loss: 2317.96435546875\n",
      "    sample_time_ms: 19057.896\n",
      "    update_time_ms: 5.163\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 273.46742224851585\n",
      "  time_since_restore: 2834.838968038559\n",
      "  time_this_iter_s: 22.894500494003296\n",
      "  time_total_s: 2834.838968038559\n",
      "  timestamp: 1553711847\n",
      "  timesteps_since_restore: 1010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1010000\n",
      "  training_iteration: 101\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2834 s, 101 iter, 1010000 ts, 547 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-37-50\n",
      "  done: false\n",
      "  episode_len_mean: 138.23\n",
      "  episode_reward_max: 729.9355607112647\n",
      "  episode_reward_mean: 574.1803150303615\n",
      "  episode_reward_min: -124.348124215431\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 7111\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3774.635\n",
      "    load_time_ms: 1.428\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6263031617930286e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1125704050064087\n",
      "      kl: 0.047485921531915665\n",
      "      policy_loss: 0.008840065449476242\n",
      "      total_loss: 1683.3646240234375\n",
      "      vf_explained_var: 0.7456456422805786\n",
      "      vf_loss: 1683.355712890625\n",
      "    sample_time_ms: 19020.495\n",
      "    update_time_ms: 5.302\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 287.09015751518064\n",
      "  time_since_restore: 2857.500820875168\n",
      "  time_this_iter_s: 22.661852836608887\n",
      "  time_total_s: 2857.500820875168\n",
      "  timestamp: 1553711870\n",
      "  timesteps_since_restore: 1020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 102\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2857 s, 102 iter, 1020000 ts, 574 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-38-13\n",
      "  done: false\n",
      "  episode_len_mean: 133.97\n",
      "  episode_reward_max: 738.236311890994\n",
      "  episode_reward_mean: 544.6174151173432\n",
      "  episode_reward_min: -123.7180156033657\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 7187\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3774.361\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 1030000\n",
      "    num_steps_trained: 1030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.439454985027613e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0732781887054443\n",
      "      kl: 0.049337007105350494\n",
      "      policy_loss: 0.009122194722294807\n",
      "      total_loss: 2185.756103515625\n",
      "      vf_explained_var: 0.6806897521018982\n",
      "      vf_loss: 2185.746826171875\n",
      "    sample_time_ms: 19063.54\n",
      "    update_time_ms: 5.426\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 272.3087075586716\n",
      "  time_since_restore: 2880.5130186080933\n",
      "  time_this_iter_s: 23.012197732925415\n",
      "  time_total_s: 2880.5130186080933\n",
      "  timestamp: 1553711893\n",
      "  timesteps_since_restore: 1030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1030000\n",
      "  training_iteration: 103\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2880 s, 103 iter, 1030000 ts, 545 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-38-35\n",
      "  done: false\n",
      "  episode_len_mean: 133.83\n",
      "  episode_reward_max: 786.8532757635272\n",
      "  episode_reward_mean: 539.0538831822873\n",
      "  episode_reward_min: -122.63954092852687\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 7265\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3777.102\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6591827198794896e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1354825496673584\n",
      "      kl: 0.03227434307336807\n",
      "      policy_loss: 0.005943607073277235\n",
      "      total_loss: 2359.470947265625\n",
      "      vf_explained_var: 0.661799430847168\n",
      "      vf_loss: 2359.46484375\n",
      "    sample_time_ms: 19029.294\n",
      "    update_time_ms: 5.354\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 269.52694159114367\n",
      "  time_since_restore: 2902.7871236801147\n",
      "  time_this_iter_s: 22.274105072021484\n",
      "  time_total_s: 2902.7871236801147\n",
      "  timestamp: 1553711915\n",
      "  timesteps_since_restore: 1040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 104\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2902 s, 104 iter, 1040000 ts, 539 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-38-59\n",
      "  done: false\n",
      "  episode_len_mean: 133.71\n",
      "  episode_reward_max: 776.6917620065043\n",
      "  episode_reward_mean: 539.0676558299028\n",
      "  episode_reward_min: -119.79532038039476\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 7339\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3780.183\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6591827198794896e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0987006425857544\n",
      "      kl: 0.04419689252972603\n",
      "      policy_loss: 0.00807047076523304\n",
      "      total_loss: 1834.4703369140625\n",
      "      vf_explained_var: 0.7403641939163208\n",
      "      vf_loss: 1834.4622802734375\n",
      "    sample_time_ms: 19040.499\n",
      "    update_time_ms: 5.381\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 269.5338279149514\n",
      "  time_since_restore: 2925.994081258774\n",
      "  time_this_iter_s: 23.206957578659058\n",
      "  time_total_s: 2925.994081258774\n",
      "  timestamp: 1553711939\n",
      "  timesteps_since_restore: 1050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 105\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2925 s, 105 iter, 1050000 ts, 539 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-39-21\n",
      "  done: false\n",
      "  episode_len_mean: 136.9\n",
      "  episode_reward_max: 772.0923963494816\n",
      "  episode_reward_mean: 556.9280423929017\n",
      "  episode_reward_min: -104.41449809923859\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 7413\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3770.111\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 1060000\n",
      "    num_steps_trained: 1060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.488773110466954e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1639865636825562\n",
      "      kl: 0.7293410301208496\n",
      "      policy_loss: 0.007981345988810062\n",
      "      total_loss: 1491.9766845703125\n",
      "      vf_explained_var: 0.8043993711471558\n",
      "      vf_loss: 1491.96875\n",
      "    sample_time_ms: 19010.227\n",
      "    update_time_ms: 5.407\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 278.46402119645086\n",
      "  time_since_restore: 2948.556181192398\n",
      "  time_this_iter_s: 22.562099933624268\n",
      "  time_total_s: 2948.556181192398\n",
      "  timestamp: 1553711961\n",
      "  timesteps_since_restore: 1060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1060000\n",
      "  training_iteration: 106\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2948 s, 106 iter, 1060000 ts, 557 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-39-44\n",
      "  done: false\n",
      "  episode_len_mean: 137.44\n",
      "  episode_reward_max: 743.360631051737\n",
      "  episode_reward_mean: 564.5046659571759\n",
      "  episode_reward_min: -121.48884224943554\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 7486\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.444\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 1070000\n",
      "    num_steps_trained: 1070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.233160635052711e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1134387254714966\n",
      "      kl: 0.044295791536569595\n",
      "      policy_loss: 0.007766890339553356\n",
      "      total_loss: 1748.4090576171875\n",
      "      vf_explained_var: 0.7500724792480469\n",
      "      vf_loss: 1748.4012451171875\n",
      "    sample_time_ms: 18976.767\n",
      "    update_time_ms: 5.397\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 282.25233297858796\n",
      "  time_since_restore: 2971.0884833335876\n",
      "  time_this_iter_s: 22.532302141189575\n",
      "  time_total_s: 2971.0884833335876\n",
      "  timestamp: 1553711984\n",
      "  timesteps_since_restore: 1070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1070000\n",
      "  training_iteration: 107\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2971 s, 107 iter, 1070000 ts, 565 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-40-07\n",
      "  done: false\n",
      "  episode_len_mean: 134.09\n",
      "  episode_reward_max: 750.2396878524268\n",
      "  episode_reward_mean: 550.5330331078212\n",
      "  episode_reward_min: -122.79800003632926\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 7562\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.669\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.234974062946164e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0740960836410522\n",
      "      kl: 0.03834391385316849\n",
      "      policy_loss: 0.007963364943861961\n",
      "      total_loss: 2113.99755859375\n",
      "      vf_explained_var: 0.7055283784866333\n",
      "      vf_loss: 2113.98974609375\n",
      "    sample_time_ms: 18962.533\n",
      "    update_time_ms: 5.176\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 275.26651655391055\n",
      "  time_since_restore: 2993.9777369499207\n",
      "  time_this_iter_s: 22.889253616333008\n",
      "  time_total_s: 2993.9777369499207\n",
      "  timestamp: 1553712007\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 108\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 2993 s, 108 iter, 1080000 ts, 551 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-40-29\n",
      "  done: false\n",
      "  episode_len_mean: 139.26\n",
      "  episode_reward_max: 750.2396878524268\n",
      "  episode_reward_mean: 581.064627034567\n",
      "  episode_reward_min: -124.74922383532152\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 7635\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3772.45\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 1090000\n",
      "    num_steps_trained: 1090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.234974062946164e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1712048053741455\n",
      "      kl: 0.4242405593395233\n",
      "      policy_loss: 0.011302941478788853\n",
      "      total_loss: 1564.973876953125\n",
      "      vf_explained_var: 0.7877174019813538\n",
      "      vf_loss: 1564.9625244140625\n",
      "    sample_time_ms: 18962.542\n",
      "    update_time_ms: 5.13\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.5323135172835\n",
      "  time_since_restore: 3016.69229054451\n",
      "  time_this_iter_s: 22.714553594589233\n",
      "  time_total_s: 3016.69229054451\n",
      "  timestamp: 1553712029\n",
      "  timesteps_since_restore: 1090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1090000\n",
      "  training_iteration: 109\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3016 s, 109 iter, 1090000 ts, 581 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-40-52\n",
      "  done: false\n",
      "  episode_len_mean: 136.28\n",
      "  episode_reward_max: 763.340550842181\n",
      "  episode_reward_mean: 551.5988683037972\n",
      "  episode_reward_min: -136.1593303615421\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 7710\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3774.959\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 1100000\n",
      "    num_steps_trained: 1100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8524607713018193e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.125540852546692\n",
      "      kl: 0.03111746348440647\n",
      "      policy_loss: 0.005952584557235241\n",
      "      total_loss: 1852.3953857421875\n",
      "      vf_explained_var: 0.7522364258766174\n",
      "      vf_loss: 1852.389404296875\n",
      "    sample_time_ms: 18955.526\n",
      "    update_time_ms: 5.055\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 275.7994341518986\n",
      "  time_since_restore: 3039.4961500167847\n",
      "  time_this_iter_s: 22.80385947227478\n",
      "  time_total_s: 3039.4961500167847\n",
      "  timestamp: 1553712052\n",
      "  timesteps_since_restore: 1100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1100000\n",
      "  training_iteration: 110\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3039 s, 110 iter, 1100000 ts, 552 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-41-15\n",
      "  done: false\n",
      "  episode_len_mean: 135.88\n",
      "  episode_reward_max: 759.7729793868202\n",
      "  episode_reward_mean: 549.0146370352556\n",
      "  episode_reward_min: -108.59498572011728\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 7784\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.374\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8524607713018193e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1215838193893433\n",
      "      kl: 0.049949467182159424\n",
      "      policy_loss: 0.008059072308242321\n",
      "      total_loss: 1871.9232177734375\n",
      "      vf_explained_var: 0.7523270845413208\n",
      "      vf_loss: 1871.9154052734375\n",
      "    sample_time_ms: 18943.856\n",
      "    update_time_ms: 4.984\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 274.5073185176278\n",
      "  time_since_restore: 3062.2891552448273\n",
      "  time_this_iter_s: 22.793005228042603\n",
      "  time_total_s: 3062.2891552448273\n",
      "  timestamp: 1553712075\n",
      "  timesteps_since_restore: 1110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 111\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3062 s, 111 iter, 1110000 ts, 549 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-41-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.63\n",
      "  episode_reward_max: 753.4693989997629\n",
      "  episode_reward_mean: 597.1712743319051\n",
      "  episode_reward_min: -114.2946991460398\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 7854\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3774.315\n",
      "    load_time_ms: 1.61\n",
      "    num_steps_sampled: 1120000\n",
      "    num_steps_trained: 1120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.778691738564097e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1180227994918823\n",
      "      kl: 0.8414772152900696\n",
      "      policy_loss: 0.009878347627818584\n",
      "      total_loss: 1280.58935546875\n",
      "      vf_explained_var: 0.831335186958313\n",
      "      vf_loss: 1280.5794677734375\n",
      "    sample_time_ms: 18980.987\n",
      "    update_time_ms: 4.749\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 298.5856371659526\n",
      "  time_since_restore: 3085.2993190288544\n",
      "  time_this_iter_s: 23.0101637840271\n",
      "  time_total_s: 3085.2993190288544\n",
      "  timestamp: 1553712098\n",
      "  timesteps_since_restore: 1120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1120000\n",
      "  training_iteration: 112\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3085 s, 112 iter, 1120000 ts, 597 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-42-01\n",
      "  done: false\n",
      "  episode_len_mean: 134.47\n",
      "  episode_reward_max: 738.2851096141723\n",
      "  episode_reward_mean: 537.9406978115192\n",
      "  episode_reward_min: -132.32641636235445\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 7931\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3777.217\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 1130000\n",
      "    num_steps_trained: 1130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.1680372201052335e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.115214228630066\n",
      "      kl: 0.08722478896379471\n",
      "      policy_loss: 0.012024786323308945\n",
      "      total_loss: 2220.33447265625\n",
      "      vf_explained_var: 0.7127787470817566\n",
      "      vf_loss: 2220.322021484375\n",
      "    sample_time_ms: 18963.83\n",
      "    update_time_ms: 4.7\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 268.9703489057595\n",
      "  time_since_restore: 3108.163830280304\n",
      "  time_this_iter_s: 22.864511251449585\n",
      "  time_total_s: 3108.163830280304\n",
      "  timestamp: 1553712121\n",
      "  timesteps_since_restore: 1130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1130000\n",
      "  training_iteration: 113\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3108 s, 113 iter, 1130000 ts, 538 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-42-24\n",
      "  done: false\n",
      "  episode_len_mean: 135.68\n",
      "  episode_reward_max: 758.2071219305557\n",
      "  episode_reward_mean: 541.1307203338097\n",
      "  episode_reward_min: -105.45650607270936\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 8005\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.963\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.252055442416938e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.128505825996399\n",
      "      kl: 0.10114683955907822\n",
      "      policy_loss: 0.013785130344331264\n",
      "      total_loss: 2010.98974609375\n",
      "      vf_explained_var: 0.7380083799362183\n",
      "      vf_loss: 2010.9759521484375\n",
      "    sample_time_ms: 19004.936\n",
      "    update_time_ms: 4.759\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 270.5653601669049\n",
      "  time_since_restore: 3130.8476881980896\n",
      "  time_this_iter_s: 22.683857917785645\n",
      "  time_total_s: 3130.8476881980896\n",
      "  timestamp: 1553712144\n",
      "  timesteps_since_restore: 1140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 114\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3130 s, 114 iter, 1140000 ts, 541 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-42-46\n",
      "  done: false\n",
      "  episode_len_mean: 138.67\n",
      "  episode_reward_max: 753.4766604073869\n",
      "  episode_reward_mean: 567.6078990462872\n",
      "  episode_reward_min: -102.34791438950053\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8077\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3773.958\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 1150000\n",
      "    num_steps_trained: 1150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.378084714589056e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.115498423576355\n",
      "      kl: 0.5132434368133545\n",
      "      policy_loss: 0.007129384204745293\n",
      "      total_loss: 1654.60595703125\n",
      "      vf_explained_var: 0.7842462658882141\n",
      "      vf_loss: 1654.5989990234375\n",
      "    sample_time_ms: 18951.325\n",
      "    update_time_ms: 4.767\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 283.80394952314356\n",
      "  time_since_restore: 3153.4882957935333\n",
      "  time_this_iter_s: 22.640607595443726\n",
      "  time_total_s: 3153.4882957935333\n",
      "  timestamp: 1553712166\n",
      "  timesteps_since_restore: 1150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1150000\n",
      "  training_iteration: 115\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3153 s, 115 iter, 1150000 ts, 568 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-43-09\n",
      "  done: false\n",
      "  episode_len_mean: 136.55\n",
      "  episode_reward_max: 754.1690013784515\n",
      "  episode_reward_mean: 563.1634850019227\n",
      "  episode_reward_min: -119.2619011794802\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 8151\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.661\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 1160000\n",
      "    num_steps_trained: 1160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4067125520919935e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0946146249771118\n",
      "      kl: 0.04084090143442154\n",
      "      policy_loss: 0.006689129862934351\n",
      "      total_loss: 1787.31005859375\n",
      "      vf_explained_var: 0.7689334154129028\n",
      "      vf_loss: 1787.3033447265625\n",
      "    sample_time_ms: 18953.673\n",
      "    update_time_ms: 4.712\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 281.58174250096135\n",
      "  time_since_restore: 3176.0182683467865\n",
      "  time_this_iter_s: 22.529972553253174\n",
      "  time_total_s: 3176.0182683467865\n",
      "  timestamp: 1553712189\n",
      "  timesteps_since_restore: 1160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1160000\n",
      "  training_iteration: 116\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3176 s, 116 iter, 1160000 ts, 563 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-43-32\n",
      "  done: false\n",
      "  episode_len_mean: 136.58\n",
      "  episode_reward_max: 760.0191296136769\n",
      "  episode_reward_mean: 553.4232021975567\n",
      "  episode_reward_min: -123.37627162324395\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 8225\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.369\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1100686730416254e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0984954833984375\n",
      "      kl: 0.07149124890565872\n",
      "      policy_loss: 0.0099136121571064\n",
      "      total_loss: 1796.1512451171875\n",
      "      vf_explained_var: 0.7653692364692688\n",
      "      vf_loss: 1796.1412353515625\n",
      "    sample_time_ms: 18960.723\n",
      "    update_time_ms: 4.805\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 276.7116010987783\n",
      "  time_since_restore: 3198.612218141556\n",
      "  time_this_iter_s: 22.593949794769287\n",
      "  time_total_s: 3198.612218141556\n",
      "  timestamp: 1553712212\n",
      "  timesteps_since_restore: 1170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 117\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3198 s, 117 iter, 1170000 ts, 553 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-43-55\n",
      "  done: false\n",
      "  episode_len_mean: 131.82\n",
      "  episode_reward_max: 765.753082532416\n",
      "  episode_reward_mean: 524.095457411621\n",
      "  episode_reward_min: -132.57813554498264\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8302\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3766.987\n",
      "    load_time_ms: 1.686\n",
      "    num_steps_sampled: 1180000\n",
      "    num_steps_trained: 1180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.1651036299478975e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0743743181228638\n",
      "      kl: 0.07312598824501038\n",
      "      policy_loss: 0.009180122055113316\n",
      "      total_loss: 2528.857666015625\n",
      "      vf_explained_var: 0.6846484541893005\n",
      "      vf_loss: 2528.848388671875\n",
      "    sample_time_ms: 18977.59\n",
      "    update_time_ms: 4.967\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 262.0477287058106\n",
      "  time_since_restore: 3221.667513847351\n",
      "  time_this_iter_s: 23.055295705795288\n",
      "  time_total_s: 3221.667513847351\n",
      "  timestamp: 1553712235\n",
      "  timesteps_since_restore: 1180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1180000\n",
      "  training_iteration: 118\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3221 s, 118 iter, 1180000 ts, 524 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-44-17\n",
      "  done: false\n",
      "  episode_len_mean: 139.35\n",
      "  episode_reward_max: 758.6876774165779\n",
      "  episode_reward_mean: 583.8301042568045\n",
      "  episode_reward_min: -109.60849994586123\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 8373\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.312\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 1190000\n",
      "    num_steps_trained: 1190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.7476556517169995e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0776630640029907\n",
      "      kl: 1.2024561166763306\n",
      "      policy_loss: 0.008702786639332771\n",
      "      total_loss: 1346.6507568359375\n",
      "      vf_explained_var: 0.819057047367096\n",
      "      vf_loss: 1346.6419677734375\n",
      "    sample_time_ms: 18953.099\n",
      "    update_time_ms: 4.787\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 291.91505212840224\n",
      "  time_since_restore: 3244.0564720630646\n",
      "  time_this_iter_s: 22.3889582157135\n",
      "  time_total_s: 3244.0564720630646\n",
      "  timestamp: 1553712257\n",
      "  timesteps_since_restore: 1190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1190000\n",
      "  training_iteration: 119\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3244 s, 119 iter, 1190000 ts, 584 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-44-40\n",
      "  done: false\n",
      "  episode_len_mean: 138.81\n",
      "  episode_reward_max: 742.9338725518362\n",
      "  episode_reward_mean: 582.8733084102167\n",
      "  episode_reward_min: -120.29023518942255\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 8447\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3757.66\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.121482443599733e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0381914377212524\n",
      "      kl: 0.12347952276468277\n",
      "      policy_loss: 0.006684270221740007\n",
      "      total_loss: 1775.869384765625\n",
      "      vf_explained_var: 0.7728919386863708\n",
      "      vf_loss: 1775.862548828125\n",
      "    sample_time_ms: 18962.994\n",
      "    update_time_ms: 4.88\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 291.43665420510837\n",
      "  time_since_restore: 3266.941365003586\n",
      "  time_this_iter_s: 22.88489294052124\n",
      "  time_total_s: 3266.941365003586\n",
      "  timestamp: 1553712280\n",
      "  timesteps_since_restore: 1200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 120\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3266 s, 120 iter, 1200000 ts, 583 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-45-03\n",
      "  done: false\n",
      "  episode_len_mean: 139.81\n",
      "  episode_reward_max: 760.629024516409\n",
      "  episode_reward_mean: 582.5703464051331\n",
      "  episode_reward_min: -132.7584319204157\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 8520\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3755.641\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 1210000\n",
      "    num_steps_trained: 1210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0682224492580213e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1123510599136353\n",
      "      kl: 0.10721945017576218\n",
      "      policy_loss: 0.01199457235634327\n",
      "      total_loss: 1714.436279296875\n",
      "      vf_explained_var: 0.7822834849357605\n",
      "      vf_loss: 1714.42431640625\n",
      "    sample_time_ms: 18970.897\n",
      "    update_time_ms: 4.926\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 291.28517320256657\n",
      "  time_since_restore: 3289.7919085025787\n",
      "  time_this_iter_s: 22.85054349899292\n",
      "  time_total_s: 3289.7919085025787\n",
      "  timestamp: 1553712303\n",
      "  timesteps_since_restore: 1210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1210000\n",
      "  training_iteration: 121\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3289 s, 121 iter, 1210000 ts, 583 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-45-26\n",
      "  done: false\n",
      "  episode_len_mean: 134.02\n",
      "  episode_reward_max: 753.9457666514995\n",
      "  episode_reward_mean: 546.4156122653566\n",
      "  episode_reward_min: -116.01898075508619\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8597\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3755.979\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 1220000\n",
      "    num_steps_trained: 1220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.60233354980994e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.010127305984497\n",
      "      kl: 0.0547732338309288\n",
      "      policy_loss: 0.0068541704677045345\n",
      "      total_loss: 2624.623046875\n",
      "      vf_explained_var: 0.6706657409667969\n",
      "      vf_loss: 2624.6162109375\n",
      "    sample_time_ms: 18975.375\n",
      "    update_time_ms: 5.033\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 273.20780613267823\n",
      "  time_since_restore: 3312.8567368984222\n",
      "  time_this_iter_s: 23.064828395843506\n",
      "  time_total_s: 3312.8567368984222\n",
      "  timestamp: 1553712326\n",
      "  timesteps_since_restore: 1220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1220000\n",
      "  training_iteration: 122\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3312 s, 122 iter, 1220000 ts, 546 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-45-49\n",
      "  done: false\n",
      "  episode_len_mean: 134.18\n",
      "  episode_reward_max: 757.2255764226076\n",
      "  episode_reward_mean: 555.6352161175572\n",
      "  episode_reward_min: -119.15660122890986\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 8673\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.003\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4035004901510326e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0279675722122192\n",
      "      kl: 0.1329718977212906\n",
      "      policy_loss: 0.014748439192771912\n",
      "      total_loss: 2160.660400390625\n",
      "      vf_explained_var: 0.7260017395019531\n",
      "      vf_loss: 2160.645751953125\n",
      "    sample_time_ms: 18966.45\n",
      "    update_time_ms: 5.02\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 277.81760805877855\n",
      "  time_since_restore: 3335.6029636859894\n",
      "  time_this_iter_s: 22.74622678756714\n",
      "  time_total_s: 3335.6029636859894\n",
      "  timestamp: 1553712349\n",
      "  timesteps_since_restore: 1230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 123\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3335 s, 123 iter, 1230000 ts, 556 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-46-12\n",
      "  done: false\n",
      "  episode_len_mean: 136.3\n",
      "  episode_reward_max: 757.2255764226076\n",
      "  episode_reward_mean: 565.7911260036825\n",
      "  episode_reward_min: -130.0090226055812\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 8748\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.228\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 1240000\n",
      "    num_steps_trained: 1240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.60525015620012e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.032226324081421\n",
      "      kl: 0.08766106516122818\n",
      "      policy_loss: 0.008746749721467495\n",
      "      total_loss: 2075.029541015625\n",
      "      vf_explained_var: 0.7388707399368286\n",
      "      vf_loss: 2075.020751953125\n",
      "    sample_time_ms: 18957.531\n",
      "    update_time_ms: 5.032\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 282.8955630018413\n",
      "  time_since_restore: 3358.197541475296\n",
      "  time_this_iter_s: 22.59457778930664\n",
      "  time_total_s: 3358.197541475296\n",
      "  timestamp: 1553712372\n",
      "  timesteps_since_restore: 1240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1240000\n",
      "  training_iteration: 124\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3358 s, 124 iter, 1240000 ts, 566 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-46-34\n",
      "  done: false\n",
      "  episode_len_mean: 136.8\n",
      "  episode_reward_max: 741.8857569607829\n",
      "  episode_reward_mean: 567.4273084157807\n",
      "  episode_reward_min: -113.84740838386074\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 8823\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3754.256\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 1250000\n",
      "    num_steps_trained: 1250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.40787655778916e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0317025184631348\n",
      "      kl: 0.06797005981206894\n",
      "      policy_loss: 0.00853403378278017\n",
      "      total_loss: 1980.284912109375\n",
      "      vf_explained_var: 0.7459409832954407\n",
      "      vf_loss: 1980.2764892578125\n",
      "    sample_time_ms: 18963.518\n",
      "    update_time_ms: 5.059\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 283.7136542078904\n",
      "  time_since_restore: 3380.909179210663\n",
      "  time_this_iter_s: 22.71163773536682\n",
      "  time_total_s: 3380.909179210663\n",
      "  timestamp: 1553712394\n",
      "  timesteps_since_restore: 1250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1250000\n",
      "  training_iteration: 125\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3380 s, 125 iter, 1250000 ts, 567 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-46-57\n",
      "  done: false\n",
      "  episode_len_mean: 131.3\n",
      "  episode_reward_max: 767.047948688734\n",
      "  episode_reward_mean: 515.134189428695\n",
      "  episode_reward_min: -121.89597470924176\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8900\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3757.681\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.11181285145027e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.076252818107605\n",
      "      kl: 0.1332680881023407\n",
      "      policy_loss: 0.013585510663688183\n",
      "      total_loss: 2737.319091796875\n",
      "      vf_explained_var: 0.6662036180496216\n",
      "      vf_loss: 2737.3056640625\n",
      "    sample_time_ms: 18997.821\n",
      "    update_time_ms: 5.211\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 257.5670947143475\n",
      "  time_since_restore: 3403.821224451065\n",
      "  time_this_iter_s: 22.91204524040222\n",
      "  time_total_s: 3403.821224451065\n",
      "  timestamp: 1553712417\n",
      "  timesteps_since_restore: 1260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 126\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3403 s, 126 iter, 1260000 ts, 515 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-47-21\n",
      "  done: false\n",
      "  episode_len_mean: 134.13\n",
      "  episode_reward_max: 751.8812726978697\n",
      "  episode_reward_mean: 539.304897375011\n",
      "  episode_reward_min: -124.29921277935074\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 8977\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.996\n",
      "    load_time_ms: 1.735\n",
      "    num_steps_sampled: 1270000\n",
      "    num_steps_trained: 1270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.216772225502561e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0380679368972778\n",
      "      kl: 0.8790704607963562\n",
      "      policy_loss: 0.01021958515048027\n",
      "      total_loss: 2067.35791015625\n",
      "      vf_explained_var: 0.7441727519035339\n",
      "      vf_loss: 2067.347900390625\n",
      "    sample_time_ms: 19019.285\n",
      "    update_time_ms: 5.642\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 269.65244868750545\n",
      "  time_since_restore: 3427.025608062744\n",
      "  time_this_iter_s: 23.204383611679077\n",
      "  time_total_s: 3427.025608062744\n",
      "  timestamp: 1553712441\n",
      "  timesteps_since_restore: 1270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1270000\n",
      "  training_iteration: 127\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3427 s, 127 iter, 1270000 ts, 539 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-47-44\n",
      "  done: false\n",
      "  episode_len_mean: 137.2\n",
      "  episode_reward_max: 759.0041658754187\n",
      "  episode_reward_mean: 572.952830113426\n",
      "  episode_reward_min: -108.54350356966454\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 9051\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3806.088\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 1280000\n",
      "    num_steps_trained: 1280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8251578750326985e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0043905973434448\n",
      "      kl: 0.8060552477836609\n",
      "      policy_loss: 0.013129189610481262\n",
      "      total_loss: 1836.385009765625\n",
      "      vf_explained_var: 0.7683283686637878\n",
      "      vf_loss: 1836.371826171875\n",
      "    sample_time_ms: 19062.779\n",
      "    update_time_ms: 5.664\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 286.476415056713\n",
      "  time_since_restore: 3450.607459306717\n",
      "  time_this_iter_s: 23.58185124397278\n",
      "  time_total_s: 3450.607459306717\n",
      "  timestamp: 1553712464\n",
      "  timesteps_since_restore: 1280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1280000\n",
      "  training_iteration: 128\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3450 s, 128 iter, 1280000 ts, 573 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-48-07\n",
      "  done: false\n",
      "  episode_len_mean: 136.01\n",
      "  episode_reward_max: 773.385972609752\n",
      "  episode_reward_mean: 564.5487223721705\n",
      "  episode_reward_min: -127.70671123630352\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 9127\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.502\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.737737011072395e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.035728096961975\n",
      "      kl: 0.30605071783065796\n",
      "      policy_loss: 0.008152157999575138\n",
      "      total_loss: 2322.42578125\n",
      "      vf_explained_var: 0.7155174612998962\n",
      "      vf_loss: 2322.41748046875\n",
      "    sample_time_ms: 19102.253\n",
      "    update_time_ms: 5.869\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 282.2743611860852\n",
      "  time_since_restore: 3473.4886033535004\n",
      "  time_this_iter_s: 22.881144046783447\n",
      "  time_total_s: 3473.4886033535004\n",
      "  timestamp: 1553712487\n",
      "  timesteps_since_restore: 1290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 129\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3473 s, 129 iter, 1290000 ts, 565 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-48-30\n",
      "  done: false\n",
      "  episode_len_mean: 142.77\n",
      "  episode_reward_max: 751.1087837630287\n",
      "  episode_reward_mean: 619.7858136637567\n",
      "  episode_reward_min: -111.59131773080779\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 9197\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3813.55\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 1300000\n",
      "    num_steps_trained: 1300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.106606046004184e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0499017238616943\n",
      "      kl: 2.1031596660614014\n",
      "      policy_loss: 0.012324267998337746\n",
      "      total_loss: 1132.7125244140625\n",
      "      vf_explained_var: 0.8569876551628113\n",
      "      vf_loss: 1132.7001953125\n",
      "    sample_time_ms: 19110.282\n",
      "    update_time_ms: 5.82\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 309.8929068318783\n",
      "  time_since_restore: 3496.436229944229\n",
      "  time_this_iter_s: 22.94762659072876\n",
      "  time_total_s: 3496.436229944229\n",
      "  timestamp: 1553712510\n",
      "  timesteps_since_restore: 1300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1300000\n",
      "  training_iteration: 130\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3496 s, 130 iter, 1300000 ts, 620 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-48-53\n",
      "  done: false\n",
      "  episode_len_mean: 142.14\n",
      "  episode_reward_max: 765.9694014128607\n",
      "  episode_reward_mean: 613.6604661161834\n",
      "  episode_reward_min: -117.90509543292946\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 9268\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.319\n",
      "    load_time_ms: 1.757\n",
      "    num_steps_sampled: 1310000\n",
      "    num_steps_trained: 1310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.159907877866194e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0213192701339722\n",
      "      kl: 35.22089767456055\n",
      "      policy_loss: 0.027057543396949768\n",
      "      total_loss: 1092.4256591796875\n",
      "      vf_explained_var: 0.8659049868583679\n",
      "      vf_loss: 1092.398681640625\n",
      "    sample_time_ms: 19078.139\n",
      "    update_time_ms: 5.86\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 306.8302330580918\n",
      "  time_since_restore: 3518.985241651535\n",
      "  time_this_iter_s: 22.549011707305908\n",
      "  time_total_s: 3518.985241651535\n",
      "  timestamp: 1553712533\n",
      "  timesteps_since_restore: 1310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1310000\n",
      "  training_iteration: 131\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3518 s, 131 iter, 1310000 ts, 614 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-49-16\n",
      "  done: false\n",
      "  episode_len_mean: 133.33\n",
      "  episode_reward_max: 748.8454686963456\n",
      "  episode_reward_mean: 553.651839813217\n",
      "  episode_reward_min: -101.98493158499012\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 9345\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3817.815\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.239862081497087e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9887579679489136\n",
      "      kl: 0.0930606797337532\n",
      "      policy_loss: 0.01044643484055996\n",
      "      total_loss: 2108.437255859375\n",
      "      vf_explained_var: 0.7414127588272095\n",
      "      vf_loss: 2108.4267578125\n",
      "    sample_time_ms: 19069.823\n",
      "    update_time_ms: 5.821\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 276.8259199066085\n",
      "  time_since_restore: 3541.98765707016\n",
      "  time_this_iter_s: 23.002415418624878\n",
      "  time_total_s: 3541.98765707016\n",
      "  timestamp: 1553712556\n",
      "  timesteps_since_restore: 1320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 132\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3541 s, 132 iter, 1320000 ts, 554 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-49-40\n",
      "  done: false\n",
      "  episode_len_mean: 126.16\n",
      "  episode_reward_max: 757.3251069076731\n",
      "  episode_reward_mean: 503.276924278991\n",
      "  episode_reward_min: -134.55434718679226\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 9426\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.803\n",
      "    load_time_ms: 1.722\n",
      "    num_steps_sampled: 1330000\n",
      "    num_steps_trained: 1330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3859795769223591e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9573205709457397\n",
      "      kl: 0.05870822072029114\n",
      "      policy_loss: 0.00836929865181446\n",
      "      total_loss: 3422.404541015625\n",
      "      vf_explained_var: 0.599328875541687\n",
      "      vf_loss: 3422.396240234375\n",
      "    sample_time_ms: 19168.258\n",
      "    update_time_ms: 5.899\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 251.63846213949554\n",
      "  time_since_restore: 3566.4284069538116\n",
      "  time_this_iter_s: 24.440749883651733\n",
      "  time_total_s: 3566.4284069538116\n",
      "  timestamp: 1553712580\n",
      "  timesteps_since_restore: 1330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1330000\n",
      "  training_iteration: 133\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3566 s, 133 iter, 1330000 ts, 503 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-50-03\n",
      "  done: false\n",
      "  episode_len_mean: 133.72\n",
      "  episode_reward_max: 758.8685651349964\n",
      "  episode_reward_mean: 564.2283315868435\n",
      "  episode_reward_min: -122.74387908955039\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 9502\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.56\n",
      "    load_time_ms: 1.763\n",
      "    num_steps_sampled: 1340000\n",
      "    num_steps_trained: 1340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0789695242022163e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9478323459625244\n",
      "      kl: 0.21826763451099396\n",
      "      policy_loss: 0.012044898234307766\n",
      "      total_loss: 2040.6397705078125\n",
      "      vf_explained_var: 0.750267744064331\n",
      "      vf_loss: 2040.6278076171875\n",
      "    sample_time_ms: 19176.971\n",
      "    update_time_ms: 5.846\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 282.11416579342176\n",
      "  time_since_restore: 3589.122704744339\n",
      "  time_this_iter_s: 22.694297790527344\n",
      "  time_total_s: 3589.122704744339\n",
      "  timestamp: 1553712603\n",
      "  timesteps_since_restore: 1340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1340000\n",
      "  training_iteration: 134\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3589 s, 134 iter, 1340000 ts, 564 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-50-26\n",
      "  done: false\n",
      "  episode_len_mean: 134.29\n",
      "  episode_reward_max: 747.3205946527848\n",
      "  episode_reward_mean: 569.8936943234982\n",
      "  episode_reward_min: -124.72570356686725\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 9578\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3888.885\n",
      "    load_time_ms: 1.743\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.118453862786851e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9338650703430176\n",
      "      kl: 0.9898372292518616\n",
      "      policy_loss: 0.018825815990567207\n",
      "      total_loss: 2058.716796875\n",
      "      vf_explained_var: 0.74879390001297\n",
      "      vf_loss: 2058.697998046875\n",
      "    sample_time_ms: 19185.752\n",
      "    update_time_ms: 5.812\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 284.946847161749\n",
      "  time_since_restore: 3611.9127113819122\n",
      "  time_this_iter_s: 22.790006637573242\n",
      "  time_total_s: 3611.9127113819122\n",
      "  timestamp: 1553712626\n",
      "  timesteps_since_restore: 1350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 135\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3611 s, 135 iter, 1350000 ts, 570 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-50-50\n",
      "  done: false\n",
      "  episode_len_mean: 135.5\n",
      "  episode_reward_max: 752.7079972099488\n",
      "  episode_reward_mean: 570.7723756931848\n",
      "  episode_reward_min: -122.38150641300808\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 9653\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3889.564\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 1360000\n",
      "    num_steps_trained: 1360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.677681005938513e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9622260928153992\n",
      "      kl: 1.2691491842269897\n",
      "      policy_loss: 0.010608802549540997\n",
      "      total_loss: 1870.35498046875\n",
      "      vf_explained_var: 0.7703334093093872\n",
      "      vf_loss: 1870.3441162109375\n",
      "    sample_time_ms: 19281.995\n",
      "    update_time_ms: 5.739\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 285.38618784659246\n",
      "  time_since_restore: 3635.7914662361145\n",
      "  time_this_iter_s: 23.87875485420227\n",
      "  time_total_s: 3635.7914662361145\n",
      "  timestamp: 1553712650\n",
      "  timesteps_since_restore: 1360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1360000\n",
      "  training_iteration: 136\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3635 s, 136 iter, 1360000 ts, 571 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-51-13\n",
      "  done: false\n",
      "  episode_len_mean: 136.7\n",
      "  episode_reward_max: 759.3170546533192\n",
      "  episode_reward_mean: 593.0191185625084\n",
      "  episode_reward_min: -131.72050372141297\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 9727\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3852.59\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 1370000\n",
      "    num_steps_trained: 1370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.016521932424243e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9195219874382019\n",
      "      kl: 410.1543884277344\n",
      "      policy_loss: 0.05528207868337631\n",
      "      total_loss: 1552.427734375\n",
      "      vf_explained_var: 0.8100746273994446\n",
      "      vf_loss: 1552.3724365234375\n",
      "    sample_time_ms: 19306.0\n",
      "    update_time_ms: 5.198\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 296.5095592812542\n",
      "  time_since_restore: 3658.858884572983\n",
      "  time_this_iter_s: 23.067418336868286\n",
      "  time_total_s: 3658.858884572983\n",
      "  timestamp: 1553712673\n",
      "  timesteps_since_restore: 1370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1370000\n",
      "  training_iteration: 137\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3658 s, 137 iter, 1370000 ts, 593 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-51-36\n",
      "  done: false\n",
      "  episode_len_mean: 139.17\n",
      "  episode_reward_max: 785.4261996444305\n",
      "  episode_reward_mean: 623.209203841083\n",
      "  episode_reward_min: -132.88557905351524\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 9799\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3845.103\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0524782475119891e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8618301749229431\n",
      "      kl: 0.043288372457027435\n",
      "      policy_loss: 0.007436896208673716\n",
      "      total_loss: 1097.3775634765625\n",
      "      vf_explained_var: 0.8636830449104309\n",
      "      vf_loss: 1097.3699951171875\n",
      "    sample_time_ms: 19250.439\n",
      "    update_time_ms: 5.259\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 311.6046019205415\n",
      "  time_since_restore: 3681.8128695487976\n",
      "  time_this_iter_s: 22.95398497581482\n",
      "  time_total_s: 3681.8128695487976\n",
      "  timestamp: 1553712696\n",
      "  timesteps_since_restore: 1380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 138\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3681 s, 138 iter, 1380000 ts, 623 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-51-59\n",
      "  done: false\n",
      "  episode_len_mean: 129.66\n",
      "  episode_reward_max: 757.937096772193\n",
      "  episode_reward_mean: 550.6433370784026\n",
      "  episode_reward_min: -101.859457305949\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 9878\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3839.372\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 1390000\n",
      "    num_steps_trained: 1390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.578717286564689e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.835185706615448\n",
      "      kl: 0.05520322918891907\n",
      "      policy_loss: 0.006918975152075291\n",
      "      total_loss: 2296.25927734375\n",
      "      vf_explained_var: 0.7149287462234497\n",
      "      vf_loss: 2296.25244140625\n",
      "    sample_time_ms: 19261.864\n",
      "    update_time_ms: 5.329\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 275.32166853920126\n",
      "  time_since_restore: 3704.750391483307\n",
      "  time_this_iter_s: 22.937521934509277\n",
      "  time_total_s: 3704.750391483307\n",
      "  timestamp: 1553712719\n",
      "  timesteps_since_restore: 1390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1390000\n",
      "  training_iteration: 139\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3704 s, 139 iter, 1390000 ts, 551 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-52-22\n",
      "  done: false\n",
      "  episode_len_mean: 126.23\n",
      "  episode_reward_max: 767.2086908411242\n",
      "  episode_reward_mean: 521.7054230511322\n",
      "  episode_reward_min: -114.13420927152255\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 9960\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3842.61\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 1400000\n",
      "    num_steps_trained: 1400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.368076099253623e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.871890127658844\n",
      "      kl: 0.08911964297294617\n",
      "      policy_loss: 0.011674351990222931\n",
      "      total_loss: 2987.315185546875\n",
      "      vf_explained_var: 0.6410166621208191\n",
      "      vf_loss: 2987.3037109375\n",
      "    sample_time_ms: 19267.166\n",
      "    update_time_ms: 5.403\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 260.8527115255662\n",
      "  time_since_restore: 3727.7823798656464\n",
      "  time_this_iter_s: 23.031988382339478\n",
      "  time_total_s: 3727.7823798656464\n",
      "  timestamp: 1553712742\n",
      "  timesteps_since_restore: 1400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1400000\n",
      "  training_iteration: 140\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3727 s, 140 iter, 1400000 ts, 522 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-52-45\n",
      "  done: false\n",
      "  episode_len_mean: 135.72\n",
      "  episode_reward_max: 751.3408760628646\n",
      "  episode_reward_mean: 608.865867372389\n",
      "  episode_reward_min: -108.09118801742748\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 10033\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3842.47\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.552113640660666e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8574396967887878\n",
      "      kl: 1.4938799142837524\n",
      "      policy_loss: 0.01188691332936287\n",
      "      total_loss: 1266.3712158203125\n",
      "      vf_explained_var: 0.8418250679969788\n",
      "      vf_loss: 1266.359375\n",
      "    sample_time_ms: 19319.105\n",
      "    update_time_ms: 5.349\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 304.43293368619436\n",
      "  time_since_restore: 3750.8514564037323\n",
      "  time_this_iter_s: 23.069076538085938\n",
      "  time_total_s: 3750.8514564037323\n",
      "  timestamp: 1553712765\n",
      "  timesteps_since_restore: 1410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 141\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3750 s, 141 iter, 1410000 ts, 609 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-53-08\n",
      "  done: false\n",
      "  episode_len_mean: 128.16\n",
      "  episode_reward_max: 741.2080005851957\n",
      "  episode_reward_mean: 539.0247609537979\n",
      "  episode_reward_min: -118.84551940079254\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 10114\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3845.021\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 1420000\n",
      "    num_steps_trained: 1420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.3281702915844095e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8560192584991455\n",
      "      kl: 0.11762125045061111\n",
      "      policy_loss: 0.012106751091778278\n",
      "      total_loss: 2785.72607421875\n",
      "      vf_explained_var: 0.6718848347663879\n",
      "      vf_loss: 2785.7138671875\n",
      "    sample_time_ms: 19311.778\n",
      "    update_time_ms: 5.402\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 269.51238047689895\n",
      "  time_since_restore: 3773.8052768707275\n",
      "  time_this_iter_s: 22.95382046699524\n",
      "  time_total_s: 3773.8052768707275\n",
      "  timestamp: 1553712788\n",
      "  timesteps_since_restore: 1420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1420000\n",
      "  training_iteration: 142\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3773 s, 142 iter, 1420000 ts, 539 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-53-31\n",
      "  done: false\n",
      "  episode_len_mean: 117.12\n",
      "  episode_reward_max: 768.6611778969608\n",
      "  episode_reward_mean: 443.30492835483363\n",
      "  episode_reward_min: -124.04064226203032\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 10201\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3775.999\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 1430000\n",
      "    num_steps_trained: 1430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.992255945596383e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8420457243919373\n",
      "      kl: 0.049966175109148026\n",
      "      policy_loss: 0.006923365406692028\n",
      "      total_loss: 4219.8427734375\n",
      "      vf_explained_var: 0.5359997153282166\n",
      "      vf_loss: 4219.8359375\n",
      "    sample_time_ms: 19244.524\n",
      "    update_time_ms: 5.353\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 221.65246417741682\n",
      "  time_since_restore: 3796.8841898441315\n",
      "  time_this_iter_s: 23.07891297340393\n",
      "  time_total_s: 3796.8841898441315\n",
      "  timestamp: 1553712811\n",
      "  timesteps_since_restore: 1430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1430000\n",
      "  training_iteration: 143\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3796 s, 143 iter, 1430000 ts, 443 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-53-54\n",
      "  done: false\n",
      "  episode_len_mean: 131.83\n",
      "  episode_reward_max: 738.3590141929424\n",
      "  episode_reward_mean: 568.6206230568217\n",
      "  episode_reward_min: -125.28852370292546\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 10276\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3774.677\n",
      "    load_time_ms: 1.454\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1988382563141858e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8759141564369202\n",
      "      kl: 26.11833381652832\n",
      "      policy_loss: 0.031777288764715195\n",
      "      total_loss: 1118.8572998046875\n",
      "      vf_explained_var: 0.8600162863731384\n",
      "      vf_loss: 1118.8255615234375\n",
      "    sample_time_ms: 19262.287\n",
      "    update_time_ms: 5.468\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 284.31031152841086\n",
      "  time_since_restore: 3819.7437884807587\n",
      "  time_this_iter_s: 22.859598636627197\n",
      "  time_total_s: 3819.7437884807587\n",
      "  timestamp: 1553712834\n",
      "  timesteps_since_restore: 1440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 144\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3819 s, 144 iter, 1440000 ts, 569 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-54-17\n",
      "  done: false\n",
      "  episode_len_mean: 125.99\n",
      "  episode_reward_max: 738.28073299859\n",
      "  episode_reward_mean: 514.9518164639596\n",
      "  episode_reward_min: -122.91685890978741\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 10357\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3775.347\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 1450000\n",
      "    num_steps_trained: 1450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7982574522339145e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8922065496444702\n",
      "      kl: 0.07994051277637482\n",
      "      policy_loss: 0.008326643146574497\n",
      "      total_loss: 2832.68603515625\n",
      "      vf_explained_var: 0.6726807355880737\n",
      "      vf_loss: 2832.677978515625\n",
      "    sample_time_ms: 19278.098\n",
      "    update_time_ms: 5.583\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 257.47590823197976\n",
      "  time_since_restore: 3842.702475309372\n",
      "  time_this_iter_s: 22.95868682861328\n",
      "  time_total_s: 3842.702475309372\n",
      "  timestamp: 1553712857\n",
      "  timesteps_since_restore: 1450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1450000\n",
      "  training_iteration: 145\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3842 s, 145 iter, 1450000 ts, 515 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-54-40\n",
      "  done: false\n",
      "  episode_len_mean: 128.57\n",
      "  episode_reward_max: 775.2864925149165\n",
      "  episode_reward_mean: 541.5248830750735\n",
      "  episode_reward_min: -139.53120530497947\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 10436\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3773.293\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 1460000\n",
      "    num_steps_trained: 1460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.6973865849266865e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8982428312301636\n",
      "      kl: 0.18671467900276184\n",
      "      policy_loss: 0.014686639420688152\n",
      "      total_loss: 2234.91796875\n",
      "      vf_explained_var: 0.7311574220657349\n",
      "      vf_loss: 2234.9033203125\n",
      "    sample_time_ms: 19179.524\n",
      "    update_time_ms: 5.585\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 270.76244153753674\n",
      "  time_since_restore: 3865.574801683426\n",
      "  time_this_iter_s: 22.872326374053955\n",
      "  time_total_s: 3865.574801683426\n",
      "  timestamp: 1553712880\n",
      "  timesteps_since_restore: 1460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1460000\n",
      "  training_iteration: 146\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3865 s, 146 iter, 1460000 ts, 542 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-55-02\n",
      "  done: false\n",
      "  episode_len_mean: 134.6\n",
      "  episode_reward_max: 751.8710194656092\n",
      "  episode_reward_mean: 580.8024772467775\n",
      "  episode_reward_min: -117.87665518291445\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 10512\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3778.466\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.0460793352889435e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9533273577690125\n",
      "      kl: 5.955127239227295\n",
      "      policy_loss: 0.016156386584043503\n",
      "      total_loss: 1662.9271240234375\n",
      "      vf_explained_var: 0.7933830618858337\n",
      "      vf_loss: 1662.9110107421875\n",
      "    sample_time_ms: 19133.392\n",
      "    update_time_ms: 5.58\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.40123862338874\n",
      "  time_since_restore: 3888.2328515052795\n",
      "  time_this_iter_s: 22.658049821853638\n",
      "  time_total_s: 3888.2328515052795\n",
      "  timestamp: 1553712902\n",
      "  timesteps_since_restore: 1470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 147\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3888 s, 147 iter, 1470000 ts, 581 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-55-26\n",
      "  done: false\n",
      "  episode_len_mean: 122.88\n",
      "  episode_reward_max: 752.6194290350461\n",
      "  episode_reward_mean: 487.9223363388953\n",
      "  episode_reward_min: -130.5910969113247\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 10595\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.89\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 1480000\n",
      "    num_steps_trained: 1480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.069119816085045e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8726056218147278\n",
      "      kl: 0.08303851634263992\n",
      "      policy_loss: 0.011041037738323212\n",
      "      total_loss: 3379.489501953125\n",
      "      vf_explained_var: 0.6093692183494568\n",
      "      vf_loss: 3379.479248046875\n",
      "    sample_time_ms: 19146.172\n",
      "    update_time_ms: 5.544\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 243.9611681694477\n",
      "  time_since_restore: 3911.2953572273254\n",
      "  time_this_iter_s: 23.0625057220459\n",
      "  time_total_s: 3911.2953572273254\n",
      "  timestamp: 1553712926\n",
      "  timesteps_since_restore: 1480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1480000\n",
      "  training_iteration: 148\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3911 s, 148 iter, 1480000 ts, 488 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-55-48\n",
      "  done: false\n",
      "  episode_len_mean: 134.82\n",
      "  episode_reward_max: 747.878688386417\n",
      "  episode_reward_mean: 584.8470163159822\n",
      "  episode_reward_min: -106.55626848731458\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 10670\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.579\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 1490000\n",
      "    num_steps_trained: 1490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.103681350430826e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.897191047668457\n",
      "      kl: 13.25737476348877\n",
      "      policy_loss: 0.04711807519197464\n",
      "      total_loss: 1761.3172607421875\n",
      "      vf_explained_var: 0.781182587146759\n",
      "      vf_loss: 1761.270263671875\n",
      "    sample_time_ms: 19120.263\n",
      "    update_time_ms: 5.267\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.42350815799114\n",
      "  time_since_restore: 3933.9715745449066\n",
      "  time_this_iter_s: 22.676217317581177\n",
      "  time_total_s: 3933.9715745449066\n",
      "  timestamp: 1553712948\n",
      "  timesteps_since_restore: 1490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1490000\n",
      "  training_iteration: 149\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3933 s, 149 iter, 1490000 ts, 585 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-56-11\n",
      "  done: false\n",
      "  episode_len_mean: 134.92\n",
      "  episode_reward_max: 787.4817810198842\n",
      "  episode_reward_mean: 586.9538799315405\n",
      "  episode_reward_min: -127.91141437662795\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 10745\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3775.674\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.365551877303972e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9214813113212585\n",
      "      kl: 4.067906379699707\n",
      "      policy_loss: 0.017780547961592674\n",
      "      total_loss: 1891.4493408203125\n",
      "      vf_explained_var: 0.7686506509780884\n",
      "      vf_loss: 1891.431884765625\n",
      "    sample_time_ms: 19104.479\n",
      "    update_time_ms: 5.217\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 293.47693996577027\n",
      "  time_since_restore: 3956.8373532295227\n",
      "  time_this_iter_s: 22.86577868461609\n",
      "  time_total_s: 3956.8373532295227\n",
      "  timestamp: 1553712971\n",
      "  timesteps_since_restore: 1500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 150\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3956 s, 150 iter, 1500000 ts, 587 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-56-34\n",
      "  done: false\n",
      "  episode_len_mean: 137.12\n",
      "  episode_reward_max: 750.9327847095369\n",
      "  episode_reward_mean: 596.8148556177653\n",
      "  episode_reward_min: -127.5655849775682\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 10820\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.75\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 1510000\n",
      "    num_steps_trained: 1510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0483276533256323e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9879365563392639\n",
      "      kl: 1.4521677494049072\n",
      "      policy_loss: 0.011619758792221546\n",
      "      total_loss: 1726.2137451171875\n",
      "      vf_explained_var: 0.7887151837348938\n",
      "      vf_loss: 1726.2022705078125\n",
      "    sample_time_ms: 19074.567\n",
      "    update_time_ms: 5.33\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 298.4074278088827\n",
      "  time_since_restore: 3979.6165075302124\n",
      "  time_this_iter_s: 22.779154300689697\n",
      "  time_total_s: 3979.6165075302124\n",
      "  timestamp: 1553712994\n",
      "  timesteps_since_restore: 1510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1510000\n",
      "  training_iteration: 151\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 3979 s, 151 iter, 1510000 ts, 597 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-56-57\n",
      "  done: false\n",
      "  episode_len_mean: 131.94\n",
      "  episode_reward_max: 736.9889046771444\n",
      "  episode_reward_mean: 561.9643881249289\n",
      "  episode_reward_min: -121.7121785964795\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 10897\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3782.863\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 1520000\n",
      "    num_steps_trained: 1520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.072491696828883e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.902116060256958\n",
      "      kl: 0.0609436109662056\n",
      "      policy_loss: 0.009196355938911438\n",
      "      total_loss: 2308.24951171875\n",
      "      vf_explained_var: 0.7221531867980957\n",
      "      vf_loss: 2308.240478515625\n",
      "    sample_time_ms: 19062.031\n",
      "    update_time_ms: 5.374\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.9821940624645\n",
      "  time_since_restore: 4002.509346008301\n",
      "  time_this_iter_s: 22.89283847808838\n",
      "  time_total_s: 4002.509346008301\n",
      "  timestamp: 1553713017\n",
      "  timesteps_since_restore: 1520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1520000\n",
      "  training_iteration: 152\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4002 s, 152 iter, 1520000 ts, 562 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-57-22\n",
      "  done: false\n",
      "  episode_len_mean: 136.45\n",
      "  episode_reward_max: 763.787295529921\n",
      "  episode_reward_mean: 590.0472544446798\n",
      "  episode_reward_min: -113.69776142837642\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 10973\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3885.806\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.608737003142238e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9463739395141602\n",
      "      kl: 2.437851905822754\n",
      "      policy_loss: 0.02475951798260212\n",
      "      total_loss: 1662.412353515625\n",
      "      vf_explained_var: 0.808711051940918\n",
      "      vf_loss: 1662.3875732421875\n",
      "    sample_time_ms: 19172.568\n",
      "    update_time_ms: 5.251\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.0236272223398\n",
      "  time_since_restore: 4027.7237906455994\n",
      "  time_this_iter_s: 25.214444637298584\n",
      "  time_total_s: 4027.7237906455994\n",
      "  timestamp: 1553713042\n",
      "  timesteps_since_restore: 1530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 153\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4027 s, 153 iter, 1530000 ts, 590 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-57-51\n",
      "  done: false\n",
      "  episode_len_mean: 132.01\n",
      "  episode_reward_max: 768.573076792758\n",
      "  episode_reward_mean: 548.0780451063561\n",
      "  episode_reward_min: -125.2817828308051\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 11048\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4109.439\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 1540000\n",
      "    num_steps_trained: 1540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.913105504713357e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9508528113365173\n",
      "      kl: 0.3583918511867523\n",
      "      policy_loss: 0.012717743404209614\n",
      "      total_loss: 2268.363037109375\n",
      "      vf_explained_var: 0.7289877533912659\n",
      "      vf_loss: 2268.35009765625\n",
      "    sample_time_ms: 19495.999\n",
      "    update_time_ms: 5.209\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 274.03902255317803\n",
      "  time_since_restore: 4056.054107427597\n",
      "  time_this_iter_s: 28.33031678199768\n",
      "  time_total_s: 4056.054107427597\n",
      "  timestamp: 1553713071\n",
      "  timesteps_since_restore: 1540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1540000\n",
      "  training_iteration: 154\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4056 s, 154 iter, 1540000 ts, 548 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-58-30\n",
      "  done: false\n",
      "  episode_len_mean: 136.04\n",
      "  episode_reward_max: 758.2804567371692\n",
      "  episode_reward_mean: 589.0717948713442\n",
      "  episode_reward_min: -124.71543476249775\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 11124\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4754.279\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 1550000\n",
      "    num_steps_trained: 1550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0369658257070036e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9523186087608337\n",
      "      kl: 1.4688515663146973\n",
      "      policy_loss: 0.012557278387248516\n",
      "      total_loss: 1751.0928955078125\n",
      "      vf_explained_var: 0.7927911281585693\n",
      "      vf_loss: 1751.080078125\n",
      "    sample_time_ms: 20474.872\n",
      "    update_time_ms: 5.084\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 294.5358974356721\n",
      "  time_since_restore: 4095.2602331638336\n",
      "  time_this_iter_s: 39.20612573623657\n",
      "  time_total_s: 4095.2602331638336\n",
      "  timestamp: 1553713110\n",
      "  timesteps_since_restore: 1550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1550000\n",
      "  training_iteration: 155\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4095 s, 155 iter, 1550000 ts, 589 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_19-59-24\n",
      "  done: false\n",
      "  episode_len_mean: 135.01\n",
      "  episode_reward_max: 761.1764528086554\n",
      "  episode_reward_mean: 583.19895601994\n",
      "  episode_reward_min: -97.12263793455136\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 11199\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5585.625\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5554486518243316e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9387682676315308\n",
      "      kl: 0.5296251177787781\n",
      "      policy_loss: 0.014873149804770947\n",
      "      total_loss: 2005.1834716796875\n",
      "      vf_explained_var: 0.758956789970398\n",
      "      vf_loss: 2005.168701171875\n",
      "    sample_time_ms: 22794.577\n",
      "    update_time_ms: 5.624\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 291.59947800997\n",
      "  time_since_restore: 4149.68585395813\n",
      "  time_this_iter_s: 54.425620794296265\n",
      "  time_total_s: 4149.68585395813\n",
      "  timestamp: 1553713164\n",
      "  timesteps_since_restore: 1560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 156\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4149 s, 156 iter, 1560000 ts, 583 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-00-17\n",
      "  done: false\n",
      "  episode_len_mean: 135.16\n",
      "  episode_reward_max: 787.95099332758\n",
      "  episode_reward_mean: 580.6815949900256\n",
      "  episode_reward_min: -89.8764179203916\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 11275\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5630.951\n",
      "    load_time_ms: 1.676\n",
      "    num_steps_sampled: 1570000\n",
      "    num_steps_trained: 1570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3331737583620615e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9496974349021912\n",
      "      kl: 0.6553558707237244\n",
      "      policy_loss: 0.0190486591309309\n",
      "      total_loss: 1820.0556640625\n",
      "      vf_explained_var: 0.7805511355400085\n",
      "      vf_loss: 1820.0364990234375\n",
      "    sample_time_ms: 25744.364\n",
      "    update_time_ms: 6.774\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.3407974950128\n",
      "  time_since_restore: 4202.310061216354\n",
      "  time_this_iter_s: 52.62420725822449\n",
      "  time_total_s: 4202.310061216354\n",
      "  timestamp: 1553713217\n",
      "  timesteps_since_restore: 1570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1570000\n",
      "  training_iteration: 157\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4202 s, 157 iter, 1570000 ts, 581 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-00-49\n",
      "  done: false\n",
      "  episode_len_mean: 128.58\n",
      "  episode_reward_max: 750.8640963953511\n",
      "  episode_reward_mean: 524.8261247569225\n",
      "  episode_reward_min: -129.11046212053424\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 11355\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5747.347\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 1580000\n",
      "    num_steps_trained: 1580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.499759509972833e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9210359454154968\n",
      "      kl: 0.19235537946224213\n",
      "      policy_loss: 0.020295443013310432\n",
      "      total_loss: 3088.6279296875\n",
      "      vf_explained_var: 0.6447829604148865\n",
      "      vf_loss: 3088.607421875\n",
      "    sample_time_ms: 26521.699\n",
      "    update_time_ms: 6.87\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 262.41306237846123\n",
      "  time_since_restore: 4234.312304019928\n",
      "  time_this_iter_s: 32.00224280357361\n",
      "  time_total_s: 4234.312304019928\n",
      "  timestamp: 1553713249\n",
      "  timesteps_since_restore: 1580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1580000\n",
      "  training_iteration: 158\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4234 s, 158 iter, 1580000 ts, 525 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-01-30\n",
      "  done: false\n",
      "  episode_len_mean: 134.21\n",
      "  episode_reward_max: 740.783339278528\n",
      "  episode_reward_mean: 571.601702384604\n",
      "  episode_reward_min: -121.51037707923311\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 11431\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6494.296\n",
      "    load_time_ms: 1.692\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.24963995884864e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9476112723350525\n",
      "      kl: 0.17802828550338745\n",
      "      policy_loss: 0.01977182738482952\n",
      "      total_loss: 2087.758544921875\n",
      "      vf_explained_var: 0.7520076036453247\n",
      "      vf_loss: 2087.73876953125\n",
      "    sample_time_ms: 27531.557\n",
      "    update_time_ms: 7.052\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 285.80085119230193\n",
      "  time_since_restore: 4274.580229759216\n",
      "  time_this_iter_s: 40.26792573928833\n",
      "  time_total_s: 4274.580229759216\n",
      "  timestamp: 1553713290\n",
      "  timesteps_since_restore: 1590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 159\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4274 s, 159 iter, 1590000 ts, 572 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-02-53\n",
      "  done: false\n",
      "  episode_len_mean: 134.09\n",
      "  episode_reward_max: 773.2406797740654\n",
      "  episode_reward_mean: 578.9477881279338\n",
      "  episode_reward_min: -126.19984144810566\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 11508\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8113.005\n",
      "    load_time_ms: 1.905\n",
      "    num_steps_sampled: 1600000\n",
      "    num_steps_trained: 1600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.874461499524088e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9332566857337952\n",
      "      kl: 1.1521176099777222\n",
      "      policy_loss: 0.01834954135119915\n",
      "      total_loss: 1957.6444091796875\n",
      "      vf_explained_var: 0.7718948125839233\n",
      "      vf_loss: 1957.626220703125\n",
      "    sample_time_ms: 31928.809\n",
      "    update_time_ms: 8.491\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 289.4738940639669\n",
      "  time_since_restore: 4357.705581903458\n",
      "  time_this_iter_s: 83.12535214424133\n",
      "  time_total_s: 4357.705581903458\n",
      "  timestamp: 1553713373\n",
      "  timesteps_since_restore: 1600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1600000\n",
      "  training_iteration: 160\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4357 s, 160 iter, 1600000 ts, 579 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-04-30\n",
      "  done: false\n",
      "  episode_len_mean: 137.28\n",
      "  episode_reward_max: 759.1580943510062\n",
      "  episode_reward_mean: 601.1019574474171\n",
      "  episode_reward_min: -97.5888913778741\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 11581\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9696.093\n",
      "    load_time_ms: 2.141\n",
      "    num_steps_sampled: 1610000\n",
      "    num_steps_trained: 1610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1811690514562656e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9534129500389099\n",
      "      kl: 9.943522453308105\n",
      "      policy_loss: 0.014144127257168293\n",
      "      total_loss: 1253.197265625\n",
      "      vf_explained_var: 0.8565835356712341\n",
      "      vf_loss: 1253.18310546875\n",
      "    sample_time_ms: 37753.67\n",
      "    update_time_ms: 9.883\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.55097872370857\n",
      "  time_since_restore: 4454.61502289772\n",
      "  time_this_iter_s: 96.9094409942627\n",
      "  time_total_s: 4454.61502289772\n",
      "  timestamp: 1553713470\n",
      "  timesteps_since_restore: 1610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1610000\n",
      "  training_iteration: 161\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4454 s, 161 iter, 1610000 ts, 601 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-06-19\n",
      "  done: false\n",
      "  episode_len_mean: 136.0\n",
      "  episode_reward_max: 781.040999807793\n",
      "  episode_reward_mean: 587.7515496996334\n",
      "  episode_reward_min: -130.52729865115685\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 11656\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 11529.495\n",
      "    load_time_ms: 2.338\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7717537159622765e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9310289025306702\n",
      "      kl: 1.0645148754119873\n",
      "      policy_loss: 0.014381546527147293\n",
      "      total_loss: 1633.4427490234375\n",
      "      vf_explained_var: 0.8092336654663086\n",
      "      vf_loss: 1633.4283447265625\n",
      "    sample_time_ms: 44580.134\n",
      "    update_time_ms: 11.491\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 293.8757748498167\n",
      "  time_since_restore: 4564.156564474106\n",
      "  time_this_iter_s: 109.5415415763855\n",
      "  time_total_s: 4564.156564474106\n",
      "  timestamp: 1553713579\n",
      "  timesteps_since_restore: 1620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 162\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4564 s, 162 iter, 1620000 ts, 588 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-08-16\n",
      "  done: false\n",
      "  episode_len_mean: 135.57\n",
      "  episode_reward_max: 775.8853037586063\n",
      "  episode_reward_mean: 586.5408139159506\n",
      "  episode_reward_min: -131.4236926971365\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 11731\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 13832.836\n",
      "    load_time_ms: 2.631\n",
      "    num_steps_sampled: 1630000\n",
      "    num_steps_trained: 1630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.657629671887207e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9240504503250122\n",
      "      kl: 0.42771047353744507\n",
      "      policy_loss: 0.02285771071910858\n",
      "      total_loss: 1873.189453125\n",
      "      vf_explained_var: 0.774174153804779\n",
      "      vf_loss: 1873.1666259765625\n",
      "    sample_time_ms: 51410.431\n",
      "    update_time_ms: 14.267\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 293.27040695797535\n",
      "  time_since_restore: 4680.803705453873\n",
      "  time_this_iter_s: 116.64714097976685\n",
      "  time_total_s: 4680.803705453873\n",
      "  timestamp: 1553713696\n",
      "  timesteps_since_restore: 1630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1630000\n",
      "  training_iteration: 163\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4680 s, 163 iter, 1630000 ts, 587 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-10-38\n",
      "  done: false\n",
      "  episode_len_mean: 137.43\n",
      "  episode_reward_max: 765.3510261189801\n",
      "  episode_reward_mean: 607.6276135428716\n",
      "  episode_reward_min: -111.80986592778531\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 11804\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 15514.199\n",
      "    load_time_ms: 2.925\n",
      "    num_steps_sampled: 1640000\n",
      "    num_steps_trained: 1640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.986444507830811e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9037221074104309\n",
      "      kl: 13.606789588928223\n",
      "      policy_loss: 0.054980382323265076\n",
      "      total_loss: 1358.281005859375\n",
      "      vf_explained_var: 0.8388851881027222\n",
      "      vf_loss: 1358.2259521484375\n",
      "    sample_time_ms: 61018.54\n",
      "    update_time_ms: 17.126\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 303.8138067714358\n",
      "  time_since_restore: 4822.081334352493\n",
      "  time_this_iter_s: 141.2776288986206\n",
      "  time_total_s: 4822.081334352493\n",
      "  timestamp: 1553713838\n",
      "  timesteps_since_restore: 1640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1640000\n",
      "  training_iteration: 164\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4822 s, 164 iter, 1640000 ts, 608 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-12-24\n",
      "  done: false\n",
      "  episode_len_mean: 132.63\n",
      "  episode_reward_max: 758.7920614263263\n",
      "  episode_reward_mean: 564.67172221742\n",
      "  episode_reward_min: -135.56021601878155\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 11881\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 15970.559\n",
      "    load_time_ms: 3.107\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.979668427080753e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9324943423271179\n",
      "      kl: 0.3908366560935974\n",
      "      policy_loss: 0.02443879470229149\n",
      "      total_loss: 2370.571533203125\n",
      "      vf_explained_var: 0.7217196226119995\n",
      "      vf_loss: 2370.546875\n",
      "    sample_time_ms: 67229.027\n",
      "    update_time_ms: 18.862\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 282.33586110871\n",
      "  time_since_restore: 4927.988604784012\n",
      "  time_this_iter_s: 105.90727043151855\n",
      "  time_total_s: 4927.988604784012\n",
      "  timestamp: 1553713944\n",
      "  timesteps_since_restore: 1650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 165\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4927 s, 165 iter, 1650000 ts, 565 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-13-13\n",
      "  done: false\n",
      "  episode_len_mean: 136.34\n",
      "  episode_reward_max: 743.9710623813022\n",
      "  episode_reward_mean: 584.4913281876954\n",
      "  episode_reward_min: -115.99352074715145\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 11957\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 15208.91\n",
      "    load_time_ms: 3.035\n",
      "    num_steps_sampled: 1660000\n",
      "    num_steps_trained: 1660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.969502363065374e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9354434609413147\n",
      "      kl: 0.2439473420381546\n",
      "      policy_loss: 0.014937186613678932\n",
      "      total_loss: 1806.6666259765625\n",
      "      vf_explained_var: 0.787247359752655\n",
      "      vf_loss: 1806.652099609375\n",
      "    sample_time_ms: 67472.251\n",
      "    update_time_ms: 20.078\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.24566409384767\n",
      "  time_since_restore: 4977.208885192871\n",
      "  time_this_iter_s: 49.22028040885925\n",
      "  time_total_s: 4977.208885192871\n",
      "  timestamp: 1553713993\n",
      "  timesteps_since_restore: 1660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1660000\n",
      "  training_iteration: 166\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 4977 s, 166 iter, 1660000 ts, 584 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-13-39\n",
      "  done: false\n",
      "  episode_len_mean: 131.63\n",
      "  episode_reward_max: 753.8667507761388\n",
      "  episode_reward_mean: 549.2064628094953\n",
      "  episode_reward_min: -125.01710410278139\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 12034\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 15164.33\n",
      "    load_time_ms: 2.98\n",
      "    num_steps_sampled: 1670000\n",
      "    num_steps_trained: 1670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.345425215681928e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9202526807785034\n",
      "      kl: 0.09027555584907532\n",
      "      policy_loss: 0.009112260304391384\n",
      "      total_loss: 2659.115234375\n",
      "      vf_explained_var: 0.6918160915374756\n",
      "      vf_loss: 2659.106201171875\n",
      "    sample_time_ms: 64826.734\n",
      "    update_time_ms: 19.063\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 274.6032314047476\n",
      "  time_since_restore: 5002.91903924942\n",
      "  time_this_iter_s: 25.710154056549072\n",
      "  time_total_s: 5002.91903924942\n",
      "  timestamp: 1553714019\n",
      "  timesteps_since_restore: 1670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1670000\n",
      "  training_iteration: 167\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5002 s, 167 iter, 1670000 ts, 549 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-14-02\n",
      "  done: false\n",
      "  episode_len_mean: 136.89\n",
      "  episode_reward_max: 767.8058545447242\n",
      "  episode_reward_mean: 589.5302247893732\n",
      "  episode_reward_min: -98.32522928921817\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 12109\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 15050.602\n",
      "    load_time_ms: 2.985\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.018138101078648e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0069607496261597\n",
      "      kl: 3.145831823348999\n",
      "      policy_loss: 0.01714697852730751\n",
      "      total_loss: 1651.4398193359375\n",
      "      vf_explained_var: 0.8002737760543823\n",
      "      vf_loss: 1651.4227294921875\n",
      "    sample_time_ms: 64093.774\n",
      "    update_time_ms: 18.924\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 294.7651123946865\n",
      "  time_since_restore: 5026.451558589935\n",
      "  time_this_iter_s: 23.532519340515137\n",
      "  time_total_s: 5026.451558589935\n",
      "  timestamp: 1553714042\n",
      "  timesteps_since_restore: 1680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 168\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5026 s, 168 iter, 1680000 ts, 590 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-14-26\n",
      "  done: false\n",
      "  episode_len_mean: 130.22\n",
      "  episode_reward_max: 745.1265357817047\n",
      "  episode_reward_mean: 527.4413698600598\n",
      "  episode_reward_min: -113.40887329618823\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 12188\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 14304.758\n",
      "    load_time_ms: 2.943\n",
      "    num_steps_sampled: 1690000\n",
      "    num_steps_trained: 1690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0272067075287623e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.005444049835205\n",
      "      kl: 0.09849829226732254\n",
      "      policy_loss: 0.013518529012799263\n",
      "      total_loss: 2848.71435546875\n",
      "      vf_explained_var: 0.675605297088623\n",
      "      vf_loss: 2848.70068359375\n",
      "    sample_time_ms: 63133.214\n",
      "    update_time_ms: 18.78\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 263.7206849300299\n",
      "  time_since_restore: 5049.630366563797\n",
      "  time_this_iter_s: 23.178807973861694\n",
      "  time_total_s: 5049.630366563797\n",
      "  timestamp: 1553714066\n",
      "  timesteps_since_restore: 1690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1690000\n",
      "  training_iteration: 169\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5049 s, 169 iter, 1690000 ts, 527 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-14-49\n",
      "  done: false\n",
      "  episode_len_mean: 134.98\n",
      "  episode_reward_max: 751.7191568221277\n",
      "  episode_reward_mean: 567.0180147077599\n",
      "  episode_reward_min: -121.82376413582652\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 12263\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 12685.358\n",
      "    load_time_ms: 2.705\n",
      "    num_steps_sampled: 1700000\n",
      "    num_steps_trained: 1700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.540810394360051e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0080535411834717\n",
      "      kl: 0.2147836983203888\n",
      "      policy_loss: 0.02156924083828926\n",
      "      total_loss: 2001.90185546875\n",
      "      vf_explained_var: 0.7655742168426514\n",
      "      vf_loss: 2001.8802490234375\n",
      "    sample_time_ms: 58759.211\n",
      "    update_time_ms: 17.394\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 283.50900735387995\n",
      "  time_since_restore: 5072.722597122192\n",
      "  time_this_iter_s: 23.092230558395386\n",
      "  time_total_s: 5072.722597122192\n",
      "  timestamp: 1553714089\n",
      "  timesteps_since_restore: 1700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1700000\n",
      "  training_iteration: 170\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5072 s, 170 iter, 1700000 ts, 567 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-15-12\n",
      "  done: false\n",
      "  episode_len_mean: 135.5\n",
      "  episode_reward_max: 770.3999337646893\n",
      "  episode_reward_mean: 568.218652109039\n",
      "  episode_reward_min: -134.84273093812095\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 12338\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 11099.386\n",
      "    load_time_ms: 2.488\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.811216035629286e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.980352520942688\n",
      "      kl: 1.7845650911331177\n",
      "      policy_loss: 0.03242155909538269\n",
      "      total_loss: 1809.117431640625\n",
      "      vf_explained_var: 0.7867444157600403\n",
      "      vf_loss: 1809.0849609375\n",
      "    sample_time_ms: 52935.601\n",
      "    update_time_ms: 15.83\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 284.1093260545194\n",
      "  time_since_restore: 5095.481769561768\n",
      "  time_this_iter_s: 22.759172439575195\n",
      "  time_total_s: 5095.481769561768\n",
      "  timestamp: 1553714112\n",
      "  timesteps_since_restore: 1710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 171\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5095 s, 171 iter, 1710000 ts, 568 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-15-34\n",
      "  done: false\n",
      "  episode_len_mean: 136.48\n",
      "  episode_reward_max: 762.7473665980821\n",
      "  episode_reward_mean: 579.1906279871538\n",
      "  episode_reward_min: -122.63206723510277\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 12413\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9259.172\n",
      "    load_time_ms: 2.23\n",
      "    num_steps_sampled: 1720000\n",
      "    num_steps_trained: 1720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0216822943220905e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.977874755859375\n",
      "      kl: 0.16865365207195282\n",
      "      policy_loss: 0.016444610431790352\n",
      "      total_loss: 1821.0238037109375\n",
      "      vf_explained_var: 0.7786955833435059\n",
      "      vf_loss: 1821.0074462890625\n",
      "    sample_time_ms: 46109.712\n",
      "    update_time_ms: 14.126\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 289.59531399357695\n",
      "  time_since_restore: 5118.3085923194885\n",
      "  time_this_iter_s: 22.826822757720947\n",
      "  time_total_s: 5118.3085923194885\n",
      "  timestamp: 1553714134\n",
      "  timesteps_since_restore: 1720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1720000\n",
      "  training_iteration: 172\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5118 s, 172 iter, 1720000 ts, 579 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-15-57\n",
      "  done: false\n",
      "  episode_len_mean: 131.64\n",
      "  episode_reward_max: 750.1807224157258\n",
      "  episode_reward_mean: 549.8829664153516\n",
      "  episode_reward_min: -120.34996073978868\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 12491\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6848.681\n",
      "    load_time_ms: 1.941\n",
      "    num_steps_sampled: 1730000\n",
      "    num_steps_trained: 1730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5325234414831357e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9742233157157898\n",
      "      kl: 0.2672751843929291\n",
      "      policy_loss: 0.02128901518881321\n",
      "      total_loss: 2678.80078125\n",
      "      vf_explained_var: 0.6879345774650574\n",
      "      vf_loss: 2678.779541015625\n",
      "    sample_time_ms: 39155.831\n",
      "    update_time_ms: 11.452\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 274.94148320767584\n",
      "  time_since_restore: 5141.2153697013855\n",
      "  time_this_iter_s: 22.906777381896973\n",
      "  time_total_s: 5141.2153697013855\n",
      "  timestamp: 1553714157\n",
      "  timesteps_since_restore: 1730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1730000\n",
      "  training_iteration: 173\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5141 s, 173 iter, 1730000 ts, 550 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-16-20\n",
      "  done: false\n",
      "  episode_len_mean: 137.34\n",
      "  episode_reward_max: 757.7805412121572\n",
      "  episode_reward_mean: 599.1501312415653\n",
      "  episode_reward_min: -128.19845690936245\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 12566\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4946.117\n",
      "    load_time_ms: 1.711\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2987851622247035e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9537083506584167\n",
      "      kl: 2.0594441890716553\n",
      "      policy_loss: 0.01791914366185665\n",
      "      total_loss: 1695.481201171875\n",
      "      vf_explained_var: 0.8005599975585938\n",
      "      vf_loss: 1695.463134765625\n",
      "    sample_time_ms: 29183.75\n",
      "    update_time_ms: 8.507\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 299.57506562078265\n",
      "  time_since_restore: 5163.692088603973\n",
      "  time_this_iter_s: 22.47671890258789\n",
      "  time_total_s: 5163.692088603973\n",
      "  timestamp: 1553714180\n",
      "  timesteps_since_restore: 1740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 174\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5163 s, 174 iter, 1740000 ts, 599 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-16-43\n",
      "  done: false\n",
      "  episode_len_mean: 135.46\n",
      "  episode_reward_max: 741.7815167825104\n",
      "  episode_reward_mean: 577.7390479437721\n",
      "  episode_reward_min: -115.60380743297333\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 12641\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3847.698\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 1750000\n",
      "    num_steps_trained: 1750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.448177920972739e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9610986709594727\n",
      "      kl: 0.40175580978393555\n",
      "      policy_loss: 0.028966685757040977\n",
      "      total_loss: 2013.2647705078125\n",
      "      vf_explained_var: 0.7612097263336182\n",
      "      vf_loss: 2013.2359619140625\n",
      "    sample_time_ms: 21962.805\n",
      "    update_time_ms: 6.838\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 288.86952397188605\n",
      "  time_since_restore: 5186.36075258255\n",
      "  time_this_iter_s: 22.66866397857666\n",
      "  time_total_s: 5186.36075258255\n",
      "  timestamp: 1553714203\n",
      "  timesteps_since_restore: 1750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1750000\n",
      "  training_iteration: 175\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5186 s, 175 iter, 1750000 ts, 578 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-17-06\n",
      "  done: false\n",
      "  episode_len_mean: 136.76\n",
      "  episode_reward_max: 760.1995563909635\n",
      "  episode_reward_mean: 586.7289733450048\n",
      "  episode_reward_min: -135.19247038513447\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 12715\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.258\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 1760000\n",
      "    num_steps_trained: 1760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.172267236730477e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9458523988723755\n",
      "      kl: 0.47760480642318726\n",
      "      policy_loss: 0.018076341599225998\n",
      "      total_loss: 1794.797119140625\n",
      "      vf_explained_var: 0.7882454991340637\n",
      "      vf_loss: 1794.77880859375\n",
      "    sample_time_ms: 19424.041\n",
      "    update_time_ms: 5.019\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 293.36448667250227\n",
      "  time_since_restore: 5209.455316543579\n",
      "  time_this_iter_s: 23.094563961029053\n",
      "  time_total_s: 5209.455316543579\n",
      "  timestamp: 1553714226\n",
      "  timesteps_since_restore: 1760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1760000\n",
      "  training_iteration: 176\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5209 s, 176 iter, 1760000 ts, 587 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 139.44\n",
      "  episode_reward_max: 764.1559452852455\n",
      "  episode_reward_mean: 608.8143923245174\n",
      "  episode_reward_min: -110.2642431072909\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 12788\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3773.866\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.758399789281611e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.012897253036499\n",
      "      kl: 60.09974670410156\n",
      "      policy_loss: 0.051719922572374344\n",
      "      total_loss: 1155.9893798828125\n",
      "      vf_explained_var: 0.8601187467575073\n",
      "      vf_loss: 1155.937744140625\n",
      "    sample_time_ms: 19163.608\n",
      "    update_time_ms: 4.99\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 304.40719616225863\n",
      "  time_since_restore: 5232.537513971329\n",
      "  time_this_iter_s: 23.082197427749634\n",
      "  time_total_s: 5232.537513971329\n",
      "  timestamp: 1553714249\n",
      "  timesteps_since_restore: 1770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 177\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5232 s, 177 iter, 1770000 ts, 609 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-17-52\n",
      "  done: false\n",
      "  episode_len_mean: 135.9\n",
      "  episode_reward_max: 788.9346899399845\n",
      "  episode_reward_mean: 569.891929129524\n",
      "  episode_reward_min: -100.74129475995308\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 12863\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3773.221\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 1780000\n",
      "    num_steps_trained: 1780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1637600039193785e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0318869352340698\n",
      "      kl: 0.19952228665351868\n",
      "      policy_loss: 0.020873699337244034\n",
      "      total_loss: 2116.473876953125\n",
      "      vf_explained_var: 0.7613253593444824\n",
      "      vf_loss: 2116.453125\n",
      "    sample_time_ms: 19094.976\n",
      "    update_time_ms: 4.961\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 284.94596456476194\n",
      "  time_since_restore: 5255.377048492432\n",
      "  time_this_iter_s: 22.839534521102905\n",
      "  time_total_s: 5255.377048492432\n",
      "  timestamp: 1553714272\n",
      "  timesteps_since_restore: 1780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1780000\n",
      "  training_iteration: 178\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5255 s, 178 iter, 1780000 ts, 570 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-18-15\n",
      "  done: false\n",
      "  episode_len_mean: 131.87\n",
      "  episode_reward_max: 751.0569773676544\n",
      "  episode_reward_mean: 540.7768856433667\n",
      "  episode_reward_min: -120.6780008124826\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 12940\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3781.224\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 1790000\n",
      "    num_steps_trained: 1790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.745639792716247e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0086095333099365\n",
      "      kl: 7.454145431518555\n",
      "      policy_loss: 0.0394025519490242\n",
      "      total_loss: 2350.630615234375\n",
      "      vf_explained_var: 0.7283163666725159\n",
      "      vf_loss: 2350.591064453125\n",
      "    sample_time_ms: 19069.271\n",
      "    update_time_ms: 4.993\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 270.3884428216833\n",
      "  time_since_restore: 5278.380491018295\n",
      "  time_this_iter_s: 23.003442525863647\n",
      "  time_total_s: 5278.380491018295\n",
      "  timestamp: 1553714295\n",
      "  timesteps_since_restore: 1790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1790000\n",
      "  training_iteration: 179\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5278 s, 179 iter, 1790000 ts, 541 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 133.6\n",
      "  episode_reward_max: 756.4760795505933\n",
      "  episode_reward_mean: 552.5027149489024\n",
      "  episode_reward_min: -120.88270229084708\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 13015\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3783.33\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.618459973291465e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.001558542251587\n",
      "      kl: 0.14257413148880005\n",
      "      policy_loss: 0.013843744061887264\n",
      "      total_loss: 2243.4169921875\n",
      "      vf_explained_var: 0.7388345003128052\n",
      "      vf_loss: 2243.403076171875\n",
      "    sample_time_ms: 18957.906\n",
      "    update_time_ms: 4.989\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 276.2513574744512\n",
      "  time_since_restore: 5300.377989768982\n",
      "  time_this_iter_s: 21.997498750686646\n",
      "  time_total_s: 5300.377989768982\n",
      "  timestamp: 1553714317\n",
      "  timesteps_since_restore: 1800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 180\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5300 s, 180 iter, 1800000 ts, 553 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-18-59\n",
      "  done: false\n",
      "  episode_len_mean: 143.05\n",
      "  episode_reward_max: 777.7649703605425\n",
      "  episode_reward_mean: 635.6035003741086\n",
      "  episode_reward_min: -113.74014334916721\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 13085\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3788.245\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 1810000\n",
      "    num_steps_trained: 1810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.9276901020457444e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9419445395469666\n",
      "      kl: 4.606053829193115\n",
      "      policy_loss: 0.03143584728240967\n",
      "      total_loss: 1001.1881103515625\n",
      "      vf_explained_var: 0.8813879489898682\n",
      "      vf_loss: 1001.15673828125\n",
      "    sample_time_ms: 18898.572\n",
      "    update_time_ms: 5.027\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 317.8017501870543\n",
      "  time_since_restore: 5322.594149112701\n",
      "  time_this_iter_s: 22.216159343719482\n",
      "  time_total_s: 5322.594149112701\n",
      "  timestamp: 1553714339\n",
      "  timesteps_since_restore: 1810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1810000\n",
      "  training_iteration: 181\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5322 s, 181 iter, 1810000 ts, 636 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-19-22\n",
      "  done: false\n",
      "  episode_len_mean: 139.66\n",
      "  episode_reward_max: 757.2530047669812\n",
      "  episode_reward_mean: 608.7334073450457\n",
      "  episode_reward_min: -104.61561572039068\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 13158\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3794.27\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 1820000\n",
      "    num_steps_trained: 1820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.891533874091692e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0177414417266846\n",
      "      kl: 0.8798685073852539\n",
      "      policy_loss: 0.015104164369404316\n",
      "      total_loss: 1496.5084228515625\n",
      "      vf_explained_var: 0.8226295113563538\n",
      "      vf_loss: 1496.493408203125\n",
      "    sample_time_ms: 18851.534\n",
      "    update_time_ms: 5.131\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 304.3667036725229\n",
      "  time_since_restore: 5345.013760089874\n",
      "  time_this_iter_s: 22.41961097717285\n",
      "  time_total_s: 5345.013760089874\n",
      "  timestamp: 1553714362\n",
      "  timesteps_since_restore: 1820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1820000\n",
      "  training_iteration: 182\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5345 s, 182 iter, 1820000 ts, 609 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-19-44\n",
      "  done: false\n",
      "  episode_len_mean: 133.34\n",
      "  episode_reward_max: 742.8253286043292\n",
      "  episode_reward_mean: 555.0064479346443\n",
      "  episode_reward_min: -112.67456664351565\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 13236\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.763\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.83730422174267e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9922358393669128\n",
      "      kl: 0.13671214878559113\n",
      "      policy_loss: 0.01569284498691559\n",
      "      total_loss: 2656.876953125\n",
      "      vf_explained_var: 0.6958234906196594\n",
      "      vf_loss: 2656.861328125\n",
      "    sample_time_ms: 18808.02\n",
      "    update_time_ms: 5.182\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 277.5032239673221\n",
      "  time_since_restore: 5367.510186910629\n",
      "  time_this_iter_s: 22.496426820755005\n",
      "  time_total_s: 5367.510186910629\n",
      "  timestamp: 1553714384\n",
      "  timesteps_since_restore: 1830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 183\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5367 s, 183 iter, 1830000 ts, 555 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-20-06\n",
      "  done: false\n",
      "  episode_len_mean: 134.41\n",
      "  episode_reward_max: 754.8274984160361\n",
      "  episode_reward_mean: 561.2085211550864\n",
      "  episode_reward_min: -135.53428708841287\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 13312\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.18\n",
      "    load_time_ms: 1.501\n",
      "    num_steps_sampled: 1840000\n",
      "    num_steps_trained: 1840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3255955764179816e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9971033930778503\n",
      "      kl: 0.5286427736282349\n",
      "      policy_loss: 0.027139749377965927\n",
      "      total_loss: 2375.244384765625\n",
      "      vf_explained_var: 0.7253797650337219\n",
      "      vf_loss: 2375.217529296875\n",
      "    sample_time_ms: 18771.102\n",
      "    update_time_ms: 5.146\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.6042605775432\n",
      "  time_since_restore: 5389.669663667679\n",
      "  time_this_iter_s: 22.15947675704956\n",
      "  time_total_s: 5389.669663667679\n",
      "  timestamp: 1553714406\n",
      "  timesteps_since_restore: 1840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1840000\n",
      "  training_iteration: 184\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5389 s, 184 iter, 1840000 ts, 561 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-20-29\n",
      "  done: false\n",
      "  episode_len_mean: 140.79\n",
      "  episode_reward_max: 735.5233172176651\n",
      "  episode_reward_mean: 605.604431622127\n",
      "  episode_reward_min: -103.34651419207385\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 13384\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3803.074\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 1850000\n",
      "    num_steps_trained: 1850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.98839347831381e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0462678670883179\n",
      "      kl: 3.223212242126465\n",
      "      policy_loss: 0.030914582312107086\n",
      "      total_loss: 1176.1654052734375\n",
      "      vf_explained_var: 0.8581022620201111\n",
      "      vf_loss: 1176.134521484375\n",
      "    sample_time_ms: 18742.88\n",
      "    update_time_ms: 5.144\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.80221581106343\n",
      "  time_since_restore: 5412.063899278641\n",
      "  time_this_iter_s: 22.394235610961914\n",
      "  time_total_s: 5412.063899278641\n",
      "  timestamp: 1553714429\n",
      "  timesteps_since_restore: 1850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1850000\n",
      "  training_iteration: 185\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5412 s, 185 iter, 1850000 ts, 606 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-20-51\n",
      "  done: false\n",
      "  episode_len_mean: 135.27\n",
      "  episode_reward_max: 757.6465301513879\n",
      "  episode_reward_mean: 558.398320215535\n",
      "  episode_reward_min: -113.85937109361798\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 13459\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3807.686\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9825896490365267e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.033380150794983\n",
      "      kl: 0.13772185146808624\n",
      "      policy_loss: 0.016292737796902657\n",
      "      total_loss: 2380.651123046875\n",
      "      vf_explained_var: 0.7258778214454651\n",
      "      vf_loss: 2380.634521484375\n",
      "    sample_time_ms: 18668.942\n",
      "    update_time_ms: 5.222\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 279.1991601077675\n",
      "  time_since_restore: 5434.467072486877\n",
      "  time_this_iter_s: 22.403173208236694\n",
      "  time_total_s: 5434.467072486877\n",
      "  timestamp: 1553714451\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 186\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5434 s, 186 iter, 1860000 ts, 558 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-21-14\n",
      "  done: false\n",
      "  episode_len_mean: 131.46\n",
      "  episode_reward_max: 774.1287259845501\n",
      "  episode_reward_mean: 530.9410051551996\n",
      "  episode_reward_min: -143.41217164886447\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 13537\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3805.048\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 1870000\n",
      "    num_steps_trained: 1870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.473884928302141e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0169146060943604\n",
      "      kl: 0.8649888634681702\n",
      "      policy_loss: 0.03600487485527992\n",
      "      total_loss: 2571.307373046875\n",
      "      vf_explained_var: 0.7065931558609009\n",
      "      vf_loss: 2571.271240234375\n",
      "    sample_time_ms: 18612.877\n",
      "    update_time_ms: 5.212\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 265.47050257759986\n",
      "  time_since_restore: 5456.962637662888\n",
      "  time_this_iter_s: 22.495565176010132\n",
      "  time_total_s: 5456.962637662888\n",
      "  timestamp: 1553714474\n",
      "  timesteps_since_restore: 1870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1870000\n",
      "  training_iteration: 187\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5456 s, 187 iter, 1870000 ts, 531 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-21-36\n",
      "  done: false\n",
      "  episode_len_mean: 136.48\n",
      "  episode_reward_max: 767.9684246081393\n",
      "  episode_reward_mean: 570.5875969689515\n",
      "  episode_reward_min: -121.51203847949515\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 13611\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3805.302\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 1880000\n",
      "    num_steps_trained: 1880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.710826710332185e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0002973079681396\n",
      "      kl: 0.18618139624595642\n",
      "      policy_loss: 0.023276034742593765\n",
      "      total_loss: 1864.1708984375\n",
      "      vf_explained_var: 0.7754945158958435\n",
      "      vf_loss: 1864.1475830078125\n",
      "    sample_time_ms: 18557.04\n",
      "    update_time_ms: 5.326\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 285.29379848447576\n",
      "  time_since_restore: 5479.245304107666\n",
      "  time_this_iter_s: 22.282666444778442\n",
      "  time_total_s: 5479.245304107666\n",
      "  timestamp: 1553714496\n",
      "  timesteps_since_restore: 1880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1880000\n",
      "  training_iteration: 188\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5479 s, 188 iter, 1880000 ts, 571 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-21-59\n",
      "  done: false\n",
      "  episode_len_mean: 138.74\n",
      "  episode_reward_max: 754.613276080762\n",
      "  episode_reward_mean: 590.9385563871447\n",
      "  episode_reward_min: -121.56400213448033\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 13684\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.295\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.006624097499298e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0181854963302612\n",
      "      kl: 1.9765698909759521\n",
      "      policy_loss: 0.02558591216802597\n",
      "      total_loss: 1825.03125\n",
      "      vf_explained_var: 0.7851377725601196\n",
      "      vf_loss: 1825.00537109375\n",
      "    sample_time_ms: 18518.335\n",
      "    update_time_ms: 5.403\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.46927819357234\n",
      "  time_since_restore: 5501.790898799896\n",
      "  time_this_iter_s: 22.545594692230225\n",
      "  time_total_s: 5501.790898799896\n",
      "  timestamp: 1553714519\n",
      "  timesteps_since_restore: 1890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 189\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5501 s, 189 iter, 1890000 ts, 591 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-22-21\n",
      "  done: false\n",
      "  episode_len_mean: 139.38\n",
      "  episode_reward_max: 787.1331141000072\n",
      "  episode_reward_mean: 604.550170300975\n",
      "  episode_reward_min: -112.50053344310567\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 13756\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.783\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 1900000\n",
      "    num_steps_trained: 1900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5099361007742118e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.037552833557129\n",
      "      kl: 1.728236436843872\n",
      "      policy_loss: 0.019720813259482384\n",
      "      total_loss: 1304.7080078125\n",
      "      vf_explained_var: 0.8477168679237366\n",
      "      vf_loss: 1304.6883544921875\n",
      "    sample_time_ms: 18551.819\n",
      "    update_time_ms: 5.477\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.27508515048754\n",
      "  time_since_restore: 5524.129958629608\n",
      "  time_this_iter_s: 22.339059829711914\n",
      "  time_total_s: 5524.129958629608\n",
      "  timestamp: 1553714541\n",
      "  timesteps_since_restore: 1900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1900000\n",
      "  training_iteration: 190\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5524 s, 190 iter, 1900000 ts, 605 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-22-44\n",
      "  done: false\n",
      "  episode_len_mean: 134.83\n",
      "  episode_reward_max: 739.7577900540723\n",
      "  episode_reward_mean: 569.5469485927802\n",
      "  episode_reward_min: -130.3259631341875\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 13833\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.783\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 1910000\n",
      "    num_steps_trained: 1910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2649039237876423e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0169029235839844\n",
      "      kl: 0.15348485112190247\n",
      "      policy_loss: 0.018588896840810776\n",
      "      total_loss: 2314.916748046875\n",
      "      vf_explained_var: 0.74149090051651\n",
      "      vf_loss: 2314.898193359375\n",
      "    sample_time_ms: 18600.732\n",
      "    update_time_ms: 5.587\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 284.7734742963901\n",
      "  time_since_restore: 5546.81818819046\n",
      "  time_this_iter_s: 22.68822956085205\n",
      "  time_total_s: 5546.81818819046\n",
      "  timestamp: 1553714564\n",
      "  timesteps_since_restore: 1910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1910000\n",
      "  training_iteration: 191\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5546 s, 191 iter, 1910000 ts, 570 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-23-07\n",
      "  done: false\n",
      "  episode_len_mean: 134.7\n",
      "  episode_reward_max: 778.874639082737\n",
      "  episode_reward_mean: 559.1749411494297\n",
      "  episode_reward_min: -107.83301274767766\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 13909\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3786.674\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.3973559766309336e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0794073343276978\n",
      "      kl: 0.23648212850093842\n",
      "      policy_loss: 0.02053077705204487\n",
      "      total_loss: 2143.723876953125\n",
      "      vf_explained_var: 0.7605390548706055\n",
      "      vf_loss: 2143.703125\n",
      "    sample_time_ms: 18656.784\n",
      "    update_time_ms: 5.591\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 279.58747057471487\n",
      "  time_since_restore: 5569.696000099182\n",
      "  time_this_iter_s: 22.877811908721924\n",
      "  time_total_s: 5569.696000099182\n",
      "  timestamp: 1553714587\n",
      "  timesteps_since_restore: 1920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 192\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5569 s, 192 iter, 1920000 ts, 559 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-23-30\n",
      "  done: false\n",
      "  episode_len_mean: 134.4\n",
      "  episode_reward_max: 758.8344150659202\n",
      "  episode_reward_mean: 553.6423859918273\n",
      "  episode_reward_min: -125.5028000133745\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 13984\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.387\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 1930000\n",
      "    num_steps_trained: 1930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.096033419249579e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.069740891456604\n",
      "      kl: 67.8360366821289\n",
      "      policy_loss: 0.06797485798597336\n",
      "      total_loss: 2500.77001953125\n",
      "      vf_explained_var: 0.7205045819282532\n",
      "      vf_loss: 2500.69873046875\n",
      "    sample_time_ms: 18743.325\n",
      "    update_time_ms: 5.689\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 276.82119299591363\n",
      "  time_since_restore: 5593.097211360931\n",
      "  time_this_iter_s: 23.401211261749268\n",
      "  time_total_s: 5593.097211360931\n",
      "  timestamp: 1553714610\n",
      "  timesteps_since_restore: 1930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1930000\n",
      "  training_iteration: 193\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5593 s, 193 iter, 1930000 ts, 554 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-23-53\n",
      "  done: false\n",
      "  episode_len_mean: 133.52\n",
      "  episode_reward_max: 755.876791875404\n",
      "  episode_reward_mean: 544.0952762949286\n",
      "  episode_reward_min: -112.52434078836305\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 14060\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.169\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 1940000\n",
      "    num_steps_trained: 1940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.644051220268011e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0790143013000488\n",
      "      kl: 0.20098857581615448\n",
      "      policy_loss: 0.021075539290905\n",
      "      total_loss: 2321.099365234375\n",
      "      vf_explained_var: 0.7375657558441162\n",
      "      vf_loss: 2321.078125\n",
      "    sample_time_ms: 18795.819\n",
      "    update_time_ms: 5.886\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 272.0476381474642\n",
      "  time_since_restore: 5615.73175907135\n",
      "  time_this_iter_s: 22.6345477104187\n",
      "  time_total_s: 5615.73175907135\n",
      "  timestamp: 1553714633\n",
      "  timesteps_since_restore: 1940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1940000\n",
      "  training_iteration: 194\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5615 s, 194 iter, 1940000 ts, 544 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-24-16\n",
      "  done: false\n",
      "  episode_len_mean: 134.84\n",
      "  episode_reward_max: 782.7033827226123\n",
      "  episode_reward_mean: 563.3899735542014\n",
      "  episode_reward_min: -123.31410417338282\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 14134\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.035\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00011466076102806255\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0524085760116577\n",
      "      kl: 0.30393508076667786\n",
      "      policy_loss: 0.013692615553736687\n",
      "      total_loss: 1674.4266357421875\n",
      "      vf_explained_var: 0.8037903904914856\n",
      "      vf_loss: 1674.4132080078125\n",
      "    sample_time_ms: 18826.033\n",
      "    update_time_ms: 5.981\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 281.69498677710067\n",
      "  time_since_restore: 5638.429929494858\n",
      "  time_this_iter_s: 22.69817042350769\n",
      "  time_total_s: 5638.429929494858\n",
      "  timestamp: 1553714656\n",
      "  timesteps_since_restore: 1950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 195\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5638 s, 195 iter, 1950000 ts, 563 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-24-38\n",
      "  done: false\n",
      "  episode_len_mean: 140.07\n",
      "  episode_reward_max: 767.7721067510762\n",
      "  episode_reward_mean: 605.9477327444312\n",
      "  episode_reward_min: -130.71725841912036\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14206\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3781.502\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 1960000\n",
      "    num_steps_trained: 1960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00017199116700794548\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0663474798202515\n",
      "      kl: 0.1754579246044159\n",
      "      policy_loss: 0.021118193864822388\n",
      "      total_loss: 1558.5665283203125\n",
      "      vf_explained_var: 0.8188853859901428\n",
      "      vf_loss: 1558.5452880859375\n",
      "    sample_time_ms: 18808.32\n",
      "    update_time_ms: 6.01\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.9738663722156\n",
      "  time_since_restore: 5660.621204853058\n",
      "  time_this_iter_s: 22.191275358200073\n",
      "  time_total_s: 5660.621204853058\n",
      "  timestamp: 1553714678\n",
      "  timesteps_since_restore: 1960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1960000\n",
      "  training_iteration: 196\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5660 s, 196 iter, 1960000 ts, 606 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-25-00\n",
      "  done: false\n",
      "  episode_len_mean: 137.95\n",
      "  episode_reward_max: 756.1950128054987\n",
      "  episode_reward_mean: 589.536872110498\n",
      "  episode_reward_min: -119.21115654969952\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 14280\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3781.729\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 1970000\n",
      "    num_steps_trained: 1970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00025798671413213015\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0722113847732544\n",
      "      kl: 0.2848397195339203\n",
      "      policy_loss: 0.021162983030080795\n",
      "      total_loss: 1835.341796875\n",
      "      vf_explained_var: 0.7920008897781372\n",
      "      vf_loss: 1835.320556640625\n",
      "    sample_time_ms: 18814.327\n",
      "    update_time_ms: 5.952\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 294.768436055249\n",
      "  time_since_restore: 5683.178297758102\n",
      "  time_this_iter_s: 22.557092905044556\n",
      "  time_total_s: 5683.178297758102\n",
      "  timestamp: 1553714700\n",
      "  timesteps_since_restore: 1970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1970000\n",
      "  training_iteration: 197\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5683 s, 197 iter, 1970000 ts, 590 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-25-23\n",
      "  done: false\n",
      "  episode_len_mean: 132.74\n",
      "  episode_reward_max: 761.07434858368\n",
      "  episode_reward_mean: 553.0918265985642\n",
      "  episode_reward_min: -115.70655369299406\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 14358\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3786.224\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0003869801003020257\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0541095733642578\n",
      "      kl: 0.11030906438827515\n",
      "      policy_loss: 0.01583588309586048\n",
      "      total_loss: 2828.56005859375\n",
      "      vf_explained_var: 0.6813880801200867\n",
      "      vf_loss: 2828.54443359375\n",
      "    sample_time_ms: 18840.782\n",
      "    update_time_ms: 5.801\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 276.5459132992821\n",
      "  time_since_restore: 5705.771986961365\n",
      "  time_this_iter_s: 22.59368920326233\n",
      "  time_total_s: 5705.771986961365\n",
      "  timestamp: 1553714723\n",
      "  timesteps_since_restore: 1980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 198\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5705 s, 198 iter, 1980000 ts, 553 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-25-46\n",
      "  done: false\n",
      "  episode_len_mean: 140.61\n",
      "  episode_reward_max: 752.1572253550372\n",
      "  episode_reward_mean: 603.1287987812451\n",
      "  episode_reward_min: -89.70926018294631\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 14431\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3787.454\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 1990000\n",
      "    num_steps_trained: 1990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0005804701359011233\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1138019561767578\n",
      "      kl: 0.8945490717887878\n",
      "      policy_loss: 0.02957352064549923\n",
      "      total_loss: 1399.3555908203125\n",
      "      vf_explained_var: 0.8364675641059875\n",
      "      vf_loss: 1399.3255615234375\n",
      "    sample_time_ms: 18871.371\n",
      "    update_time_ms: 5.959\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 301.56439939062255\n",
      "  time_since_restore: 5728.63606095314\n",
      "  time_this_iter_s: 22.864073991775513\n",
      "  time_total_s: 5728.63606095314\n",
      "  timestamp: 1553714746\n",
      "  timesteps_since_restore: 1990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1990000\n",
      "  training_iteration: 199\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5728 s, 199 iter, 1990000 ts, 603 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-26-09\n",
      "  done: false\n",
      "  episode_len_mean: 139.78\n",
      "  episode_reward_max: 750.6986828120794\n",
      "  episode_reward_mean: 600.0607503249844\n",
      "  episode_reward_min: -123.37925979895111\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14503\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.088\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 2000000\n",
      "    num_steps_trained: 2000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0008707052329555154\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1147161722183228\n",
      "      kl: 0.2815752625465393\n",
      "      policy_loss: 0.024086065590381622\n",
      "      total_loss: 1487.6805419921875\n",
      "      vf_explained_var: 0.8325515985488892\n",
      "      vf_loss: 1487.656005859375\n",
      "    sample_time_ms: 18938.996\n",
      "    update_time_ms: 5.912\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.0303751624922\n",
      "  time_since_restore: 5751.678123474121\n",
      "  time_this_iter_s: 23.042062520980835\n",
      "  time_total_s: 5751.678123474121\n",
      "  timestamp: 1553714769\n",
      "  timesteps_since_restore: 2000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2000000\n",
      "  training_iteration: 200\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5751 s, 200 iter, 2000000 ts, 600 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-26-31\n",
      "  done: false\n",
      "  episode_len_mean: 141.88\n",
      "  episode_reward_max: 769.945004449942\n",
      "  episode_reward_mean: 611.4463617993802\n",
      "  episode_reward_min: -76.1994257787171\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 14574\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3789.474\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0013060577912256122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.143604040145874\n",
      "      kl: 1.8245165348052979\n",
      "      policy_loss: 0.014451215043663979\n",
      "      total_loss: 886.2660522460938\n",
      "      vf_explained_var: 0.8971342444419861\n",
      "      vf_loss: 886.2492065429688\n",
      "    sample_time_ms: 18897.23\n",
      "    update_time_ms: 5.914\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 305.7231808996901\n",
      "  time_since_restore: 5773.94286942482\n",
      "  time_this_iter_s: 22.264745950698853\n",
      "  time_total_s: 5773.94286942482\n",
      "  timestamp: 1553714791\n",
      "  timesteps_since_restore: 2010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 201\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5773 s, 201 iter, 2010000 ts, 611 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-26-54\n",
      "  done: false\n",
      "  episode_len_mean: 139.47\n",
      "  episode_reward_max: 778.2076483318698\n",
      "  episode_reward_mean: 589.5597436398025\n",
      "  episode_reward_min: -125.07640058891002\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14646\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3788.912\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 2020000\n",
      "    num_steps_trained: 2020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0019590866286307573\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1373941898345947\n",
      "      kl: 0.3596850037574768\n",
      "      policy_loss: 0.017083032056689262\n",
      "      total_loss: 1581.0843505859375\n",
      "      vf_explained_var: 0.818888247013092\n",
      "      vf_loss: 1581.0665283203125\n",
      "    sample_time_ms: 18883.56\n",
      "    update_time_ms: 5.912\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 294.77987181990125\n",
      "  time_since_restore: 5796.679149389267\n",
      "  time_this_iter_s: 22.73627996444702\n",
      "  time_total_s: 5796.679149389267\n",
      "  timestamp: 1553714814\n",
      "  timesteps_since_restore: 2020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2020000\n",
      "  training_iteration: 202\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5796 s, 202 iter, 2020000 ts, 590 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-27-16\n",
      "  done: false\n",
      "  episode_len_mean: 139.82\n",
      "  episode_reward_max: 768.3080040868665\n",
      "  episode_reward_mean: 594.760417695492\n",
      "  episode_reward_min: -137.18801766604295\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14718\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3784.095\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 2030000\n",
      "    num_steps_trained: 2030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.002938630059361458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1340055465698242\n",
      "      kl: 0.38858309388160706\n",
      "      policy_loss: 0.028010448440909386\n",
      "      total_loss: 1480.9268798828125\n",
      "      vf_explained_var: 0.8314568996429443\n",
      "      vf_loss: 1480.8975830078125\n",
      "    sample_time_ms: 18777.86\n",
      "    update_time_ms: 5.792\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 297.380208847746\n",
      "  time_since_restore: 5818.974831581116\n",
      "  time_this_iter_s: 22.295682191848755\n",
      "  time_total_s: 5818.974831581116\n",
      "  timestamp: 1553714836\n",
      "  timesteps_since_restore: 2030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2030000\n",
      "  training_iteration: 203\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5818 s, 203 iter, 2030000 ts, 595 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-27-38\n",
      "  done: false\n",
      "  episode_len_mean: 134.22\n",
      "  episode_reward_max: 761.5434648458738\n",
      "  episode_reward_mean: 550.6146457330932\n",
      "  episode_reward_min: -122.49225243189608\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 14795\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3780.429\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004407945554703474\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1045349836349487\n",
      "      kl: 0.14915287494659424\n",
      "      policy_loss: 0.0146260354667902\n",
      "      total_loss: 2200.59375\n",
      "      vf_explained_var: 0.7617171406745911\n",
      "      vf_loss: 2200.578369140625\n",
      "    sample_time_ms: 18716.185\n",
      "    update_time_ms: 5.666\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 275.3073228665466\n",
      "  time_since_restore: 5840.954584360123\n",
      "  time_this_iter_s: 21.979752779006958\n",
      "  time_total_s: 5840.954584360123\n",
      "  timestamp: 1553714858\n",
      "  timesteps_since_restore: 2040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 204\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5840 s, 204 iter, 2040000 ts, 551 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-28-01\n",
      "  done: false\n",
      "  episode_len_mean: 135.37\n",
      "  episode_reward_max: 768.3538115186236\n",
      "  episode_reward_mean: 563.5731056474157\n",
      "  episode_reward_min: -107.9071372300931\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 14870\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.687\n",
      "    load_time_ms: 1.498\n",
      "    num_steps_sampled: 2050000\n",
      "    num_steps_trained: 2050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.006611918564885855\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0679895877838135\n",
      "      kl: 0.0796772837638855\n",
      "      policy_loss: 0.012780123390257359\n",
      "      total_loss: 2209.48388671875\n",
      "      vf_explained_var: 0.7485268115997314\n",
      "      vf_loss: 2209.470458984375\n",
      "    sample_time_ms: 18716.642\n",
      "    update_time_ms: 5.571\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 281.78655282370784\n",
      "  time_since_restore: 5863.618180513382\n",
      "  time_this_iter_s: 22.663596153259277\n",
      "  time_total_s: 5863.618180513382\n",
      "  timestamp: 1553714881\n",
      "  timesteps_since_restore: 2050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2050000\n",
      "  training_iteration: 205\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5863 s, 205 iter, 2050000 ts, 564 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-28-23\n",
      "  done: false\n",
      "  episode_len_mean: 135.1\n",
      "  episode_reward_max: 783.9240004787961\n",
      "  episode_reward_mean: 561.6583877583205\n",
      "  episode_reward_min: -125.09320291291961\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 14945\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3779.619\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 2060000\n",
      "    num_steps_trained: 2060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.009917876683175564\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.078574299812317\n",
      "      kl: 0.049515172839164734\n",
      "      policy_loss: 0.009069115854799747\n",
      "      total_loss: 2082.813232421875\n",
      "      vf_explained_var: 0.7644738554954529\n",
      "      vf_loss: 2082.8037109375\n",
      "    sample_time_ms: 18721.857\n",
      "    update_time_ms: 5.634\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.82919387916024\n",
      "  time_since_restore: 5885.892905950546\n",
      "  time_this_iter_s: 22.274725437164307\n",
      "  time_total_s: 5885.892905950546\n",
      "  timestamp: 1553714903\n",
      "  timesteps_since_restore: 2060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2060000\n",
      "  training_iteration: 206\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5885 s, 206 iter, 2060000 ts, 562 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-28-45\n",
      "  done: false\n",
      "  episode_len_mean: 137.58\n",
      "  episode_reward_max: 744.9855356659818\n",
      "  episode_reward_mean: 577.5868928991208\n",
      "  episode_reward_min: -119.02167296051962\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 15019\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3782.058\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014876814559102058\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.104368805885315\n",
      "      kl: 0.045694999396800995\n",
      "      policy_loss: 0.006852449383586645\n",
      "      total_loss: 1846.66845703125\n",
      "      vf_explained_var: 0.7875158786773682\n",
      "      vf_loss: 1846.6610107421875\n",
      "    sample_time_ms: 18637.166\n",
      "    update_time_ms: 5.672\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 288.79344644956035\n",
      "  time_since_restore: 5907.628440856934\n",
      "  time_this_iter_s: 21.73553490638733\n",
      "  time_total_s: 5907.628440856934\n",
      "  timestamp: 1553714925\n",
      "  timesteps_since_restore: 2070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 207\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5907 s, 207 iter, 2070000 ts, 578 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-29-07\n",
      "  done: false\n",
      "  episode_len_mean: 143.71\n",
      "  episode_reward_max: 754.5149977605125\n",
      "  episode_reward_mean: 627.9889909390943\n",
      "  episode_reward_min: -133.8456629824128\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 15089\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3775.142\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 2080000\n",
      "    num_steps_trained: 2080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022315220907330513\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0886138677597046\n",
      "      kl: 0.1990833580493927\n",
      "      policy_loss: 0.02356027066707611\n",
      "      total_loss: 908.7012939453125\n",
      "      vf_explained_var: 0.8949671983718872\n",
      "      vf_loss: 908.6732788085938\n",
      "    sample_time_ms: 18557.222\n",
      "    update_time_ms: 5.884\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.99449546954713\n",
      "  time_since_restore: 5929.353662252426\n",
      "  time_this_iter_s: 21.725221395492554\n",
      "  time_total_s: 5929.353662252426\n",
      "  timestamp: 1553714947\n",
      "  timesteps_since_restore: 2080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2080000\n",
      "  training_iteration: 208\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5929 s, 208 iter, 2080000 ts, 628 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 138.26\n",
      "  episode_reward_max: 742.0736737752845\n",
      "  episode_reward_mean: 589.2199576045313\n",
      "  episode_reward_min: -129.66778610521294\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 15162\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3771.672\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 2090000\n",
      "    num_steps_trained: 2090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033472832292318344\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0406819581985474\n",
      "      kl: 0.04220255836844444\n",
      "      policy_loss: 0.009572976268827915\n",
      "      total_loss: 1526.288818359375\n",
      "      vf_explained_var: 0.8283238410949707\n",
      "      vf_loss: 1526.27783203125\n",
      "    sample_time_ms: 18483.629\n",
      "    update_time_ms: 5.636\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 294.60997880226563\n",
      "  time_since_restore: 5951.447238206863\n",
      "  time_this_iter_s: 22.093575954437256\n",
      "  time_total_s: 5951.447238206863\n",
      "  timestamp: 1553714969\n",
      "  timesteps_since_restore: 2090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2090000\n",
      "  training_iteration: 209\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5951 s, 209 iter, 2090000 ts, 589 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-29-51\n",
      "  done: false\n",
      "  episode_len_mean: 137.78\n",
      "  episode_reward_max: 773.0146780067387\n",
      "  episode_reward_mean: 580.2861998824433\n",
      "  episode_reward_min: -134.65836878250514\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 15237\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3769.532\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05020924285054207\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.083461880683899\n",
      "      kl: 0.08312984555959702\n",
      "      policy_loss: 0.013505932874977589\n",
      "      total_loss: 2110.24169921875\n",
      "      vf_explained_var: 0.7766274809837341\n",
      "      vf_loss: 2110.22412109375\n",
      "    sample_time_ms: 18383.13\n",
      "    update_time_ms: 5.559\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.1430999412216\n",
      "  time_since_restore: 5973.4607944488525\n",
      "  time_this_iter_s: 22.013556241989136\n",
      "  time_total_s: 5973.4607944488525\n",
      "  timestamp: 1553714991\n",
      "  timesteps_since_restore: 2100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 210\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5973 s, 210 iter, 2100000 ts, 580 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-30-13\n",
      "  done: false\n",
      "  episode_len_mean: 139.91\n",
      "  episode_reward_max: 779.0873993261733\n",
      "  episode_reward_mean: 607.1780766855026\n",
      "  episode_reward_min: -81.03176381948461\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 15308\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3772.002\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 2110000\n",
      "    num_steps_trained: 2110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07531387358903885\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0514310598373413\n",
      "      kl: 0.091581329703331\n",
      "      policy_loss: 0.01167095173150301\n",
      "      total_loss: 931.5280151367188\n",
      "      vf_explained_var: 0.8951371908187866\n",
      "      vf_loss: 931.5096435546875\n",
      "    sample_time_ms: 18383.26\n",
      "    update_time_ms: 5.538\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 303.58903834275134\n",
      "  time_since_restore: 5995.751205444336\n",
      "  time_this_iter_s: 22.2904109954834\n",
      "  time_total_s: 5995.751205444336\n",
      "  timestamp: 1553715013\n",
      "  timesteps_since_restore: 2110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2110000\n",
      "  training_iteration: 211\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 5995 s, 211 iter, 2110000 ts, 607 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 140.02\n",
      "  episode_reward_max: 771.956084990057\n",
      "  episode_reward_mean: 611.9742863292098\n",
      "  episode_reward_min: -72.4630343149998\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 15380\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3771.844\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 2120000\n",
      "    num_steps_trained: 2120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11297080665826797\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.096352458000183\n",
      "      kl: 0.024621620774269104\n",
      "      policy_loss: 0.005199535749852657\n",
      "      total_loss: 1221.7169189453125\n",
      "      vf_explained_var: 0.8600528240203857\n",
      "      vf_loss: 1221.7088623046875\n",
      "    sample_time_ms: 18348.677\n",
      "    update_time_ms: 5.501\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 305.98714316460484\n",
      "  time_since_restore: 6018.140507221222\n",
      "  time_this_iter_s: 22.389301776885986\n",
      "  time_total_s: 6018.140507221222\n",
      "  timestamp: 1553715036\n",
      "  timesteps_since_restore: 2120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2120000\n",
      "  training_iteration: 212\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6018 s, 212 iter, 2120000 ts, 612 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-30-58\n",
      "  done: false\n",
      "  episode_len_mean: 142.51\n",
      "  episode_reward_max: 769.8845993290541\n",
      "  episode_reward_mean: 626.3707151360652\n",
      "  episode_reward_min: -110.40106633384737\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 15451\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3773.703\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11297080665826797\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0574125051498413\n",
      "      kl: 0.034215524792671204\n",
      "      policy_loss: 0.008494728244841099\n",
      "      total_loss: 1247.1397705078125\n",
      "      vf_explained_var: 0.8599191308021545\n",
      "      vf_loss: 1247.1275634765625\n",
      "    sample_time_ms: 18354.816\n",
      "    update_time_ms: 5.458\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.1853575680326\n",
      "  time_since_restore: 6040.513790369034\n",
      "  time_this_iter_s: 22.37328314781189\n",
      "  time_total_s: 6040.513790369034\n",
      "  timestamp: 1553715058\n",
      "  timesteps_since_restore: 2130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 213\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6040 s, 213 iter, 2130000 ts, 626 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-31-21\n",
      "  done: false\n",
      "  episode_len_mean: 139.36\n",
      "  episode_reward_max: 799.6786113230205\n",
      "  episode_reward_mean: 596.8423786443168\n",
      "  episode_reward_min: -111.32185172770536\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 15524\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3783.045\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 2140000\n",
      "    num_steps_trained: 2140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11297080665826797\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0760153532028198\n",
      "      kl: 0.029679089784622192\n",
      "      policy_loss: 0.00489492854103446\n",
      "      total_loss: 1770.139404296875\n",
      "      vf_explained_var: 0.8050767183303833\n",
      "      vf_loss: 1770.1314697265625\n",
      "    sample_time_ms: 18388.247\n",
      "    update_time_ms: 5.388\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 298.4211893221584\n",
      "  time_since_restore: 6062.919492959976\n",
      "  time_this_iter_s: 22.405702590942383\n",
      "  time_total_s: 6062.919492959976\n",
      "  timestamp: 1553715081\n",
      "  timesteps_since_restore: 2140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2140000\n",
      "  training_iteration: 214\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6062 s, 214 iter, 2140000 ts, 597 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-31-43\n",
      "  done: false\n",
      "  episode_len_mean: 137.25\n",
      "  episode_reward_max: 757.4075702333246\n",
      "  episode_reward_mean: 581.0423680389189\n",
      "  episode_reward_min: -133.182757708373\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 15599\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3782.799\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 2150000\n",
      "    num_steps_trained: 2150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11297080665826797\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.033029556274414\n",
      "      kl: 0.035302046686410904\n",
      "      policy_loss: 0.007827247492969036\n",
      "      total_loss: 1655.240478515625\n",
      "      vf_explained_var: 0.8194112181663513\n",
      "      vf_loss: 1655.2286376953125\n",
      "    sample_time_ms: 18347.395\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.5211840194595\n",
      "  time_since_restore: 6085.171690702438\n",
      "  time_this_iter_s: 22.252197742462158\n",
      "  time_total_s: 6085.171690702438\n",
      "  timestamp: 1553715103\n",
      "  timesteps_since_restore: 2150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2150000\n",
      "  training_iteration: 215\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6085 s, 215 iter, 2150000 ts, 581 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-32-05\n",
      "  done: false\n",
      "  episode_len_mean: 133.31\n",
      "  episode_reward_max: 772.2913536323856\n",
      "  episode_reward_mean: 558.6185077388792\n",
      "  episode_reward_min: -140.12353395867405\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 15677\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.429\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11297080665826797\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.019683599472046\n",
      "      kl: 0.034599583595991135\n",
      "      policy_loss: 0.007994050160050392\n",
      "      total_loss: 2200.123046875\n",
      "      vf_explained_var: 0.7777366042137146\n",
      "      vf_loss: 2200.111328125\n",
      "    sample_time_ms: 18339.074\n",
      "    update_time_ms: 5.145\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 279.3092538694396\n",
      "  time_since_restore: 6107.385411262512\n",
      "  time_this_iter_s: 22.213720560073853\n",
      "  time_total_s: 6107.385411262512\n",
      "  timestamp: 1553715125\n",
      "  timesteps_since_restore: 2160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 216\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6107 s, 216 iter, 2160000 ts, 559 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-32-28\n",
      "  done: false\n",
      "  episode_len_mean: 136.79\n",
      "  episode_reward_max: 759.4682244604937\n",
      "  episode_reward_mean: 584.5809421399947\n",
      "  episode_reward_min: -118.02012514259816\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 15750\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.481\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 2170000\n",
      "    num_steps_trained: 2170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11297080665826797\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0459672212600708\n",
      "      kl: 0.03608996793627739\n",
      "      policy_loss: 0.009005656465888023\n",
      "      total_loss: 1563.7325439453125\n",
      "      vf_explained_var: 0.8414578437805176\n",
      "      vf_loss: 1563.7196044921875\n",
      "    sample_time_ms: 18437.275\n",
      "    update_time_ms: 5.106\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.29047106999735\n",
      "  time_since_restore: 6130.10021686554\n",
      "  time_this_iter_s: 22.714805603027344\n",
      "  time_total_s: 6130.10021686554\n",
      "  timestamp: 1553715148\n",
      "  timesteps_since_restore: 2170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2170000\n",
      "  training_iteration: 217\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6130 s, 217 iter, 2170000 ts, 585 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-32-51\n",
      "  done: false\n",
      "  episode_len_mean: 136.93\n",
      "  episode_reward_max: 765.101099144206\n",
      "  episode_reward_mean: 580.2129703755423\n",
      "  episode_reward_min: -115.0158864818945\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 15824\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3789.548\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 2180000\n",
      "    num_steps_trained: 2180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.11297080665826797\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.069982886314392\n",
      "      kl: 0.04170427471399307\n",
      "      policy_loss: 0.009695629589259624\n",
      "      total_loss: 1601.2615966796875\n",
      "      vf_explained_var: 0.8373774290084839\n",
      "      vf_loss: 1601.2471923828125\n",
      "    sample_time_ms: 18518.872\n",
      "    update_time_ms: 4.945\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.10648518777117\n",
      "  time_since_restore: 6152.679940700531\n",
      "  time_this_iter_s: 22.579723834991455\n",
      "  time_total_s: 6152.679940700531\n",
      "  timestamp: 1553715171\n",
      "  timesteps_since_restore: 2180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2180000\n",
      "  training_iteration: 218\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6152 s, 218 iter, 2180000 ts, 580 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-33-13\n",
      "  done: false\n",
      "  episode_len_mean: 138.09\n",
      "  episode_reward_max: 750.0936386152018\n",
      "  episode_reward_mean: 592.6838777179862\n",
      "  episode_reward_min: -121.54869943476128\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 15898\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3793.416\n",
      "    load_time_ms: 1.449\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16945624351501465\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0394569635391235\n",
      "      kl: 0.0197523795068264\n",
      "      policy_loss: 0.0037312121130526066\n",
      "      total_loss: 1031.1630859375\n",
      "      vf_explained_var: 0.8958685398101807\n",
      "      vf_loss: 1031.156005859375\n",
      "    sample_time_ms: 18531.387\n",
      "    update_time_ms: 5.164\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 296.34193885899316\n",
      "  time_since_restore: 6174.936821222305\n",
      "  time_this_iter_s: 22.256880521774292\n",
      "  time_total_s: 6174.936821222305\n",
      "  timestamp: 1553715193\n",
      "  timesteps_since_restore: 2190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 219\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6174 s, 219 iter, 2190000 ts, 593 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-33-35\n",
      "  done: false\n",
      "  episode_len_mean: 135.88\n",
      "  episode_reward_max: 774.886748259922\n",
      "  episode_reward_mean: 572.7145645641335\n",
      "  episode_reward_min: -125.36454687399709\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 15973\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3793.475\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 2200000\n",
      "    num_steps_trained: 2200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16945624351501465\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0537598133087158\n",
      "      kl: 0.022926388308405876\n",
      "      policy_loss: 0.0037106466479599476\n",
      "      total_loss: 1619.012451171875\n",
      "      vf_explained_var: 0.8339851498603821\n",
      "      vf_loss: 1619.0047607421875\n",
      "    sample_time_ms: 18532.404\n",
      "    update_time_ms: 5.157\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 286.35728228206676\n",
      "  time_since_restore: 6196.964200019836\n",
      "  time_this_iter_s: 22.027378797531128\n",
      "  time_total_s: 6196.964200019836\n",
      "  timestamp: 1553715215\n",
      "  timesteps_since_restore: 2200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2200000\n",
      "  training_iteration: 220\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6196 s, 220 iter, 2200000 ts, 573 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-33-57\n",
      "  done: false\n",
      "  episode_len_mean: 137.23\n",
      "  episode_reward_max: 762.034597359354\n",
      "  episode_reward_mean: 580.9254531910572\n",
      "  episode_reward_min: -128.56064904026425\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 16048\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3794.032\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 2210000\n",
      "    num_steps_trained: 2210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16945624351501465\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0753939151763916\n",
      "      kl: 0.02070174552500248\n",
      "      policy_loss: 0.0037516909651458263\n",
      "      total_loss: 1283.2933349609375\n",
      "      vf_explained_var: 0.863146960735321\n",
      "      vf_loss: 1283.2861328125\n",
      "    sample_time_ms: 18524.262\n",
      "    update_time_ms: 5.162\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.4627265955285\n",
      "  time_since_restore: 6219.179756402969\n",
      "  time_this_iter_s: 22.215556383132935\n",
      "  time_total_s: 6219.179756402969\n",
      "  timestamp: 1553715237\n",
      "  timesteps_since_restore: 2210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2210000\n",
      "  training_iteration: 221\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6219 s, 221 iter, 2210000 ts, 581 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-34-20\n",
      "  done: false\n",
      "  episode_len_mean: 139.1\n",
      "  episode_reward_max: 758.2645210855759\n",
      "  episode_reward_mean: 603.8348870127994\n",
      "  episode_reward_min: -120.99461108797263\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 16120\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.029\n",
      "    load_time_ms: 1.376\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16945624351501465\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.052790880203247\n",
      "      kl: 0.018189573660492897\n",
      "      policy_loss: 0.0053454674780368805\n",
      "      total_loss: 891.0620727539062\n",
      "      vf_explained_var: 0.9130728244781494\n",
      "      vf_loss: 891.0535888671875\n",
      "    sample_time_ms: 18534.203\n",
      "    update_time_ms: 5.22\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 301.91744350639965\n",
      "  time_since_restore: 6241.716123819351\n",
      "  time_this_iter_s: 22.536367416381836\n",
      "  time_total_s: 6241.716123819351\n",
      "  timestamp: 1553715260\n",
      "  timesteps_since_restore: 2220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 222\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6241 s, 222 iter, 2220000 ts, 604 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-34-42\n",
      "  done: false\n",
      "  episode_len_mean: 138.3\n",
      "  episode_reward_max: 764.2484313589604\n",
      "  episode_reward_mean: 595.3279466144685\n",
      "  episode_reward_min: -110.19453545197632\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 16193\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.122\n",
      "    load_time_ms: 1.366\n",
      "    num_steps_sampled: 2230000\n",
      "    num_steps_trained: 2230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.16945624351501465\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0621986389160156\n",
      "      kl: 0.048833344131708145\n",
      "      policy_loss: 0.008814823813736439\n",
      "      total_loss: 819.9630126953125\n",
      "      vf_explained_var: 0.9220101833343506\n",
      "      vf_loss: 819.9459838867188\n",
      "    sample_time_ms: 18503.937\n",
      "    update_time_ms: 5.261\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 297.66397330723424\n",
      "  time_since_restore: 6263.817101240158\n",
      "  time_this_iter_s: 22.100977420806885\n",
      "  time_total_s: 6263.817101240158\n",
      "  timestamp: 1553715282\n",
      "  timesteps_since_restore: 2230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2230000\n",
      "  training_iteration: 223\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6263 s, 223 iter, 2230000 ts, 595 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-35-04\n",
      "  done: false\n",
      "  episode_len_mean: 142.91\n",
      "  episode_reward_max: 750.7181937266162\n",
      "  episode_reward_mean: 629.7380154852244\n",
      "  episode_reward_min: -116.68684728459401\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 16265\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.207\n",
      "    load_time_ms: 1.367\n",
      "    num_steps_sampled: 2240000\n",
      "    num_steps_trained: 2240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.2541843354701996\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0529495477676392\n",
      "      kl: 0.02126404643058777\n",
      "      policy_loss: 0.007268831599503756\n",
      "      total_loss: 507.2339782714844\n",
      "      vf_explained_var: 0.9513917565345764\n",
      "      vf_loss: 507.22125244140625\n",
      "    sample_time_ms: 18511.985\n",
      "    update_time_ms: 5.316\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 314.86900774261215\n",
      "  time_since_restore: 6286.267873287201\n",
      "  time_this_iter_s: 22.450772047042847\n",
      "  time_total_s: 6286.267873287201\n",
      "  timestamp: 1553715304\n",
      "  timesteps_since_restore: 2240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2240000\n",
      "  training_iteration: 224\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6286 s, 224 iter, 2240000 ts, 630 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-35-27\n",
      "  done: false\n",
      "  episode_len_mean: 139.69\n",
      "  episode_reward_max: 760.5005065700747\n",
      "  episode_reward_mean: 608.2905104870342\n",
      "  episode_reward_min: -119.26940986596931\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 16337\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3801.073\n",
      "    load_time_ms: 1.374\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.2541843354701996\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0274876356124878\n",
      "      kl: 0.01436118595302105\n",
      "      policy_loss: 0.0025210429448634386\n",
      "      total_loss: 710.7067260742188\n",
      "      vf_explained_var: 0.9387183785438538\n",
      "      vf_loss: 710.7006225585938\n",
      "    sample_time_ms: 18551.587\n",
      "    update_time_ms: 5.435\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 304.1452552435171\n",
      "  time_since_restore: 6308.945061922073\n",
      "  time_this_iter_s: 22.677188634872437\n",
      "  time_total_s: 6308.945061922073\n",
      "  timestamp: 1553715327\n",
      "  timesteps_since_restore: 2250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 225\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6308 s, 225 iter, 2250000 ts, 608 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-35-50\n",
      "  done: false\n",
      "  episode_len_mean: 136.11\n",
      "  episode_reward_max: 770.2346714122207\n",
      "  episode_reward_mean: 585.1713003776557\n",
      "  episode_reward_min: -109.26999318758669\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 16412\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.095\n",
      "    load_time_ms: 1.383\n",
      "    num_steps_sampled: 2260000\n",
      "    num_steps_trained: 2260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.2541843354701996\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.016162633895874\n",
      "      kl: 0.017409710213541985\n",
      "      policy_loss: 0.0019232294289395213\n",
      "      total_loss: 824.819580078125\n",
      "      vf_explained_var: 0.9318049550056458\n",
      "      vf_loss: 824.8131713867188\n",
      "    sample_time_ms: 18628.229\n",
      "    update_time_ms: 5.575\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.58565018882786\n",
      "  time_since_restore: 6331.867879629135\n",
      "  time_this_iter_s: 22.922817707061768\n",
      "  time_total_s: 6331.867879629135\n",
      "  timestamp: 1553715350\n",
      "  timesteps_since_restore: 2260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2260000\n",
      "  training_iteration: 226\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6331 s, 226 iter, 2260000 ts, 585 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-36-13\n",
      "  done: false\n",
      "  episode_len_mean: 131.14\n",
      "  episode_reward_max: 762.913849396797\n",
      "  episode_reward_mean: 543.8815860171514\n",
      "  episode_reward_min: -131.3992368215204\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 16490\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.296\n",
      "    load_time_ms: 1.385\n",
      "    num_steps_sampled: 2270000\n",
      "    num_steps_trained: 2270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.2541843354701996\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.03250253200531\n",
      "      kl: 0.017275677993893623\n",
      "      policy_loss: 0.000633829680737108\n",
      "      total_loss: 1225.6644287109375\n",
      "      vf_explained_var: 0.892480731010437\n",
      "      vf_loss: 1225.659423828125\n",
      "    sample_time_ms: 18634.314\n",
      "    update_time_ms: 5.621\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 271.9407930085758\n",
      "  time_since_restore: 6354.645440340042\n",
      "  time_this_iter_s: 22.777560710906982\n",
      "  time_total_s: 6354.645440340042\n",
      "  timestamp: 1553715373\n",
      "  timesteps_since_restore: 2270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2270000\n",
      "  training_iteration: 227\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6354 s, 227 iter, 2270000 ts, 544 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-36-36\n",
      "  done: false\n",
      "  episode_len_mean: 137.0\n",
      "  episode_reward_max: 746.2949298194962\n",
      "  episode_reward_mean: 585.9253698341083\n",
      "  episode_reward_min: -129.66044928623901\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 16564\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3791.687\n",
      "    load_time_ms: 1.386\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.2541843354701996\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0581530332565308\n",
      "      kl: 0.01281152293086052\n",
      "      policy_loss: 0.003912354353815317\n",
      "      total_loss: 626.8617553710938\n",
      "      vf_explained_var: 0.945839524269104\n",
      "      vf_loss: 626.8545532226562\n",
      "    sample_time_ms: 18649.737\n",
      "    update_time_ms: 5.458\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.9626849170542\n",
      "  time_since_restore: 6377.342396497726\n",
      "  time_this_iter_s: 22.696956157684326\n",
      "  time_total_s: 6377.342396497726\n",
      "  timestamp: 1553715396\n",
      "  timesteps_since_restore: 2280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 228\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6377 s, 228 iter, 2280000 ts, 586 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-36-58\n",
      "  done: false\n",
      "  episode_len_mean: 137.25\n",
      "  episode_reward_max: 749.6378122811072\n",
      "  episode_reward_mean: 584.4786626831892\n",
      "  episode_reward_min: -123.4719210519781\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 16639\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.152\n",
      "    load_time_ms: 1.422\n",
      "    num_steps_sampled: 2290000\n",
      "    num_steps_trained: 2290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.2541843354701996\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.064828872680664\n",
      "      kl: 0.04223603382706642\n",
      "      policy_loss: 0.012125860899686813\n",
      "      total_loss: 612.2376098632812\n",
      "      vf_explained_var: 0.9477517604827881\n",
      "      vf_loss: 612.2147216796875\n",
      "    sample_time_ms: 18623.629\n",
      "    update_time_ms: 5.272\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.2393313415946\n",
      "  time_since_restore: 6399.321032524109\n",
      "  time_this_iter_s: 21.978636026382446\n",
      "  time_total_s: 6399.321032524109\n",
      "  timestamp: 1553715418\n",
      "  timesteps_since_restore: 2290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2290000\n",
      "  training_iteration: 229\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6399 s, 229 iter, 2290000 ts, 584 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-37-20\n",
      "  done: false\n",
      "  episode_len_mean: 134.0\n",
      "  episode_reward_max: 789.2945184545201\n",
      "  episode_reward_mean: 561.3207493581892\n",
      "  episode_reward_min: -137.44100236481523\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 16715\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3792.868\n",
      "    load_time_ms: 1.417\n",
      "    num_steps_sampled: 2300000\n",
      "    num_steps_trained: 2300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.38127651810646057\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0683913230895996\n",
      "      kl: 0.009300739504396915\n",
      "      policy_loss: 0.0003705850103870034\n",
      "      total_loss: 682.6806640625\n",
      "      vf_explained_var: 0.9452295303344727\n",
      "      vf_loss: 682.6767578125\n",
      "    sample_time_ms: 18636.487\n",
      "    update_time_ms: 5.347\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.6603746790946\n",
      "  time_since_restore: 6421.503377437592\n",
      "  time_this_iter_s: 22.182344913482666\n",
      "  time_total_s: 6421.503377437592\n",
      "  timestamp: 1553715440\n",
      "  timesteps_since_restore: 2300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2300000\n",
      "  training_iteration: 230\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6421 s, 230 iter, 2300000 ts, 561 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-37-44\n",
      "  done: false\n",
      "  episode_len_mean: 135.03\n",
      "  episode_reward_max: 756.3993811924424\n",
      "  episode_reward_mean: 560.8134050334148\n",
      "  episode_reward_min: -130.23788143721515\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 16791\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3791.58\n",
      "    load_time_ms: 1.405\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.19063825905323029\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0647261142730713\n",
      "      kl: 0.05495554208755493\n",
      "      policy_loss: 0.0071721612475812435\n",
      "      total_loss: 731.0362548828125\n",
      "      vf_explained_var: 0.9387306571006775\n",
      "      vf_loss: 731.0185546875\n",
      "    sample_time_ms: 18778.778\n",
      "    update_time_ms: 5.952\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.4067025167074\n",
      "  time_since_restore: 6445.132111787796\n",
      "  time_this_iter_s: 23.628734350204468\n",
      "  time_total_s: 6445.132111787796\n",
      "  timestamp: 1553715464\n",
      "  timesteps_since_restore: 2310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 231\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6445 s, 231 iter, 2310000 ts, 561 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-38-06\n",
      "  done: false\n",
      "  episode_len_mean: 136.61\n",
      "  episode_reward_max: 750.0423286436015\n",
      "  episode_reward_mean: 578.076601419594\n",
      "  episode_reward_min: -128.09460125789315\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 16864\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3792.996\n",
      "    load_time_ms: 1.445\n",
      "    num_steps_sampled: 2320000\n",
      "    num_steps_trained: 2320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.28595736622810364\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0885486602783203\n",
      "      kl: 0.01896914839744568\n",
      "      policy_loss: 0.0017779985209926963\n",
      "      total_loss: 664.8524780273438\n",
      "      vf_explained_var: 0.9395567178726196\n",
      "      vf_loss: 664.8452758789062\n",
      "    sample_time_ms: 18785.912\n",
      "    update_time_ms: 5.889\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 289.03830070979706\n",
      "  time_since_restore: 6467.756146192551\n",
      "  time_this_iter_s: 22.62403440475464\n",
      "  time_total_s: 6467.756146192551\n",
      "  timestamp: 1553715486\n",
      "  timesteps_since_restore: 2320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2320000\n",
      "  training_iteration: 232\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6467 s, 232 iter, 2320000 ts, 578 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-38-29\n",
      "  done: false\n",
      "  episode_len_mean: 138.0\n",
      "  episode_reward_max: 770.7470333514118\n",
      "  episode_reward_mean: 592.0835812228129\n",
      "  episode_reward_min: -122.24580528767541\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 16937\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3792.587\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 2330000\n",
      "    num_steps_trained: 2330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.28595736622810364\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0760689973831177\n",
      "      kl: 0.01301141269505024\n",
      "      policy_loss: 0.0016919905319809914\n",
      "      total_loss: 844.5164184570312\n",
      "      vf_explained_var: 0.9199368357658386\n",
      "      vf_loss: 844.5110473632812\n",
      "    sample_time_ms: 18806.244\n",
      "    update_time_ms: 5.829\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 296.0417906114064\n",
      "  time_since_restore: 6490.057039737701\n",
      "  time_this_iter_s: 22.300893545150757\n",
      "  time_total_s: 6490.057039737701\n",
      "  timestamp: 1553715509\n",
      "  timesteps_since_restore: 2330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2330000\n",
      "  training_iteration: 233\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6490 s, 233 iter, 2330000 ts, 592 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-38-51\n",
      "  done: false\n",
      "  episode_len_mean: 137.37\n",
      "  episode_reward_max: 775.5757963927593\n",
      "  episode_reward_mean: 590.2818068953277\n",
      "  episode_reward_min: -135.1745545000765\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 17010\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3791.672\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.28595736622810364\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0971442461013794\n",
      "      kl: 0.026416096836328506\n",
      "      policy_loss: 0.0012408331967890263\n",
      "      total_loss: 841.1387939453125\n",
      "      vf_explained_var: 0.927742600440979\n",
      "      vf_loss: 841.130126953125\n",
      "    sample_time_ms: 18848.754\n",
      "    update_time_ms: 5.964\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.1409034476639\n",
      "  time_since_restore: 6512.923183917999\n",
      "  time_this_iter_s: 22.86614418029785\n",
      "  time_total_s: 6512.923183917999\n",
      "  timestamp: 1553715531\n",
      "  timesteps_since_restore: 2340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 234\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6512 s, 234 iter, 2340000 ts, 590 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-39-14\n",
      "  done: false\n",
      "  episode_len_mean: 136.67\n",
      "  episode_reward_max: 750.6393531536971\n",
      "  episode_reward_mean: 585.7985655669371\n",
      "  episode_reward_min: -130.52149048228824\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 17086\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3792.533\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 2350000\n",
      "    num_steps_trained: 2350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.28595736622810364\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0456875562667847\n",
      "      kl: 0.014109230600297451\n",
      "      policy_loss: 0.0008302563801407814\n",
      "      total_loss: 720.4903564453125\n",
      "      vf_explained_var: 0.9343522787094116\n",
      "      vf_loss: 720.4854736328125\n",
      "    sample_time_ms: 18797.863\n",
      "    update_time_ms: 5.844\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.89928278346855\n",
      "  time_since_restore: 6535.10006737709\n",
      "  time_this_iter_s: 22.176883459091187\n",
      "  time_total_s: 6535.10006737709\n",
      "  timestamp: 1553715554\n",
      "  timesteps_since_restore: 2350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2350000\n",
      "  training_iteration: 235\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6535 s, 235 iter, 2350000 ts, 586 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-39-37\n",
      "  done: false\n",
      "  episode_len_mean: 134.6\n",
      "  episode_reward_max: 761.6370786291766\n",
      "  episode_reward_mean: 570.2596413166364\n",
      "  episode_reward_min: -122.9005887112501\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 17160\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3813.135\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 2360000\n",
      "    num_steps_trained: 2360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.28595736622810364\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0606344938278198\n",
      "      kl: 0.020379845052957535\n",
      "      policy_loss: 0.00448894826695323\n",
      "      total_loss: 621.7726440429688\n",
      "      vf_explained_var: 0.9449400305747986\n",
      "      vf_loss: 621.7623291015625\n",
      "    sample_time_ms: 18811.037\n",
      "    update_time_ms: 5.738\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 285.1298206583182\n",
      "  time_since_restore: 6558.359792470932\n",
      "  time_this_iter_s: 23.259725093841553\n",
      "  time_total_s: 6558.359792470932\n",
      "  timestamp: 1553715577\n",
      "  timesteps_since_restore: 2360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2360000\n",
      "  training_iteration: 236\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6558 s, 236 iter, 2360000 ts, 570 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-40-00\n",
      "  done: false\n",
      "  episode_len_mean: 135.09\n",
      "  episode_reward_max: 731.7059248355031\n",
      "  episode_reward_mean: 569.0712970623209\n",
      "  episode_reward_min: -112.32436957138695\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 17235\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3812.648\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.28595736622810364\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0473238229751587\n",
      "      kl: 0.008472190238535404\n",
      "      policy_loss: 0.0016190210590139031\n",
      "      total_loss: 514.87158203125\n",
      "      vf_explained_var: 0.9553194046020508\n",
      "      vf_loss: 514.8675537109375\n",
      "    sample_time_ms: 18837.09\n",
      "    update_time_ms: 5.801\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 284.53564853116046\n",
      "  time_since_restore: 6581.395858049393\n",
      "  time_this_iter_s: 23.036065578460693\n",
      "  time_total_s: 6581.395858049393\n",
      "  timestamp: 1553715600\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 237\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6581 s, 237 iter, 2370000 ts, 569 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-40-23\n",
      "  done: false\n",
      "  episode_len_mean: 131.61\n",
      "  episode_reward_max: 736.6666931366574\n",
      "  episode_reward_mean: 547.9069465557866\n",
      "  episode_reward_min: -134.71164818026682\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 17312\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.571\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 2380000\n",
      "    num_steps_trained: 2380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0527335405349731\n",
      "      kl: 0.014827942475676537\n",
      "      policy_loss: -0.0007573742768727243\n",
      "      total_loss: 746.3251953125\n",
      "      vf_explained_var: 0.940529465675354\n",
      "      vf_loss: 746.3237915039062\n",
      "    sample_time_ms: 18880.031\n",
      "    update_time_ms: 6.018\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 273.9534732778933\n",
      "  time_since_restore: 6604.554552316666\n",
      "  time_this_iter_s: 23.15869426727295\n",
      "  time_total_s: 6604.554552316666\n",
      "  timestamp: 1553715623\n",
      "  timesteps_since_restore: 2380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2380000\n",
      "  training_iteration: 238\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6604 s, 238 iter, 2380000 ts, 548 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-40-46\n",
      "  done: false\n",
      "  episode_len_mean: 138.82\n",
      "  episode_reward_max: 773.82330543839\n",
      "  episode_reward_mean: 601.508732567096\n",
      "  episode_reward_min: -127.5627425396069\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 17385\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.769\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 2390000\n",
      "    num_steps_trained: 2390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1004388332366943\n",
      "      kl: 0.03098955564200878\n",
      "      policy_loss: 0.002941046841442585\n",
      "      total_loss: 668.1500244140625\n",
      "      vf_explained_var: 0.9418769478797913\n",
      "      vf_loss: 668.1426391601562\n",
      "    sample_time_ms: 18901.873\n",
      "    update_time_ms: 6.07\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.754366283548\n",
      "  time_since_restore: 6626.755108833313\n",
      "  time_this_iter_s: 22.20055651664734\n",
      "  time_total_s: 6626.755108833313\n",
      "  timestamp: 1553715646\n",
      "  timesteps_since_restore: 2390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2390000\n",
      "  training_iteration: 239\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6626 s, 239 iter, 2390000 ts, 602 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-41-08\n",
      "  done: false\n",
      "  episode_len_mean: 140.72\n",
      "  episode_reward_max: 766.7028086263261\n",
      "  episode_reward_mean: 616.371535955322\n",
      "  episode_reward_min: -105.27016858977362\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 17458\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3814.853\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0897836685180664\n",
      "      kl: 0.018859373405575752\n",
      "      policy_loss: 0.0026732252445071936\n",
      "      total_loss: 396.75506591796875\n",
      "      vf_explained_var: 0.9666063189506531\n",
      "      vf_loss: 396.7496643066406\n",
      "    sample_time_ms: 18921.157\n",
      "    update_time_ms: 6.051\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 308.18576797766093\n",
      "  time_since_restore: 6649.119998216629\n",
      "  time_this_iter_s: 22.36488938331604\n",
      "  time_total_s: 6649.119998216629\n",
      "  timestamp: 1553715668\n",
      "  timesteps_since_restore: 2400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 240\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6649 s, 240 iter, 2400000 ts, 616 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-41-31\n",
      "  done: false\n",
      "  episode_len_mean: 135.09\n",
      "  episode_reward_max: 742.3231145395282\n",
      "  episode_reward_mean: 573.3908679591045\n",
      "  episode_reward_min: -115.62693363835365\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 17533\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3814.467\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 2410000\n",
      "    num_steps_trained: 2410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0683984756469727\n",
      "      kl: 0.011696677654981613\n",
      "      policy_loss: 0.0008171124500222504\n",
      "      total_loss: 480.989990234375\n",
      "      vf_explained_var: 0.9608264565467834\n",
      "      vf_loss: 480.9874267578125\n",
      "    sample_time_ms: 18861.407\n",
      "    update_time_ms: 5.499\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 286.69543397955226\n",
      "  time_since_restore: 6672.143766403198\n",
      "  time_this_iter_s: 23.023768186569214\n",
      "  time_total_s: 6672.143766403198\n",
      "  timestamp: 1553715691\n",
      "  timesteps_since_restore: 2410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2410000\n",
      "  training_iteration: 241\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6672 s, 241 iter, 2410000 ts, 573 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-41-53\n",
      "  done: false\n",
      "  episode_len_mean: 137.59\n",
      "  episode_reward_max: 773.6917682123226\n",
      "  episode_reward_mean: 591.8889027759126\n",
      "  episode_reward_min: -119.41659764885102\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 17607\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3810.253\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 2420000\n",
      "    num_steps_trained: 2420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0589070320129395\n",
      "      kl: 0.023301368579268456\n",
      "      policy_loss: 0.0024969601072371006\n",
      "      total_loss: 465.9463195800781\n",
      "      vf_explained_var: 0.9628045558929443\n",
      "      vf_loss: 465.94049072265625\n",
      "    sample_time_ms: 18846.71\n",
      "    update_time_ms: 5.441\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.94445138795624\n",
      "  time_since_restore: 6694.578575849533\n",
      "  time_this_iter_s: 22.43480944633484\n",
      "  time_total_s: 6694.578575849533\n",
      "  timestamp: 1553715713\n",
      "  timesteps_since_restore: 2420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2420000\n",
      "  training_iteration: 242\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6694 s, 242 iter, 2420000 ts, 592 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-42-16\n",
      "  done: false\n",
      "  episode_len_mean: 139.39\n",
      "  episode_reward_max: 745.9764108180144\n",
      "  episode_reward_mean: 604.5178730006629\n",
      "  episode_reward_min: -132.5893751441613\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 17681\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3807.913\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0989419221878052\n",
      "      kl: 0.018978701904416084\n",
      "      policy_loss: 0.001774365664459765\n",
      "      total_loss: 448.8724365234375\n",
      "      vf_explained_var: 0.9622134566307068\n",
      "      vf_loss: 448.8679504394531\n",
      "    sample_time_ms: 18864.481\n",
      "    update_time_ms: 5.477\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.25893650033146\n",
      "  time_since_restore: 6717.036623239517\n",
      "  time_this_iter_s: 22.45804738998413\n",
      "  time_total_s: 6717.036623239517\n",
      "  timestamp: 1553715736\n",
      "  timesteps_since_restore: 2430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 243\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6717 s, 243 iter, 2430000 ts, 605 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-42-39\n",
      "  done: false\n",
      "  episode_len_mean: 139.47\n",
      "  episode_reward_max: 753.3696903717619\n",
      "  episode_reward_mean: 601.442001336676\n",
      "  episode_reward_min: -120.74937763611312\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17753\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3808.674\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 2440000\n",
      "    num_steps_trained: 2440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0933303833007812\n",
      "      kl: 0.010650108568370342\n",
      "      policy_loss: -0.000748392310924828\n",
      "      total_loss: 434.3616638183594\n",
      "      vf_explained_var: 0.9632165431976318\n",
      "      vf_loss: 434.3609313964844\n",
      "    sample_time_ms: 18855.576\n",
      "    update_time_ms: 5.377\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.7210006683379\n",
      "  time_since_restore: 6739.821797132492\n",
      "  time_this_iter_s: 22.785173892974854\n",
      "  time_total_s: 6739.821797132492\n",
      "  timestamp: 1553715759\n",
      "  timesteps_since_restore: 2440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2440000\n",
      "  training_iteration: 244\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6739 s, 244 iter, 2440000 ts, 601 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-43-01\n",
      "  done: false\n",
      "  episode_len_mean: 141.24\n",
      "  episode_reward_max: 758.6288734577778\n",
      "  episode_reward_mean: 618.8990429808123\n",
      "  episode_reward_min: -121.38530652710968\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17825\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3810.773\n",
      "    load_time_ms: 1.648\n",
      "    num_steps_sampled: 2450000\n",
      "    num_steps_trained: 2450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.061165690422058\n",
      "      kl: 0.014698252081871033\n",
      "      policy_loss: 0.001556276110932231\n",
      "      total_loss: 664.0912475585938\n",
      "      vf_explained_var: 0.9406740069389343\n",
      "      vf_loss: 664.0875854492188\n",
      "    sample_time_ms: 18887.286\n",
      "    update_time_ms: 5.385\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 309.4495214904062\n",
      "  time_since_restore: 6762.337258338928\n",
      "  time_this_iter_s: 22.515461206436157\n",
      "  time_total_s: 6762.337258338928\n",
      "  timestamp: 1553715781\n",
      "  timesteps_since_restore: 2450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2450000\n",
      "  training_iteration: 245\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6762 s, 245 iter, 2450000 ts, 619 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-43-24\n",
      "  done: false\n",
      "  episode_len_mean: 137.91\n",
      "  episode_reward_max: 779.6897238297718\n",
      "  episode_reward_mean: 591.9474141739979\n",
      "  episode_reward_min: -112.92689670737705\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 17899\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.074\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1038702726364136\n",
      "      kl: 0.013631937094032764\n",
      "      policy_loss: -7.51343304727925e-06\n",
      "      total_loss: 520.8275146484375\n",
      "      vf_explained_var: 0.9554997682571411\n",
      "      vf_loss: 520.8255004882812\n",
      "    sample_time_ms: 18807.705\n",
      "    update_time_ms: 5.353\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.9737070869989\n",
      "  time_since_restore: 6784.644082546234\n",
      "  time_this_iter_s: 22.306824207305908\n",
      "  time_total_s: 6784.644082546234\n",
      "  timestamp: 1553715804\n",
      "  timesteps_since_restore: 2460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 246\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6784 s, 246 iter, 2460000 ts, 592 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-43-46\n",
      "  done: false\n",
      "  episode_len_mean: 139.02\n",
      "  episode_reward_max: 779.389028635363\n",
      "  episode_reward_mean: 601.8970866239732\n",
      "  episode_reward_min: -135.29367712394517\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17971\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3794.525\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 2470000\n",
      "    num_steps_trained: 2470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.127020001411438\n",
      "      kl: 0.021389223635196686\n",
      "      policy_loss: 0.00025344736059196293\n",
      "      total_loss: 681.8139038085938\n",
      "      vf_explained_var: 0.9400376677513123\n",
      "      vf_loss: 681.810546875\n",
      "    sample_time_ms: 18771.296\n",
      "    update_time_ms: 5.328\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.9485433119866\n",
      "  time_since_restore: 6807.311157941818\n",
      "  time_this_iter_s: 22.667075395584106\n",
      "  time_total_s: 6807.311157941818\n",
      "  timestamp: 1553715826\n",
      "  timesteps_since_restore: 2470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2470000\n",
      "  training_iteration: 247\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6807 s, 247 iter, 2470000 ts, 602 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-44-09\n",
      "  done: false\n",
      "  episode_len_mean: 142.73\n",
      "  episode_reward_max: 761.6242429322525\n",
      "  episode_reward_mean: 626.0547931690678\n",
      "  episode_reward_min: -107.02477184522088\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 18043\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.689\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 2480000\n",
      "    num_steps_trained: 2480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1097464561462402\n",
      "      kl: 0.010946185328066349\n",
      "      policy_loss: -2.407034298812505e-05\n",
      "      total_loss: 458.6636657714844\n",
      "      vf_explained_var: 0.9587526321411133\n",
      "      vf_loss: 458.66204833984375\n",
      "    sample_time_ms: 18718.365\n",
      "    update_time_ms: 5.243\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.0273965845339\n",
      "  time_since_restore: 6829.99113202095\n",
      "  time_this_iter_s: 22.67997407913208\n",
      "  time_total_s: 6829.99113202095\n",
      "  timestamp: 1553715849\n",
      "  timesteps_since_restore: 2480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2480000\n",
      "  training_iteration: 248\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6829 s, 248 iter, 2480000 ts, 626 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-44-32\n",
      "  done: false\n",
      "  episode_len_mean: 137.51\n",
      "  episode_reward_max: 747.7636043178887\n",
      "  episode_reward_mean: 573.3970155964431\n",
      "  episode_reward_min: -133.36556547741014\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 18117\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.033\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1377475261688232\n",
      "      kl: 0.02432142198085785\n",
      "      policy_loss: 0.0006176288588903844\n",
      "      total_loss: 361.12078857421875\n",
      "      vf_explained_var: 0.9722561836242676\n",
      "      vf_loss: 361.11669921875\n",
      "    sample_time_ms: 18821.138\n",
      "    update_time_ms: 5.395\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 286.69850779822156\n",
      "  time_since_restore: 6853.202552556992\n",
      "  time_this_iter_s: 23.21142053604126\n",
      "  time_total_s: 6853.202552556992\n",
      "  timestamp: 1553715872\n",
      "  timesteps_since_restore: 2490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 249\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6853 s, 249 iter, 2490000 ts, 573 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-44-54\n",
      "  done: false\n",
      "  episode_len_mean: 137.89\n",
      "  episode_reward_max: 728.4449174306612\n",
      "  episode_reward_mean: 583.6868666940532\n",
      "  episode_reward_min: -128.4408722035395\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 18190\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.686\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 2500000\n",
      "    num_steps_trained: 2500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.105691909790039\n",
      "      kl: 0.014705413021147251\n",
      "      policy_loss: 0.0011039570672437549\n",
      "      total_loss: 398.604248046875\n",
      "      vf_explained_var: 0.9674752950668335\n",
      "      vf_loss: 398.60107421875\n",
      "    sample_time_ms: 18784.874\n",
      "    update_time_ms: 5.357\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 291.8434333470265\n",
      "  time_since_restore: 6875.183252573013\n",
      "  time_this_iter_s: 21.98070001602173\n",
      "  time_total_s: 6875.183252573013\n",
      "  timestamp: 1553715894\n",
      "  timesteps_since_restore: 2500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2500000\n",
      "  training_iteration: 250\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6875 s, 250 iter, 2500000 ts, 584 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-45-17\n",
      "  done: false\n",
      "  episode_len_mean: 137.03\n",
      "  episode_reward_max: 761.1460899282824\n",
      "  episode_reward_mean: 584.55395112683\n",
      "  episode_reward_min: -129.31223685853337\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 18265\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.113\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 2510000\n",
      "    num_steps_trained: 2510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.097489356994629\n",
      "      kl: 0.014731199480593204\n",
      "      policy_loss: -0.002689347369596362\n",
      "      total_loss: 701.4608154296875\n",
      "      vf_explained_var: 0.9395540952682495\n",
      "      vf_loss: 701.46142578125\n",
      "    sample_time_ms: 18760.957\n",
      "    update_time_ms: 5.311\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.276975563415\n",
      "  time_since_restore: 6897.96920633316\n",
      "  time_this_iter_s: 22.785953760147095\n",
      "  time_total_s: 6897.96920633316\n",
      "  timestamp: 1553715917\n",
      "  timesteps_since_restore: 2510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2510000\n",
      "  training_iteration: 251\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6897 s, 251 iter, 2510000 ts, 585 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-45-40\n",
      "  done: false\n",
      "  episode_len_mean: 137.13\n",
      "  episode_reward_max: 744.5590194075583\n",
      "  episode_reward_mean: 580.4477270011316\n",
      "  episode_reward_min: -134.54947528096534\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 18340\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.174\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.14297868311405182\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.130353331565857\n",
      "      kl: 0.0756368488073349\n",
      "      policy_loss: 0.016337839886546135\n",
      "      total_loss: 670.2637939453125\n",
      "      vf_explained_var: 0.9443259835243225\n",
      "      vf_loss: 670.2366943359375\n",
      "    sample_time_ms: 18745.966\n",
      "    update_time_ms: 5.318\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.2238635005658\n",
      "  time_since_restore: 6920.256544113159\n",
      "  time_this_iter_s: 22.28733777999878\n",
      "  time_total_s: 6920.256544113159\n",
      "  timestamp: 1553715940\n",
      "  timesteps_since_restore: 2520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 252\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6920 s, 252 iter, 2520000 ts, 580 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-46-02\n",
      "  done: false\n",
      "  episode_len_mean: 134.26\n",
      "  episode_reward_max: 772.4701697379726\n",
      "  episode_reward_mean: 568.7443906546702\n",
      "  episode_reward_min: -126.05322080720423\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 18415\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.994\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 2530000\n",
      "    num_steps_trained: 2530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.21446803212165833\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.09429931640625\n",
      "      kl: 0.009949927218258381\n",
      "      policy_loss: 0.0010127363493666053\n",
      "      total_loss: 297.9016418457031\n",
      "      vf_explained_var: 0.9764953851699829\n",
      "      vf_loss: 297.89849853515625\n",
      "    sample_time_ms: 18721.896\n",
      "    update_time_ms: 5.376\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 284.3721953273351\n",
      "  time_since_restore: 6942.480952501297\n",
      "  time_this_iter_s: 22.224408388137817\n",
      "  time_total_s: 6942.480952501297\n",
      "  timestamp: 1553715962\n",
      "  timesteps_since_restore: 2530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2530000\n",
      "  training_iteration: 253\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6942 s, 253 iter, 2530000 ts, 569 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-46-25\n",
      "  done: false\n",
      "  episode_len_mean: 139.43\n",
      "  episode_reward_max: 754.8481937477698\n",
      "  episode_reward_mean: 614.099013025197\n",
      "  episode_reward_min: -109.19877956359156\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 18489\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3794.009\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 2540000\n",
      "    num_steps_trained: 2540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0855159759521484\n",
      "      kl: 0.010818945243954659\n",
      "      policy_loss: 0.0010606569703668356\n",
      "      total_loss: 685.5062255859375\n",
      "      vf_explained_var: 0.9391224980354309\n",
      "      vf_loss: 685.5039672851562\n",
      "    sample_time_ms: 18727.623\n",
      "    update_time_ms: 5.363\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 307.0495065125985\n",
      "  time_since_restore: 6965.294787406921\n",
      "  time_this_iter_s: 22.81383490562439\n",
      "  time_total_s: 6965.294787406921\n",
      "  timestamp: 1553715985\n",
      "  timesteps_since_restore: 2540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2540000\n",
      "  training_iteration: 254\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6965 s, 254 iter, 2540000 ts, 614 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-46-47\n",
      "  done: false\n",
      "  episode_len_mean: 136.49\n",
      "  episode_reward_max: 756.5105880459712\n",
      "  episode_reward_mean: 580.2882127518367\n",
      "  episode_reward_min: -127.82185151980755\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 18563\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.64\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.094864010810852\n",
      "      kl: 0.028882252052426338\n",
      "      policy_loss: 0.0010274866363033652\n",
      "      total_loss: 385.365478515625\n",
      "      vf_explained_var: 0.9705196022987366\n",
      "      vf_loss: 385.36138916015625\n",
      "    sample_time_ms: 18685.208\n",
      "    update_time_ms: 5.427\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.14410637591834\n",
      "  time_since_restore: 6987.355224847794\n",
      "  time_this_iter_s: 22.060437440872192\n",
      "  time_total_s: 6987.355224847794\n",
      "  timestamp: 1553716007\n",
      "  timesteps_since_restore: 2550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 255\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 6987 s, 255 iter, 2550000 ts, 580 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-47-09\n",
      "  done: false\n",
      "  episode_len_mean: 133.5\n",
      "  episode_reward_max: 756.8595971566416\n",
      "  episode_reward_mean: 561.9290060962767\n",
      "  episode_reward_min: -113.9345539887255\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 18639\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.88\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 2560000\n",
      "    num_steps_trained: 2560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1091418266296387\n",
      "      kl: 0.020794516429305077\n",
      "      policy_loss: 0.000702221819665283\n",
      "      total_loss: 813.9493408203125\n",
      "      vf_explained_var: 0.9357765316963196\n",
      "      vf_loss: 813.946533203125\n",
      "    sample_time_ms: 18719.25\n",
      "    update_time_ms: 5.608\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 280.96450304813834\n",
      "  time_since_restore: 7010.007976055145\n",
      "  time_this_iter_s: 22.652751207351685\n",
      "  time_total_s: 7010.007976055145\n",
      "  timestamp: 1553716029\n",
      "  timesteps_since_restore: 2560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2560000\n",
      "  training_iteration: 256\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7010 s, 256 iter, 2560000 ts, 562 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-47-32\n",
      "  done: false\n",
      "  episode_len_mean: 135.18\n",
      "  episode_reward_max: 768.07127760951\n",
      "  episode_reward_mean: 571.6829128421637\n",
      "  episode_reward_min: -125.37784611299315\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 18714\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3791.831\n",
      "    load_time_ms: 1.661\n",
      "    num_steps_sampled: 2570000\n",
      "    num_steps_trained: 2570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0913041830062866\n",
      "      kl: 0.01713862642645836\n",
      "      policy_loss: -0.0015468014171347022\n",
      "      total_loss: 403.6173095703125\n",
      "      vf_explained_var: 0.9685855507850647\n",
      "      vf_loss: 403.6170654296875\n",
      "    sample_time_ms: 18667.843\n",
      "    update_time_ms: 5.598\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 285.8414564210818\n",
      "  time_since_restore: 7032.1716430187225\n",
      "  time_this_iter_s: 22.16366696357727\n",
      "  time_total_s: 7032.1716430187225\n",
      "  timestamp: 1553716052\n",
      "  timesteps_since_restore: 2570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2570000\n",
      "  training_iteration: 257\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7032 s, 257 iter, 2570000 ts, 572 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-47-54\n",
      "  done: false\n",
      "  episode_len_mean: 139.02\n",
      "  episode_reward_max: 780.1300621686947\n",
      "  episode_reward_mean: 600.5495304079791\n",
      "  episode_reward_min: -127.93131892449593\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 18787\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3786.038\n",
      "    load_time_ms: 1.676\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.126434564590454\n",
      "      kl: 0.011257688514888287\n",
      "      policy_loss: -0.00037970280391164124\n",
      "      total_loss: 452.19781494140625\n",
      "      vf_explained_var: 0.9618147015571594\n",
      "      vf_loss: 452.197021484375\n",
      "    sample_time_ms: 18611.085\n",
      "    update_time_ms: 5.702\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.2747652039896\n",
      "  time_since_restore: 7054.228050708771\n",
      "  time_this_iter_s: 22.056407690048218\n",
      "  time_total_s: 7054.228050708771\n",
      "  timestamp: 1553716074\n",
      "  timesteps_since_restore: 2580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 258\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7054 s, 258 iter, 2580000 ts, 601 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-48-16\n",
      "  done: false\n",
      "  episode_len_mean: 138.52\n",
      "  episode_reward_max: 748.1446856893674\n",
      "  episode_reward_mean: 597.3514319873238\n",
      "  episode_reward_min: -98.34547423118454\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 18861\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3787.325\n",
      "    load_time_ms: 1.716\n",
      "    num_steps_sampled: 2590000\n",
      "    num_steps_trained: 2590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.121764063835144\n",
      "      kl: 0.015085839666426182\n",
      "      policy_loss: -0.0015958950389176607\n",
      "      total_loss: 868.5684814453125\n",
      "      vf_explained_var: 0.9257681369781494\n",
      "      vf_loss: 868.5684814453125\n",
      "    sample_time_ms: 18487.25\n",
      "    update_time_ms: 5.563\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 298.6757159936619\n",
      "  time_since_restore: 7076.217885017395\n",
      "  time_this_iter_s: 21.989834308624268\n",
      "  time_total_s: 7076.217885017395\n",
      "  timestamp: 1553716096\n",
      "  timesteps_since_restore: 2590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2590000\n",
      "  training_iteration: 259\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7076 s, 259 iter, 2590000 ts, 597 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-48-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.17\n",
      "  episode_reward_max: 750.8336591199319\n",
      "  episode_reward_mean: 624.6027468147012\n",
      "  episode_reward_min: -98.34547423118454\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 18932\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3784.242\n",
      "    load_time_ms: 1.7\n",
      "    num_steps_sampled: 2600000\n",
      "    num_steps_trained: 2600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1361013650894165\n",
      "      kl: 0.012143874540925026\n",
      "      policy_loss: -0.0002920822589658201\n",
      "      total_loss: 540.2882080078125\n",
      "      vf_explained_var: 0.9516090154647827\n",
      "      vf_loss: 540.2872314453125\n",
      "    sample_time_ms: 18554.26\n",
      "    update_time_ms: 5.578\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.30137340735064\n",
      "  time_since_restore: 7098.836627244949\n",
      "  time_this_iter_s: 22.61874222755432\n",
      "  time_total_s: 7098.836627244949\n",
      "  timestamp: 1553716118\n",
      "  timesteps_since_restore: 2600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2600000\n",
      "  training_iteration: 260\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7098 s, 260 iter, 2600000 ts, 625 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-49-00\n",
      "  done: false\n",
      "  episode_len_mean: 133.74\n",
      "  episode_reward_max: 747.1071658871131\n",
      "  episode_reward_mean: 557.2842099766818\n",
      "  episode_reward_min: -134.50430007952212\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 19009\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3782.197\n",
      "    load_time_ms: 1.708\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1406700611114502\n",
      "      kl: 0.01263873279094696\n",
      "      policy_loss: -0.0016245695296674967\n",
      "      total_loss: 472.8056945800781\n",
      "      vf_explained_var: 0.9637564420700073\n",
      "      vf_loss: 472.8059387207031\n",
      "    sample_time_ms: 18446.564\n",
      "    update_time_ms: 5.498\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 278.64210498834086\n",
      "  time_since_restore: 7120.525186538696\n",
      "  time_this_iter_s: 21.68855929374695\n",
      "  time_total_s: 7120.525186538696\n",
      "  timestamp: 1553716140\n",
      "  timesteps_since_restore: 2610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 261\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7120 s, 261 iter, 2610000 ts, 557 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-49-23\n",
      "  done: false\n",
      "  episode_len_mean: 142.03\n",
      "  episode_reward_max: 744.087398493378\n",
      "  episode_reward_mean: 623.2586760916139\n",
      "  episode_reward_min: -127.6830933325301\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 19080\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.428\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 2620000\n",
      "    num_steps_trained: 2620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.142698049545288\n",
      "      kl: 0.0154993562027812\n",
      "      policy_loss: 0.0002640944148879498\n",
      "      total_loss: 589.0718383789062\n",
      "      vf_explained_var: 0.9486594796180725\n",
      "      vf_loss: 589.0698852539062\n",
      "    sample_time_ms: 18487.361\n",
      "    update_time_ms: 5.599\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 311.6293380458069\n",
      "  time_since_restore: 7143.300438642502\n",
      "  time_this_iter_s: 22.775252103805542\n",
      "  time_total_s: 7143.300438642502\n",
      "  timestamp: 1553716163\n",
      "  timesteps_since_restore: 2620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2620000\n",
      "  training_iteration: 262\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7143 s, 262 iter, 2620000 ts, 623 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-49-46\n",
      "  done: false\n",
      "  episode_len_mean: 138.06\n",
      "  episode_reward_max: 760.8533821622481\n",
      "  episode_reward_mean: 598.3028382628501\n",
      "  episode_reward_min: -110.92838471199218\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 19153\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3794.011\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 2630000\n",
      "    num_steps_trained: 2630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10723401606082916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0914355516433716\n",
      "      kl: 0.00739707937464118\n",
      "      policy_loss: -0.0013150061713531613\n",
      "      total_loss: 471.56939697265625\n",
      "      vf_explained_var: 0.9600352048873901\n",
      "      vf_loss: 471.56982421875\n",
      "    sample_time_ms: 18545.019\n",
      "    update_time_ms: 5.521\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 299.1514191314251\n",
      "  time_since_restore: 7166.135633468628\n",
      "  time_this_iter_s: 22.8351948261261\n",
      "  time_total_s: 7166.135633468628\n",
      "  timestamp: 1553716186\n",
      "  timesteps_since_restore: 2630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2630000\n",
      "  training_iteration: 263\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7166 s, 263 iter, 2630000 ts, 598 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-50-08\n",
      "  done: false\n",
      "  episode_len_mean: 135.57\n",
      "  episode_reward_max: 778.5585856661902\n",
      "  episode_reward_mean: 578.6595660859439\n",
      "  episode_reward_min: -132.23397125431873\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 19229\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.829\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1457128524780273\n",
      "      kl: 0.037569914013147354\n",
      "      policy_loss: -0.0005893359775654972\n",
      "      total_loss: 1069.295166015625\n",
      "      vf_explained_var: 0.9082379341125488\n",
      "      vf_loss: 1069.293701171875\n",
      "    sample_time_ms: 18498.729\n",
      "    update_time_ms: 5.513\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 289.32978304297194\n",
      "  time_since_restore: 7188.502652168274\n",
      "  time_this_iter_s: 22.367018699645996\n",
      "  time_total_s: 7188.502652168274\n",
      "  timestamp: 1553716208\n",
      "  timesteps_since_restore: 2640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 264\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7188 s, 264 iter, 2640000 ts, 579 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-50-31\n",
      "  done: false\n",
      "  episode_len_mean: 137.87\n",
      "  episode_reward_max: 765.7484078187125\n",
      "  episode_reward_mean: 591.7595973289325\n",
      "  episode_reward_min: -120.36846708912118\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 19302\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.987\n",
      "    load_time_ms: 1.618\n",
      "    num_steps_sampled: 2650000\n",
      "    num_steps_trained: 2650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.133860468864441\n",
      "      kl: 0.02081376686692238\n",
      "      policy_loss: 0.0013872083509340882\n",
      "      total_loss: 655.1703491210938\n",
      "      vf_explained_var: 0.94049072265625\n",
      "      vf_loss: 655.1678466796875\n",
      "    sample_time_ms: 18568.848\n",
      "    update_time_ms: 5.626\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.8797986644662\n",
      "  time_since_restore: 7211.2638030052185\n",
      "  time_this_iter_s: 22.76115083694458\n",
      "  time_total_s: 7211.2638030052185\n",
      "  timestamp: 1553716231\n",
      "  timesteps_since_restore: 2650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2650000\n",
      "  training_iteration: 265\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7211 s, 265 iter, 2650000 ts, 592 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 136.31\n",
      "  episode_reward_max: 745.7752549990494\n",
      "  episode_reward_mean: 583.4604988639987\n",
      "  episode_reward_min: -118.79099381440297\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 19376\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3791.686\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 2660000\n",
      "    num_steps_trained: 2660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1286362409591675\n",
      "      kl: 0.010465490631759167\n",
      "      policy_loss: -0.0005656553548760712\n",
      "      total_loss: 199.73643493652344\n",
      "      vf_explained_var: 0.9849106073379517\n",
      "      vf_loss: 199.73643493652344\n",
      "    sample_time_ms: 18579.071\n",
      "    update_time_ms: 5.56\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 291.7302494319993\n",
      "  time_since_restore: 7233.977342367172\n",
      "  time_this_iter_s: 22.713539361953735\n",
      "  time_total_s: 7233.977342367172\n",
      "  timestamp: 1553716254\n",
      "  timesteps_since_restore: 2660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2660000\n",
      "  training_iteration: 266\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7233 s, 266 iter, 2660000 ts, 583 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-51-16\n",
      "  done: false\n",
      "  episode_len_mean: 141.43\n",
      "  episode_reward_max: 776.7708696577457\n",
      "  episode_reward_mean: 634.3799401949294\n",
      "  episode_reward_min: -75.24206152833551\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 19448\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3791.619\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1565723419189453\n",
      "      kl: 0.013357603922486305\n",
      "      policy_loss: -0.0002456922666169703\n",
      "      total_loss: 190.76466369628906\n",
      "      vf_explained_var: 0.9843116402626038\n",
      "      vf_loss: 190.76419067382812\n",
      "    sample_time_ms: 18605.449\n",
      "    update_time_ms: 5.651\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 317.1899700974647\n",
      "  time_since_restore: 7256.403833389282\n",
      "  time_this_iter_s: 22.426491022109985\n",
      "  time_total_s: 7256.403833389282\n",
      "  timestamp: 1553716276\n",
      "  timesteps_since_restore: 2670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 267\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7256 s, 267 iter, 2670000 ts, 634 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-51-39\n",
      "  done: false\n",
      "  episode_len_mean: 140.08\n",
      "  episode_reward_max: 759.8084982319396\n",
      "  episode_reward_mean: 619.5958451511183\n",
      "  episode_reward_min: -121.84755481498874\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 19520\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3792.096\n",
      "    load_time_ms: 1.583\n",
      "    num_steps_sampled: 2680000\n",
      "    num_steps_trained: 2680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.140097975730896\n",
      "      kl: 0.01342835370451212\n",
      "      policy_loss: 0.00046034270781092346\n",
      "      total_loss: 779.2951049804688\n",
      "      vf_explained_var: 0.9270222783088684\n",
      "      vf_loss: 779.2939453125\n",
      "    sample_time_ms: 18657.206\n",
      "    update_time_ms: 5.441\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 309.79792257555914\n",
      "  time_since_restore: 7278.9797875881195\n",
      "  time_this_iter_s: 22.57595419883728\n",
      "  time_total_s: 7278.9797875881195\n",
      "  timestamp: 1553716299\n",
      "  timesteps_since_restore: 2680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2680000\n",
      "  training_iteration: 268\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7278 s, 268 iter, 2680000 ts, 620 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-52-01\n",
      "  done: false\n",
      "  episode_len_mean: 140.16\n",
      "  episode_reward_max: 765.0160245092089\n",
      "  episode_reward_mean: 613.3695675844992\n",
      "  episode_reward_min: -128.10841397499095\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 19593\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.397\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 2690000\n",
      "    num_steps_trained: 2690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1546186208724976\n",
      "      kl: 0.011864706873893738\n",
      "      policy_loss: -0.0005523505387827754\n",
      "      total_loss: 261.5359802246094\n",
      "      vf_explained_var: 0.9787012934684753\n",
      "      vf_loss: 261.5359191894531\n",
      "    sample_time_ms: 18689.611\n",
      "    update_time_ms: 5.463\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 306.6847837922495\n",
      "  time_since_restore: 7301.325933218002\n",
      "  time_this_iter_s: 22.346145629882812\n",
      "  time_total_s: 7301.325933218002\n",
      "  timestamp: 1553716321\n",
      "  timesteps_since_restore: 2690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2690000\n",
      "  training_iteration: 269\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7301 s, 269 iter, 2690000 ts, 613 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-52-24\n",
      "  done: false\n",
      "  episode_len_mean: 137.76\n",
      "  episode_reward_max: 757.8000896330212\n",
      "  episode_reward_mean: 592.7127089236224\n",
      "  episode_reward_min: -123.7941924745911\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 19666\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.817\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1322269439697266\n",
      "      kl: 0.015658153221011162\n",
      "      policy_loss: 0.0006746636354364455\n",
      "      total_loss: 227.28961181640625\n",
      "      vf_explained_var: 0.9819596409797668\n",
      "      vf_loss: 227.28811645507812\n",
      "    sample_time_ms: 18661.837\n",
      "    update_time_ms: 5.482\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 296.3563544618112\n",
      "  time_since_restore: 7323.699574947357\n",
      "  time_this_iter_s: 22.37364172935486\n",
      "  time_total_s: 7323.699574947357\n",
      "  timestamp: 1553716344\n",
      "  timesteps_since_restore: 2700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 270\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7323 s, 270 iter, 2700000 ts, 593 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-52-46\n",
      "  done: false\n",
      "  episode_len_mean: 138.51\n",
      "  episode_reward_max: 768.6563342239866\n",
      "  episode_reward_mean: 605.4013409737538\n",
      "  episode_reward_min: -125.84990853949944\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 19741\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.11\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 2710000\n",
      "    num_steps_trained: 2710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1527178287506104\n",
      "      kl: 0.019728031009435654\n",
      "      policy_loss: 0.0005132639780640602\n",
      "      total_loss: 585.3507690429688\n",
      "      vf_explained_var: 0.9537891745567322\n",
      "      vf_loss: 585.3491821289062\n",
      "    sample_time_ms: 18744.799\n",
      "    update_time_ms: 5.443\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.7006704868769\n",
      "  time_since_restore: 7346.211796998978\n",
      "  time_this_iter_s: 22.512222051620483\n",
      "  time_total_s: 7346.211796998978\n",
      "  timestamp: 1553716366\n",
      "  timesteps_since_restore: 2710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2710000\n",
      "  training_iteration: 271\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7346 s, 271 iter, 2710000 ts, 605 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-53-09\n",
      "  done: false\n",
      "  episode_len_mean: 140.31\n",
      "  episode_reward_max: 757.4911312085613\n",
      "  episode_reward_mean: 616.212992895386\n",
      "  episode_reward_min: -87.74045868493492\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 19812\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3804.398\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 2720000\n",
      "    num_steps_trained: 2720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05361700803041458\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1395779848098755\n",
      "      kl: 0.009274100884795189\n",
      "      policy_loss: -0.0025973760057240725\n",
      "      total_loss: 203.95361328125\n",
      "      vf_explained_var: 0.9832214117050171\n",
      "      vf_loss: 203.95571899414062\n",
      "    sample_time_ms: 18735.01\n",
      "    update_time_ms: 5.298\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 308.10649644769296\n",
      "  time_since_restore: 7368.950851917267\n",
      "  time_this_iter_s: 22.739054918289185\n",
      "  time_total_s: 7368.950851917267\n",
      "  timestamp: 1553716389\n",
      "  timesteps_since_restore: 2720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2720000\n",
      "  training_iteration: 272\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7368 s, 272 iter, 2720000 ts, 616 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-53-32\n",
      "  done: false\n",
      "  episode_len_mean: 141.26\n",
      "  episode_reward_max: 768.5459614386629\n",
      "  episode_reward_mean: 624.9241330363568\n",
      "  episode_reward_min: -88.73153004537716\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 19883\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3800.371\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02680850401520729\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1777267456054688\n",
      "      kl: 0.018105320632457733\n",
      "      policy_loss: -0.0031339002307504416\n",
      "      total_loss: 520.7830810546875\n",
      "      vf_explained_var: 0.954791247844696\n",
      "      vf_loss: 520.7857666015625\n",
      "    sample_time_ms: 18706.156\n",
      "    update_time_ms: 5.265\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.46206651817846\n",
      "  time_since_restore: 7391.457729101181\n",
      "  time_this_iter_s: 22.506877183914185\n",
      "  time_total_s: 7391.457729101181\n",
      "  timestamp: 1553716412\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 273\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7391 s, 273 iter, 2730000 ts, 625 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-53-54\n",
      "  done: false\n",
      "  episode_len_mean: 136.97\n",
      "  episode_reward_max: 779.7352867516142\n",
      "  episode_reward_mean: 589.4190947255902\n",
      "  episode_reward_min: -140.52028266084602\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 19957\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.474\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 2740000\n",
      "    num_steps_trained: 2740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02680850401520729\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.137038230895996\n",
      "      kl: 0.018835021182894707\n",
      "      policy_loss: 0.002007438335567713\n",
      "      total_loss: 669.4283447265625\n",
      "      vf_explained_var: 0.9461351037025452\n",
      "      vf_loss: 669.42578125\n",
      "    sample_time_ms: 18681.752\n",
      "    update_time_ms: 5.328\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 294.7095473627951\n",
      "  time_since_restore: 7413.570033550262\n",
      "  time_this_iter_s: 22.11230444908142\n",
      "  time_total_s: 7413.570033550262\n",
      "  timestamp: 1553716434\n",
      "  timesteps_since_restore: 2740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2740000\n",
      "  training_iteration: 274\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7413 s, 274 iter, 2740000 ts, 589 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-54-15\n",
      "  done: false\n",
      "  episode_len_mean: 141.62\n",
      "  episode_reward_max: 766.7991016189413\n",
      "  episode_reward_mean: 624.8798567148639\n",
      "  episode_reward_min: -112.19426688098957\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 20029\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.929\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 2750000\n",
      "    num_steps_trained: 2750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02680850401520729\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.16073739528656\n",
      "      kl: 0.020292771980166435\n",
      "      policy_loss: 0.0014390479773283005\n",
      "      total_loss: 306.4714050292969\n",
      "      vf_explained_var: 0.9780684113502502\n",
      "      vf_loss: 306.4694519042969\n",
      "    sample_time_ms: 18564.752\n",
      "    update_time_ms: 5.161\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.439928357432\n",
      "  time_since_restore: 7435.153541088104\n",
      "  time_this_iter_s: 21.583507537841797\n",
      "  time_total_s: 7435.153541088104\n",
      "  timestamp: 1553716455\n",
      "  timesteps_since_restore: 2750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2750000\n",
      "  training_iteration: 275\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7435 s, 275 iter, 2750000 ts, 625 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-54-37\n",
      "  done: false\n",
      "  episode_len_mean: 141.4\n",
      "  episode_reward_max: 752.0977116877281\n",
      "  episode_reward_mean: 627.691432922668\n",
      "  episode_reward_min: -136.23304750748866\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 20100\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3800.981\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02680850401520729\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.151788592338562\n",
      "      kl: 0.015023954212665558\n",
      "      policy_loss: -0.0019981020595878363\n",
      "      total_loss: 467.61810302734375\n",
      "      vf_explained_var: 0.9591493010520935\n",
      "      vf_loss: 467.61968994140625\n",
      "    sample_time_ms: 18484.268\n",
      "    update_time_ms: 5.28\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.845716461334\n",
      "  time_since_restore: 7457.082268238068\n",
      "  time_this_iter_s: 21.92872714996338\n",
      "  time_total_s: 7457.082268238068\n",
      "  timestamp: 1553716477\n",
      "  timesteps_since_restore: 2760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 276\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7457 s, 276 iter, 2760000 ts, 628 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-54-59\n",
      "  done: false\n",
      "  episode_len_mean: 135.02\n",
      "  episode_reward_max: 777.2668651062413\n",
      "  episode_reward_mean: 581.796733230713\n",
      "  episode_reward_min: -123.87698736064672\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 20176\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.025\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 2770000\n",
      "    num_steps_trained: 2770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02680850401520729\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1446799039840698\n",
      "      kl: 0.023237084969878197\n",
      "      policy_loss: -0.0007743602618575096\n",
      "      total_loss: 737.8618774414062\n",
      "      vf_explained_var: 0.9475172162055969\n",
      "      vf_loss: 737.862060546875\n",
      "    sample_time_ms: 18431.241\n",
      "    update_time_ms: 5.415\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.89836661535657\n",
      "  time_since_restore: 7478.98956489563\n",
      "  time_this_iter_s: 21.907296657562256\n",
      "  time_total_s: 7478.98956489563\n",
      "  timestamp: 1553716499\n",
      "  timesteps_since_restore: 2770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2770000\n",
      "  training_iteration: 277\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7478 s, 277 iter, 2770000 ts, 582 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-55-21\n",
      "  done: false\n",
      "  episode_len_mean: 136.94\n",
      "  episode_reward_max: 765.8213902805046\n",
      "  episode_reward_mean: 595.0635723888739\n",
      "  episode_reward_min: -128.2181404747161\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 20250\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3804.007\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 2780000\n",
      "    num_steps_trained: 2780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02680850401520729\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1453968286514282\n",
      "      kl: 0.009390207007527351\n",
      "      policy_loss: -0.00025130348512902856\n",
      "      total_loss: 592.99951171875\n",
      "      vf_explained_var: 0.9540427923202515\n",
      "      vf_loss: 592.99951171875\n",
      "    sample_time_ms: 18318.224\n",
      "    update_time_ms: 5.487\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 297.5317861944369\n",
      "  time_since_restore: 7500.456632614136\n",
      "  time_this_iter_s: 21.46706771850586\n",
      "  time_total_s: 7500.456632614136\n",
      "  timestamp: 1553716521\n",
      "  timesteps_since_restore: 2780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2780000\n",
      "  training_iteration: 278\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7500 s, 278 iter, 2780000 ts, 595 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 139.24\n",
      "  episode_reward_max: 789.3901758942569\n",
      "  episode_reward_mean: 619.5029000051676\n",
      "  episode_reward_min: -126.0714545684505\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 20323\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.037\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.013404252007603645\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1679742336273193\n",
      "      kl: 0.01100701279938221\n",
      "      policy_loss: -0.0011987074976786971\n",
      "      total_loss: 289.43133544921875\n",
      "      vf_explained_var: 0.9767783880233765\n",
      "      vf_loss: 289.4324035644531\n",
      "    sample_time_ms: 18343.436\n",
      "    update_time_ms: 5.444\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 309.75145000258374\n",
      "  time_since_restore: 7522.976963043213\n",
      "  time_this_iter_s: 22.52033042907715\n",
      "  time_total_s: 7522.976963043213\n",
      "  timestamp: 1553716543\n",
      "  timesteps_since_restore: 2790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 279\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7522 s, 279 iter, 2790000 ts, 620 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-56-05\n",
      "  done: false\n",
      "  episode_len_mean: 138.36\n",
      "  episode_reward_max: 769.0452681906594\n",
      "  episode_reward_mean: 603.3532881844305\n",
      "  episode_reward_min: -85.81984146582568\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 20396\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.925\n",
      "    load_time_ms: 1.685\n",
      "    num_steps_sampled: 2800000\n",
      "    num_steps_trained: 2800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.013404252007603645\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1600028276443481\n",
      "      kl: 0.01924820989370346\n",
      "      policy_loss: 0.0010296052787452936\n",
      "      total_loss: 597.8272094726562\n",
      "      vf_explained_var: 0.950070321559906\n",
      "      vf_loss: 597.8258666992188\n",
      "    sample_time_ms: 18305.25\n",
      "    update_time_ms: 5.391\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 301.67664409221527\n",
      "  time_since_restore: 7544.967748165131\n",
      "  time_this_iter_s: 21.990785121917725\n",
      "  time_total_s: 7544.967748165131\n",
      "  timestamp: 1553716565\n",
      "  timesteps_since_restore: 2800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2800000\n",
      "  training_iteration: 280\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7544 s, 280 iter, 2800000 ts, 603 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 139.78\n",
      "  episode_reward_max: 760.8383710722406\n",
      "  episode_reward_mean: 624.6260869749785\n",
      "  episode_reward_min: -106.71762854572327\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 20468\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.385\n",
      "    load_time_ms: 1.724\n",
      "    num_steps_sampled: 2810000\n",
      "    num_steps_trained: 2810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.013404252007603645\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1562960147857666\n",
      "      kl: 0.01845688745379448\n",
      "      policy_loss: -0.0036387289874255657\n",
      "      total_loss: 461.228759765625\n",
      "      vf_explained_var: 0.9602256417274475\n",
      "      vf_loss: 461.232177734375\n",
      "    sample_time_ms: 18286.361\n",
      "    update_time_ms: 5.526\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.31304348748927\n",
      "  time_since_restore: 7567.31893658638\n",
      "  time_this_iter_s: 22.35118842124939\n",
      "  time_total_s: 7567.31893658638\n",
      "  timestamp: 1553716588\n",
      "  timesteps_since_restore: 2810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2810000\n",
      "  training_iteration: 281\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7567 s, 281 iter, 2810000 ts, 625 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-56-50\n",
      "  done: false\n",
      "  episode_len_mean: 137.72\n",
      "  episode_reward_max: 758.6568591911782\n",
      "  episode_reward_mean: 612.3665521276856\n",
      "  episode_reward_min: -113.71150807318867\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 20541\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.837\n",
      "    load_time_ms: 1.72\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.013404252007603645\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.142543911933899\n",
      "      kl: 0.012573495507240295\n",
      "      policy_loss: -0.000744486867915839\n",
      "      total_loss: 328.5627746582031\n",
      "      vf_explained_var: 0.9724320769309998\n",
      "      vf_loss: 328.5633544921875\n",
      "    sample_time_ms: 18233.425\n",
      "    update_time_ms: 5.65\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 306.1832760638428\n",
      "  time_since_restore: 7589.406180381775\n",
      "  time_this_iter_s: 22.087243795394897\n",
      "  time_total_s: 7589.406180381775\n",
      "  timestamp: 1553716610\n",
      "  timesteps_since_restore: 2820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 282\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7589 s, 282 iter, 2820000 ts, 612 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-57-12\n",
      "  done: false\n",
      "  episode_len_mean: 135.11\n",
      "  episode_reward_max: 770.7262406384522\n",
      "  episode_reward_mean: 594.3867873180438\n",
      "  episode_reward_min: -125.46497493113803\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 20617\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.082\n",
      "    load_time_ms: 1.729\n",
      "    num_steps_sampled: 2830000\n",
      "    num_steps_trained: 2830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.013404252007603645\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1081756353378296\n",
      "      kl: 0.0407320000231266\n",
      "      policy_loss: -0.0009193009464070201\n",
      "      total_loss: 760.12939453125\n",
      "      vf_explained_var: 0.9420831203460693\n",
      "      vf_loss: 760.1298217773438\n",
      "    sample_time_ms: 18233.139\n",
      "    update_time_ms: 5.637\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 297.1933936590219\n",
      "  time_since_restore: 7611.903628349304\n",
      "  time_this_iter_s: 22.497447967529297\n",
      "  time_total_s: 7611.903628349304\n",
      "  timestamp: 1553716632\n",
      "  timesteps_since_restore: 2830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2830000\n",
      "  training_iteration: 283\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7611 s, 283 iter, 2830000 ts, 594 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-57-34\n",
      "  done: false\n",
      "  episode_len_mean: 138.99\n",
      "  episode_reward_max: 781.8564630631614\n",
      "  episode_reward_mean: 624.0072527984498\n",
      "  episode_reward_min: -116.87327022698926\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 20690\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.3\n",
      "    load_time_ms: 1.784\n",
      "    num_steps_sampled: 2840000\n",
      "    num_steps_trained: 2840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.020106378942728043\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1640955209732056\n",
      "      kl: 0.018113642930984497\n",
      "      policy_loss: -0.0021682102233171463\n",
      "      total_loss: 488.1161804199219\n",
      "      vf_explained_var: 0.9594303965568542\n",
      "      vf_loss: 488.11798095703125\n",
      "    sample_time_ms: 18218.788\n",
      "    update_time_ms: 5.555\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.0036263992248\n",
      "  time_since_restore: 7633.875293493271\n",
      "  time_this_iter_s: 21.971665143966675\n",
      "  time_total_s: 7633.875293493271\n",
      "  timestamp: 1553716654\n",
      "  timesteps_since_restore: 2840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2840000\n",
      "  training_iteration: 284\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7633 s, 284 iter, 2840000 ts, 624 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 138.95\n",
      "  episode_reward_max: 763.66288181045\n",
      "  episode_reward_mean: 624.9835016210042\n",
      "  episode_reward_min: -136.74713362496527\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 20763\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3788.148\n",
      "    load_time_ms: 1.8\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.020106378942728043\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1602858304977417\n",
      "      kl: 0.033117104321718216\n",
      "      policy_loss: 0.003646808909252286\n",
      "      total_loss: 390.6376953125\n",
      "      vf_explained_var: 0.9670407176017761\n",
      "      vf_loss: 390.63336181640625\n",
      "    sample_time_ms: 18292.07\n",
      "    update_time_ms: 5.538\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.49175081050214\n",
      "  time_since_restore: 7656.220887184143\n",
      "  time_this_iter_s: 22.345593690872192\n",
      "  time_total_s: 7656.220887184143\n",
      "  timestamp: 1553716677\n",
      "  timesteps_since_restore: 2850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 285\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7656 s, 285 iter, 2850000 ts, 625 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-58-20\n",
      "  done: false\n",
      "  episode_len_mean: 134.38\n",
      "  episode_reward_max: 755.5307948477734\n",
      "  episode_reward_mean: 591.4630962635255\n",
      "  episode_reward_min: -119.85570462618675\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 20838\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3787.659\n",
      "    load_time_ms: 1.767\n",
      "    num_steps_sampled: 2860000\n",
      "    num_steps_trained: 2860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.020106378942728043\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.093211054801941\n",
      "      kl: 0.06912800669670105\n",
      "      policy_loss: 0.004240372218191624\n",
      "      total_loss: 597.6254272460938\n",
      "      vf_explained_var: 0.9549345374107361\n",
      "      vf_loss: 597.6197509765625\n",
      "    sample_time_ms: 18384.58\n",
      "    update_time_ms: 5.326\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.7315481317627\n",
      "  time_since_restore: 7679.065736055374\n",
      "  time_this_iter_s: 22.84484887123108\n",
      "  time_total_s: 7679.065736055374\n",
      "  timestamp: 1553716700\n",
      "  timesteps_since_restore: 2860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2860000\n",
      "  training_iteration: 286\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7679 s, 286 iter, 2860000 ts, 591 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-58-42\n",
      "  done: false\n",
      "  episode_len_mean: 139.0\n",
      "  episode_reward_max: 767.5151841517977\n",
      "  episode_reward_mean: 622.4188775491803\n",
      "  episode_reward_min: -117.29208423790831\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 20912\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.67\n",
      "    load_time_ms: 1.761\n",
      "    num_steps_sampled: 2870000\n",
      "    num_steps_trained: 2870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.030159564688801765\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1721374988555908\n",
      "      kl: 0.009007304906845093\n",
      "      policy_loss: -0.002447043312713504\n",
      "      total_loss: 155.33566284179688\n",
      "      vf_explained_var: 0.9883947372436523\n",
      "      vf_loss: 155.3378448486328\n",
      "    sample_time_ms: 18389.437\n",
      "    update_time_ms: 5.107\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 311.2094387745902\n",
      "  time_since_restore: 7700.999564409256\n",
      "  time_this_iter_s: 21.933828353881836\n",
      "  time_total_s: 7700.999564409256\n",
      "  timestamp: 1553716722\n",
      "  timesteps_since_restore: 2870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2870000\n",
      "  training_iteration: 287\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7700 s, 287 iter, 2870000 ts, 622 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-59-04\n",
      "  done: false\n",
      "  episode_len_mean: 135.41\n",
      "  episode_reward_max: 767.9354784408534\n",
      "  episode_reward_mean: 591.3516389499295\n",
      "  episode_reward_min: -135.73011023177216\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 20987\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3781.946\n",
      "    load_time_ms: 1.756\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.015079782344400883\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1400896310806274\n",
      "      kl: 0.01934044435620308\n",
      "      policy_loss: -0.0049401274882256985\n",
      "      total_loss: 454.81060791015625\n",
      "      vf_explained_var: 0.9693435430526733\n",
      "      vf_loss: 454.8153076171875\n",
      "    sample_time_ms: 18465.584\n",
      "    update_time_ms: 5.104\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.6758194749647\n",
      "  time_since_restore: 7723.189479351044\n",
      "  time_this_iter_s: 22.18991494178772\n",
      "  time_total_s: 7723.189479351044\n",
      "  timestamp: 1553716744\n",
      "  timesteps_since_restore: 2880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 288\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7723 s, 288 iter, 2880000 ts, 591 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-59-26\n",
      "  done: false\n",
      "  episode_len_mean: 134.98\n",
      "  episode_reward_max: 756.7343657561363\n",
      "  episode_reward_mean: 589.1948479962257\n",
      "  episode_reward_min: -130.67880730697266\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 21063\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3789.634\n",
      "    load_time_ms: 1.709\n",
      "    num_steps_sampled: 2890000\n",
      "    num_steps_trained: 2890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.015079782344400883\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1584131717681885\n",
      "      kl: 0.012052306905388832\n",
      "      policy_loss: -0.0005074311629869044\n",
      "      total_loss: 550.4080810546875\n",
      "      vf_explained_var: 0.9580408930778503\n",
      "      vf_loss: 550.4083251953125\n",
      "    sample_time_ms: 18436.098\n",
      "    update_time_ms: 5.152\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 294.59742399811284\n",
      "  time_since_restore: 7745.490605592728\n",
      "  time_this_iter_s: 22.30112624168396\n",
      "  time_total_s: 7745.490605592728\n",
      "  timestamp: 1553716766\n",
      "  timesteps_since_restore: 2890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2890000\n",
      "  training_iteration: 289\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7745 s, 289 iter, 2890000 ts, 589 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_20-59-48\n",
      "  done: false\n",
      "  episode_len_mean: 136.84\n",
      "  episode_reward_max: 766.5817962975877\n",
      "  episode_reward_mean: 606.5919960720935\n",
      "  episode_reward_min: -134.90962739557523\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 21138\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3789.807\n",
      "    load_time_ms: 1.711\n",
      "    num_steps_sampled: 2900000\n",
      "    num_steps_trained: 2900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.015079782344400883\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1379644870758057\n",
      "      kl: 0.014432578347623348\n",
      "      policy_loss: -0.0006751121254637837\n",
      "      total_loss: 531.5171508789062\n",
      "      vf_explained_var: 0.9567102193832397\n",
      "      vf_loss: 531.5177001953125\n",
      "    sample_time_ms: 18420.119\n",
      "    update_time_ms: 5.216\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 303.29599803604674\n",
      "  time_since_restore: 7767.326169013977\n",
      "  time_this_iter_s: 21.83556342124939\n",
      "  time_total_s: 7767.326169013977\n",
      "  timestamp: 1553716788\n",
      "  timesteps_since_restore: 2900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2900000\n",
      "  training_iteration: 290\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7767 s, 290 iter, 2900000 ts, 607 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-00-11\n",
      "  done: false\n",
      "  episode_len_mean: 128.54\n",
      "  episode_reward_max: 770.651383255999\n",
      "  episode_reward_mean: 536.8081016662396\n",
      "  episode_reward_min: -108.40901950726835\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 21218\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3803.657\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.015079782344400883\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1377679109573364\n",
      "      kl: 0.0250515379011631\n",
      "      policy_loss: -0.00010330421355320141\n",
      "      total_loss: 1025.30810546875\n",
      "      vf_explained_var: 0.9305440187454224\n",
      "      vf_loss: 1025.307861328125\n",
      "    sample_time_ms: 18461.786\n",
      "    update_time_ms: 5.052\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 268.4040508331198\n",
      "  time_since_restore: 7790.2282502651215\n",
      "  time_this_iter_s: 22.90208125114441\n",
      "  time_total_s: 7790.2282502651215\n",
      "  timestamp: 1553716811\n",
      "  timesteps_since_restore: 2910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 291\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7790 s, 291 iter, 2910000 ts, 537 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-00-33\n",
      "  done: false\n",
      "  episode_len_mean: 136.39\n",
      "  episode_reward_max: 777.507505039257\n",
      "  episode_reward_mean: 603.287986577545\n",
      "  episode_reward_min: -126.82820955248032\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 21291\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.702\n",
      "    load_time_ms: 1.638\n",
      "    num_steps_sampled: 2920000\n",
      "    num_steps_trained: 2920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.015079782344400883\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1635072231292725\n",
      "      kl: 0.07682270556688309\n",
      "      policy_loss: 0.00505023542791605\n",
      "      total_loss: 605.6776123046875\n",
      "      vf_explained_var: 0.9514559507369995\n",
      "      vf_loss: 605.67138671875\n",
      "    sample_time_ms: 18428.875\n",
      "    update_time_ms: 4.94\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 301.6439932887725\n",
      "  time_since_restore: 7811.974021196365\n",
      "  time_this_iter_s: 21.745770931243896\n",
      "  time_total_s: 7811.974021196365\n",
      "  timestamp: 1553716833\n",
      "  timesteps_since_restore: 2920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2920000\n",
      "  training_iteration: 292\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7811 s, 292 iter, 2920000 ts, 603 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-00-55\n",
      "  done: false\n",
      "  episode_len_mean: 133.68\n",
      "  episode_reward_max: 762.0146199184812\n",
      "  episode_reward_mean: 583.5005128231281\n",
      "  episode_reward_min: -129.29262375666235\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 21368\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.18\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 2930000\n",
      "    num_steps_trained: 2930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02261967770755291\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.12992262840271\n",
      "      kl: 0.008383831940591335\n",
      "      policy_loss: -0.001275304821319878\n",
      "      total_loss: 289.9085998535156\n",
      "      vf_explained_var: 0.9779525995254517\n",
      "      vf_loss: 289.9096984863281\n",
      "    sample_time_ms: 18382.683\n",
      "    update_time_ms: 4.963\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 291.75025641156407\n",
      "  time_since_restore: 7834.002927541733\n",
      "  time_this_iter_s: 22.02890634536743\n",
      "  time_total_s: 7834.002927541733\n",
      "  timestamp: 1553716855\n",
      "  timesteps_since_restore: 2930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2930000\n",
      "  training_iteration: 293\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7834 s, 293 iter, 2930000 ts, 584 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-01-18\n",
      "  done: false\n",
      "  episode_len_mean: 137.71\n",
      "  episode_reward_max: 766.4910558581589\n",
      "  episode_reward_mean: 608.4113952835834\n",
      "  episode_reward_min: -97.08143534223281\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 21441\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3803.342\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011309838853776455\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.174194097518921\n",
      "      kl: 0.009972293861210346\n",
      "      policy_loss: -0.00029015541076660156\n",
      "      total_loss: 502.5847473144531\n",
      "      vf_explained_var: 0.9599824547767639\n",
      "      vf_loss: 502.58489990234375\n",
      "    sample_time_ms: 18459.032\n",
      "    update_time_ms: 5.016\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 304.2056976417917\n",
      "  time_since_restore: 7856.752475500107\n",
      "  time_this_iter_s: 22.749547958374023\n",
      "  time_total_s: 7856.752475500107\n",
      "  timestamp: 1553716878\n",
      "  timesteps_since_restore: 2940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 294\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7856 s, 294 iter, 2940000 ts, 608 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-01-41\n",
      "  done: false\n",
      "  episode_len_mean: 133.57\n",
      "  episode_reward_max: 762.224104670476\n",
      "  episode_reward_mean: 580.0011869559984\n",
      "  episode_reward_min: -108.97838362217414\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 21518\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.907\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 2950000\n",
      "    num_steps_trained: 2950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0056549194268882275\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1249386072158813\n",
      "      kl: 0.0195637084543705\n",
      "      policy_loss: -7.42280317354016e-05\n",
      "      total_loss: 1012.5911254882812\n",
      "      vf_explained_var: 0.922549307346344\n",
      "      vf_loss: 1012.591064453125\n",
      "    sample_time_ms: 18520.186\n",
      "    update_time_ms: 5.029\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.00059347799913\n",
      "  time_since_restore: 7879.836685657501\n",
      "  time_this_iter_s: 23.08421015739441\n",
      "  time_total_s: 7879.836685657501\n",
      "  timestamp: 1553716901\n",
      "  timesteps_since_restore: 2950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2950000\n",
      "  training_iteration: 295\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7879 s, 295 iter, 2950000 ts, 580 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-02-04\n",
      "  done: false\n",
      "  episode_len_mean: 137.15\n",
      "  episode_reward_max: 768.7819952441965\n",
      "  episode_reward_mean: 613.487923453666\n",
      "  episode_reward_min: -121.28443417290167\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 21592\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3816.299\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 2960000\n",
      "    num_steps_trained: 2960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0056549194268882275\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1309930086135864\n",
      "      kl: 0.018781889230012894\n",
      "      policy_loss: -0.0014963016146793962\n",
      "      total_loss: 808.2854614257812\n",
      "      vf_explained_var: 0.9336960911750793\n",
      "      vf_loss: 808.2869873046875\n",
      "    sample_time_ms: 18524.075\n",
      "    update_time_ms: 5.165\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 306.74396172683294\n",
      "  time_since_restore: 7902.726530075073\n",
      "  time_this_iter_s: 22.88984441757202\n",
      "  time_total_s: 7902.726530075073\n",
      "  timestamp: 1553716924\n",
      "  timesteps_since_restore: 2960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2960000\n",
      "  training_iteration: 296\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7902 s, 296 iter, 2960000 ts, 613 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-02-26\n",
      "  done: false\n",
      "  episode_len_mean: 137.92\n",
      "  episode_reward_max: 782.2854368546147\n",
      "  episode_reward_mean: 622.4816383884998\n",
      "  episode_reward_min: -117.316912098533\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 21666\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3816.0\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0056549194268882275\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1869841814041138\n",
      "      kl: 0.021419163793325424\n",
      "      policy_loss: -0.0025040151085704565\n",
      "      total_loss: 676.2749633789062\n",
      "      vf_explained_var: 0.9490929841995239\n",
      "      vf_loss: 676.27734375\n",
      "    sample_time_ms: 18589.415\n",
      "    update_time_ms: 5.378\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 311.24081919425\n",
      "  time_since_restore: 7925.313457250595\n",
      "  time_this_iter_s: 22.58692717552185\n",
      "  time_total_s: 7925.313457250595\n",
      "  timestamp: 1553716946\n",
      "  timesteps_since_restore: 2970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 297\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7925 s, 297 iter, 2970000 ts, 622 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-02-49\n",
      "  done: false\n",
      "  episode_len_mean: 126.79\n",
      "  episode_reward_max: 763.7387472132816\n",
      "  episode_reward_mean: 520.0977281938754\n",
      "  episode_reward_min: -134.46689145266228\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 21746\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3821.049\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 2980000\n",
      "    num_steps_trained: 2980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0056549194268882275\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1291582584381104\n",
      "      kl: 0.009628130123019218\n",
      "      policy_loss: -0.0010217329254373908\n",
      "      total_loss: 648.9481201171875\n",
      "      vf_explained_var: 0.9587996006011963\n",
      "      vf_loss: 648.9490966796875\n",
      "    sample_time_ms: 18628.328\n",
      "    update_time_ms: 5.347\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 260.0488640969376\n",
      "  time_since_restore: 7947.941060781479\n",
      "  time_this_iter_s: 22.62760353088379\n",
      "  time_total_s: 7947.941060781479\n",
      "  timestamp: 1553716969\n",
      "  timesteps_since_restore: 2980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2980000\n",
      "  training_iteration: 298\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7947 s, 298 iter, 2980000 ts, 520 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-03-12\n",
      "  done: false\n",
      "  episode_len_mean: 132.69\n",
      "  episode_reward_max: 770.3408956314659\n",
      "  episode_reward_mean: 581.6356134735677\n",
      "  episode_reward_min: -130.50637537431663\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 21823\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3820.07\n",
      "    load_time_ms: 1.435\n",
      "    num_steps_sampled: 2990000\n",
      "    num_steps_trained: 2990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1122528314590454\n",
      "      kl: 0.018082188442349434\n",
      "      policy_loss: 0.0015038897981867194\n",
      "      total_loss: 572.3800048828125\n",
      "      vf_explained_var: 0.9601887464523315\n",
      "      vf_loss: 572.37841796875\n",
      "    sample_time_ms: 18695.967\n",
      "    update_time_ms: 5.253\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 290.81780673678384\n",
      "  time_since_restore: 7970.905295848846\n",
      "  time_this_iter_s: 22.964235067367554\n",
      "  time_total_s: 7970.905295848846\n",
      "  timestamp: 1553716992\n",
      "  timesteps_since_restore: 2990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2990000\n",
      "  training_iteration: 299\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7970 s, 299 iter, 2990000 ts, 582 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-03-34\n",
      "  done: false\n",
      "  episode_len_mean: 137.25\n",
      "  episode_reward_max: 773.2232628535214\n",
      "  episode_reward_mean: 606.7951844804943\n",
      "  episode_reward_min: -126.43645481605819\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 21898\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3820.932\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1662088632583618\n",
      "      kl: 0.011445884592831135\n",
      "      policy_loss: -0.0005624479381367564\n",
      "      total_loss: 755.6586303710938\n",
      "      vf_explained_var: 0.9428808689117432\n",
      "      vf_loss: 755.6591186523438\n",
      "    sample_time_ms: 18741.748\n",
      "    update_time_ms: 5.253\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 303.39759224024715\n",
      "  time_since_restore: 7993.208770036697\n",
      "  time_this_iter_s: 22.303474187850952\n",
      "  time_total_s: 7993.208770036697\n",
      "  timestamp: 1553717014\n",
      "  timesteps_since_restore: 3000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 300\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 7993 s, 300 iter, 3000000 ts, 607 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-03-57\n",
      "  done: false\n",
      "  episode_len_mean: 137.83\n",
      "  episode_reward_max: 786.8303660037014\n",
      "  episode_reward_mean: 617.0880555903568\n",
      "  episode_reward_min: -106.16300434363605\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 21972\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3804.719\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 3010000\n",
      "    num_steps_trained: 3010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1241636276245117\n",
      "      kl: 0.01050847303122282\n",
      "      policy_loss: -0.00036879992694593966\n",
      "      total_loss: 247.6826171875\n",
      "      vf_explained_var: 0.9819615483283997\n",
      "      vf_loss: 247.6829376220703\n",
      "    sample_time_ms: 18736.7\n",
      "    update_time_ms: 5.37\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 308.54402779517835\n",
      "  time_since_restore: 8015.899831533432\n",
      "  time_this_iter_s: 22.69106149673462\n",
      "  time_total_s: 8015.899831533432\n",
      "  timestamp: 1553717037\n",
      "  timesteps_since_restore: 3010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3010000\n",
      "  training_iteration: 301\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8015 s, 301 iter, 3010000 ts, 617 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 135.44\n",
      "  episode_reward_max: 764.7917703699509\n",
      "  episode_reward_mean: 607.4188222291691\n",
      "  episode_reward_min: -124.25695003193215\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 22047\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3803.1\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 3020000\n",
      "    num_steps_trained: 3020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1197845935821533\n",
      "      kl: 0.024005845189094543\n",
      "      policy_loss: -0.0012249067658558488\n",
      "      total_loss: 532.59912109375\n",
      "      vf_explained_var: 0.9601008296012878\n",
      "      vf_loss: 532.6002807617188\n",
      "    sample_time_ms: 18788.134\n",
      "    update_time_ms: 5.501\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 303.70941111458455\n",
      "  time_since_restore: 8038.146456956863\n",
      "  time_this_iter_s: 22.246625423431396\n",
      "  time_total_s: 8038.146456956863\n",
      "  timestamp: 1553717059\n",
      "  timesteps_since_restore: 3020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3020000\n",
      "  training_iteration: 302\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8038 s, 302 iter, 3020000 ts, 607 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-04-42\n",
      "  done: false\n",
      "  episode_len_mean: 134.88\n",
      "  episode_reward_max: 766.0710436140788\n",
      "  episode_reward_mean: 605.0722398908342\n",
      "  episode_reward_min: -123.92636243423591\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 22121\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3805.064\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 3030000\n",
      "    num_steps_trained: 3030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0952187776565552\n",
      "      kl: 0.021769355982542038\n",
      "      policy_loss: -0.0013310041977092624\n",
      "      total_loss: 333.4216613769531\n",
      "      vf_explained_var: 0.9737153649330139\n",
      "      vf_loss: 333.42291259765625\n",
      "    sample_time_ms: 18831.595\n",
      "    update_time_ms: 5.593\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.53611994541717\n",
      "  time_since_restore: 8060.630127668381\n",
      "  time_this_iter_s: 22.483670711517334\n",
      "  time_total_s: 8060.630127668381\n",
      "  timestamp: 1553717082\n",
      "  timesteps_since_restore: 3030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3030000\n",
      "  training_iteration: 303\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8060 s, 303 iter, 3030000 ts, 605 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-05-04\n",
      "  done: false\n",
      "  episode_len_mean: 139.25\n",
      "  episode_reward_max: 775.7897390496007\n",
      "  episode_reward_mean: 633.9959883125152\n",
      "  episode_reward_min: -110.84896960991685\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 22195\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3806.506\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 3040000\n",
      "    num_steps_trained: 3040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1299798488616943\n",
      "      kl: 0.01959669031202793\n",
      "      policy_loss: -0.002232830971479416\n",
      "      total_loss: 514.454833984375\n",
      "      vf_explained_var: 0.960216224193573\n",
      "      vf_loss: 514.4569091796875\n",
      "    sample_time_ms: 18778.534\n",
      "    update_time_ms: 5.507\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.9979941562576\n",
      "  time_since_restore: 8082.860607624054\n",
      "  time_this_iter_s: 22.230479955673218\n",
      "  time_total_s: 8082.860607624054\n",
      "  timestamp: 1553717104\n",
      "  timesteps_since_restore: 3040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3040000\n",
      "  training_iteration: 304\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8082 s, 304 iter, 3040000 ts, 634 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-05-27\n",
      "  done: false\n",
      "  episode_len_mean: 139.81\n",
      "  episode_reward_max: 780.3537926336444\n",
      "  episode_reward_mean: 635.1523486896173\n",
      "  episode_reward_min: -121.79956928103579\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 22266\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3791.855\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 3050000\n",
      "    num_steps_trained: 3050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1262320280075073\n",
      "      kl: 0.0114901689812541\n",
      "      policy_loss: 0.00015952590911183506\n",
      "      total_loss: 91.3792724609375\n",
      "      vf_explained_var: 0.992588222026825\n",
      "      vf_loss: 91.37908172607422\n",
      "    sample_time_ms: 18724.46\n",
      "    update_time_ms: 5.62\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 317.57617434480875\n",
      "  time_since_restore: 8105.2571721076965\n",
      "  time_this_iter_s: 22.396564483642578\n",
      "  time_total_s: 8105.2571721076965\n",
      "  timestamp: 1553717127\n",
      "  timesteps_since_restore: 3050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3050000\n",
      "  training_iteration: 305\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8105 s, 305 iter, 3050000 ts, 635 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-05-49\n",
      "  done: false\n",
      "  episode_len_mean: 140.23\n",
      "  episode_reward_max: 760.3667787514197\n",
      "  episode_reward_mean: 641.43102100648\n",
      "  episode_reward_min: -127.6814561449629\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 22339\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.647\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 3060000\n",
      "    num_steps_trained: 3060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0826040506362915\n",
      "      kl: 0.013681924901902676\n",
      "      policy_loss: 0.00013073018635623157\n",
      "      total_loss: 296.37255859375\n",
      "      vf_explained_var: 0.9768427610397339\n",
      "      vf_loss: 296.3723449707031\n",
      "    sample_time_ms: 18629.231\n",
      "    update_time_ms: 5.541\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.71551050324007\n",
      "  time_since_restore: 8127.181679487228\n",
      "  time_this_iter_s: 21.92450737953186\n",
      "  time_total_s: 8127.181679487228\n",
      "  timestamp: 1553717149\n",
      "  timesteps_since_restore: 3060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3060000\n",
      "  training_iteration: 306\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8127 s, 306 iter, 3060000 ts, 641 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-06-11\n",
      "  done: false\n",
      "  episode_len_mean: 139.2\n",
      "  episode_reward_max: 762.088944663777\n",
      "  episode_reward_mean: 644.6026300301902\n",
      "  episode_reward_min: -136.22169337012855\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 22411\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3803.192\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 3070000\n",
      "    num_steps_trained: 3070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0399715900421143\n",
      "      kl: 0.0244296882301569\n",
      "      policy_loss: -0.002261985559016466\n",
      "      total_loss: 221.10549926757812\n",
      "      vf_explained_var: 0.9817804098129272\n",
      "      vf_loss: 221.107666015625\n",
      "    sample_time_ms: 18604.833\n",
      "    update_time_ms: 5.269\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 322.30131501509516\n",
      "  time_since_restore: 8149.646844148636\n",
      "  time_this_iter_s: 22.46516466140747\n",
      "  time_total_s: 8149.646844148636\n",
      "  timestamp: 1553717171\n",
      "  timesteps_since_restore: 3070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3070000\n",
      "  training_iteration: 307\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8149 s, 307 iter, 3070000 ts, 645 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-06-34\n",
      "  done: false\n",
      "  episode_len_mean: 137.65\n",
      "  episode_reward_max: 762.088944663777\n",
      "  episode_reward_mean: 630.3194966689997\n",
      "  episode_reward_min: -124.1856510096329\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 22485\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3820.77\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 3080000\n",
      "    num_steps_trained: 3080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0321688652038574\n",
      "      kl: 0.014226949773728848\n",
      "      policy_loss: 0.0004694515373557806\n",
      "      total_loss: 143.54913330078125\n",
      "      vf_explained_var: 0.9884412884712219\n",
      "      vf_loss: 143.5486297607422\n",
      "    sample_time_ms: 18602.543\n",
      "    update_time_ms: 5.382\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 315.1597483344999\n",
      "  time_since_restore: 8172.4282829761505\n",
      "  time_this_iter_s: 22.78143882751465\n",
      "  time_total_s: 8172.4282829761505\n",
      "  timestamp: 1553717194\n",
      "  timesteps_since_restore: 3080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3080000\n",
      "  training_iteration: 308\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8172 s, 308 iter, 3080000 ts, 630 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-06-58\n",
      "  done: false\n",
      "  episode_len_mean: 136.66\n",
      "  episode_reward_max: 789.240048631246\n",
      "  episode_reward_mean: 625.0838214494834\n",
      "  episode_reward_min: -113.29800870512385\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 22559\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3852.185\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 3090000\n",
      "    num_steps_trained: 3090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0142673254013062\n",
      "      kl: 0.01163262315094471\n",
      "      policy_loss: -0.0016805273480713367\n",
      "      total_loss: 762.46875\n",
      "      vf_explained_var: 0.9400190711021423\n",
      "      vf_loss: 762.470458984375\n",
      "    sample_time_ms: 18704.333\n",
      "    update_time_ms: 5.356\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.5419107247417\n",
      "  time_since_restore: 8196.723608970642\n",
      "  time_this_iter_s: 24.295325994491577\n",
      "  time_total_s: 8196.723608970642\n",
      "  timestamp: 1553717218\n",
      "  timesteps_since_restore: 3090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3090000\n",
      "  training_iteration: 309\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8196 s, 309 iter, 3090000 ts, 625 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-07-25\n",
      "  done: false\n",
      "  episode_len_mean: 138.27\n",
      "  episode_reward_max: 766.9564137277886\n",
      "  episode_reward_mean: 633.1573205855661\n",
      "  episode_reward_min: -110.7145918080047\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 22632\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3942.375\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 3100000\n",
      "    num_steps_trained: 3100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0515912771224976\n",
      "      kl: 0.017583398148417473\n",
      "      policy_loss: -0.0018339019734412432\n",
      "      total_loss: 433.0985107421875\n",
      "      vf_explained_var: 0.9653071165084839\n",
      "      vf_loss: 433.1002502441406\n",
      "    sample_time_ms: 19024.666\n",
      "    update_time_ms: 5.437\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.57866029278307\n",
      "  time_since_restore: 8223.129422187805\n",
      "  time_this_iter_s: 26.405813217163086\n",
      "  time_total_s: 8223.129422187805\n",
      "  timestamp: 1553717245\n",
      "  timesteps_since_restore: 3100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3100000\n",
      "  training_iteration: 310\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8223 s, 310 iter, 3100000 ts, 633 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-07-50\n",
      "  done: false\n",
      "  episode_len_mean: 130.69\n",
      "  episode_reward_max: 754.1313858866426\n",
      "  episode_reward_mean: 574.5047257936046\n",
      "  episode_reward_min: -135.56941218291075\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 22710\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3982.56\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 3110000\n",
      "    num_steps_trained: 3110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9717947244644165\n",
      "      kl: 0.022883061319589615\n",
      "      policy_loss: 0.0007404289790429175\n",
      "      total_loss: 972.7427978515625\n",
      "      vf_explained_var: 0.9316421747207642\n",
      "      vf_loss: 972.7420043945312\n",
      "    sample_time_ms: 19282.439\n",
      "    update_time_ms: 5.473\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 287.25236289680225\n",
      "  time_since_restore: 8248.801891565323\n",
      "  time_this_iter_s: 25.6724693775177\n",
      "  time_total_s: 8248.801891565323\n",
      "  timestamp: 1553717270\n",
      "  timesteps_since_restore: 3110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3110000\n",
      "  training_iteration: 311\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8248 s, 311 iter, 3110000 ts, 575 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-08-15\n",
      "  done: false\n",
      "  episode_len_mean: 136.86\n",
      "  episode_reward_max: 777.1766213846345\n",
      "  episode_reward_mean: 626.2712523277404\n",
      "  episode_reward_min: -127.4332746631469\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 22785\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3985.152\n",
      "    load_time_ms: 1.402\n",
      "    num_steps_sampled: 3120000\n",
      "    num_steps_trained: 3120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0028274597134441137\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0205330848693848\n",
      "      kl: 0.049906808882951736\n",
      "      policy_loss: -0.0010274481028318405\n",
      "      total_loss: 632.8272094726562\n",
      "      vf_explained_var: 0.9520478844642639\n",
      "      vf_loss: 632.8280029296875\n",
      "    sample_time_ms: 19538.615\n",
      "    update_time_ms: 5.503\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.1356261638702\n",
      "  time_since_restore: 8273.635570764542\n",
      "  time_this_iter_s: 24.83367919921875\n",
      "  time_total_s: 8273.635570764542\n",
      "  timestamp: 1553717295\n",
      "  timesteps_since_restore: 3120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3120000\n",
      "  training_iteration: 312\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8273 s, 312 iter, 3120000 ts, 626 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 133.06\n",
      "  episode_reward_max: 779.634176272206\n",
      "  episode_reward_mean: 598.123018591097\n",
      "  episode_reward_min: -124.4356049107115\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 22862\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4039.711\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 3130000\n",
      "    num_steps_trained: 3130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0245157480239868\n",
      "      kl: 0.02179154008626938\n",
      "      policy_loss: -0.001388353412039578\n",
      "      total_loss: 733.6453857421875\n",
      "      vf_explained_var: 0.9433891177177429\n",
      "      vf_loss: 733.6466674804688\n",
      "    sample_time_ms: 19772.291\n",
      "    update_time_ms: 5.451\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 299.0615092955485\n",
      "  time_since_restore: 8299.002806425095\n",
      "  time_this_iter_s: 25.36723566055298\n",
      "  time_total_s: 8299.002806425095\n",
      "  timestamp: 1553717321\n",
      "  timesteps_since_restore: 3130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3130000\n",
      "  training_iteration: 313\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8299 s, 313 iter, 3130000 ts, 598 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-09-08\n",
      "  done: false\n",
      "  episode_len_mean: 130.93\n",
      "  episode_reward_max: 767.79558180049\n",
      "  episode_reward_mean: 574.7804001542585\n",
      "  episode_reward_min: -124.36090933494685\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 22940\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4074.852\n",
      "    load_time_ms: 1.441\n",
      "    num_steps_sampled: 3140000\n",
      "    num_steps_trained: 3140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0035427808761597\n",
      "      kl: 0.01603560894727707\n",
      "      policy_loss: -0.0006707124412059784\n",
      "      total_loss: 166.12216186523438\n",
      "      vf_explained_var: 0.9885445833206177\n",
      "      vf_loss: 166.12274169921875\n",
      "    sample_time_ms: 20256.236\n",
      "    update_time_ms: 5.542\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 287.3902000771292\n",
      "  time_since_restore: 8326.426508188248\n",
      "  time_this_iter_s: 27.423701763153076\n",
      "  time_total_s: 8326.426508188248\n",
      "  timestamp: 1553717348\n",
      "  timesteps_since_restore: 3140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3140000\n",
      "  training_iteration: 314\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8326 s, 314 iter, 3140000 ts, 575 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-09-34\n",
      "  done: false\n",
      "  episode_len_mean: 134.21\n",
      "  episode_reward_max: 769.0947214133633\n",
      "  episode_reward_mean: 605.0776820341648\n",
      "  episode_reward_min: -127.98452091231849\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 23015\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4105.996\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 3150000\n",
      "    num_steps_trained: 3150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0074732303619385\n",
      "      kl: 0.020513257011771202\n",
      "      policy_loss: 0.0009214764577336609\n",
      "      total_loss: 162.6837921142578\n",
      "      vf_explained_var: 0.9880255460739136\n",
      "      vf_loss: 162.6827850341797\n",
      "    sample_time_ms: 20567.474\n",
      "    update_time_ms: 5.507\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.53884101708246\n",
      "  time_since_restore: 8352.24812912941\n",
      "  time_this_iter_s: 25.82162094116211\n",
      "  time_total_s: 8352.24812912941\n",
      "  timestamp: 1553717374\n",
      "  timesteps_since_restore: 3150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3150000\n",
      "  training_iteration: 315\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8352 s, 315 iter, 3150000 ts, 605 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-10-02\n",
      "  done: false\n",
      "  episode_len_mean: 131.74\n",
      "  episode_reward_max: 768.4322776912437\n",
      "  episode_reward_mean: 583.242509221006\n",
      "  episode_reward_min: -131.95139528655545\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 23094\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4141.944\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 3160000\n",
      "    num_steps_trained: 3160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0183281898498535\n",
      "      kl: 0.01693890430033207\n",
      "      policy_loss: -0.0011162915034219623\n",
      "      total_loss: 298.4625549316406\n",
      "      vf_explained_var: 0.9802312850952148\n",
      "      vf_loss: 298.4635925292969\n",
      "    sample_time_ms: 21128.757\n",
      "    update_time_ms: 5.511\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 291.621254610503\n",
      "  time_since_restore: 8380.147096395493\n",
      "  time_this_iter_s: 27.898967266082764\n",
      "  time_total_s: 8380.147096395493\n",
      "  timestamp: 1553717402\n",
      "  timesteps_since_restore: 3160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3160000\n",
      "  training_iteration: 316\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8380 s, 316 iter, 3160000 ts, 583 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-10-29\n",
      "  done: false\n",
      "  episode_len_mean: 134.51\n",
      "  episode_reward_max: 764.6491106993667\n",
      "  episode_reward_mean: 604.1944044997707\n",
      "  episode_reward_min: -118.85946469077194\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 23168\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4179.311\n",
      "    load_time_ms: 1.473\n",
      "    num_steps_sampled: 3170000\n",
      "    num_steps_trained: 3170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.009059190750122\n",
      "      kl: 0.020509276539087296\n",
      "      policy_loss: -0.0010362562024965882\n",
      "      total_loss: 1284.4427490234375\n",
      "      vf_explained_var: 0.8933349251747131\n",
      "      vf_loss: 1284.44384765625\n",
      "    sample_time_ms: 21588.443\n",
      "    update_time_ms: 5.549\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.09720224988536\n",
      "  time_since_restore: 8407.591576337814\n",
      "  time_this_iter_s: 27.444479942321777\n",
      "  time_total_s: 8407.591576337814\n",
      "  timestamp: 1553717429\n",
      "  timesteps_since_restore: 3170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3170000\n",
      "  training_iteration: 317\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8407 s, 317 iter, 3170000 ts, 604 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-10-58\n",
      "  done: false\n",
      "  episode_len_mean: 134.53\n",
      "  episode_reward_max: 793.2513635771586\n",
      "  episode_reward_mean: 607.3541620525085\n",
      "  episode_reward_min: -127.88697371042733\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 23243\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4165.388\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 3180000\n",
      "    num_steps_trained: 3180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9910720586776733\n",
      "      kl: 0.032321058213710785\n",
      "      policy_loss: 0.002809777157381177\n",
      "      total_loss: 286.16754150390625\n",
      "      vf_explained_var: 0.9783037900924683\n",
      "      vf_loss: 286.16461181640625\n",
      "    sample_time_ms: 22169.217\n",
      "    update_time_ms: 5.554\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 303.67708102625426\n",
      "  time_since_restore: 8436.043184995651\n",
      "  time_this_iter_s: 28.451608657836914\n",
      "  time_total_s: 8436.043184995651\n",
      "  timestamp: 1553717458\n",
      "  timesteps_since_restore: 3180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3180000\n",
      "  training_iteration: 318\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8436 s, 318 iter, 3180000 ts, 607 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-11-21\n",
      "  done: false\n",
      "  episode_len_mean: 135.58\n",
      "  episode_reward_max: 782.5070699054409\n",
      "  episode_reward_mean: 618.9500588936996\n",
      "  episode_reward_min: -104.27085919680728\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 23318\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4141.108\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 3190000\n",
      "    num_steps_trained: 3190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.987153172492981\n",
      "      kl: 0.021816512569785118\n",
      "      policy_loss: -0.0014705187641084194\n",
      "      total_loss: 1042.279296875\n",
      "      vf_explained_var: 0.9104366898536682\n",
      "      vf_loss: 1042.2806396484375\n",
      "    sample_time_ms: 22022.862\n",
      "    update_time_ms: 5.831\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 309.4750294468499\n",
      "  time_since_restore: 8458.63638830185\n",
      "  time_this_iter_s: 22.59320330619812\n",
      "  time_total_s: 8458.63638830185\n",
      "  timestamp: 1553717481\n",
      "  timesteps_since_restore: 3190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3190000\n",
      "  training_iteration: 319\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8458 s, 319 iter, 3190000 ts, 619 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-11-44\n",
      "  done: false\n",
      "  episode_len_mean: 138.51\n",
      "  episode_reward_max: 765.9916927650644\n",
      "  episode_reward_mean: 639.2317782583597\n",
      "  episode_reward_min: -124.04301656315195\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 23391\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4076.204\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 3200000\n",
      "    num_steps_trained: 3200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0384197235107422\n",
      "      kl: 0.028033999726176262\n",
      "      policy_loss: -0.005163427442312241\n",
      "      total_loss: 425.107666015625\n",
      "      vf_explained_var: 0.9653934836387634\n",
      "      vf_loss: 425.11273193359375\n",
      "    sample_time_ms: 21803.473\n",
      "    update_time_ms: 5.744\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 319.6158891291799\n",
      "  time_since_restore: 8482.200908899307\n",
      "  time_this_iter_s: 23.564520597457886\n",
      "  time_total_s: 8482.200908899307\n",
      "  timestamp: 1553717504\n",
      "  timesteps_since_restore: 3200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3200000\n",
      "  training_iteration: 320\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8482 s, 320 iter, 3200000 ts, 639 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-12-08\n",
      "  done: false\n",
      "  episode_len_mean: 136.98\n",
      "  episode_reward_max: 781.9338301203114\n",
      "  episode_reward_mean: 632.5142601640737\n",
      "  episode_reward_min: -123.5654935792258\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 23465\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4048.896\n",
      "    load_time_ms: 1.641\n",
      "    num_steps_sampled: 3210000\n",
      "    num_steps_trained: 3210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0234718322753906\n",
      "      kl: 0.016793493181467056\n",
      "      policy_loss: -0.005486279726028442\n",
      "      total_loss: 199.0384063720703\n",
      "      vf_explained_var: 0.9876018166542053\n",
      "      vf_loss: 199.0438232421875\n",
      "    sample_time_ms: 21647.381\n",
      "    update_time_ms: 5.625\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.2571300820367\n",
      "  time_since_restore: 8506.038612365723\n",
      "  time_this_iter_s: 23.837703466415405\n",
      "  time_total_s: 8506.038612365723\n",
      "  timestamp: 1553717528\n",
      "  timesteps_since_restore: 3210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3210000\n",
      "  training_iteration: 321\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8506 s, 321 iter, 3210000 ts, 633 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-12-31\n",
      "  done: false\n",
      "  episode_len_mean: 138.51\n",
      "  episode_reward_max: 779.1366972353057\n",
      "  episode_reward_mean: 640.5837839197392\n",
      "  episode_reward_min: -126.32403145923769\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 23538\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4057.716\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 3220000\n",
      "    num_steps_trained: 3220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0354187488555908\n",
      "      kl: 0.021160079166293144\n",
      "      policy_loss: -0.0005868346779607236\n",
      "      total_loss: 416.9678649902344\n",
      "      vf_explained_var: 0.9665435552597046\n",
      "      vf_loss: 416.9684143066406\n",
      "    sample_time_ms: 21478.275\n",
      "    update_time_ms: 5.529\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.29189195986953\n",
      "  time_since_restore: 8529.269883394241\n",
      "  time_this_iter_s: 23.231271028518677\n",
      "  time_total_s: 8529.269883394241\n",
      "  timestamp: 1553717551\n",
      "  timesteps_since_restore: 3220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3220000\n",
      "  training_iteration: 322\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8529 s, 322 iter, 3220000 ts, 641 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-12-55\n",
      "  done: false\n",
      "  episode_len_mean: 139.87\n",
      "  episode_reward_max: 770.5593093728914\n",
      "  episode_reward_mean: 647.7430789611768\n",
      "  episode_reward_min: -92.66716784697317\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 23610\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4026.531\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 3230000\n",
      "    num_steps_trained: 3230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.028810977935791\n",
      "      kl: 0.01466927770525217\n",
      "      policy_loss: -0.004259434994310141\n",
      "      total_loss: 535.5929565429688\n",
      "      vf_explained_var: 0.9537222385406494\n",
      "      vf_loss: 535.5971069335938\n",
      "    sample_time_ms: 21360.554\n",
      "    update_time_ms: 5.477\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 323.8715394805884\n",
      "  time_since_restore: 8553.146743059158\n",
      "  time_this_iter_s: 23.876859664916992\n",
      "  time_total_s: 8553.146743059158\n",
      "  timestamp: 1553717575\n",
      "  timesteps_since_restore: 3230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3230000\n",
      "  training_iteration: 323\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8553 s, 323 iter, 3230000 ts, 648 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-13-24\n",
      "  done: false\n",
      "  episode_len_mean: 134.68\n",
      "  episode_reward_max: 768.6469512441772\n",
      "  episode_reward_mean: 609.2073801629765\n",
      "  episode_reward_min: -130.64940162656853\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 23686\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4154.614\n",
      "    load_time_ms: 1.646\n",
      "    num_steps_sampled: 3240000\n",
      "    num_steps_trained: 3240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.021798849105835\n",
      "      kl: 0.0263038482517004\n",
      "      policy_loss: -0.001378594315610826\n",
      "      total_loss: 869.7620239257812\n",
      "      vf_explained_var: 0.9331867694854736\n",
      "      vf_loss: 869.763427734375\n",
      "    sample_time_ms: 21395.127\n",
      "    update_time_ms: 5.421\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 304.60369008148825\n",
      "  time_since_restore: 8582.199712276459\n",
      "  time_this_iter_s: 29.052969217300415\n",
      "  time_total_s: 8582.199712276459\n",
      "  timestamp: 1553717604\n",
      "  timesteps_since_restore: 3240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3240000\n",
      "  training_iteration: 324\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8582 s, 324 iter, 3240000 ts, 609 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-13-52\n",
      "  done: false\n",
      "  episode_len_mean: 139.17\n",
      "  episode_reward_max: 777.7516330995848\n",
      "  episode_reward_mean: 641.1004122714822\n",
      "  episode_reward_min: -102.85599892575458\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 23757\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4177.901\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 3250000\n",
      "    num_steps_trained: 3250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.029346227645874\n",
      "      kl: 0.029091626405715942\n",
      "      policy_loss: -0.005750901065766811\n",
      "      total_loss: 502.03094482421875\n",
      "      vf_explained_var: 0.9559425711631775\n",
      "      vf_loss: 502.03656005859375\n",
      "    sample_time_ms: 21522.118\n",
      "    update_time_ms: 5.346\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.5502061357411\n",
      "  time_since_restore: 8609.522777557373\n",
      "  time_this_iter_s: 27.323065280914307\n",
      "  time_total_s: 8609.522777557373\n",
      "  timestamp: 1553717632\n",
      "  timesteps_since_restore: 3250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3250000\n",
      "  training_iteration: 325\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8609 s, 325 iter, 3250000 ts, 641 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-14-18\n",
      "  done: false\n",
      "  episode_len_mean: 136.27\n",
      "  episode_reward_max: 778.1108414462728\n",
      "  episode_reward_mean: 613.961520454553\n",
      "  episode_reward_min: -137.9641886742892\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 23832\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4154.557\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 3260000\n",
      "    num_steps_trained: 3260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0307888984680176\n",
      "      kl: 0.015766248106956482\n",
      "      policy_loss: 6.57007476547733e-05\n",
      "      total_loss: 759.6312255859375\n",
      "      vf_explained_var: 0.9378545880317688\n",
      "      vf_loss: 759.6309814453125\n",
      "    sample_time_ms: 21407.694\n",
      "    update_time_ms: 5.357\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 306.9807602272765\n",
      "  time_since_restore: 8636.046236515045\n",
      "  time_this_iter_s: 26.52345895767212\n",
      "  time_total_s: 8636.046236515045\n",
      "  timestamp: 1553717658\n",
      "  timesteps_since_restore: 3260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3260000\n",
      "  training_iteration: 326\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8636 s, 326 iter, 3260000 ts, 614 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-14-46\n",
      "  done: false\n",
      "  episode_len_mean: 137.87\n",
      "  episode_reward_max: 768.0427018191803\n",
      "  episode_reward_mean: 626.8509757931857\n",
      "  episode_reward_min: -129.89351335539288\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 23907\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4173.832\n",
      "    load_time_ms: 1.703\n",
      "    num_steps_sampled: 3270000\n",
      "    num_steps_trained: 3270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0230340957641602\n",
      "      kl: 0.018077030777931213\n",
      "      policy_loss: -0.0050666192546486855\n",
      "      total_loss: 548.9464111328125\n",
      "      vf_explained_var: 0.9576913118362427\n",
      "      vf_loss: 548.951416015625\n",
      "    sample_time_ms: 21393.285\n",
      "    update_time_ms: 5.314\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.4254878965929\n",
      "  time_since_restore: 8663.530886650085\n",
      "  time_this_iter_s: 27.484650135040283\n",
      "  time_total_s: 8663.530886650085\n",
      "  timestamp: 1553717686\n",
      "  timesteps_since_restore: 3270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3270000\n",
      "  training_iteration: 327\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8663 s, 327 iter, 3270000 ts, 627 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-15-17\n",
      "  done: false\n",
      "  episode_len_mean: 139.55\n",
      "  episode_reward_max: 765.8830318563748\n",
      "  episode_reward_mean: 642.6033471044258\n",
      "  episode_reward_min: -79.62211481659577\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 23978\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4266.869\n",
      "    load_time_ms: 1.698\n",
      "    num_steps_sampled: 3280000\n",
      "    num_steps_trained: 3280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0412863492965698\n",
      "      kl: 0.024006465449929237\n",
      "      policy_loss: -0.0018045470351353288\n",
      "      total_loss: 522.3524780273438\n",
      "      vf_explained_var: 0.9608029127120972\n",
      "      vf_loss: 522.3541870117188\n",
      "    sample_time_ms: 21537.493\n",
      "    update_time_ms: 5.63\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 321.30167355221295\n",
      "  time_since_restore: 8694.357414245605\n",
      "  time_this_iter_s: 30.82652759552002\n",
      "  time_total_s: 8694.357414245605\n",
      "  timestamp: 1553717717\n",
      "  timesteps_since_restore: 3280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3280000\n",
      "  training_iteration: 328\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8694 s, 328 iter, 3280000 ts, 643 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-15-46\n",
      "  done: false\n",
      "  episode_len_mean: 136.15\n",
      "  episode_reward_max: 766.7530260873549\n",
      "  episode_reward_mean: 607.8345264539663\n",
      "  episode_reward_min: -124.81390555396496\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 24053\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4295.56\n",
      "    load_time_ms: 1.742\n",
      "    num_steps_sampled: 3290000\n",
      "    num_steps_trained: 3290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0497448444366455\n",
      "      kl: 0.013140354305505753\n",
      "      policy_loss: -0.00015851053467486054\n",
      "      total_loss: 683.1060791015625\n",
      "      vf_explained_var: 0.9456143379211426\n",
      "      vf_loss: 683.1061401367188\n",
      "    sample_time_ms: 22192.666\n",
      "    update_time_ms: 5.436\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 303.91726322698315\n",
      "  time_since_restore: 8723.788777828217\n",
      "  time_this_iter_s: 29.431363582611084\n",
      "  time_total_s: 8723.788777828217\n",
      "  timestamp: 1553717746\n",
      "  timesteps_since_restore: 3290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3290000\n",
      "  training_iteration: 329\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8723 s, 329 iter, 3290000 ts, 608 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-16-11\n",
      "  done: false\n",
      "  episode_len_mean: 138.09\n",
      "  episode_reward_max: 779.7272842112712\n",
      "  episode_reward_mean: 627.2626343100873\n",
      "  episode_reward_min: -131.67878729364503\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 24126\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4285.245\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 3300000\n",
      "    num_steps_trained: 3300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0375399589538574\n",
      "      kl: 0.015220802277326584\n",
      "      policy_loss: -0.00031496048904955387\n",
      "      total_loss: 439.4825134277344\n",
      "      vf_explained_var: 0.9665846228599548\n",
      "      vf_loss: 439.4827575683594\n",
      "    sample_time_ms: 22354.581\n",
      "    update_time_ms: 5.434\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.6313171550437\n",
      "  time_since_restore: 8748.868740320206\n",
      "  time_this_iter_s: 25.079962491989136\n",
      "  time_total_s: 8748.868740320206\n",
      "  timestamp: 1553717771\n",
      "  timesteps_since_restore: 3300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3300000\n",
      "  training_iteration: 330\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8748 s, 330 iter, 3300000 ts, 627 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-16-39\n",
      "  done: false\n",
      "  episode_len_mean: 135.96\n",
      "  episode_reward_max: 788.9298540479307\n",
      "  episode_reward_mean: 615.6927837349621\n",
      "  episode_reward_min: -127.9025919141809\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 24202\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4551.508\n",
      "    load_time_ms: 1.678\n",
      "    num_steps_sampled: 3310000\n",
      "    num_steps_trained: 3310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.030650019645691\n",
      "      kl: 0.014622416347265244\n",
      "      policy_loss: -0.0020435380283743143\n",
      "      total_loss: 488.96923828125\n",
      "      vf_explained_var: 0.964603841304779\n",
      "      vf_loss: 488.97125244140625\n",
      "    sample_time_ms: 22458.215\n",
      "    update_time_ms: 5.462\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 307.846391867481\n",
      "  time_since_restore: 8776.409611701965\n",
      "  time_this_iter_s: 27.540871381759644\n",
      "  time_total_s: 8776.409611701965\n",
      "  timestamp: 1553717799\n",
      "  timesteps_since_restore: 3310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3310000\n",
      "  training_iteration: 331\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8776 s, 331 iter, 3310000 ts, 616 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-17-17\n",
      "  done: false\n",
      "  episode_len_mean: 134.11\n",
      "  episode_reward_max: 772.3071007743857\n",
      "  episode_reward_mean: 597.6812793306948\n",
      "  episode_reward_min: -130.51782311799886\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 24278\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4973.973\n",
      "    load_time_ms: 1.723\n",
      "    num_steps_sampled: 3320000\n",
      "    num_steps_trained: 3320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004241189453750849\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9998446702957153\n",
      "      kl: 0.007928646169602871\n",
      "      policy_loss: -0.000642801693174988\n",
      "      total_loss: 253.144287109375\n",
      "      vf_explained_var: 0.9836754202842712\n",
      "      vf_loss: 253.14483642578125\n",
      "    sample_time_ms: 23509.758\n",
      "    update_time_ms: 5.452\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 298.8406396653474\n",
      "  time_since_restore: 8814.389137744904\n",
      "  time_this_iter_s: 37.97952604293823\n",
      "  time_total_s: 8814.389137744904\n",
      "  timestamp: 1553717837\n",
      "  timesteps_since_restore: 3320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3320000\n",
      "  training_iteration: 332\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8814 s, 332 iter, 3320000 ts, 598 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-17-47\n",
      "  done: false\n",
      "  episode_len_mean: 141.83\n",
      "  episode_reward_max: 772.3071007743857\n",
      "  episode_reward_mean: 661.4927304016144\n",
      "  episode_reward_min: -114.03289233051726\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 24350\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5097.754\n",
      "    load_time_ms: 1.788\n",
      "    num_steps_sampled: 3330000\n",
      "    num_steps_trained: 3330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021205947268754244\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.028528094291687\n",
      "      kl: 0.020461903885006905\n",
      "      policy_loss: 0.0003669716534204781\n",
      "      total_loss: 112.37110900878906\n",
      "      vf_explained_var: 0.9930269122123718\n",
      "      vf_loss: 112.37068939208984\n",
      "    sample_time_ms: 23967.484\n",
      "    update_time_ms: 6.958\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 330.7463652008072\n",
      "  time_since_restore: 8844.097994565964\n",
      "  time_this_iter_s: 29.70885682106018\n",
      "  time_total_s: 8844.097994565964\n",
      "  timestamp: 1553717867\n",
      "  timesteps_since_restore: 3330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3330000\n",
      "  training_iteration: 333\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8844 s, 333 iter, 3330000 ts, 661 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-18-20\n",
      "  done: false\n",
      "  episode_len_mean: 140.61\n",
      "  episode_reward_max: 768.2605107549482\n",
      "  episode_reward_mean: 648.3721615804125\n",
      "  episode_reward_min: -123.62134410107066\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 24421\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5214.642\n",
      "    load_time_ms: 1.854\n",
      "    num_steps_sampled: 3340000\n",
      "    num_steps_trained: 3340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021205947268754244\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0320169925689697\n",
      "      kl: 0.015074150636792183\n",
      "      policy_loss: -0.0056640030816197395\n",
      "      total_loss: 189.4116668701172\n",
      "      vf_explained_var: 0.9856051802635193\n",
      "      vf_loss: 189.4173126220703\n",
      "    sample_time_ms: 24300.228\n",
      "    update_time_ms: 7.011\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.18608079020623\n",
      "  time_since_restore: 8877.652873039246\n",
      "  time_this_iter_s: 33.55487847328186\n",
      "  time_total_s: 8877.652873039246\n",
      "  timestamp: 1553717900\n",
      "  timesteps_since_restore: 3340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3340000\n",
      "  training_iteration: 334\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8877 s, 334 iter, 3340000 ts, 648 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-18-48\n",
      "  done: false\n",
      "  episode_len_mean: 143.82\n",
      "  episode_reward_max: 796.6853811303743\n",
      "  episode_reward_mean: 678.6108253550562\n",
      "  episode_reward_min: -64.49124602917263\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 24491\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5342.733\n",
      "    load_time_ms: 1.847\n",
      "    num_steps_sampled: 3350000\n",
      "    num_steps_trained: 3350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021205947268754244\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0761679410934448\n",
      "      kl: 0.015128469094634056\n",
      "      policy_loss: -0.0030688787810504436\n",
      "      total_loss: 344.97259521484375\n",
      "      vf_explained_var: 0.9730120897293091\n",
      "      vf_loss: 344.97564697265625\n",
      "    sample_time_ms: 24215.151\n",
      "    update_time_ms: 7.366\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.30541267752824\n",
      "  time_since_restore: 8905.412866830826\n",
      "  time_this_iter_s: 27.7599937915802\n",
      "  time_total_s: 8905.412866830826\n",
      "  timestamp: 1553717928\n",
      "  timesteps_since_restore: 3350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3350000\n",
      "  training_iteration: 335\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8905 s, 335 iter, 3350000 ts, 679 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-19-18\n",
      "  done: false\n",
      "  episode_len_mean: 132.54\n",
      "  episode_reward_max: 770.9852425692465\n",
      "  episode_reward_mean: 598.4587116253509\n",
      "  episode_reward_min: -136.82207502906093\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 24568\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5378.327\n",
      "    load_time_ms: 1.773\n",
      "    num_steps_sampled: 3360000\n",
      "    num_steps_trained: 3360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021205947268754244\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.986768364906311\n",
      "      kl: 0.020663805305957794\n",
      "      policy_loss: -0.0002777522895485163\n",
      "      total_loss: 101.94428253173828\n",
      "      vf_explained_var: 0.9937205910682678\n",
      "      vf_loss: 101.94451904296875\n",
      "    sample_time_ms: 24489.681\n",
      "    update_time_ms: 7.552\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 299.2293558126754\n",
      "  time_since_restore: 8935.035930633545\n",
      "  time_this_iter_s: 29.623063802719116\n",
      "  time_total_s: 8935.035930633545\n",
      "  timestamp: 1553717958\n",
      "  timesteps_since_restore: 3360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3360000\n",
      "  training_iteration: 336\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8935 s, 336 iter, 3360000 ts, 598 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-19-43\n",
      "  done: false\n",
      "  episode_len_mean: 138.32\n",
      "  episode_reward_max: 775.6386783502346\n",
      "  episode_reward_mean: 640.9976771397568\n",
      "  episode_reward_min: -136.24659787105315\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 24642\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5319.586\n",
      "    load_time_ms: 1.778\n",
      "    num_steps_sampled: 3370000\n",
      "    num_steps_trained: 3370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021205947268754244\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0535967350006104\n",
      "      kl: 0.029242362827062607\n",
      "      policy_loss: -0.002564831869676709\n",
      "      total_loss: 223.75070190429688\n",
      "      vf_explained_var: 0.9840207099914551\n",
      "      vf_loss: 223.753173828125\n",
      "    sample_time_ms: 24291.728\n",
      "    update_time_ms: 7.608\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.4988385698784\n",
      "  time_since_restore: 8959.952701568604\n",
      "  time_this_iter_s: 24.916770935058594\n",
      "  time_total_s: 8959.952701568604\n",
      "  timestamp: 1553717983\n",
      "  timesteps_since_restore: 3370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3370000\n",
      "  training_iteration: 337\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8959 s, 337 iter, 3370000 ts, 641 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-20-13\n",
      "  done: false\n",
      "  episode_len_mean: 136.36\n",
      "  episode_reward_max: 787.1660900046271\n",
      "  episode_reward_mean: 618.2632795265523\n",
      "  episode_reward_min: -139.7227191649003\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 24717\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5501.012\n",
      "    load_time_ms: 1.859\n",
      "    num_steps_sampled: 3380000\n",
      "    num_steps_trained: 3380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021205947268754244\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0802373886108398\n",
      "      kl: 0.01420447789132595\n",
      "      policy_loss: -0.004587325733155012\n",
      "      total_loss: 626.0665893554688\n",
      "      vf_explained_var: 0.9521129131317139\n",
      "      vf_loss: 626.0711059570312\n",
      "    sample_time_ms: 24098.81\n",
      "    update_time_ms: 7.276\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 309.1316397632762\n",
      "  time_since_restore: 8990.668490886688\n",
      "  time_this_iter_s: 30.715789318084717\n",
      "  time_total_s: 8990.668490886688\n",
      "  timestamp: 1553718013\n",
      "  timesteps_since_restore: 3380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3380000\n",
      "  training_iteration: 338\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 8990 s, 338 iter, 3380000 ts, 618 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-20-40\n",
      "  done: false\n",
      "  episode_len_mean: 131.83\n",
      "  episode_reward_max: 791.4506383562056\n",
      "  episode_reward_mean: 577.2699647246345\n",
      "  episode_reward_min: -108.86797111879721\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 24795\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5488.53\n",
      "    load_time_ms: 1.836\n",
      "    num_steps_sampled: 3390000\n",
      "    num_steps_trained: 3390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021205947268754244\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0656687021255493\n",
      "      kl: 0.009782757610082626\n",
      "      policy_loss: -0.0019089350244030356\n",
      "      total_loss: 367.9725036621094\n",
      "      vf_explained_var: 0.9763862490653992\n",
      "      vf_loss: 367.974365234375\n",
      "    sample_time_ms: 23775.481\n",
      "    update_time_ms: 7.472\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 288.63498236231726\n",
      "  time_since_restore: 9016.74322605133\n",
      "  time_this_iter_s: 26.074735164642334\n",
      "  time_total_s: 9016.74322605133\n",
      "  timestamp: 1553718040\n",
      "  timesteps_since_restore: 3390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3390000\n",
      "  training_iteration: 339\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9016 s, 339 iter, 3390000 ts, 577 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 138.91\n",
      "  episode_reward_max: 757.4620389325263\n",
      "  episode_reward_mean: 646.1024729843934\n",
      "  episode_reward_min: -104.78723632042535\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 24866\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5478.012\n",
      "    load_time_ms: 1.743\n",
      "    num_steps_sampled: 3400000\n",
      "    num_steps_trained: 3400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0744272470474243\n",
      "      kl: 0.022190021350979805\n",
      "      policy_loss: -0.006482074502855539\n",
      "      total_loss: 445.70562744140625\n",
      "      vf_explained_var: 0.9638470411300659\n",
      "      vf_loss: 445.7120361328125\n",
      "    sample_time_ms: 23553.246\n",
      "    update_time_ms: 7.533\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 323.0512364921967\n",
      "  time_since_restore: 9039.495440721512\n",
      "  time_this_iter_s: 22.752214670181274\n",
      "  time_total_s: 9039.495440721512\n",
      "  timestamp: 1553718062\n",
      "  timesteps_since_restore: 3400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3400000\n",
      "  training_iteration: 340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9039 s, 340 iter, 3400000 ts, 646 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-21-25\n",
      "  done: false\n",
      "  episode_len_mean: 136.35\n",
      "  episode_reward_max: 775.834518066874\n",
      "  episode_reward_mean: 621.974687014163\n",
      "  episode_reward_min: -123.030868540906\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 24941\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5204.092\n",
      "    load_time_ms: 1.77\n",
      "    num_steps_sampled: 3410000\n",
      "    num_steps_trained: 3410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0723974704742432\n",
      "      kl: 0.01002692710608244\n",
      "      policy_loss: -0.001505858963355422\n",
      "      total_loss: 193.5396728515625\n",
      "      vf_explained_var: 0.9846165180206299\n",
      "      vf_loss: 193.5411834716797\n",
      "    sample_time_ms: 23317.304\n",
      "    update_time_ms: 7.677\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 310.9873435070816\n",
      "  time_since_restore: 9061.93349313736\n",
      "  time_this_iter_s: 22.43805241584778\n",
      "  time_total_s: 9061.93349313736\n",
      "  timestamp: 1553718085\n",
      "  timesteps_since_restore: 3410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3410000\n",
      "  training_iteration: 341\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9061 s, 341 iter, 3410000 ts, 622 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-21-47\n",
      "  done: false\n",
      "  episode_len_mean: 137.73\n",
      "  episode_reward_max: 774.7787276387282\n",
      "  episode_reward_mean: 630.7377280842526\n",
      "  episode_reward_min: -128.61509318238788\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 25014\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4773.198\n",
      "    load_time_ms: 1.714\n",
      "    num_steps_sampled: 3420000\n",
      "    num_steps_trained: 3420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0560239553451538\n",
      "      kl: 0.011902802623808384\n",
      "      policy_loss: -0.0012902762973681092\n",
      "      total_loss: 187.95578002929688\n",
      "      vf_explained_var: 0.9868201017379761\n",
      "      vf_loss: 187.95706176757812\n",
      "    sample_time_ms: 22188.2\n",
      "    update_time_ms: 7.666\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 315.36886404212635\n",
      "  time_since_restore: 9084.304115533829\n",
      "  time_this_iter_s: 22.370622396469116\n",
      "  time_total_s: 9084.304115533829\n",
      "  timestamp: 1553718107\n",
      "  timesteps_since_restore: 3420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3420000\n",
      "  training_iteration: 342\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9084 s, 342 iter, 3420000 ts, 631 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-22-09\n",
      "  done: false\n",
      "  episode_len_mean: 136.67\n",
      "  episode_reward_max: 762.6354435187548\n",
      "  episode_reward_mean: 626.5539502313911\n",
      "  episode_reward_min: -122.53032483475005\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 25089\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4631.085\n",
      "    load_time_ms: 1.642\n",
      "    num_steps_sampled: 3430000\n",
      "    num_steps_trained: 3430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0672746896743774\n",
      "      kl: 0.010787129402160645\n",
      "      policy_loss: -0.0026556223165243864\n",
      "      total_loss: 360.205322265625\n",
      "      vf_explained_var: 0.9736347794532776\n",
      "      vf_loss: 360.20794677734375\n",
      "    sample_time_ms: 21546.081\n",
      "    update_time_ms: 6.119\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.2769751156956\n",
      "  time_since_restore: 9106.15290236473\n",
      "  time_this_iter_s: 21.8487868309021\n",
      "  time_total_s: 9106.15290236473\n",
      "  timestamp: 1553718129\n",
      "  timesteps_since_restore: 3430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3430000\n",
      "  training_iteration: 343\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9106 s, 343 iter, 3430000 ts, 627 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-22-32\n",
      "  done: false\n",
      "  episode_len_mean: 137.33\n",
      "  episode_reward_max: 768.9593181673716\n",
      "  episode_reward_mean: 646.2034396556214\n",
      "  episode_reward_min: -115.96062186565833\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 25164\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4348.658\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 3440000\n",
      "    num_steps_trained: 3440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9978938698768616\n",
      "      kl: 0.01632465422153473\n",
      "      policy_loss: -0.0020154225639998913\n",
      "      total_loss: 564.9301147460938\n",
      "      vf_explained_var: 0.9562587141990662\n",
      "      vf_loss: 564.9320678710938\n",
      "    sample_time_ms: 20718.591\n",
      "    update_time_ms: 6.118\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 323.1017198278107\n",
      "  time_since_restore: 9128.599020957947\n",
      "  time_this_iter_s: 22.446118593215942\n",
      "  time_total_s: 9128.599020957947\n",
      "  timestamp: 1553718152\n",
      "  timesteps_since_restore: 3440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3440000\n",
      "  training_iteration: 344\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9128 s, 344 iter, 3440000 ts, 646 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-22-56\n",
      "  done: false\n",
      "  episode_len_mean: 133.39\n",
      "  episode_reward_max: 769.9117137238567\n",
      "  episode_reward_mean: 613.6366495412653\n",
      "  episode_reward_min: -115.86312101974721\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 25240\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4184.36\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 3450000\n",
      "    num_steps_trained: 3450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9911733865737915\n",
      "      kl: 0.01654091291129589\n",
      "      policy_loss: -0.0031387999188154936\n",
      "      total_loss: 298.0617980957031\n",
      "      vf_explained_var: 0.9772065281867981\n",
      "      vf_loss: 298.06494140625\n",
      "    sample_time_ms: 20559.596\n",
      "    update_time_ms: 5.926\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 306.8183247706327\n",
      "  time_since_restore: 9153.121332406998\n",
      "  time_this_iter_s: 24.522311449050903\n",
      "  time_total_s: 9153.121332406998\n",
      "  timestamp: 1553718176\n",
      "  timesteps_since_restore: 3450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3450000\n",
      "  training_iteration: 345\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9153 s, 345 iter, 3450000 ts, 614 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-23-20\n",
      "  done: false\n",
      "  episode_len_mean: 135.58\n",
      "  episode_reward_max: 755.5133160112266\n",
      "  episode_reward_mean: 623.5034171638285\n",
      "  episode_reward_min: -135.63850603470559\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 25314\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4137.58\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 3460000\n",
      "    num_steps_trained: 3460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0284969806671143\n",
      "      kl: 0.011349241249263287\n",
      "      policy_loss: -0.004567867144942284\n",
      "      total_loss: 396.06646728515625\n",
      "      vf_explained_var: 0.9733262658119202\n",
      "      vf_loss: 396.0710754394531\n",
      "    sample_time_ms: 19988.028\n",
      "    update_time_ms: 5.65\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 311.7517085819143\n",
      "  time_since_restore: 9176.559067487717\n",
      "  time_this_iter_s: 23.437735080718994\n",
      "  time_total_s: 9176.559067487717\n",
      "  timestamp: 1553718200\n",
      "  timesteps_since_restore: 3460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3460000\n",
      "  training_iteration: 346\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9176 s, 346 iter, 3460000 ts, 624 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-23-42\n",
      "  done: false\n",
      "  episode_len_mean: 133.86\n",
      "  episode_reward_max: 765.8208463878287\n",
      "  episode_reward_mean: 601.6401235337455\n",
      "  episode_reward_min: -113.39676911576849\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 25391\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4129.719\n",
      "    load_time_ms: 1.666\n",
      "    num_steps_sampled: 3470000\n",
      "    num_steps_trained: 3470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0118016004562378\n",
      "      kl: 0.016812795773148537\n",
      "      policy_loss: -0.0030468255281448364\n",
      "      total_loss: 769.6048583984375\n",
      "      vf_explained_var: 0.9486228823661804\n",
      "      vf_loss: 769.6078491210938\n",
      "    sample_time_ms: 19750.715\n",
      "    update_time_ms: 5.532\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 300.8200617668727\n",
      "  time_since_restore: 9199.024719715118\n",
      "  time_this_iter_s: 22.465652227401733\n",
      "  time_total_s: 9199.024719715118\n",
      "  timestamp: 1553718222\n",
      "  timesteps_since_restore: 3470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3470000\n",
      "  training_iteration: 347\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9199 s, 347 iter, 3470000 ts, 602 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-24-05\n",
      "  done: false\n",
      "  episode_len_mean: 132.05\n",
      "  episode_reward_max: 774.3577513252808\n",
      "  episode_reward_mean: 595.6724894337352\n",
      "  episode_reward_min: -132.72492051255693\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 25468\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3847.51\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 3480000\n",
      "    num_steps_trained: 3480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.995904803276062\n",
      "      kl: 0.018392415717244148\n",
      "      policy_loss: -0.004547300282865763\n",
      "      total_loss: 317.05572509765625\n",
      "      vf_explained_var: 0.9770561456680298\n",
      "      vf_loss: 317.060302734375\n",
      "    sample_time_ms: 19249.677\n",
      "    update_time_ms: 5.575\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 297.8362447168676\n",
      "  time_since_restore: 9221.903114080429\n",
      "  time_this_iter_s: 22.87839436531067\n",
      "  time_total_s: 9221.903114080429\n",
      "  timestamp: 1553718245\n",
      "  timesteps_since_restore: 3480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3480000\n",
      "  training_iteration: 348\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9221 s, 348 iter, 3480000 ts, 596 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-24-28\n",
      "  done: false\n",
      "  episode_len_mean: 135.36\n",
      "  episode_reward_max: 768.6531830760313\n",
      "  episode_reward_mean: 626.0374426027645\n",
      "  episode_reward_min: -104.38108960815113\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 25543\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3824.297\n",
      "    load_time_ms: 1.613\n",
      "    num_steps_sampled: 3490000\n",
      "    num_steps_trained: 3490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0581395626068115\n",
      "      kl: 0.021551193669438362\n",
      "      policy_loss: -0.0035197967663407326\n",
      "      total_loss: 450.4733581542969\n",
      "      vf_explained_var: 0.9658390879631042\n",
      "      vf_loss: 450.47686767578125\n",
      "    sample_time_ms: 18936.837\n",
      "    update_time_ms: 5.251\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.01872130138224\n",
      "  time_since_restore: 9244.612121343613\n",
      "  time_this_iter_s: 22.709007263183594\n",
      "  time_total_s: 9244.612121343613\n",
      "  timestamp: 1553718268\n",
      "  timesteps_since_restore: 3490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3490000\n",
      "  training_iteration: 349\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9244 s, 349 iter, 3490000 ts, 626 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-24-50\n",
      "  done: false\n",
      "  episode_len_mean: 137.6\n",
      "  episode_reward_max: 772.5523403891023\n",
      "  episode_reward_mean: 634.9478803692953\n",
      "  episode_reward_min: -95.1990726330846\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 25616\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3818.001\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 3500000\n",
      "    num_steps_trained: 3500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.078688621520996\n",
      "      kl: 0.017415061593055725\n",
      "      policy_loss: -0.0020141680724918842\n",
      "      total_loss: 243.1902618408203\n",
      "      vf_explained_var: 0.9846686124801636\n",
      "      vf_loss: 243.19223022460938\n",
      "    sample_time_ms: 18886.81\n",
      "    update_time_ms: 5.258\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 317.47394018464763\n",
      "  time_since_restore: 9266.801476955414\n",
      "  time_this_iter_s: 22.189355611801147\n",
      "  time_total_s: 9266.801476955414\n",
      "  timestamp: 1553718290\n",
      "  timesteps_since_restore: 3500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3500000\n",
      "  training_iteration: 350\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9266 s, 350 iter, 3500000 ts, 635 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-25-12\n",
      "  done: false\n",
      "  episode_len_mean: 132.99\n",
      "  episode_reward_max: 777.1477832719465\n",
      "  episode_reward_mean: 598.4165699707032\n",
      "  episode_reward_min: -120.91243581723505\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 25694\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.44\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 3510000\n",
      "    num_steps_trained: 3510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0461652278900146\n",
      "      kl: 0.01100259181112051\n",
      "      policy_loss: -0.0021561221219599247\n",
      "      total_loss: 631.4347534179688\n",
      "      vf_explained_var: 0.9565531611442566\n",
      "      vf_loss: 631.4368286132812\n",
      "    sample_time_ms: 18875.205\n",
      "    update_time_ms: 5.147\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 299.20828498535155\n",
      "  time_since_restore: 9289.094105243683\n",
      "  time_this_iter_s: 22.292628288269043\n",
      "  time_total_s: 9289.094105243683\n",
      "  timestamp: 1553718312\n",
      "  timesteps_since_restore: 3510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3510000\n",
      "  training_iteration: 351\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9289 s, 351 iter, 3510000 ts, 598 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-25-35\n",
      "  done: false\n",
      "  episode_len_mean: 140.35\n",
      "  episode_reward_max: 772.9584651039836\n",
      "  episode_reward_mean: 665.5844391565145\n",
      "  episode_reward_min: -101.71679853218929\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 25766\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3812.376\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 3520000\n",
      "    num_steps_trained: 3520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0645664930343628\n",
      "      kl: 0.01439011748880148\n",
      "      policy_loss: -0.004128917120397091\n",
      "      total_loss: 352.20196533203125\n",
      "      vf_explained_var: 0.9713241457939148\n",
      "      vf_loss: 352.2060546875\n",
      "    sample_time_ms: 18916.936\n",
      "    update_time_ms: 5.15\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 332.79221957825723\n",
      "  time_since_restore: 9311.84976029396\n",
      "  time_this_iter_s: 22.75565505027771\n",
      "  time_total_s: 9311.84976029396\n",
      "  timestamp: 1553718335\n",
      "  timesteps_since_restore: 3520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3520000\n",
      "  training_iteration: 352\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9311 s, 352 iter, 3520000 ts, 666 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-25-58\n",
      "  done: false\n",
      "  episode_len_mean: 130.18\n",
      "  episode_reward_max: 771.529880073783\n",
      "  episode_reward_mean: 585.292332270003\n",
      "  episode_reward_min: -137.37983445763678\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 25845\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3812.07\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 3530000\n",
      "    num_steps_trained: 3530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0256322622299194\n",
      "      kl: 0.010267439298331738\n",
      "      policy_loss: -0.0030339728109538555\n",
      "      total_loss: 951.4533081054688\n",
      "      vf_explained_var: 0.9340724349021912\n",
      "      vf_loss: 951.4563598632812\n",
      "    sample_time_ms: 19003.478\n",
      "    update_time_ms: 5.279\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 292.6461661350015\n",
      "  time_since_restore: 9334.563745737076\n",
      "  time_this_iter_s: 22.713985443115234\n",
      "  time_total_s: 9334.563745737076\n",
      "  timestamp: 1553718358\n",
      "  timesteps_since_restore: 3530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3530000\n",
      "  training_iteration: 353\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9334 s, 353 iter, 3530000 ts, 585 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-26-21\n",
      "  done: false\n",
      "  episode_len_mean: 134.55\n",
      "  episode_reward_max: 775.1461772651505\n",
      "  episode_reward_mean: 621.5126367694711\n",
      "  episode_reward_min: -112.26107142626117\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 25919\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3814.678\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 3540000\n",
      "    num_steps_trained: 3540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0010602973634377122\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0357071161270142\n",
      "      kl: 0.009251831099390984\n",
      "      policy_loss: -0.004465899895876646\n",
      "      total_loss: 254.33082580566406\n",
      "      vf_explained_var: 0.9812961220741272\n",
      "      vf_loss: 254.33531188964844\n",
      "    sample_time_ms: 19062.705\n",
      "    update_time_ms: 5.243\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 310.75631838473555\n",
      "  time_since_restore: 9357.624937057495\n",
      "  time_this_iter_s: 23.06119132041931\n",
      "  time_total_s: 9357.624937057495\n",
      "  timestamp: 1553718381\n",
      "  timesteps_since_restore: 3540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3540000\n",
      "  training_iteration: 354\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9357 s, 354 iter, 3540000 ts, 622 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 135.83\n",
      "  episode_reward_max: 767.428864605532\n",
      "  episode_reward_mean: 628.8339134443676\n",
      "  episode_reward_min: -109.81929236818868\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 25994\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.625\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 3550000\n",
      "    num_steps_trained: 3550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0005301486817188561\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0567264556884766\n",
      "      kl: 0.008629165589809418\n",
      "      policy_loss: -0.0010300058638677\n",
      "      total_loss: 311.71990966796875\n",
      "      vf_explained_var: 0.977120041847229\n",
      "      vf_loss: 311.7209167480469\n",
      "    sample_time_ms: 18871.655\n",
      "    update_time_ms: 5.159\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 314.41695672218384\n",
      "  time_since_restore: 9380.085304737091\n",
      "  time_this_iter_s: 22.460367679595947\n",
      "  time_total_s: 9380.085304737091\n",
      "  timestamp: 1553718404\n",
      "  timesteps_since_restore: 3550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3550000\n",
      "  training_iteration: 355\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9380 s, 355 iter, 3550000 ts, 629 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-27-06\n",
      "  done: false\n",
      "  episode_len_mean: 137.27\n",
      "  episode_reward_max: 766.5275918505065\n",
      "  episode_reward_mean: 629.1460672892027\n",
      "  episode_reward_min: -121.12055087316936\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 26068\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3800.531\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 3560000\n",
      "    num_steps_trained: 3560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1016381978988647\n",
      "      kl: 0.0185394324362278\n",
      "      policy_loss: -0.003793016541749239\n",
      "      total_loss: 280.00927734375\n",
      "      vf_explained_var: 0.9792488217353821\n",
      "      vf_loss: 280.0130310058594\n",
      "    sample_time_ms: 18772.527\n",
      "    update_time_ms: 5.125\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 314.57303364460137\n",
      "  time_since_restore: 9402.540435314178\n",
      "  time_this_iter_s: 22.455130577087402\n",
      "  time_total_s: 9402.540435314178\n",
      "  timestamp: 1553718426\n",
      "  timesteps_since_restore: 3560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3560000\n",
      "  training_iteration: 356\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9402 s, 356 iter, 3560000 ts, 629 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-27-29\n",
      "  done: false\n",
      "  episode_len_mean: 133.22\n",
      "  episode_reward_max: 767.1460136732879\n",
      "  episode_reward_mean: 602.1431721571279\n",
      "  episode_reward_min: -115.17153072324656\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 26145\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.269\n",
      "    load_time_ms: 1.522\n",
      "    num_steps_sampled: 3570000\n",
      "    num_steps_trained: 3570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0607367753982544\n",
      "      kl: 0.018715186044573784\n",
      "      policy_loss: -0.005790491122752428\n",
      "      total_loss: 531.0210571289062\n",
      "      vf_explained_var: 0.9668490886688232\n",
      "      vf_loss: 531.02685546875\n",
      "    sample_time_ms: 18804.696\n",
      "    update_time_ms: 5.226\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 301.07158607856394\n",
      "  time_since_restore: 9425.308517456055\n",
      "  time_this_iter_s: 22.76808214187622\n",
      "  time_total_s: 9425.308517456055\n",
      "  timestamp: 1553718449\n",
      "  timesteps_since_restore: 3570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3570000\n",
      "  training_iteration: 357\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9425 s, 357 iter, 3570000 ts, 602 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-27-52\n",
      "  done: false\n",
      "  episode_len_mean: 136.67\n",
      "  episode_reward_max: 767.1460136732879\n",
      "  episode_reward_mean: 639.5330252875393\n",
      "  episode_reward_min: -122.17020502465986\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 26220\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3797.172\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 3580000\n",
      "    num_steps_trained: 3580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0982593297958374\n",
      "      kl: 0.014300832524895668\n",
      "      policy_loss: -0.0056898221373558044\n",
      "      total_loss: 70.75291442871094\n",
      "      vf_explained_var: 0.9950802326202393\n",
      "      vf_loss: 70.75859832763672\n",
      "    sample_time_ms: 18811.992\n",
      "    update_time_ms: 5.159\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 319.7665126437696\n",
      "  time_since_restore: 9448.245076417923\n",
      "  time_this_iter_s: 22.936558961868286\n",
      "  time_total_s: 9448.245076417923\n",
      "  timestamp: 1553718472\n",
      "  timesteps_since_restore: 3580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3580000\n",
      "  training_iteration: 358\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9448 s, 358 iter, 3580000 ts, 640 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-28-15\n",
      "  done: false\n",
      "  episode_len_mean: 137.51\n",
      "  episode_reward_max: 777.2812123869104\n",
      "  episode_reward_mean: 638.3342259266708\n",
      "  episode_reward_min: -116.00440097715986\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 26293\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.653\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 3590000\n",
      "    num_steps_trained: 3590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.150673747062683\n",
      "      kl: 0.026837991550564766\n",
      "      policy_loss: -0.007055622059851885\n",
      "      total_loss: 444.689697265625\n",
      "      vf_explained_var: 0.9650440812110901\n",
      "      vf_loss: 444.69671630859375\n",
      "    sample_time_ms: 18808.059\n",
      "    update_time_ms: 5.279\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 319.1671129633354\n",
      "  time_since_restore: 9470.911155939102\n",
      "  time_this_iter_s: 22.6660795211792\n",
      "  time_total_s: 9470.911155939102\n",
      "  timestamp: 1553718495\n",
      "  timesteps_since_restore: 3590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3590000\n",
      "  training_iteration: 359\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9470 s, 359 iter, 3590000 ts, 638 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-28-37\n",
      "  done: false\n",
      "  episode_len_mean: 133.31\n",
      "  episode_reward_max: 769.1751948029157\n",
      "  episode_reward_mean: 614.410262424191\n",
      "  episode_reward_min: -140.9797044588271\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 26369\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3797.987\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 3600000\n",
      "    num_steps_trained: 3600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.092402696609497\n",
      "      kl: 0.010412707924842834\n",
      "      policy_loss: -0.002854606369510293\n",
      "      total_loss: 447.1638488769531\n",
      "      vf_explained_var: 0.9675077795982361\n",
      "      vf_loss: 447.1667175292969\n",
      "    sample_time_ms: 18785.109\n",
      "    update_time_ms: 5.369\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 307.20513121209547\n",
      "  time_since_restore: 9492.884166955948\n",
      "  time_this_iter_s: 21.973011016845703\n",
      "  time_total_s: 9492.884166955948\n",
      "  timestamp: 1553718517\n",
      "  timesteps_since_restore: 3600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3600000\n",
      "  training_iteration: 360\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9492 s, 360 iter, 3600000 ts, 614 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-28-59\n",
      "  done: false\n",
      "  episode_len_mean: 134.39\n",
      "  episode_reward_max: 767.0921743100241\n",
      "  episode_reward_mean: 626.3840926715773\n",
      "  episode_reward_min: -117.45666649917028\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 26445\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.937\n",
      "    load_time_ms: 1.562\n",
      "    num_steps_sampled: 3610000\n",
      "    num_steps_trained: 3610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1088855266571045\n",
      "      kl: 0.013798370957374573\n",
      "      policy_loss: -0.0007318614516407251\n",
      "      total_loss: 375.9443664550781\n",
      "      vf_explained_var: 0.9742705225944519\n",
      "      vf_loss: 375.945068359375\n",
      "    sample_time_ms: 18813.071\n",
      "    update_time_ms: 5.318\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.1920463357885\n",
      "  time_since_restore: 9515.450120925903\n",
      "  time_this_iter_s: 22.565953969955444\n",
      "  time_total_s: 9515.450120925903\n",
      "  timestamp: 1553718539\n",
      "  timesteps_since_restore: 3610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3610000\n",
      "  training_iteration: 361\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9515 s, 361 iter, 3610000 ts, 626 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-29-22\n",
      "  done: false\n",
      "  episode_len_mean: 136.54\n",
      "  episode_reward_max: 772.1719585546562\n",
      "  episode_reward_mean: 641.1394013283717\n",
      "  episode_reward_min: -93.97552754934152\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 26520\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3803.817\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 3620000\n",
      "    num_steps_trained: 3620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.09443998336792\n",
      "      kl: 0.01066648494452238\n",
      "      policy_loss: -0.0011285837972536683\n",
      "      total_loss: 734.6971435546875\n",
      "      vf_explained_var: 0.9474076628684998\n",
      "      vf_loss: 734.6982421875\n",
      "    sample_time_ms: 18792.648\n",
      "    update_time_ms: 5.381\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.56970066418586\n",
      "  time_since_restore: 9538.069692134857\n",
      "  time_this_iter_s: 22.619571208953857\n",
      "  time_total_s: 9538.069692134857\n",
      "  timestamp: 1553718562\n",
      "  timesteps_since_restore: 3620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3620000\n",
      "  training_iteration: 362\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9538 s, 362 iter, 3620000 ts, 641 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-29-45\n",
      "  done: false\n",
      "  episode_len_mean: 135.97\n",
      "  episode_reward_max: 783.1180017696271\n",
      "  episode_reward_mean: 633.4047550344654\n",
      "  episode_reward_min: -130.3163788646087\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 26594\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.944\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 3630000\n",
      "    num_steps_trained: 3630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1295233964920044\n",
      "      kl: 0.013654467649757862\n",
      "      policy_loss: -0.0018053791718557477\n",
      "      total_loss: 482.5008544921875\n",
      "      vf_explained_var: 0.9641844630241394\n",
      "      vf_loss: 482.5025939941406\n",
      "    sample_time_ms: 18804.731\n",
      "    update_time_ms: 5.336\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.7023775172327\n",
      "  time_since_restore: 9560.862467050552\n",
      "  time_this_iter_s: 22.79277491569519\n",
      "  time_total_s: 9560.862467050552\n",
      "  timestamp: 1553718585\n",
      "  timesteps_since_restore: 3630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3630000\n",
      "  training_iteration: 363\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9560 s, 363 iter, 3630000 ts, 633 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-30-07\n",
      "  done: false\n",
      "  episode_len_mean: 133.72\n",
      "  episode_reward_max: 792.064243170679\n",
      "  episode_reward_mean: 597.8886775402041\n",
      "  episode_reward_min: -127.32936378260845\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 26670\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3801.702\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 3640000\n",
      "    num_steps_trained: 3640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.135524034500122\n",
      "      kl: 0.010251031257212162\n",
      "      policy_loss: -0.0023993586655706167\n",
      "      total_loss: 654.821533203125\n",
      "      vf_explained_var: 0.950452446937561\n",
      "      vf_loss: 654.8239135742188\n",
      "    sample_time_ms: 18768.322\n",
      "    update_time_ms: 5.296\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 298.9443387701021\n",
      "  time_since_restore: 9583.578100442886\n",
      "  time_this_iter_s: 22.715633392333984\n",
      "  time_total_s: 9583.578100442886\n",
      "  timestamp: 1553718607\n",
      "  timesteps_since_restore: 3640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3640000\n",
      "  training_iteration: 364\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9583 s, 364 iter, 3640000 ts, 598 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-30-30\n",
      "  done: false\n",
      "  episode_len_mean: 135.44\n",
      "  episode_reward_max: 770.9614295237091\n",
      "  episode_reward_mean: 627.7916069887917\n",
      "  episode_reward_min: -137.4048685347381\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 26745\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.651\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 3650000\n",
      "    num_steps_trained: 3650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1055322885513306\n",
      "      kl: 0.012818467803299427\n",
      "      policy_loss: -0.0022659783717244864\n",
      "      total_loss: 296.96478271484375\n",
      "      vf_explained_var: 0.9778898358345032\n",
      "      vf_loss: 296.9670104980469\n",
      "    sample_time_ms: 18798.813\n",
      "    update_time_ms: 5.292\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.89580349439586\n",
      "  time_since_restore: 9606.322523832321\n",
      "  time_this_iter_s: 22.744423389434814\n",
      "  time_total_s: 9606.322523832321\n",
      "  timestamp: 1553718630\n",
      "  timesteps_since_restore: 3650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3650000\n",
      "  training_iteration: 365\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9606 s, 365 iter, 3650000 ts, 628 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-30-52\n",
      "  done: false\n",
      "  episode_len_mean: 141.42\n",
      "  episode_reward_max: 765.9583832767173\n",
      "  episode_reward_mean: 672.2965625122382\n",
      "  episode_reward_min: -119.98040172091845\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 26815\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3797.074\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 3660000\n",
      "    num_steps_trained: 3660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00026507434085942805\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1705158948898315\n",
      "      kl: 0.007337321061640978\n",
      "      policy_loss: -0.0014145722379907966\n",
      "      total_loss: 104.27593231201172\n",
      "      vf_explained_var: 0.9944489598274231\n",
      "      vf_loss: 104.27735137939453\n",
      "    sample_time_ms: 18766.529\n",
      "    update_time_ms: 5.563\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.14828125611916\n",
      "  time_since_restore: 9628.428819179535\n",
      "  time_this_iter_s: 22.106295347213745\n",
      "  time_total_s: 9628.428819179535\n",
      "  timestamp: 1553718652\n",
      "  timesteps_since_restore: 3660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3660000\n",
      "  training_iteration: 366\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9628 s, 366 iter, 3660000 ts, 672 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-31-15\n",
      "  done: false\n",
      "  episode_len_mean: 137.51\n",
      "  episode_reward_max: 762.1711041456565\n",
      "  episode_reward_mean: 633.8821776759892\n",
      "  episode_reward_min: -104.06645304910323\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 26890\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.821\n",
      "    load_time_ms: 1.613\n",
      "    num_steps_sampled: 3670000\n",
      "    num_steps_trained: 3670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00013253717042971402\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1126121282577515\n",
      "      kl: 0.007786489557474852\n",
      "      policy_loss: -0.0021014136727899313\n",
      "      total_loss: 253.5402069091797\n",
      "      vf_explained_var: 0.9809175133705139\n",
      "      vf_loss: 253.5423126220703\n",
      "    sample_time_ms: 18757.406\n",
      "    update_time_ms: 5.592\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.9410888379946\n",
      "  time_since_restore: 9651.089020252228\n",
      "  time_this_iter_s: 22.66020107269287\n",
      "  time_total_s: 9651.089020252228\n",
      "  timestamp: 1553718675\n",
      "  timesteps_since_restore: 3670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3670000\n",
      "  training_iteration: 367\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9651 s, 367 iter, 3670000 ts, 634 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-31-38\n",
      "  done: false\n",
      "  episode_len_mean: 138.49\n",
      "  episode_reward_max: 762.1199422703313\n",
      "  episode_reward_mean: 646.6678798337745\n",
      "  episode_reward_min: -132.83168555754344\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 26963\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.962\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 3680000\n",
      "    num_steps_trained: 3680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.626858521485701e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.123464584350586\n",
      "      kl: 0.01139741949737072\n",
      "      policy_loss: -0.0021148263476788998\n",
      "      total_loss: 378.7176513671875\n",
      "      vf_explained_var: 0.971067488193512\n",
      "      vf_loss: 378.7197570800781\n",
      "    sample_time_ms: 18739.214\n",
      "    update_time_ms: 5.731\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 323.3339399168872\n",
      "  time_since_restore: 9673.877431154251\n",
      "  time_this_iter_s: 22.788410902023315\n",
      "  time_total_s: 9673.877431154251\n",
      "  timestamp: 1553718698\n",
      "  timesteps_since_restore: 3680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3680000\n",
      "  training_iteration: 368\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9673 s, 368 iter, 3680000 ts, 647 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-32-00\n",
      "  done: false\n",
      "  episode_len_mean: 138.41\n",
      "  episode_reward_max: 762.6566884891989\n",
      "  episode_reward_mean: 643.9835006956376\n",
      "  episode_reward_min: -115.06301587154337\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 27036\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3800.309\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 3690000\n",
      "    num_steps_trained: 3690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.626858521485701e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0875595808029175\n",
      "      kl: 0.013077320531010628\n",
      "      policy_loss: -0.002562189009040594\n",
      "      total_loss: 195.996826171875\n",
      "      vf_explained_var: 0.9848433136940002\n",
      "      vf_loss: 195.9993896484375\n",
      "    sample_time_ms: 18726.796\n",
      "    update_time_ms: 5.849\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 321.9917503478189\n",
      "  time_since_restore: 9696.4321539402\n",
      "  time_this_iter_s: 22.554722785949707\n",
      "  time_total_s: 9696.4321539402\n",
      "  timestamp: 1553718720\n",
      "  timesteps_since_restore: 3690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3690000\n",
      "  training_iteration: 369\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9696 s, 369 iter, 3690000 ts, 644 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-32-23\n",
      "  done: false\n",
      "  episode_len_mean: 136.67\n",
      "  episode_reward_max: 788.564180316814\n",
      "  episode_reward_mean: 626.940203389145\n",
      "  episode_reward_min: -125.2268880980744\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 27111\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.665\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 3700000\n",
      "    num_steps_trained: 3700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.626858521485701e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1415354013442993\n",
      "      kl: 0.026178525760769844\n",
      "      policy_loss: -0.01195959746837616\n",
      "      total_loss: 428.57232666015625\n",
      "      vf_explained_var: 0.9692416191101074\n",
      "      vf_loss: 428.5843200683594\n",
      "    sample_time_ms: 18775.625\n",
      "    update_time_ms: 5.595\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.47010169457246\n",
      "  time_since_restore: 9718.874031305313\n",
      "  time_this_iter_s: 22.441877365112305\n",
      "  time_total_s: 9718.874031305313\n",
      "  timestamp: 1553718743\n",
      "  timesteps_since_restore: 3700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3700000\n",
      "  training_iteration: 370\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9718 s, 370 iter, 3700000 ts, 627 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-32-46\n",
      "  done: false\n",
      "  episode_len_mean: 136.69\n",
      "  episode_reward_max: 767.442384511385\n",
      "  episode_reward_mean: 628.1485488355174\n",
      "  episode_reward_min: -128.22973141096645\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 27184\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.078\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 3710000\n",
      "    num_steps_trained: 3710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.626858521485701e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0958586931228638\n",
      "      kl: 0.014535943977534771\n",
      "      policy_loss: -0.0033004023134708405\n",
      "      total_loss: 641.3860473632812\n",
      "      vf_explained_var: 0.9492431879043579\n",
      "      vf_loss: 641.3893432617188\n",
      "    sample_time_ms: 18785.707\n",
      "    update_time_ms: 5.702\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 314.07427441775866\n",
      "  time_since_restore: 9741.572826862335\n",
      "  time_this_iter_s: 22.698795557022095\n",
      "  time_total_s: 9741.572826862335\n",
      "  timestamp: 1553718766\n",
      "  timesteps_since_restore: 3710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3710000\n",
      "  training_iteration: 371\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9741 s, 371 iter, 3710000 ts, 628 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-33-08\n",
      "  done: false\n",
      "  episode_len_mean: 137.14\n",
      "  episode_reward_max: 767.442384511385\n",
      "  episode_reward_mean: 632.2770707098109\n",
      "  episode_reward_min: -126.0414350915544\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 27259\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3797.13\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 3720000\n",
      "    num_steps_trained: 3720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.626858521485701e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0503721237182617\n",
      "      kl: 0.011997608467936516\n",
      "      policy_loss: -0.003527366556227207\n",
      "      total_loss: 326.3896179199219\n",
      "      vf_explained_var: 0.9760130047798157\n",
      "      vf_loss: 326.3931884765625\n",
      "    sample_time_ms: 18787.871\n",
      "    update_time_ms: 5.657\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.1385353549054\n",
      "  time_since_restore: 9764.16714310646\n",
      "  time_this_iter_s: 22.594316244125366\n",
      "  time_total_s: 9764.16714310646\n",
      "  timestamp: 1553718788\n",
      "  timesteps_since_restore: 3720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3720000\n",
      "  training_iteration: 372\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9764 s, 372 iter, 3720000 ts, 632 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-33-31\n",
      "  done: false\n",
      "  episode_len_mean: 139.88\n",
      "  episode_reward_max: 767.3968528859759\n",
      "  episode_reward_mean: 666.8577277577315\n",
      "  episode_reward_min: -103.98760827401154\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 27331\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.065\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 3730000\n",
      "    num_steps_trained: 3730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.626858521485701e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.094959020614624\n",
      "      kl: 0.01697670854628086\n",
      "      policy_loss: -0.0009675601031631231\n",
      "      total_loss: 77.2405776977539\n",
      "      vf_explained_var: 0.9967154264450073\n",
      "      vf_loss: 77.24154663085938\n",
      "    sample_time_ms: 18753.599\n",
      "    update_time_ms: 5.682\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 333.4288638788658\n",
      "  time_since_restore: 9786.626187562943\n",
      "  time_this_iter_s: 22.459044456481934\n",
      "  time_total_s: 9786.626187562943\n",
      "  timestamp: 1553718811\n",
      "  timesteps_since_restore: 3730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3730000\n",
      "  training_iteration: 373\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9786 s, 373 iter, 3730000 ts, 667 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-33-53\n",
      "  done: false\n",
      "  episode_len_mean: 134.44\n",
      "  episode_reward_max: 776.9749421565574\n",
      "  episode_reward_mean: 617.7313066078359\n",
      "  episode_reward_min: -84.15676998640551\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 27407\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.769\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 3740000\n",
      "    num_steps_trained: 3740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.626858521485701e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1072083711624146\n",
      "      kl: 0.006363990250974894\n",
      "      policy_loss: -0.0008919439860619605\n",
      "      total_loss: 375.1651916503906\n",
      "      vf_explained_var: 0.9731642603874207\n",
      "      vf_loss: 375.1661071777344\n",
      "    sample_time_ms: 18702.696\n",
      "    update_time_ms: 5.755\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 308.8656533039179\n",
      "  time_since_restore: 9808.84142422676\n",
      "  time_this_iter_s: 22.21523666381836\n",
      "  time_total_s: 9808.84142422676\n",
      "  timestamp: 1553718833\n",
      "  timesteps_since_restore: 3740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3740000\n",
      "  training_iteration: 374\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9808 s, 374 iter, 3740000 ts, 618 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-34-16\n",
      "  done: false\n",
      "  episode_len_mean: 131.22\n",
      "  episode_reward_max: 773.510419101969\n",
      "  episode_reward_mean: 588.9369745859952\n",
      "  episode_reward_min: -133.19078424386132\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 27485\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3800.04\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 3750000\n",
      "    num_steps_trained: 3750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.3134292607428506e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.101781964302063\n",
      "      kl: 0.01167295966297388\n",
      "      policy_loss: -0.00481350626796484\n",
      "      total_loss: 768.7025756835938\n",
      "      vf_explained_var: 0.9485235214233398\n",
      "      vf_loss: 768.7074584960938\n",
      "    sample_time_ms: 18672.216\n",
      "    update_time_ms: 5.688\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 294.46848729299757\n",
      "  time_since_restore: 9831.293190956116\n",
      "  time_this_iter_s: 22.45176672935486\n",
      "  time_total_s: 9831.293190956116\n",
      "  timestamp: 1553718856\n",
      "  timesteps_since_restore: 3750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3750000\n",
      "  training_iteration: 375\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9831 s, 375 iter, 3750000 ts, 589 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-34-37\n",
      "  done: false\n",
      "  episode_len_mean: 137.45\n",
      "  episode_reward_max: 773.8401693180516\n",
      "  episode_reward_mean: 645.3601717272697\n",
      "  episode_reward_min: -116.68337229033656\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 27559\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3800.69\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 3760000\n",
      "    num_steps_trained: 3760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.3134292607428506e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1380213499069214\n",
      "      kl: 0.015261081978678703\n",
      "      policy_loss: -0.0013740971917286515\n",
      "      total_loss: 708.8429565429688\n",
      "      vf_explained_var: 0.9471801519393921\n",
      "      vf_loss: 708.84423828125\n",
      "    sample_time_ms: 18610.632\n",
      "    update_time_ms: 5.528\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 322.6800858636349\n",
      "  time_since_restore: 9852.790665626526\n",
      "  time_this_iter_s: 21.497474670410156\n",
      "  time_total_s: 9852.790665626526\n",
      "  timestamp: 1553718877\n",
      "  timesteps_since_restore: 3760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3760000\n",
      "  training_iteration: 376\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9852 s, 376 iter, 3760000 ts, 645 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-34-59\n",
      "  done: false\n",
      "  episode_len_mean: 137.07\n",
      "  episode_reward_max: 787.1215807225761\n",
      "  episode_reward_mean: 641.9095031179862\n",
      "  episode_reward_min: -116.68337229033656\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 27631\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.9\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 3770000\n",
      "    num_steps_trained: 3770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.3134292607428506e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0830256938934326\n",
      "      kl: 0.009656091220676899\n",
      "      policy_loss: -0.0018482903251424432\n",
      "      total_loss: 29.50272560119629\n",
      "      vf_explained_var: 0.9978009462356567\n",
      "      vf_loss: 29.504575729370117\n",
      "    sample_time_ms: 18578.683\n",
      "    update_time_ms: 5.434\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.95475155899317\n",
      "  time_since_restore: 9875.126232862473\n",
      "  time_this_iter_s: 22.335567235946655\n",
      "  time_total_s: 9875.126232862473\n",
      "  timestamp: 1553718899\n",
      "  timesteps_since_restore: 3770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3770000\n",
      "  training_iteration: 377\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9875 s, 377 iter, 3770000 ts, 642 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-35-22\n",
      "  done: false\n",
      "  episode_len_mean: 137.51\n",
      "  episode_reward_max: 769.4802099753769\n",
      "  episode_reward_mean: 654.466765176973\n",
      "  episode_reward_min: -101.40035418397363\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 27705\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3806.373\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 3780000\n",
      "    num_steps_trained: 3780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6567146303714253e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0651007890701294\n",
      "      kl: 0.009237398393452168\n",
      "      policy_loss: -0.0022317487746477127\n",
      "      total_loss: 680.3804321289062\n",
      "      vf_explained_var: 0.940182626247406\n",
      "      vf_loss: 680.3826904296875\n",
      "    sample_time_ms: 18498.318\n",
      "    update_time_ms: 5.299\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 327.23338258848656\n",
      "  time_since_restore: 9897.177134752274\n",
      "  time_this_iter_s: 22.050901889801025\n",
      "  time_total_s: 9897.177134752274\n",
      "  timestamp: 1553718922\n",
      "  timesteps_since_restore: 3780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3780000\n",
      "  training_iteration: 378\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9897 s, 378 iter, 3780000 ts, 654 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-35-44\n",
      "  done: false\n",
      "  episode_len_mean: 137.96\n",
      "  episode_reward_max: 769.4802099753769\n",
      "  episode_reward_mean: 651.1326082115149\n",
      "  episode_reward_min: -102.1312766010208\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 27778\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3804.651\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 3790000\n",
      "    num_steps_trained: 3790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.283573151857127e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1176574230194092\n",
      "      kl: 0.012121486477553844\n",
      "      policy_loss: -0.0014222689205780625\n",
      "      total_loss: 429.2486877441406\n",
      "      vf_explained_var: 0.9698389768600464\n",
      "      vf_loss: 429.2501525878906\n",
      "    sample_time_ms: 18468.948\n",
      "    update_time_ms: 5.314\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 325.56630410575747\n",
      "  time_since_restore: 9919.423193693161\n",
      "  time_this_iter_s: 22.24605894088745\n",
      "  time_total_s: 9919.423193693161\n",
      "  timestamp: 1553718944\n",
      "  timesteps_since_restore: 3790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3790000\n",
      "  training_iteration: 379\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9919 s, 379 iter, 3790000 ts, 651 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-36-06\n",
      "  done: false\n",
      "  episode_len_mean: 135.86\n",
      "  episode_reward_max: 780.798487982168\n",
      "  episode_reward_mean: 623.3177693459171\n",
      "  episode_reward_min: -140.14664988289314\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 27853\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3807.927\n",
      "    load_time_ms: 1.65\n",
      "    num_steps_sampled: 3800000\n",
      "    num_steps_trained: 3800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.283573151857127e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0831634998321533\n",
      "      kl: 0.011021208949387074\n",
      "      policy_loss: -0.0011620265431702137\n",
      "      total_loss: 391.3135070800781\n",
      "      vf_explained_var: 0.971744954586029\n",
      "      vf_loss: 391.3146667480469\n",
      "    sample_time_ms: 18437.737\n",
      "    update_time_ms: 5.421\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 311.6588846729585\n",
      "  time_since_restore: 9941.588448286057\n",
      "  time_this_iter_s: 22.165254592895508\n",
      "  time_total_s: 9941.588448286057\n",
      "  timestamp: 1553718966\n",
      "  timesteps_since_restore: 3800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3800000\n",
      "  training_iteration: 380\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9941 s, 380 iter, 3800000 ts, 623 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-36-28\n",
      "  done: false\n",
      "  episode_len_mean: 140.78\n",
      "  episode_reward_max: 780.798487982168\n",
      "  episode_reward_mean: 668.3135040555131\n",
      "  episode_reward_min: -81.39210343888013\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 27926\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3807.042\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 3810000\n",
      "    num_steps_trained: 3810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.283573151857127e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0833369493484497\n",
      "      kl: 0.00941105093806982\n",
      "      policy_loss: -0.002591530093923211\n",
      "      total_loss: 140.86373901367188\n",
      "      vf_explained_var: 0.9890878200531006\n",
      "      vf_loss: 140.8663330078125\n",
      "    sample_time_ms: 18367.033\n",
      "    update_time_ms: 5.333\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.15675202775657\n",
      "  time_since_restore: 9963.570845127106\n",
      "  time_this_iter_s: 21.982396841049194\n",
      "  time_total_s: 9963.570845127106\n",
      "  timestamp: 1553718988\n",
      "  timesteps_since_restore: 3810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3810000\n",
      "  training_iteration: 381\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9963 s, 381 iter, 3810000 ts, 668 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-36-51\n",
      "  done: false\n",
      "  episode_len_mean: 137.67\n",
      "  episode_reward_max: 782.6844792853205\n",
      "  episode_reward_mean: 637.7741210472932\n",
      "  episode_reward_min: -116.93991285449044\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 27999\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3806.498\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 3820000\n",
      "    num_steps_trained: 3820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.141786575928563e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1105161905288696\n",
      "      kl: 0.010649005882441998\n",
      "      policy_loss: -0.0008639345760457218\n",
      "      total_loss: 400.4587707519531\n",
      "      vf_explained_var: 0.9692439436912537\n",
      "      vf_loss: 400.4596862792969\n",
      "    sample_time_ms: 18359.93\n",
      "    update_time_ms: 5.245\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 318.8870605236466\n",
      "  time_since_restore: 9986.087406635284\n",
      "  time_this_iter_s: 22.51656150817871\n",
      "  time_total_s: 9986.087406635284\n",
      "  timestamp: 1553719011\n",
      "  timesteps_since_restore: 3820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3820000\n",
      "  training_iteration: 382\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 9986 s, 382 iter, 3820000 ts, 638 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-37-13\n",
      "  done: false\n",
      "  episode_len_mean: 136.94\n",
      "  episode_reward_max: 782.3879935993912\n",
      "  episode_reward_mean: 634.2445858829883\n",
      "  episode_reward_min: -131.8790006212944\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 28074\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3803.864\n",
      "    load_time_ms: 1.699\n",
      "    num_steps_sampled: 3830000\n",
      "    num_steps_trained: 3830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.141786575928563e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1103365421295166\n",
      "      kl: 0.010182694531977177\n",
      "      policy_loss: -0.0015517488354817033\n",
      "      total_loss: 818.1304931640625\n",
      "      vf_explained_var: 0.9352110028266907\n",
      "      vf_loss: 818.1321411132812\n",
      "    sample_time_ms: 18361.343\n",
      "    update_time_ms: 5.245\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 317.1222929414942\n",
      "  time_since_restore: 10008.536345481873\n",
      "  time_this_iter_s: 22.448938846588135\n",
      "  time_total_s: 10008.536345481873\n",
      "  timestamp: 1553719033\n",
      "  timesteps_since_restore: 3830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3830000\n",
      "  training_iteration: 383\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10008 s, 383 iter, 3830000 ts, 634 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-37-36\n",
      "  done: false\n",
      "  episode_len_mean: 135.67\n",
      "  episode_reward_max: 773.1960279312812\n",
      "  episode_reward_mean: 628.6019337408975\n",
      "  episode_reward_min: -128.0355489314964\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 28149\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.897\n",
      "    load_time_ms: 1.742\n",
      "    num_steps_sampled: 3840000\n",
      "    num_steps_trained: 3840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.141786575928563e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0929391384124756\n",
      "      kl: 0.009906445629894733\n",
      "      policy_loss: -0.0031076837331056595\n",
      "      total_loss: 611.7359619140625\n",
      "      vf_explained_var: 0.9540861248970032\n",
      "      vf_loss: 611.7390747070312\n",
      "    sample_time_ms: 18399.604\n",
      "    update_time_ms: 5.157\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 314.30096687044875\n",
      "  time_since_restore: 10031.093529462814\n",
      "  time_this_iter_s: 22.557183980941772\n",
      "  time_total_s: 10031.093529462814\n",
      "  timestamp: 1553719056\n",
      "  timesteps_since_restore: 3840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3840000\n",
      "  training_iteration: 384\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10031 s, 384 iter, 3840000 ts, 629 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-37-59\n",
      "  done: false\n",
      "  episode_len_mean: 132.33\n",
      "  episode_reward_max: 773.1960279312812\n",
      "  episode_reward_mean: 604.7693056543862\n",
      "  episode_reward_min: -117.24742090277446\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 28225\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.376\n",
      "    load_time_ms: 1.708\n",
      "    num_steps_sampled: 3850000\n",
      "    num_steps_trained: 3850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0708932879642816e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1016881465911865\n",
      "      kl: 0.02670258656144142\n",
      "      policy_loss: -0.009520978666841984\n",
      "      total_loss: 788.393310546875\n",
      "      vf_explained_var: 0.9511154294013977\n",
      "      vf_loss: 788.40283203125\n",
      "    sample_time_ms: 18455.528\n",
      "    update_time_ms: 5.173\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.3846528271931\n",
      "  time_since_restore: 10054.097549676895\n",
      "  time_this_iter_s: 23.00402021408081\n",
      "  time_total_s: 10054.097549676895\n",
      "  timestamp: 1553719079\n",
      "  timesteps_since_restore: 3850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3850000\n",
      "  training_iteration: 385\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10054 s, 385 iter, 3850000 ts, 605 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-38-22\n",
      "  done: false\n",
      "  episode_len_mean: 129.1\n",
      "  episode_reward_max: 782.5592957569365\n",
      "  episode_reward_mean: 572.3014165910049\n",
      "  episode_reward_min: -130.12208430425983\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 28305\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.284\n",
      "    load_time_ms: 1.719\n",
      "    num_steps_sampled: 3860000\n",
      "    num_steps_trained: 3860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0708932879642816e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1538907289505005\n",
      "      kl: 0.01993066444993019\n",
      "      policy_loss: -0.003460436360910535\n",
      "      total_loss: 845.3212280273438\n",
      "      vf_explained_var: 0.9415053129196167\n",
      "      vf_loss: 845.32470703125\n",
      "    sample_time_ms: 18588.456\n",
      "    update_time_ms: 5.417\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 286.15070829550245\n",
      "  time_since_restore: 10076.926035404205\n",
      "  time_this_iter_s: 22.82848572731018\n",
      "  time_total_s: 10076.926035404205\n",
      "  timestamp: 1553719102\n",
      "  timesteps_since_restore: 3860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3860000\n",
      "  training_iteration: 386\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10076 s, 386 iter, 3860000 ts, 572 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-38-44\n",
      "  done: false\n",
      "  episode_len_mean: 137.86\n",
      "  episode_reward_max: 773.5810512167801\n",
      "  episode_reward_mean: 637.4075374004566\n",
      "  episode_reward_min: -111.11257618143419\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 28378\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.105\n",
      "    load_time_ms: 1.667\n",
      "    num_steps_sampled: 3870000\n",
      "    num_steps_trained: 3870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0708932879642816e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1723687648773193\n",
      "      kl: 0.008832124061882496\n",
      "      policy_loss: -0.0009737685322761536\n",
      "      total_loss: 390.58660888671875\n",
      "      vf_explained_var: 0.9686669707298279\n",
      "      vf_loss: 390.58758544921875\n",
      "    sample_time_ms: 18610.586\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 318.70376870022824\n",
      "  time_since_restore: 10099.507992506027\n",
      "  time_this_iter_s: 22.5819571018219\n",
      "  time_total_s: 10099.507992506027\n",
      "  timestamp: 1553719124\n",
      "  timesteps_since_restore: 3870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3870000\n",
      "  training_iteration: 387\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10099 s, 387 iter, 3870000 ts, 637 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-39-06\n",
      "  done: false\n",
      "  episode_len_mean: 142.58\n",
      "  episode_reward_max: 789.5581248494736\n",
      "  episode_reward_mean: 669.2639498374219\n",
      "  episode_reward_min: -100.52667114466301\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 28448\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3795.906\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 3880000\n",
      "    num_steps_trained: 3880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0354466439821408e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1767698526382446\n",
      "      kl: 0.018119683489203453\n",
      "      policy_loss: -0.0030563746113330126\n",
      "      total_loss: 436.32220458984375\n",
      "      vf_explained_var: 0.9641267657279968\n",
      "      vf_loss: 436.3253173828125\n",
      "    sample_time_ms: 18621.949\n",
      "    update_time_ms: 5.568\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.6319749187111\n",
      "  time_since_restore: 10121.609256029129\n",
      "  time_this_iter_s: 22.101263523101807\n",
      "  time_total_s: 10121.609256029129\n",
      "  timestamp: 1553719146\n",
      "  timesteps_since_restore: 3880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3880000\n",
      "  training_iteration: 388\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10121 s, 388 iter, 3880000 ts, 669 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-39-29\n",
      "  done: false\n",
      "  episode_len_mean: 136.31\n",
      "  episode_reward_max: 777.8014882230678\n",
      "  episode_reward_mean: 623.2106510523213\n",
      "  episode_reward_min: -104.62958933205626\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 28523\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3793.597\n",
      "    load_time_ms: 1.691\n",
      "    num_steps_sampled: 3890000\n",
      "    num_steps_trained: 3890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0354466439821408e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1453056335449219\n",
      "      kl: 0.013799059204757214\n",
      "      policy_loss: -0.0028645996935665607\n",
      "      total_loss: 826.0820922851562\n",
      "      vf_explained_var: 0.9376449584960938\n",
      "      vf_loss: 826.0849609375\n",
      "    sample_time_ms: 18685.529\n",
      "    update_time_ms: 5.394\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 311.60532552616064\n",
      "  time_since_restore: 10144.466578722\n",
      "  time_this_iter_s: 22.857322692871094\n",
      "  time_total_s: 10144.466578722\n",
      "  timestamp: 1553719169\n",
      "  timesteps_since_restore: 3890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3890000\n",
      "  training_iteration: 389\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10144 s, 389 iter, 3890000 ts, 623 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-39-52\n",
      "  done: false\n",
      "  episode_len_mean: 138.68\n",
      "  episode_reward_max: 777.8014882230678\n",
      "  episode_reward_mean: 632.8023173639052\n",
      "  episode_reward_min: -115.40082313095239\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 28596\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.401\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 3900000\n",
      "    num_steps_trained: 3900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0354466439821408e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1661397218704224\n",
      "      kl: 0.013620440848171711\n",
      "      policy_loss: -0.0046837590634822845\n",
      "      total_loss: 355.15399169921875\n",
      "      vf_explained_var: 0.9746942520141602\n",
      "      vf_loss: 355.15869140625\n",
      "    sample_time_ms: 18715.438\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.40115868195255\n",
      "  time_since_restore: 10166.899409294128\n",
      "  time_this_iter_s: 22.432830572128296\n",
      "  time_total_s: 10166.899409294128\n",
      "  timestamp: 1553719192\n",
      "  timesteps_since_restore: 3900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3900000\n",
      "  training_iteration: 390\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10166 s, 390 iter, 3900000 ts, 633 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 143.74\n",
      "  episode_reward_max: 781.9192320903286\n",
      "  episode_reward_mean: 676.1463956948614\n",
      "  episode_reward_min: -131.9299699807026\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 28666\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3806.557\n",
      "    load_time_ms: 1.701\n",
      "    num_steps_sampled: 3910000\n",
      "    num_steps_trained: 3910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0354466439821408e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1740566492080688\n",
      "      kl: 0.009602378122508526\n",
      "      policy_loss: -0.001271450542844832\n",
      "      total_loss: 419.41424560546875\n",
      "      vf_explained_var: 0.9629924297332764\n",
      "      vf_loss: 419.41552734375\n",
      "    sample_time_ms: 18761.964\n",
      "    update_time_ms: 5.303\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.0731978474308\n",
      "  time_since_restore: 10189.506673812866\n",
      "  time_this_iter_s: 22.607264518737793\n",
      "  time_total_s: 10189.506673812866\n",
      "  timestamp: 1553719214\n",
      "  timesteps_since_restore: 3910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3910000\n",
      "  training_iteration: 391\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10189 s, 391 iter, 3910000 ts, 676 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-40-37\n",
      "  done: false\n",
      "  episode_len_mean: 139.83\n",
      "  episode_reward_max: 768.4178136959342\n",
      "  episode_reward_mean: 640.5222429317778\n",
      "  episode_reward_min: -124.78517875697742\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 28739\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3805.634\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 3920000\n",
      "    num_steps_trained: 3920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.177233219910704e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.110895037651062\n",
      "      kl: 0.010374847799539566\n",
      "      policy_loss: -0.0014039339730516076\n",
      "      total_loss: 181.69276428222656\n",
      "      vf_explained_var: 0.9865754842758179\n",
      "      vf_loss: 181.6941680908203\n",
      "    sample_time_ms: 18757.506\n",
      "    update_time_ms: 5.399\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.2611214658889\n",
      "  time_since_restore: 10211.970156908035\n",
      "  time_this_iter_s: 22.463483095169067\n",
      "  time_total_s: 10211.970156908035\n",
      "  timestamp: 1553719237\n",
      "  timesteps_since_restore: 3920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3920000\n",
      "  training_iteration: 392\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10211 s, 392 iter, 3920000 ts, 641 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-40-59\n",
      "  done: false\n",
      "  episode_len_mean: 138.68\n",
      "  episode_reward_max: 768.5280627092884\n",
      "  episode_reward_mean: 645.6478302394627\n",
      "  episode_reward_min: -125.36499568526563\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 28813\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3805.085\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 3930000\n",
      "    num_steps_trained: 3930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.177233219910704e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1121752262115479\n",
      "      kl: 0.019405759871006012\n",
      "      policy_loss: -0.0013604667037725449\n",
      "      total_loss: 291.59454345703125\n",
      "      vf_explained_var: 0.9771620035171509\n",
      "      vf_loss: 291.5959167480469\n",
      "    sample_time_ms: 18760.987\n",
      "    update_time_ms: 5.308\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 322.8239151197314\n",
      "  time_since_restore: 10234.446447610855\n",
      "  time_this_iter_s: 22.476290702819824\n",
      "  time_total_s: 10234.446447610855\n",
      "  timestamp: 1553719259\n",
      "  timesteps_since_restore: 3930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3930000\n",
      "  training_iteration: 393\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10234 s, 393 iter, 3930000 ts, 646 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-41-22\n",
      "  done: false\n",
      "  episode_len_mean: 144.41\n",
      "  episode_reward_max: 771.9138532363065\n",
      "  episode_reward_mean: 696.8659920399249\n",
      "  episode_reward_min: 367.52698933423017\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 28882\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3810.646\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 3940000\n",
      "    num_steps_trained: 3940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.177233219910704e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1688143014907837\n",
      "      kl: 0.012648159638047218\n",
      "      policy_loss: -0.005090733990073204\n",
      "      total_loss: 38.12315368652344\n",
      "      vf_explained_var: 0.9966307282447815\n",
      "      vf_loss: 38.12824249267578\n",
      "    sample_time_ms: 18715.343\n",
      "    update_time_ms: 5.303\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.4329960199625\n",
      "  time_since_restore: 10256.605598449707\n",
      "  time_this_iter_s: 22.15915083885193\n",
      "  time_total_s: 10256.605598449707\n",
      "  timestamp: 1553719282\n",
      "  timesteps_since_restore: 3940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3940000\n",
      "  training_iteration: 394\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10256 s, 394 iter, 3940000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-41-44\n",
      "  done: false\n",
      "  episode_len_mean: 142.89\n",
      "  episode_reward_max: 766.6957875928339\n",
      "  episode_reward_mean: 677.7403276680998\n",
      "  episode_reward_min: -97.2591654937175\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 28953\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3811.938\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 3950000\n",
      "    num_steps_trained: 3950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.177233219910704e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.185111165046692\n",
      "      kl: 0.01175888255238533\n",
      "      policy_loss: 6.835124077042565e-05\n",
      "      total_loss: 238.2890167236328\n",
      "      vf_explained_var: 0.9811775088310242\n",
      "      vf_loss: 238.28895568847656\n",
      "    sample_time_ms: 18643.005\n",
      "    update_time_ms: 5.335\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.8701638340499\n",
      "  time_since_restore: 10278.900113582611\n",
      "  time_this_iter_s: 22.294515132904053\n",
      "  time_total_s: 10278.900113582611\n",
      "  timestamp: 1553719304\n",
      "  timesteps_since_restore: 3950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3950000\n",
      "  training_iteration: 395\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10278 s, 395 iter, 3950000 ts, 678 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-42-06\n",
      "  done: false\n",
      "  episode_len_mean: 134.99\n",
      "  episode_reward_max: 766.6957875928339\n",
      "  episode_reward_mean: 605.1566973450775\n",
      "  episode_reward_min: -118.14377367885962\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 29028\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3816.322\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 3960000\n",
      "    num_steps_trained: 3960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.177233219910704e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1280730962753296\n",
      "      kl: 0.011448662728071213\n",
      "      policy_loss: -0.0008997748955152929\n",
      "      total_loss: 564.5302734375\n",
      "      vf_explained_var: 0.9596307277679443\n",
      "      vf_loss: 564.5311279296875\n",
      "    sample_time_ms: 18587.867\n",
      "    update_time_ms: 5.119\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 302.57834867253877\n",
      "  time_since_restore: 10301.216108560562\n",
      "  time_this_iter_s: 22.31599497795105\n",
      "  time_total_s: 10301.216108560562\n",
      "  timestamp: 1553719326\n",
      "  timesteps_since_restore: 3960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3960000\n",
      "  training_iteration: 396\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10301 s, 396 iter, 3960000 ts, 605 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-42-29\n",
      "  done: false\n",
      "  episode_len_mean: 143.76\n",
      "  episode_reward_max: 774.342010189587\n",
      "  episode_reward_mean: 687.377591620621\n",
      "  episode_reward_min: -19.823621851453566\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 29098\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3815.131\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 3970000\n",
      "    num_steps_trained: 3970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.177233219910704e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1623897552490234\n",
      "      kl: 0.01749851368367672\n",
      "      policy_loss: -0.004866131115704775\n",
      "      total_loss: 224.2516326904297\n",
      "      vf_explained_var: 0.9797731041908264\n",
      "      vf_loss: 224.25648498535156\n",
      "    sample_time_ms: 18554.299\n",
      "    update_time_ms: 5.203\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.68879581031047\n",
      "  time_since_restore: 10323.45239830017\n",
      "  time_this_iter_s: 22.236289739608765\n",
      "  time_total_s: 10323.45239830017\n",
      "  timestamp: 1553719349\n",
      "  timesteps_since_restore: 3970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3970000\n",
      "  training_iteration: 397\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10323 s, 397 iter, 3970000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-42-51\n",
      "  done: false\n",
      "  episode_len_mean: 140.67\n",
      "  episode_reward_max: 774.342010189587\n",
      "  episode_reward_mean: 664.2279653220306\n",
      "  episode_reward_min: -104.5868511396922\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 29170\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3810.122\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 3980000\n",
      "    num_steps_trained: 3980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.177233219910704e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1538219451904297\n",
      "      kl: 0.01865476742386818\n",
      "      policy_loss: -0.003592349123209715\n",
      "      total_loss: 343.9639587402344\n",
      "      vf_explained_var: 0.9715496897697449\n",
      "      vf_loss: 343.967529296875\n",
      "    sample_time_ms: 18586.978\n",
      "    update_time_ms: 5.014\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 332.1139826610153\n",
      "  time_since_restore: 10345.829336166382\n",
      "  time_this_iter_s: 22.376937866210938\n",
      "  time_total_s: 10345.829336166382\n",
      "  timestamp: 1553719371\n",
      "  timesteps_since_restore: 3980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3980000\n",
      "  training_iteration: 398\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10345 s, 398 iter, 3980000 ts, 664 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-43-13\n",
      "  done: false\n",
      "  episode_len_mean: 141.37\n",
      "  episode_reward_max: 757.282680289128\n",
      "  episode_reward_mean: 662.1240927101695\n",
      "  episode_reward_min: -104.5868511396922\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 29240\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3823.446\n",
      "    load_time_ms: 1.596\n",
      "    num_steps_sampled: 3990000\n",
      "    num_steps_trained: 3990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.177233219910704e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1527154445648193\n",
      "      kl: 0.04124130308628082\n",
      "      policy_loss: -0.0005417804350145161\n",
      "      total_loss: 368.37030029296875\n",
      "      vf_explained_var: 0.9679060578346252\n",
      "      vf_loss: 368.3708190917969\n",
      "    sample_time_ms: 18520.013\n",
      "    update_time_ms: 4.949\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 331.06204635508476\n",
      "  time_since_restore: 10368.152143478394\n",
      "  time_this_iter_s: 22.32280731201172\n",
      "  time_total_s: 10368.152143478394\n",
      "  timestamp: 1553719393\n",
      "  timesteps_since_restore: 3990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3990000\n",
      "  training_iteration: 399\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10368 s, 399 iter, 3990000 ts, 662 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-43-36\n",
      "  done: false\n",
      "  episode_len_mean: 133.57\n",
      "  episode_reward_max: 772.0799888885314\n",
      "  episode_reward_mean: 591.4700756032751\n",
      "  episode_reward_min: -106.72778284987592\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 29317\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3823.8\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 4000000\n",
      "    num_steps_trained: 4000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.765848977214773e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1064845323562622\n",
      "      kl: 0.014732561074197292\n",
      "      policy_loss: -0.0027824859134852886\n",
      "      total_loss: 650.2091064453125\n",
      "      vf_explained_var: 0.9550905227661133\n",
      "      vf_loss: 650.2119140625\n",
      "    sample_time_ms: 18579.623\n",
      "    update_time_ms: 5.015\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 295.73503780163753\n",
      "  time_since_restore: 10391.181829452515\n",
      "  time_this_iter_s: 23.029685974121094\n",
      "  time_total_s: 10391.181829452515\n",
      "  timestamp: 1553719416\n",
      "  timesteps_since_restore: 4000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4000000\n",
      "  training_iteration: 400\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10391 s, 400 iter, 4000000 ts, 591 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-43-59\n",
      "  done: false\n",
      "  episode_len_mean: 137.93\n",
      "  episode_reward_max: 786.9852453646043\n",
      "  episode_reward_mean: 629.2173411095229\n",
      "  episode_reward_min: -127.41669794391345\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 29391\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3806.3\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 4010000\n",
      "    num_steps_trained: 4010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.765848977214773e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1048877239227295\n",
      "      kl: 0.040851276367902756\n",
      "      policy_loss: 0.0036028975155204535\n",
      "      total_loss: 360.02239990234375\n",
      "      vf_explained_var: 0.9734681248664856\n",
      "      vf_loss: 360.0188293457031\n",
      "    sample_time_ms: 18603.666\n",
      "    update_time_ms: 5.072\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 314.60867055476143\n",
      "  time_since_restore: 10413.857060909271\n",
      "  time_this_iter_s: 22.675231456756592\n",
      "  time_total_s: 10413.857060909271\n",
      "  timestamp: 1553719439\n",
      "  timesteps_since_restore: 4010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4010000\n",
      "  training_iteration: 401\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10413 s, 401 iter, 4010000 ts, 629 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-44-21\n",
      "  done: false\n",
      "  episode_len_mean: 141.86\n",
      "  episode_reward_max: 786.9852453646043\n",
      "  episode_reward_mean: 668.655898896388\n",
      "  episode_reward_min: -85.95594846578867\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 29462\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3809.087\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 4020000\n",
      "    num_steps_trained: 4020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1648774034256348e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1223300695419312\n",
      "      kl: 0.009817318990826607\n",
      "      policy_loss: -0.003926610108464956\n",
      "      total_loss: 329.3843078613281\n",
      "      vf_explained_var: 0.9726307988166809\n",
      "      vf_loss: 329.3882141113281\n",
      "    sample_time_ms: 18549.844\n",
      "    update_time_ms: 5.028\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.327949448194\n",
      "  time_since_restore: 10435.809916257858\n",
      "  time_this_iter_s: 21.952855348587036\n",
      "  time_total_s: 10435.809916257858\n",
      "  timestamp: 1553719461\n",
      "  timesteps_since_restore: 4020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4020000\n",
      "  training_iteration: 402\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10435 s, 402 iter, 4020000 ts, 669 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-44-43\n",
      "  done: false\n",
      "  episode_len_mean: 139.24\n",
      "  episode_reward_max: 777.9541736353938\n",
      "  episode_reward_mean: 649.1985787404351\n",
      "  episode_reward_min: -115.52412273704391\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 29535\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3833.125\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 4030000\n",
      "    num_steps_trained: 4030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1026124954223633\n",
      "      kl: 0.013833791948854923\n",
      "      policy_loss: -0.0041298340074718\n",
      "      total_loss: 320.2345886230469\n",
      "      vf_explained_var: 0.9733788967132568\n",
      "      vf_loss: 320.2387390136719\n",
      "    sample_time_ms: 18461.056\n",
      "    update_time_ms: 5.215\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.5992893702175\n",
      "  time_since_restore: 10457.639990568161\n",
      "  time_this_iter_s: 21.830074310302734\n",
      "  time_total_s: 10457.639990568161\n",
      "  timestamp: 1553719483\n",
      "  timesteps_since_restore: 4030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4030000\n",
      "  training_iteration: 403\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10457 s, 403 iter, 4030000 ts, 649 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-45-05\n",
      "  done: false\n",
      "  episode_len_mean: 137.94\n",
      "  episode_reward_max: 778.6598839472374\n",
      "  episode_reward_mean: 638.6384563881343\n",
      "  episode_reward_min: -135.87417256556944\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 29608\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3825.922\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 4040000\n",
      "    num_steps_trained: 4040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1452280282974243\n",
      "      kl: 0.01614513248205185\n",
      "      policy_loss: -0.004778653383255005\n",
      "      total_loss: 690.2137451171875\n",
      "      vf_explained_var: 0.946349024772644\n",
      "      vf_loss: 690.2184448242188\n",
      "    sample_time_ms: 18435.784\n",
      "    update_time_ms: 5.266\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 319.31922819406714\n",
      "  time_since_restore: 10479.471470355988\n",
      "  time_this_iter_s: 21.831479787826538\n",
      "  time_total_s: 10479.471470355988\n",
      "  timestamp: 1553719505\n",
      "  timesteps_since_restore: 4040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4040000\n",
      "  training_iteration: 404\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10479 s, 404 iter, 4040000 ts, 639 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-45-27\n",
      "  done: false\n",
      "  episode_len_mean: 140.53\n",
      "  episode_reward_max: 778.6598839472374\n",
      "  episode_reward_mean: 663.7400236722248\n",
      "  episode_reward_min: -123.72379819754946\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 29681\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3821.621\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 4050000\n",
      "    num_steps_trained: 4050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0821901559829712\n",
      "      kl: 0.014293516054749489\n",
      "      policy_loss: -0.0019250845070928335\n",
      "      total_loss: 268.0931701660156\n",
      "      vf_explained_var: 0.9768218994140625\n",
      "      vf_loss: 268.0950927734375\n",
      "    sample_time_ms: 18470.79\n",
      "    update_time_ms: 5.319\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 331.87001183611227\n",
      "  time_since_restore: 10502.074809551239\n",
      "  time_this_iter_s: 22.603339195251465\n",
      "  time_total_s: 10502.074809551239\n",
      "  timestamp: 1553719527\n",
      "  timesteps_since_restore: 4050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4050000\n",
      "  training_iteration: 405\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10502 s, 405 iter, 4050000 ts, 664 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-45-49\n",
      "  done: false\n",
      "  episode_len_mean: 137.52\n",
      "  episode_reward_max: 797.0614642990278\n",
      "  episode_reward_mean: 635.4658631286239\n",
      "  episode_reward_min: -116.96454968551768\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 29754\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3818.748\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 4060000\n",
      "    num_steps_trained: 4060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1212981939315796\n",
      "      kl: 0.022867530584335327\n",
      "      policy_loss: -0.006238540168851614\n",
      "      total_loss: 464.23828125\n",
      "      vf_explained_var: 0.964635968208313\n",
      "      vf_loss: 464.2445373535156\n",
      "    sample_time_ms: 18417.942\n",
      "    update_time_ms: 5.258\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 317.73293156431197\n",
      "  time_since_restore: 10523.834490299225\n",
      "  time_this_iter_s: 21.75968074798584\n",
      "  time_total_s: 10523.834490299225\n",
      "  timestamp: 1553719549\n",
      "  timesteps_since_restore: 4060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4060000\n",
      "  training_iteration: 406\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10523 s, 406 iter, 4060000 ts, 635 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-46-12\n",
      "  done: false\n",
      "  episode_len_mean: 137.91\n",
      "  episode_reward_max: 780.7514411697582\n",
      "  episode_reward_mean: 643.0829151341359\n",
      "  episode_reward_min: -120.26602228786906\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 29829\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3823.28\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 4070000\n",
      "    num_steps_trained: 4070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0940741300582886\n",
      "      kl: 0.01199251413345337\n",
      "      policy_loss: -0.0025340793654322624\n",
      "      total_loss: 316.9797668457031\n",
      "      vf_explained_var: 0.9775983095169067\n",
      "      vf_loss: 316.9822692871094\n",
      "    sample_time_ms: 18415.006\n",
      "    update_time_ms: 5.222\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 321.54145756706794\n",
      "  time_since_restore: 10546.091825723648\n",
      "  time_this_iter_s: 22.257335424423218\n",
      "  time_total_s: 10546.091825723648\n",
      "  timestamp: 1553719572\n",
      "  timesteps_since_restore: 4070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4070000\n",
      "  training_iteration: 407\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10546 s, 407 iter, 4070000 ts, 643 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-46-34\n",
      "  done: false\n",
      "  episode_len_mean: 141.7\n",
      "  episode_reward_max: 774.6824734538407\n",
      "  episode_reward_mean: 681.5573484325819\n",
      "  episode_reward_min: -115.96539477370395\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 29900\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3823.93\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 4080000\n",
      "    num_steps_trained: 4080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0975840091705322\n",
      "      kl: 0.015275154262781143\n",
      "      policy_loss: -0.000807137053925544\n",
      "      total_loss: 24.774076461791992\n",
      "      vf_explained_var: 0.998183012008667\n",
      "      vf_loss: 24.77488136291504\n",
      "    sample_time_ms: 18392.539\n",
      "    update_time_ms: 5.293\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.7786742162909\n",
      "  time_since_restore: 10568.25383591652\n",
      "  time_this_iter_s: 22.162010192871094\n",
      "  time_total_s: 10568.25383591652\n",
      "  timestamp: 1553719594\n",
      "  timesteps_since_restore: 4080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4080000\n",
      "  training_iteration: 408\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10568 s, 408 iter, 4080000 ts, 682 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-46-56\n",
      "  done: false\n",
      "  episode_len_mean: 142.63\n",
      "  episode_reward_max: 778.1170777197858\n",
      "  episode_reward_mean: 684.887370187389\n",
      "  episode_reward_min: -59.70262250185431\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 29971\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3812.225\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 4090000\n",
      "    num_steps_trained: 4090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1547949314117432\n",
      "      kl: 0.012475897558033466\n",
      "      policy_loss: -0.002457078779116273\n",
      "      total_loss: 270.123779296875\n",
      "      vf_explained_var: 0.9784039258956909\n",
      "      vf_loss: 270.1262512207031\n",
      "    sample_time_ms: 18402.848\n",
      "    update_time_ms: 5.474\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.44368509369457\n",
      "  time_since_restore: 10590.562557458878\n",
      "  time_this_iter_s: 22.3087215423584\n",
      "  time_total_s: 10590.562557458878\n",
      "  timestamp: 1553719616\n",
      "  timesteps_since_restore: 4090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4090000\n",
      "  training_iteration: 409\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10590 s, 409 iter, 4090000 ts, 685 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-47-18\n",
      "  done: false\n",
      "  episode_len_mean: 139.5\n",
      "  episode_reward_max: 787.7101605915451\n",
      "  episode_reward_mean: 650.9760012571237\n",
      "  episode_reward_min: -121.76980138339812\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 30044\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3809.478\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 4100000\n",
      "    num_steps_trained: 4100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1160086393356323\n",
      "      kl: 0.013915124349296093\n",
      "      policy_loss: -0.004142198245972395\n",
      "      total_loss: 261.9056091308594\n",
      "      vf_explained_var: 0.9796330332756042\n",
      "      vf_loss: 261.9097900390625\n",
      "    sample_time_ms: 18329.301\n",
      "    update_time_ms: 5.547\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 325.48800062856185\n",
      "  time_since_restore: 10612.829598903656\n",
      "  time_this_iter_s: 22.267041444778442\n",
      "  time_total_s: 10612.829598903656\n",
      "  timestamp: 1553719638\n",
      "  timesteps_since_restore: 4100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4100000\n",
      "  training_iteration: 410\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10612 s, 410 iter, 4100000 ts, 651 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-47-41\n",
      "  done: false\n",
      "  episode_len_mean: 143.15\n",
      "  episode_reward_max: 787.7101605915451\n",
      "  episode_reward_mean: 680.0045623618726\n",
      "  episode_reward_min: -118.54069451773482\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 30114\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3808.928\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 4110000\n",
      "    num_steps_trained: 4110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0970412492752075\n",
      "      kl: 0.017724603414535522\n",
      "      policy_loss: -0.00314121856354177\n",
      "      total_loss: 527.4729614257812\n",
      "      vf_explained_var: 0.9544875025749207\n",
      "      vf_loss: 527.4761352539062\n",
      "    sample_time_ms: 18300.399\n",
      "    update_time_ms: 5.503\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.0022811809363\n",
      "  time_since_restore: 10635.210118055344\n",
      "  time_this_iter_s: 22.380519151687622\n",
      "  time_total_s: 10635.210118055344\n",
      "  timestamp: 1553719661\n",
      "  timesteps_since_restore: 4110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4110000\n",
      "  training_iteration: 411\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10635 s, 411 iter, 4110000 ts, 680 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-48-03\n",
      "  done: false\n",
      "  episode_len_mean: 139.1\n",
      "  episode_reward_max: 779.418797330861\n",
      "  episode_reward_mean: 645.4239869930537\n",
      "  episode_reward_min: -101.75117177962578\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 30187\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3809.085\n",
      "    load_time_ms: 1.583\n",
      "    num_steps_sampled: 4120000\n",
      "    num_steps_trained: 4120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.18071711063385\n",
      "      kl: 0.03990006446838379\n",
      "      policy_loss: -0.006470778025686741\n",
      "      total_loss: 1143.4898681640625\n",
      "      vf_explained_var: 0.9053882956504822\n",
      "      vf_loss: 1143.496337890625\n",
      "    sample_time_ms: 18308.263\n",
      "    update_time_ms: 5.537\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 322.7119934965269\n",
      "  time_since_restore: 10657.239823102951\n",
      "  time_this_iter_s: 22.029705047607422\n",
      "  time_total_s: 10657.239823102951\n",
      "  timestamp: 1553719683\n",
      "  timesteps_since_restore: 4120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4120000\n",
      "  training_iteration: 412\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10657 s, 412 iter, 4120000 ts, 645 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-48-25\n",
      "  done: false\n",
      "  episode_len_mean: 141.1\n",
      "  episode_reward_max: 776.3053640688486\n",
      "  episode_reward_mean: 658.8197331765384\n",
      "  episode_reward_min: -135.43273821043482\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 30258\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3783.617\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 4130000\n",
      "    num_steps_trained: 4130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1479778289794922\n",
      "      kl: 0.02441413514316082\n",
      "      policy_loss: -0.0034343195147812366\n",
      "      total_loss: 340.3747863769531\n",
      "      vf_explained_var: 0.972084641456604\n",
      "      vf_loss: 340.37823486328125\n",
      "    sample_time_ms: 18364.23\n",
      "    update_time_ms: 5.508\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 329.40986658826915\n",
      "  time_since_restore: 10679.374567270279\n",
      "  time_this_iter_s: 22.13474416732788\n",
      "  time_total_s: 10679.374567270279\n",
      "  timestamp: 1553719705\n",
      "  timesteps_since_restore: 4130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4130000\n",
      "  training_iteration: 413\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10679 s, 413 iter, 4130000 ts, 659 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-48-48\n",
      "  done: false\n",
      "  episode_len_mean: 138.54\n",
      "  episode_reward_max: 781.8893125943109\n",
      "  episode_reward_mean: 627.3694281658727\n",
      "  episode_reward_min: -109.4420494755135\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 30332\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.896\n",
      "    load_time_ms: 1.665\n",
      "    num_steps_sampled: 4140000\n",
      "    num_steps_trained: 4140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1502211093902588\n",
      "      kl: 0.019997181370854378\n",
      "      policy_loss: -0.004073679447174072\n",
      "      total_loss: 330.83929443359375\n",
      "      vf_explained_var: 0.9760048985481262\n",
      "      vf_loss: 330.8433837890625\n",
      "    sample_time_ms: 18422.025\n",
      "    update_time_ms: 5.392\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 313.68471408293635\n",
      "  time_since_restore: 10701.809112548828\n",
      "  time_this_iter_s: 22.434545278549194\n",
      "  time_total_s: 10701.809112548828\n",
      "  timestamp: 1553719728\n",
      "  timesteps_since_restore: 4140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4140000\n",
      "  training_iteration: 414\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10701 s, 414 iter, 4140000 ts, 627 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-49-09\n",
      "  done: false\n",
      "  episode_len_mean: 142.27\n",
      "  episode_reward_max: 781.8893125943109\n",
      "  episode_reward_mean: 649.3919906123351\n",
      "  episode_reward_min: -96.7461875241204\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 30403\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3787.568\n",
      "    load_time_ms: 1.652\n",
      "    num_steps_sampled: 4150000\n",
      "    num_steps_trained: 4150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1393827199935913\n",
      "      kl: 0.026845373213291168\n",
      "      policy_loss: -0.003793168580159545\n",
      "      total_loss: 513.38623046875\n",
      "      vf_explained_var: 0.9590673446655273\n",
      "      vf_loss: 513.3899536132812\n",
      "    sample_time_ms: 18346.665\n",
      "    update_time_ms: 5.265\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.69599530616745\n",
      "  time_since_restore: 10723.672293663025\n",
      "  time_this_iter_s: 21.863181114196777\n",
      "  time_total_s: 10723.672293663025\n",
      "  timestamp: 1553719749\n",
      "  timesteps_since_restore: 4150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4150000\n",
      "  training_iteration: 415\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10723 s, 415 iter, 4150000 ts, 649 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-49-32\n",
      "  done: false\n",
      "  episode_len_mean: 141.54\n",
      "  episode_reward_max: 774.4929140447316\n",
      "  episode_reward_mean: 641.6155864283256\n",
      "  episode_reward_min: -129.11358267042826\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 30475\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3786.044\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 4160000\n",
      "    num_steps_trained: 4160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1348813772201538\n",
      "      kl: 0.010348023846745491\n",
      "      policy_loss: -0.0009233611635863781\n",
      "      total_loss: 311.126708984375\n",
      "      vf_explained_var: 0.9772151112556458\n",
      "      vf_loss: 311.12762451171875\n",
      "    sample_time_ms: 18437.699\n",
      "    update_time_ms: 5.326\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.8077932141628\n",
      "  time_since_restore: 10746.327080965042\n",
      "  time_this_iter_s: 22.654787302017212\n",
      "  time_total_s: 10746.327080965042\n",
      "  timestamp: 1553719772\n",
      "  timesteps_since_restore: 4160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4160000\n",
      "  training_iteration: 416\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10746 s, 416 iter, 4160000 ts, 642 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-49-55\n",
      "  done: false\n",
      "  episode_len_mean: 140.41\n",
      "  episode_reward_max: 783.6747418100305\n",
      "  episode_reward_mean: 624.8899649059671\n",
      "  episode_reward_min: -117.77789075434136\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 30548\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3782.505\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 4170000\n",
      "    num_steps_trained: 4170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0982576608657837\n",
      "      kl: 0.017015807330608368\n",
      "      policy_loss: -0.003841948928311467\n",
      "      total_loss: 262.1228332519531\n",
      "      vf_explained_var: 0.9806405305862427\n",
      "      vf_loss: 262.1266784667969\n",
      "    sample_time_ms: 18464.787\n",
      "    update_time_ms: 5.338\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.44498245298354\n",
      "  time_since_restore: 10768.812470436096\n",
      "  time_this_iter_s: 22.485389471054077\n",
      "  time_total_s: 10768.812470436096\n",
      "  timestamp: 1553719795\n",
      "  timesteps_since_restore: 4170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4170000\n",
      "  training_iteration: 417\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10768 s, 417 iter, 4170000 ts, 625 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-50-18\n",
      "  done: false\n",
      "  episode_len_mean: 146.13\n",
      "  episode_reward_max: 774.4939704896412\n",
      "  episode_reward_mean: 673.313990383091\n",
      "  episode_reward_min: -61.48706375332074\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 30617\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3784.984\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 4180000\n",
      "    num_steps_trained: 4180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1129204034805298\n",
      "      kl: 0.02203778363764286\n",
      "      policy_loss: -0.0036876308731734753\n",
      "      total_loss: 429.533447265625\n",
      "      vf_explained_var: 0.9626940488815308\n",
      "      vf_loss: 429.537109375\n",
      "    sample_time_ms: 18529.586\n",
      "    update_time_ms: 5.319\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.6569951915455\n",
      "  time_since_restore: 10791.644757509232\n",
      "  time_this_iter_s: 22.832287073135376\n",
      "  time_total_s: 10791.644757509232\n",
      "  timestamp: 1553719818\n",
      "  timesteps_since_restore: 4180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4180000\n",
      "  training_iteration: 418\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10791 s, 418 iter, 4180000 ts, 673 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-50-40\n",
      "  done: false\n",
      "  episode_len_mean: 139.51\n",
      "  episode_reward_max: 771.4570177679633\n",
      "  episode_reward_mean: 632.7574646856651\n",
      "  episode_reward_min: -116.73861969431827\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 30690\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3783.652\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 4190000\n",
      "    num_steps_trained: 4190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1126333475112915\n",
      "      kl: 0.01937919855117798\n",
      "      policy_loss: -0.001806130399927497\n",
      "      total_loss: 552.9793701171875\n",
      "      vf_explained_var: 0.9567758440971375\n",
      "      vf_loss: 552.9811401367188\n",
      "    sample_time_ms: 18546.736\n",
      "    update_time_ms: 5.138\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.37873234283256\n",
      "  time_since_restore: 10814.107467889786\n",
      "  time_this_iter_s: 22.4627103805542\n",
      "  time_total_s: 10814.107467889786\n",
      "  timestamp: 1553719840\n",
      "  timesteps_since_restore: 4190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4190000\n",
      "  training_iteration: 419\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10814 s, 419 iter, 4190000 ts, 633 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-51-02\n",
      "  done: false\n",
      "  episode_len_mean: 144.52\n",
      "  episode_reward_max: 771.4570177679633\n",
      "  episode_reward_mean: 677.516724521856\n",
      "  episode_reward_min: -76.03125408289088\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 30758\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3787.169\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 4200000\n",
      "    num_steps_trained: 4200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0825780630111694\n",
      "      kl: 0.016495445743203163\n",
      "      policy_loss: -0.0020350085105746984\n",
      "      total_loss: 10.065459251403809\n",
      "      vf_explained_var: 0.9991215467453003\n",
      "      vf_loss: 10.067493438720703\n",
      "    sample_time_ms: 18517.855\n",
      "    update_time_ms: 5.133\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.758362260928\n",
      "  time_since_restore: 10836.122796535492\n",
      "  time_this_iter_s: 22.015328645706177\n",
      "  time_total_s: 10836.122796535492\n",
      "  timestamp: 1553719862\n",
      "  timesteps_since_restore: 4200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4200000\n",
      "  training_iteration: 420\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10836 s, 420 iter, 4200000 ts, 678 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-51-24\n",
      "  done: false\n",
      "  episode_len_mean: 143.12\n",
      "  episode_reward_max: 769.8610061746542\n",
      "  episode_reward_mean: 670.9503012052201\n",
      "  episode_reward_min: -90.67250091288126\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 30829\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3793.455\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 4210000\n",
      "    num_steps_trained: 4210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1046074628829956\n",
      "      kl: 0.01232778001576662\n",
      "      policy_loss: -0.0009009994682855904\n",
      "      total_loss: 118.70769500732422\n",
      "      vf_explained_var: 0.9912371635437012\n",
      "      vf_loss: 118.70861053466797\n",
      "    sample_time_ms: 18458.865\n",
      "    update_time_ms: 5.178\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 335.4751506026099\n",
      "  time_since_restore: 10857.976570367813\n",
      "  time_this_iter_s: 21.853773832321167\n",
      "  time_total_s: 10857.976570367813\n",
      "  timestamp: 1553719884\n",
      "  timesteps_since_restore: 4210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4210000\n",
      "  training_iteration: 421\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10857 s, 421 iter, 4210000 ts, 671 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-51-47\n",
      "  done: false\n",
      "  episode_len_mean: 146.21\n",
      "  episode_reward_max: 769.5482079880842\n",
      "  episode_reward_mean: 707.7495273709579\n",
      "  episode_reward_min: 653.3081681835696\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 30897\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3791.057\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 4220000\n",
      "    num_steps_trained: 4220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.106190800666809\n",
      "      kl: 0.017580626532435417\n",
      "      policy_loss: -0.0010263752192258835\n",
      "      total_loss: 48.36978530883789\n",
      "      vf_explained_var: 0.996871829032898\n",
      "      vf_loss: 48.370811462402344\n",
      "    sample_time_ms: 18512.484\n",
      "    update_time_ms: 5.421\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.87476368547897\n",
      "  time_since_restore: 10880.524170398712\n",
      "  time_this_iter_s: 22.547600030899048\n",
      "  time_total_s: 10880.524170398712\n",
      "  timestamp: 1553719907\n",
      "  timesteps_since_restore: 4220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4220000\n",
      "  training_iteration: 422\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10880 s, 422 iter, 4220000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-52-08\n",
      "  done: false\n",
      "  episode_len_mean: 140.89\n",
      "  episode_reward_max: 776.0199562561239\n",
      "  episode_reward_mean: 655.3160834600599\n",
      "  episode_reward_min: -98.8836965937456\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 30970\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.359\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 4230000\n",
      "    num_steps_trained: 4230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1286885738372803\n",
      "      kl: 0.02002527378499508\n",
      "      policy_loss: -0.0037435556296259165\n",
      "      total_loss: 95.55831146240234\n",
      "      vf_explained_var: 0.993893563747406\n",
      "      vf_loss: 95.56206512451172\n",
      "    sample_time_ms: 18416.261\n",
      "    update_time_ms: 5.333\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 327.6580417300298\n",
      "  time_since_restore: 10901.746869802475\n",
      "  time_this_iter_s: 21.222699403762817\n",
      "  time_total_s: 10901.746869802475\n",
      "  timestamp: 1553719928\n",
      "  timesteps_since_restore: 4230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4230000\n",
      "  training_iteration: 423\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10901 s, 423 iter, 4230000 ts, 655 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-52-30\n",
      "  done: false\n",
      "  episode_len_mean: 140.75\n",
      "  episode_reward_max: 776.0199562561239\n",
      "  episode_reward_mean: 645.9675280852792\n",
      "  episode_reward_min: -129.22956940895727\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 31042\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3792.879\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 4240000\n",
      "    num_steps_trained: 4240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.141244888305664\n",
      "      kl: 0.025373931974172592\n",
      "      policy_loss: -0.0017163517186418176\n",
      "      total_loss: 441.5952453613281\n",
      "      vf_explained_var: 0.9662714004516602\n",
      "      vf_loss: 441.5968933105469\n",
      "    sample_time_ms: 18385.143\n",
      "    update_time_ms: 5.372\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 322.9837640426395\n",
      "  time_since_restore: 10923.833793401718\n",
      "  time_this_iter_s: 22.086923599243164\n",
      "  time_total_s: 10923.833793401718\n",
      "  timestamp: 1553719950\n",
      "  timesteps_since_restore: 4240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4240000\n",
      "  training_iteration: 424\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10923 s, 424 iter, 4240000 ts, 646 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-52-52\n",
      "  done: false\n",
      "  episode_len_mean: 143.76\n",
      "  episode_reward_max: 766.4881358277794\n",
      "  episode_reward_mean: 668.3390808113809\n",
      "  episode_reward_min: -61.568978001049516\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 31112\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3789.492\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 4250000\n",
      "    num_steps_trained: 4250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1597644090652466\n",
      "      kl: 0.01144572626799345\n",
      "      policy_loss: -0.0004920302308164537\n",
      "      total_loss: 346.3229675292969\n",
      "      vf_explained_var: 0.9708447456359863\n",
      "      vf_loss: 346.3234558105469\n",
      "    sample_time_ms: 18448.947\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.1695404056903\n",
      "  time_since_restore: 10946.302441358566\n",
      "  time_this_iter_s: 22.468647956848145\n",
      "  time_total_s: 10946.302441358566\n",
      "  timestamp: 1553719972\n",
      "  timesteps_since_restore: 4250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4250000\n",
      "  training_iteration: 425\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10946 s, 425 iter, 4250000 ts, 668 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-53-15\n",
      "  done: false\n",
      "  episode_len_mean: 143.04\n",
      "  episode_reward_max: 778.0606833992213\n",
      "  episode_reward_mean: 671.5920634480638\n",
      "  episode_reward_min: -113.75724013996879\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 31184\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3797.06\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 4260000\n",
      "    num_steps_trained: 4260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1048955917358398\n",
      "      kl: 0.014190713874995708\n",
      "      policy_loss: -0.002205493627116084\n",
      "      total_loss: 379.78704833984375\n",
      "      vf_explained_var: 0.9701438546180725\n",
      "      vf_loss: 379.78924560546875\n",
      "    sample_time_ms: 18407.022\n",
      "    update_time_ms: 5.239\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 335.79603172403176\n",
      "  time_since_restore: 10968.613941907883\n",
      "  time_this_iter_s: 22.311500549316406\n",
      "  time_total_s: 10968.613941907883\n",
      "  timestamp: 1553719995\n",
      "  timesteps_since_restore: 4260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4260000\n",
      "  training_iteration: 426\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10968 s, 426 iter, 4260000 ts, 672 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-53-37\n",
      "  done: false\n",
      "  episode_len_mean: 141.39\n",
      "  episode_reward_max: 778.0606833992213\n",
      "  episode_reward_mean: 656.0099613890984\n",
      "  episode_reward_min: -117.57130716381914\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 31256\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3794.549\n",
      "    load_time_ms: 1.457\n",
      "    num_steps_sampled: 4270000\n",
      "    num_steps_trained: 4270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1118954420089722\n",
      "      kl: 0.015644503757357597\n",
      "      policy_loss: 0.0014444177504628897\n",
      "      total_loss: 219.07321166992188\n",
      "      vf_explained_var: 0.9835273623466492\n",
      "      vf_loss: 219.07176208496094\n",
      "    sample_time_ms: 18414.395\n",
      "    update_time_ms: 5.258\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 328.00498069454915\n",
      "  time_since_restore: 10991.148882865906\n",
      "  time_this_iter_s: 22.53494095802307\n",
      "  time_total_s: 10991.148882865906\n",
      "  timestamp: 1553720017\n",
      "  timesteps_since_restore: 4270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4270000\n",
      "  training_iteration: 427\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 10991 s, 427 iter, 4270000 ts, 656 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-54-00\n",
      "  done: false\n",
      "  episode_len_mean: 142.93\n",
      "  episode_reward_max: 768.2208620910752\n",
      "  episode_reward_mean: 676.5908264881618\n",
      "  episode_reward_min: -134.40908093448604\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 31326\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.094\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 4280000\n",
      "    num_steps_trained: 4280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1180261373519897\n",
      "      kl: 0.020345650613307953\n",
      "      policy_loss: -0.002418945077806711\n",
      "      total_loss: 489.482177734375\n",
      "      vf_explained_var: 0.9599876403808594\n",
      "      vf_loss: 489.484619140625\n",
      "    sample_time_ms: 18392.92\n",
      "    update_time_ms: 5.319\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.29541324408086\n",
      "  time_since_restore: 11013.783217430115\n",
      "  time_this_iter_s: 22.634334564208984\n",
      "  time_total_s: 11013.783217430115\n",
      "  timestamp: 1553720040\n",
      "  timesteps_since_restore: 4280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4280000\n",
      "  training_iteration: 428\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11013 s, 428 iter, 4280000 ts, 677 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-54-23\n",
      "  done: false\n",
      "  episode_len_mean: 142.84\n",
      "  episode_reward_max: 770.5988581954359\n",
      "  episode_reward_mean: 668.6613519656082\n",
      "  episode_reward_min: -127.6764137291072\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 31397\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3804.106\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 4290000\n",
      "    num_steps_trained: 4290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1119369268417358\n",
      "      kl: 0.019708123058080673\n",
      "      policy_loss: -0.002536034444347024\n",
      "      total_loss: 236.64913940429688\n",
      "      vf_explained_var: 0.9817714095115662\n",
      "      vf_loss: 236.65167236328125\n",
      "    sample_time_ms: 18427.741\n",
      "    update_time_ms: 5.31\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.3306759828041\n",
      "  time_since_restore: 11036.673068761826\n",
      "  time_this_iter_s: 22.889851331710815\n",
      "  time_total_s: 11036.673068761826\n",
      "  timestamp: 1553720063\n",
      "  timesteps_since_restore: 4290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4290000\n",
      "  training_iteration: 429\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11036 s, 429 iter, 4290000 ts, 669 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 144.5\n",
      "  episode_reward_max: 781.6535799822934\n",
      "  episode_reward_mean: 685.9985960380671\n",
      "  episode_reward_min: -74.32173661898862\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 31467\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3805.64\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 4300000\n",
      "    num_steps_trained: 4300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.059844732284546\n",
      "      kl: 0.021078327670693398\n",
      "      policy_loss: -0.005106727126985788\n",
      "      total_loss: 274.12469482421875\n",
      "      vf_explained_var: 0.9787451028823853\n",
      "      vf_loss: 274.1297912597656\n",
      "    sample_time_ms: 18489.999\n",
      "    update_time_ms: 5.234\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.9992980190336\n",
      "  time_since_restore: 11059.325100660324\n",
      "  time_this_iter_s: 22.652031898498535\n",
      "  time_total_s: 11059.325100660324\n",
      "  timestamp: 1553720086\n",
      "  timesteps_since_restore: 4300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4300000\n",
      "  training_iteration: 430\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11059 s, 430 iter, 4300000 ts, 686 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-55-08\n",
      "  done: false\n",
      "  episode_len_mean: 144.66\n",
      "  episode_reward_max: 788.6628707431436\n",
      "  episode_reward_mean: 677.496926501238\n",
      "  episode_reward_min: -84.50761469762867\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 31537\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.479\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 4310000\n",
      "    num_steps_trained: 4310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1014071702957153\n",
      "      kl: 0.013444607146084309\n",
      "      policy_loss: -0.0031202768441289663\n",
      "      total_loss: 525.690185546875\n",
      "      vf_explained_var: 0.9593133926391602\n",
      "      vf_loss: 525.6932373046875\n",
      "    sample_time_ms: 18541.265\n",
      "    update_time_ms: 5.289\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.7484632506191\n",
      "  time_since_restore: 11081.632522583008\n",
      "  time_this_iter_s: 22.307421922683716\n",
      "  time_total_s: 11081.632522583008\n",
      "  timestamp: 1553720108\n",
      "  timesteps_since_restore: 4310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4310000\n",
      "  training_iteration: 431\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11081 s, 431 iter, 4310000 ts, 677 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-55-31\n",
      "  done: false\n",
      "  episode_len_mean: 144.79\n",
      "  episode_reward_max: 773.5495824833876\n",
      "  episode_reward_mean: 670.5849889820265\n",
      "  episode_reward_min: -129.55250550859876\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 31606\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.221\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 4320000\n",
      "    num_steps_trained: 4320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1023123264312744\n",
      "      kl: 0.013669087551534176\n",
      "      policy_loss: -0.0011477366788312793\n",
      "      total_loss: 230.13206481933594\n",
      "      vf_explained_var: 0.9819958209991455\n",
      "      vf_loss: 230.13320922851562\n",
      "    sample_time_ms: 18537.532\n",
      "    update_time_ms: 5.083\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 335.2924944910134\n",
      "  time_since_restore: 11104.166793346405\n",
      "  time_this_iter_s: 22.534270763397217\n",
      "  time_total_s: 11104.166793346405\n",
      "  timestamp: 1553720131\n",
      "  timesteps_since_restore: 4320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4320000\n",
      "  training_iteration: 432\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11104 s, 432 iter, 4320000 ts, 671 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-55-53\n",
      "  done: false\n",
      "  episode_len_mean: 140.91\n",
      "  episode_reward_max: 773.5495824833876\n",
      "  episode_reward_mean: 655.0618373698543\n",
      "  episode_reward_min: -133.120303369592\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 31678\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3801.377\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 4330000\n",
      "    num_steps_trained: 4330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0805431604385376\n",
      "      kl: 0.01527487300336361\n",
      "      policy_loss: -0.0036439693067222834\n",
      "      total_loss: 480.9052429199219\n",
      "      vf_explained_var: 0.9618034362792969\n",
      "      vf_loss: 480.9088439941406\n",
      "    sample_time_ms: 18644.768\n",
      "    update_time_ms: 5.117\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 327.5309186849271\n",
      "  time_since_restore: 11126.45628118515\n",
      "  time_this_iter_s: 22.289487838745117\n",
      "  time_total_s: 11126.45628118515\n",
      "  timestamp: 1553720153\n",
      "  timesteps_since_restore: 4330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4330000\n",
      "  training_iteration: 433\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11126 s, 433 iter, 4330000 ts, 655 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-56-16\n",
      "  done: false\n",
      "  episode_len_mean: 145.74\n",
      "  episode_reward_max: 789.6126296492452\n",
      "  episode_reward_mean: 690.4704500551245\n",
      "  episode_reward_min: -100.63757471205288\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 31747\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3804.722\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 4340000\n",
      "    num_steps_trained: 4340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1042895317077637\n",
      "      kl: 0.0290142260491848\n",
      "      policy_loss: -0.005235627759248018\n",
      "      total_loss: 318.9993591308594\n",
      "      vf_explained_var: 0.9726736545562744\n",
      "      vf_loss: 319.0046081542969\n",
      "    sample_time_ms: 18717.692\n",
      "    update_time_ms: 5.193\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.23522502756225\n",
      "  time_since_restore: 11149.303908586502\n",
      "  time_this_iter_s: 22.84762740135193\n",
      "  time_total_s: 11149.303908586502\n",
      "  timestamp: 1553720176\n",
      "  timesteps_since_restore: 4340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4340000\n",
      "  training_iteration: 434\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11149 s, 434 iter, 4340000 ts, 690 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-56-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.11\n",
      "  episode_reward_max: 789.6126296492452\n",
      "  episode_reward_mean: 663.9637910327631\n",
      "  episode_reward_min: -117.79896421935271\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 31819\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3808.78\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 4350000\n",
      "    num_steps_trained: 4350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.058124303817749\n",
      "      kl: 0.014925059862434864\n",
      "      policy_loss: -0.0017368143890053034\n",
      "      total_loss: 378.7102966308594\n",
      "      vf_explained_var: 0.9709449410438538\n",
      "      vf_loss: 378.7120361328125\n",
      "    sample_time_ms: 18666.866\n",
      "    update_time_ms: 5.275\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 331.9818955163815\n",
      "  time_since_restore: 11171.308399438858\n",
      "  time_this_iter_s: 22.004490852355957\n",
      "  time_total_s: 11171.308399438858\n",
      "  timestamp: 1553720198\n",
      "  timesteps_since_restore: 4350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4350000\n",
      "  training_iteration: 435\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11171 s, 435 iter, 4350000 ts, 664 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-57-00\n",
      "  done: false\n",
      "  episode_len_mean: 144.44\n",
      "  episode_reward_max: 785.8638726444069\n",
      "  episode_reward_mean: 683.515005183889\n",
      "  episode_reward_min: -127.08709754276376\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 31889\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3801.513\n",
      "    load_time_ms: 1.656\n",
      "    num_steps_sampled: 4360000\n",
      "    num_steps_trained: 4360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0857518911361694\n",
      "      kl: 0.017543694004416466\n",
      "      policy_loss: -0.0020852149464190006\n",
      "      total_loss: 138.0252685546875\n",
      "      vf_explained_var: 0.9884912371635437\n",
      "      vf_loss: 138.02734375\n",
      "    sample_time_ms: 18693.671\n",
      "    update_time_ms: 5.38\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.75750259194444\n",
      "  time_since_restore: 11193.812376022339\n",
      "  time_this_iter_s: 22.503976583480835\n",
      "  time_total_s: 11193.812376022339\n",
      "  timestamp: 1553720220\n",
      "  timesteps_since_restore: 4360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4360000\n",
      "  training_iteration: 436\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11193 s, 436 iter, 4360000 ts, 684 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-57-22\n",
      "  done: false\n",
      "  episode_len_mean: 143.42\n",
      "  episode_reward_max: 767.677114054891\n",
      "  episode_reward_mean: 673.1512307771554\n",
      "  episode_reward_min: -127.6646025916139\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 31960\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3810.166\n",
      "    load_time_ms: 1.665\n",
      "    num_steps_sampled: 4370000\n",
      "    num_steps_trained: 4370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.06282639503479\n",
      "      kl: 0.01615019328892231\n",
      "      policy_loss: -0.0006640609935857356\n",
      "      total_loss: 60.147891998291016\n",
      "      vf_explained_var: 0.9956417679786682\n",
      "      vf_loss: 60.14855194091797\n",
      "    sample_time_ms: 18633.111\n",
      "    update_time_ms: 5.364\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.5756153885777\n",
      "  time_since_restore: 11215.827995300293\n",
      "  time_this_iter_s: 22.0156192779541\n",
      "  time_total_s: 11215.827995300293\n",
      "  timestamp: 1553720242\n",
      "  timesteps_since_restore: 4370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4370000\n",
      "  training_iteration: 437\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11215 s, 437 iter, 4370000 ts, 673 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-57-45\n",
      "  done: false\n",
      "  episode_len_mean: 145.62\n",
      "  episode_reward_max: 773.3937161074451\n",
      "  episode_reward_mean: 693.1175402910635\n",
      "  episode_reward_min: -137.47845635898364\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 32029\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3822.763\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 4380000\n",
      "    num_steps_trained: 4380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0713977813720703\n",
      "      kl: 0.01217093039304018\n",
      "      policy_loss: -0.0012440893333405256\n",
      "      total_loss: 89.5738754272461\n",
      "      vf_explained_var: 0.9925634860992432\n",
      "      vf_loss: 89.57511901855469\n",
      "    sample_time_ms: 18555.71\n",
      "    update_time_ms: 5.506\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.55877014553175\n",
      "  time_since_restore: 11237.815658807755\n",
      "  time_this_iter_s: 21.987663507461548\n",
      "  time_total_s: 11237.815658807755\n",
      "  timestamp: 1553720265\n",
      "  timesteps_since_restore: 4380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4380000\n",
      "  training_iteration: 438\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11237 s, 438 iter, 4380000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-58-07\n",
      "  done: false\n",
      "  episode_len_mean: 142.65\n",
      "  episode_reward_max: 773.3937161074451\n",
      "  episode_reward_mean: 662.9189100809796\n",
      "  episode_reward_min: -97.59561077364589\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 32100\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3814.858\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 4390000\n",
      "    num_steps_trained: 4390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0849688053131104\n",
      "      kl: 0.01302817277610302\n",
      "      policy_loss: -0.0037538898177444935\n",
      "      total_loss: 719.7752685546875\n",
      "      vf_explained_var: 0.9463332891464233\n",
      "      vf_loss: 719.779052734375\n",
      "    sample_time_ms: 18486.917\n",
      "    update_time_ms: 5.631\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 331.4594550404898\n",
      "  time_since_restore: 11259.939348459244\n",
      "  time_this_iter_s: 22.123689651489258\n",
      "  time_total_s: 11259.939348459244\n",
      "  timestamp: 1553720287\n",
      "  timesteps_since_restore: 4390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4390000\n",
      "  training_iteration: 439\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11259 s, 439 iter, 4390000 ts, 663 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-58-29\n",
      "  done: false\n",
      "  episode_len_mean: 145.23\n",
      "  episode_reward_max: 779.3172945417784\n",
      "  episode_reward_mean: 689.1439593950354\n",
      "  episode_reward_min: -38.62920384999279\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 32169\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3805.593\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 4400000\n",
      "    num_steps_trained: 4400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0190519094467163\n",
      "      kl: 0.011705317534506321\n",
      "      policy_loss: -0.0016568127321079373\n",
      "      total_loss: 276.1044616699219\n",
      "      vf_explained_var: 0.9773784279823303\n",
      "      vf_loss: 276.1061096191406\n",
      "    sample_time_ms: 18492.851\n",
      "    update_time_ms: 5.676\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.5719796975177\n",
      "  time_since_restore: 11282.561923027039\n",
      "  time_this_iter_s: 22.6225745677948\n",
      "  time_total_s: 11282.561923027039\n",
      "  timestamp: 1553720309\n",
      "  timesteps_since_restore: 4400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4400000\n",
      "  training_iteration: 440\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11282 s, 440 iter, 4400000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-58-51\n",
      "  done: false\n",
      "  episode_len_mean: 145.8\n",
      "  episode_reward_max: 772.5861460067645\n",
      "  episode_reward_mean: 701.7046199731135\n",
      "  episode_reward_min: -42.7399026611306\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 32238\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3799.694\n",
      "    load_time_ms: 1.633\n",
      "    num_steps_sampled: 4410000\n",
      "    num_steps_trained: 4410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.061329960823059\n",
      "      kl: 0.02786419726908207\n",
      "      policy_loss: -0.003635705215856433\n",
      "      total_loss: 8.1388521194458\n",
      "      vf_explained_var: 0.9993595480918884\n",
      "      vf_loss: 8.142486572265625\n",
      "    sample_time_ms: 18464.47\n",
      "    update_time_ms: 5.523\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.85230998655663\n",
      "  time_since_restore: 11304.523075342178\n",
      "  time_this_iter_s: 21.96115231513977\n",
      "  time_total_s: 11304.523075342178\n",
      "  timestamp: 1553720331\n",
      "  timesteps_since_restore: 4410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4410000\n",
      "  training_iteration: 441\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11304 s, 441 iter, 4410000 ts, 702 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-59-14\n",
      "  done: false\n",
      "  episode_len_mean: 146.24\n",
      "  episode_reward_max: 770.982844769392\n",
      "  episode_reward_mean: 702.6058149410668\n",
      "  episode_reward_min: -65.72776804820151\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 32307\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3808.925\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 4420000\n",
      "    num_steps_trained: 4420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.092936396598816\n",
      "      kl: 0.017438067123293877\n",
      "      policy_loss: -0.0023121426347643137\n",
      "      total_loss: 362.58099365234375\n",
      "      vf_explained_var: 0.9707391262054443\n",
      "      vf_loss: 362.58331298828125\n",
      "    sample_time_ms: 18449.438\n",
      "    update_time_ms: 5.694\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.30290747053346\n",
      "  time_since_restore: 11327.000801324844\n",
      "  time_this_iter_s: 22.477725982666016\n",
      "  time_total_s: 11327.000801324844\n",
      "  timestamp: 1553720354\n",
      "  timesteps_since_restore: 4420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4420000\n",
      "  training_iteration: 442\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11327 s, 442 iter, 4420000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-59-36\n",
      "  done: false\n",
      "  episode_len_mean: 143.6\n",
      "  episode_reward_max: 786.2367129754133\n",
      "  episode_reward_mean: 687.6730295482985\n",
      "  episode_reward_min: -65.72776804820151\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 32376\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.463\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 4430000\n",
      "    num_steps_trained: 4430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0425572395324707\n",
      "      kl: 0.017841486260294914\n",
      "      policy_loss: -0.0032185912132263184\n",
      "      total_loss: 222.66964721679688\n",
      "      vf_explained_var: 0.9816992282867432\n",
      "      vf_loss: 222.67282104492188\n",
      "    sample_time_ms: 18483.905\n",
      "    update_time_ms: 5.651\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.83651477414924\n",
      "  time_since_restore: 11349.530707120895\n",
      "  time_this_iter_s: 22.529905796051025\n",
      "  time_total_s: 11349.530707120895\n",
      "  timestamp: 1553720376\n",
      "  timesteps_since_restore: 4430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4430000\n",
      "  training_iteration: 443\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11349 s, 443 iter, 4430000 ts, 688 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_21-59-58\n",
      "  done: false\n",
      "  episode_len_mean: 144.34\n",
      "  episode_reward_max: 786.2367129754133\n",
      "  episode_reward_mean: 698.6071396224611\n",
      "  episode_reward_min: -83.48576418859163\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 32446\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3797.853\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 4440000\n",
      "    num_steps_trained: 4440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0350539684295654\n",
      "      kl: 0.01807435043156147\n",
      "      policy_loss: -0.003088924568146467\n",
      "      total_loss: 216.32606506347656\n",
      "      vf_explained_var: 0.9846535921096802\n",
      "      vf_loss: 216.3291778564453\n",
      "    sample_time_ms: 18351.971\n",
      "    update_time_ms: 5.63\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.30356981123055\n",
      "  time_since_restore: 11371.056207895279\n",
      "  time_this_iter_s: 21.525500774383545\n",
      "  time_total_s: 11371.056207895279\n",
      "  timestamp: 1553720398\n",
      "  timesteps_since_restore: 4440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4440000\n",
      "  training_iteration: 444\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11371 s, 444 iter, 4440000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-00-20\n",
      "  done: false\n",
      "  episode_len_mean: 144.56\n",
      "  episode_reward_max: 777.1472360705585\n",
      "  episode_reward_mean: 690.489528806314\n",
      "  episode_reward_min: -70.58058192518368\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 32515\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.931\n",
      "    load_time_ms: 1.519\n",
      "    num_steps_sampled: 4450000\n",
      "    num_steps_trained: 4450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.06851327419281\n",
      "      kl: 0.01803913153707981\n",
      "      policy_loss: -0.0033068174961954355\n",
      "      total_loss: 246.82151794433594\n",
      "      vf_explained_var: 0.9790849685668945\n",
      "      vf_loss: 246.82484436035156\n",
      "    sample_time_ms: 18329.9\n",
      "    update_time_ms: 5.61\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.24476440315703\n",
      "  time_since_restore: 11392.767838716507\n",
      "  time_this_iter_s: 21.711630821228027\n",
      "  time_total_s: 11392.767838716507\n",
      "  timestamp: 1553720420\n",
      "  timesteps_since_restore: 4450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4450000\n",
      "  training_iteration: 445\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11392 s, 445 iter, 4450000 ts, 690 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-00-42\n",
      "  done: false\n",
      "  episode_len_mean: 144.88\n",
      "  episode_reward_max: 781.379234524302\n",
      "  episode_reward_mean: 692.5754904762074\n",
      "  episode_reward_min: -106.22817397225191\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 32584\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3798.075\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 4460000\n",
      "    num_steps_trained: 4460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0373623371124268\n",
      "      kl: 0.02372201345860958\n",
      "      policy_loss: -0.002878079656511545\n",
      "      total_loss: 200.02366638183594\n",
      "      vf_explained_var: 0.9846530556678772\n",
      "      vf_loss: 200.0265350341797\n",
      "    sample_time_ms: 18296.441\n",
      "    update_time_ms: 5.613\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.2877452381037\n",
      "  time_since_restore: 11415.009658813477\n",
      "  time_this_iter_s: 22.241820096969604\n",
      "  time_total_s: 11415.009658813477\n",
      "  timestamp: 1553720442\n",
      "  timesteps_since_restore: 4460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4460000\n",
      "  training_iteration: 446\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11415 s, 446 iter, 4460000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-01-04\n",
      "  done: false\n",
      "  episode_len_mean: 141.45\n",
      "  episode_reward_max: 788.1614071398915\n",
      "  episode_reward_mean: 688.9888991459194\n",
      "  episode_reward_min: -111.54995096486039\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 32656\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3784.787\n",
      "    load_time_ms: 1.529\n",
      "    num_steps_sampled: 4470000\n",
      "    num_steps_trained: 4470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9880412220954895\n",
      "      kl: 0.018665537238121033\n",
      "      policy_loss: -0.0016685051377862692\n",
      "      total_loss: 305.5958557128906\n",
      "      vf_explained_var: 0.9801555275917053\n",
      "      vf_loss: 305.5974426269531\n",
      "    sample_time_ms: 18298.341\n",
      "    update_time_ms: 5.6\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.4944495729597\n",
      "  time_since_restore: 11436.91072511673\n",
      "  time_this_iter_s: 21.901066303253174\n",
      "  time_total_s: 11436.91072511673\n",
      "  timestamp: 1553720464\n",
      "  timesteps_since_restore: 4470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4470000\n",
      "  training_iteration: 447\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11436 s, 447 iter, 4470000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-01-27\n",
      "  done: false\n",
      "  episode_len_mean: 140.76\n",
      "  episode_reward_max: 772.3970278106547\n",
      "  episode_reward_mean: 678.1906040683882\n",
      "  episode_reward_min: -125.03309512996941\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 32727\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3765.554\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 4480000\n",
      "    num_steps_trained: 4480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.022268295288086\n",
      "      kl: 0.020908614620566368\n",
      "      policy_loss: -0.0016421190230175853\n",
      "      total_loss: 164.08253479003906\n",
      "      vf_explained_var: 0.9878852963447571\n",
      "      vf_loss: 164.0841827392578\n",
      "    sample_time_ms: 18417.376\n",
      "    update_time_ms: 5.434\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.09530203419416\n",
      "  time_since_restore: 11459.893627643585\n",
      "  time_this_iter_s: 22.98290252685547\n",
      "  time_total_s: 11459.893627643585\n",
      "  timestamp: 1553720487\n",
      "  timesteps_since_restore: 4480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4480000\n",
      "  training_iteration: 448\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11459 s, 448 iter, 4480000 ts, 678 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-01-50\n",
      "  done: false\n",
      "  episode_len_mean: 140.31\n",
      "  episode_reward_max: 780.8639653405135\n",
      "  episode_reward_mean: 674.7003686109925\n",
      "  episode_reward_min: -65.01760649687412\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 32799\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.767\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 4490000\n",
      "    num_steps_trained: 4490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.824387017128174e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.012290596961975\n",
      "      kl: 0.009766005910933018\n",
      "      policy_loss: 4.575802813633345e-05\n",
      "      total_loss: 334.2842102050781\n",
      "      vf_explained_var: 0.9743818640708923\n",
      "      vf_loss: 334.2841491699219\n",
      "    sample_time_ms: 18506.833\n",
      "    update_time_ms: 5.456\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.3501843054962\n",
      "  time_since_restore: 11482.856549024582\n",
      "  time_this_iter_s: 22.962921380996704\n",
      "  time_total_s: 11482.856549024582\n",
      "  timestamp: 1553720510\n",
      "  timesteps_since_restore: 4490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4490000\n",
      "  training_iteration: 449\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11482 s, 449 iter, 4490000 ts, 675 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-02-12\n",
      "  done: false\n",
      "  episode_len_mean: 142.9\n",
      "  episode_reward_max: 780.8639653405135\n",
      "  episode_reward_mean: 692.1322131918574\n",
      "  episode_reward_min: -113.356219244997\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 32869\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.717\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 4500000\n",
      "    num_steps_trained: 4500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.033287763595581\n",
      "      kl: 0.014617232605814934\n",
      "      policy_loss: -0.0032806580420583487\n",
      "      total_loss: 220.2659454345703\n",
      "      vf_explained_var: 0.9831059575080872\n",
      "      vf_loss: 220.26922607421875\n",
      "    sample_time_ms: 18450.724\n",
      "    update_time_ms: 5.413\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.0661065959287\n",
      "  time_since_restore: 11505.082534790039\n",
      "  time_this_iter_s: 22.225985765457153\n",
      "  time_total_s: 11505.082534790039\n",
      "  timestamp: 1553720532\n",
      "  timesteps_since_restore: 4500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4500000\n",
      "  training_iteration: 450\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11505 s, 450 iter, 4500000 ts, 692 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-02-34\n",
      "  done: false\n",
      "  episode_len_mean: 143.53\n",
      "  episode_reward_max: 776.501359779505\n",
      "  episode_reward_mean: 690.2473170782063\n",
      "  episode_reward_min: -110.31110648559945\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 32940\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3778.462\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 4510000\n",
      "    num_steps_trained: 4510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.058855652809143\n",
      "      kl: 0.02967449277639389\n",
      "      policy_loss: -0.0022228260058909655\n",
      "      total_loss: 283.73883056640625\n",
      "      vf_explained_var: 0.9773898720741272\n",
      "      vf_loss: 283.74102783203125\n",
      "    sample_time_ms: 18421.58\n",
      "    update_time_ms: 5.605\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.1236585391032\n",
      "  time_since_restore: 11526.77074766159\n",
      "  time_this_iter_s: 21.688212871551514\n",
      "  time_total_s: 11526.77074766159\n",
      "  timestamp: 1553720554\n",
      "  timesteps_since_restore: 4510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4510000\n",
      "  training_iteration: 451\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11526 s, 451 iter, 4510000 ts, 690 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-02-56\n",
      "  done: false\n",
      "  episode_len_mean: 140.84\n",
      "  episode_reward_max: 776.501359779505\n",
      "  episode_reward_mean: 679.0059888987039\n",
      "  episode_reward_min: -87.1417065188706\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 33011\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.921\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 4520000\n",
      "    num_steps_trained: 4520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.027721643447876\n",
      "      kl: 0.015648236498236656\n",
      "      policy_loss: -0.0009772193152457476\n",
      "      total_loss: 168.98175048828125\n",
      "      vf_explained_var: 0.987023651599884\n",
      "      vf_loss: 168.98272705078125\n",
      "    sample_time_ms: 18380.301\n",
      "    update_time_ms: 5.486\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.50299444935195\n",
      "  time_since_restore: 11548.649635314941\n",
      "  time_this_iter_s: 21.87888765335083\n",
      "  time_total_s: 11548.649635314941\n",
      "  timestamp: 1553720576\n",
      "  timesteps_since_restore: 4520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4520000\n",
      "  training_iteration: 452\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11548 s, 452 iter, 4520000 ts, 679 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-03-18\n",
      "  done: false\n",
      "  episode_len_mean: 142.76\n",
      "  episode_reward_max: 792.1717585672814\n",
      "  episode_reward_mean: 711.9951617506016\n",
      "  episode_reward_min: 672.2026712853261\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 33081\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.408\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 4530000\n",
      "    num_steps_trained: 4530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.989248514175415\n",
      "      kl: 0.01805289089679718\n",
      "      policy_loss: -0.0013369363732635975\n",
      "      total_loss: 7.670807838439941\n",
      "      vf_explained_var: 0.9995583891868591\n",
      "      vf_loss: 7.672144412994385\n",
      "    sample_time_ms: 18313.303\n",
      "    update_time_ms: 5.531\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.9975808753008\n",
      "  time_since_restore: 11570.50233578682\n",
      "  time_this_iter_s: 21.85270047187805\n",
      "  time_total_s: 11570.50233578682\n",
      "  timestamp: 1553720598\n",
      "  timesteps_since_restore: 4530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4530000\n",
      "  training_iteration: 453\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11570 s, 453 iter, 4530000 ts, 712 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-03-39\n",
      "  done: false\n",
      "  episode_len_mean: 142.98\n",
      "  episode_reward_max: 792.1717585672814\n",
      "  episode_reward_mean: 708.9202976392099\n",
      "  episode_reward_min: -36.23150711244418\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 33152\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3751.697\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 4540000\n",
      "    num_steps_trained: 4540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.038791537284851\n",
      "      kl: 0.017532650381326675\n",
      "      policy_loss: -0.0016963687958195806\n",
      "      total_loss: 54.61050033569336\n",
      "      vf_explained_var: 0.9961251616477966\n",
      "      vf_loss: 54.61219024658203\n",
      "    sample_time_ms: 18317.239\n",
      "    update_time_ms: 5.522\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.46014881960497\n",
      "  time_since_restore: 11591.988991260529\n",
      "  time_this_iter_s: 21.486655473709106\n",
      "  time_total_s: 11591.988991260529\n",
      "  timestamp: 1553720619\n",
      "  timesteps_since_restore: 4540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4540000\n",
      "  training_iteration: 454\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11591 s, 454 iter, 4540000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-04-01\n",
      "  done: false\n",
      "  episode_len_mean: 142.66\n",
      "  episode_reward_max: 771.2879766682064\n",
      "  episode_reward_mean: 708.0214101071983\n",
      "  episode_reward_min: -116.77473480816984\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 33222\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3750.61\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 4550000\n",
      "    num_steps_trained: 4550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0092878341674805\n",
      "      kl: 0.019579032436013222\n",
      "      policy_loss: -0.0022960109636187553\n",
      "      total_loss: 390.8134460449219\n",
      "      vf_explained_var: 0.9662913680076599\n",
      "      vf_loss: 390.8157653808594\n",
      "    sample_time_ms: 18345.01\n",
      "    update_time_ms: 5.496\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.0107050535991\n",
      "  time_since_restore: 11613.966395616531\n",
      "  time_this_iter_s: 21.977404356002808\n",
      "  time_total_s: 11613.966395616531\n",
      "  timestamp: 1553720641\n",
      "  timesteps_since_restore: 4550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4550000\n",
      "  training_iteration: 455\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11613 s, 455 iter, 4550000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-04-24\n",
      "  done: false\n",
      "  episode_len_mean: 142.21\n",
      "  episode_reward_max: 795.8264209205907\n",
      "  episode_reward_mean: 709.2543229219119\n",
      "  episode_reward_min: -56.15985091215529\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 33293\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.228\n",
      "    load_time_ms: 1.422\n",
      "    num_steps_sampled: 4560000\n",
      "    num_steps_trained: 4560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9930398464202881\n",
      "      kl: 0.014262489974498749\n",
      "      policy_loss: -0.001148176728747785\n",
      "      total_loss: 185.84176635742188\n",
      "      vf_explained_var: 0.9847785830497742\n",
      "      vf_loss: 185.84292602539062\n",
      "    sample_time_ms: 18359.551\n",
      "    update_time_ms: 5.508\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.6271614609559\n",
      "  time_since_restore: 11636.199687242508\n",
      "  time_this_iter_s: 22.233291625976562\n",
      "  time_total_s: 11636.199687242508\n",
      "  timestamp: 1553720664\n",
      "  timesteps_since_restore: 4560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4560000\n",
      "  training_iteration: 456\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11636 s, 456 iter, 4560000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-04-45\n",
      "  done: false\n",
      "  episode_len_mean: 142.03\n",
      "  episode_reward_max: 795.8264209205907\n",
      "  episode_reward_mean: 711.2965988740174\n",
      "  episode_reward_min: -44.13899269838177\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 33364\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3751.403\n",
      "    load_time_ms: 1.431\n",
      "    num_steps_sampled: 4570000\n",
      "    num_steps_trained: 4570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0114214420318604\n",
      "      kl: 0.029448166489601135\n",
      "      policy_loss: -0.0016835734713822603\n",
      "      total_loss: 355.0386047363281\n",
      "      vf_explained_var: 0.970326840877533\n",
      "      vf_loss: 355.0403137207031\n",
      "    sample_time_ms: 18309.184\n",
      "    update_time_ms: 5.383\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.6482994370085\n",
      "  time_since_restore: 11657.75778746605\n",
      "  time_this_iter_s: 21.55810022354126\n",
      "  time_total_s: 11657.75778746605\n",
      "  timestamp: 1553720685\n",
      "  timesteps_since_restore: 4570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4570000\n",
      "  training_iteration: 457\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11657 s, 457 iter, 4570000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-05-07\n",
      "  done: false\n",
      "  episode_len_mean: 141.82\n",
      "  episode_reward_max: 790.7883485370727\n",
      "  episode_reward_mean: 713.3426329090648\n",
      "  episode_reward_min: -35.65068559937538\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 33434\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3750.94\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 4580000\n",
      "    num_steps_trained: 4580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9734451174736023\n",
      "      kl: 0.019910039380192757\n",
      "      policy_loss: -0.003246166044846177\n",
      "      total_loss: 26.7602481842041\n",
      "      vf_explained_var: 0.9982139468193054\n",
      "      vf_loss: 26.763490676879883\n",
      "    sample_time_ms: 18199.938\n",
      "    update_time_ms: 5.359\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.67131645453236\n",
      "  time_since_restore: 11679.644356250763\n",
      "  time_this_iter_s: 21.886568784713745\n",
      "  time_total_s: 11679.644356250763\n",
      "  timestamp: 1553720707\n",
      "  timesteps_since_restore: 4580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4580000\n",
      "  training_iteration: 458\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11679 s, 458 iter, 4580000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-05-29\n",
      "  done: false\n",
      "  episode_len_mean: 139.86\n",
      "  episode_reward_max: 789.517974362083\n",
      "  episode_reward_mean: 699.643126476041\n",
      "  episode_reward_min: -121.23317972801507\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 33506\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3748.234\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 4590000\n",
      "    num_steps_trained: 4590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0083215236663818\n",
      "      kl: 0.021608347073197365\n",
      "      policy_loss: -0.0018324562115594745\n",
      "      total_loss: 93.11844635009766\n",
      "      vf_explained_var: 0.9923915266990662\n",
      "      vf_loss: 93.12027740478516\n",
      "    sample_time_ms: 18126.349\n",
      "    update_time_ms: 5.24\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.8215632380205\n",
      "  time_since_restore: 11701.839951992035\n",
      "  time_this_iter_s: 22.195595741271973\n",
      "  time_total_s: 11701.839951992035\n",
      "  timestamp: 1553720729\n",
      "  timesteps_since_restore: 4590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4590000\n",
      "  training_iteration: 459\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11701 s, 459 iter, 4590000 ts, 700 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-05-51\n",
      "  done: false\n",
      "  episode_len_mean: 140.11\n",
      "  episode_reward_max: 790.6681261149621\n",
      "  episode_reward_mean: 695.8280533066066\n",
      "  episode_reward_min: -90.75802227515042\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 33578\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3732.106\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 4600000\n",
      "    num_steps_trained: 4600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.060080647468567\n",
      "      kl: 0.014325650408864021\n",
      "      policy_loss: -0.0015827578026801348\n",
      "      total_loss: 278.20330810546875\n",
      "      vf_explained_var: 0.9806100130081177\n",
      "      vf_loss: 278.204833984375\n",
      "    sample_time_ms: 18051.567\n",
      "    update_time_ms: 5.205\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.9140266533032\n",
      "  time_since_restore: 11723.15790104866\n",
      "  time_this_iter_s: 21.317949056625366\n",
      "  time_total_s: 11723.15790104866\n",
      "  timestamp: 1553720751\n",
      "  timesteps_since_restore: 4600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4600000\n",
      "  training_iteration: 460\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11723 s, 460 iter, 4600000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-06-14\n",
      "  done: false\n",
      "  episode_len_mean: 137.41\n",
      "  episode_reward_max: 790.6681261149621\n",
      "  episode_reward_mean: 679.8114872769653\n",
      "  episode_reward_min: -123.08938247003611\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 33652\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.044\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 4610000\n",
      "    num_steps_trained: 4610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9924138188362122\n",
      "      kl: 0.014957813546061516\n",
      "      policy_loss: -0.00233926298096776\n",
      "      total_loss: 875.7703247070312\n",
      "      vf_explained_var: 0.9264197945594788\n",
      "      vf_loss: 875.7726440429688\n",
      "    sample_time_ms: 18162.658\n",
      "    update_time_ms: 5.077\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.90574363848253\n",
      "  time_since_restore: 11746.094209909439\n",
      "  time_this_iter_s: 22.93630886077881\n",
      "  time_total_s: 11746.094209909439\n",
      "  timestamp: 1553720774\n",
      "  timesteps_since_restore: 4610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4610000\n",
      "  training_iteration: 461\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11746 s, 461 iter, 4610000 ts, 680 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-06-36\n",
      "  done: false\n",
      "  episode_len_mean: 138.15\n",
      "  episode_reward_max: 784.0548669146876\n",
      "  episode_reward_mean: 688.8630590264655\n",
      "  episode_reward_min: -92.2580740078231\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 33724\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3751.719\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 4620000\n",
      "    num_steps_trained: 4620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9917690753936768\n",
      "      kl: 0.014256834983825684\n",
      "      policy_loss: -0.0006927636568434536\n",
      "      total_loss: 134.0164794921875\n",
      "      vf_explained_var: 0.9896336793899536\n",
      "      vf_loss: 134.0171661376953\n",
      "    sample_time_ms: 18236.739\n",
      "    update_time_ms: 5.006\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.4315295132328\n",
      "  time_since_restore: 11768.771054029465\n",
      "  time_this_iter_s: 22.676844120025635\n",
      "  time_total_s: 11768.771054029465\n",
      "  timestamp: 1553720796\n",
      "  timesteps_since_restore: 4620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4620000\n",
      "  training_iteration: 462\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11768 s, 462 iter, 4620000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-06-59\n",
      "  done: false\n",
      "  episode_len_mean: 138.42\n",
      "  episode_reward_max: 780.1803743061673\n",
      "  episode_reward_mean: 701.287460191692\n",
      "  episode_reward_min: -127.10502177540491\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 33796\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.202\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 4630000\n",
      "    num_steps_trained: 4630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.912193508564087e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0269286632537842\n",
      "      kl: 0.04427076131105423\n",
      "      policy_loss: 0.00040816879482008517\n",
      "      total_loss: 400.5233459472656\n",
      "      vf_explained_var: 0.9665791392326355\n",
      "      vf_loss: 400.5229187011719\n",
      "    sample_time_ms: 18269.063\n",
      "    update_time_ms: 4.98\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.6437300958462\n",
      "  time_since_restore: 11790.99439406395\n",
      "  time_this_iter_s: 22.223340034484863\n",
      "  time_total_s: 11790.99439406395\n",
      "  timestamp: 1553720819\n",
      "  timesteps_since_restore: 4630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4630000\n",
      "  training_iteration: 463\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11790 s, 463 iter, 4630000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-07-21\n",
      "  done: false\n",
      "  episode_len_mean: 137.34\n",
      "  episode_reward_max: 776.7649485428113\n",
      "  episode_reward_mean: 680.6395532596711\n",
      "  episode_reward_min: -76.43148210236721\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 33870\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.771\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 4640000\n",
      "    num_steps_trained: 4640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9681463241577148\n",
      "      kl: 0.016284486278891563\n",
      "      policy_loss: -0.0023252118844538927\n",
      "      total_loss: 593.7322998046875\n",
      "      vf_explained_var: 0.9516817927360535\n",
      "      vf_loss: 593.734619140625\n",
      "    sample_time_ms: 18347.771\n",
      "    update_time_ms: 4.977\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.31977662983553\n",
      "  time_since_restore: 11813.3417699337\n",
      "  time_this_iter_s: 22.347375869750977\n",
      "  time_total_s: 11813.3417699337\n",
      "  timestamp: 1553720841\n",
      "  timesteps_since_restore: 4640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4640000\n",
      "  training_iteration: 464\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11813 s, 464 iter, 4640000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-07-44\n",
      "  done: false\n",
      "  episode_len_mean: 138.68\n",
      "  episode_reward_max: 778.7898799695981\n",
      "  episode_reward_mean: 697.829432991539\n",
      "  episode_reward_min: -42.700349883382415\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 33942\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3779.77\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 4650000\n",
      "    num_steps_trained: 4650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9781711101531982\n",
      "      kl: 0.012974962592124939\n",
      "      policy_loss: -0.0014420768711715937\n",
      "      total_loss: 290.77276611328125\n",
      "      vf_explained_var: 0.977887749671936\n",
      "      vf_loss: 290.7742004394531\n",
      "    sample_time_ms: 18395.046\n",
      "    update_time_ms: 5.092\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.91471649576954\n",
      "  time_since_restore: 11835.95517039299\n",
      "  time_this_iter_s: 22.61340045928955\n",
      "  time_total_s: 11835.95517039299\n",
      "  timestamp: 1553720864\n",
      "  timesteps_since_restore: 4650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4650000\n",
      "  training_iteration: 465\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11835 s, 465 iter, 4650000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-08-06\n",
      "  done: false\n",
      "  episode_len_mean: 138.24\n",
      "  episode_reward_max: 789.8584897518622\n",
      "  episode_reward_mean: 693.3833111143322\n",
      "  episode_reward_min: -90.64384210109627\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 34015\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3785.957\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 4660000\n",
      "    num_steps_trained: 4660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9768776297569275\n",
      "      kl: 0.016336726024746895\n",
      "      policy_loss: -0.0026551997289061546\n",
      "      total_loss: 226.63487243652344\n",
      "      vf_explained_var: 0.9824005365371704\n",
      "      vf_loss: 226.6375274658203\n",
      "    sample_time_ms: 18411.838\n",
      "    update_time_ms: 4.998\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.6916555571661\n",
      "  time_since_restore: 11858.421091079712\n",
      "  time_this_iter_s: 22.4659206867218\n",
      "  time_total_s: 11858.421091079712\n",
      "  timestamp: 1553720886\n",
      "  timesteps_since_restore: 4660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4660000\n",
      "  training_iteration: 466\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11858 s, 466 iter, 4660000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-08-29\n",
      "  done: false\n",
      "  episode_len_mean: 134.0\n",
      "  episode_reward_max: 789.8584897518622\n",
      "  episode_reward_mean: 653.832805802143\n",
      "  episode_reward_min: -130.3411361844702\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 34091\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3769.395\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 4670000\n",
      "    num_steps_trained: 4670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9850913882255554\n",
      "      kl: 0.015005948953330517\n",
      "      policy_loss: -0.0010708811460062861\n",
      "      total_loss: 456.45843505859375\n",
      "      vf_explained_var: 0.9666969180107117\n",
      "      vf_loss: 456.45953369140625\n",
      "    sample_time_ms: 18553.27\n",
      "    update_time_ms: 5.199\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 326.9164029010714\n",
      "  time_since_restore: 11881.230913639069\n",
      "  time_this_iter_s: 22.80982255935669\n",
      "  time_total_s: 11881.230913639069\n",
      "  timestamp: 1553720909\n",
      "  timesteps_since_restore: 4670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4670000\n",
      "  training_iteration: 467\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11881 s, 467 iter, 4670000 ts, 654 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-08-51\n",
      "  done: false\n",
      "  episode_len_mean: 129.93\n",
      "  episode_reward_max: 784.0583047332127\n",
      "  episode_reward_mean: 618.8569894362474\n",
      "  episode_reward_min: -132.64578251172213\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 34169\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.699\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 4680000\n",
      "    num_steps_trained: 4680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9507472515106201\n",
      "      kl: 0.021054411306977272\n",
      "      policy_loss: -0.004229388665407896\n",
      "      total_loss: 1361.4637451171875\n",
      "      vf_explained_var: 0.9050700068473816\n",
      "      vf_loss: 1361.468017578125\n",
      "    sample_time_ms: 18599.656\n",
      "    update_time_ms: 5.158\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 309.4284947181237\n",
      "  time_since_restore: 11903.561181306839\n",
      "  time_this_iter_s: 22.330267667770386\n",
      "  time_total_s: 11903.561181306839\n",
      "  timestamp: 1553720931\n",
      "  timesteps_since_restore: 4680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4680000\n",
      "  training_iteration: 468\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11903 s, 468 iter, 4680000 ts, 619 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-09-14\n",
      "  done: false\n",
      "  episode_len_mean: 134.46\n",
      "  episode_reward_max: 788.1336921259888\n",
      "  episode_reward_mean: 662.9013292697958\n",
      "  episode_reward_min: -121.27380704124107\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 34242\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.684\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 4690000\n",
      "    num_steps_trained: 4690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9528491497039795\n",
      "      kl: 0.01733558066189289\n",
      "      policy_loss: -0.0020258408039808273\n",
      "      total_loss: 150.27511596679688\n",
      "      vf_explained_var: 0.9888981580734253\n",
      "      vf_loss: 150.27716064453125\n",
      "    sample_time_ms: 18600.796\n",
      "    update_time_ms: 5.286\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 331.450664634898\n",
      "  time_since_restore: 11926.004356861115\n",
      "  time_this_iter_s: 22.443175554275513\n",
      "  time_total_s: 11926.004356861115\n",
      "  timestamp: 1553720954\n",
      "  timesteps_since_restore: 4690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4690000\n",
      "  training_iteration: 469\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11926 s, 469 iter, 4690000 ts, 663 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-09-36\n",
      "  done: false\n",
      "  episode_len_mean: 136.84\n",
      "  episode_reward_max: 792.1078381075015\n",
      "  episode_reward_mean: 685.2775924433913\n",
      "  episode_reward_min: -133.9825974801867\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 34317\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3787.588\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 4700000\n",
      "    num_steps_trained: 4700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9924371242523193\n",
      "      kl: 0.02526511810719967\n",
      "      policy_loss: -0.0036886786110699177\n",
      "      total_loss: 723.0587158203125\n",
      "      vf_explained_var: 0.942044198513031\n",
      "      vf_loss: 723.0623779296875\n",
      "    sample_time_ms: 18660.725\n",
      "    update_time_ms: 5.29\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.6387962216956\n",
      "  time_since_restore: 11947.889633655548\n",
      "  time_this_iter_s: 21.885276794433594\n",
      "  time_total_s: 11947.889633655548\n",
      "  timestamp: 1553720976\n",
      "  timesteps_since_restore: 4700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4700000\n",
      "  training_iteration: 470\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11947 s, 470 iter, 4700000 ts, 685 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-09-58\n",
      "  done: false\n",
      "  episode_len_mean: 137.79\n",
      "  episode_reward_max: 802.5165361301089\n",
      "  episode_reward_mean: 683.7101921333082\n",
      "  episode_reward_min: -61.9525336439431\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 34389\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3773.348\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 4710000\n",
      "    num_steps_trained: 4710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9303311109542847\n",
      "      kl: 0.01899830624461174\n",
      "      policy_loss: -0.0015688803978264332\n",
      "      total_loss: 189.86770629882812\n",
      "      vf_explained_var: 0.9848583936691284\n",
      "      vf_loss: 189.86929321289062\n",
      "    sample_time_ms: 18598.0\n",
      "    update_time_ms: 5.252\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.8550960666541\n",
      "  time_since_restore: 11970.057253360748\n",
      "  time_this_iter_s: 22.167619705200195\n",
      "  time_total_s: 11970.057253360748\n",
      "  timestamp: 1553720998\n",
      "  timesteps_since_restore: 4710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4710000\n",
      "  training_iteration: 471\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11970 s, 471 iter, 4710000 ts, 684 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-10-20\n",
      "  done: false\n",
      "  episode_len_mean: 135.34\n",
      "  episode_reward_max: 802.5165361301089\n",
      "  episode_reward_mean: 674.4745791750184\n",
      "  episode_reward_min: -111.02036801959554\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 34464\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3769.891\n",
      "    load_time_ms: 1.468\n",
      "    num_steps_sampled: 4720000\n",
      "    num_steps_trained: 4720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8861984610557556\n",
      "      kl: 0.03671771287918091\n",
      "      policy_loss: -0.003299864474684\n",
      "      total_loss: 473.5675048828125\n",
      "      vf_explained_var: 0.9617751836776733\n",
      "      vf_loss: 473.57080078125\n",
      "    sample_time_ms: 18532.648\n",
      "    update_time_ms: 5.147\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.2372895875093\n",
      "  time_since_restore: 11992.043159484863\n",
      "  time_this_iter_s: 21.98590612411499\n",
      "  time_total_s: 11992.043159484863\n",
      "  timestamp: 1553721020\n",
      "  timesteps_since_restore: 4720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4720000\n",
      "  training_iteration: 472\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 11992 s, 472 iter, 4720000 ts, 674 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 133.64\n",
      "  episode_reward_max: 783.5880515289344\n",
      "  episode_reward_mean: 666.1947784140601\n",
      "  episode_reward_min: -111.6369371351017\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 34538\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3784.264\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 4730000\n",
      "    num_steps_trained: 4730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8138097524642944\n",
      "      kl: 0.015192979015409946\n",
      "      policy_loss: 0.00048705420340411365\n",
      "      total_loss: 339.8606262207031\n",
      "      vf_explained_var: 0.9735676646232605\n",
      "      vf_loss: 339.86016845703125\n",
      "    sample_time_ms: 18528.396\n",
      "    update_time_ms: 5.165\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 333.0973892070299\n",
      "  time_since_restore: 12014.367094516754\n",
      "  time_this_iter_s: 22.32393503189087\n",
      "  time_total_s: 12014.367094516754\n",
      "  timestamp: 1553721042\n",
      "  timesteps_since_restore: 4730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4730000\n",
      "  training_iteration: 473\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12014 s, 473 iter, 4730000 ts, 666 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-11-04\n",
      "  done: false\n",
      "  episode_len_mean: 134.75\n",
      "  episode_reward_max: 776.8466082416576\n",
      "  episode_reward_mean: 666.4152106120799\n",
      "  episode_reward_min: -117.13209018023457\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 34613\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3777.481\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 4740000\n",
      "    num_steps_trained: 4740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8570767641067505\n",
      "      kl: 0.01638135313987732\n",
      "      policy_loss: -0.0007752905949018896\n",
      "      total_loss: 345.3725280761719\n",
      "      vf_explained_var: 0.9731648564338684\n",
      "      vf_loss: 345.373291015625\n",
      "    sample_time_ms: 18494.421\n",
      "    update_time_ms: 5.299\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 333.20760530603997\n",
      "  time_since_restore: 12036.310271024704\n",
      "  time_this_iter_s: 21.94317650794983\n",
      "  time_total_s: 12036.310271024704\n",
      "  timestamp: 1553721064\n",
      "  timesteps_since_restore: 4740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4740000\n",
      "  training_iteration: 474\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12036 s, 474 iter, 4740000 ts, 666 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 138.95\n",
      "  episode_reward_max: 790.8605074184159\n",
      "  episode_reward_mean: 701.125565767703\n",
      "  episode_reward_min: -53.250885878506864\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 34685\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.004\n",
      "    load_time_ms: 1.421\n",
      "    num_steps_sampled: 4750000\n",
      "    num_steps_trained: 4750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8462573289871216\n",
      "      kl: 0.02709953673183918\n",
      "      policy_loss: -0.003058097092434764\n",
      "      total_loss: 161.06820678710938\n",
      "      vf_explained_var: 0.9869396686553955\n",
      "      vf_loss: 161.0712890625\n",
      "    sample_time_ms: 18457.539\n",
      "    update_time_ms: 5.236\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.56278288385147\n",
      "  time_since_restore: 12058.396523714066\n",
      "  time_this_iter_s: 22.086252689361572\n",
      "  time_total_s: 12058.396523714066\n",
      "  timestamp: 1553721086\n",
      "  timesteps_since_restore: 4750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4750000\n",
      "  training_iteration: 475\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12058 s, 475 iter, 4750000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-11-48\n",
      "  done: false\n",
      "  episode_len_mean: 137.94\n",
      "  episode_reward_max: 790.8605074184159\n",
      "  episode_reward_mean: 689.1835847070944\n",
      "  episode_reward_min: -125.57460831176492\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 34758\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.735\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 4760000\n",
      "    num_steps_trained: 4760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.851025402545929\n",
      "      kl: 0.02281726710498333\n",
      "      policy_loss: -0.0033539736177772284\n",
      "      total_loss: 217.0690155029297\n",
      "      vf_explained_var: 0.9826720952987671\n",
      "      vf_loss: 217.0723876953125\n",
      "    sample_time_ms: 18316.512\n",
      "    update_time_ms: 5.306\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.5917923535472\n",
      "  time_since_restore: 12079.439876556396\n",
      "  time_this_iter_s: 21.043352842330933\n",
      "  time_total_s: 12079.439876556396\n",
      "  timestamp: 1553721108\n",
      "  timesteps_since_restore: 4760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4760000\n",
      "  training_iteration: 476\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12079 s, 476 iter, 4760000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-12-09\n",
      "  done: false\n",
      "  episode_len_mean: 138.53\n",
      "  episode_reward_max: 786.8719439729614\n",
      "  episode_reward_mean: 690.7662864959847\n",
      "  episode_reward_min: -49.1254184053773\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 34831\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3766.03\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 4770000\n",
      "    num_steps_trained: 4770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7974007725715637\n",
      "      kl: 0.02045847661793232\n",
      "      policy_loss: -0.003189670853316784\n",
      "      total_loss: 303.9092102050781\n",
      "      vf_explained_var: 0.9750929474830627\n",
      "      vf_loss: 303.91241455078125\n",
      "    sample_time_ms: 18215.135\n",
      "    update_time_ms: 5.11\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.38314324799234\n",
      "  time_since_restore: 12101.287884235382\n",
      "  time_this_iter_s: 21.848007678985596\n",
      "  time_total_s: 12101.287884235382\n",
      "  timestamp: 1553721129\n",
      "  timesteps_since_restore: 4770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4770000\n",
      "  training_iteration: 477\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12101 s, 477 iter, 4770000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-12-32\n",
      "  done: false\n",
      "  episode_len_mean: 136.09\n",
      "  episode_reward_max: 787.4477647069237\n",
      "  episode_reward_mean: 687.4993805011541\n",
      "  episode_reward_min: -124.75110527890575\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 34905\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.322\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 4780000\n",
      "    num_steps_trained: 4780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7483328580856323\n",
      "      kl: 0.016464224085211754\n",
      "      policy_loss: -0.0030026633758097887\n",
      "      total_loss: 183.9436798095703\n",
      "      vf_explained_var: 0.984647810459137\n",
      "      vf_loss: 183.94668579101562\n",
      "    sample_time_ms: 18181.143\n",
      "    update_time_ms: 5.242\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.7496902505771\n",
      "  time_since_restore: 12123.294461488724\n",
      "  time_this_iter_s: 22.006577253341675\n",
      "  time_total_s: 12123.294461488724\n",
      "  timestamp: 1553721152\n",
      "  timesteps_since_restore: 4780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4780000\n",
      "  training_iteration: 478\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12123 s, 478 iter, 4780000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-12-53\n",
      "  done: false\n",
      "  episode_len_mean: 139.6\n",
      "  episode_reward_max: 792.9285767851642\n",
      "  episode_reward_mean: 712.9881219350922\n",
      "  episode_reward_min: -100.64622680165014\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 34977\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.146\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 4790000\n",
      "    num_steps_trained: 4790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3682899786290363e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.844096839427948\n",
      "      kl: 1.351245641708374\n",
      "      policy_loss: 0.00034825369948521256\n",
      "      total_loss: 29.31758689880371\n",
      "      vf_explained_var: 0.9980028867721558\n",
      "      vf_loss: 29.31723976135254\n",
      "    sample_time_ms: 18144.333\n",
      "    update_time_ms: 5.256\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.4940609675461\n",
      "  time_since_restore: 12145.153754234314\n",
      "  time_this_iter_s: 21.85929274559021\n",
      "  time_total_s: 12145.153754234314\n",
      "  timestamp: 1553721173\n",
      "  timesteps_since_restore: 4790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4790000\n",
      "  training_iteration: 479\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12145 s, 479 iter, 4790000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-13-15\n",
      "  done: false\n",
      "  episode_len_mean: 136.14\n",
      "  episode_reward_max: 779.5556026599842\n",
      "  episode_reward_mean: 681.1505110678336\n",
      "  episode_reward_min: -92.88755049280192\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 35051\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.166\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 4800000\n",
      "    num_steps_trained: 4800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.552435820594837e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8014312386512756\n",
      "      kl: 0.013053955510258675\n",
      "      policy_loss: -0.0023224418982863426\n",
      "      total_loss: 119.34760284423828\n",
      "      vf_explained_var: 0.9907560348510742\n",
      "      vf_loss: 119.34992218017578\n",
      "    sample_time_ms: 18137.076\n",
      "    update_time_ms: 5.321\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.5752555339168\n",
      "  time_since_restore: 12167.099122524261\n",
      "  time_this_iter_s: 21.94536828994751\n",
      "  time_total_s: 12167.099122524261\n",
      "  timestamp: 1553721195\n",
      "  timesteps_since_restore: 4800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4800000\n",
      "  training_iteration: 480\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12167 s, 480 iter, 4800000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-13-37\n",
      "  done: false\n",
      "  episode_len_mean: 138.47\n",
      "  episode_reward_max: 797.9557012058502\n",
      "  episode_reward_mean: 700.9147458642738\n",
      "  episode_reward_min: -127.08981748608278\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 35124\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.936\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 4810000\n",
      "    num_steps_trained: 4810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.552435820594837e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8368841409683228\n",
      "      kl: 0.05755864083766937\n",
      "      policy_loss: -6.178250714583555e-06\n",
      "      total_loss: 56.84016799926758\n",
      "      vf_explained_var: 0.9962950348854065\n",
      "      vf_loss: 56.84017562866211\n",
      "    sample_time_ms: 18114.39\n",
      "    update_time_ms: 5.378\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.45737293213693\n",
      "  time_since_restore: 12189.01866054535\n",
      "  time_this_iter_s: 21.919538021087646\n",
      "  time_total_s: 12189.01866054535\n",
      "  timestamp: 1553721217\n",
      "  timesteps_since_restore: 4810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4810000\n",
      "  training_iteration: 481\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12189 s, 481 iter, 4810000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-14-00\n",
      "  done: false\n",
      "  episode_len_mean: 137.14\n",
      "  episode_reward_max: 797.9557012058502\n",
      "  episode_reward_mean: 701.9889512851458\n",
      "  episode_reward_min: -127.98372484880679\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 35199\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3758.137\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 4820000\n",
      "    num_steps_trained: 4820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.828653446675162e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8563860654830933\n",
      "      kl: 0.016116853803396225\n",
      "      policy_loss: -0.003489954397082329\n",
      "      total_loss: 76.5932846069336\n",
      "      vf_explained_var: 0.9945352077484131\n",
      "      vf_loss: 76.59677124023438\n",
      "    sample_time_ms: 18150.832\n",
      "    update_time_ms: 5.63\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.9944756425729\n",
      "  time_since_restore: 12211.384174585342\n",
      "  time_this_iter_s: 22.365514039993286\n",
      "  time_total_s: 12211.384174585342\n",
      "  timestamp: 1553721240\n",
      "  timesteps_since_restore: 4820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4820000\n",
      "  training_iteration: 482\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12211 s, 482 iter, 4820000 ts, 702 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-14-22\n",
      "  done: false\n",
      "  episode_len_mean: 137.06\n",
      "  episode_reward_max: 781.5255553190837\n",
      "  episode_reward_mean: 696.0304000044271\n",
      "  episode_reward_min: -113.93108440310154\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 35272\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.277\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 4830000\n",
      "    num_steps_trained: 4830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.828653446675162e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8700444102287292\n",
      "      kl: 0.02565242163836956\n",
      "      policy_loss: -0.0016923642251640558\n",
      "      total_loss: 144.38096618652344\n",
      "      vf_explained_var: 0.9892318844795227\n",
      "      vf_loss: 144.3826904296875\n",
      "    sample_time_ms: 18149.154\n",
      "    update_time_ms: 5.58\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.01520000221353\n",
      "  time_since_restore: 12233.573136091232\n",
      "  time_this_iter_s: 22.188961505889893\n",
      "  time_total_s: 12233.573136091232\n",
      "  timestamp: 1553721262\n",
      "  timesteps_since_restore: 4830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4830000\n",
      "  training_iteration: 483\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12233 s, 483 iter, 4830000 ts, 696 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 138.34\n",
      "  episode_reward_max: 792.9809219022686\n",
      "  episode_reward_mean: 705.0239138141774\n",
      "  episode_reward_min: -120.96199075687171\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 35345\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.821\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 4840000\n",
      "    num_steps_trained: 4840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.828653446675162e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8929060101509094\n",
      "      kl: 1.2398892641067505\n",
      "      policy_loss: 0.0024306834675371647\n",
      "      total_loss: 105.36154174804688\n",
      "      vf_explained_var: 0.9937601089477539\n",
      "      vf_loss: 105.35912322998047\n",
      "    sample_time_ms: 18128.799\n",
      "    update_time_ms: 5.391\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.5119569070887\n",
      "  time_since_restore: 12255.446159362793\n",
      "  time_this_iter_s: 21.87302327156067\n",
      "  time_total_s: 12255.446159362793\n",
      "  timestamp: 1553721284\n",
      "  timesteps_since_restore: 4840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4840000\n",
      "  training_iteration: 484\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12255 s, 484 iter, 4840000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 139.96\n",
      "  episode_reward_max: 796.549580970046\n",
      "  episode_reward_mean: 724.0223792556645\n",
      "  episode_reward_min: -123.17745039473499\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 35417\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.31\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 4850000\n",
      "    num_steps_trained: 4850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4742979601578554e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8616891503334045\n",
      "      kl: 0.1195998415350914\n",
      "      policy_loss: -0.00018701187218539417\n",
      "      total_loss: 9.065671920776367\n",
      "      vf_explained_var: 0.9992915391921997\n",
      "      vf_loss: 9.065858840942383\n",
      "    sample_time_ms: 18128.174\n",
      "    update_time_ms: 5.578\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.0111896278322\n",
      "  time_since_restore: 12277.491021871567\n",
      "  time_this_iter_s: 22.044862508773804\n",
      "  time_total_s: 12277.491021871567\n",
      "  timestamp: 1553721306\n",
      "  timesteps_since_restore: 4850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4850000\n",
      "  training_iteration: 485\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12277 s, 485 iter, 4850000 ts, 724 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-15-28\n",
      "  done: false\n",
      "  episode_len_mean: 138.51\n",
      "  episode_reward_max: 797.5164669198604\n",
      "  episode_reward_mean: 718.0433346511204\n",
      "  episode_reward_min: -72.04081025632831\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 35490\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.002\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 4860000\n",
      "    num_steps_trained: 4860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2114468265499454e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8637617230415344\n",
      "      kl: 0.023733140900731087\n",
      "      policy_loss: -0.005528639070689678\n",
      "      total_loss: 171.61300659179688\n",
      "      vf_explained_var: 0.9857983589172363\n",
      "      vf_loss: 171.61854553222656\n",
      "    sample_time_ms: 18257.402\n",
      "    update_time_ms: 5.745\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.0216673255602\n",
      "  time_since_restore: 12299.826078176498\n",
      "  time_this_iter_s: 22.33505630493164\n",
      "  time_total_s: 12299.826078176498\n",
      "  timestamp: 1553721328\n",
      "  timesteps_since_restore: 4860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4860000\n",
      "  training_iteration: 486\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12299 s, 486 iter, 4860000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-15-51\n",
      "  done: false\n",
      "  episode_len_mean: 138.33\n",
      "  episode_reward_max: 797.5164669198604\n",
      "  episode_reward_mean: 714.9273186779029\n",
      "  episode_reward_min: -79.00540170882452\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 35563\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3748.448\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 4870000\n",
      "    num_steps_trained: 4870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2114468265499454e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.893772304058075\n",
      "      kl: 0.013880277052521706\n",
      "      policy_loss: -0.0018639654153957963\n",
      "      total_loss: 101.89141082763672\n",
      "      vf_explained_var: 0.992722749710083\n",
      "      vf_loss: 101.89328002929688\n",
      "    sample_time_ms: 18327.192\n",
      "    update_time_ms: 5.864\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.46365933895146\n",
      "  time_since_restore: 12322.29896569252\n",
      "  time_this_iter_s: 22.47288751602173\n",
      "  time_total_s: 12322.29896569252\n",
      "  timestamp: 1553721351\n",
      "  timesteps_since_restore: 4870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4870000\n",
      "  training_iteration: 487\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12322 s, 487 iter, 4870000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-16-14\n",
      "  done: false\n",
      "  episode_len_mean: 136.97\n",
      "  episode_reward_max: 798.9869815163602\n",
      "  episode_reward_mean: 692.1380691774434\n",
      "  episode_reward_min: -105.56877437956952\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 35637\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.619\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 4880000\n",
      "    num_steps_trained: 4880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2114468265499454e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9511785507202148\n",
      "      kl: 0.026200328022241592\n",
      "      policy_loss: -0.0039487676694989204\n",
      "      total_loss: 86.86918640136719\n",
      "      vf_explained_var: 0.9949069619178772\n",
      "      vf_loss: 86.87313079833984\n",
      "    sample_time_ms: 18383.114\n",
      "    update_time_ms: 5.741\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.06903458872154\n",
      "  time_since_restore: 12345.014702558517\n",
      "  time_this_iter_s: 22.715736865997314\n",
      "  time_total_s: 12345.014702558517\n",
      "  timestamp: 1553721374\n",
      "  timesteps_since_restore: 4880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4880000\n",
      "  training_iteration: 488\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12345 s, 488 iter, 4880000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 138.47\n",
      "  episode_reward_max: 800.8261914198714\n",
      "  episode_reward_mean: 724.6093302493666\n",
      "  episode_reward_min: -81.50754243082368\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 35710\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3764.925\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 4890000\n",
      "    num_steps_trained: 4890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2114468265499454e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9474772810935974\n",
      "      kl: 0.12711165845394135\n",
      "      policy_loss: -0.00302813365124166\n",
      "      total_loss: 279.3403015136719\n",
      "      vf_explained_var: 0.980971097946167\n",
      "      vf_loss: 279.34332275390625\n",
      "    sample_time_ms: 18422.627\n",
      "    update_time_ms: 5.62\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.30466512468325\n",
      "  time_since_restore: 12367.284217596054\n",
      "  time_this_iter_s: 22.26951503753662\n",
      "  time_total_s: 12367.284217596054\n",
      "  timestamp: 1553721396\n",
      "  timesteps_since_restore: 4890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4890000\n",
      "  training_iteration: 489\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12367 s, 489 iter, 4890000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-16-58\n",
      "  done: false\n",
      "  episode_len_mean: 138.92\n",
      "  episode_reward_max: 800.8261914198714\n",
      "  episode_reward_mean: 718.7050660764797\n",
      "  episode_reward_min: -45.61714232965116\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 35782\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.086\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 4900000\n",
      "    num_steps_trained: 4900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.317170239824918e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.978504478931427\n",
      "      kl: 0.024076983332633972\n",
      "      policy_loss: -0.0036807216238230467\n",
      "      total_loss: 124.85550689697266\n",
      "      vf_explained_var: 0.9913946390151978\n",
      "      vf_loss: 124.85919952392578\n",
      "    sample_time_ms: 18479.454\n",
      "    update_time_ms: 5.696\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.35253303823976\n",
      "  time_since_restore: 12389.678230047226\n",
      "  time_this_iter_s: 22.394012451171875\n",
      "  time_total_s: 12389.678230047226\n",
      "  timestamp: 1553721418\n",
      "  timesteps_since_restore: 4900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4900000\n",
      "  training_iteration: 490\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12389 s, 490 iter, 4900000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-17-21\n",
      "  done: false\n",
      "  episode_len_mean: 138.51\n",
      "  episode_reward_max: 791.8192101093324\n",
      "  episode_reward_mean: 701.506624458902\n",
      "  episode_reward_min: -123.11136025368258\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 35855\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.234\n",
      "    load_time_ms: 1.583\n",
      "    num_steps_sampled: 4910000\n",
      "    num_steps_trained: 4910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.317170239824918e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0411134958267212\n",
      "      kl: 0.02052053064107895\n",
      "      policy_loss: -0.003007733728736639\n",
      "      total_loss: 587.2576293945312\n",
      "      vf_explained_var: 0.9541264176368713\n",
      "      vf_loss: 587.2605590820312\n",
      "    sample_time_ms: 18579.917\n",
      "    update_time_ms: 5.71\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.7533122294511\n",
      "  time_since_restore: 12412.634938955307\n",
      "  time_this_iter_s: 22.956708908081055\n",
      "  time_total_s: 12412.634938955307\n",
      "  timestamp: 1553721441\n",
      "  timesteps_since_restore: 4910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4910000\n",
      "  training_iteration: 491\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12412 s, 491 iter, 4910000 ts, 702 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-17-44\n",
      "  done: false\n",
      "  episode_len_mean: 139.07\n",
      "  episode_reward_max: 787.4679511020743\n",
      "  episode_reward_mean: 706.6913229182787\n",
      "  episode_reward_min: -113.50687425312795\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 35927\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3770.985\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 4920000\n",
      "    num_steps_trained: 4920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.317170239824918e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9701422452926636\n",
      "      kl: 3.093540906906128\n",
      "      policy_loss: -0.001859833369962871\n",
      "      total_loss: 113.63744354248047\n",
      "      vf_explained_var: 0.9915376305580139\n",
      "      vf_loss: 113.63929748535156\n",
      "    sample_time_ms: 18591.275\n",
      "    update_time_ms: 5.522\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.34566145913936\n",
      "  time_since_restore: 12435.257536411285\n",
      "  time_this_iter_s: 22.622597455978394\n",
      "  time_total_s: 12435.257536411285\n",
      "  timestamp: 1553721464\n",
      "  timesteps_since_restore: 4920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4920000\n",
      "  training_iteration: 492\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12435 s, 492 iter, 4920000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-18-06\n",
      "  done: false\n",
      "  episode_len_mean: 138.3\n",
      "  episode_reward_max: 784.3898800178703\n",
      "  episode_reward_mean: 719.8093668768531\n",
      "  episode_reward_min: -115.87402185421811\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 36000\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3772.653\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 4930000\n",
      "    num_steps_trained: 4930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.975755018676864e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9341241121292114\n",
      "      kl: 0.015513665974140167\n",
      "      policy_loss: 0.00020343295182101429\n",
      "      total_loss: 212.2198944091797\n",
      "      vf_explained_var: 0.9821356534957886\n",
      "      vf_loss: 212.2196807861328\n",
      "    sample_time_ms: 18571.012\n",
      "    update_time_ms: 5.583\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.90468343842656\n",
      "  time_since_restore: 12457.259442329407\n",
      "  time_this_iter_s: 22.001905918121338\n",
      "  time_total_s: 12457.259442329407\n",
      "  timestamp: 1553721486\n",
      "  timesteps_since_restore: 4930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4930000\n",
      "  training_iteration: 493\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12457 s, 493 iter, 4930000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-18-28\n",
      "  done: false\n",
      "  episode_len_mean: 139.16\n",
      "  episode_reward_max: 785.0276246205389\n",
      "  episode_reward_mean: 726.1029894750558\n",
      "  episode_reward_min: 675.2691254385228\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 36072\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.626\n",
      "    load_time_ms: 1.545\n",
      "    num_steps_sampled: 4940000\n",
      "    num_steps_trained: 4940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.975755018676864e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9795234799385071\n",
      "      kl: 0.023613382130861282\n",
      "      policy_loss: -0.004057168494910002\n",
      "      total_loss: 79.47140502929688\n",
      "      vf_explained_var: 0.996242105960846\n",
      "      vf_loss: 79.4754638671875\n",
      "    sample_time_ms: 18631.247\n",
      "    update_time_ms: 5.592\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 363.05149473752795\n",
      "  time_since_restore: 12479.624264478683\n",
      "  time_this_iter_s: 22.364822149276733\n",
      "  time_total_s: 12479.624264478683\n",
      "  timestamp: 1553721508\n",
      "  timesteps_since_restore: 4940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4940000\n",
      "  training_iteration: 494\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12479 s, 494 iter, 4940000 ts, 726 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-18-51\n",
      "  done: false\n",
      "  episode_len_mean: 138.64\n",
      "  episode_reward_max: 785.3563181599415\n",
      "  episode_reward_mean: 719.286595986997\n",
      "  episode_reward_min: -116.69503332414278\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 36144\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3765.421\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 4950000\n",
      "    num_steps_trained: 4950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.975755018676864e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0415146350860596\n",
      "      kl: 0.03174060583114624\n",
      "      policy_loss: -0.0011978039983659983\n",
      "      total_loss: 118.91586303710938\n",
      "      vf_explained_var: 0.9929873943328857\n",
      "      vf_loss: 118.91707611083984\n",
      "    sample_time_ms: 18644.44\n",
      "    update_time_ms: 5.375\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.6432979934985\n",
      "  time_since_restore: 12501.841413736343\n",
      "  time_this_iter_s: 22.217149257659912\n",
      "  time_total_s: 12501.841413736343\n",
      "  timestamp: 1553721531\n",
      "  timesteps_since_restore: 4950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4950000\n",
      "  training_iteration: 495\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12501 s, 495 iter, 4950000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-19-13\n",
      "  done: false\n",
      "  episode_len_mean: 135.94\n",
      "  episode_reward_max: 784.08389082409\n",
      "  episode_reward_mean: 694.3401718361176\n",
      "  episode_reward_min: -95.93109683987757\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 36218\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3779.745\n",
      "    load_time_ms: 1.641\n",
      "    num_steps_sampled: 4960000\n",
      "    num_steps_trained: 4960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.975755018676864e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9305756688117981\n",
      "      kl: 0.01620384119451046\n",
      "      policy_loss: -0.00276849209330976\n",
      "      total_loss: 683.2957153320312\n",
      "      vf_explained_var: 0.9438134431838989\n",
      "      vf_loss: 683.2985229492188\n",
      "    sample_time_ms: 18640.088\n",
      "    update_time_ms: 5.321\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.17008591805876\n",
      "  time_since_restore: 12524.273710250854\n",
      "  time_this_iter_s: 22.43229651451111\n",
      "  time_total_s: 12524.273710250854\n",
      "  timestamp: 1553721553\n",
      "  timesteps_since_restore: 4960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4960000\n",
      "  training_iteration: 496\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12524 s, 496 iter, 4960000 ts, 694 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-19-36\n",
      "  done: false\n",
      "  episode_len_mean: 136.85\n",
      "  episode_reward_max: 793.9832107149671\n",
      "  episode_reward_mean: 708.304858013732\n",
      "  episode_reward_min: -115.58026946776323\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 36291\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3781.117\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 4970000\n",
      "    num_steps_trained: 4970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.975755018676864e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9249203205108643\n",
      "      kl: 0.01880030147731304\n",
      "      policy_loss: -0.0019427529769018292\n",
      "      total_loss: 101.630615234375\n",
      "      vf_explained_var: 0.9917383193969727\n",
      "      vf_loss: 101.63255310058594\n",
      "    sample_time_ms: 18644.837\n",
      "    update_time_ms: 5.344\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.152429006866\n",
      "  time_since_restore: 12546.803897619247\n",
      "  time_this_iter_s: 22.530187368392944\n",
      "  time_total_s: 12546.803897619247\n",
      "  timestamp: 1553721576\n",
      "  timesteps_since_restore: 4970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4970000\n",
      "  training_iteration: 497\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12546 s, 497 iter, 4970000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-19-58\n",
      "  done: false\n",
      "  episode_len_mean: 135.91\n",
      "  episode_reward_max: 798.3574736796262\n",
      "  episode_reward_mean: 696.6204263282373\n",
      "  episode_reward_min: -126.73151492683056\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 36366\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.915\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 4980000\n",
      "    num_steps_trained: 4980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.975755018676864e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9615263342857361\n",
      "      kl: 0.04340652748942375\n",
      "      policy_loss: -0.0008161509176716208\n",
      "      total_loss: 464.6204528808594\n",
      "      vf_explained_var: 0.9621114730834961\n",
      "      vf_loss: 464.6213073730469\n",
      "    sample_time_ms: 18565.633\n",
      "    update_time_ms: 5.321\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.3102131641187\n",
      "  time_since_restore: 12568.604437112808\n",
      "  time_this_iter_s: 21.80053949356079\n",
      "  time_total_s: 12568.604437112808\n",
      "  timestamp: 1553721598\n",
      "  timesteps_since_restore: 4980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4980000\n",
      "  training_iteration: 498\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12568 s, 498 iter, 4980000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-20-20\n",
      "  done: false\n",
      "  episode_len_mean: 137.54\n",
      "  episode_reward_max: 798.3574736796262\n",
      "  episode_reward_mean: 721.2725818155059\n",
      "  episode_reward_min: -63.426270145851646\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 36438\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.429\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 4990000\n",
      "    num_steps_trained: 4990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.463632755388971e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9652876257896423\n",
      "      kl: 0.01785965822637081\n",
      "      policy_loss: -0.0041660647839307785\n",
      "      total_loss: 222.244140625\n",
      "      vf_explained_var: 0.9807833433151245\n",
      "      vf_loss: 222.24832153320312\n",
      "    sample_time_ms: 18569.414\n",
      "    update_time_ms: 5.447\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.63629090775305\n",
      "  time_since_restore: 12590.898851633072\n",
      "  time_this_iter_s: 22.294414520263672\n",
      "  time_total_s: 12590.898851633072\n",
      "  timestamp: 1553721620\n",
      "  timesteps_since_restore: 4990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4990000\n",
      "  training_iteration: 499\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12590 s, 499 iter, 4990000 ts, 721 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-20-42\n",
      "  done: false\n",
      "  episode_len_mean: 134.95\n",
      "  episode_reward_max: 797.5691764741981\n",
      "  episode_reward_mean: 696.4921211289741\n",
      "  episode_reward_min: -104.14956668416708\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 36513\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3783.4\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 5000000\n",
      "    num_steps_trained: 5000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.463632755388971e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9357120990753174\n",
      "      kl: 0.013565601781010628\n",
      "      policy_loss: -0.0006928304210305214\n",
      "      total_loss: 297.9629821777344\n",
      "      vf_explained_var: 0.9784429669380188\n",
      "      vf_loss: 297.96368408203125\n",
      "    sample_time_ms: 18540.713\n",
      "    update_time_ms: 5.387\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.24606056448715\n",
      "  time_since_restore: 12613.163339614868\n",
      "  time_this_iter_s: 22.264487981796265\n",
      "  time_total_s: 12613.163339614868\n",
      "  timestamp: 1553721642\n",
      "  timesteps_since_restore: 5000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5000000\n",
      "  training_iteration: 500\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12613 s, 500 iter, 5000000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-21-05\n",
      "  done: false\n",
      "  episode_len_mean: 135.86\n",
      "  episode_reward_max: 790.5919857563097\n",
      "  episode_reward_mean: 704.7157918421519\n",
      "  episode_reward_min: -85.98716777599253\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 36587\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3781.091\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 5010000\n",
      "    num_steps_trained: 5010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.463632755388971e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9589176774024963\n",
      "      kl: 0.01505229715257883\n",
      "      policy_loss: -0.004262365400791168\n",
      "      total_loss: 57.91355514526367\n",
      "      vf_explained_var: 0.9957983493804932\n",
      "      vf_loss: 57.91781997680664\n",
      "    sample_time_ms: 18475.779\n",
      "    update_time_ms: 5.294\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.35789592107596\n",
      "  time_since_restore: 12635.443211555481\n",
      "  time_this_iter_s: 22.279871940612793\n",
      "  time_total_s: 12635.443211555481\n",
      "  timestamp: 1553721665\n",
      "  timesteps_since_restore: 5010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5010000\n",
      "  training_iteration: 501\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12635 s, 501 iter, 5010000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 136.72\n",
      "  episode_reward_max: 790.7442251663263\n",
      "  episode_reward_mean: 711.5385302488789\n",
      "  episode_reward_min: -69.70201863801154\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 36660\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.861\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 5020000\n",
      "    num_steps_trained: 5020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.463632755388971e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9325677752494812\n",
      "      kl: 0.018167642876505852\n",
      "      policy_loss: -0.0036352896131575108\n",
      "      total_loss: 368.6000671386719\n",
      "      vf_explained_var: 0.9698977470397949\n",
      "      vf_loss: 368.6036682128906\n",
      "    sample_time_ms: 18454.503\n",
      "    update_time_ms: 5.212\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.7692651244395\n",
      "  time_since_restore: 12657.672286987305\n",
      "  time_this_iter_s: 22.22907543182373\n",
      "  time_total_s: 12657.672286987305\n",
      "  timestamp: 1553721687\n",
      "  timesteps_since_restore: 5020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5020000\n",
      "  training_iteration: 502\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12657 s, 502 iter, 5020000 ts, 712 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-21-49\n",
      "  done: false\n",
      "  episode_len_mean: 133.95\n",
      "  episode_reward_max: 790.7442251663263\n",
      "  episode_reward_mean: 690.779727446246\n",
      "  episode_reward_min: -124.48746324491447\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 36734\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3757.392\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 5030000\n",
      "    num_steps_trained: 5030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.463632755388971e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9586349725723267\n",
      "      kl: 0.017642129212617874\n",
      "      policy_loss: -0.003229656955227256\n",
      "      total_loss: 324.2786560058594\n",
      "      vf_explained_var: 0.9754900932312012\n",
      "      vf_loss: 324.2818908691406\n",
      "    sample_time_ms: 18454.865\n",
      "    update_time_ms: 5.159\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.38986372312314\n",
      "  time_since_restore: 12679.622044563293\n",
      "  time_this_iter_s: 21.94975757598877\n",
      "  time_total_s: 12679.622044563293\n",
      "  timestamp: 1553721709\n",
      "  timesteps_since_restore: 5030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5030000\n",
      "  training_iteration: 503\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12679 s, 503 iter, 5030000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-22-11\n",
      "  done: false\n",
      "  episode_len_mean: 134.8\n",
      "  episode_reward_max: 787.2398747976785\n",
      "  episode_reward_mean: 684.9145201167548\n",
      "  episode_reward_min: -66.03533187632746\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 36810\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3754.08\n",
      "    load_time_ms: 1.495\n",
      "    num_steps_sampled: 5040000\n",
      "    num_steps_trained: 5040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.463632755388971e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9625201225280762\n",
      "      kl: 0.021544931456446648\n",
      "      policy_loss: -0.003993301186710596\n",
      "      total_loss: 436.8573303222656\n",
      "      vf_explained_var: 0.968086838722229\n",
      "      vf_loss: 436.86126708984375\n",
      "    sample_time_ms: 18440.97\n",
      "    update_time_ms: 5.29\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.4572600583776\n",
      "  time_since_restore: 12701.818254470825\n",
      "  time_this_iter_s: 22.19620990753174\n",
      "  time_total_s: 12701.818254470825\n",
      "  timestamp: 1553721731\n",
      "  timesteps_since_restore: 5040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5040000\n",
      "  training_iteration: 504\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12701 s, 504 iter, 5040000 ts, 685 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-22-33\n",
      "  done: false\n",
      "  episode_len_mean: 134.52\n",
      "  episode_reward_max: 787.918006559905\n",
      "  episode_reward_mean: 696.2816951359778\n",
      "  episode_reward_min: -118.19820032660832\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 36883\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.545\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 5050000\n",
      "    num_steps_trained: 5050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.463632755388971e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9034944176673889\n",
      "      kl: 0.026218904182314873\n",
      "      policy_loss: -0.0022078019101172686\n",
      "      total_loss: 498.6436767578125\n",
      "      vf_explained_var: 0.9587875008583069\n",
      "      vf_loss: 498.64593505859375\n",
      "    sample_time_ms: 18421.082\n",
      "    update_time_ms: 5.212\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.1408475679889\n",
      "  time_since_restore: 12723.828883647919\n",
      "  time_this_iter_s: 22.010629177093506\n",
      "  time_total_s: 12723.828883647919\n",
      "  timestamp: 1553721753\n",
      "  timesteps_since_restore: 5050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5050000\n",
      "  training_iteration: 505\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12723 s, 505 iter, 5050000 ts, 696 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-22-55\n",
      "  done: false\n",
      "  episode_len_mean: 136.08\n",
      "  episode_reward_max: 790.761498896612\n",
      "  episode_reward_mean: 711.7813021346045\n",
      "  episode_reward_min: -119.42445647999432\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 36958\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3737.769\n",
      "    load_time_ms: 1.43\n",
      "    num_steps_sampled: 5060000\n",
      "    num_steps_trained: 5060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.463632755388971e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9453606009483337\n",
      "      kl: 2.940443277359009\n",
      "      policy_loss: -0.0008568331249989569\n",
      "      total_loss: 182.17202758789062\n",
      "      vf_explained_var: 0.9878937005996704\n",
      "      vf_loss: 182.1728515625\n",
      "    sample_time_ms: 18408.824\n",
      "    update_time_ms: 5.159\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.8906510673023\n",
      "  time_since_restore: 12745.977488279343\n",
      "  time_this_iter_s: 22.14860463142395\n",
      "  time_total_s: 12745.977488279343\n",
      "  timestamp: 1553721775\n",
      "  timesteps_since_restore: 5060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5060000\n",
      "  training_iteration: 506\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12745 s, 506 iter, 5060000 ts, 712 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-23-18\n",
      "  done: false\n",
      "  episode_len_mean: 135.76\n",
      "  episode_reward_max: 790.761498896612\n",
      "  episode_reward_mean: 710.8158477450888\n",
      "  episode_reward_min: -118.66833647429232\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 37033\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.225\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 5070000\n",
      "    num_steps_trained: 5070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1195449587830808e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9509873986244202\n",
      "      kl: 0.024221133440732956\n",
      "      policy_loss: -0.0036438684910535812\n",
      "      total_loss: 178.25271606445312\n",
      "      vf_explained_var: 0.9853140115737915\n",
      "      vf_loss: 178.25634765625\n",
      "    sample_time_ms: 18396.616\n",
      "    update_time_ms: 5.126\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.4079238725445\n",
      "  time_since_restore: 12768.410489320755\n",
      "  time_this_iter_s: 22.433001041412354\n",
      "  time_total_s: 12768.410489320755\n",
      "  timestamp: 1553721798\n",
      "  timesteps_since_restore: 5070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5070000\n",
      "  training_iteration: 507\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12768 s, 507 iter, 5070000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-23-40\n",
      "  done: false\n",
      "  episode_len_mean: 134.57\n",
      "  episode_reward_max: 780.5435149933197\n",
      "  episode_reward_mean: 703.0557406588143\n",
      "  episode_reward_min: -74.25121526974739\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 37107\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.584\n",
      "    load_time_ms: 1.422\n",
      "    num_steps_sampled: 5080000\n",
      "    num_steps_trained: 5080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1195449587830808e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9923176169395447\n",
      "      kl: 0.018910493701696396\n",
      "      policy_loss: -0.0014723386848345399\n",
      "      total_loss: 65.57621002197266\n",
      "      vf_explained_var: 0.9958419799804688\n",
      "      vf_loss: 65.57767486572266\n",
      "    sample_time_ms: 18404.281\n",
      "    update_time_ms: 5.268\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.5278703294071\n",
      "  time_since_restore: 12790.2526845932\n",
      "  time_this_iter_s: 21.84219527244568\n",
      "  time_total_s: 12790.2526845932\n",
      "  timestamp: 1553721820\n",
      "  timesteps_since_restore: 5080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5080000\n",
      "  training_iteration: 508\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12790 s, 508 iter, 5080000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-24-02\n",
      "  done: false\n",
      "  episode_len_mean: 132.91\n",
      "  episode_reward_max: 789.985412135431\n",
      "  episode_reward_mean: 697.1548228004676\n",
      "  episode_reward_min: -88.87842448482645\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 37183\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.006\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 5090000\n",
      "    num_steps_trained: 5090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1195449587830808e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9378808736801147\n",
      "      kl: 0.014771687798202038\n",
      "      policy_loss: -0.001955633284524083\n",
      "      total_loss: 458.6739807128906\n",
      "      vf_explained_var: 0.9643908739089966\n",
      "      vf_loss: 458.6759948730469\n",
      "    sample_time_ms: 18442.722\n",
      "    update_time_ms: 5.157\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.5774114002338\n",
      "  time_since_restore: 12812.962991476059\n",
      "  time_this_iter_s: 22.710306882858276\n",
      "  time_total_s: 12812.962991476059\n",
      "  timestamp: 1553721842\n",
      "  timesteps_since_restore: 5090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5090000\n",
      "  training_iteration: 509\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12812 s, 509 iter, 5090000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-24-25\n",
      "  done: false\n",
      "  episode_len_mean: 131.31\n",
      "  episode_reward_max: 789.985412135431\n",
      "  episode_reward_mean: 702.1544955992322\n",
      "  episode_reward_min: -132.4476031142505\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 37261\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3728.253\n",
      "    load_time_ms: 1.411\n",
      "    num_steps_sampled: 5100000\n",
      "    num_steps_trained: 5100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1195449587830808e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8929973244667053\n",
      "      kl: 0.028252044692635536\n",
      "      policy_loss: -0.005237380508333445\n",
      "      total_loss: 333.525390625\n",
      "      vf_explained_var: 0.9730215668678284\n",
      "      vf_loss: 333.5306396484375\n",
      "    sample_time_ms: 18499.44\n",
      "    update_time_ms: 5.176\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.07724779961615\n",
      "  time_since_restore: 12835.6849899292\n",
      "  time_this_iter_s: 22.72199845314026\n",
      "  time_total_s: 12835.6849899292\n",
      "  timestamp: 1553721865\n",
      "  timesteps_since_restore: 5100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5100000\n",
      "  training_iteration: 510\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12835 s, 510 iter, 5100000 ts, 702 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-24-48\n",
      "  done: false\n",
      "  episode_len_mean: 131.69\n",
      "  episode_reward_max: 795.6658737757191\n",
      "  episode_reward_mean: 691.7060836896583\n",
      "  episode_reward_min: -85.66398588814525\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 37335\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3728.426\n",
      "    load_time_ms: 1.406\n",
      "    num_steps_sampled: 5110000\n",
      "    num_steps_trained: 5110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1195449587830808e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9596135020256042\n",
      "      kl: 0.013330867514014244\n",
      "      policy_loss: -0.0028972013387829065\n",
      "      total_loss: 73.17886352539062\n",
      "      vf_explained_var: 0.9946151375770569\n",
      "      vf_loss: 73.1817626953125\n",
      "    sample_time_ms: 18510.413\n",
      "    update_time_ms: 5.363\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.8530418448292\n",
      "  time_since_restore: 12858.078676223755\n",
      "  time_this_iter_s: 22.393686294555664\n",
      "  time_total_s: 12858.078676223755\n",
      "  timestamp: 1553721888\n",
      "  timesteps_since_restore: 5110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5110000\n",
      "  training_iteration: 511\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12858 s, 511 iter, 5110000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-25-13\n",
      "  done: false\n",
      "  episode_len_mean: 132.32\n",
      "  episode_reward_max: 790.4686906476651\n",
      "  episode_reward_mean: 683.937139043976\n",
      "  episode_reward_min: -116.7132152530639\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 37412\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3764.299\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 5120000\n",
      "    num_steps_trained: 5120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1195449587830808e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9589323401451111\n",
      "      kl: 0.022263113409280777\n",
      "      policy_loss: -0.004797408357262611\n",
      "      total_loss: 208.38330078125\n",
      "      vf_explained_var: 0.9846664071083069\n",
      "      vf_loss: 208.38809204101562\n",
      "    sample_time_ms: 18754.874\n",
      "    update_time_ms: 5.373\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.968569521988\n",
      "  time_since_restore: 12883.112798452377\n",
      "  time_this_iter_s: 25.034122228622437\n",
      "  time_total_s: 12883.112798452377\n",
      "  timestamp: 1553721913\n",
      "  timesteps_since_restore: 5120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5120000\n",
      "  training_iteration: 512\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12883 s, 512 iter, 5120000 ts, 684 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-25-36\n",
      "  done: false\n",
      "  episode_len_mean: 133.43\n",
      "  episode_reward_max: 790.5966316471711\n",
      "  episode_reward_mean: 704.8272921020898\n",
      "  episode_reward_min: -95.3870027904296\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 37488\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3779.334\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 5130000\n",
      "    num_steps_trained: 5130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1195449587830808e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9172201156616211\n",
      "      kl: 0.04716372489929199\n",
      "      policy_loss: 0.0010914378799498081\n",
      "      total_loss: 233.91964721679688\n",
      "      vf_explained_var: 0.9810498356819153\n",
      "      vf_loss: 233.91856384277344\n",
      "    sample_time_ms: 18860.711\n",
      "    update_time_ms: 5.411\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.4136460510449\n",
      "  time_since_restore: 12906.273735523224\n",
      "  time_this_iter_s: 23.160937070846558\n",
      "  time_total_s: 12906.273735523224\n",
      "  timestamp: 1553721936\n",
      "  timesteps_since_restore: 5130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5130000\n",
      "  training_iteration: 513\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12906 s, 513 iter, 5130000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-26-01\n",
      "  done: false\n",
      "  episode_len_mean: 131.95\n",
      "  episode_reward_max: 781.8491360939938\n",
      "  episode_reward_mean: 698.2390037648995\n",
      "  episode_reward_min: -97.3698054155036\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 37564\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3803.291\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 5140000\n",
      "    num_steps_trained: 5140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6793172108009458e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8231044411659241\n",
      "      kl: 0.02185421623289585\n",
      "      policy_loss: -0.004140759352594614\n",
      "      total_loss: 113.70297241210938\n",
      "      vf_explained_var: 0.992438793182373\n",
      "      vf_loss: 113.70710754394531\n",
      "    sample_time_ms: 19153.847\n",
      "    update_time_ms: 5.368\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.11950188244987\n",
      "  time_since_restore: 12931.637843608856\n",
      "  time_this_iter_s: 25.364108085632324\n",
      "  time_total_s: 12931.637843608856\n",
      "  timestamp: 1553721961\n",
      "  timesteps_since_restore: 5140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5140000\n",
      "  training_iteration: 514\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12931 s, 514 iter, 5140000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-26-27\n",
      "  done: false\n",
      "  episode_len_mean: 133.63\n",
      "  episode_reward_max: 800.3880592029813\n",
      "  episode_reward_mean: 712.6406933323088\n",
      "  episode_reward_min: -26.47015833609325\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 37639\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3896.684\n",
      "    load_time_ms: 1.473\n",
      "    num_steps_sampled: 5150000\n",
      "    num_steps_trained: 5150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6793172108009458e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9262579679489136\n",
      "      kl: 0.0478435680270195\n",
      "      policy_loss: -0.005687138065695763\n",
      "      total_loss: 556.5657958984375\n",
      "      vf_explained_var: 0.9585782289505005\n",
      "      vf_loss: 556.571533203125\n",
      "    sample_time_ms: 19480.114\n",
      "    update_time_ms: 5.55\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.32034666615436\n",
      "  time_since_restore: 12957.847474098206\n",
      "  time_this_iter_s: 26.209630489349365\n",
      "  time_total_s: 12957.847474098206\n",
      "  timestamp: 1553721987\n",
      "  timesteps_since_restore: 5150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5150000\n",
      "  training_iteration: 515\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12957 s, 515 iter, 5150000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-26-59\n",
      "  done: false\n",
      "  episode_len_mean: 131.67\n",
      "  episode_reward_max: 800.3880592029813\n",
      "  episode_reward_mean: 689.4660718871197\n",
      "  episode_reward_min: -115.60053213582398\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 37714\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4361.741\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 5160000\n",
      "    num_steps_trained: 5160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.843498706817627\n",
      "      kl: 0.02003086917102337\n",
      "      policy_loss: -0.004116787109524012\n",
      "      total_loss: 245.65379333496094\n",
      "      vf_explained_var: 0.9811410903930664\n",
      "      vf_loss: 245.65789794921875\n",
      "    sample_time_ms: 19907.68\n",
      "    update_time_ms: 5.467\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.73303594355997\n",
      "  time_since_restore: 12988.93294930458\n",
      "  time_this_iter_s: 31.085475206375122\n",
      "  time_total_s: 12988.93294930458\n",
      "  timestamp: 1553722019\n",
      "  timesteps_since_restore: 5160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5160000\n",
      "  training_iteration: 516\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 12988 s, 516 iter, 5160000 ts, 689 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-27-42\n",
      "  done: false\n",
      "  episode_len_mean: 132.18\n",
      "  episode_reward_max: 784.9730475383099\n",
      "  episode_reward_mean: 698.4087193857882\n",
      "  episode_reward_min: -130.1079696479084\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 37791\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4581.462\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 5170000\n",
      "    num_steps_trained: 5170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8526040315628052\n",
      "      kl: 0.02178562618792057\n",
      "      policy_loss: -0.0007526524714194238\n",
      "      total_loss: 377.3722839355469\n",
      "      vf_explained_var: 0.9703081846237183\n",
      "      vf_loss: 377.3730163574219\n",
      "    sample_time_ms: 21749.276\n",
      "    update_time_ms: 6.149\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.20435969289406\n",
      "  time_since_restore: 13031.988708496094\n",
      "  time_this_iter_s: 43.05575919151306\n",
      "  time_total_s: 13031.988708496094\n",
      "  timestamp: 1553722062\n",
      "  timesteps_since_restore: 5170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5170000\n",
      "  training_iteration: 517\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13031 s, 517 iter, 5170000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 133.56\n",
      "  episode_reward_max: 789.3253641350772\n",
      "  episode_reward_mean: 717.5442905408346\n",
      "  episode_reward_min: -108.14029014436825\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 37867\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4763.608\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 5180000\n",
      "    num_steps_trained: 5180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8672364354133606\n",
      "      kl: 0.01783583126962185\n",
      "      policy_loss: -0.002016717102378607\n",
      "      total_loss: 148.4134063720703\n",
      "      vf_explained_var: 0.9884933233261108\n",
      "      vf_loss: 148.41542053222656\n",
      "    sample_time_ms: 22267.241\n",
      "    update_time_ms: 6.171\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.7721452704173\n",
      "  time_since_restore: 13060.840867042542\n",
      "  time_this_iter_s: 28.852158546447754\n",
      "  time_total_s: 13060.840867042542\n",
      "  timestamp: 1553722091\n",
      "  timesteps_since_restore: 5180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5180000\n",
      "  training_iteration: 518\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13060 s, 518 iter, 5180000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-28-45\n",
      "  done: false\n",
      "  episode_len_mean: 133.52\n",
      "  episode_reward_max: 795.3117318024665\n",
      "  episode_reward_mean: 705.5693779508077\n",
      "  episode_reward_min: -44.057260337176814\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 37942\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5307.956\n",
      "    load_time_ms: 1.71\n",
      "    num_steps_sampled: 5190000\n",
      "    num_steps_trained: 5190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8791966438293457\n",
      "      kl: 0.023974165320396423\n",
      "      policy_loss: -0.007935927249491215\n",
      "      total_loss: 210.01170349121094\n",
      "      vf_explained_var: 0.9849051237106323\n",
      "      vf_loss: 210.01963806152344\n",
      "    sample_time_ms: 22868.04\n",
      "    update_time_ms: 6.466\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.78468897540387\n",
      "  time_since_restore: 13095.02287197113\n",
      "  time_this_iter_s: 34.18200492858887\n",
      "  time_total_s: 13095.02287197113\n",
      "  timestamp: 1553722125\n",
      "  timesteps_since_restore: 5190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5190000\n",
      "  training_iteration: 519\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13095 s, 519 iter, 5190000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-29-54\n",
      "  done: false\n",
      "  episode_len_mean: 132.39\n",
      "  episode_reward_max: 798.8094772816889\n",
      "  episode_reward_mean: 696.8060828961266\n",
      "  episode_reward_min: -100.87567074166938\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 38018\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6609.826\n",
      "    load_time_ms: 2.097\n",
      "    num_steps_sampled: 5200000\n",
      "    num_steps_trained: 5200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9063716530799866\n",
      "      kl: 0.020634358748793602\n",
      "      policy_loss: -0.002634279429912567\n",
      "      total_loss: 261.8041687011719\n",
      "      vf_explained_var: 0.9813668727874756\n",
      "      vf_loss: 261.80682373046875\n",
      "    sample_time_ms: 26167.795\n",
      "    update_time_ms: 7.139\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.4030414480632\n",
      "  time_since_restore: 13163.809772253036\n",
      "  time_this_iter_s: 68.78690028190613\n",
      "  time_total_s: 13163.809772253036\n",
      "  timestamp: 1553722194\n",
      "  timesteps_since_restore: 5200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5200000\n",
      "  training_iteration: 520\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13163 s, 520 iter, 5200000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-31-32\n",
      "  done: false\n",
      "  episode_len_mean: 133.93\n",
      "  episode_reward_max: 799.020723516806\n",
      "  episode_reward_mean: 709.328321600194\n",
      "  episode_reward_min: -124.18751866153934\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 38093\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8248.841\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 5210000\n",
      "    num_steps_trained: 5210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8929545283317566\n",
      "      kl: 0.02427123673260212\n",
      "      policy_loss: -0.004425998777151108\n",
      "      total_loss: 38.3135871887207\n",
      "      vf_explained_var: 0.9977180361747742\n",
      "      vf_loss: 38.318016052246094\n",
      "    sample_time_ms: 32120.608\n",
      "    update_time_ms: 8.419\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.6641608000971\n",
      "  time_since_restore: 13262.177253246307\n",
      "  time_this_iter_s: 98.36748099327087\n",
      "  time_total_s: 13262.177253246307\n",
      "  timestamp: 1553722292\n",
      "  timesteps_since_restore: 5210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5210000\n",
      "  training_iteration: 521\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13262 s, 521 iter, 5210000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-32-32\n",
      "  done: false\n",
      "  episode_len_mean: 132.85\n",
      "  episode_reward_max: 799.020723516806\n",
      "  episode_reward_mean: 694.821672823176\n",
      "  episode_reward_min: -123.0490382436467\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 38169\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8426.163\n",
      "    load_time_ms: 2.506\n",
      "    num_steps_sampled: 5220000\n",
      "    num_steps_trained: 5220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9227126836776733\n",
      "      kl: 0.022256609052419662\n",
      "      policy_loss: -0.005214992444962263\n",
      "      total_loss: 509.1803894042969\n",
      "      vf_explained_var: 0.9610104560852051\n",
      "      vf_loss: 509.18560791015625\n",
      "    sample_time_ms: 35433.605\n",
      "    update_time_ms: 9.696\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.4108364115881\n",
      "  time_since_restore: 13322.143692731857\n",
      "  time_this_iter_s: 59.96643948554993\n",
      "  time_total_s: 13322.143692731857\n",
      "  timestamp: 1553722352\n",
      "  timesteps_since_restore: 5220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5220000\n",
      "  training_iteration: 522\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13322 s, 522 iter, 5220000 ts, 695 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-32-59\n",
      "  done: false\n",
      "  episode_len_mean: 131.59\n",
      "  episode_reward_max: 787.8554665140366\n",
      "  episode_reward_mean: 688.5768912004186\n",
      "  episode_reward_min: -97.47504217397264\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 38245\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8534.914\n",
      "    load_time_ms: 2.447\n",
      "    num_steps_sampled: 5230000\n",
      "    num_steps_trained: 5230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8869775533676147\n",
      "      kl: 0.015520283952355385\n",
      "      policy_loss: -0.002006910275667906\n",
      "      total_loss: 561.4088745117188\n",
      "      vf_explained_var: 0.958158552646637\n",
      "      vf_loss: 561.4108276367188\n",
      "    sample_time_ms: 35714.965\n",
      "    update_time_ms: 9.953\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.2884456002093\n",
      "  time_since_restore: 13349.206772327423\n",
      "  time_this_iter_s: 27.063079595565796\n",
      "  time_total_s: 13349.206772327423\n",
      "  timestamp: 1553722379\n",
      "  timesteps_since_restore: 5230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5230000\n",
      "  training_iteration: 523\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13349 s, 523 iter, 5230000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-33-34\n",
      "  done: false\n",
      "  episode_len_mean: 132.9\n",
      "  episode_reward_max: 806.7141934349481\n",
      "  episode_reward_mean: 694.9188897504464\n",
      "  episode_reward_min: -32.32410755460651\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 38320\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8786.014\n",
      "    load_time_ms: 2.445\n",
      "    num_steps_sampled: 5240000\n",
      "    num_steps_trained: 5240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.876141369342804\n",
      "      kl: 0.026926783844828606\n",
      "      policy_loss: -0.008357159793376923\n",
      "      total_loss: 91.56307220458984\n",
      "      vf_explained_var: 0.9923683404922485\n",
      "      vf_loss: 91.57142639160156\n",
      "    sample_time_ms: 36409.255\n",
      "    update_time_ms: 9.922\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.4594448752232\n",
      "  time_since_restore: 13384.02931690216\n",
      "  time_this_iter_s: 34.82254457473755\n",
      "  time_total_s: 13384.02931690216\n",
      "  timestamp: 1553722414\n",
      "  timesteps_since_restore: 5240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5240000\n",
      "  training_iteration: 524\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13384 s, 524 iter, 5240000 ts, 695 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-34-22\n",
      "  done: false\n",
      "  episode_len_mean: 128.97\n",
      "  episode_reward_max: 806.7141934349481\n",
      "  episode_reward_mean: 662.9586921480242\n",
      "  episode_reward_min: -115.55977981963413\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 38399\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9924.001\n",
      "    load_time_ms: 2.585\n",
      "    num_steps_sampled: 5250000\n",
      "    num_steps_trained: 5250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8326959013938904\n",
      "      kl: 0.03161747381091118\n",
      "      policy_loss: -0.006391411181539297\n",
      "      total_loss: 486.2436828613281\n",
      "      vf_explained_var: 0.9654054045677185\n",
      "      vf_loss: 486.2500915527344\n",
      "    sample_time_ms: 37372.863\n",
      "    update_time_ms: 10.16\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 331.47934607401197\n",
      "  time_since_restore: 13431.28597187996\n",
      "  time_this_iter_s: 47.25665497779846\n",
      "  time_total_s: 13431.28597187996\n",
      "  timestamp: 1553722462\n",
      "  timesteps_since_restore: 5250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5250000\n",
      "  training_iteration: 525\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13431 s, 525 iter, 5250000 ts, 663 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-35-15\n",
      "  done: false\n",
      "  episode_len_mean: 132.97\n",
      "  episode_reward_max: 799.1119882377774\n",
      "  episode_reward_mean: 710.3970452568019\n",
      "  episode_reward_min: -106.86744249498952\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 38474\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 10090.395\n",
      "    load_time_ms: 2.815\n",
      "    num_steps_sampled: 5260000\n",
      "    num_steps_trained: 5260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.518975998100359e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8679400682449341\n",
      "      kl: 1.5133843421936035\n",
      "      policy_loss: -0.00397607171908021\n",
      "      total_loss: 39.69778060913086\n",
      "      vf_explained_var: 0.9975071549415588\n",
      "      vf_loss: 39.70172119140625\n",
      "    sample_time_ms: 39432.478\n",
      "    update_time_ms: 10.982\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.1985226284009\n",
      "  time_since_restore: 13484.652102470398\n",
      "  time_this_iter_s: 53.36613059043884\n",
      "  time_total_s: 13484.652102470398\n",
      "  timestamp: 1553722515\n",
      "  timesteps_since_restore: 5260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5260000\n",
      "  training_iteration: 526\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13484 s, 526 iter, 5260000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-35-45\n",
      "  done: false\n",
      "  episode_len_mean: 127.92\n",
      "  episode_reward_max: 791.1996443064388\n",
      "  episode_reward_mean: 673.3455875440708\n",
      "  episode_reward_min: -124.94280074956833\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 38554\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9989.064\n",
      "    load_time_ms: 2.809\n",
      "    num_steps_sampled: 5270000\n",
      "    num_steps_trained: 5270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8655360341072083\n",
      "      kl: 0.025050103664398193\n",
      "      policy_loss: -0.0044493903405964375\n",
      "      total_loss: 496.84100341796875\n",
      "      vf_explained_var: 0.9617872834205627\n",
      "      vf_loss: 496.845458984375\n",
      "    sample_time_ms: 38181.204\n",
      "    update_time_ms: 10.944\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.6727937720354\n",
      "  time_since_restore: 13514.189175844193\n",
      "  time_this_iter_s: 29.537073373794556\n",
      "  time_total_s: 13514.189175844193\n",
      "  timestamp: 1553722545\n",
      "  timesteps_since_restore: 5270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5270000\n",
      "  training_iteration: 527\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13514 s, 527 iter, 5270000 ts, 673 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-36-52\n",
      "  done: false\n",
      "  episode_len_mean: 131.43\n",
      "  episode_reward_max: 785.9180548274524\n",
      "  episode_reward_mean: 696.2930901660977\n",
      "  episode_reward_min: -99.24408519219836\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 38630\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 11247.664\n",
      "    load_time_ms: 2.99\n",
      "    num_steps_sampled: 5280000\n",
      "    num_steps_trained: 5280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8891235589981079\n",
      "      kl: 0.012130885384976864\n",
      "      policy_loss: -0.0021781004033982754\n",
      "      total_loss: 261.4269104003906\n",
      "      vf_explained_var: 0.9775881767272949\n",
      "      vf_loss: 261.4290771484375\n",
      "    sample_time_ms: 40797.681\n",
      "    update_time_ms: 11.135\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.146545083049\n",
      "  time_since_restore: 13581.824250459671\n",
      "  time_this_iter_s: 67.63507461547852\n",
      "  time_total_s: 13581.824250459671\n",
      "  timestamp: 1553722612\n",
      "  timesteps_since_restore: 5280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5280000\n",
      "  training_iteration: 528\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13581 s, 528 iter, 5280000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-38-39\n",
      "  done: false\n",
      "  episode_len_mean: 132.42\n",
      "  episode_reward_max: 785.9180548274524\n",
      "  episode_reward_mean: 706.9034797585674\n",
      "  episode_reward_min: -53.35623839961042\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 38705\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 12405.681\n",
      "    load_time_ms: 3.167\n",
      "    num_steps_sampled: 5290000\n",
      "    num_steps_trained: 5290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8537609577178955\n",
      "      kl: 0.020771626383066177\n",
      "      policy_loss: -0.004523657262325287\n",
      "      total_loss: 451.20703125\n",
      "      vf_explained_var: 0.9656039476394653\n",
      "      vf_loss: 451.2115478515625\n",
      "    sample_time_ms: 46854.506\n",
      "    update_time_ms: 12.486\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.4517398792837\n",
      "  time_since_restore: 13688.214203596115\n",
      "  time_this_iter_s: 106.38995313644409\n",
      "  time_total_s: 13688.214203596115\n",
      "  timestamp: 1553722719\n",
      "  timesteps_since_restore: 5290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5290000\n",
      "  training_iteration: 529\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13688 s, 529 iter, 5290000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-39-54\n",
      "  done: false\n",
      "  episode_len_mean: 133.28\n",
      "  episode_reward_max: 791.5460672407584\n",
      "  episode_reward_mean: 717.5048844984626\n",
      "  episode_reward_min: 32.10091257605794\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 38781\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 11407.926\n",
      "    load_time_ms: 2.837\n",
      "    num_steps_sampled: 5300000\n",
      "    num_steps_trained: 5300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8210603594779968\n",
      "      kl: 0.022079769521951675\n",
      "      policy_loss: -0.004967363551259041\n",
      "      total_loss: 74.42594146728516\n",
      "      vf_explained_var: 0.9944584369659424\n",
      "      vf_loss: 74.430908203125\n",
      "    sample_time_ms: 48451.749\n",
      "    update_time_ms: 15.906\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.75244224923136\n",
      "  time_since_restore: 13762.988659381866\n",
      "  time_this_iter_s: 74.77445578575134\n",
      "  time_total_s: 13762.988659381866\n",
      "  timestamp: 1553722794\n",
      "  timesteps_since_restore: 5300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5300000\n",
      "  training_iteration: 530\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13762 s, 530 iter, 5300000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-40-20\n",
      "  done: false\n",
      "  episode_len_mean: 132.94\n",
      "  episode_reward_max: 793.6526522018697\n",
      "  episode_reward_mean: 725.0597436738365\n",
      "  episode_reward_min: 673.4135469599764\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 38856\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9874.766\n",
      "    load_time_ms: 2.537\n",
      "    num_steps_sampled: 5310000\n",
      "    num_steps_trained: 5310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.785768449306488\n",
      "      kl: 0.02029281295835972\n",
      "      policy_loss: -0.0023604349698871374\n",
      "      total_loss: 37.09844970703125\n",
      "      vf_explained_var: 0.9982587099075317\n",
      "      vf_loss: 37.10081100463867\n",
      "    sample_time_ms: 42733.408\n",
      "    update_time_ms: 14.555\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.52987183691835\n",
      "  time_since_restore: 13788.785805940628\n",
      "  time_this_iter_s: 25.797146558761597\n",
      "  time_total_s: 13788.785805940628\n",
      "  timestamp: 1553722820\n",
      "  timesteps_since_restore: 5310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5310000\n",
      "  training_iteration: 531\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13788 s, 531 iter, 5310000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-40-54\n",
      "  done: false\n",
      "  episode_len_mean: 130.84\n",
      "  episode_reward_max: 793.6526522018697\n",
      "  episode_reward_mean: 700.7017139238915\n",
      "  episode_reward_min: -130.43712938809085\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 38934\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9926.161\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 5320000\n",
      "    num_steps_trained: 5320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8679592609405518\n",
      "      kl: 0.0168000515550375\n",
      "      policy_loss: -0.0031428674701601267\n",
      "      total_loss: 458.448974609375\n",
      "      vf_explained_var: 0.9650634527206421\n",
      "      vf_loss: 458.4521179199219\n",
      "    sample_time_ms: 40147.376\n",
      "    update_time_ms: 13.507\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.35085696194585\n",
      "  time_since_restore: 13823.377320766449\n",
      "  time_this_iter_s: 34.59151482582092\n",
      "  time_total_s: 13823.377320766449\n",
      "  timestamp: 1553722854\n",
      "  timesteps_since_restore: 5320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5320000\n",
      "  training_iteration: 532\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13823 s, 532 iter, 5320000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-41-49\n",
      "  done: false\n",
      "  episode_len_mean: 126.94\n",
      "  episode_reward_max: 778.8737853081412\n",
      "  episode_reward_mean: 648.4607890568424\n",
      "  episode_reward_min: -112.42782069549226\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 39013\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 11354.353\n",
      "    load_time_ms: 3.189\n",
      "    num_steps_sampled: 5330000\n",
      "    num_steps_trained: 5330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8758701682090759\n",
      "      kl: 0.018311696127057076\n",
      "      policy_loss: -0.002603611908853054\n",
      "      total_loss: 1060.871337890625\n",
      "      vf_explained_var: 0.9264401197433472\n",
      "      vf_loss: 1060.8740234375\n",
      "    sample_time_ms: 41518.82\n",
      "    update_time_ms: 13.227\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.23039452842113\n",
      "  time_since_restore: 13878.509065151215\n",
      "  time_this_iter_s: 55.131744384765625\n",
      "  time_total_s: 13878.509065151215\n",
      "  timestamp: 1553722909\n",
      "  timesteps_since_restore: 5330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5330000\n",
      "  training_iteration: 533\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 13878 s, 533 iter, 5330000 ts, 648 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-43-51\n",
      "  done: false\n",
      "  episode_len_mean: 127.03\n",
      "  episode_reward_max: 789.5662951408443\n",
      "  episode_reward_mean: 651.594699278648\n",
      "  episode_reward_min: -112.42782069549226\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 39091\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 13347.624\n",
      "    load_time_ms: 3.68\n",
      "    num_steps_sampled: 5340000\n",
      "    num_steps_trained: 5340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8264707922935486\n",
      "      kl: 0.02150389738380909\n",
      "      policy_loss: -0.0013964871177449822\n",
      "      total_loss: 839.335693359375\n",
      "      vf_explained_var: 0.9295785427093506\n",
      "      vf_loss: 839.337158203125\n",
      "    sample_time_ms: 48197.458\n",
      "    update_time_ms: 15.424\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 325.797349639324\n",
      "  time_since_restore: 14000.12811589241\n",
      "  time_this_iter_s: 121.61905074119568\n",
      "  time_total_s: 14000.12811589241\n",
      "  timestamp: 1553723031\n",
      "  timesteps_since_restore: 5340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5340000\n",
      "  training_iteration: 534\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14000 s, 534 iter, 5340000 ts, 652 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-45-20\n",
      "  done: false\n",
      "  episode_len_mean: 129.65\n",
      "  episode_reward_max: 774.3990361533848\n",
      "  episode_reward_mean: 673.8221423149703\n",
      "  episode_reward_min: -101.79043707256704\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39168\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 12675.475\n",
      "    load_time_ms: 3.684\n",
      "    num_steps_sampled: 5350000\n",
      "    num_steps_trained: 5350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8163138031959534\n",
      "      kl: 0.02172323316335678\n",
      "      policy_loss: -0.0038336317520588636\n",
      "      total_loss: 497.9378356933594\n",
      "      vf_explained_var: 0.961969792842865\n",
      "      vf_loss: 497.94171142578125\n",
      "    sample_time_ms: 53000.154\n",
      "    update_time_ms: 16.115\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.9110711574852\n",
      "  time_since_restore: 14088.684319496155\n",
      "  time_this_iter_s: 88.5562036037445\n",
      "  time_total_s: 14088.684319496155\n",
      "  timestamp: 1553723120\n",
      "  timesteps_since_restore: 5350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5350000\n",
      "  training_iteration: 535\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14088 s, 535 iter, 5350000 ts, 674 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-45-52\n",
      "  done: false\n",
      "  episode_len_mean: 131.4\n",
      "  episode_reward_max: 775.9241047977938\n",
      "  episode_reward_mean: 695.1191716273738\n",
      "  episode_reward_min: -61.32868172744378\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 39244\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 12064.764\n",
      "    load_time_ms: 3.464\n",
      "    num_steps_sampled: 5360000\n",
      "    num_steps_trained: 5360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.754918098449707\n",
      "      kl: 0.03130210191011429\n",
      "      policy_loss: -0.005775494500994682\n",
      "      total_loss: 199.3716583251953\n",
      "      vf_explained_var: 0.9837042093276978\n",
      "      vf_loss: 199.37742614746094\n",
      "    sample_time_ms: 51453.234\n",
      "    update_time_ms: 16.043\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.559585813687\n",
      "  time_since_restore: 14120.453981161118\n",
      "  time_this_iter_s: 31.76966166496277\n",
      "  time_total_s: 14120.453981161118\n",
      "  timestamp: 1553723152\n",
      "  timesteps_since_restore: 5360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5360000\n",
      "  training_iteration: 536\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14120 s, 536 iter, 5360000 ts, 695 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-46-17\n",
      "  done: false\n",
      "  episode_len_mean: 131.35\n",
      "  episode_reward_max: 779.2863901512649\n",
      "  episode_reward_mean: 702.068148413197\n",
      "  episode_reward_min: -90.6945985995319\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39321\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 11953.579\n",
      "    load_time_ms: 3.492\n",
      "    num_steps_sampled: 5370000\n",
      "    num_steps_trained: 5370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7816089987754822\n",
      "      kl: 0.020189441740512848\n",
      "      policy_loss: -0.0030749456491321325\n",
      "      total_loss: 331.9735107421875\n",
      "      vf_explained_var: 0.9722983241081238\n",
      "      vf_loss: 331.9765930175781\n",
      "    sample_time_ms: 51129.287\n",
      "    update_time_ms: 15.403\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.0340742065985\n",
      "  time_since_restore: 14145.62665772438\n",
      "  time_this_iter_s: 25.17267656326294\n",
      "  time_total_s: 14145.62665772438\n",
      "  timestamp: 1553723177\n",
      "  timesteps_since_restore: 5370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5370000\n",
      "  training_iteration: 537\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14145 s, 537 iter, 5370000 ts, 702 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-46-39\n",
      "  done: false\n",
      "  episode_len_mean: 132.0\n",
      "  episode_reward_max: 783.6578029802802\n",
      "  episode_reward_mean: 704.6092518602771\n",
      "  episode_reward_min: -73.98697277118059\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 39397\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 10519.396\n",
      "    load_time_ms: 3.259\n",
      "    num_steps_sampled: 5380000\n",
      "    num_steps_trained: 5380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7393958568572998\n",
      "      kl: 0.02129470370709896\n",
      "      policy_loss: -0.0022171468008309603\n",
      "      total_loss: 349.96142578125\n",
      "      vf_explained_var: 0.9707130789756775\n",
      "      vf_loss: 349.9636535644531\n",
      "    sample_time_ms: 48028.122\n",
      "    update_time_ms: 15.041\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.30462593013857\n",
      "  time_since_restore: 14167.87023639679\n",
      "  time_this_iter_s: 22.243578672409058\n",
      "  time_total_s: 14167.87023639679\n",
      "  timestamp: 1553723199\n",
      "  timesteps_since_restore: 5380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5380000\n",
      "  training_iteration: 538\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14167 s, 538 iter, 5380000 ts, 705 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-47-01\n",
      "  done: false\n",
      "  episode_len_mean: 132.05\n",
      "  episode_reward_max: 793.6379172223052\n",
      "  episode_reward_mean: 707.5284490037219\n",
      "  episode_reward_min: -121.0942283459747\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 39472\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8819.953\n",
      "    load_time_ms: 3.092\n",
      "    num_steps_sampled: 5390000\n",
      "    num_steps_trained: 5390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.778464088100009e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7412936687469482\n",
      "      kl: 1.8084098100662231\n",
      "      policy_loss: -0.0036812610924243927\n",
      "      total_loss: 60.26507568359375\n",
      "      vf_explained_var: 0.9949896335601807\n",
      "      vf_loss: 60.26869201660156\n",
      "    sample_time_ms: 41289.709\n",
      "    update_time_ms: 13.446\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.7642245018609\n",
      "  time_since_restore: 14189.805358886719\n",
      "  time_this_iter_s: 21.9351224899292\n",
      "  time_total_s: 14189.805358886719\n",
      "  timestamp: 1553723221\n",
      "  timesteps_since_restore: 5390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5390000\n",
      "  training_iteration: 539\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14189 s, 539 iter, 5390000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-47-24\n",
      "  done: false\n",
      "  episode_len_mean: 132.93\n",
      "  episode_reward_max: 791.497789193753\n",
      "  episode_reward_mean: 723.131030676444\n",
      "  episode_reward_min: 483.420037475452\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 39548\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8526.522\n",
      "    load_time_ms: 3.001\n",
      "    num_steps_sampled: 5400000\n",
      "    num_steps_trained: 5400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7067862749099731\n",
      "      kl: 0.02587355487048626\n",
      "      policy_loss: -0.00213475595228374\n",
      "      total_loss: 40.28565979003906\n",
      "      vf_explained_var: 0.9969697594642639\n",
      "      vf_loss: 40.28779220581055\n",
      "    sample_time_ms: 36362.124\n",
      "    update_time_ms: 9.276\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.56551533822204\n",
      "  time_since_restore: 14212.321573495865\n",
      "  time_this_iter_s: 22.516214609146118\n",
      "  time_total_s: 14212.321573495865\n",
      "  timestamp: 1553723244\n",
      "  timesteps_since_restore: 5400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5400000\n",
      "  training_iteration: 540\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14212 s, 540 iter, 5400000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-47-46\n",
      "  done: false\n",
      "  episode_len_mean: 132.88\n",
      "  episode_reward_max: 791.497789193753\n",
      "  episode_reward_mean: 722.782991717293\n",
      "  episode_reward_min: -30.351164391277848\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 39623\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8427.102\n",
      "    load_time_ms: 3.032\n",
      "    num_steps_sampled: 5410000\n",
      "    num_steps_trained: 5410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.730768084526062\n",
      "      kl: 0.016070589423179626\n",
      "      policy_loss: -0.0007183669949881732\n",
      "      total_loss: 44.96828842163086\n",
      "      vf_explained_var: 0.9968252182006836\n",
      "      vf_loss: 44.9690055847168\n",
      "    sample_time_ms: 36129.575\n",
      "    update_time_ms: 9.228\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.3914958586465\n",
      "  time_since_restore: 14234.800226926804\n",
      "  time_this_iter_s: 22.47865343093872\n",
      "  time_total_s: 14234.800226926804\n",
      "  timestamp: 1553723266\n",
      "  timesteps_since_restore: 5410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5410000\n",
      "  training_iteration: 541\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14234 s, 541 iter, 5410000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-48-09\n",
      "  done: false\n",
      "  episode_len_mean: 132.77\n",
      "  episode_reward_max: 778.0788238260759\n",
      "  episode_reward_mean: 718.5794580904604\n",
      "  episode_reward_min: -53.015082915875894\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 39699\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8171.965\n",
      "    load_time_ms: 3.016\n",
      "    num_steps_sampled: 5420000\n",
      "    num_steps_trained: 5420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6956068873405457\n",
      "      kl: 0.022605784237384796\n",
      "      policy_loss: -0.004975051619112492\n",
      "      total_loss: 138.0828094482422\n",
      "      vf_explained_var: 0.9890848994255066\n",
      "      vf_loss: 138.0877685546875\n",
      "    sample_time_ms: 35174.803\n",
      "    update_time_ms: 9.032\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.28972904523005\n",
      "  time_since_restore: 14257.290344238281\n",
      "  time_this_iter_s: 22.49011731147766\n",
      "  time_total_s: 14257.290344238281\n",
      "  timestamp: 1553723289\n",
      "  timesteps_since_restore: 5420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5420000\n",
      "  training_iteration: 542\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14257 s, 542 iter, 5420000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-48-31\n",
      "  done: false\n",
      "  episode_len_mean: 131.66\n",
      "  episode_reward_max: 782.3393548836979\n",
      "  episode_reward_mean: 693.7422623851671\n",
      "  episode_reward_min: -99.15054011517798\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 39776\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6626.141\n",
      "    load_time_ms: 2.282\n",
      "    num_steps_sampled: 5430000\n",
      "    num_steps_trained: 5430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8125573396682739\n",
      "      kl: 0.021926704794168472\n",
      "      policy_loss: -0.006630249321460724\n",
      "      total_loss: 488.05126953125\n",
      "      vf_explained_var: 0.9619269967079163\n",
      "      vf_loss: 488.0578918457031\n",
      "    sample_time_ms: 33425.037\n",
      "    update_time_ms: 9.234\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.87113119258356\n",
      "  time_since_restore: 14279.395631313324\n",
      "  time_this_iter_s: 22.105287075042725\n",
      "  time_total_s: 14279.395631313324\n",
      "  timestamp: 1553723311\n",
      "  timesteps_since_restore: 5430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5430000\n",
      "  training_iteration: 543\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14279 s, 543 iter, 5430000 ts, 694 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-48-53\n",
      "  done: false\n",
      "  episode_len_mean: 131.22\n",
      "  episode_reward_max: 783.6545689347188\n",
      "  episode_reward_mean: 699.4272181980582\n",
      "  episode_reward_min: -128.0876714310723\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 39852\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4367.144\n",
      "    load_time_ms: 1.79\n",
      "    num_steps_sampled: 5440000\n",
      "    num_steps_trained: 5440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7339222431182861\n",
      "      kl: 0.01981959491968155\n",
      "      policy_loss: -0.0016079579945653677\n",
      "      total_loss: 441.4396057128906\n",
      "      vf_explained_var: 0.9654562473297119\n",
      "      vf_loss: 441.4412536621094\n",
      "    sample_time_ms: 25763.506\n",
      "    update_time_ms: 7.055\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.71360909902904\n",
      "  time_since_restore: 14301.72974896431\n",
      "  time_this_iter_s: 22.334117650985718\n",
      "  time_total_s: 14301.72974896431\n",
      "  timestamp: 1553723333\n",
      "  timesteps_since_restore: 5440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5440000\n",
      "  training_iteration: 544\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14301 s, 544 iter, 5440000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-49-16\n",
      "  done: false\n",
      "  episode_len_mean: 131.49\n",
      "  episode_reward_max: 783.6545689347188\n",
      "  episode_reward_mean: 710.1521769383603\n",
      "  episode_reward_min: -100.59216469803363\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 39928\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3814.877\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 5450000\n",
      "    num_steps_trained: 5450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7808560132980347\n",
      "      kl: 0.031844064593315125\n",
      "      policy_loss: -0.005425038281828165\n",
      "      total_loss: 354.05242919921875\n",
      "      vf_explained_var: 0.9690205454826355\n",
      "      vf_loss: 354.0578308105469\n",
      "    sample_time_ms: 19736.529\n",
      "    update_time_ms: 5.909\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.07608846918015\n",
      "  time_since_restore: 14324.464938879013\n",
      "  time_this_iter_s: 22.73518991470337\n",
      "  time_total_s: 14324.464938879013\n",
      "  timestamp: 1553723356\n",
      "  timesteps_since_restore: 5450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5450000\n",
      "  training_iteration: 545\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14324 s, 545 iter, 5450000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-49-38\n",
      "  done: false\n",
      "  episode_len_mean: 130.46\n",
      "  episode_reward_max: 787.2352932962897\n",
      "  episode_reward_mean: 703.168748579295\n",
      "  episode_reward_min: -120.70650902015257\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40005\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3800.527\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 5460000\n",
      "    num_steps_trained: 5460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.735808253288269\n",
      "      kl: 0.03289792314171791\n",
      "      policy_loss: -0.004521054215729237\n",
      "      total_loss: 342.9060363769531\n",
      "      vf_explained_var: 0.9723414778709412\n",
      "      vf_loss: 342.9104919433594\n",
      "    sample_time_ms: 18778.394\n",
      "    update_time_ms: 5.211\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.58437428964737\n",
      "  time_since_restore: 14346.501981973648\n",
      "  time_this_iter_s: 22.03704309463501\n",
      "  time_total_s: 14346.501981973648\n",
      "  timestamp: 1553723378\n",
      "  timesteps_since_restore: 5460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5460000\n",
      "  training_iteration: 546\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14346 s, 546 iter, 5460000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-50-00\n",
      "  done: false\n",
      "  episode_len_mean: 130.95\n",
      "  episode_reward_max: 790.2598926349539\n",
      "  episode_reward_mean: 705.7713103013772\n",
      "  episode_reward_min: -69.87256151321594\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40082\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3802.049\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 5470000\n",
      "    num_steps_trained: 5470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7005601525306702\n",
      "      kl: 0.027500497177243233\n",
      "      policy_loss: -0.0014151023933663964\n",
      "      total_loss: 125.05630493164062\n",
      "      vf_explained_var: 0.9899516105651855\n",
      "      vf_loss: 125.0577163696289\n",
      "    sample_time_ms: 18477.863\n",
      "    update_time_ms: 5.315\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.8856551506886\n",
      "  time_since_restore: 14368.684894561768\n",
      "  time_this_iter_s: 22.182912588119507\n",
      "  time_total_s: 14368.684894561768\n",
      "  timestamp: 1553723400\n",
      "  timesteps_since_restore: 5470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5470000\n",
      "  training_iteration: 547\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14368 s, 547 iter, 5470000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-50-24\n",
      "  done: false\n",
      "  episode_len_mean: 133.19\n",
      "  episode_reward_max: 798.2717787732947\n",
      "  episode_reward_mean: 728.872154320839\n",
      "  episode_reward_min: 495.74756558339016\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40158\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3811.549\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 5480000\n",
      "    num_steps_trained: 5480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7193670272827148\n",
      "      kl: 0.02730422466993332\n",
      "      policy_loss: -0.003393423045054078\n",
      "      total_loss: 191.93714904785156\n",
      "      vf_explained_var: 0.9836886525154114\n",
      "      vf_loss: 191.9405517578125\n",
      "    sample_time_ms: 18584.468\n",
      "    update_time_ms: 5.379\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.4360771604195\n",
      "  time_since_restore: 14392.088779687881\n",
      "  time_this_iter_s: 23.40388512611389\n",
      "  time_total_s: 14392.088779687881\n",
      "  timestamp: 1553723424\n",
      "  timesteps_since_restore: 5480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5480000\n",
      "  training_iteration: 548\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14392 s, 548 iter, 5480000 ts, 729 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-50-47\n",
      "  done: false\n",
      "  episode_len_mean: 132.76\n",
      "  episode_reward_max: 798.2717787732947\n",
      "  episode_reward_mean: 722.1689997415441\n",
      "  episode_reward_min: -127.39166638112843\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 40233\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3812.811\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 5490000\n",
      "    num_steps_trained: 5490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7602114677429199\n",
      "      kl: 0.031632330268621445\n",
      "      policy_loss: -0.0018056831322610378\n",
      "      total_loss: 191.653564453125\n",
      "      vf_explained_var: 0.9833654761314392\n",
      "      vf_loss: 191.65538024902344\n",
      "    sample_time_ms: 18651.529\n",
      "    update_time_ms: 5.394\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.08449987077205\n",
      "  time_since_restore: 14414.705161094666\n",
      "  time_this_iter_s: 22.616381406784058\n",
      "  time_total_s: 14414.705161094666\n",
      "  timestamp: 1553723447\n",
      "  timesteps_since_restore: 5490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5490000\n",
      "  training_iteration: 549\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14414 s, 549 iter, 5490000 ts, 722 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-51-10\n",
      "  done: false\n",
      "  episode_len_mean: 131.36\n",
      "  episode_reward_max: 782.4373911830153\n",
      "  episode_reward_mean: 681.7688151589974\n",
      "  episode_reward_min: -128.37888404701366\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 40310\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3804.203\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 5500000\n",
      "    num_steps_trained: 5500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8035807609558105\n",
      "      kl: 0.024516429752111435\n",
      "      policy_loss: -0.004442167468369007\n",
      "      total_loss: 667.3524169921875\n",
      "      vf_explained_var: 0.9537349343299866\n",
      "      vf_loss: 667.3567504882812\n",
      "    sample_time_ms: 18710.536\n",
      "    update_time_ms: 5.402\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.8844075794987\n",
      "  time_since_restore: 14437.727771282196\n",
      "  time_this_iter_s: 23.022610187530518\n",
      "  time_total_s: 14437.727771282196\n",
      "  timestamp: 1553723470\n",
      "  timesteps_since_restore: 5500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5500000\n",
      "  training_iteration: 550\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14437 s, 550 iter, 5500000 ts, 682 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-51-32\n",
      "  done: false\n",
      "  episode_len_mean: 132.31\n",
      "  episode_reward_max: 788.8925278273452\n",
      "  episode_reward_mean: 706.0279463048433\n",
      "  episode_reward_min: -91.10759022887183\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 40384\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3801.897\n",
      "    load_time_ms: 1.438\n",
      "    num_steps_sampled: 5510000\n",
      "    num_steps_trained: 5510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.6676974054425955e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7377098202705383\n",
      "      kl: 1.7718979120254517\n",
      "      policy_loss: -0.0031041784677654505\n",
      "      total_loss: 110.69564056396484\n",
      "      vf_explained_var: 0.9923829436302185\n",
      "      vf_loss: 110.69865417480469\n",
      "    sample_time_ms: 18687.241\n",
      "    update_time_ms: 5.382\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.01397315242167\n",
      "  time_since_restore: 14459.949579954147\n",
      "  time_this_iter_s: 22.221808671951294\n",
      "  time_total_s: 14459.949579954147\n",
      "  timestamp: 1553723492\n",
      "  timesteps_since_restore: 5510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5510000\n",
      "  training_iteration: 551\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14459 s, 551 iter, 5510000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-51-55\n",
      "  done: false\n",
      "  episode_len_mean: 133.93\n",
      "  episode_reward_max: 790.1724146416018\n",
      "  episode_reward_mean: 723.0270988806207\n",
      "  episode_reward_min: -104.80349606196047\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40460\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3796.179\n",
      "    load_time_ms: 1.478\n",
      "    num_steps_sampled: 5520000\n",
      "    num_steps_trained: 5520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.501543197780848e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7015331387519836\n",
      "      kl: 0.02036936953663826\n",
      "      policy_loss: -0.0002956866519525647\n",
      "      total_loss: 177.4886932373047\n",
      "      vf_explained_var: 0.9860736131668091\n",
      "      vf_loss: 177.48898315429688\n",
      "    sample_time_ms: 18744.055\n",
      "    update_time_ms: 5.365\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.51354944031044\n",
      "  time_since_restore: 14482.950003862381\n",
      "  time_this_iter_s: 23.000423908233643\n",
      "  time_total_s: 14482.950003862381\n",
      "  timestamp: 1553723515\n",
      "  timesteps_since_restore: 5520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5520000\n",
      "  training_iteration: 552\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14482 s, 552 iter, 5520000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-52-17\n",
      "  done: false\n",
      "  episode_len_mean: 132.74\n",
      "  episode_reward_max: 798.8448879791354\n",
      "  episode_reward_mean: 725.777015931899\n",
      "  episode_reward_min: 525.9049888350485\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40536\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3794.498\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 5530000\n",
      "    num_steps_trained: 5530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.501543197780848e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6852049827575684\n",
      "      kl: 0.028126878663897514\n",
      "      policy_loss: -0.004464081488549709\n",
      "      total_loss: 22.341278076171875\n",
      "      vf_explained_var: 0.9983917474746704\n",
      "      vf_loss: 22.34573745727539\n",
      "    sample_time_ms: 18757.916\n",
      "    update_time_ms: 5.174\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.88850796594954\n",
      "  time_since_restore: 14505.174839496613\n",
      "  time_this_iter_s: 22.224835634231567\n",
      "  time_total_s: 14505.174839496613\n",
      "  timestamp: 1553723537\n",
      "  timesteps_since_restore: 5530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5530000\n",
      "  training_iteration: 553\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14505 s, 553 iter, 5530000 ts, 726 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-52-40\n",
      "  done: false\n",
      "  episode_len_mean: 130.39\n",
      "  episode_reward_max: 785.4616546544331\n",
      "  episode_reward_mean: 707.8064752814705\n",
      "  episode_reward_min: -65.90361199852705\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40612\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3789.174\n",
      "    load_time_ms: 1.506\n",
      "    num_steps_sampled: 5540000\n",
      "    num_steps_trained: 5540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.501543197780848e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7063419818878174\n",
      "      kl: 0.01799842342734337\n",
      "      policy_loss: -0.0036079264245927334\n",
      "      total_loss: 363.74853515625\n",
      "      vf_explained_var: 0.9709143042564392\n",
      "      vf_loss: 363.7521667480469\n",
      "    sample_time_ms: 18775.296\n",
      "    update_time_ms: 5.18\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.90323764073514\n",
      "  time_since_restore: 14527.63009428978\n",
      "  time_this_iter_s: 22.455254793167114\n",
      "  time_total_s: 14527.63009428978\n",
      "  timestamp: 1553723560\n",
      "  timesteps_since_restore: 5540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5540000\n",
      "  training_iteration: 554\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14527 s, 554 iter, 5540000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-53-02\n",
      "  done: false\n",
      "  episode_len_mean: 131.64\n",
      "  episode_reward_max: 785.4616546544331\n",
      "  episode_reward_mean: 716.9175693690289\n",
      "  episode_reward_min: -65.90361199852705\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 40688\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3788.25\n",
      "    load_time_ms: 1.494\n",
      "    num_steps_sampled: 5550000\n",
      "    num_steps_trained: 5550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.501543197780848e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7638314366340637\n",
      "      kl: 0.08054935187101364\n",
      "      policy_loss: -0.006910976022481918\n",
      "      total_loss: 66.1578369140625\n",
      "      vf_explained_var: 0.9944949746131897\n",
      "      vf_loss: 66.16474151611328\n",
      "    sample_time_ms: 18734.62\n",
      "    update_time_ms: 5.364\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.4587846845144\n",
      "  time_since_restore: 14549.94963502884\n",
      "  time_this_iter_s: 22.31954073905945\n",
      "  time_total_s: 14549.94963502884\n",
      "  timestamp: 1553723582\n",
      "  timesteps_since_restore: 5550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5550000\n",
      "  training_iteration: 555\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14549 s, 555 iter, 5550000 ts, 717 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-53-24\n",
      "  done: false\n",
      "  episode_len_mean: 127.08\n",
      "  episode_reward_max: 793.3473127172456\n",
      "  episode_reward_mean: 671.3069654387022\n",
      "  episode_reward_min: -112.09670258950177\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 40768\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3790.314\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 5560000\n",
      "    num_steps_trained: 5560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00012752317707054317\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7173680663108826\n",
      "      kl: 0.02579289861023426\n",
      "      policy_loss: -0.006635448895394802\n",
      "      total_loss: 832.1293334960938\n",
      "      vf_explained_var: 0.9343359470367432\n",
      "      vf_loss: 832.1358642578125\n",
      "    sample_time_ms: 18738.258\n",
      "    update_time_ms: 5.391\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 335.653482719351\n",
      "  time_since_restore: 14572.043682575226\n",
      "  time_this_iter_s: 22.09404754638672\n",
      "  time_total_s: 14572.043682575226\n",
      "  timestamp: 1553723604\n",
      "  timesteps_since_restore: 5560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5560000\n",
      "  training_iteration: 556\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14572 s, 556 iter, 5560000 ts, 671 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-53-47\n",
      "  done: false\n",
      "  episode_len_mean: 126.68\n",
      "  episode_reward_max: 787.4060182198739\n",
      "  episode_reward_mean: 666.9175513976218\n",
      "  episode_reward_min: -75.662438548561\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 40846\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3782.093\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 5570000\n",
      "    num_steps_trained: 5570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00012752317707054317\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7586463093757629\n",
      "      kl: 0.015316559933125973\n",
      "      policy_loss: -0.0021941002923995256\n",
      "      total_loss: 570.3789672851562\n",
      "      vf_explained_var: 0.9546645879745483\n",
      "      vf_loss: 570.381103515625\n",
      "    sample_time_ms: 18775.207\n",
      "    update_time_ms: 5.307\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 333.45877569881077\n",
      "  time_since_restore: 14594.512224197388\n",
      "  time_this_iter_s: 22.468541622161865\n",
      "  time_total_s: 14594.512224197388\n",
      "  timestamp: 1553723627\n",
      "  timesteps_since_restore: 5570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5570000\n",
      "  training_iteration: 557\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14594 s, 557 iter, 5570000 ts, 667 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-54-10\n",
      "  done: false\n",
      "  episode_len_mean: 129.26\n",
      "  episode_reward_max: 778.4644173601466\n",
      "  episode_reward_mean: 681.2765366484939\n",
      "  episode_reward_min: -82.25972000544148\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 40924\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.603\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 5580000\n",
      "    num_steps_trained: 5580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00012752317707054317\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7669501900672913\n",
      "      kl: 0.02394861914217472\n",
      "      policy_loss: -0.003979191184043884\n",
      "      total_loss: 1094.749755859375\n",
      "      vf_explained_var: 0.9083714485168457\n",
      "      vf_loss: 1094.7537841796875\n",
      "    sample_time_ms: 18746.371\n",
      "    update_time_ms: 5.259\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.63826832424706\n",
      "  time_since_restore: 14617.48985862732\n",
      "  time_this_iter_s: 22.97763442993164\n",
      "  time_total_s: 14617.48985862732\n",
      "  timestamp: 1553723650\n",
      "  timesteps_since_restore: 5580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5580000\n",
      "  training_iteration: 558\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14617 s, 558 iter, 5580000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-54-33\n",
      "  done: false\n",
      "  episode_len_mean: 126.95\n",
      "  episode_reward_max: 781.0199519818829\n",
      "  episode_reward_mean: 675.6992379390393\n",
      "  episode_reward_min: -41.17634657209794\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 41003\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.068\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 5590000\n",
      "    num_steps_trained: 5590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00012752317707054317\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7106918096542358\n",
      "      kl: 0.019509147852659225\n",
      "      policy_loss: -0.0020973726641386747\n",
      "      total_loss: 874.50830078125\n",
      "      vf_explained_var: 0.9246595501899719\n",
      "      vf_loss: 874.5104370117188\n",
      "    sample_time_ms: 18779.967\n",
      "    update_time_ms: 5.183\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.84961896951967\n",
      "  time_since_restore: 14640.42588710785\n",
      "  time_this_iter_s: 22.936028480529785\n",
      "  time_total_s: 14640.42588710785\n",
      "  timestamp: 1553723673\n",
      "  timesteps_since_restore: 5590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5590000\n",
      "  training_iteration: 559\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14640 s, 559 iter, 5590000 ts, 676 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-54-55\n",
      "  done: false\n",
      "  episode_len_mean: 127.94\n",
      "  episode_reward_max: 791.7066987793205\n",
      "  episode_reward_mean: 700.3183431652807\n",
      "  episode_reward_min: -122.85560435291859\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 41081\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3766.808\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 5600000\n",
      "    num_steps_trained: 5600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00012752317707054317\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5984012484550476\n",
      "      kl: 0.43006256222724915\n",
      "      policy_loss: -0.0020467776339501143\n",
      "      total_loss: 267.3576354980469\n",
      "      vf_explained_var: 0.9790483117103577\n",
      "      vf_loss: 267.359619140625\n",
      "    sample_time_ms: 18746.831\n",
      "    update_time_ms: 5.348\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.1591715826405\n",
      "  time_since_restore: 14663.114708423615\n",
      "  time_this_iter_s: 22.68882131576538\n",
      "  time_total_s: 14663.114708423615\n",
      "  timestamp: 1553723695\n",
      "  timesteps_since_restore: 5600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5600000\n",
      "  training_iteration: 560\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14663 s, 560 iter, 5600000 ts, 700 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-55-18\n",
      "  done: false\n",
      "  episode_len_mean: 131.02\n",
      "  episode_reward_max: 794.3012365348105\n",
      "  episode_reward_mean: 714.0121584112329\n",
      "  episode_reward_min: -83.57646649615523\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 41157\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3766.949\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 5610000\n",
      "    num_steps_trained: 5610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00019128475105389953\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6422457695007324\n",
      "      kl: 1.4761987924575806\n",
      "      policy_loss: -0.00213471963070333\n",
      "      total_loss: 73.05372619628906\n",
      "      vf_explained_var: 0.9951651096343994\n",
      "      vf_loss: 73.05558013916016\n",
      "    sample_time_ms: 18769.751\n",
      "    update_time_ms: 5.383\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.0060792056164\n",
      "  time_since_restore: 14685.566890716553\n",
      "  time_this_iter_s: 22.452182292938232\n",
      "  time_total_s: 14685.566890716553\n",
      "  timestamp: 1553723718\n",
      "  timesteps_since_restore: 5610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5610000\n",
      "  training_iteration: 561\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14685 s, 561 iter, 5610000 ts, 714 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-55-40\n",
      "  done: false\n",
      "  episode_len_mean: 132.89\n",
      "  episode_reward_max: 789.8178927850912\n",
      "  episode_reward_mean: 723.2660594980887\n",
      "  episode_reward_min: -40.31692527236055\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 41233\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3766.542\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 5620000\n",
      "    num_steps_trained: 5620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00028692715568467975\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6738505363464355\n",
      "      kl: 0.2761431038379669\n",
      "      policy_loss: -0.0028306341264396906\n",
      "      total_loss: 77.00804138183594\n",
      "      vf_explained_var: 0.9949901103973389\n",
      "      vf_loss: 77.01079559326172\n",
      "    sample_time_ms: 18690.789\n",
      "    update_time_ms: 5.405\n",
      "  iterations_since_restore: 562\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.6330297490442\n",
      "  time_since_restore: 14707.77306675911\n",
      "  time_this_iter_s: 22.206176042556763\n",
      "  time_total_s: 14707.77306675911\n",
      "  timestamp: 1553723740\n",
      "  timesteps_since_restore: 5620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5620000\n",
      "  training_iteration: 562\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14707 s, 562 iter, 5620000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-56-03\n",
      "  done: false\n",
      "  episode_len_mean: 132.38\n",
      "  episode_reward_max: 795.3783293309001\n",
      "  episode_reward_mean: 717.1130934489335\n",
      "  episode_reward_min: -78.94441172788778\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 41309\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3765.079\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 5630000\n",
      "    num_steps_trained: 5630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00043039070442318916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6367665529251099\n",
      "      kl: 0.016807738691568375\n",
      "      policy_loss: -0.00046474457485601306\n",
      "      total_loss: 328.5500793457031\n",
      "      vf_explained_var: 0.9747470021247864\n",
      "      vf_loss: 328.550537109375\n",
      "    sample_time_ms: 18711.544\n",
      "    update_time_ms: 5.399\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.55654672446667\n",
      "  time_since_restore: 14730.18823814392\n",
      "  time_this_iter_s: 22.4151713848114\n",
      "  time_total_s: 14730.18823814392\n",
      "  timestamp: 1553723763\n",
      "  timesteps_since_restore: 5630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5630000\n",
      "  training_iteration: 563\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14730 s, 563 iter, 5630000 ts, 717 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-56-26\n",
      "  done: false\n",
      "  episode_len_mean: 130.77\n",
      "  episode_reward_max: 784.8898663358206\n",
      "  episode_reward_mean: 715.2930808972607\n",
      "  episode_reward_min: -86.44539792998302\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 41386\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.854\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 5640000\n",
      "    num_steps_trained: 5640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00043039070442318916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6340181231498718\n",
      "      kl: 0.0177316814661026\n",
      "      policy_loss: -0.0035236906260252\n",
      "      total_loss: 318.7973327636719\n",
      "      vf_explained_var: 0.972823441028595\n",
      "      vf_loss: 318.80084228515625\n",
      "    sample_time_ms: 18762.878\n",
      "    update_time_ms: 5.311\n",
      "  iterations_since_restore: 564\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.6465404486304\n",
      "  time_since_restore: 14753.143383264542\n",
      "  time_this_iter_s: 22.955145120620728\n",
      "  time_total_s: 14753.143383264542\n",
      "  timestamp: 1553723786\n",
      "  timesteps_since_restore: 5640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5640000\n",
      "  training_iteration: 564\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14753 s, 564 iter, 5640000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-56-49\n",
      "  done: false\n",
      "  episode_len_mean: 131.29\n",
      "  episode_reward_max: 784.9345550121636\n",
      "  episode_reward_mean: 715.2972929822514\n",
      "  episode_reward_min: -44.27035225621637\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 41462\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.219\n",
      "    load_time_ms: 1.476\n",
      "    num_steps_sampled: 5650000\n",
      "    num_steps_trained: 5650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00043039070442318916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6164198517799377\n",
      "      kl: 0.02592221274971962\n",
      "      policy_loss: -0.0018568650120869279\n",
      "      total_loss: 183.31056213378906\n",
      "      vf_explained_var: 0.984011709690094\n",
      "      vf_loss: 183.31239318847656\n",
      "    sample_time_ms: 18828.798\n",
      "    update_time_ms: 5.274\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.6486464911257\n",
      "  time_since_restore: 14776.088829040527\n",
      "  time_this_iter_s: 22.945445775985718\n",
      "  time_total_s: 14776.088829040527\n",
      "  timestamp: 1553723809\n",
      "  timesteps_since_restore: 5650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5650000\n",
      "  training_iteration: 565\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14776 s, 565 iter, 5650000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-57-11\n",
      "  done: false\n",
      "  episode_len_mean: 133.03\n",
      "  episode_reward_max: 790.3134133000021\n",
      "  episode_reward_mean: 730.8244486992293\n",
      "  episode_reward_min: 678.58389960621\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 41537\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3755.491\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 5660000\n",
      "    num_steps_trained: 5660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00043039070442318916\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7313345670700073\n",
      "      kl: 5.650967597961426\n",
      "      policy_loss: -0.009050818160176277\n",
      "      total_loss: 22.244489669799805\n",
      "      vf_explained_var: 0.9984461665153503\n",
      "      vf_loss: 22.251108169555664\n",
      "    sample_time_ms: 18908.258\n",
      "    update_time_ms: 5.265\n",
      "  iterations_since_restore: 566\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 365.4122243496146\n",
      "  time_since_restore: 14798.929060935974\n",
      "  time_this_iter_s: 22.840231895446777\n",
      "  time_total_s: 14798.929060935974\n",
      "  timestamp: 1553723831\n",
      "  timesteps_since_restore: 5660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5660000\n",
      "  training_iteration: 566\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14798 s, 566 iter, 5660000 ts, 731 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-57-34\n",
      "  done: false\n",
      "  episode_len_mean: 129.8\n",
      "  episode_reward_max: 791.3443475964679\n",
      "  episode_reward_mean: 730.4982627179415\n",
      "  episode_reward_min: 680.6175604510863\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 41615\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.424\n",
      "    load_time_ms: 1.388\n",
      "    num_steps_sampled: 5670000\n",
      "    num_steps_trained: 5670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6001368761062622\n",
      "      kl: 0.020231610164046288\n",
      "      policy_loss: -0.0009064989862963557\n",
      "      total_loss: 14.164938926696777\n",
      "      vf_explained_var: 0.9989554286003113\n",
      "      vf_loss: 14.16583251953125\n",
      "    sample_time_ms: 18901.788\n",
      "    update_time_ms: 5.33\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 365.2491313589708\n",
      "  time_since_restore: 14821.34180188179\n",
      "  time_this_iter_s: 22.41274094581604\n",
      "  time_total_s: 14821.34180188179\n",
      "  timestamp: 1553723854\n",
      "  timesteps_since_restore: 5670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5670000\n",
      "  training_iteration: 567\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14821 s, 567 iter, 5670000 ts, 730 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 130.34\n",
      "  episode_reward_max: 791.3443475964679\n",
      "  episode_reward_mean: 729.4242231189995\n",
      "  episode_reward_min: 677.1426485642768\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 41692\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.575\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 5680000\n",
      "    num_steps_trained: 5680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.65939861536026\n",
      "      kl: 0.028555601835250854\n",
      "      policy_loss: 0.0004175389476586133\n",
      "      total_loss: 10.538804054260254\n",
      "      vf_explained_var: 0.9992527961730957\n",
      "      vf_loss: 10.538368225097656\n",
      "    sample_time_ms: 18871.941\n",
      "    update_time_ms: 5.375\n",
      "  iterations_since_restore: 568\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.7121115594998\n",
      "  time_since_restore: 14844.062967538834\n",
      "  time_this_iter_s: 22.721165657043457\n",
      "  time_total_s: 14844.062967538834\n",
      "  timestamp: 1553723877\n",
      "  timesteps_since_restore: 5680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5680000\n",
      "  training_iteration: 568\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14844 s, 568 iter, 5680000 ts, 729 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-58-19\n",
      "  done: false\n",
      "  episode_len_mean: 130.6\n",
      "  episode_reward_max: 789.9868010272202\n",
      "  episode_reward_mean: 724.3541692690405\n",
      "  episode_reward_min: -47.269767057731514\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 41767\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3758.62\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 5690000\n",
      "    num_steps_trained: 5690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6592345833778381\n",
      "      kl: 0.017735883593559265\n",
      "      policy_loss: -0.0048364331014454365\n",
      "      total_loss: 133.54579162597656\n",
      "      vf_explained_var: 0.9895784258842468\n",
      "      vf_loss: 133.5506134033203\n",
      "    sample_time_ms: 18780.445\n",
      "    update_time_ms: 5.312\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.17708463452027\n",
      "  time_since_restore: 14866.062361001968\n",
      "  time_this_iter_s: 21.999393463134766\n",
      "  time_total_s: 14866.062361001968\n",
      "  timestamp: 1553723899\n",
      "  timesteps_since_restore: 5690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5690000\n",
      "  training_iteration: 569\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14866 s, 569 iter, 5690000 ts, 724 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-58-41\n",
      "  done: false\n",
      "  episode_len_mean: 129.65\n",
      "  episode_reward_max: 783.4710993901066\n",
      "  episode_reward_mean: 714.1719700414772\n",
      "  episode_reward_min: -66.0112740726538\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 41845\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.79\n",
      "    load_time_ms: 1.441\n",
      "    num_steps_sampled: 5700000\n",
      "    num_steps_trained: 5700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6428343653678894\n",
      "      kl: 0.020038846880197525\n",
      "      policy_loss: -0.0014284064527601004\n",
      "      total_loss: 277.1062316894531\n",
      "      vf_explained_var: 0.9777612090110779\n",
      "      vf_loss: 277.107666015625\n",
      "    sample_time_ms: 18784.886\n",
      "    update_time_ms: 5.202\n",
      "  iterations_since_restore: 570\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.0859850207386\n",
      "  time_since_restore: 14888.8168592453\n",
      "  time_this_iter_s: 22.75449824333191\n",
      "  time_total_s: 14888.8168592453\n",
      "  timestamp: 1553723921\n",
      "  timesteps_since_restore: 5700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5700000\n",
      "  training_iteration: 570\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14888 s, 570 iter, 5700000 ts, 714 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-59-04\n",
      "  done: false\n",
      "  episode_len_mean: 127.1\n",
      "  episode_reward_max: 784.2733502614228\n",
      "  episode_reward_mean: 706.2176788445565\n",
      "  episode_reward_min: -66.0112740726538\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 41924\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.681\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 5710000\n",
      "    num_steps_trained: 5710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6056286096572876\n",
      "      kl: 0.022889764979481697\n",
      "      policy_loss: -0.0046623204834759235\n",
      "      total_loss: 158.17613220214844\n",
      "      vf_explained_var: 0.9896455407142639\n",
      "      vf_loss: 158.18077087402344\n",
      "    sample_time_ms: 18810.264\n",
      "    update_time_ms: 5.11\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.10883942227827\n",
      "  time_since_restore: 14911.530117034912\n",
      "  time_this_iter_s: 22.713257789611816\n",
      "  time_total_s: 14911.530117034912\n",
      "  timestamp: 1553723944\n",
      "  timesteps_since_restore: 5710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5710000\n",
      "  training_iteration: 571\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14911 s, 571 iter, 5710000 ts, 706 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-59-27\n",
      "  done: false\n",
      "  episode_len_mean: 126.64\n",
      "  episode_reward_max: 805.3716036489168\n",
      "  episode_reward_mean: 700.4118194751526\n",
      "  episode_reward_min: -129.95330189553385\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 42003\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.146\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 5720000\n",
      "    num_steps_trained: 5720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6717346906661987\n",
      "      kl: 0.02519562467932701\n",
      "      policy_loss: -0.006400298327207565\n",
      "      total_loss: 533.4564208984375\n",
      "      vf_explained_var: 0.9639305472373962\n",
      "      vf_loss: 533.4627685546875\n",
      "    sample_time_ms: 18870.442\n",
      "    update_time_ms: 5.21\n",
      "  iterations_since_restore: 572\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.2059097375763\n",
      "  time_since_restore: 14934.348341941833\n",
      "  time_this_iter_s: 22.818224906921387\n",
      "  time_total_s: 14934.348341941833\n",
      "  timestamp: 1553723967\n",
      "  timesteps_since_restore: 5720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5720000\n",
      "  training_iteration: 572\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14934 s, 572 iter, 5720000 ts, 700 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_22-59-49\n",
      "  done: false\n",
      "  episode_len_mean: 128.26\n",
      "  episode_reward_max: 811.1423834399088\n",
      "  episode_reward_mean: 709.4232055647451\n",
      "  episode_reward_min: -75.20385491745418\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 42082\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.847\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 5730000\n",
      "    num_steps_trained: 5730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6812153458595276\n",
      "      kl: 0.019771285355091095\n",
      "      policy_loss: -0.0036241901107132435\n",
      "      total_loss: 334.0765686035156\n",
      "      vf_explained_var: 0.974664568901062\n",
      "      vf_loss: 334.0802001953125\n",
      "    sample_time_ms: 18828.702\n",
      "    update_time_ms: 5.208\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.71160278237255\n",
      "  time_since_restore: 14956.344164848328\n",
      "  time_this_iter_s: 21.99582290649414\n",
      "  time_total_s: 14956.344164848328\n",
      "  timestamp: 1553723989\n",
      "  timesteps_since_restore: 5730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5730000\n",
      "  training_iteration: 573\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14956 s, 573 iter, 5730000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-00-11\n",
      "  done: false\n",
      "  episode_len_mean: 129.51\n",
      "  episode_reward_max: 811.1423834399088\n",
      "  episode_reward_mean: 725.1665624757385\n",
      "  episode_reward_min: -61.86692481095008\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 42159\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.324\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 5740000\n",
      "    num_steps_trained: 5740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6416986584663391\n",
      "      kl: 0.021023975685238838\n",
      "      policy_loss: -0.000504406460095197\n",
      "      total_loss: 166.8068389892578\n",
      "      vf_explained_var: 0.9865051507949829\n",
      "      vf_loss: 166.80734252929688\n",
      "    sample_time_ms: 18712.1\n",
      "    update_time_ms: 5.236\n",
      "  iterations_since_restore: 574\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.5832812378692\n",
      "  time_since_restore: 14978.137718439102\n",
      "  time_this_iter_s: 21.793553590774536\n",
      "  time_total_s: 14978.137718439102\n",
      "  timestamp: 1553724011\n",
      "  timesteps_since_restore: 5740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5740000\n",
      "  training_iteration: 574\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 14978 s, 574 iter, 5740000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-00-33\n",
      "  done: false\n",
      "  episode_len_mean: 128.91\n",
      "  episode_reward_max: 793.9021086470617\n",
      "  episode_reward_mean: 727.244592923972\n",
      "  episode_reward_min: 27.227458966974126\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 42237\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.869\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 5750000\n",
      "    num_steps_trained: 5750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0006455860566347837\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.677758514881134\n",
      "      kl: 0.7770459055900574\n",
      "      policy_loss: 0.002596649108454585\n",
      "      total_loss: 349.91351318359375\n",
      "      vf_explained_var: 0.9710468649864197\n",
      "      vf_loss: 349.910400390625\n",
      "    sample_time_ms: 18620.554\n",
      "    update_time_ms: 5.218\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 363.62229646198597\n",
      "  time_since_restore: 15000.146598100662\n",
      "  time_this_iter_s: 22.00887966156006\n",
      "  time_total_s: 15000.146598100662\n",
      "  timestamp: 1553724033\n",
      "  timesteps_since_restore: 5750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5750000\n",
      "  training_iteration: 575\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15000 s, 575 iter, 5750000 ts, 727 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-00-55\n",
      "  done: false\n",
      "  episode_len_mean: 128.78\n",
      "  episode_reward_max: 793.9021086470617\n",
      "  episode_reward_mean: 723.639935134314\n",
      "  episode_reward_min: 27.227458966974126\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 42314\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3758.993\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 5760000\n",
      "    num_steps_trained: 5760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0009683790849521756\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6675270199775696\n",
      "      kl: 0.15894202888011932\n",
      "      policy_loss: -0.0019451016560196877\n",
      "      total_loss: 33.33695602416992\n",
      "      vf_explained_var: 0.9969363808631897\n",
      "      vf_loss: 33.3387451171875\n",
      "    sample_time_ms: 18561.368\n",
      "    update_time_ms: 5.087\n",
      "  iterations_since_restore: 576\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.819967567157\n",
      "  time_since_restore: 15022.384778499603\n",
      "  time_this_iter_s: 22.23818039894104\n",
      "  time_total_s: 15022.384778499603\n",
      "  timestamp: 1553724055\n",
      "  timesteps_since_restore: 5760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5760000\n",
      "  training_iteration: 576\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15022 s, 576 iter, 5760000 ts, 724 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-01-18\n",
      "  done: false\n",
      "  episode_len_mean: 127.81\n",
      "  episode_reward_max: 787.3141170417642\n",
      "  episode_reward_mean: 714.7063533878592\n",
      "  episode_reward_min: -76.97084176592948\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 42393\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.945\n",
      "    load_time_ms: 1.505\n",
      "    num_steps_sampled: 5770000\n",
      "    num_steps_trained: 5770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0014525686856359243\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6535473465919495\n",
      "      kl: 0.048231057822704315\n",
      "      policy_loss: -0.015155777335166931\n",
      "      total_loss: 192.47784423828125\n",
      "      vf_explained_var: 0.9859520196914673\n",
      "      vf_loss: 192.492919921875\n",
      "    sample_time_ms: 18564.487\n",
      "    update_time_ms: 4.944\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.3531766939296\n",
      "  time_since_restore: 15044.86711859703\n",
      "  time_this_iter_s: 22.482340097427368\n",
      "  time_total_s: 15044.86711859703\n",
      "  timestamp: 1553724078\n",
      "  timesteps_since_restore: 5770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5770000\n",
      "  training_iteration: 577\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15044 s, 577 iter, 5770000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-01-40\n",
      "  done: false\n",
      "  episode_len_mean: 124.83\n",
      "  episode_reward_max: 791.3107523040768\n",
      "  episode_reward_mean: 686.684992292661\n",
      "  episode_reward_min: -52.823567275134025\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 42474\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.377\n",
      "    load_time_ms: 1.5\n",
      "    num_steps_sampled: 5780000\n",
      "    num_steps_trained: 5780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021788531448692083\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.676324725151062\n",
      "      kl: 0.02298686094582081\n",
      "      policy_loss: -0.0036756510380655527\n",
      "      total_loss: 897.4559326171875\n",
      "      vf_explained_var: 0.9288482666015625\n",
      "      vf_loss: 897.4595336914062\n",
      "    sample_time_ms: 18540.819\n",
      "    update_time_ms: 4.888\n",
      "  iterations_since_restore: 578\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.3424961463305\n",
      "  time_since_restore: 15067.32595705986\n",
      "  time_this_iter_s: 22.45883846282959\n",
      "  time_total_s: 15067.32595705986\n",
      "  timestamp: 1553724100\n",
      "  timesteps_since_restore: 5780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5780000\n",
      "  training_iteration: 578\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15067 s, 578 iter, 5780000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-02-02\n",
      "  done: false\n",
      "  episode_len_mean: 126.13\n",
      "  episode_reward_max: 793.5216979562132\n",
      "  episode_reward_mean: 696.6644524392468\n",
      "  episode_reward_min: -52.823567275134025\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 42552\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.69\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 5790000\n",
      "    num_steps_trained: 5790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021788531448692083\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6439392566680908\n",
      "      kl: 0.024132300168275833\n",
      "      policy_loss: -0.0010651499032974243\n",
      "      total_loss: 43.23231506347656\n",
      "      vf_explained_var: 0.9962263703346252\n",
      "      vf_loss: 43.23332595825195\n",
      "    sample_time_ms: 18485.284\n",
      "    update_time_ms: 4.99\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.3322262196234\n",
      "  time_since_restore: 15088.784917116165\n",
      "  time_this_iter_s: 21.45896005630493\n",
      "  time_total_s: 15088.784917116165\n",
      "  timestamp: 1553724122\n",
      "  timesteps_since_restore: 5790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5790000\n",
      "  training_iteration: 579\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15088 s, 579 iter, 5790000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-02-24\n",
      "  done: false\n",
      "  episode_len_mean: 127.53\n",
      "  episode_reward_max: 801.6939622615637\n",
      "  episode_reward_mean: 718.4870042035419\n",
      "  episode_reward_min: -130.10749102872398\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 42631\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.438\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 5800000\n",
      "    num_steps_trained: 5800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0021788531448692083\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6903735399246216\n",
      "      kl: 0.0420730784535408\n",
      "      policy_loss: -0.0069541167467832565\n",
      "      total_loss: 249.34320068359375\n",
      "      vf_explained_var: 0.9780305027961731\n",
      "      vf_loss: 249.35000610351562\n",
      "    sample_time_ms: 18429.124\n",
      "    update_time_ms: 5.008\n",
      "  iterations_since_restore: 580\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.24350210177084\n",
      "  time_since_restore: 15110.97662472725\n",
      "  time_this_iter_s: 22.191707611083984\n",
      "  time_total_s: 15110.97662472725\n",
      "  timestamp: 1553724144\n",
      "  timesteps_since_restore: 5800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5800000\n",
      "  training_iteration: 580\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15110 s, 580 iter, 5800000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-02-46\n",
      "  done: false\n",
      "  episode_len_mean: 126.55\n",
      "  episode_reward_max: 798.3173237205531\n",
      "  episode_reward_mean: 704.6624275214782\n",
      "  episode_reward_min: -130.10749102872398\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 42710\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.787\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 5810000\n",
      "    num_steps_trained: 5810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.003268279368057847\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7076876759529114\n",
      "      kl: 0.026032734662294388\n",
      "      policy_loss: -0.006329148076474667\n",
      "      total_loss: 390.7091979980469\n",
      "      vf_explained_var: 0.9669729471206665\n",
      "      vf_loss: 390.71539306640625\n",
      "    sample_time_ms: 18368.095\n",
      "    update_time_ms: 5.183\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.331213760739\n",
      "  time_since_restore: 15133.084868907928\n",
      "  time_this_iter_s: 22.10824418067932\n",
      "  time_total_s: 15133.084868907928\n",
      "  timestamp: 1553724166\n",
      "  timesteps_since_restore: 5810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5810000\n",
      "  training_iteration: 581\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15133 s, 581 iter, 5810000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-03-09\n",
      "  done: false\n",
      "  episode_len_mean: 128.1\n",
      "  episode_reward_max: 798.3173237205531\n",
      "  episode_reward_mean: 716.6377737807733\n",
      "  episode_reward_min: -11.587738329416993\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 42788\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.762\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 5820000\n",
      "    num_steps_trained: 5820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.003268279368057847\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.65016108751297\n",
      "      kl: 0.027833547443151474\n",
      "      policy_loss: -0.005791769362986088\n",
      "      total_loss: 256.4687194824219\n",
      "      vf_explained_var: 0.9796926975250244\n",
      "      vf_loss: 256.4744567871094\n",
      "    sample_time_ms: 18337.057\n",
      "    update_time_ms: 5.187\n",
      "  iterations_since_restore: 582\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.3188868903867\n",
      "  time_since_restore: 15155.591500282288\n",
      "  time_this_iter_s: 22.50663137435913\n",
      "  time_total_s: 15155.591500282288\n",
      "  timestamp: 1553724189\n",
      "  timesteps_since_restore: 5820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5820000\n",
      "  training_iteration: 582\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15155 s, 582 iter, 5820000 ts, 717 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-03-31\n",
      "  done: false\n",
      "  episode_len_mean: 128.1\n",
      "  episode_reward_max: 802.1267617927481\n",
      "  episode_reward_mean: 727.4657780416304\n",
      "  episode_reward_min: -58.45575454319439\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 42867\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3764.384\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 5830000\n",
      "    num_steps_trained: 5830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.003268279368057847\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6380210518836975\n",
      "      kl: 0.02250230312347412\n",
      "      policy_loss: -0.0063351355493068695\n",
      "      total_loss: 186.39002990722656\n",
      "      vf_explained_var: 0.9842793345451355\n",
      "      vf_loss: 186.39630126953125\n",
      "    sample_time_ms: 18380.352\n",
      "    update_time_ms: 5.168\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 363.7328890208152\n",
      "  time_since_restore: 15178.046314239502\n",
      "  time_this_iter_s: 22.454813957214355\n",
      "  time_total_s: 15178.046314239502\n",
      "  timestamp: 1553724211\n",
      "  timesteps_since_restore: 5830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5830000\n",
      "  training_iteration: 583\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15178 s, 583 iter, 5830000 ts, 727 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-03-54\n",
      "  done: false\n",
      "  episode_len_mean: 126.34\n",
      "  episode_reward_max: 802.1267617927481\n",
      "  episode_reward_mean: 708.8930626672471\n",
      "  episode_reward_min: -92.52399095917664\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 42946\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3764.191\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 5840000\n",
      "    num_steps_trained: 5840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.003268279368057847\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6264940500259399\n",
      "      kl: 0.019610421732068062\n",
      "      policy_loss: -0.0034093265421688557\n",
      "      total_loss: 538.0870361328125\n",
      "      vf_explained_var: 0.9548564553260803\n",
      "      vf_loss: 538.0903930664062\n",
      "    sample_time_ms: 18471.168\n",
      "    update_time_ms: 5.181\n",
      "  iterations_since_restore: 584\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.44653133362357\n",
      "  time_since_restore: 15200.747871875763\n",
      "  time_this_iter_s: 22.701557636260986\n",
      "  time_total_s: 15200.747871875763\n",
      "  timestamp: 1553724234\n",
      "  timesteps_since_restore: 5840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5840000\n",
      "  training_iteration: 584\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15200 s, 584 iter, 5840000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-04-16\n",
      "  done: false\n",
      "  episode_len_mean: 125.95\n",
      "  episode_reward_max: 792.5308770306883\n",
      "  episode_reward_mean: 700.6482824382746\n",
      "  episode_reward_min: -60.9506447322199\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 43025\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.856\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 5850000\n",
      "    num_steps_trained: 5850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.003268279368057847\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6452063322067261\n",
      "      kl: 0.01853940822184086\n",
      "      policy_loss: -0.0031185210682451725\n",
      "      total_loss: 403.773193359375\n",
      "      vf_explained_var: 0.9645063877105713\n",
      "      vf_loss: 403.7762451171875\n",
      "    sample_time_ms: 18508.941\n",
      "    update_time_ms: 5.214\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.3241412191373\n",
      "  time_since_restore: 15223.166868686676\n",
      "  time_this_iter_s: 22.418996810913086\n",
      "  time_total_s: 15223.166868686676\n",
      "  timestamp: 1553724256\n",
      "  timesteps_since_restore: 5850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5850000\n",
      "  training_iteration: 585\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15223 s, 585 iter, 5850000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-04-39\n",
      "  done: false\n",
      "  episode_len_mean: 125.94\n",
      "  episode_reward_max: 789.1706172894433\n",
      "  episode_reward_mean: 674.0363075731889\n",
      "  episode_reward_min: -84.77009400450021\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 43105\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3766.229\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 5860000\n",
      "    num_steps_trained: 5860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.003268279368057847\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7415623664855957\n",
      "      kl: 0.02153010480105877\n",
      "      policy_loss: -0.0019884509965777397\n",
      "      total_loss: 1007.1820068359375\n",
      "      vf_explained_var: 0.9225919842720032\n",
      "      vf_loss: 1007.1838989257812\n",
      "    sample_time_ms: 18561.543\n",
      "    update_time_ms: 5.237\n",
      "  iterations_since_restore: 586\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.01815378659444\n",
      "  time_since_restore: 15245.915914535522\n",
      "  time_this_iter_s: 22.749045848846436\n",
      "  time_total_s: 15245.915914535522\n",
      "  timestamp: 1553724279\n",
      "  timesteps_since_restore: 5860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5860000\n",
      "  training_iteration: 586\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15245 s, 586 iter, 5860000 ts, 674 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-05-01\n",
      "  done: false\n",
      "  episode_len_mean: 128.07\n",
      "  episode_reward_max: 807.4958810308513\n",
      "  episode_reward_mean: 692.5190549873248\n",
      "  episode_reward_min: -18.257710755812496\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 43184\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.209\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 5870000\n",
      "    num_steps_trained: 5870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.003268279368057847\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6754146218299866\n",
      "      kl: 0.01995372772216797\n",
      "      policy_loss: -0.0017828112468123436\n",
      "      total_loss: 514.3504638671875\n",
      "      vf_explained_var: 0.9563871622085571\n",
      "      vf_loss: 514.3522338867188\n",
      "    sample_time_ms: 18534.922\n",
      "    update_time_ms: 5.299\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.2595274936624\n",
      "  time_since_restore: 15268.105778455734\n",
      "  time_this_iter_s: 22.189863920211792\n",
      "  time_total_s: 15268.105778455734\n",
      "  timestamp: 1553724301\n",
      "  timesteps_since_restore: 5870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5870000\n",
      "  training_iteration: 587\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15268 s, 587 iter, 5870000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-05-23\n",
      "  done: false\n",
      "  episode_len_mean: 128.42\n",
      "  episode_reward_max: 785.9081374522825\n",
      "  episode_reward_mean: 707.4236594973935\n",
      "  episode_reward_min: -20.460304439304906\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 43262\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3766.556\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 5880000\n",
      "    num_steps_trained: 5880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.003268279368057847\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.635076642036438\n",
      "      kl: 0.47772637009620667\n",
      "      policy_loss: 0.0014128783950582147\n",
      "      total_loss: 161.3504638671875\n",
      "      vf_explained_var: 0.9866172671318054\n",
      "      vf_loss: 161.34750366210938\n",
      "    sample_time_ms: 18486.862\n",
      "    update_time_ms: 5.476\n",
      "  iterations_since_restore: 588\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.71182974869674\n",
      "  time_since_restore: 15290.117460250854\n",
      "  time_this_iter_s: 22.01168179512024\n",
      "  time_total_s: 15290.117460250854\n",
      "  timestamp: 1553724323\n",
      "  timesteps_since_restore: 5880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5880000\n",
      "  training_iteration: 588\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15290 s, 588 iter, 5880000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-05-46\n",
      "  done: false\n",
      "  episode_len_mean: 127.95\n",
      "  episode_reward_max: 807.2231195823899\n",
      "  episode_reward_mean: 720.3376047388157\n",
      "  episode_reward_min: -93.2121242981404\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 43340\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3769.267\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 5890000\n",
      "    num_steps_trained: 5890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.004902419168502092\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6450379490852356\n",
      "      kl: 0.3020269572734833\n",
      "      policy_loss: -0.0019416423747316003\n",
      "      total_loss: 57.29627227783203\n",
      "      vf_explained_var: 0.9954689145088196\n",
      "      vf_loss: 57.29673767089844\n",
      "    sample_time_ms: 18571.356\n",
      "    update_time_ms: 5.541\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.16880236940784\n",
      "  time_since_restore: 15312.451382398605\n",
      "  time_this_iter_s: 22.333922147750854\n",
      "  time_total_s: 15312.451382398605\n",
      "  timestamp: 1553724346\n",
      "  timesteps_since_restore: 5890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5890000\n",
      "  training_iteration: 589\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15312 s, 589 iter, 5890000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-06-09\n",
      "  done: false\n",
      "  episode_len_mean: 127.58\n",
      "  episode_reward_max: 801.2279238302608\n",
      "  episode_reward_mean: 724.2236174554807\n",
      "  episode_reward_min: -93.2121242981404\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 43419\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3770.839\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 5900000\n",
      "    num_steps_trained: 5900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.007353628519922495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5395070314407349\n",
      "      kl: 0.027164233848452568\n",
      "      policy_loss: -0.00227481871843338\n",
      "      total_loss: 3.7572851181030273\n",
      "      vf_explained_var: 0.9996541142463684\n",
      "      vf_loss: 3.759359836578369\n",
      "    sample_time_ms: 18672.288\n",
      "    update_time_ms: 5.465\n",
      "  iterations_since_restore: 590\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.1118087277404\n",
      "  time_since_restore: 15335.669049501419\n",
      "  time_this_iter_s: 23.21766710281372\n",
      "  time_total_s: 15335.669049501419\n",
      "  timestamp: 1553724369\n",
      "  timesteps_since_restore: 5900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5900000\n",
      "  training_iteration: 590\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15335 s, 590 iter, 5900000 ts, 724 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-06-32\n",
      "  done: false\n",
      "  episode_len_mean: 125.55\n",
      "  episode_reward_max: 787.9618822059547\n",
      "  episode_reward_mean: 710.7626636855498\n",
      "  episode_reward_min: -53.896857656014504\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 43499\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3766.082\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 5910000\n",
      "    num_steps_trained: 5910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.007353628519922495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6658766865730286\n",
      "      kl: 0.01911005936563015\n",
      "      policy_loss: -0.0074201845563948154\n",
      "      total_loss: 577.3855590820312\n",
      "      vf_explained_var: 0.9553060531616211\n",
      "      vf_loss: 577.392822265625\n",
      "    sample_time_ms: 18726.687\n",
      "    update_time_ms: 5.613\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.38133184277496\n",
      "  time_since_restore: 15358.27911567688\n",
      "  time_this_iter_s: 22.610066175460815\n",
      "  time_total_s: 15358.27911567688\n",
      "  timestamp: 1553724392\n",
      "  timesteps_since_restore: 5910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5910000\n",
      "  training_iteration: 591\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15358 s, 591 iter, 5910000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-06-54\n",
      "  done: false\n",
      "  episode_len_mean: 126.86\n",
      "  episode_reward_max: 790.8849251928008\n",
      "  episode_reward_mean: 695.7831468684213\n",
      "  episode_reward_min: -53.896857656014504\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 43577\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.142\n",
      "    load_time_ms: 1.7\n",
      "    num_steps_sampled: 5920000\n",
      "    num_steps_trained: 5920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.007353628519922495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6629356145858765\n",
      "      kl: 0.018927792087197304\n",
      "      policy_loss: -0.0021736889611929655\n",
      "      total_loss: 110.45105743408203\n",
      "      vf_explained_var: 0.9915089011192322\n",
      "      vf_loss: 110.4531021118164\n",
      "    sample_time_ms: 18679.899\n",
      "    update_time_ms: 5.524\n",
      "  iterations_since_restore: 592\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.8915734342107\n",
      "  time_since_restore: 15380.286612987518\n",
      "  time_this_iter_s: 22.007497310638428\n",
      "  time_total_s: 15380.286612987518\n",
      "  timestamp: 1553724414\n",
      "  timesteps_since_restore: 5920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5920000\n",
      "  training_iteration: 592\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15380 s, 592 iter, 5920000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-07-16\n",
      "  done: false\n",
      "  episode_len_mean: 125.65\n",
      "  episode_reward_max: 793.252836994696\n",
      "  episode_reward_mean: 693.5314550063439\n",
      "  episode_reward_min: -56.31222885367305\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 43658\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.108\n",
      "    load_time_ms: 1.746\n",
      "    num_steps_sampled: 5930000\n",
      "    num_steps_trained: 5930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.007353628519922495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6214185953140259\n",
      "      kl: 0.017169730737805367\n",
      "      policy_loss: -0.004827433731406927\n",
      "      total_loss: 705.1039428710938\n",
      "      vf_explained_var: 0.9410732984542847\n",
      "      vf_loss: 705.1085815429688\n",
      "    sample_time_ms: 18654.625\n",
      "    update_time_ms: 5.459\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.765727503172\n",
      "  time_since_restore: 15402.45808839798\n",
      "  time_this_iter_s: 22.171475410461426\n",
      "  time_total_s: 15402.45808839798\n",
      "  timestamp: 1553724436\n",
      "  timesteps_since_restore: 5930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5930000\n",
      "  training_iteration: 593\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15402 s, 593 iter, 5930000 ts, 694 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-07-38\n",
      "  done: false\n",
      "  episode_len_mean: 126.89\n",
      "  episode_reward_max: 793.252836994696\n",
      "  episode_reward_mean: 686.8781203713963\n",
      "  episode_reward_min: -83.72668461934119\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 43736\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.911\n",
      "    load_time_ms: 1.708\n",
      "    num_steps_sampled: 5940000\n",
      "    num_steps_trained: 5940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.007353628519922495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7188136577606201\n",
      "      kl: 0.018016166985034943\n",
      "      policy_loss: -0.0035285658668726683\n",
      "      total_loss: 455.2890625\n",
      "      vf_explained_var: 0.962726891040802\n",
      "      vf_loss: 455.29248046875\n",
      "    sample_time_ms: 18617.161\n",
      "    update_time_ms: 5.443\n",
      "  iterations_since_restore: 594\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.43906018569817\n",
      "  time_since_restore: 15424.790412425995\n",
      "  time_this_iter_s: 22.332324028015137\n",
      "  time_total_s: 15424.790412425995\n",
      "  timestamp: 1553724458\n",
      "  timesteps_since_restore: 5940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5940000\n",
      "  training_iteration: 594\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15424 s, 594 iter, 5940000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-08-01\n",
      "  done: false\n",
      "  episode_len_mean: 129.96\n",
      "  episode_reward_max: 795.4070073009725\n",
      "  episode_reward_mean: 706.9348336855774\n",
      "  episode_reward_min: -67.15320287624309\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 43813\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.698\n",
      "    load_time_ms: 1.747\n",
      "    num_steps_sampled: 5950000\n",
      "    num_steps_trained: 5950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.007353628519922495\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6590678691864014\n",
      "      kl: 0.06548110395669937\n",
      "      policy_loss: -0.0026279569137841463\n",
      "      total_loss: 204.0144500732422\n",
      "      vf_explained_var: 0.9812484979629517\n",
      "      vf_loss: 204.0166015625\n",
      "    sample_time_ms: 18613.512\n",
      "    update_time_ms: 5.556\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.4674168427887\n",
      "  time_since_restore: 15447.184814214706\n",
      "  time_this_iter_s: 22.394401788711548\n",
      "  time_total_s: 15447.184814214706\n",
      "  timestamp: 1553724481\n",
      "  timesteps_since_restore: 5950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5950000\n",
      "  training_iteration: 595\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15447 s, 595 iter, 5950000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-08-23\n",
      "  done: false\n",
      "  episode_len_mean: 129.06\n",
      "  episode_reward_max: 793.2318801835446\n",
      "  episode_reward_mean: 703.5783149873948\n",
      "  episode_reward_min: -110.62344818254036\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 43891\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.943\n",
      "    load_time_ms: 1.706\n",
      "    num_steps_sampled: 5960000\n",
      "    num_steps_trained: 5960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6791456341743469\n",
      "      kl: 0.026951270177960396\n",
      "      policy_loss: -0.004830469843000174\n",
      "      total_loss: 279.63189697265625\n",
      "      vf_explained_var: 0.9753352403640747\n",
      "      vf_loss: 279.636474609375\n",
      "    sample_time_ms: 18594.697\n",
      "    update_time_ms: 5.636\n",
      "  iterations_since_restore: 596\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.7891574936974\n",
      "  time_since_restore: 15469.757038593292\n",
      "  time_this_iter_s: 22.572224378585815\n",
      "  time_total_s: 15469.757038593292\n",
      "  timestamp: 1553724503\n",
      "  timesteps_since_restore: 5960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5960000\n",
      "  training_iteration: 596\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15469 s, 596 iter, 5960000 ts, 704 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-08-46\n",
      "  done: false\n",
      "  episode_len_mean: 127.01\n",
      "  episode_reward_max: 791.9499435991842\n",
      "  episode_reward_mean: 693.0399873070393\n",
      "  episode_reward_min: -82.56573249881447\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 43970\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3758.175\n",
      "    load_time_ms: 1.7\n",
      "    num_steps_sampled: 5970000\n",
      "    num_steps_trained: 5970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6987003684043884\n",
      "      kl: 0.017235828563570976\n",
      "      policy_loss: -0.005671520251780748\n",
      "      total_loss: 570.6273803710938\n",
      "      vf_explained_var: 0.9549153447151184\n",
      "      vf_loss: 570.6328735351562\n",
      "    sample_time_ms: 18668.285\n",
      "    update_time_ms: 5.603\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.51999365351963\n",
      "  time_since_restore: 15492.631591558456\n",
      "  time_this_iter_s: 22.874552965164185\n",
      "  time_total_s: 15492.631591558456\n",
      "  timestamp: 1553724526\n",
      "  timesteps_since_restore: 5970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5970000\n",
      "  training_iteration: 597\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15492 s, 597 iter, 5970000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-09-09\n",
      "  done: false\n",
      "  episode_len_mean: 126.47\n",
      "  episode_reward_max: 795.9850832128866\n",
      "  episode_reward_mean: 690.9328205888008\n",
      "  episode_reward_min: -82.56573249881447\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 44049\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.05\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 5980000\n",
      "    num_steps_trained: 5980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6860581636428833\n",
      "      kl: 0.01870507001876831\n",
      "      policy_loss: -0.001118095126003027\n",
      "      total_loss: 507.15045166015625\n",
      "      vf_explained_var: 0.95937579870224\n",
      "      vf_loss: 507.1513366699219\n",
      "    sample_time_ms: 18687.343\n",
      "    update_time_ms: 5.55\n",
      "  iterations_since_restore: 598\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.4664102944004\n",
      "  time_since_restore: 15514.784100294113\n",
      "  time_this_iter_s: 22.15250873565674\n",
      "  time_total_s: 15514.784100294113\n",
      "  timestamp: 1553724549\n",
      "  timesteps_since_restore: 5980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5980000\n",
      "  training_iteration: 598\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15514 s, 598 iter, 5980000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-09-31\n",
      "  done: false\n",
      "  episode_len_mean: 128.96\n",
      "  episode_reward_max: 791.8275010680464\n",
      "  episode_reward_mean: 712.8205361861693\n",
      "  episode_reward_min: -72.09955629479161\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 44128\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3747.951\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 5990000\n",
      "    num_steps_trained: 5990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.567115843296051\n",
      "      kl: 0.022532803937792778\n",
      "      policy_loss: -0.0006406119791790843\n",
      "      total_loss: 136.6131134033203\n",
      "      vf_explained_var: 0.9883886575698853\n",
      "      vf_loss: 136.61349487304688\n",
      "    sample_time_ms: 18739.764\n",
      "    update_time_ms: 5.578\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.41026809308477\n",
      "  time_since_restore: 15537.587707042694\n",
      "  time_this_iter_s: 22.803606748580933\n",
      "  time_total_s: 15537.587707042694\n",
      "  timestamp: 1553724571\n",
      "  timesteps_since_restore: 5990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5990000\n",
      "  training_iteration: 599\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15537 s, 599 iter, 5990000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-09-53\n",
      "  done: false\n",
      "  episode_len_mean: 128.1\n",
      "  episode_reward_max: 789.2186656668312\n",
      "  episode_reward_mean: 716.8677387104359\n",
      "  episode_reward_min: -52.028926516307536\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 44205\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.039\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 6000000\n",
      "    num_steps_trained: 6000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6205211281776428\n",
      "      kl: 0.023229578509926796\n",
      "      policy_loss: -0.00572063447907567\n",
      "      total_loss: 170.88233947753906\n",
      "      vf_explained_var: 0.9861692786216736\n",
      "      vf_loss: 170.88780212402344\n",
      "    sample_time_ms: 18620.165\n",
      "    update_time_ms: 5.473\n",
      "  iterations_since_restore: 600\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.4338693552179\n",
      "  time_since_restore: 15559.558649539948\n",
      "  time_this_iter_s: 21.970942497253418\n",
      "  time_total_s: 15559.558649539948\n",
      "  timestamp: 1553724593\n",
      "  timesteps_since_restore: 6000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6000000\n",
      "  training_iteration: 600\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15559 s, 600 iter, 6000000 ts, 717 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-10-16\n",
      "  done: false\n",
      "  episode_len_mean: 127.19\n",
      "  episode_reward_max: 784.8279846811268\n",
      "  episode_reward_mean: 682.1357216760074\n",
      "  episode_reward_min: -83.05387262235159\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 44284\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3741.382\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 6010000\n",
      "    num_steps_trained: 6010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.71036297082901\n",
      "      kl: 0.02544742077589035\n",
      "      policy_loss: -0.005298200529068708\n",
      "      total_loss: 520.78515625\n",
      "      vf_explained_var: 0.9600188136100769\n",
      "      vf_loss: 520.7901611328125\n",
      "    sample_time_ms: 18572.826\n",
      "    update_time_ms: 5.253\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.0678608380037\n",
      "  time_since_restore: 15581.673772573471\n",
      "  time_this_iter_s: 22.11512303352356\n",
      "  time_total_s: 15581.673772573471\n",
      "  timestamp: 1553724616\n",
      "  timesteps_since_restore: 6010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6010000\n",
      "  training_iteration: 601\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15581 s, 601 iter, 6010000 ts, 682 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-10-38\n",
      "  done: false\n",
      "  episode_len_mean: 128.53\n",
      "  episode_reward_max: 784.9228637949159\n",
      "  episode_reward_mean: 672.6828510069104\n",
      "  episode_reward_min: -84.91513254977377\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 44362\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.557\n",
      "    load_time_ms: 1.473\n",
      "    num_steps_sampled: 6020000\n",
      "    num_steps_trained: 6020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7032224535942078\n",
      "      kl: 0.020643433555960655\n",
      "      policy_loss: -0.0026287068612873554\n",
      "      total_loss: 446.0709228515625\n",
      "      vf_explained_var: 0.9622959494590759\n",
      "      vf_loss: 446.07330322265625\n",
      "    sample_time_ms: 18630.434\n",
      "    update_time_ms: 5.319\n",
      "  iterations_since_restore: 602\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.3414255034551\n",
      "  time_since_restore: 15604.268238306046\n",
      "  time_this_iter_s: 22.594465732574463\n",
      "  time_total_s: 15604.268238306046\n",
      "  timestamp: 1553724638\n",
      "  timesteps_since_restore: 6020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6020000\n",
      "  training_iteration: 602\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15604 s, 602 iter, 6020000 ts, 673 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-11-01\n",
      "  done: false\n",
      "  episode_len_mean: 128.24\n",
      "  episode_reward_max: 784.9228637949159\n",
      "  episode_reward_mean: 708.4361131734324\n",
      "  episode_reward_min: -84.91513254977377\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 44440\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.671\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 6030000\n",
      "    num_steps_trained: 6030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5742112994194031\n",
      "      kl: 0.025164244696497917\n",
      "      policy_loss: -0.002876134356483817\n",
      "      total_loss: 159.28929138183594\n",
      "      vf_explained_var: 0.9867361783981323\n",
      "      vf_loss: 159.29188537597656\n",
      "    sample_time_ms: 18704.225\n",
      "    update_time_ms: 5.515\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.2180565867161\n",
      "  time_since_restore: 15627.150736808777\n",
      "  time_this_iter_s: 22.882498502731323\n",
      "  time_total_s: 15627.150736808777\n",
      "  timestamp: 1553724661\n",
      "  timesteps_since_restore: 6030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6030000\n",
      "  training_iteration: 603\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15627 s, 603 iter, 6030000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-11-24\n",
      "  done: false\n",
      "  episode_len_mean: 127.73\n",
      "  episode_reward_max: 797.925243529245\n",
      "  episode_reward_mean: 731.0723109058938\n",
      "  episode_reward_min: 675.3076245292277\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 44519\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.672\n",
      "    load_time_ms: 1.463\n",
      "    num_steps_sampled: 6040000\n",
      "    num_steps_trained: 6040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5366271138191223\n",
      "      kl: 0.030305122956633568\n",
      "      policy_loss: -0.0026802734937518835\n",
      "      total_loss: 10.6984281539917\n",
      "      vf_explained_var: 0.999110758304596\n",
      "      vf_loss: 10.700774192810059\n",
      "    sample_time_ms: 18740.781\n",
      "    update_time_ms: 5.511\n",
      "  iterations_since_restore: 604\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 365.5361554529469\n",
      "  time_since_restore: 15649.878418445587\n",
      "  time_this_iter_s: 22.727681636810303\n",
      "  time_total_s: 15649.878418445587\n",
      "  timestamp: 1553724684\n",
      "  timesteps_since_restore: 6040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6040000\n",
      "  training_iteration: 604\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15649 s, 604 iter, 6040000 ts, 731 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-11-46\n",
      "  done: false\n",
      "  episode_len_mean: 129.42\n",
      "  episode_reward_max: 795.5693086607808\n",
      "  episode_reward_mean: 722.7969300073833\n",
      "  episode_reward_min: -53.98882299951674\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 44596\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.101\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 6050000\n",
      "    num_steps_trained: 6050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6589773893356323\n",
      "      kl: 0.02135213278234005\n",
      "      policy_loss: -0.0032080472446978092\n",
      "      total_loss: 121.53509521484375\n",
      "      vf_explained_var: 0.9894582033157349\n",
      "      vf_loss: 121.5380630493164\n",
      "    sample_time_ms: 18711.296\n",
      "    update_time_ms: 5.438\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.3984650036917\n",
      "  time_since_restore: 15671.977739095688\n",
      "  time_this_iter_s: 22.099320650100708\n",
      "  time_total_s: 15671.977739095688\n",
      "  timestamp: 1553724706\n",
      "  timesteps_since_restore: 6050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6050000\n",
      "  training_iteration: 605\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15671 s, 605 iter, 6050000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-12-08\n",
      "  done: false\n",
      "  episode_len_mean: 129.14\n",
      "  episode_reward_max: 799.2507950612551\n",
      "  episode_reward_mean: 716.4010983383981\n",
      "  episode_reward_min: -63.357080888491964\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 44674\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.468\n",
      "    load_time_ms: 1.461\n",
      "    num_steps_sampled: 6060000\n",
      "    num_steps_trained: 6060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6009017825126648\n",
      "      kl: 0.019988175481557846\n",
      "      policy_loss: -0.008543603122234344\n",
      "      total_loss: 95.00669860839844\n",
      "      vf_explained_var: 0.9928401112556458\n",
      "      vf_loss: 95.0150146484375\n",
      "    sample_time_ms: 18694.566\n",
      "    update_time_ms: 5.372\n",
      "  iterations_since_restore: 606\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.20054916919906\n",
      "  time_since_restore: 15694.387001752853\n",
      "  time_this_iter_s: 22.409262657165527\n",
      "  time_total_s: 15694.387001752853\n",
      "  timestamp: 1553724728\n",
      "  timesteps_since_restore: 6060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6060000\n",
      "  training_iteration: 606\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15694 s, 606 iter, 6060000 ts, 716 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-12-30\n",
      "  done: false\n",
      "  episode_len_mean: 127.47\n",
      "  episode_reward_max: 791.8688165099417\n",
      "  episode_reward_mean: 680.860664643563\n",
      "  episode_reward_min: -81.59600960436285\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 44753\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.207\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 6070000\n",
      "    num_steps_trained: 6070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8087824583053589\n",
      "      kl: 0.019252920523285866\n",
      "      policy_loss: -0.0007843153434805572\n",
      "      total_loss: 1029.7562255859375\n",
      "      vf_explained_var: 0.9199793934822083\n",
      "      vf_loss: 1029.7568359375\n",
      "    sample_time_ms: 18578.582\n",
      "    update_time_ms: 5.318\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.4303323217815\n",
      "  time_since_restore: 15716.118828773499\n",
      "  time_this_iter_s: 21.73182702064514\n",
      "  time_total_s: 15716.118828773499\n",
      "  timestamp: 1553724750\n",
      "  timesteps_since_restore: 6070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6070000\n",
      "  training_iteration: 607\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15716 s, 607 iter, 6070000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-12-52\n",
      "  done: false\n",
      "  episode_len_mean: 127.57\n",
      "  episode_reward_max: 779.4212189465015\n",
      "  episode_reward_mean: 673.2033602250635\n",
      "  episode_reward_min: -81.59600960436285\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 44832\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.063\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 6080000\n",
      "    num_steps_trained: 6080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6798502206802368\n",
      "      kl: 0.020829355344176292\n",
      "      policy_loss: -0.00426026014611125\n",
      "      total_loss: 511.2582092285156\n",
      "      vf_explained_var: 0.9624266028404236\n",
      "      vf_loss: 511.26226806640625\n",
      "    sample_time_ms: 18584.206\n",
      "    update_time_ms: 5.311\n",
      "  iterations_since_restore: 608\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.60168011253177\n",
      "  time_since_restore: 15738.324169158936\n",
      "  time_this_iter_s: 22.20534038543701\n",
      "  time_total_s: 15738.324169158936\n",
      "  timestamp: 1553724772\n",
      "  timesteps_since_restore: 6080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6080000\n",
      "  training_iteration: 608\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15738 s, 608 iter, 6080000 ts, 673 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-13-15\n",
      "  done: false\n",
      "  episode_len_mean: 128.2\n",
      "  episode_reward_max: 787.1942960180212\n",
      "  episode_reward_mean: 717.9589015674087\n",
      "  episode_reward_min: -32.09150454878218\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 44911\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3744.359\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 6090000\n",
      "    num_steps_trained: 6090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.644058108329773\n",
      "      kl: 0.02680824138224125\n",
      "      policy_loss: -0.0022537242621183395\n",
      "      total_loss: 259.20196533203125\n",
      "      vf_explained_var: 0.9791842699050903\n",
      "      vf_loss: 259.20391845703125\n",
      "    sample_time_ms: 18586.482\n",
      "    update_time_ms: 5.177\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.97945078370446\n",
      "  time_since_restore: 15761.144091367722\n",
      "  time_this_iter_s: 22.81992220878601\n",
      "  time_total_s: 15761.144091367722\n",
      "  timestamp: 1553724795\n",
      "  timesteps_since_restore: 6090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6090000\n",
      "  training_iteration: 609\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15761 s, 609 iter, 6090000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-13-38\n",
      "  done: false\n",
      "  episode_len_mean: 129.3\n",
      "  episode_reward_max: 782.6587356321999\n",
      "  episode_reward_mean: 692.3964416410679\n",
      "  episode_reward_min: -68.31160439080415\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 44987\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.804\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 6100000\n",
      "    num_steps_trained: 6100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7700396776199341\n",
      "      kl: 0.013487830758094788\n",
      "      policy_loss: -0.00025123031809926033\n",
      "      total_loss: 396.916259765625\n",
      "      vf_explained_var: 0.9709152579307556\n",
      "      vf_loss: 396.9163513183594\n",
      "    sample_time_ms: 18660.515\n",
      "    update_time_ms: 5.255\n",
      "  iterations_since_restore: 610\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.19822082053395\n",
      "  time_since_restore: 15783.8391726017\n",
      "  time_this_iter_s: 22.69508123397827\n",
      "  time_total_s: 15783.8391726017\n",
      "  timestamp: 1553724818\n",
      "  timesteps_since_restore: 6100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6100000\n",
      "  training_iteration: 610\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15783 s, 610 iter, 6100000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-14-00\n",
      "  done: false\n",
      "  episode_len_mean: 130.92\n",
      "  episode_reward_max: 787.6008291369702\n",
      "  episode_reward_mean: 722.4169855475568\n",
      "  episode_reward_min: -18.946680030055177\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 45065\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.593\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 6110000\n",
      "    num_steps_trained: 6110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6340611577033997\n",
      "      kl: 0.0369570329785347\n",
      "      policy_loss: -0.0011464908020570874\n",
      "      total_loss: 181.02000427246094\n",
      "      vf_explained_var: 0.9840887784957886\n",
      "      vf_loss: 181.020751953125\n",
      "    sample_time_ms: 18646.68\n",
      "    update_time_ms: 5.224\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.2084927737784\n",
      "  time_since_restore: 15805.841324567795\n",
      "  time_this_iter_s: 22.00215196609497\n",
      "  time_total_s: 15805.841324567795\n",
      "  timestamp: 1553724840\n",
      "  timesteps_since_restore: 6110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6110000\n",
      "  training_iteration: 611\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15805 s, 611 iter, 6110000 ts, 722 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-14-22\n",
      "  done: false\n",
      "  episode_len_mean: 129.29\n",
      "  episode_reward_max: 781.8720518080931\n",
      "  episode_reward_mean: 712.9852848217774\n",
      "  episode_reward_min: -54.23494927028989\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 45143\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.427\n",
      "    load_time_ms: 1.513\n",
      "    num_steps_sampled: 6120000\n",
      "    num_steps_trained: 6120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6153278350830078\n",
      "      kl: 0.02003040909767151\n",
      "      policy_loss: -0.002454340923577547\n",
      "      total_loss: 388.9910888671875\n",
      "      vf_explained_var: 0.9665457010269165\n",
      "      vf_loss: 388.99334716796875\n",
      "    sample_time_ms: 18591.223\n",
      "    update_time_ms: 5.324\n",
      "  iterations_since_restore: 612\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.4926424108888\n",
      "  time_since_restore: 15827.890732049942\n",
      "  time_this_iter_s: 22.049407482147217\n",
      "  time_total_s: 15827.890732049942\n",
      "  timestamp: 1553724862\n",
      "  timesteps_since_restore: 6120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6120000\n",
      "  training_iteration: 612\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15827 s, 612 iter, 6120000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-14-45\n",
      "  done: false\n",
      "  episode_len_mean: 129.17\n",
      "  episode_reward_max: 791.5677052321031\n",
      "  episode_reward_mean: 723.8483061699277\n",
      "  episode_reward_min: -54.23494927028989\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 45220\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3748.278\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 6130000\n",
      "    num_steps_trained: 6130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011030443012714386\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5700104832649231\n",
      "      kl: 0.04121340066194534\n",
      "      policy_loss: -0.002660333411768079\n",
      "      total_loss: 42.28895950317383\n",
      "      vf_explained_var: 0.9964224100112915\n",
      "      vf_loss: 42.29116439819336\n",
      "    sample_time_ms: 18559.212\n",
      "    update_time_ms: 5.167\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.9241530849638\n",
      "  time_since_restore: 15850.469375371933\n",
      "  time_this_iter_s: 22.578643321990967\n",
      "  time_total_s: 15850.469375371933\n",
      "  timestamp: 1553724885\n",
      "  timesteps_since_restore: 6130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6130000\n",
      "  training_iteration: 613\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15850 s, 613 iter, 6130000 ts, 724 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-15-07\n",
      "  done: false\n",
      "  episode_len_mean: 128.98\n",
      "  episode_reward_max: 791.5677052321031\n",
      "  episode_reward_mean: 702.2124448212354\n",
      "  episode_reward_min: -64.58188754183982\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 45299\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.972\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 6140000\n",
      "    num_steps_trained: 6140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016545666381716728\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.717954695224762\n",
      "      kl: 0.02233000099658966\n",
      "      policy_loss: -0.006289137993007898\n",
      "      total_loss: 367.214111328125\n",
      "      vf_explained_var: 0.971274733543396\n",
      "      vf_loss: 367.2200622558594\n",
      "    sample_time_ms: 18467.54\n",
      "    update_time_ms: 5.183\n",
      "  iterations_since_restore: 614\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.1062224106177\n",
      "  time_since_restore: 15872.20583152771\n",
      "  time_this_iter_s: 21.736456155776978\n",
      "  time_total_s: 15872.20583152771\n",
      "  timestamp: 1553724907\n",
      "  timesteps_since_restore: 6140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6140000\n",
      "  training_iteration: 614\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15872 s, 614 iter, 6140000 ts, 702 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-15-29\n",
      "  done: false\n",
      "  episode_len_mean: 127.69\n",
      "  episode_reward_max: 789.1104219046676\n",
      "  episode_reward_mean: 697.6251756723366\n",
      "  episode_reward_min: -46.42230690762429\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 45378\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.487\n",
      "    load_time_ms: 1.562\n",
      "    num_steps_sampled: 6150000\n",
      "    num_steps_trained: 6150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016545666381716728\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6672755479812622\n",
      "      kl: 0.16381412744522095\n",
      "      policy_loss: -0.0008206810452975333\n",
      "      total_loss: 369.30078125\n",
      "      vf_explained_var: 0.9679228067398071\n",
      "      vf_loss: 369.29888916015625\n",
      "    sample_time_ms: 18487.229\n",
      "    update_time_ms: 5.035\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.81258783616823\n",
      "  time_since_restore: 15894.46010184288\n",
      "  time_this_iter_s: 22.254270315170288\n",
      "  time_total_s: 15894.46010184288\n",
      "  timestamp: 1553724929\n",
      "  timesteps_since_restore: 6150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6150000\n",
      "  training_iteration: 615\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15894 s, 615 iter, 6150000 ts, 698 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-15-51\n",
      "  done: false\n",
      "  episode_len_mean: 124.48\n",
      "  episode_reward_max: 781.2655118080922\n",
      "  episode_reward_mean: 665.3804004259956\n",
      "  episode_reward_min: -103.32579584484002\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 45457\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.419\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 6160000\n",
      "    num_steps_trained: 6160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02481849491596222\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7076490521430969\n",
      "      kl: 0.016278287395834923\n",
      "      policy_loss: -0.0012389554176479578\n",
      "      total_loss: 974.8639526367188\n",
      "      vf_explained_var: 0.9230816960334778\n",
      "      vf_loss: 974.8648071289062\n",
      "    sample_time_ms: 18484.752\n",
      "    update_time_ms: 5.288\n",
      "  iterations_since_restore: 616\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 332.69020021299787\n",
      "  time_since_restore: 15916.847578525543\n",
      "  time_this_iter_s: 22.387476682662964\n",
      "  time_total_s: 15916.847578525543\n",
      "  timestamp: 1553724951\n",
      "  timesteps_since_restore: 6160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6160000\n",
      "  training_iteration: 616\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15916 s, 616 iter, 6160000 ts, 665 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-16-13\n",
      "  done: false\n",
      "  episode_len_mean: 123.77\n",
      "  episode_reward_max: 776.3368598276584\n",
      "  episode_reward_mean: 680.5796585005538\n",
      "  episode_reward_min: -127.01235169567069\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 45539\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3738.001\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 6170000\n",
      "    num_steps_trained: 6170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02481849491596222\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6321731209754944\n",
      "      kl: 0.020397154614329338\n",
      "      policy_loss: -0.0031945761293172836\n",
      "      total_loss: 834.6708984375\n",
      "      vf_explained_var: 0.9323331117630005\n",
      "      vf_loss: 834.673583984375\n",
      "    sample_time_ms: 18515.347\n",
      "    update_time_ms: 5.395\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.2898292502769\n",
      "  time_since_restore: 15938.903390169144\n",
      "  time_this_iter_s: 22.055811643600464\n",
      "  time_total_s: 15938.903390169144\n",
      "  timestamp: 1553724973\n",
      "  timesteps_since_restore: 6170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6170000\n",
      "  training_iteration: 617\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15938 s, 617 iter, 6170000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 127.26\n",
      "  episode_reward_max: 776.8888058191615\n",
      "  episode_reward_mean: 706.3107008187704\n",
      "  episode_reward_min: -52.40698263762425\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 45617\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3738.792\n",
      "    load_time_ms: 1.618\n",
      "    num_steps_sampled: 6180000\n",
      "    num_steps_trained: 6180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02481849491596222\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6656559705734253\n",
      "      kl: 0.015426497906446457\n",
      "      policy_loss: -0.00517714349552989\n",
      "      total_loss: 236.08534240722656\n",
      "      vf_explained_var: 0.9819136261940002\n",
      "      vf_loss: 236.09011840820312\n",
      "    sample_time_ms: 18524.533\n",
      "    update_time_ms: 5.448\n",
      "  iterations_since_restore: 618\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.15535040938516\n",
      "  time_since_restore: 15961.214393377304\n",
      "  time_this_iter_s: 22.3110032081604\n",
      "  time_total_s: 15961.214393377304\n",
      "  timestamp: 1553724996\n",
      "  timesteps_since_restore: 6180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6180000\n",
      "  training_iteration: 618\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15961 s, 618 iter, 6180000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-16-58\n",
      "  done: false\n",
      "  episode_len_mean: 128.35\n",
      "  episode_reward_max: 792.7043110527704\n",
      "  episode_reward_mean: 716.1384666631103\n",
      "  episode_reward_min: -67.55469534859736\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 45695\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.166\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 6190000\n",
      "    num_steps_trained: 6190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02481849491596222\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6313782334327698\n",
      "      kl: 0.018583131954073906\n",
      "      policy_loss: -0.0037713111378252506\n",
      "      total_loss: 377.9585876464844\n",
      "      vf_explained_var: 0.966523289680481\n",
      "      vf_loss: 377.9618835449219\n",
      "    sample_time_ms: 18418.571\n",
      "    update_time_ms: 5.596\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.0692333315552\n",
      "  time_since_restore: 15983.119042873383\n",
      "  time_this_iter_s: 21.90464949607849\n",
      "  time_total_s: 15983.119042873383\n",
      "  timestamp: 1553725018\n",
      "  timesteps_since_restore: 6190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6190000\n",
      "  training_iteration: 619\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 15983 s, 619 iter, 6190000 ts, 716 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-17-20\n",
      "  done: false\n",
      "  episode_len_mean: 128.85\n",
      "  episode_reward_max: 792.7043110527704\n",
      "  episode_reward_mean: 720.3202523128166\n",
      "  episode_reward_min: -6.525375589619301\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 45773\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3755.133\n",
      "    load_time_ms: 1.656\n",
      "    num_steps_sampled: 6200000\n",
      "    num_steps_trained: 6200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02481849491596222\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6002314686775208\n",
      "      kl: 0.04799546301364899\n",
      "      policy_loss: -0.00037032863474451005\n",
      "      total_loss: 68.2011947631836\n",
      "      vf_explained_var: 0.9942622780799866\n",
      "      vf_loss: 68.20037078857422\n",
      "    sample_time_ms: 18416.49\n",
      "    update_time_ms: 5.551\n",
      "  iterations_since_restore: 620\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.16012615640835\n",
      "  time_since_restore: 16005.813610076904\n",
      "  time_this_iter_s: 22.69456720352173\n",
      "  time_total_s: 16005.813610076904\n",
      "  timestamp: 1553725040\n",
      "  timesteps_since_restore: 6200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6200000\n",
      "  training_iteration: 620\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16005 s, 620 iter, 6200000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-17-43\n",
      "  done: false\n",
      "  episode_len_mean: 127.21\n",
      "  episode_reward_max: 787.7424270586507\n",
      "  episode_reward_mean: 690.8583250779806\n",
      "  episode_reward_min: -95.67255031348994\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 45852\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3757.059\n",
      "    load_time_ms: 1.676\n",
      "    num_steps_sampled: 6210000\n",
      "    num_steps_trained: 6210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03722774237394333\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7309810519218445\n",
      "      kl: 0.010327979922294617\n",
      "      policy_loss: 0.00016492835129611194\n",
      "      total_loss: 567.3990478515625\n",
      "      vf_explained_var: 0.9541877508163452\n",
      "      vf_loss: 567.3984985351562\n",
      "    sample_time_ms: 18492.818\n",
      "    update_time_ms: 5.626\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.4291625389903\n",
      "  time_since_restore: 16028.601984262466\n",
      "  time_this_iter_s: 22.788374185562134\n",
      "  time_total_s: 16028.601984262466\n",
      "  timestamp: 1553725063\n",
      "  timesteps_since_restore: 6210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6210000\n",
      "  training_iteration: 621\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16028 s, 621 iter, 6210000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-18-06\n",
      "  done: false\n",
      "  episode_len_mean: 130.28\n",
      "  episode_reward_max: 797.1885472179727\n",
      "  episode_reward_mean: 715.985135023147\n",
      "  episode_reward_min: -38.48658045054984\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 45929\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3757.218\n",
      "    load_time_ms: 1.679\n",
      "    num_steps_sampled: 6220000\n",
      "    num_steps_trained: 6220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03722774237394333\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6855751276016235\n",
      "      kl: 0.04887540638446808\n",
      "      policy_loss: -0.0012343060225248337\n",
      "      total_loss: 206.1914520263672\n",
      "      vf_explained_var: 0.9811031818389893\n",
      "      vf_loss: 206.19088745117188\n",
      "    sample_time_ms: 18599.621\n",
      "    update_time_ms: 5.518\n",
      "  iterations_since_restore: 622\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.99256751157355\n",
      "  time_since_restore: 16051.719566822052\n",
      "  time_this_iter_s: 23.11758255958557\n",
      "  time_total_s: 16051.719566822052\n",
      "  timestamp: 1553725086\n",
      "  timesteps_since_restore: 6220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6220000\n",
      "  training_iteration: 622\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16051 s, 622 iter, 6220000 ts, 716 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-18-29\n",
      "  done: false\n",
      "  episode_len_mean: 129.95\n",
      "  episode_reward_max: 797.1885472179727\n",
      "  episode_reward_mean: 718.9171398315104\n",
      "  episode_reward_min: -63.706245861588116\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 46008\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.01\n",
      "    load_time_ms: 1.645\n",
      "    num_steps_sampled: 6230000\n",
      "    num_steps_trained: 6230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6635868549346924\n",
      "      kl: 0.015166332013905048\n",
      "      policy_loss: -0.0006281550158746541\n",
      "      total_loss: 293.64727783203125\n",
      "      vf_explained_var: 0.9752246141433716\n",
      "      vf_loss: 293.64703369140625\n",
      "    sample_time_ms: 18584.743\n",
      "    update_time_ms: 5.691\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.4585699157552\n",
      "  time_since_restore: 16074.140570402145\n",
      "  time_this_iter_s: 22.421003580093384\n",
      "  time_total_s: 16074.140570402145\n",
      "  timestamp: 1553725109\n",
      "  timesteps_since_restore: 6230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6230000\n",
      "  training_iteration: 623\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16074 s, 623 iter, 6230000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-18-51\n",
      "  done: false\n",
      "  episode_len_mean: 129.55\n",
      "  episode_reward_max: 793.2755563914453\n",
      "  episode_reward_mean: 700.9332470005082\n",
      "  episode_reward_min: -63.706245861588116\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 46085\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.835\n",
      "    load_time_ms: 1.624\n",
      "    num_steps_sampled: 6240000\n",
      "    num_steps_trained: 6240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7041610479354858\n",
      "      kl: 0.026320824399590492\n",
      "      policy_loss: -0.0043813553638756275\n",
      "      total_loss: 276.1656188964844\n",
      "      vf_explained_var: 0.9780885577201843\n",
      "      vf_loss: 276.16851806640625\n",
      "    sample_time_ms: 18604.54\n",
      "    update_time_ms: 5.776\n",
      "  iterations_since_restore: 624\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.46662350025406\n",
      "  time_since_restore: 16096.125514268875\n",
      "  time_this_iter_s: 21.984943866729736\n",
      "  time_total_s: 16096.125514268875\n",
      "  timestamp: 1553725131\n",
      "  timesteps_since_restore: 6240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6240000\n",
      "  training_iteration: 624\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16096 s, 624 iter, 6240000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-19-13\n",
      "  done: false\n",
      "  episode_len_mean: 130.54\n",
      "  episode_reward_max: 797.1901878983757\n",
      "  episode_reward_mean: 709.7021372710633\n",
      "  episode_reward_min: -56.27020398757173\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 46161\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.205\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 6250000\n",
      "    num_steps_trained: 6250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.732371985912323\n",
      "      kl: 0.010071545839309692\n",
      "      policy_loss: -0.0022083111107349396\n",
      "      total_loss: 253.47335815429688\n",
      "      vf_explained_var: 0.9785344004631042\n",
      "      vf_loss: 253.47500610351562\n",
      "    sample_time_ms: 18564.112\n",
      "    update_time_ms: 5.851\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.85106863553165\n",
      "  time_since_restore: 16117.98504781723\n",
      "  time_this_iter_s: 21.859533548355103\n",
      "  time_total_s: 16117.98504781723\n",
      "  timestamp: 1553725153\n",
      "  timesteps_since_restore: 6250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6250000\n",
      "  training_iteration: 625\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16117 s, 625 iter, 6250000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-19-35\n",
      "  done: false\n",
      "  episode_len_mean: 129.31\n",
      "  episode_reward_max: 797.1901878983757\n",
      "  episode_reward_mean: 701.9705428008211\n",
      "  episode_reward_min: -125.02993092920141\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 46240\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.183\n",
      "    load_time_ms: 1.624\n",
      "    num_steps_sampled: 6260000\n",
      "    num_steps_trained: 6260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7104820609092712\n",
      "      kl: 0.017145490273833275\n",
      "      policy_loss: -0.002269215416163206\n",
      "      total_loss: 178.1003875732422\n",
      "      vf_explained_var: 0.9867774844169617\n",
      "      vf_loss: 178.10171508789062\n",
      "    sample_time_ms: 18566.194\n",
      "    update_time_ms: 5.669\n",
      "  iterations_since_restore: 626\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.98527140041057\n",
      "  time_since_restore: 16140.382730484009\n",
      "  time_this_iter_s: 22.397682666778564\n",
      "  time_total_s: 16140.382730484009\n",
      "  timestamp: 1553725175\n",
      "  timesteps_since_restore: 6260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6260000\n",
      "  training_iteration: 626\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16140 s, 626 iter, 6260000 ts, 702 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-19-58\n",
      "  done: false\n",
      "  episode_len_mean: 130.24\n",
      "  episode_reward_max: 786.6689277974465\n",
      "  episode_reward_mean: 706.5770026243918\n",
      "  episode_reward_min: -106.62644063288711\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 46318\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3778.408\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 6270000\n",
      "    num_steps_trained: 6270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6970230340957642\n",
      "      kl: 0.025771016255021095\n",
      "      policy_loss: -0.004147632978856564\n",
      "      total_loss: 287.2734680175781\n",
      "      vf_explained_var: 0.9746991395950317\n",
      "      vf_loss: 287.27618408203125\n",
      "    sample_time_ms: 18580.181\n",
      "    update_time_ms: 5.665\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.2885013121959\n",
      "  time_since_restore: 16162.750336885452\n",
      "  time_this_iter_s: 22.36760640144348\n",
      "  time_total_s: 16162.750336885452\n",
      "  timestamp: 1553725198\n",
      "  timesteps_since_restore: 6270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6270000\n",
      "  training_iteration: 627\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16162 s, 627 iter, 6270000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-20-20\n",
      "  done: false\n",
      "  episode_len_mean: 125.96\n",
      "  episode_reward_max: 782.4021486596779\n",
      "  episode_reward_mean: 682.0321203012218\n",
      "  episode_reward_min: -78.83496730137297\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 46398\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3777.231\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 6280000\n",
      "    num_steps_trained: 6280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7190670967102051\n",
      "      kl: 0.012570174410939217\n",
      "      policy_loss: -0.004182965494692326\n",
      "      total_loss: 735.1372680664062\n",
      "      vf_explained_var: 0.947360098361969\n",
      "      vf_loss: 735.1407470703125\n",
      "    sample_time_ms: 18607.803\n",
      "    update_time_ms: 5.531\n",
      "  iterations_since_restore: 628\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.0160601506109\n",
      "  time_since_restore: 16185.3210105896\n",
      "  time_this_iter_s: 22.57067370414734\n",
      "  time_total_s: 16185.3210105896\n",
      "  timestamp: 1553725220\n",
      "  timesteps_since_restore: 6280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6280000\n",
      "  training_iteration: 628\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16185 s, 628 iter, 6280000 ts, 682 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-20-43\n",
      "  done: false\n",
      "  episode_len_mean: 124.89\n",
      "  episode_reward_max: 789.1157082374439\n",
      "  episode_reward_mean: 656.5919386586515\n",
      "  episode_reward_min: -105.69225238240537\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 46478\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.878\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 6290000\n",
      "    num_steps_trained: 6290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7227427363395691\n",
      "      kl: 0.01837567798793316\n",
      "      policy_loss: -0.001474405056796968\n",
      "      total_loss: 1041.352783203125\n",
      "      vf_explained_var: 0.915237545967102\n",
      "      vf_loss: 1041.353271484375\n",
      "    sample_time_ms: 18670.011\n",
      "    update_time_ms: 5.408\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 328.29596932932577\n",
      "  time_since_restore: 16207.683952331543\n",
      "  time_this_iter_s: 22.36294174194336\n",
      "  time_total_s: 16207.683952331543\n",
      "  timestamp: 1553725243\n",
      "  timesteps_since_restore: 6290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6290000\n",
      "  training_iteration: 629\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16207 s, 629 iter, 6290000 ts, 657 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-21-05\n",
      "  done: false\n",
      "  episode_len_mean: 128.07\n",
      "  episode_reward_max: 789.1157082374439\n",
      "  episode_reward_mean: 707.0442461141043\n",
      "  episode_reward_min: -110.97342577717946\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 46556\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.938\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 6300000\n",
      "    num_steps_trained: 6300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6232553720474243\n",
      "      kl: 0.02034255862236023\n",
      "      policy_loss: -0.005632124841213226\n",
      "      total_loss: 255.1856689453125\n",
      "      vf_explained_var: 0.9768489003181458\n",
      "      vf_loss: 255.19015502929688\n",
      "    sample_time_ms: 18658.402\n",
      "    update_time_ms: 5.667\n",
      "  iterations_since_restore: 630\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.52212305705217\n",
      "  time_since_restore: 16230.193179607391\n",
      "  time_this_iter_s: 22.50922727584839\n",
      "  time_total_s: 16230.193179607391\n",
      "  timestamp: 1553725265\n",
      "  timesteps_since_restore: 6300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6300000\n",
      "  training_iteration: 630\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16230 s, 630 iter, 6300000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 127.85\n",
      "  episode_reward_max: 788.1551114700362\n",
      "  episode_reward_mean: 690.0234684789043\n",
      "  episode_reward_min: -133.4662273069602\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 46635\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3769.248\n",
      "    load_time_ms: 1.482\n",
      "    num_steps_sampled: 6310000\n",
      "    num_steps_trained: 6310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6863458156585693\n",
      "      kl: 0.016568623483181\n",
      "      policy_loss: -0.0042289807461202145\n",
      "      total_loss: 680.7794189453125\n",
      "      vf_explained_var: 0.9507180452346802\n",
      "      vf_loss: 680.78271484375\n",
      "    sample_time_ms: 18572.607\n",
      "    update_time_ms: 5.735\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.01173423945204\n",
      "  time_since_restore: 16252.27655005455\n",
      "  time_this_iter_s: 22.083370447158813\n",
      "  time_total_s: 16252.27655005455\n",
      "  timestamp: 1553725287\n",
      "  timesteps_since_restore: 6310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6310000\n",
      "  training_iteration: 631\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16252 s, 631 iter, 6310000 ts, 690 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-21-49\n",
      "  done: false\n",
      "  episode_len_mean: 131.56\n",
      "  episode_reward_max: 791.1630089997358\n",
      "  episode_reward_mean: 685.2784681219179\n",
      "  episode_reward_min: -88.69101623330073\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 46711\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3765.447\n",
      "    load_time_ms: 1.472\n",
      "    num_steps_sampled: 6320000\n",
      "    num_steps_trained: 6320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8521049618721008\n",
      "      kl: 0.010002057999372482\n",
      "      policy_loss: -0.00030335565679706633\n",
      "      total_loss: 453.3855285644531\n",
      "      vf_explained_var: 0.9631041288375854\n",
      "      vf_loss: 453.38525390625\n",
      "    sample_time_ms: 18407.662\n",
      "    update_time_ms: 5.767\n",
      "  iterations_since_restore: 632\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.6392340609589\n",
      "  time_since_restore: 16273.706763505936\n",
      "  time_this_iter_s: 21.430213451385498\n",
      "  time_total_s: 16273.706763505936\n",
      "  timestamp: 1553725309\n",
      "  timesteps_since_restore: 6320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6320000\n",
      "  training_iteration: 632\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16273 s, 632 iter, 6320000 ts, 685 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-22-11\n",
      "  done: false\n",
      "  episode_len_mean: 129.0\n",
      "  episode_reward_max: 798.7513877715639\n",
      "  episode_reward_mean: 654.5842258633338\n",
      "  episode_reward_min: -102.56916008965945\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 46790\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.33\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 6330000\n",
      "    num_steps_trained: 6330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.786137580871582\n",
      "      kl: 0.014422202482819557\n",
      "      policy_loss: -0.0010005083167925477\n",
      "      total_loss: 1151.855224609375\n",
      "      vf_explained_var: 0.9112733006477356\n",
      "      vf_loss: 1151.8553466796875\n",
      "    sample_time_ms: 18361.916\n",
      "    update_time_ms: 5.6\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 327.2921129316669\n",
      "  time_since_restore: 16295.61923623085\n",
      "  time_this_iter_s: 21.91247272491455\n",
      "  time_total_s: 16295.61923623085\n",
      "  timestamp: 1553725331\n",
      "  timesteps_since_restore: 6330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6330000\n",
      "  training_iteration: 633\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16295 s, 633 iter, 6330000 ts, 655 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-22-33\n",
      "  done: false\n",
      "  episode_len_mean: 126.17\n",
      "  episode_reward_max: 798.7513877715639\n",
      "  episode_reward_mean: 692.6876698440664\n",
      "  episode_reward_min: -108.4463856775641\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 46869\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.401\n",
      "    load_time_ms: 1.559\n",
      "    num_steps_sampled: 6340000\n",
      "    num_steps_trained: 6340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5184434652328491\n",
      "      kl: 0.021800566464662552\n",
      "      policy_loss: -0.005010413005948067\n",
      "      total_loss: 266.33099365234375\n",
      "      vf_explained_var: 0.9796844720840454\n",
      "      vf_loss: 266.3347473144531\n",
      "    sample_time_ms: 18355.653\n",
      "    update_time_ms: 5.638\n",
      "  iterations_since_restore: 634\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.34383492203335\n",
      "  time_since_restore: 16317.471392393112\n",
      "  time_this_iter_s: 21.852156162261963\n",
      "  time_total_s: 16317.471392393112\n",
      "  timestamp: 1553725353\n",
      "  timesteps_since_restore: 6340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6340000\n",
      "  training_iteration: 634\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16317 s, 634 iter, 6340000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-22-55\n",
      "  done: false\n",
      "  episode_len_mean: 128.67\n",
      "  episode_reward_max: 796.6677122078005\n",
      "  episode_reward_mean: 725.2124658144447\n",
      "  episode_reward_min: -108.4463856775641\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 46947\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3770.002\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 6350000\n",
      "    num_steps_trained: 6350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.54524165391922\n",
      "      kl: 0.012399458326399326\n",
      "      policy_loss: -0.0013892509741708636\n",
      "      total_loss: 26.12533950805664\n",
      "      vf_explained_var: 0.998196542263031\n",
      "      vf_loss: 26.126033782958984\n",
      "    sample_time_ms: 18380.674\n",
      "    update_time_ms: 5.585\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.60623290722236\n",
      "  time_since_restore: 16339.74882721901\n",
      "  time_this_iter_s: 22.277434825897217\n",
      "  time_total_s: 16339.74882721901\n",
      "  timestamp: 1553725375\n",
      "  timesteps_since_restore: 6350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6350000\n",
      "  training_iteration: 635\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16339 s, 635 iter, 6350000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-23-16\n",
      "  done: false\n",
      "  episode_len_mean: 130.35\n",
      "  episode_reward_max: 787.886484653761\n",
      "  episode_reward_mean: 733.016372710469\n",
      "  episode_reward_min: 688.9434988377578\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 47024\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.193\n",
      "    load_time_ms: 1.521\n",
      "    num_steps_sampled: 6360000\n",
      "    num_steps_trained: 6360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6004589200019836\n",
      "      kl: 0.01330021396279335\n",
      "      policy_loss: -0.0019543643575161695\n",
      "      total_loss: 23.137916564941406\n",
      "      vf_explained_var: 0.9983279705047607\n",
      "      vf_loss: 23.139127731323242\n",
      "    sample_time_ms: 18286.391\n",
      "    update_time_ms: 5.653\n",
      "  iterations_since_restore: 636\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 366.5081863552345\n",
      "  time_since_restore: 16361.111827611923\n",
      "  time_this_iter_s: 21.36300039291382\n",
      "  time_total_s: 16361.111827611923\n",
      "  timestamp: 1553725396\n",
      "  timesteps_since_restore: 6360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6360000\n",
      "  training_iteration: 636\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16361 s, 636 iter, 6360000 ts, 733 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-23-39\n",
      "  done: false\n",
      "  episode_len_mean: 131.12\n",
      "  episode_reward_max: 803.2223383338971\n",
      "  episode_reward_mean: 709.9607216297464\n",
      "  episode_reward_min: -53.89117230981006\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 47101\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.747\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 6370000\n",
      "    num_steps_trained: 6370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7107046842575073\n",
      "      kl: 0.01103631965816021\n",
      "      policy_loss: -0.001501355436630547\n",
      "      total_loss: 309.59912109375\n",
      "      vf_explained_var: 0.9765682816505432\n",
      "      vf_loss: 309.5999755859375\n",
      "    sample_time_ms: 18337.941\n",
      "    update_time_ms: 5.577\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.9803608148732\n",
      "  time_since_restore: 16383.776167154312\n",
      "  time_this_iter_s: 22.664339542388916\n",
      "  time_total_s: 16383.776167154312\n",
      "  timestamp: 1553725419\n",
      "  timesteps_since_restore: 6370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6370000\n",
      "  training_iteration: 637\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16383 s, 637 iter, 6370000 ts, 710 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-24-01\n",
      "  done: false\n",
      "  episode_len_mean: 130.09\n",
      "  episode_reward_max: 796.3617143617231\n",
      "  episode_reward_mean: 715.7109227898738\n",
      "  episode_reward_min: -53.89117230981006\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 47179\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3738.244\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 6380000\n",
      "    num_steps_trained: 6380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5869515538215637\n",
      "      kl: 0.01093091070652008\n",
      "      policy_loss: -0.0014970445772632957\n",
      "      total_loss: 86.09154510498047\n",
      "      vf_explained_var: 0.9937268495559692\n",
      "      vf_loss: 86.09242248535156\n",
      "    sample_time_ms: 18286.718\n",
      "    update_time_ms: 5.516\n",
      "  iterations_since_restore: 638\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.85546139493704\n",
      "  time_since_restore: 16405.82117152214\n",
      "  time_this_iter_s: 22.04500436782837\n",
      "  time_total_s: 16405.82117152214\n",
      "  timestamp: 1553725441\n",
      "  timesteps_since_restore: 6380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6380000\n",
      "  training_iteration: 638\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16405 s, 638 iter, 6380000 ts, 716 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-24-24\n",
      "  done: false\n",
      "  episode_len_mean: 131.73\n",
      "  episode_reward_max: 791.9222527378441\n",
      "  episode_reward_mean: 696.5854712509685\n",
      "  episode_reward_min: -61.35268006589797\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 47254\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3737.848\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 6390000\n",
      "    num_steps_trained: 6390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8139411211013794\n",
      "      kl: 0.02622123807668686\n",
      "      policy_loss: -0.003839723998680711\n",
      "      total_loss: 407.8203125\n",
      "      vf_explained_var: 0.9711387753486633\n",
      "      vf_loss: 407.8227233886719\n",
      "    sample_time_ms: 18319.127\n",
      "    update_time_ms: 5.559\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.2927356254842\n",
      "  time_since_restore: 16428.504374027252\n",
      "  time_this_iter_s: 22.683202505111694\n",
      "  time_total_s: 16428.504374027252\n",
      "  timestamp: 1553725464\n",
      "  timesteps_since_restore: 6390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6390000\n",
      "  training_iteration: 639\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16428 s, 639 iter, 6390000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-24-46\n",
      "  done: false\n",
      "  episode_len_mean: 130.41\n",
      "  episode_reward_max: 788.1696422969036\n",
      "  episode_reward_mean: 678.0080567183877\n",
      "  episode_reward_min: -110.3214599757749\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 47333\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.367\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 6400000\n",
      "    num_steps_trained: 6400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6024632453918457\n",
      "      kl: 0.012344666756689548\n",
      "      policy_loss: -0.002439762931317091\n",
      "      total_loss: 483.97216796875\n",
      "      vf_explained_var: 0.9622765779495239\n",
      "      vf_loss: 483.9738464355469\n",
      "    sample_time_ms: 18280.193\n",
      "    update_time_ms: 5.434\n",
      "  iterations_since_restore: 640\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.0040283591939\n",
      "  time_since_restore: 16450.68021965027\n",
      "  time_this_iter_s: 22.175845623016357\n",
      "  time_total_s: 16450.68021965027\n",
      "  timestamp: 1553725486\n",
      "  timesteps_since_restore: 6400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6400000\n",
      "  training_iteration: 640\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16450 s, 640 iter, 6400000 ts, 678 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 131.51\n",
      "  episode_reward_max: 791.2071448787444\n",
      "  episode_reward_mean: 697.1633137838774\n",
      "  episode_reward_min: -53.39842924658629\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 47409\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.109\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 6410000\n",
      "    num_steps_trained: 6410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6916926503181458\n",
      "      kl: 0.014868240803480148\n",
      "      policy_loss: -0.0029438298661261797\n",
      "      total_loss: 261.9285888671875\n",
      "      vf_explained_var: 0.9809013605117798\n",
      "      vf_loss: 261.93072509765625\n",
      "    sample_time_ms: 18374.027\n",
      "    update_time_ms: 5.304\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.5816568919386\n",
      "  time_since_restore: 16473.508153438568\n",
      "  time_this_iter_s: 22.82793378829956\n",
      "  time_total_s: 16473.508153438568\n",
      "  timestamp: 1553725509\n",
      "  timesteps_since_restore: 6410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6410000\n",
      "  training_iteration: 641\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16473 s, 641 iter, 6410000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-25-32\n",
      "  done: false\n",
      "  episode_len_mean: 129.75\n",
      "  episode_reward_max: 791.2071448787444\n",
      "  episode_reward_mean: 706.3063100429549\n",
      "  episode_reward_min: -117.39169643840067\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 47488\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.018\n",
      "    load_time_ms: 1.631\n",
      "    num_steps_sampled: 6420000\n",
      "    num_steps_trained: 6420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5739176869392395\n",
      "      kl: 0.020066533237695694\n",
      "      policy_loss: 0.00010281419235980138\n",
      "      total_loss: 325.80157470703125\n",
      "      vf_explained_var: 0.974087655544281\n",
      "      vf_loss: 325.80035400390625\n",
      "    sample_time_ms: 18505.889\n",
      "    update_time_ms: 5.207\n",
      "  iterations_since_restore: 642\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.15315502147746\n",
      "  time_since_restore: 16496.257676124573\n",
      "  time_this_iter_s: 22.74952268600464\n",
      "  time_total_s: 16496.257676124573\n",
      "  timestamp: 1553725532\n",
      "  timesteps_since_restore: 6420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6420000\n",
      "  training_iteration: 642\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16496 s, 642 iter, 6420000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-25-54\n",
      "  done: false\n",
      "  episode_len_mean: 132.92\n",
      "  episode_reward_max: 782.6565049636541\n",
      "  episode_reward_mean: 714.7635225396014\n",
      "  episode_reward_min: -25.750075106815046\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 47563\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.319\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 6430000\n",
      "    num_steps_trained: 6430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6850489377975464\n",
      "      kl: 0.01721089705824852\n",
      "      policy_loss: -0.0033956628758460283\n",
      "      total_loss: 221.57852172851562\n",
      "      vf_explained_var: 0.980246901512146\n",
      "      vf_loss: 221.5809326171875\n",
      "    sample_time_ms: 18521.695\n",
      "    update_time_ms: 5.307\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.3817612698006\n",
      "  time_since_restore: 16518.377123355865\n",
      "  time_this_iter_s: 22.119447231292725\n",
      "  time_total_s: 16518.377123355865\n",
      "  timestamp: 1553725554\n",
      "  timesteps_since_restore: 6430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6430000\n",
      "  training_iteration: 643\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16518 s, 643 iter, 6430000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-26-17\n",
      "  done: false\n",
      "  episode_len_mean: 129.97\n",
      "  episode_reward_max: 802.6705165802207\n",
      "  episode_reward_mean: 725.4478766612523\n",
      "  episode_reward_min: -25.26886386285068\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 47641\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3731.5\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 6440000\n",
      "    num_steps_trained: 6440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5092790722846985\n",
      "      kl: 0.024443387985229492\n",
      "      policy_loss: -0.0009825294837355614\n",
      "      total_loss: 33.229583740234375\n",
      "      vf_explained_var: 0.9977921843528748\n",
      "      vf_loss: 33.22920608520508\n",
      "    sample_time_ms: 18619.079\n",
      "    update_time_ms: 5.302\n",
      "  iterations_since_restore: 644\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.72393833062614\n",
      "  time_since_restore: 16541.225950717926\n",
      "  time_this_iter_s: 22.848827362060547\n",
      "  time_total_s: 16541.225950717926\n",
      "  timestamp: 1553725577\n",
      "  timesteps_since_restore: 6440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6440000\n",
      "  training_iteration: 644\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16541 s, 644 iter, 6440000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-26-39\n",
      "  done: false\n",
      "  episode_len_mean: 129.57\n",
      "  episode_reward_max: 802.6705165802207\n",
      "  episode_reward_mean: 703.8999320937804\n",
      "  episode_reward_min: -73.8868673216492\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 47718\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.377\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 6450000\n",
      "    num_steps_trained: 6450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6780639886856079\n",
      "      kl: 0.016906199976801872\n",
      "      policy_loss: -0.0025697301607578993\n",
      "      total_loss: 481.7545471191406\n",
      "      vf_explained_var: 0.9620636105537415\n",
      "      vf_loss: 481.7561950683594\n",
      "    sample_time_ms: 18643.861\n",
      "    update_time_ms: 5.446\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.9499660468902\n",
      "  time_since_restore: 16563.571123838425\n",
      "  time_this_iter_s: 22.345173120498657\n",
      "  time_total_s: 16563.571123838425\n",
      "  timestamp: 1553725599\n",
      "  timesteps_since_restore: 6450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6450000\n",
      "  training_iteration: 645\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16563 s, 645 iter, 6450000 ts, 704 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-27-02\n",
      "  done: false\n",
      "  episode_len_mean: 131.69\n",
      "  episode_reward_max: 795.3620641658451\n",
      "  episode_reward_mean: 698.9663618580817\n",
      "  episode_reward_min: -73.8868673216492\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 47795\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.044\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 6460000\n",
      "    num_steps_trained: 6460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6617510914802551\n",
      "      kl: 0.014987139031291008\n",
      "      policy_loss: -0.00447073532268405\n",
      "      total_loss: 307.6116638183594\n",
      "      vf_explained_var: 0.9740118384361267\n",
      "      vf_loss: 307.61529541015625\n",
      "    sample_time_ms: 18765.375\n",
      "    update_time_ms: 5.241\n",
      "  iterations_since_restore: 646\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.4831809290408\n",
      "  time_since_restore: 16586.224838018417\n",
      "  time_this_iter_s: 22.653714179992676\n",
      "  time_total_s: 16586.224838018417\n",
      "  timestamp: 1553725622\n",
      "  timesteps_since_restore: 6460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6460000\n",
      "  training_iteration: 646\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16586 s, 646 iter, 6460000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-27-25\n",
      "  done: false\n",
      "  episode_len_mean: 131.21\n",
      "  episode_reward_max: 783.9448155129834\n",
      "  episode_reward_mean: 719.0477964245662\n",
      "  episode_reward_min: -63.95862819109419\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 47873\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3744.376\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 6470000\n",
      "    num_steps_trained: 6470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5945451259613037\n",
      "      kl: 0.01338602788746357\n",
      "      policy_loss: -0.0019786772318184376\n",
      "      total_loss: 273.4291076660156\n",
      "      vf_explained_var: 0.9780130386352539\n",
      "      vf_loss: 273.4303283691406\n",
      "    sample_time_ms: 18769.996\n",
      "    update_time_ms: 5.256\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.5238982122831\n",
      "  time_since_restore: 16609.16925907135\n",
      "  time_this_iter_s: 22.94442105293274\n",
      "  time_total_s: 16609.16925907135\n",
      "  timestamp: 1553725645\n",
      "  timesteps_since_restore: 6470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6470000\n",
      "  training_iteration: 647\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16609 s, 647 iter, 6470000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-27-47\n",
      "  done: false\n",
      "  episode_len_mean: 129.83\n",
      "  episode_reward_max: 777.2962738479815\n",
      "  episode_reward_mean: 715.0991986813447\n",
      "  episode_reward_min: -63.95862819109419\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 47950\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3744.367\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 6480000\n",
      "    num_steps_trained: 6480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05584161728620529\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5568399429321289\n",
      "      kl: 0.04196539893746376\n",
      "      policy_loss: -0.006243858486413956\n",
      "      total_loss: 107.6694107055664\n",
      "      vf_explained_var: 0.9913314580917358\n",
      "      vf_loss: 107.67330169677734\n",
      "    sample_time_ms: 18800.999\n",
      "    update_time_ms: 5.203\n",
      "  iterations_since_restore: 648\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.54959934067244\n",
      "  time_since_restore: 16631.520228862762\n",
      "  time_this_iter_s: 22.350969791412354\n",
      "  time_total_s: 16631.520228862762\n",
      "  timestamp: 1553725667\n",
      "  timesteps_since_restore: 6480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6480000\n",
      "  training_iteration: 648\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16631 s, 648 iter, 6480000 ts, 715 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-28-10\n",
      "  done: false\n",
      "  episode_len_mean: 128.4\n",
      "  episode_reward_max: 774.7471491690231\n",
      "  episode_reward_mean: 720.2276533496056\n",
      "  episode_reward_min: 130.02651057432632\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 48028\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.775\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 6490000\n",
      "    num_steps_trained: 6490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08376242220401764\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48630571365356445\n",
      "      kl: 0.02634219266474247\n",
      "      policy_loss: -0.0030615723226219416\n",
      "      total_loss: 138.26976013183594\n",
      "      vf_explained_var: 0.9889239072799683\n",
      "      vf_loss: 138.27061462402344\n",
      "    sample_time_ms: 18794.289\n",
      "    update_time_ms: 5.126\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.11382667480285\n",
      "  time_since_restore: 16654.14968752861\n",
      "  time_this_iter_s: 22.62945866584778\n",
      "  time_total_s: 16654.14968752861\n",
      "  timestamp: 1553725690\n",
      "  timesteps_since_restore: 6490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6490000\n",
      "  training_iteration: 649\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16654 s, 649 iter, 6490000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-28-32\n",
      "  done: false\n",
      "  episode_len_mean: 128.01\n",
      "  episode_reward_max: 785.070992404982\n",
      "  episode_reward_mean: 690.74410232683\n",
      "  episode_reward_min: -111.36316685434171\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 48108\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.287\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 6500000\n",
      "    num_steps_trained: 6500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08376242220401764\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6452398300170898\n",
      "      kl: 0.011533799581229687\n",
      "      policy_loss: -0.004248660523444414\n",
      "      total_loss: 573.5830078125\n",
      "      vf_explained_var: 0.9548068046569824\n",
      "      vf_loss: 573.5863647460938\n",
      "    sample_time_ms: 18817.94\n",
      "    update_time_ms: 5.046\n",
      "  iterations_since_restore: 650\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.372051163415\n",
      "  time_since_restore: 16676.555000782013\n",
      "  time_this_iter_s: 22.40531325340271\n",
      "  time_total_s: 16676.555000782013\n",
      "  timestamp: 1553725712\n",
      "  timesteps_since_restore: 6500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6500000\n",
      "  training_iteration: 650\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16676 s, 650 iter, 6500000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-28-55\n",
      "  done: false\n",
      "  episode_len_mean: 129.19\n",
      "  episode_reward_max: 783.8887724562518\n",
      "  episode_reward_mean: 676.9087272124787\n",
      "  episode_reward_min: -68.9057882500226\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 48185\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.054\n",
      "    load_time_ms: 1.721\n",
      "    num_steps_sampled: 6510000\n",
      "    num_steps_trained: 6510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08376242220401764\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7169651985168457\n",
      "      kl: 0.014096579514443874\n",
      "      policy_loss: -0.0064309206791222095\n",
      "      total_loss: 537.665771484375\n",
      "      vf_explained_var: 0.959131121635437\n",
      "      vf_loss: 537.6710815429688\n",
      "    sample_time_ms: 18820.922\n",
      "    update_time_ms: 5.127\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.4543636062393\n",
      "  time_since_restore: 16699.572422504425\n",
      "  time_this_iter_s: 23.01742172241211\n",
      "  time_total_s: 16699.572422504425\n",
      "  timestamp: 1553725735\n",
      "  timesteps_since_restore: 6510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6510000\n",
      "  training_iteration: 651\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16699 s, 651 iter, 6510000 ts, 677 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-29-17\n",
      "  done: false\n",
      "  episode_len_mean: 128.05\n",
      "  episode_reward_max: 787.8800311340865\n",
      "  episode_reward_mean: 719.7491706385117\n",
      "  episode_reward_min: -45.94066200799048\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 48263\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.061\n",
      "    load_time_ms: 1.716\n",
      "    num_steps_sampled: 6520000\n",
      "    num_steps_trained: 6520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08376242220401764\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5207812190055847\n",
      "      kl: 0.014662032015621662\n",
      "      policy_loss: -0.0013269197661429644\n",
      "      total_loss: 50.85823059082031\n",
      "      vf_explained_var: 0.9956294298171997\n",
      "      vf_loss: 50.85832595825195\n",
      "    sample_time_ms: 18730.705\n",
      "    update_time_ms: 5.142\n",
      "  iterations_since_restore: 652\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.87458531925586\n",
      "  time_since_restore: 16721.43777656555\n",
      "  time_this_iter_s: 21.86535406112671\n",
      "  time_total_s: 16721.43777656555\n",
      "  timestamp: 1553725757\n",
      "  timesteps_since_restore: 6520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6520000\n",
      "  training_iteration: 652\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16721 s, 652 iter, 6520000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-29-40\n",
      "  done: false\n",
      "  episode_len_mean: 129.67\n",
      "  episode_reward_max: 787.8800311340865\n",
      "  episode_reward_mean: 719.9707245268132\n",
      "  episode_reward_min: -28.829338715732774\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 48340\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.976\n",
      "    load_time_ms: 1.711\n",
      "    num_steps_sampled: 6530000\n",
      "    num_steps_trained: 6530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.08376242220401764\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6938455104827881\n",
      "      kl: 0.008497918955981731\n",
      "      policy_loss: -0.002015205565840006\n",
      "      total_loss: 276.9607238769531\n",
      "      vf_explained_var: 0.9769986271858215\n",
      "      vf_loss: 276.9620056152344\n",
      "    sample_time_ms: 18770.302\n",
      "    update_time_ms: 5.046\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.9853622634066\n",
      "  time_since_restore: 16743.942220687866\n",
      "  time_this_iter_s: 22.504444122314453\n",
      "  time_total_s: 16743.942220687866\n",
      "  timestamp: 1553725780\n",
      "  timesteps_since_restore: 6530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6530000\n",
      "  training_iteration: 653\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16743 s, 653 iter, 6530000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-30-03\n",
      "  done: false\n",
      "  episode_len_mean: 130.86\n",
      "  episode_reward_max: 788.7627097893527\n",
      "  episode_reward_mean: 688.2995519860368\n",
      "  episode_reward_min: -63.70399964188559\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 48417\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3765.95\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 6540000\n",
      "    num_steps_trained: 6540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04188121110200882\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7333536148071289\n",
      "      kl: 0.016872478649020195\n",
      "      policy_loss: -0.002638828009366989\n",
      "      total_loss: 411.1836853027344\n",
      "      vf_explained_var: 0.9655885100364685\n",
      "      vf_loss: 411.18560791015625\n",
      "    sample_time_ms: 18745.128\n",
      "    update_time_ms: 4.958\n",
      "  iterations_since_restore: 654\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.1497759930184\n",
      "  time_since_restore: 16766.57629585266\n",
      "  time_this_iter_s: 22.634075164794922\n",
      "  time_total_s: 16766.57629585266\n",
      "  timestamp: 1553725803\n",
      "  timesteps_since_restore: 6540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6540000\n",
      "  training_iteration: 654\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16766 s, 654 iter, 6540000 ts, 688 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-30-25\n",
      "  done: false\n",
      "  episode_len_mean: 132.1\n",
      "  episode_reward_max: 789.89355019259\n",
      "  episode_reward_mean: 713.1166252726694\n",
      "  episode_reward_min: -60.0152045096259\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 48493\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3782.908\n",
      "    load_time_ms: 1.703\n",
      "    num_steps_sampled: 6550000\n",
      "    num_steps_trained: 6550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04188121110200882\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7088059782981873\n",
      "      kl: 0.016527194529771805\n",
      "      policy_loss: -0.0013572883326560259\n",
      "      total_loss: 108.83148956298828\n",
      "      vf_explained_var: 0.9915208220481873\n",
      "      vf_loss: 108.8321533203125\n",
      "    sample_time_ms: 18740.092\n",
      "    update_time_ms: 4.827\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.5583126363346\n",
      "  time_since_restore: 16789.041977882385\n",
      "  time_this_iter_s: 22.46568202972412\n",
      "  time_total_s: 16789.041977882385\n",
      "  timestamp: 1553725825\n",
      "  timesteps_since_restore: 6550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6550000\n",
      "  training_iteration: 655\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16789 s, 655 iter, 6550000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-30-47\n",
      "  done: false\n",
      "  episode_len_mean: 134.94\n",
      "  episode_reward_max: 791.6104780516648\n",
      "  episode_reward_mean: 714.3290915031857\n",
      "  episode_reward_min: -49.620521777137384\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 48568\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3780.402\n",
      "    load_time_ms: 1.699\n",
      "    num_steps_sampled: 6560000\n",
      "    num_steps_trained: 6560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04188121110200882\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7722256779670715\n",
      "      kl: 0.027478862553834915\n",
      "      policy_loss: -0.0019470155239105225\n",
      "      total_loss: 166.06678771972656\n",
      "      vf_explained_var: 0.9876450896263123\n",
      "      vf_loss: 166.0675811767578\n",
      "    sample_time_ms: 18662.355\n",
      "    update_time_ms: 4.923\n",
      "  iterations_since_restore: 656\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.164545751593\n",
      "  time_since_restore: 16810.893550157547\n",
      "  time_this_iter_s: 21.851572275161743\n",
      "  time_total_s: 16810.893550157547\n",
      "  timestamp: 1553725847\n",
      "  timesteps_since_restore: 6560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6560000\n",
      "  training_iteration: 656\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16810 s, 656 iter, 6560000 ts, 714 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-31-09\n",
      "  done: false\n",
      "  episode_len_mean: 130.18\n",
      "  episode_reward_max: 790.1580158188951\n",
      "  episode_reward_mean: 707.6208023832202\n",
      "  episode_reward_min: -127.47597312145444\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 48647\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.611\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 6570000\n",
      "    num_steps_trained: 6570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04188121110200882\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.550291895866394\n",
      "      kl: 0.01697954162955284\n",
      "      policy_loss: -0.0003200794162694365\n",
      "      total_loss: 246.0050811767578\n",
      "      vf_explained_var: 0.980218768119812\n",
      "      vf_loss: 246.0046844482422\n",
      "    sample_time_ms: 18605.584\n",
      "    update_time_ms: 4.872\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.8104011916101\n",
      "  time_since_restore: 16833.065071582794\n",
      "  time_this_iter_s: 22.171521425247192\n",
      "  time_total_s: 16833.065071582794\n",
      "  timestamp: 1553725869\n",
      "  timesteps_since_restore: 6570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6570000\n",
      "  training_iteration: 657\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16833 s, 657 iter, 6570000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-31-31\n",
      "  done: false\n",
      "  episode_len_mean: 128.44\n",
      "  episode_reward_max: 791.0301703418357\n",
      "  episode_reward_mean: 718.6309854992469\n",
      "  episode_reward_min: 149.28525511405144\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 48726\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.312\n",
      "    load_time_ms: 1.643\n",
      "    num_steps_sampled: 6580000\n",
      "    num_steps_trained: 6580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04188121110200882\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.574019193649292\n",
      "      kl: 0.043318238109350204\n",
      "      policy_loss: -0.0006016363040544093\n",
      "      total_loss: 41.88199234008789\n",
      "      vf_explained_var: 0.9965701699256897\n",
      "      vf_loss: 41.88077926635742\n",
      "    sample_time_ms: 18559.069\n",
      "    update_time_ms: 4.976\n",
      "  iterations_since_restore: 658\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.3154927496235\n",
      "  time_since_restore: 16854.95063972473\n",
      "  time_this_iter_s: 21.885568141937256\n",
      "  time_total_s: 16854.95063972473\n",
      "  timestamp: 1553725891\n",
      "  timesteps_since_restore: 6580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6580000\n",
      "  training_iteration: 658\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16854 s, 658 iter, 6580000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-31-53\n",
      "  done: false\n",
      "  episode_len_mean: 128.8\n",
      "  episode_reward_max: 774.1733338405527\n",
      "  episode_reward_mean: 715.0370148272128\n",
      "  episode_reward_min: -80.60150249975807\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 48803\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.04\n",
      "    load_time_ms: 1.581\n",
      "    num_steps_sampled: 6590000\n",
      "    num_steps_trained: 6590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06282181292772293\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6628485321998596\n",
      "      kl: 0.011172580532729626\n",
      "      policy_loss: -0.001490508089773357\n",
      "      total_loss: 142.76690673828125\n",
      "      vf_explained_var: 0.989030122756958\n",
      "      vf_loss: 142.76768493652344\n",
      "    sample_time_ms: 18492.84\n",
      "    update_time_ms: 5.187\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.5185074136064\n",
      "  time_since_restore: 16876.914486408234\n",
      "  time_this_iter_s: 21.963846683502197\n",
      "  time_total_s: 16876.914486408234\n",
      "  timestamp: 1553725913\n",
      "  timesteps_since_restore: 6590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6590000\n",
      "  training_iteration: 659\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16876 s, 659 iter, 6590000 ts, 715 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-32-16\n",
      "  done: false\n",
      "  episode_len_mean: 131.89\n",
      "  episode_reward_max: 791.9093190658343\n",
      "  episode_reward_mean: 712.1762330832648\n",
      "  episode_reward_min: -80.60150249975807\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 48880\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3757.306\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 6600000\n",
      "    num_steps_trained: 6600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06282181292772293\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7075968980789185\n",
      "      kl: 0.02690179832279682\n",
      "      policy_loss: -0.004555739928036928\n",
      "      total_loss: 98.0064468383789\n",
      "      vf_explained_var: 0.9920980930328369\n",
      "      vf_loss: 98.00931549072266\n",
      "    sample_time_ms: 18494.308\n",
      "    update_time_ms: 5.178\n",
      "  iterations_since_restore: 660\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.0881165416324\n",
      "  time_since_restore: 16899.315962553024\n",
      "  time_this_iter_s: 22.40147614479065\n",
      "  time_total_s: 16899.315962553024\n",
      "  timestamp: 1553725936\n",
      "  timesteps_since_restore: 6600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6600000\n",
      "  training_iteration: 660\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16899 s, 660 iter, 6600000 ts, 712 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-32-37\n",
      "  done: false\n",
      "  episode_len_mean: 129.05\n",
      "  episode_reward_max: 788.8071944808\n",
      "  episode_reward_mean: 729.7603783372927\n",
      "  episode_reward_min: -64.81226377390789\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 48958\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3741.889\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 6610000\n",
      "    num_steps_trained: 6610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06282181292772293\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.51678067445755\n",
      "      kl: 0.00983416847884655\n",
      "      policy_loss: -0.0008840316440910101\n",
      "      total_loss: 146.87367248535156\n",
      "      vf_explained_var: 0.9897449016571045\n",
      "      vf_loss: 146.8739471435547\n",
      "    sample_time_ms: 18400.347\n",
      "    update_time_ms: 5.043\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.88018916864644\n",
      "  time_since_restore: 16921.235111951828\n",
      "  time_this_iter_s: 21.91914939880371\n",
      "  time_total_s: 16921.235111951828\n",
      "  timestamp: 1553725957\n",
      "  timesteps_since_restore: 6610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6610000\n",
      "  training_iteration: 661\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16921 s, 661 iter, 6610000 ts, 730 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-32-59\n",
      "  done: false\n",
      "  episode_len_mean: 125.08\n",
      "  episode_reward_max: 791.6058785957846\n",
      "  episode_reward_mean: 694.8484705387937\n",
      "  episode_reward_min: -127.04157512226705\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 49037\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3741.512\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 6620000\n",
      "    num_steps_trained: 6620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.031410906463861465\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6203396320343018\n",
      "      kl: 0.026637490838766098\n",
      "      policy_loss: -0.005494972690939903\n",
      "      total_loss: 461.7286682128906\n",
      "      vf_explained_var: 0.9653502106666565\n",
      "      vf_loss: 461.73333740234375\n",
      "    sample_time_ms: 18391.183\n",
      "    update_time_ms: 5.01\n",
      "  iterations_since_restore: 662\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.4242352693969\n",
      "  time_since_restore: 16943.004266262054\n",
      "  time_this_iter_s: 21.76915431022644\n",
      "  time_total_s: 16943.004266262054\n",
      "  timestamp: 1553725979\n",
      "  timesteps_since_restore: 6620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6620000\n",
      "  training_iteration: 662\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16943 s, 662 iter, 6620000 ts, 695 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-33-22\n",
      "  done: false\n",
      "  episode_len_mean: 126.75\n",
      "  episode_reward_max: 791.6058785957846\n",
      "  episode_reward_mean: 706.6557779414028\n",
      "  episode_reward_min: -88.62334447520493\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 49117\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3744.228\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 6630000\n",
      "    num_steps_trained: 6630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.031410906463861465\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5418556332588196\n",
      "      kl: 0.01699484884738922\n",
      "      policy_loss: -0.004695577546954155\n",
      "      total_loss: 238.584716796875\n",
      "      vf_explained_var: 0.9819703698158264\n",
      "      vf_loss: 238.58889770507812\n",
      "    sample_time_ms: 18367.199\n",
      "    update_time_ms: 4.967\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.32788897070145\n",
      "  time_since_restore: 16965.29639816284\n",
      "  time_this_iter_s: 22.292131900787354\n",
      "  time_total_s: 16965.29639816284\n",
      "  timestamp: 1553726002\n",
      "  timesteps_since_restore: 6630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6630000\n",
      "  training_iteration: 663\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16965 s, 663 iter, 6630000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-33-44\n",
      "  done: false\n",
      "  episode_len_mean: 128.45\n",
      "  episode_reward_max: 789.7017747990554\n",
      "  episode_reward_mean: 718.1497862022654\n",
      "  episode_reward_min: -88.62334447520493\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 49194\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.089\n",
      "    load_time_ms: 1.429\n",
      "    num_steps_sampled: 6640000\n",
      "    num_steps_trained: 6640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.031410906463861465\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5630953907966614\n",
      "      kl: 0.06377259641885757\n",
      "      policy_loss: 0.002764807315543294\n",
      "      total_loss: 23.7728214263916\n",
      "      vf_explained_var: 0.9979208707809448\n",
      "      vf_loss: 23.768051147460938\n",
      "    sample_time_ms: 18347.602\n",
      "    update_time_ms: 4.933\n",
      "  iterations_since_restore: 664\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.0748931011327\n",
      "  time_since_restore: 16987.684928178787\n",
      "  time_this_iter_s: 22.388530015945435\n",
      "  time_total_s: 16987.684928178787\n",
      "  timestamp: 1553726024\n",
      "  timesteps_since_restore: 6640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6640000\n",
      "  training_iteration: 664\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 16987 s, 664 iter, 6640000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-34-07\n",
      "  done: false\n",
      "  episode_len_mean: 129.88\n",
      "  episode_reward_max: 793.3175622626162\n",
      "  episode_reward_mean: 723.2351999737846\n",
      "  episode_reward_min: -61.594867229043274\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 49272\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.915\n",
      "    load_time_ms: 1.386\n",
      "    num_steps_sampled: 6650000\n",
      "    num_steps_trained: 6650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6749183535575867\n",
      "      kl: 0.013600616715848446\n",
      "      policy_loss: 0.000535894650965929\n",
      "      total_loss: 203.0500030517578\n",
      "      vf_explained_var: 0.9823072552680969\n",
      "      vf_loss: 203.048828125\n",
      "    sample_time_ms: 18378.719\n",
      "    update_time_ms: 4.912\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.6175999868923\n",
      "  time_since_restore: 17010.28435111046\n",
      "  time_this_iter_s: 22.599422931671143\n",
      "  time_total_s: 17010.28435111046\n",
      "  timestamp: 1553726047\n",
      "  timesteps_since_restore: 6650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6650000\n",
      "  training_iteration: 665\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17010 s, 665 iter, 6650000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-34-29\n",
      "  done: false\n",
      "  episode_len_mean: 129.33\n",
      "  episode_reward_max: 793.3175622626162\n",
      "  episode_reward_mean: 698.8729405302558\n",
      "  episode_reward_min: -81.23677320113168\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 49350\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.17\n",
      "    load_time_ms: 1.388\n",
      "    num_steps_sampled: 6660000\n",
      "    num_steps_trained: 6660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7692645192146301\n",
      "      kl: 0.019112300127744675\n",
      "      policy_loss: -0.00373574486002326\n",
      "      total_loss: 589.1686401367188\n",
      "      vf_explained_var: 0.9546894431114197\n",
      "      vf_loss: 589.1714477539062\n",
      "    sample_time_ms: 18445.841\n",
      "    update_time_ms: 4.852\n",
      "  iterations_since_restore: 666\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.43647026512787\n",
      "  time_since_restore: 17032.819857358932\n",
      "  time_this_iter_s: 22.53550624847412\n",
      "  time_total_s: 17032.819857358932\n",
      "  timestamp: 1553726069\n",
      "  timesteps_since_restore: 6660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6660000\n",
      "  training_iteration: 666\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17032 s, 666 iter, 6660000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-34-52\n",
      "  done: false\n",
      "  episode_len_mean: 130.01\n",
      "  episode_reward_max: 790.8031820484405\n",
      "  episode_reward_mean: 704.5469225591177\n",
      "  episode_reward_min: -81.23677320113168\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 49427\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.043\n",
      "    load_time_ms: 1.368\n",
      "    num_steps_sampled: 6670000\n",
      "    num_steps_trained: 6670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7251774668693542\n",
      "      kl: 0.01192331500351429\n",
      "      policy_loss: -0.0029585869051516056\n",
      "      total_loss: 236.88246154785156\n",
      "      vf_explained_var: 0.9854687452316284\n",
      "      vf_loss: 236.88487243652344\n",
      "    sample_time_ms: 18478.283\n",
      "    update_time_ms: 5.143\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.2734612795589\n",
      "  time_since_restore: 17055.265477657318\n",
      "  time_this_iter_s: 22.44562029838562\n",
      "  time_total_s: 17055.265477657318\n",
      "  timestamp: 1553726092\n",
      "  timesteps_since_restore: 6670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6670000\n",
      "  training_iteration: 667\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17055 s, 667 iter, 6670000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-35-14\n",
      "  done: false\n",
      "  episode_len_mean: 130.18\n",
      "  episode_reward_max: 793.1194598348316\n",
      "  episode_reward_mean: 724.8390547866393\n",
      "  episode_reward_min: 17.353873032070368\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 49504\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.507\n",
      "    load_time_ms: 1.353\n",
      "    num_steps_sampled: 6680000\n",
      "    num_steps_trained: 6680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6651033163070679\n",
      "      kl: 0.011519037187099457\n",
      "      policy_loss: -0.003061736235395074\n",
      "      total_loss: 170.9976806640625\n",
      "      vf_explained_var: 0.9867444038391113\n",
      "      vf_loss: 171.00021362304688\n",
      "    sample_time_ms: 18554.22\n",
      "    update_time_ms: 5.183\n",
      "  iterations_since_restore: 668\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.41952739331964\n",
      "  time_since_restore: 17077.87474155426\n",
      "  time_this_iter_s: 22.60926389694214\n",
      "  time_total_s: 17077.87474155426\n",
      "  timestamp: 1553726114\n",
      "  timesteps_since_restore: 6680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6680000\n",
      "  training_iteration: 668\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17077 s, 668 iter, 6680000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-35-37\n",
      "  done: false\n",
      "  episode_len_mean: 127.57\n",
      "  episode_reward_max: 793.1194598348316\n",
      "  episode_reward_mean: 683.6474811683873\n",
      "  episode_reward_min: -112.75822585802932\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 49584\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.544\n",
      "    load_time_ms: 1.356\n",
      "    num_steps_sampled: 6690000\n",
      "    num_steps_trained: 6690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7234835624694824\n",
      "      kl: 0.013814421370625496\n",
      "      policy_loss: -0.004570284392684698\n",
      "      total_loss: 536.1859741210938\n",
      "      vf_explained_var: 0.9605995416641235\n",
      "      vf_loss: 536.18994140625\n",
      "    sample_time_ms: 18626.04\n",
      "    update_time_ms: 5.034\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.82374058419356\n",
      "  time_since_restore: 17100.545952558517\n",
      "  time_this_iter_s: 22.671211004257202\n",
      "  time_total_s: 17100.545952558517\n",
      "  timestamp: 1553726137\n",
      "  timesteps_since_restore: 6690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6690000\n",
      "  training_iteration: 669\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17100 s, 669 iter, 6690000 ts, 684 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-36-00\n",
      "  done: false\n",
      "  episode_len_mean: 127.05\n",
      "  episode_reward_max: 779.2437037054834\n",
      "  episode_reward_mean: 694.015983932541\n",
      "  episode_reward_min: -115.37092711268104\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 49662\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.587\n",
      "    load_time_ms: 1.329\n",
      "    num_steps_sampled: 6700000\n",
      "    num_steps_trained: 6700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6213868856430054\n",
      "      kl: 0.01850222237408161\n",
      "      policy_loss: -0.0034461633767932653\n",
      "      total_loss: 419.8622131347656\n",
      "      vf_explained_var: 0.9684114456176758\n",
      "      vf_loss: 419.86480712890625\n",
      "    sample_time_ms: 18625.48\n",
      "    update_time_ms: 5.066\n",
      "  iterations_since_restore: 670\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.00799196627037\n",
      "  time_since_restore: 17122.93448972702\n",
      "  time_this_iter_s: 22.388537168502808\n",
      "  time_total_s: 17122.93448972702\n",
      "  timestamp: 1553726160\n",
      "  timesteps_since_restore: 6700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6700000\n",
      "  training_iteration: 670\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17122 s, 670 iter, 6700000 ts, 694 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-36-22\n",
      "  done: false\n",
      "  episode_len_mean: 129.48\n",
      "  episode_reward_max: 786.7598388336224\n",
      "  episode_reward_mean: 718.3532840234657\n",
      "  episode_reward_min: -58.48999569502166\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 49739\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.065\n",
      "    load_time_ms: 1.35\n",
      "    num_steps_sampled: 6710000\n",
      "    num_steps_trained: 6710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6690681576728821\n",
      "      kl: 0.0379757285118103\n",
      "      policy_loss: -0.0004298457643017173\n",
      "      total_loss: 226.9357452392578\n",
      "      vf_explained_var: 0.981141209602356\n",
      "      vf_loss: 226.9344024658203\n",
      "    sample_time_ms: 18667.721\n",
      "    update_time_ms: 5.101\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.1766420117328\n",
      "  time_since_restore: 17145.23363184929\n",
      "  time_this_iter_s: 22.299142122268677\n",
      "  time_total_s: 17145.23363184929\n",
      "  timestamp: 1553726182\n",
      "  timesteps_since_restore: 6710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6710000\n",
      "  training_iteration: 671\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17145 s, 671 iter, 6710000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-36-44\n",
      "  done: false\n",
      "  episode_len_mean: 126.34\n",
      "  episode_reward_max: 786.7598388336224\n",
      "  episode_reward_mean: 718.3095328394087\n",
      "  episode_reward_min: -100.42516577794643\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 49820\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.825\n",
      "    load_time_ms: 1.369\n",
      "    num_steps_sampled: 6720000\n",
      "    num_steps_trained: 6720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.45516684651374817\n",
      "      kl: 0.012470066547393799\n",
      "      policy_loss: -0.00020771875279024243\n",
      "      total_loss: 142.53282165527344\n",
      "      vf_explained_var: 0.9878059029579163\n",
      "      vf_loss: 142.53245544433594\n",
      "    sample_time_ms: 18707.092\n",
      "    update_time_ms: 5.39\n",
      "  iterations_since_restore: 672\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.15476641970423\n",
      "  time_since_restore: 17167.37815618515\n",
      "  time_this_iter_s: 22.144524335861206\n",
      "  time_total_s: 17167.37815618515\n",
      "  timestamp: 1553726204\n",
      "  timesteps_since_restore: 6720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6720000\n",
      "  training_iteration: 672\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17167 s, 672 iter, 6720000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-37-07\n",
      "  done: false\n",
      "  episode_len_mean: 127.08\n",
      "  episode_reward_max: 795.3912591947337\n",
      "  episode_reward_mean: 719.3211600452062\n",
      "  episode_reward_min: -95.47034088132241\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 49899\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.274\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 6730000\n",
      "    num_steps_trained: 6730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.577620804309845\n",
      "      kl: 0.014778060838580132\n",
      "      policy_loss: -0.0017061593243852258\n",
      "      total_loss: 212.2079315185547\n",
      "      vf_explained_var: 0.9812883138656616\n",
      "      vf_loss: 212.2089385986328\n",
      "    sample_time_ms: 18740.742\n",
      "    update_time_ms: 5.448\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.6605800226031\n",
      "  time_since_restore: 17189.954213142395\n",
      "  time_this_iter_s: 22.576056957244873\n",
      "  time_total_s: 17189.954213142395\n",
      "  timestamp: 1553726227\n",
      "  timesteps_since_restore: 6730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6730000\n",
      "  training_iteration: 673\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17189 s, 673 iter, 6730000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-37-30\n",
      "  done: false\n",
      "  episode_len_mean: 126.49\n",
      "  episode_reward_max: 795.3912591947337\n",
      "  episode_reward_mean: 691.4586773382384\n",
      "  episode_reward_min: -82.74719394159665\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 49977\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.976\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 6740000\n",
      "    num_steps_trained: 6740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.722519040107727\n",
      "      kl: 0.014392663724720478\n",
      "      policy_loss: 0.0005801627412438393\n",
      "      total_loss: 603.0436401367188\n",
      "      vf_explained_var: 0.9518976211547852\n",
      "      vf_loss: 603.04248046875\n",
      "    sample_time_ms: 18788.567\n",
      "    update_time_ms: 5.481\n",
      "  iterations_since_restore: 674\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.72933866911916\n",
      "  time_since_restore: 17212.82016849518\n",
      "  time_this_iter_s: 22.865955352783203\n",
      "  time_total_s: 17212.82016849518\n",
      "  timestamp: 1553726250\n",
      "  timesteps_since_restore: 6740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6740000\n",
      "  training_iteration: 674\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17212 s, 674 iter, 6740000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-37-52\n",
      "  done: false\n",
      "  episode_len_mean: 126.08\n",
      "  episode_reward_max: 801.1064166446355\n",
      "  episode_reward_mean: 677.3025946047416\n",
      "  episode_reward_min: -122.8006106134616\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 50058\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.79\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 6750000\n",
      "    num_steps_trained: 6750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6626707315444946\n",
      "      kl: 0.013358614407479763\n",
      "      policy_loss: -0.0011465310817584395\n",
      "      total_loss: 673.8327026367188\n",
      "      vf_explained_var: 0.9459017515182495\n",
      "      vf_loss: 673.833251953125\n",
      "    sample_time_ms: 18779.018\n",
      "    update_time_ms: 5.535\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.6512973023708\n",
      "  time_since_restore: 17235.2963411808\n",
      "  time_this_iter_s: 22.47617268562317\n",
      "  time_total_s: 17235.2963411808\n",
      "  timestamp: 1553726272\n",
      "  timesteps_since_restore: 6750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6750000\n",
      "  training_iteration: 675\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17235 s, 675 iter, 6750000 ts, 677 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-38-14\n",
      "  done: false\n",
      "  episode_len_mean: 128.26\n",
      "  episode_reward_max: 805.1812246777423\n",
      "  episode_reward_mean: 680.0971092807089\n",
      "  episode_reward_min: -108.38579480315737\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 50134\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.445\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 6760000\n",
      "    num_steps_trained: 6760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7220209836959839\n",
      "      kl: 0.013834474608302116\n",
      "      policy_loss: -0.002833994571119547\n",
      "      total_loss: 294.8487548828125\n",
      "      vf_explained_var: 0.9784234762191772\n",
      "      vf_loss: 294.8509216308594\n",
      "    sample_time_ms: 18735.403\n",
      "    update_time_ms: 5.587\n",
      "  iterations_since_restore: 676\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.04855464035444\n",
      "  time_since_restore: 17257.391492843628\n",
      "  time_this_iter_s: 22.095151662826538\n",
      "  time_total_s: 17257.391492843628\n",
      "  timestamp: 1553726294\n",
      "  timesteps_since_restore: 6760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6760000\n",
      "  training_iteration: 676\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17257 s, 676 iter, 6760000 ts, 680 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-38-37\n",
      "  done: false\n",
      "  episode_len_mean: 129.33\n",
      "  episode_reward_max: 805.1812246777423\n",
      "  episode_reward_mean: 712.4495509184395\n",
      "  episode_reward_min: -106.03390049632648\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 50213\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.931\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 6770000\n",
      "    num_steps_trained: 6770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.592819333076477\n",
      "      kl: 0.025553831830620766\n",
      "      policy_loss: -0.003983064088970423\n",
      "      total_loss: 100.55188751220703\n",
      "      vf_explained_var: 0.992567777633667\n",
      "      vf_loss: 100.55467224121094\n",
      "    sample_time_ms: 18742.193\n",
      "    update_time_ms: 5.316\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.2247754592198\n",
      "  time_since_restore: 17279.94904947281\n",
      "  time_this_iter_s: 22.557556629180908\n",
      "  time_total_s: 17279.94904947281\n",
      "  timestamp: 1553726317\n",
      "  timesteps_since_restore: 6770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6770000\n",
      "  training_iteration: 677\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17279 s, 677 iter, 6770000 ts, 712 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-38-59\n",
      "  done: false\n",
      "  episode_len_mean: 129.46\n",
      "  episode_reward_max: 790.3137394911349\n",
      "  episode_reward_mean: 709.6869553822685\n",
      "  episode_reward_min: -46.75517846109244\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 50290\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.503\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 6780000\n",
      "    num_steps_trained: 6780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.743604302406311\n",
      "      kl: 0.0114107271656394\n",
      "      policy_loss: -0.0016248577740043402\n",
      "      total_loss: 296.0724182128906\n",
      "      vf_explained_var: 0.9776967167854309\n",
      "      vf_loss: 296.0735168457031\n",
      "    sample_time_ms: 18718.41\n",
      "    update_time_ms: 5.297\n",
      "  iterations_since_restore: 678\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.8434776911342\n",
      "  time_since_restore: 17302.36590242386\n",
      "  time_this_iter_s: 22.416852951049805\n",
      "  time_total_s: 17302.36590242386\n",
      "  timestamp: 1553726339\n",
      "  timesteps_since_restore: 6780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6780000\n",
      "  training_iteration: 678\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17302 s, 678 iter, 6780000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-39-22\n",
      "  done: false\n",
      "  episode_len_mean: 128.36\n",
      "  episode_reward_max: 793.6268939242261\n",
      "  episode_reward_mean: 709.6892747580234\n",
      "  episode_reward_min: -46.75517846109244\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 50368\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.907\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 6790000\n",
      "    num_steps_trained: 6790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5406428575515747\n",
      "      kl: 0.02112552523612976\n",
      "      policy_loss: -0.005697677377611399\n",
      "      total_loss: 197.9786376953125\n",
      "      vf_explained_var: 0.9833409190177917\n",
      "      vf_loss: 197.9833526611328\n",
      "    sample_time_ms: 18681.488\n",
      "    update_time_ms: 5.375\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.8446373790117\n",
      "  time_since_restore: 17324.714615106583\n",
      "  time_this_iter_s: 22.348712682724\n",
      "  time_total_s: 17324.714615106583\n",
      "  timestamp: 1553726362\n",
      "  timesteps_since_restore: 6790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6790000\n",
      "  training_iteration: 679\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17324 s, 679 iter, 6790000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-39-44\n",
      "  done: false\n",
      "  episode_len_mean: 127.58\n",
      "  episode_reward_max: 793.6268939242261\n",
      "  episode_reward_mean: 718.9414300391837\n",
      "  episode_reward_min: -44.007762249520226\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 50446\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.371\n",
      "    load_time_ms: 1.578\n",
      "    num_steps_sampled: 6800000\n",
      "    num_steps_trained: 6800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.569370687007904\n",
      "      kl: 0.018775882199406624\n",
      "      policy_loss: -0.0007129761506803334\n",
      "      total_loss: 148.6521453857422\n",
      "      vf_explained_var: 0.9880465269088745\n",
      "      vf_loss: 148.65196228027344\n",
      "    sample_time_ms: 18639.717\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 680\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.47071501959186\n",
      "  time_since_restore: 17346.698493480682\n",
      "  time_this_iter_s: 21.98387837409973\n",
      "  time_total_s: 17346.698493480682\n",
      "  timestamp: 1553726384\n",
      "  timesteps_since_restore: 6800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6800000\n",
      "  training_iteration: 680\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17346 s, 680 iter, 6800000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-40-06\n",
      "  done: false\n",
      "  episode_len_mean: 130.65\n",
      "  episode_reward_max: 787.0615608046264\n",
      "  episode_reward_mean: 729.9000024310924\n",
      "  episode_reward_min: -48.77045296922435\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 50524\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.889\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 6810000\n",
      "    num_steps_trained: 6810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5933862328529358\n",
      "      kl: 0.022201528772711754\n",
      "      policy_loss: -0.0013987773563712835\n",
      "      total_loss: 85.92222595214844\n",
      "      vf_explained_var: 0.9930745363235474\n",
      "      vf_loss: 85.92257690429688\n",
      "    sample_time_ms: 18606.822\n",
      "    update_time_ms: 5.544\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.95000121554614\n",
      "  time_since_restore: 17368.71254682541\n",
      "  time_this_iter_s: 22.014053344726562\n",
      "  time_total_s: 17368.71254682541\n",
      "  timestamp: 1553726406\n",
      "  timesteps_since_restore: 6810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6810000\n",
      "  training_iteration: 681\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17368 s, 681 iter, 6810000 ts, 730 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-40-29\n",
      "  done: false\n",
      "  episode_len_mean: 130.58\n",
      "  episode_reward_max: 791.5746676539068\n",
      "  episode_reward_mean: 704.1601992641412\n",
      "  episode_reward_min: -48.77045296922435\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 50600\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.326\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 6820000\n",
      "    num_steps_trained: 6820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7116148471832275\n",
      "      kl: 0.016279544681310654\n",
      "      policy_loss: -0.005269872024655342\n",
      "      total_loss: 358.11669921875\n",
      "      vf_explained_var: 0.9748079180717468\n",
      "      vf_loss: 358.1211853027344\n",
      "    sample_time_ms: 18683.735\n",
      "    update_time_ms: 5.336\n",
      "  iterations_since_restore: 682\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.08009963207064\n",
      "  time_since_restore: 17391.638021230698\n",
      "  time_this_iter_s: 22.925474405288696\n",
      "  time_total_s: 17391.638021230698\n",
      "  timestamp: 1553726429\n",
      "  timesteps_since_restore: 6820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6820000\n",
      "  training_iteration: 682\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17391 s, 682 iter, 6820000 ts, 704 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-40-52\n",
      "  done: false\n",
      "  episode_len_mean: 130.19\n",
      "  episode_reward_max: 797.8396950866986\n",
      "  episode_reward_mean: 707.75353358832\n",
      "  episode_reward_min: -64.65302882584271\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 50678\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.961\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 6830000\n",
      "    num_steps_trained: 6830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5545975565910339\n",
      "      kl: 0.014927179552614689\n",
      "      policy_loss: -0.0012923169415444136\n",
      "      total_loss: 258.0444641113281\n",
      "      vf_explained_var: 0.9778661727905273\n",
      "      vf_loss: 258.0450439453125\n",
      "    sample_time_ms: 18736.386\n",
      "    update_time_ms: 5.389\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.87676679416006\n",
      "  time_since_restore: 17414.785753250122\n",
      "  time_this_iter_s: 23.14773201942444\n",
      "  time_total_s: 17414.785753250122\n",
      "  timestamp: 1553726452\n",
      "  timesteps_since_restore: 6830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6830000\n",
      "  training_iteration: 683\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17414 s, 683 iter, 6830000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-41-15\n",
      "  done: false\n",
      "  episode_len_mean: 129.81\n",
      "  episode_reward_max: 799.9234321822778\n",
      "  episode_reward_mean: 721.491804743078\n",
      "  episode_reward_min: -81.06295990494115\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 50755\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.051\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 6840000\n",
      "    num_steps_trained: 6840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6606237292289734\n",
      "      kl: 0.027428077533841133\n",
      "      policy_loss: -0.0038979400414973497\n",
      "      total_loss: 187.4674530029297\n",
      "      vf_explained_var: 0.985603928565979\n",
      "      vf_loss: 187.4700469970703\n",
      "    sample_time_ms: 18719.35\n",
      "    update_time_ms: 5.447\n",
      "  iterations_since_restore: 684\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.745902371539\n",
      "  time_since_restore: 17437.482368946075\n",
      "  time_this_iter_s: 22.69661569595337\n",
      "  time_total_s: 17437.482368946075\n",
      "  timestamp: 1553726475\n",
      "  timesteps_since_restore: 6840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6840000\n",
      "  training_iteration: 684\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17437 s, 684 iter, 6840000 ts, 721 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-41-36\n",
      "  done: false\n",
      "  episode_len_mean: 129.72\n",
      "  episode_reward_max: 799.9234321822778\n",
      "  episode_reward_mean: 710.9696204434783\n",
      "  episode_reward_min: -31.3859226120793\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 50832\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.404\n",
      "    load_time_ms: 1.432\n",
      "    num_steps_sampled: 6850000\n",
      "    num_steps_trained: 6850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.047116365283727646\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6036778688430786\n",
      "      kl: 0.04857843369245529\n",
      "      policy_loss: 0.0012228343402966857\n",
      "      total_loss: 379.3045349121094\n",
      "      vf_explained_var: 0.9683348536491394\n",
      "      vf_loss: 379.301025390625\n",
      "    sample_time_ms: 18632.072\n",
      "    update_time_ms: 5.366\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.48481022173917\n",
      "  time_since_restore: 17459.086358308792\n",
      "  time_this_iter_s: 21.603989362716675\n",
      "  time_total_s: 17459.086358308792\n",
      "  timestamp: 1553726496\n",
      "  timesteps_since_restore: 6850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6850000\n",
      "  training_iteration: 685\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17459 s, 685 iter, 6850000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-41-59\n",
      "  done: false\n",
      "  episode_len_mean: 127.55\n",
      "  episode_reward_max: 797.920815066913\n",
      "  episode_reward_mean: 718.9594033758331\n",
      "  episode_reward_min: -62.170533114230864\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 50912\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.747\n",
      "    load_time_ms: 1.437\n",
      "    num_steps_sampled: 6860000\n",
      "    num_steps_trained: 6860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07067453861236572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5300058126449585\n",
      "      kl: 0.014154849573969841\n",
      "      policy_loss: -0.0030736953485757113\n",
      "      total_loss: 266.38568115234375\n",
      "      vf_explained_var: 0.9780107140541077\n",
      "      vf_loss: 266.38775634765625\n",
      "    sample_time_ms: 18638.006\n",
      "    update_time_ms: 5.392\n",
      "  iterations_since_restore: 686\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.4797016879166\n",
      "  time_since_restore: 17481.295653820038\n",
      "  time_this_iter_s: 22.209295511245728\n",
      "  time_total_s: 17481.295653820038\n",
      "  timestamp: 1553726519\n",
      "  timesteps_since_restore: 6860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6860000\n",
      "  training_iteration: 686\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17481 s, 686 iter, 6860000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-42-20\n",
      "  done: false\n",
      "  episode_len_mean: 129.19\n",
      "  episode_reward_max: 799.4438764322348\n",
      "  episode_reward_mean: 720.0085551922202\n",
      "  episode_reward_min: -57.76440321875256\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 50988\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.844\n",
      "    load_time_ms: 1.371\n",
      "    num_steps_sampled: 6870000\n",
      "    num_steps_trained: 6870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07067453861236572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.647183895111084\n",
      "      kl: 0.01154591329395771\n",
      "      policy_loss: -0.0027531094383448362\n",
      "      total_loss: 94.00343322753906\n",
      "      vf_explained_var: 0.9922590851783752\n",
      "      vf_loss: 94.00537109375\n",
      "    sample_time_ms: 18560.348\n",
      "    update_time_ms: 5.414\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.00427759611006\n",
      "  time_since_restore: 17503.04553580284\n",
      "  time_this_iter_s: 21.749881982803345\n",
      "  time_total_s: 17503.04553580284\n",
      "  timestamp: 1553726540\n",
      "  timesteps_since_restore: 6870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6870000\n",
      "  training_iteration: 687\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17503 s, 687 iter, 6870000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-42-43\n",
      "  done: false\n",
      "  episode_len_mean: 132.14\n",
      "  episode_reward_max: 799.4438764322348\n",
      "  episode_reward_mean: 733.0192123274475\n",
      "  episode_reward_min: 201.72832610478866\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 51065\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.07\n",
      "    load_time_ms: 1.371\n",
      "    num_steps_sampled: 6880000\n",
      "    num_steps_trained: 6880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.07067453861236572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6334137320518494\n",
      "      kl: 0.009075450710952282\n",
      "      policy_loss: -0.0008172406232915819\n",
      "      total_loss: 131.94113159179688\n",
      "      vf_explained_var: 0.9898098707199097\n",
      "      vf_loss: 131.9413299560547\n",
      "    sample_time_ms: 18553.089\n",
      "    update_time_ms: 5.425\n",
      "  iterations_since_restore: 688\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 366.5096061637237\n",
      "  time_since_restore: 17525.34997320175\n",
      "  time_this_iter_s: 22.304437398910522\n",
      "  time_total_s: 17525.34997320175\n",
      "  timestamp: 1553726563\n",
      "  timesteps_since_restore: 6880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6880000\n",
      "  training_iteration: 688\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17525 s, 688 iter, 6880000 ts, 733 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-43-04\n",
      "  done: false\n",
      "  episode_len_mean: 131.56\n",
      "  episode_reward_max: 786.2306819969302\n",
      "  episode_reward_mean: 725.8806619305278\n",
      "  episode_reward_min: 167.50504244918386\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 51141\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.953\n",
      "    load_time_ms: 1.369\n",
      "    num_steps_sampled: 6890000\n",
      "    num_steps_trained: 6890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03533726930618286\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.635116696357727\n",
      "      kl: 0.01740107126533985\n",
      "      policy_loss: -0.001458574552088976\n",
      "      total_loss: 146.2881317138672\n",
      "      vf_explained_var: 0.9880171418190002\n",
      "      vf_loss: 146.2889862060547\n",
      "    sample_time_ms: 18480.262\n",
      "    update_time_ms: 5.379\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.940330965264\n",
      "  time_since_restore: 17546.88912129402\n",
      "  time_this_iter_s: 21.539148092269897\n",
      "  time_total_s: 17546.88912129402\n",
      "  timestamp: 1553726584\n",
      "  timesteps_since_restore: 6890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6890000\n",
      "  training_iteration: 689\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17546 s, 689 iter, 6890000 ts, 726 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-43-26\n",
      "  done: false\n",
      "  episode_len_mean: 131.92\n",
      "  episode_reward_max: 793.5215533662903\n",
      "  episode_reward_mean: 709.8292891813745\n",
      "  episode_reward_min: -7.7127865077838464\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 51219\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.982\n",
      "    load_time_ms: 1.367\n",
      "    num_steps_sampled: 6900000\n",
      "    num_steps_trained: 6900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03533726930618286\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7302284240722656\n",
      "      kl: 0.5935670733451843\n",
      "      policy_loss: 0.004175965674221516\n",
      "      total_loss: 287.3832092285156\n",
      "      vf_explained_var: 0.9760707020759583\n",
      "      vf_loss: 287.3580627441406\n",
      "    sample_time_ms: 18473.795\n",
      "    update_time_ms: 5.238\n",
      "  iterations_since_restore: 690\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.91464459068726\n",
      "  time_since_restore: 17568.987475156784\n",
      "  time_this_iter_s: 22.09835386276245\n",
      "  time_total_s: 17568.987475156784\n",
      "  timestamp: 1553726606\n",
      "  timesteps_since_restore: 6900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6900000\n",
      "  training_iteration: 690\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17568 s, 690 iter, 6900000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 134.56\n",
      "  episode_reward_max: 798.7297719543004\n",
      "  episode_reward_mean: 697.517856329063\n",
      "  episode_reward_min: -20.761668327519573\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 51292\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.601\n",
      "    load_time_ms: 1.376\n",
      "    num_steps_sampled: 6910000\n",
      "    num_steps_trained: 6910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05300590395927429\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.02156400680542\n",
      "      kl: 0.005076123401522636\n",
      "      policy_loss: -0.0010935416212305427\n",
      "      total_loss: 555.5665283203125\n",
      "      vf_explained_var: 0.9613925218582153\n",
      "      vf_loss: 555.5673828125\n",
      "    sample_time_ms: 18493.722\n",
      "    update_time_ms: 5.138\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.75892816453154\n",
      "  time_since_restore: 17591.186794757843\n",
      "  time_this_iter_s: 22.19931960105896\n",
      "  time_total_s: 17591.186794757843\n",
      "  timestamp: 1553726629\n",
      "  timesteps_since_restore: 6910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6910000\n",
      "  training_iteration: 691\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17591 s, 691 iter, 6910000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-44-11\n",
      "  done: false\n",
      "  episode_len_mean: 132.55\n",
      "  episode_reward_max: 798.7297719543004\n",
      "  episode_reward_mean: 701.4141782015115\n",
      "  episode_reward_min: -70.214627497317\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 51371\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3728.748\n",
      "    load_time_ms: 1.394\n",
      "    num_steps_sampled: 6920000\n",
      "    num_steps_trained: 6920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.026502951979637146\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6502102613449097\n",
      "      kl: 0.012872417457401752\n",
      "      policy_loss: -0.0005705532385036349\n",
      "      total_loss: 215.48863220214844\n",
      "      vf_explained_var: 0.9827198386192322\n",
      "      vf_loss: 215.48883056640625\n",
      "    sample_time_ms: 18413.243\n",
      "    update_time_ms: 5.065\n",
      "  iterations_since_restore: 692\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.70708910075575\n",
      "  time_since_restore: 17613.300325393677\n",
      "  time_this_iter_s: 22.11353063583374\n",
      "  time_total_s: 17613.300325393677\n",
      "  timestamp: 1553726651\n",
      "  timesteps_since_restore: 6920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6920000\n",
      "  training_iteration: 692\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17613 s, 692 iter, 6920000 ts, 701 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-44-33\n",
      "  done: false\n",
      "  episode_len_mean: 130.07\n",
      "  episode_reward_max: 785.690207893896\n",
      "  episode_reward_mean: 715.28268091157\n",
      "  episode_reward_min: -70.214627497317\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 51448\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.599\n",
      "    load_time_ms: 1.384\n",
      "    num_steps_sampled: 6930000\n",
      "    num_steps_trained: 6930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.026502951979637146\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6202524900436401\n",
      "      kl: 0.04345310479402542\n",
      "      policy_loss: -0.003295746399089694\n",
      "      total_loss: 67.98738098144531\n",
      "      vf_explained_var: 0.9943271279335022\n",
      "      vf_loss: 67.98953247070312\n",
      "    sample_time_ms: 18310.548\n",
      "    update_time_ms: 5.072\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.641340455785\n",
      "  time_since_restore: 17635.397387504578\n",
      "  time_this_iter_s: 22.09706211090088\n",
      "  time_total_s: 17635.397387504578\n",
      "  timestamp: 1553726673\n",
      "  timesteps_since_restore: 6930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6930000\n",
      "  training_iteration: 693\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17635 s, 693 iter, 6930000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-44-55\n",
      "  done: false\n",
      "  episode_len_mean: 128.62\n",
      "  episode_reward_max: 805.1469599116548\n",
      "  episode_reward_mean: 720.5480600792788\n",
      "  episode_reward_min: -67.41800561250943\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 51526\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.819\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 6940000\n",
      "    num_steps_trained: 6940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03975442796945572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6741786599159241\n",
      "      kl: 0.02209569700062275\n",
      "      policy_loss: -0.00200910703279078\n",
      "      total_loss: 87.68038940429688\n",
      "      vf_explained_var: 0.9925227761268616\n",
      "      vf_loss: 87.6815185546875\n",
      "    sample_time_ms: 18203.685\n",
      "    update_time_ms: 4.983\n",
      "  iterations_since_restore: 694\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.27403003963934\n",
      "  time_since_restore: 17657.11940217018\n",
      "  time_this_iter_s: 21.722014665603638\n",
      "  time_total_s: 17657.11940217018\n",
      "  timestamp: 1553726695\n",
      "  timesteps_since_restore: 6940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6940000\n",
      "  training_iteration: 694\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17657 s, 694 iter, 6940000 ts, 721 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-45-17\n",
      "  done: false\n",
      "  episode_len_mean: 131.38\n",
      "  episode_reward_max: 805.1469599116548\n",
      "  episode_reward_mean: 724.5901419171739\n",
      "  episode_reward_min: 125.3328790649237\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 51603\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3738.487\n",
      "    load_time_ms: 1.451\n",
      "    num_steps_sampled: 6950000\n",
      "    num_steps_trained: 6950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03975442796945572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7246869206428528\n",
      "      kl: 0.010068324394524097\n",
      "      policy_loss: -0.00014393203309737146\n",
      "      total_loss: 78.26801300048828\n",
      "      vf_explained_var: 0.993796706199646\n",
      "      vf_loss: 78.26776885986328\n",
      "    sample_time_ms: 18243.126\n",
      "    update_time_ms: 5.666\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.295070958587\n",
      "  time_since_restore: 17679.15223455429\n",
      "  time_this_iter_s: 22.032832384109497\n",
      "  time_total_s: 17679.15223455429\n",
      "  timestamp: 1553726717\n",
      "  timesteps_since_restore: 6950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6950000\n",
      "  training_iteration: 695\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17679 s, 695 iter, 6950000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-45-39\n",
      "  done: false\n",
      "  episode_len_mean: 128.85\n",
      "  episode_reward_max: 786.5035791366355\n",
      "  episode_reward_mean: 720.8084228298759\n",
      "  episode_reward_min: 32.21667657641757\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 51681\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.296\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 6960000\n",
      "    num_steps_trained: 6960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03975442796945572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.658453106880188\n",
      "      kl: 0.027399521321058273\n",
      "      policy_loss: -0.0046982052735984325\n",
      "      total_loss: 165.5701141357422\n",
      "      vf_explained_var: 0.987762451171875\n",
      "      vf_loss: 165.57371520996094\n",
      "    sample_time_ms: 18238.827\n",
      "    update_time_ms: 5.758\n",
      "  iterations_since_restore: 696\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.40421141493806\n",
      "  time_since_restore: 17701.228655815125\n",
      "  time_this_iter_s: 22.07642126083374\n",
      "  time_total_s: 17701.228655815125\n",
      "  timestamp: 1553726739\n",
      "  timesteps_since_restore: 6960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6960000\n",
      "  training_iteration: 696\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17701 s, 696 iter, 6960000 ts, 721 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-46-01\n",
      "  done: false\n",
      "  episode_len_mean: 130.67\n",
      "  episode_reward_max: 786.5035791366355\n",
      "  episode_reward_mean: 718.3314050545033\n",
      "  episode_reward_min: 32.21667657641757\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 51758\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.349\n",
      "    load_time_ms: 1.445\n",
      "    num_steps_sampled: 6970000\n",
      "    num_steps_trained: 6970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03975442796945572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6991444826126099\n",
      "      kl: 0.023279227316379547\n",
      "      policy_loss: -0.0003057693538721651\n",
      "      total_loss: 94.29825592041016\n",
      "      vf_explained_var: 0.9924967885017395\n",
      "      vf_loss: 94.2976303100586\n",
      "    sample_time_ms: 18297.618\n",
      "    update_time_ms: 5.931\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.1657025272517\n",
      "  time_since_restore: 17723.580415725708\n",
      "  time_this_iter_s: 22.351759910583496\n",
      "  time_total_s: 17723.580415725708\n",
      "  timestamp: 1553726761\n",
      "  timesteps_since_restore: 6970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6970000\n",
      "  training_iteration: 697\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17723 s, 697 iter, 6970000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-46-23\n",
      "  done: false\n",
      "  episode_len_mean: 127.96\n",
      "  episode_reward_max: 792.5974933036057\n",
      "  episode_reward_mean: 718.6566402803846\n",
      "  episode_reward_min: -53.28767399922248\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 51837\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3731.163\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 6980000\n",
      "    num_steps_trained: 6980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03975442796945572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6053231954574585\n",
      "      kl: 0.012425868771970272\n",
      "      policy_loss: -0.0019425791688263416\n",
      "      total_loss: 50.12248229980469\n",
      "      vf_explained_var: 0.9958239793777466\n",
      "      vf_loss: 50.12392807006836\n",
      "    sample_time_ms: 18273.645\n",
      "    update_time_ms: 5.99\n",
      "  iterations_since_restore: 698\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.3283201401924\n",
      "  time_since_restore: 17745.65444612503\n",
      "  time_this_iter_s: 22.07403039932251\n",
      "  time_total_s: 17745.65444612503\n",
      "  timestamp: 1553726783\n",
      "  timesteps_since_restore: 6980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6980000\n",
      "  training_iteration: 698\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17745 s, 698 iter, 6980000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-46-45\n",
      "  done: false\n",
      "  episode_len_mean: 129.02\n",
      "  episode_reward_max: 803.0505474961086\n",
      "  episode_reward_mean: 706.7706177473706\n",
      "  episode_reward_min: -90.2156831515108\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 51915\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.95\n",
      "    load_time_ms: 1.436\n",
      "    num_steps_sampled: 6990000\n",
      "    num_steps_trained: 6990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03975442796945572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7529179453849792\n",
      "      kl: 0.014962990768253803\n",
      "      policy_loss: -0.001749074668623507\n",
      "      total_loss: 329.2530517578125\n",
      "      vf_explained_var: 0.9773812890052795\n",
      "      vf_loss: 329.2542419433594\n",
      "    sample_time_ms: 18261.535\n",
      "    update_time_ms: 5.972\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.38530887368535\n",
      "  time_since_restore: 17767.120167970657\n",
      "  time_this_iter_s: 21.46572184562683\n",
      "  time_total_s: 17767.120167970657\n",
      "  timestamp: 1553726805\n",
      "  timesteps_since_restore: 6990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6990000\n",
      "  training_iteration: 699\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17767 s, 699 iter, 6990000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-47-07\n",
      "  done: false\n",
      "  episode_len_mean: 127.49\n",
      "  episode_reward_max: 797.3113226053368\n",
      "  episode_reward_mean: 692.6241299483721\n",
      "  episode_reward_min: -90.2156831515108\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 51994\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.57\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 7000000\n",
      "    num_steps_trained: 7000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03975442796945572\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6022230982780457\n",
      "      kl: 0.009455607272684574\n",
      "      policy_loss: -0.0013141032541170716\n",
      "      total_loss: 69.40673828125\n",
      "      vf_explained_var: 0.9952309727668762\n",
      "      vf_loss: 69.40766143798828\n",
      "    sample_time_ms: 18314.043\n",
      "    update_time_ms: 6.002\n",
      "  iterations_since_restore: 700\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.31206497418606\n",
      "  time_since_restore: 17789.540087223053\n",
      "  time_this_iter_s: 22.41991925239563\n",
      "  time_total_s: 17789.540087223053\n",
      "  timestamp: 1553726827\n",
      "  timesteps_since_restore: 7000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7000000\n",
      "  training_iteration: 700\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17789 s, 700 iter, 7000000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-47-30\n",
      "  done: false\n",
      "  episode_len_mean: 128.38\n",
      "  episode_reward_max: 793.6850650839401\n",
      "  episode_reward_mean: 726.3867023336387\n",
      "  episode_reward_min: -42.46358540117666\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 52072\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.849\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 7010000\n",
      "    num_steps_trained: 7010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6397241353988647\n",
      "      kl: 0.021550584584474564\n",
      "      policy_loss: -0.006278511602431536\n",
      "      total_loss: 105.30347442626953\n",
      "      vf_explained_var: 0.9920293092727661\n",
      "      vf_loss: 105.30931854248047\n",
      "    sample_time_ms: 18318.397\n",
      "    update_time_ms: 5.988\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 363.19335116681935\n",
      "  time_since_restore: 17811.75580883026\n",
      "  time_this_iter_s: 22.215721607208252\n",
      "  time_total_s: 17811.75580883026\n",
      "  timestamp: 1553726850\n",
      "  timesteps_since_restore: 7010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7010000\n",
      "  training_iteration: 701\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17811 s, 701 iter, 7010000 ts, 726 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-47-52\n",
      "  done: false\n",
      "  episode_len_mean: 126.83\n",
      "  episode_reward_max: 808.5247336027757\n",
      "  episode_reward_mean: 721.2901313296649\n",
      "  episode_reward_min: -42.46358540117666\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 52151\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.773\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 7020000\n",
      "    num_steps_trained: 7020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5630189776420593\n",
      "      kl: 0.03256380185484886\n",
      "      policy_loss: -0.01066376268863678\n",
      "      total_loss: 34.37502670288086\n",
      "      vf_explained_var: 0.9972383379936218\n",
      "      vf_loss: 34.385047912597656\n",
      "    sample_time_ms: 18336.354\n",
      "    update_time_ms: 5.963\n",
      "  iterations_since_restore: 702\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.64506566483243\n",
      "  time_since_restore: 17834.038076400757\n",
      "  time_this_iter_s: 22.282267570495605\n",
      "  time_total_s: 17834.038076400757\n",
      "  timestamp: 1553726872\n",
      "  timesteps_since_restore: 7020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7020000\n",
      "  training_iteration: 702\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17834 s, 702 iter, 7020000 ts, 721 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-48-15\n",
      "  done: false\n",
      "  episode_len_mean: 126.85\n",
      "  episode_reward_max: 801.1523974430646\n",
      "  episode_reward_mean: 726.0224005450985\n",
      "  episode_reward_min: 73.82814480449895\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 52230\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.425\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 7030000\n",
      "    num_steps_trained: 7030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.626746654510498\n",
      "      kl: 0.017533287405967712\n",
      "      policy_loss: -0.0013141550589352846\n",
      "      total_loss: 59.58013916015625\n",
      "      vf_explained_var: 0.9954797029495239\n",
      "      vf_loss: 59.58110427856445\n",
      "    sample_time_ms: 18393.225\n",
      "    update_time_ms: 5.899\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 363.01120027254916\n",
      "  time_since_restore: 17856.689214468002\n",
      "  time_this_iter_s: 22.651138067245483\n",
      "  time_total_s: 17856.689214468002\n",
      "  timestamp: 1553726895\n",
      "  timesteps_since_restore: 7030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7030000\n",
      "  training_iteration: 703\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17856 s, 703 iter, 7030000 ts, 726 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-48-37\n",
      "  done: false\n",
      "  episode_len_mean: 130.17\n",
      "  episode_reward_max: 801.1523974430646\n",
      "  episode_reward_mean: 719.0597289272092\n",
      "  episode_reward_min: -87.92691182275674\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 52307\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.887\n",
      "    load_time_ms: 1.473\n",
      "    num_steps_sampled: 7040000\n",
      "    num_steps_trained: 7040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7103136777877808\n",
      "      kl: 0.012959180399775505\n",
      "      policy_loss: -8.297128806589171e-05\n",
      "      total_loss: 181.66714477539062\n",
      "      vf_explained_var: 0.9845048785209656\n",
      "      vf_loss: 181.66696166992188\n",
      "    sample_time_ms: 18477.452\n",
      "    update_time_ms: 6.188\n",
      "  iterations_since_restore: 704\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.5298644636046\n",
      "  time_since_restore: 17879.19746518135\n",
      "  time_this_iter_s: 22.50825071334839\n",
      "  time_total_s: 17879.19746518135\n",
      "  timestamp: 1553726917\n",
      "  timesteps_since_restore: 7040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7040000\n",
      "  training_iteration: 704\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17879 s, 704 iter, 7040000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-49-00\n",
      "  done: false\n",
      "  episode_len_mean: 127.82\n",
      "  episode_reward_max: 794.5400358530081\n",
      "  episode_reward_mean: 708.7400620587713\n",
      "  episode_reward_min: -111.72751303278395\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 52385\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.819\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 7050000\n",
      "    num_steps_trained: 7050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6660588383674622\n",
      "      kl: 0.014552757143974304\n",
      "      policy_loss: -0.00044655209057964385\n",
      "      total_loss: 256.9695129394531\n",
      "      vf_explained_var: 0.9804844260215759\n",
      "      vf_loss: 256.96966552734375\n",
      "    sample_time_ms: 18565.115\n",
      "    update_time_ms: 5.762\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.37003102938564\n",
      "  time_since_restore: 17902.103716611862\n",
      "  time_this_iter_s: 22.906251430511475\n",
      "  time_total_s: 17902.103716611862\n",
      "  timestamp: 1553726940\n",
      "  timesteps_since_restore: 7050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7050000\n",
      "  training_iteration: 705\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17902 s, 705 iter, 7050000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-49-23\n",
      "  done: false\n",
      "  episode_len_mean: 128.22\n",
      "  episode_reward_max: 785.5812109805617\n",
      "  episode_reward_mean: 730.4393390438892\n",
      "  episode_reward_min: 674.4334465892912\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 52464\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.819\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 7060000\n",
      "    num_steps_trained: 7060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5568756461143494\n",
      "      kl: 0.034010149538517\n",
      "      policy_loss: -0.0010464841034263372\n",
      "      total_loss: 5.382387161254883\n",
      "      vf_explained_var: 0.9995719790458679\n",
      "      vf_loss: 5.382757663726807\n",
      "    sample_time_ms: 18602.033\n",
      "    update_time_ms: 5.793\n",
      "  iterations_since_restore: 706\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 365.2196695219446\n",
      "  time_since_restore: 17924.638456583023\n",
      "  time_this_iter_s: 22.53473997116089\n",
      "  time_total_s: 17924.638456583023\n",
      "  timestamp: 1553726963\n",
      "  timesteps_since_restore: 7060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7060000\n",
      "  training_iteration: 706\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17924 s, 706 iter, 7060000 ts, 730 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-49-45\n",
      "  done: false\n",
      "  episode_len_mean: 127.26\n",
      "  episode_reward_max: 782.102081599125\n",
      "  episode_reward_mean: 722.6650630628692\n",
      "  episode_reward_min: 54.315884955630196\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 52542\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.591\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 7070000\n",
      "    num_steps_trained: 7070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6065991520881653\n",
      "      kl: 0.018874354660511017\n",
      "      policy_loss: -0.0037934505380690098\n",
      "      total_loss: 98.45036315917969\n",
      "      vf_explained_var: 0.9917584657669067\n",
      "      vf_loss: 98.45379638671875\n",
      "    sample_time_ms: 18587.288\n",
      "    update_time_ms: 5.758\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.3325315314345\n",
      "  time_since_restore: 17946.87937092781\n",
      "  time_this_iter_s: 22.240914344787598\n",
      "  time_total_s: 17946.87937092781\n",
      "  timestamp: 1553726985\n",
      "  timesteps_since_restore: 7070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7070000\n",
      "  training_iteration: 707\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17946 s, 707 iter, 7070000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-50-07\n",
      "  done: false\n",
      "  episode_len_mean: 130.51\n",
      "  episode_reward_max: 793.5065702126451\n",
      "  episode_reward_mean: 713.0386315119925\n",
      "  episode_reward_min: -67.27622132667378\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 52620\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.644\n",
      "    load_time_ms: 1.479\n",
      "    num_steps_sampled: 7080000\n",
      "    num_steps_trained: 7080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7708210349082947\n",
      "      kl: 0.018740316852927208\n",
      "      policy_loss: -0.007767764385789633\n",
      "      total_loss: 360.0341796875\n",
      "      vf_explained_var: 0.9744672775268555\n",
      "      vf_loss: 360.0415954589844\n",
      "    sample_time_ms: 18602.115\n",
      "    update_time_ms: 5.61\n",
      "  iterations_since_restore: 708\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.51931575599633\n",
      "  time_since_restore: 17969.114051818848\n",
      "  time_this_iter_s: 22.234680891036987\n",
      "  time_total_s: 17969.114051818848\n",
      "  timestamp: 1553727007\n",
      "  timesteps_since_restore: 7080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7080000\n",
      "  training_iteration: 708\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17969 s, 708 iter, 7080000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-50-29\n",
      "  done: false\n",
      "  episode_len_mean: 132.6\n",
      "  episode_reward_max: 789.2714236543745\n",
      "  episode_reward_mean: 687.4085065111732\n",
      "  episode_reward_min: -76.25514397179599\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 52696\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.013\n",
      "    load_time_ms: 1.486\n",
      "    num_steps_sampled: 7090000\n",
      "    num_steps_trained: 7090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.737476646900177\n",
      "      kl: 0.032893866300582886\n",
      "      policy_loss: -0.0024936366826295853\n",
      "      total_loss: 270.72369384765625\n",
      "      vf_explained_var: 0.9789527654647827\n",
      "      vf_loss: 270.7255554199219\n",
      "    sample_time_ms: 18670.415\n",
      "    update_time_ms: 5.598\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.7042532555866\n",
      "  time_since_restore: 17991.226541519165\n",
      "  time_this_iter_s: 22.112489700317383\n",
      "  time_total_s: 17991.226541519165\n",
      "  timestamp: 1553727029\n",
      "  timesteps_since_restore: 7090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7090000\n",
      "  training_iteration: 709\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 17991 s, 709 iter, 7090000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-50-51\n",
      "  done: false\n",
      "  episode_len_mean: 130.69\n",
      "  episode_reward_max: 795.9860917079251\n",
      "  episode_reward_mean: 691.5183325167299\n",
      "  episode_reward_min: -80.46009319082458\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 52774\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.428\n",
      "    load_time_ms: 1.453\n",
      "    num_steps_sampled: 7100000\n",
      "    num_steps_trained: 7100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01987721398472786\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6783220767974854\n",
      "      kl: 0.04016254469752312\n",
      "      policy_loss: -0.005949347745627165\n",
      "      total_loss: 499.51904296875\n",
      "      vf_explained_var: 0.9652203321456909\n",
      "      vf_loss: 499.5241394042969\n",
      "    sample_time_ms: 18630.677\n",
      "    update_time_ms: 5.593\n",
      "  iterations_since_restore: 710\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.7591662583649\n",
      "  time_since_restore: 18013.25228357315\n",
      "  time_this_iter_s: 22.025742053985596\n",
      "  time_total_s: 18013.25228357315\n",
      "  timestamp: 1553727051\n",
      "  timesteps_since_restore: 7100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7100000\n",
      "  training_iteration: 710\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18013 s, 710 iter, 7100000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-51-13\n",
      "  done: false\n",
      "  episode_len_mean: 127.34\n",
      "  episode_reward_max: 797.0057201101015\n",
      "  episode_reward_mean: 718.1936981826733\n",
      "  episode_reward_min: -80.46009319082458\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 52852\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.851\n",
      "    load_time_ms: 1.496\n",
      "    num_steps_sampled: 7110000\n",
      "    num_steps_trained: 7110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.029815826565027237\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5595336556434631\n",
      "      kl: 0.026000844314694405\n",
      "      policy_loss: -0.002008149866014719\n",
      "      total_loss: 19.806365966796875\n",
      "      vf_explained_var: 0.9982200860977173\n",
      "      vf_loss: 19.807598114013672\n",
      "    sample_time_ms: 18614.312\n",
      "    update_time_ms: 5.545\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.09684909133665\n",
      "  time_since_restore: 18035.318329811096\n",
      "  time_this_iter_s: 22.066046237945557\n",
      "  time_total_s: 18035.318329811096\n",
      "  timestamp: 1553727073\n",
      "  timesteps_since_restore: 7110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7110000\n",
      "  training_iteration: 711\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18035 s, 711 iter, 7110000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-51-36\n",
      "  done: false\n",
      "  episode_len_mean: 130.45\n",
      "  episode_reward_max: 797.0057201101015\n",
      "  episode_reward_mean: 710.5147832666659\n",
      "  episode_reward_min: -49.95878486078652\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 52929\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.024\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 7120000\n",
      "    num_steps_trained: 7120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.029815826565027237\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.761451244354248\n",
      "      kl: 0.009978569112718105\n",
      "      policy_loss: -0.0032993783243000507\n",
      "      total_loss: 401.60125732421875\n",
      "      vf_explained_var: 0.9700863361358643\n",
      "      vf_loss: 401.604248046875\n",
      "    sample_time_ms: 18650.049\n",
      "    update_time_ms: 5.632\n",
      "  iterations_since_restore: 712\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.2573916333329\n",
      "  time_since_restore: 18057.946722745895\n",
      "  time_this_iter_s: 22.628392934799194\n",
      "  time_total_s: 18057.946722745895\n",
      "  timestamp: 1553727096\n",
      "  timesteps_since_restore: 7120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7120000\n",
      "  training_iteration: 712\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18057 s, 712 iter, 7120000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-51-59\n",
      "  done: false\n",
      "  episode_len_mean: 133.33\n",
      "  episode_reward_max: 793.5973759011957\n",
      "  episode_reward_mean: 701.1894498538537\n",
      "  episode_reward_min: -129.9369487625559\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 53006\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3717.69\n",
      "    load_time_ms: 1.473\n",
      "    num_steps_sampled: 7130000\n",
      "    num_steps_trained: 7130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7389401197433472\n",
      "      kl: 0.012877278961241245\n",
      "      policy_loss: -0.0006869223434478045\n",
      "      total_loss: 217.7147216796875\n",
      "      vf_explained_var: 0.9857463240623474\n",
      "      vf_loss: 217.71519470214844\n",
      "    sample_time_ms: 18685.915\n",
      "    update_time_ms: 5.613\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.59472492692674\n",
      "  time_since_restore: 18080.976344823837\n",
      "  time_this_iter_s: 23.029622077941895\n",
      "  time_total_s: 18080.976344823837\n",
      "  timestamp: 1553727119\n",
      "  timesteps_since_restore: 7130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7130000\n",
      "  training_iteration: 713\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18080 s, 713 iter, 7130000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-52-22\n",
      "  done: false\n",
      "  episode_len_mean: 130.72\n",
      "  episode_reward_max: 793.5973759011957\n",
      "  episode_reward_mean: 689.5632621446935\n",
      "  episode_reward_min: -94.30731994769297\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 53083\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.392\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 7140000\n",
      "    num_steps_trained: 7140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.756158709526062\n",
      "      kl: 0.016804441809654236\n",
      "      policy_loss: 0.000282182329101488\n",
      "      total_loss: 359.74017333984375\n",
      "      vf_explained_var: 0.9767459034919739\n",
      "      vf_loss: 359.7396240234375\n",
      "    sample_time_ms: 18692.951\n",
      "    update_time_ms: 5.314\n",
      "  iterations_since_restore: 714\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.7816310723468\n",
      "  time_since_restore: 18103.52967786789\n",
      "  time_this_iter_s: 22.553333044052124\n",
      "  time_total_s: 18103.52967786789\n",
      "  timestamp: 1553727142\n",
      "  timesteps_since_restore: 7140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7140000\n",
      "  training_iteration: 714\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18103 s, 714 iter, 7140000 ts, 690 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-52-44\n",
      "  done: false\n",
      "  episode_len_mean: 128.65\n",
      "  episode_reward_max: 789.745569808801\n",
      "  episode_reward_mean: 692.636695932696\n",
      "  episode_reward_min: -111.85433072012715\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 53161\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.551\n",
      "    load_time_ms: 1.442\n",
      "    num_steps_sampled: 7150000\n",
      "    num_steps_trained: 7150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6939635872840881\n",
      "      kl: 0.019903631880879402\n",
      "      policy_loss: -0.002963592763990164\n",
      "      total_loss: 499.29547119140625\n",
      "      vf_explained_var: 0.9648776650428772\n",
      "      vf_loss: 499.2980651855469\n",
      "    sample_time_ms: 18648.969\n",
      "    update_time_ms: 5.095\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.318347966348\n",
      "  time_since_restore: 18125.981805562973\n",
      "  time_this_iter_s: 22.452127695083618\n",
      "  time_total_s: 18125.981805562973\n",
      "  timestamp: 1553727164\n",
      "  timesteps_since_restore: 7150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7150000\n",
      "  training_iteration: 715\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18125 s, 715 iter, 7150000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-53-06\n",
      "  done: false\n",
      "  episode_len_mean: 132.86\n",
      "  episode_reward_max: 792.3629361746672\n",
      "  episode_reward_mean: 713.9884173144733\n",
      "  episode_reward_min: -63.55113090339489\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 53236\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.36\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 7160000\n",
      "    num_steps_trained: 7160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.735071063041687\n",
      "      kl: 0.0247257761657238\n",
      "      policy_loss: -0.0016629374586045742\n",
      "      total_loss: 125.5987548828125\n",
      "      vf_explained_var: 0.9900886416435242\n",
      "      vf_loss: 125.60003662109375\n",
      "    sample_time_ms: 18591.117\n",
      "    update_time_ms: 4.854\n",
      "  iterations_since_restore: 716\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.99420865723675\n",
      "  time_since_restore: 18147.834419965744\n",
      "  time_this_iter_s: 21.852614402770996\n",
      "  time_total_s: 18147.834419965744\n",
      "  timestamp: 1553727186\n",
      "  timesteps_since_restore: 7160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7160000\n",
      "  training_iteration: 716\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18147 s, 716 iter, 7160000 ts, 714 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-53-28\n",
      "  done: false\n",
      "  episode_len_mean: 133.07\n",
      "  episode_reward_max: 792.6270385152201\n",
      "  episode_reward_mean: 707.2981913741844\n",
      "  episode_reward_min: -67.13632569007083\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 53314\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.281\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 7170000\n",
      "    num_steps_trained: 7170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6816229224205017\n",
      "      kl: 0.020457392558455467\n",
      "      policy_loss: -0.0029114645440131426\n",
      "      total_loss: 280.7306823730469\n",
      "      vf_explained_var: 0.977666437625885\n",
      "      vf_loss: 280.7332763671875\n",
      "    sample_time_ms: 18556.85\n",
      "    update_time_ms: 4.68\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.6490956870922\n",
      "  time_since_restore: 18169.898116350174\n",
      "  time_this_iter_s: 22.06369638442993\n",
      "  time_total_s: 18169.898116350174\n",
      "  timestamp: 1553727208\n",
      "  timesteps_since_restore: 7170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7170000\n",
      "  training_iteration: 717\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18169 s, 717 iter, 7170000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-53-51\n",
      "  done: false\n",
      "  episode_len_mean: 128.88\n",
      "  episode_reward_max: 789.8281008906939\n",
      "  episode_reward_mean: 701.0986112733507\n",
      "  episode_reward_min: -73.85511724831325\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 53391\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.787\n",
      "    load_time_ms: 1.434\n",
      "    num_steps_sampled: 7180000\n",
      "    num_steps_trained: 7180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6214982271194458\n",
      "      kl: 0.015629447996616364\n",
      "      policy_loss: -0.001989194890484214\n",
      "      total_loss: 234.77944946289062\n",
      "      vf_explained_var: 0.9814639091491699\n",
      "      vf_loss: 234.7811737060547\n",
      "    sample_time_ms: 18562.554\n",
      "    update_time_ms: 4.767\n",
      "  iterations_since_restore: 718\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.5493056366753\n",
      "  time_since_restore: 18192.17288541794\n",
      "  time_this_iter_s: 22.274769067764282\n",
      "  time_total_s: 18192.17288541794\n",
      "  timestamp: 1553727231\n",
      "  timesteps_since_restore: 7180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7180000\n",
      "  training_iteration: 718\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18192 s, 718 iter, 7180000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-54-13\n",
      "  done: false\n",
      "  episode_len_mean: 129.17\n",
      "  episode_reward_max: 797.4978132448258\n",
      "  episode_reward_mean: 702.5650485228231\n",
      "  episode_reward_min: -92.3940217803769\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 53469\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.086\n",
      "    load_time_ms: 1.455\n",
      "    num_steps_sampled: 7190000\n",
      "    num_steps_trained: 7190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6663922071456909\n",
      "      kl: 0.02747257798910141\n",
      "      policy_loss: -0.006383290980011225\n",
      "      total_loss: 159.31683349609375\n",
      "      vf_explained_var: 0.9886195063591003\n",
      "      vf_loss: 159.32278442382812\n",
      "    sample_time_ms: 18625.269\n",
      "    update_time_ms: 4.798\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.2825242614116\n",
      "  time_since_restore: 18214.9351041317\n",
      "  time_this_iter_s: 22.762218713760376\n",
      "  time_total_s: 18214.9351041317\n",
      "  timestamp: 1553727253\n",
      "  timesteps_since_restore: 7190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7190000\n",
      "  training_iteration: 719\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18214 s, 719 iter, 7190000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-54-36\n",
      "  done: false\n",
      "  episode_len_mean: 128.65\n",
      "  episode_reward_max: 797.4978132448258\n",
      "  episode_reward_mean: 696.4146155477165\n",
      "  episode_reward_min: -95.49388756618586\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 53548\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.064\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 7200000\n",
      "    num_steps_trained: 7200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.65577632188797\n",
      "      kl: 0.027754154056310654\n",
      "      policy_loss: -0.00969088263809681\n",
      "      total_loss: 541.3508911132812\n",
      "      vf_explained_var: 0.9566634893417358\n",
      "      vf_loss: 541.3601684570312\n",
      "    sample_time_ms: 18688.991\n",
      "    update_time_ms: 4.789\n",
      "  iterations_since_restore: 720\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.20730777385836\n",
      "  time_since_restore: 18237.589039564133\n",
      "  time_this_iter_s: 22.653935432434082\n",
      "  time_total_s: 18237.589039564133\n",
      "  timestamp: 1553727276\n",
      "  timesteps_since_restore: 7200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7200000\n",
      "  training_iteration: 720\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18237 s, 720 iter, 7200000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-54-58\n",
      "  done: false\n",
      "  episode_len_mean: 131.84\n",
      "  episode_reward_max: 796.8041997924508\n",
      "  episode_reward_mean: 715.189083829231\n",
      "  episode_reward_min: -6.809252556871144\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 53623\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3741.337\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 7210000\n",
      "    num_steps_trained: 7210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014907913282513618\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7990543842315674\n",
      "      kl: 0.05126065015792847\n",
      "      policy_loss: -0.005262326914817095\n",
      "      total_loss: 88.51002502441406\n",
      "      vf_explained_var: 0.9932569861412048\n",
      "      vf_loss: 88.5145263671875\n",
      "    sample_time_ms: 18663.331\n",
      "    update_time_ms: 4.847\n",
      "  iterations_since_restore: 721\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.59454191461555\n",
      "  time_since_restore: 18259.603466033936\n",
      "  time_this_iter_s: 22.014426469802856\n",
      "  time_total_s: 18259.603466033936\n",
      "  timestamp: 1553727298\n",
      "  timesteps_since_restore: 7210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7210000\n",
      "  training_iteration: 721\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18259 s, 721 iter, 7210000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 131.3\n",
      "  episode_reward_max: 796.8041997924508\n",
      "  episode_reward_mean: 714.8868407677155\n",
      "  episode_reward_min: -109.97093395540675\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 53699\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3744.841\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 7220000\n",
      "    num_steps_trained: 7220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022361868992447853\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7320935130119324\n",
      "      kl: 0.02378225326538086\n",
      "      policy_loss: -0.007826381362974644\n",
      "      total_loss: 295.23974609375\n",
      "      vf_explained_var: 0.9790411591529846\n",
      "      vf_loss: 295.24700927734375\n",
      "    sample_time_ms: 18586.369\n",
      "    update_time_ms: 4.757\n",
      "  iterations_since_restore: 722\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.44342038385776\n",
      "  time_since_restore: 18281.5007917881\n",
      "  time_this_iter_s: 21.89732575416565\n",
      "  time_total_s: 18281.5007917881\n",
      "  timestamp: 1553727320\n",
      "  timesteps_since_restore: 7220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7220000\n",
      "  training_iteration: 722\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18281 s, 722 iter, 7220000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 127.47\n",
      "  episode_reward_max: 792.8510207635843\n",
      "  episode_reward_mean: 722.0526226474791\n",
      "  episode_reward_min: -61.03178981346383\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 53779\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.526\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 7230000\n",
      "    num_steps_trained: 7230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022361868992447853\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4678861200809479\n",
      "      kl: 0.01714714616537094\n",
      "      policy_loss: -0.004913958255201578\n",
      "      total_loss: 156.03480529785156\n",
      "      vf_explained_var: 0.987675666809082\n",
      "      vf_loss: 156.03933715820312\n",
      "    sample_time_ms: 18539.57\n",
      "    update_time_ms: 4.732\n",
      "  iterations_since_restore: 723\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.02631132373955\n",
      "  time_since_restore: 18304.0387403965\n",
      "  time_this_iter_s: 22.537948608398438\n",
      "  time_total_s: 18304.0387403965\n",
      "  timestamp: 1553727343\n",
      "  timesteps_since_restore: 7230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7230000\n",
      "  training_iteration: 723\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18304 s, 723 iter, 7230000 ts, 722 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-56-05\n",
      "  done: false\n",
      "  episode_len_mean: 126.15\n",
      "  episode_reward_max: 792.8510207635843\n",
      "  episode_reward_mean: 713.1066670615711\n",
      "  episode_reward_min: -92.14606495225553\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 53859\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.678\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 7240000\n",
      "    num_steps_trained: 7240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022361868992447853\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6091328263282776\n",
      "      kl: 0.015580826438963413\n",
      "      policy_loss: -0.001908608595840633\n",
      "      total_loss: 200.2185821533203\n",
      "      vf_explained_var: 0.9846179485321045\n",
      "      vf_loss: 200.22015380859375\n",
      "    sample_time_ms: 18543.507\n",
      "    update_time_ms: 4.788\n",
      "  iterations_since_restore: 724\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.55333353078555\n",
      "  time_since_restore: 18326.612210989\n",
      "  time_this_iter_s: 22.57347059249878\n",
      "  time_total_s: 18326.612210989\n",
      "  timestamp: 1553727365\n",
      "  timesteps_since_restore: 7240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7240000\n",
      "  training_iteration: 724\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18326 s, 724 iter, 7240000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 128.45\n",
      "  episode_reward_max: 789.6100767551566\n",
      "  episode_reward_mean: 710.6232928582966\n",
      "  episode_reward_min: -28.087110111650702\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 53937\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3757.637\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 7250000\n",
      "    num_steps_trained: 7250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022361868992447853\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6491307020187378\n",
      "      kl: 0.024937443435192108\n",
      "      policy_loss: -0.004216608125716448\n",
      "      total_loss: 348.45892333984375\n",
      "      vf_explained_var: 0.9708964228630066\n",
      "      vf_loss: 348.46258544921875\n",
      "    sample_time_ms: 18576.465\n",
      "    update_time_ms: 4.831\n",
      "  iterations_since_restore: 725\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.31164642914825\n",
      "  time_since_restore: 18349.56577849388\n",
      "  time_this_iter_s: 22.953567504882812\n",
      "  time_total_s: 18349.56577849388\n",
      "  timestamp: 1553727388\n",
      "  timesteps_since_restore: 7250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7250000\n",
      "  training_iteration: 725\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18349 s, 725 iter, 7250000 ts, 711 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-56-51\n",
      "  done: false\n",
      "  episode_len_mean: 129.61\n",
      "  episode_reward_max: 791.9589359359471\n",
      "  episode_reward_mean: 709.3487140693195\n",
      "  episode_reward_min: -47.26186414930234\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 54015\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.662\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 7260000\n",
      "    num_steps_trained: 7260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022361868992447853\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6871851682662964\n",
      "      kl: 0.017353605479002\n",
      "      policy_loss: -0.0031909297686070204\n",
      "      total_loss: 498.1952209472656\n",
      "      vf_explained_var: 0.9621246457099915\n",
      "      vf_loss: 498.1980285644531\n",
      "    sample_time_ms: 18635.097\n",
      "    update_time_ms: 4.888\n",
      "  iterations_since_restore: 726\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.67435703465986\n",
      "  time_since_restore: 18372.02514076233\n",
      "  time_this_iter_s: 22.459362268447876\n",
      "  time_total_s: 18372.02514076233\n",
      "  timestamp: 1553727411\n",
      "  timesteps_since_restore: 7260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7260000\n",
      "  training_iteration: 726\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18372 s, 726 iter, 7260000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-57-13\n",
      "  done: false\n",
      "  episode_len_mean: 128.85\n",
      "  episode_reward_max: 794.3496270211357\n",
      "  episode_reward_mean: 707.0328880069924\n",
      "  episode_reward_min: -67.5628685265811\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 54093\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.145\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 7270000\n",
      "    num_steps_trained: 7270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022361868992447853\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6300262212753296\n",
      "      kl: 0.024896973744034767\n",
      "      policy_loss: -0.002102222293615341\n",
      "      total_loss: 168.7646026611328\n",
      "      vf_explained_var: 0.9852185249328613\n",
      "      vf_loss: 168.76614379882812\n",
      "    sample_time_ms: 18675.291\n",
      "    update_time_ms: 4.944\n",
      "  iterations_since_restore: 727\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.5164440034962\n",
      "  time_since_restore: 18394.287900447845\n",
      "  time_this_iter_s: 22.262759685516357\n",
      "  time_total_s: 18394.287900447845\n",
      "  timestamp: 1553727433\n",
      "  timesteps_since_restore: 7270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7270000\n",
      "  training_iteration: 727\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18394 s, 727 iter, 7270000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-57-36\n",
      "  done: false\n",
      "  episode_len_mean: 131.98\n",
      "  episode_reward_max: 786.3996770798573\n",
      "  episode_reward_mean: 691.3257006588283\n",
      "  episode_reward_min: -67.5628685265811\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 54170\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.048\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 7280000\n",
      "    num_steps_trained: 7280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.022361868992447853\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8346886038780212\n",
      "      kl: 0.051125381141901016\n",
      "      policy_loss: -0.0007639394607394934\n",
      "      total_loss: 401.37786865234375\n",
      "      vf_explained_var: 0.9701934456825256\n",
      "      vf_loss: 401.37750244140625\n",
      "    sample_time_ms: 18700.28\n",
      "    update_time_ms: 4.956\n",
      "  iterations_since_restore: 728\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.6628503294142\n",
      "  time_since_restore: 18416.821001291275\n",
      "  time_this_iter_s: 22.533100843429565\n",
      "  time_total_s: 18416.821001291275\n",
      "  timestamp: 1553727456\n",
      "  timesteps_since_restore: 7280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7280000\n",
      "  training_iteration: 728\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18416 s, 728 iter, 7280000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-57-58\n",
      "  done: false\n",
      "  episode_len_mean: 128.65\n",
      "  episode_reward_max: 780.7733124548093\n",
      "  episode_reward_mean: 672.0576907261417\n",
      "  episode_reward_min: -88.4399047132036\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 54247\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3764.321\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 7290000\n",
      "    num_steps_trained: 7290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033542804419994354\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7934406995773315\n",
      "      kl: 0.015005395747721195\n",
      "      policy_loss: -0.004089190624654293\n",
      "      total_loss: 741.4259033203125\n",
      "      vf_explained_var: 0.9421396255493164\n",
      "      vf_loss: 741.4295043945312\n",
      "    sample_time_ms: 18661.876\n",
      "    update_time_ms: 5.0\n",
      "  iterations_since_restore: 729\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.02884536307084\n",
      "  time_since_restore: 18439.44016289711\n",
      "  time_this_iter_s: 22.61916160583496\n",
      "  time_total_s: 18439.44016289711\n",
      "  timestamp: 1553727478\n",
      "  timesteps_since_restore: 7290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7290000\n",
      "  training_iteration: 729\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18439 s, 729 iter, 7290000 ts, 672 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-58-21\n",
      "  done: false\n",
      "  episode_len_mean: 128.24\n",
      "  episode_reward_max: 788.9648231312063\n",
      "  episode_reward_mean: 689.3402047327445\n",
      "  episode_reward_min: -51.02854317650815\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 54326\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.018\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 7300000\n",
      "    num_steps_trained: 7300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033542804419994354\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6122416257858276\n",
      "      kl: 0.021146724000573158\n",
      "      policy_loss: -0.004072536714375019\n",
      "      total_loss: 240.13327026367188\n",
      "      vf_explained_var: 0.9803372621536255\n",
      "      vf_loss: 240.1366424560547\n",
      "    sample_time_ms: 18669.739\n",
      "    update_time_ms: 5.028\n",
      "  iterations_since_restore: 730\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.67010236637225\n",
      "  time_since_restore: 18462.158952236176\n",
      "  time_this_iter_s: 22.71878933906555\n",
      "  time_total_s: 18462.158952236176\n",
      "  timestamp: 1553727501\n",
      "  timesteps_since_restore: 7300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7300000\n",
      "  training_iteration: 730\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18462 s, 730 iter, 7300000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-58-44\n",
      "  done: false\n",
      "  episode_len_mean: 131.0\n",
      "  episode_reward_max: 791.4802719880402\n",
      "  episode_reward_mean: 724.5876146213784\n",
      "  episode_reward_min: 171.004901950805\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 54402\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3744.918\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 7310000\n",
      "    num_steps_trained: 7310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033542804419994354\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6753416061401367\n",
      "      kl: 0.014836742542684078\n",
      "      policy_loss: -0.002801857190206647\n",
      "      total_loss: 96.20562744140625\n",
      "      vf_explained_var: 0.9932641983032227\n",
      "      vf_loss: 96.20792388916016\n",
      "    sample_time_ms: 18736.883\n",
      "    update_time_ms: 5.224\n",
      "  iterations_since_restore: 731\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.2938073106893\n",
      "  time_since_restore: 18484.663563728333\n",
      "  time_this_iter_s: 22.504611492156982\n",
      "  time_total_s: 18484.663563728333\n",
      "  timestamp: 1553727524\n",
      "  timesteps_since_restore: 7310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7310000\n",
      "  training_iteration: 731\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18484 s, 731 iter, 7310000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-59-05\n",
      "  done: false\n",
      "  episode_len_mean: 128.79\n",
      "  episode_reward_max: 802.5183963743959\n",
      "  episode_reward_mean: 704.4102492980164\n",
      "  episode_reward_min: -90.08516638008636\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 54481\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.042\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 7320000\n",
      "    num_steps_trained: 7320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033542804419994354\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6447903513908386\n",
      "      kl: 0.014696585945785046\n",
      "      policy_loss: -0.003971776459366083\n",
      "      total_loss: 194.7560272216797\n",
      "      vf_explained_var: 0.9859278798103333\n",
      "      vf_loss: 194.75949096679688\n",
      "    sample_time_ms: 18733.229\n",
      "    update_time_ms: 5.367\n",
      "  iterations_since_restore: 732\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.2051246490082\n",
      "  time_since_restore: 18506.492977380753\n",
      "  time_this_iter_s: 21.829413652420044\n",
      "  time_total_s: 18506.492977380753\n",
      "  timestamp: 1553727545\n",
      "  timesteps_since_restore: 7320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7320000\n",
      "  training_iteration: 732\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18506 s, 732 iter, 7320000 ts, 704 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-59-28\n",
      "  done: false\n",
      "  episode_len_mean: 126.34\n",
      "  episode_reward_max: 789.633400178281\n",
      "  episode_reward_mean: 720.0611010072978\n",
      "  episode_reward_min: -48.998519081334365\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 54560\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.265\n",
      "    load_time_ms: 1.361\n",
      "    num_steps_sampled: 7330000\n",
      "    num_steps_trained: 7330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033542804419994354\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5218217372894287\n",
      "      kl: 0.011936833150684834\n",
      "      policy_loss: -0.0024014990776777267\n",
      "      total_loss: 234.40176391601562\n",
      "      vf_explained_var: 0.9805917739868164\n",
      "      vf_loss: 234.40379333496094\n",
      "    sample_time_ms: 18720.8\n",
      "    update_time_ms: 5.622\n",
      "  iterations_since_restore: 733\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.030550503649\n",
      "  time_since_restore: 18529.122802257538\n",
      "  time_this_iter_s: 22.62982487678528\n",
      "  time_total_s: 18529.122802257538\n",
      "  timestamp: 1553727568\n",
      "  timesteps_since_restore: 7330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7330000\n",
      "  training_iteration: 733\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18529 s, 733 iter, 7330000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-27_23-59-50\n",
      "  done: false\n",
      "  episode_len_mean: 129.45\n",
      "  episode_reward_max: 806.0412227661282\n",
      "  episode_reward_mean: 712.0510077930095\n",
      "  episode_reward_min: -48.998519081334365\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 54638\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3765.96\n",
      "    load_time_ms: 1.363\n",
      "    num_steps_sampled: 7340000\n",
      "    num_steps_trained: 7340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033542804419994354\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5643859505653381\n",
      "      kl: 0.021797142922878265\n",
      "      policy_loss: -0.0008926555747166276\n",
      "      total_loss: 63.62100601196289\n",
      "      vf_explained_var: 0.9953425526618958\n",
      "      vf_loss: 63.62118148803711\n",
      "    sample_time_ms: 18688.226\n",
      "    update_time_ms: 5.697\n",
      "  iterations_since_restore: 734\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.0255038965048\n",
      "  time_since_restore: 18551.398280382156\n",
      "  time_this_iter_s: 22.27547812461853\n",
      "  time_total_s: 18551.398280382156\n",
      "  timestamp: 1553727590\n",
      "  timesteps_since_restore: 7340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7340000\n",
      "  training_iteration: 734\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18551 s, 734 iter, 7340000 ts, 712 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-00-12\n",
      "  done: false\n",
      "  episode_len_mean: 133.34\n",
      "  episode_reward_max: 806.0412227661282\n",
      "  episode_reward_mean: 696.1045461953796\n",
      "  episode_reward_min: -0.4970046680634539\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 54713\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3748.756\n",
      "    load_time_ms: 1.363\n",
      "    num_steps_sampled: 7350000\n",
      "    num_steps_trained: 7350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033542804419994354\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8193433880805969\n",
      "      kl: 0.01488649845123291\n",
      "      policy_loss: 0.0006744196871295571\n",
      "      total_loss: 199.6658477783203\n",
      "      vf_explained_var: 0.9860935807228088\n",
      "      vf_loss: 199.66465759277344\n",
      "    sample_time_ms: 18601.755\n",
      "    update_time_ms: 5.834\n",
      "  iterations_since_restore: 735\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.0522730976898\n",
      "  time_since_restore: 18573.314952373505\n",
      "  time_this_iter_s: 21.916671991348267\n",
      "  time_total_s: 18573.314952373505\n",
      "  timestamp: 1553727612\n",
      "  timesteps_since_restore: 7350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7350000\n",
      "  training_iteration: 735\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18573 s, 735 iter, 7350000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-00-35\n",
      "  done: false\n",
      "  episode_len_mean: 133.32\n",
      "  episode_reward_max: 785.5818466919435\n",
      "  episode_reward_mean: 708.8470557010539\n",
      "  episode_reward_min: -44.59995311885834\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 54790\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3750.021\n",
      "    load_time_ms: 1.35\n",
      "    num_steps_sampled: 7360000\n",
      "    num_steps_trained: 7360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.033542804419994354\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6389840245246887\n",
      "      kl: 0.009161802008748055\n",
      "      policy_loss: -0.0012883138842880726\n",
      "      total_loss: 173.04307556152344\n",
      "      vf_explained_var: 0.987246572971344\n",
      "      vf_loss: 173.0440673828125\n",
      "    sample_time_ms: 18570.459\n",
      "    update_time_ms: 5.89\n",
      "  iterations_since_restore: 736\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.42352785052697\n",
      "  time_since_restore: 18595.474650144577\n",
      "  time_this_iter_s: 22.159697771072388\n",
      "  time_total_s: 18595.474650144577\n",
      "  timestamp: 1553727635\n",
      "  timesteps_since_restore: 7360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7360000\n",
      "  training_iteration: 736\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18595 s, 736 iter, 7360000 ts, 709 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-00-56\n",
      "  done: false\n",
      "  episode_len_mean: 130.77\n",
      "  episode_reward_max: 784.9813550587122\n",
      "  episode_reward_mean: 693.3252191077834\n",
      "  episode_reward_min: -65.43885199418287\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 54867\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.107\n",
      "    load_time_ms: 1.442\n",
      "    num_steps_sampled: 7370000\n",
      "    num_steps_trained: 7370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016771402209997177\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7384443283081055\n",
      "      kl: 0.03359314799308777\n",
      "      policy_loss: -0.006955228745937347\n",
      "      total_loss: 578.545166015625\n",
      "      vf_explained_var: 0.9580619931221008\n",
      "      vf_loss: 578.5515747070312\n",
      "    sample_time_ms: 18470.334\n",
      "    update_time_ms: 5.91\n",
      "  iterations_since_restore: 737\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.6626095538915\n",
      "  time_since_restore: 18616.918119430542\n",
      "  time_this_iter_s: 21.443469285964966\n",
      "  time_total_s: 18616.918119430542\n",
      "  timestamp: 1553727656\n",
      "  timesteps_since_restore: 7370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7370000\n",
      "  training_iteration: 737\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18616 s, 737 iter, 7370000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-01-18\n",
      "  done: false\n",
      "  episode_len_mean: 130.49\n",
      "  episode_reward_max: 794.6761071291079\n",
      "  episode_reward_mean: 697.1876932777186\n",
      "  episode_reward_min: -108.95207893500117\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 54943\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.544\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 7380000\n",
      "    num_steps_trained: 7380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016771402209997177\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6011067628860474\n",
      "      kl: 0.0215032659471035\n",
      "      policy_loss: -0.005381098948419094\n",
      "      total_loss: 236.9062042236328\n",
      "      vf_explained_var: 0.9808695912361145\n",
      "      vf_loss: 236.91123962402344\n",
      "    sample_time_ms: 18412.302\n",
      "    update_time_ms: 5.845\n",
      "  iterations_since_restore: 738\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.5938466388593\n",
      "  time_since_restore: 18638.875319957733\n",
      "  time_this_iter_s: 21.957200527191162\n",
      "  time_total_s: 18638.875319957733\n",
      "  timestamp: 1553727678\n",
      "  timesteps_since_restore: 7380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7380000\n",
      "  training_iteration: 738\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18638 s, 738 iter, 7380000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-01-40\n",
      "  done: false\n",
      "  episode_len_mean: 131.97\n",
      "  episode_reward_max: 794.6761071291079\n",
      "  episode_reward_mean: 696.4454665867396\n",
      "  episode_reward_min: -82.759481210752\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 55020\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3747.56\n",
      "    load_time_ms: 1.443\n",
      "    num_steps_sampled: 7390000\n",
      "    num_steps_trained: 7390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016771402209997177\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7543966770172119\n",
      "      kl: 0.02118946798145771\n",
      "      policy_loss: -0.002927771070972085\n",
      "      total_loss: 322.8210754394531\n",
      "      vf_explained_var: 0.980431854724884\n",
      "      vf_loss: 322.8236389160156\n",
      "    sample_time_ms: 18402.874\n",
      "    update_time_ms: 5.86\n",
      "  iterations_since_restore: 739\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.2227332933699\n",
      "  time_since_restore: 18661.195767879486\n",
      "  time_this_iter_s: 22.32044792175293\n",
      "  time_total_s: 18661.195767879486\n",
      "  timestamp: 1553727700\n",
      "  timesteps_since_restore: 7390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7390000\n",
      "  training_iteration: 739\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18661 s, 739 iter, 7390000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-02-03\n",
      "  done: false\n",
      "  episode_len_mean: 129.01\n",
      "  episode_reward_max: 800.2463637150714\n",
      "  episode_reward_mean: 692.8952109210348\n",
      "  episode_reward_min: -104.57028593496322\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 55097\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.649\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 7400000\n",
      "    num_steps_trained: 7400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016771402209997177\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6430975794792175\n",
      "      kl: 0.02366609312593937\n",
      "      policy_loss: -0.0031737457029521465\n",
      "      total_loss: 289.77886962890625\n",
      "      vf_explained_var: 0.9770259261131287\n",
      "      vf_loss: 289.7816467285156\n",
      "    sample_time_ms: 18401.982\n",
      "    update_time_ms: 6.037\n",
      "  iterations_since_restore: 740\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.44760546051754\n",
      "  time_since_restore: 18683.969654083252\n",
      "  time_this_iter_s: 22.77388620376587\n",
      "  time_total_s: 18683.969654083252\n",
      "  timestamp: 1553727723\n",
      "  timesteps_since_restore: 7400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7400000\n",
      "  training_iteration: 740\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18683 s, 740 iter, 7400000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-02-26\n",
      "  done: false\n",
      "  episode_len_mean: 131.56\n",
      "  episode_reward_max: 800.2463637150714\n",
      "  episode_reward_mean: 709.0952544529554\n",
      "  episode_reward_min: -58.433752460753055\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 55172\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.683\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 7410000\n",
      "    num_steps_trained: 7410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016771402209997177\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7097246050834656\n",
      "      kl: 0.02083054557442665\n",
      "      policy_loss: -0.002201355528086424\n",
      "      total_loss: 160.0734405517578\n",
      "      vf_explained_var: 0.9897677898406982\n",
      "      vf_loss: 160.07530212402344\n",
      "    sample_time_ms: 18422.332\n",
      "    update_time_ms: 5.794\n",
      "  iterations_since_restore: 741\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.5476272264778\n",
      "  time_since_restore: 18706.826316833496\n",
      "  time_this_iter_s: 22.85666275024414\n",
      "  time_total_s: 18706.826316833496\n",
      "  timestamp: 1553727746\n",
      "  timesteps_since_restore: 7410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7410000\n",
      "  training_iteration: 741\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18706 s, 741 iter, 7410000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-02-48\n",
      "  done: false\n",
      "  episode_len_mean: 135.77\n",
      "  episode_reward_max: 784.8539067972505\n",
      "  episode_reward_mean: 676.1935002055741\n",
      "  episode_reward_min: -68.09060047715812\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 55249\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3765.748\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 7420000\n",
      "    num_steps_trained: 7420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016771402209997177\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7683373689651489\n",
      "      kl: 0.03081364557147026\n",
      "      policy_loss: -0.007254204712808132\n",
      "      total_loss: 437.2550048828125\n",
      "      vf_explained_var: 0.9705628752708435\n",
      "      vf_loss: 437.26171875\n",
      "    sample_time_ms: 18416.737\n",
      "    update_time_ms: 5.703\n",
      "  iterations_since_restore: 742\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.09675010278704\n",
      "  time_since_restore: 18728.571587085724\n",
      "  time_this_iter_s: 21.745270252227783\n",
      "  time_total_s: 18728.571587085724\n",
      "  timestamp: 1553727768\n",
      "  timesteps_since_restore: 7420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7420000\n",
      "  training_iteration: 742\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18728 s, 742 iter, 7420000 ts, 676 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-03-10\n",
      "  done: false\n",
      "  episode_len_mean: 133.69\n",
      "  episode_reward_max: 790.3332662018726\n",
      "  episode_reward_mean: 680.4319539559085\n",
      "  episode_reward_min: -68.09060047715812\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 55325\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3747.085\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 7430000\n",
      "    num_steps_trained: 7430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016771402209997177\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7527135014533997\n",
      "      kl: 0.03183087334036827\n",
      "      policy_loss: -0.005330189131200314\n",
      "      total_loss: 421.1263427734375\n",
      "      vf_explained_var: 0.9710069298744202\n",
      "      vf_loss: 421.131103515625\n",
      "    sample_time_ms: 18394.216\n",
      "    update_time_ms: 5.611\n",
      "  iterations_since_restore: 743\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.21597697795426\n",
      "  time_since_restore: 18750.786675691605\n",
      "  time_this_iter_s: 22.215088605880737\n",
      "  time_total_s: 18750.786675691605\n",
      "  timestamp: 1553727790\n",
      "  timesteps_since_restore: 7430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7430000\n",
      "  training_iteration: 743\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18750 s, 743 iter, 7430000 ts, 680 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-03-32\n",
      "  done: false\n",
      "  episode_len_mean: 134.73\n",
      "  episode_reward_max: 790.3332662018726\n",
      "  episode_reward_mean: 705.9802359785326\n",
      "  episode_reward_min: -83.51045681446358\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 55401\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.037\n",
      "    load_time_ms: 1.503\n",
      "    num_steps_sampled: 7440000\n",
      "    num_steps_trained: 7440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.016771402209997177\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6325052976608276\n",
      "      kl: 0.04909311980009079\n",
      "      policy_loss: -0.0025905221700668335\n",
      "      total_loss: 162.55184936523438\n",
      "      vf_explained_var: 0.9862005710601807\n",
      "      vf_loss: 162.55360412597656\n",
      "    sample_time_ms: 18366.346\n",
      "    update_time_ms: 5.56\n",
      "  iterations_since_restore: 744\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.9901179892662\n",
      "  time_since_restore: 18772.743326425552\n",
      "  time_this_iter_s: 21.956650733947754\n",
      "  time_total_s: 18772.743326425552\n",
      "  timestamp: 1553727812\n",
      "  timesteps_since_restore: 7440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7440000\n",
      "  training_iteration: 744\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18772 s, 744 iter, 7440000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-03-54\n",
      "  done: false\n",
      "  episode_len_mean: 130.74\n",
      "  episode_reward_max: 796.7849975845543\n",
      "  episode_reward_mean: 695.6586916254258\n",
      "  episode_reward_min: -106.0839642642249\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 55479\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.443\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 7450000\n",
      "    num_steps_trained: 7450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6043761372566223\n",
      "      kl: 0.029021011665463448\n",
      "      policy_loss: -0.003444504225626588\n",
      "      total_loss: 293.27349853515625\n",
      "      vf_explained_var: 0.9813312888145447\n",
      "      vf_loss: 293.27618408203125\n",
      "    sample_time_ms: 18369.869\n",
      "    update_time_ms: 5.348\n",
      "  iterations_since_restore: 745\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.829345812713\n",
      "  time_since_restore: 18794.69692158699\n",
      "  time_this_iter_s: 21.95359516143799\n",
      "  time_total_s: 18794.69692158699\n",
      "  timestamp: 1553727834\n",
      "  timesteps_since_restore: 7450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7450000\n",
      "  training_iteration: 745\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18794 s, 745 iter, 7450000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-04-16\n",
      "  done: false\n",
      "  episode_len_mean: 128.73\n",
      "  episode_reward_max: 785.0185528102976\n",
      "  episode_reward_mean: 697.8865416381562\n",
      "  episode_reward_min: -79.24125127339389\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 55558\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.161\n",
      "    load_time_ms: 1.562\n",
      "    num_steps_sampled: 7460000\n",
      "    num_steps_trained: 7460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4713190495967865\n",
      "      kl: 0.021423278376460075\n",
      "      policy_loss: -0.0026349110994488\n",
      "      total_loss: 180.63876342773438\n",
      "      vf_explained_var: 0.9860072135925293\n",
      "      vf_loss: 180.640869140625\n",
      "    sample_time_ms: 18352.264\n",
      "    update_time_ms: 5.419\n",
      "  iterations_since_restore: 746\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.9432708190782\n",
      "  time_since_restore: 18816.68182373047\n",
      "  time_this_iter_s: 21.984902143478394\n",
      "  time_total_s: 18816.68182373047\n",
      "  timestamp: 1553727856\n",
      "  timesteps_since_restore: 7460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7460000\n",
      "  training_iteration: 746\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18816 s, 746 iter, 7460000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-04-38\n",
      "  done: false\n",
      "  episode_len_mean: 132.86\n",
      "  episode_reward_max: 790.8330842227195\n",
      "  episode_reward_mean: 693.716239782282\n",
      "  episode_reward_min: -52.83321612867769\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 55632\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.581\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 7470000\n",
      "    num_steps_trained: 7470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9094662666320801\n",
      "      kl: 0.02406223677098751\n",
      "      policy_loss: -0.0022792404051870108\n",
      "      total_loss: 510.9991455078125\n",
      "      vf_explained_var: 0.9645686149597168\n",
      "      vf_loss: 511.00079345703125\n",
      "    sample_time_ms: 18397.368\n",
      "    update_time_ms: 5.486\n",
      "  iterations_since_restore: 747\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.858119891141\n",
      "  time_since_restore: 18838.41954421997\n",
      "  time_this_iter_s: 21.737720489501953\n",
      "  time_total_s: 18838.41954421997\n",
      "  timestamp: 1553727878\n",
      "  timesteps_since_restore: 7470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7470000\n",
      "  training_iteration: 747\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18838 s, 747 iter, 7470000 ts, 694 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-05-00\n",
      "  done: false\n",
      "  episode_len_mean: 137.32\n",
      "  episode_reward_max: 797.0247066338216\n",
      "  episode_reward_mean: 675.2993212751492\n",
      "  episode_reward_min: -70.2079463025195\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 55705\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.877\n",
      "    load_time_ms: 1.466\n",
      "    num_steps_sampled: 7480000\n",
      "    num_steps_trained: 7480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7931416630744934\n",
      "      kl: 0.019182462245225906\n",
      "      policy_loss: -0.0021738046780228615\n",
      "      total_loss: 333.4220886230469\n",
      "      vf_explained_var: 0.9777225852012634\n",
      "      vf_loss: 333.4237365722656\n",
      "    sample_time_ms: 18407.576\n",
      "    update_time_ms: 5.414\n",
      "  iterations_since_restore: 748\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.6496606375746\n",
      "  time_since_restore: 18860.48224210739\n",
      "  time_this_iter_s: 22.062697887420654\n",
      "  time_total_s: 18860.48224210739\n",
      "  timestamp: 1553727900\n",
      "  timesteps_since_restore: 7480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7480000\n",
      "  training_iteration: 748\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18860 s, 748 iter, 7480000 ts, 675 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-05-22\n",
      "  done: false\n",
      "  episode_len_mean: 131.12\n",
      "  episode_reward_max: 786.8571326931075\n",
      "  episode_reward_mean: 703.7631783758885\n",
      "  episode_reward_min: -70.2079463025195\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 55783\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.568\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 7490000\n",
      "    num_steps_trained: 7490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5443353056907654\n",
      "      kl: 0.022216377779841423\n",
      "      policy_loss: -0.001625751843675971\n",
      "      total_loss: 255.6072235107422\n",
      "      vf_explained_var: 0.9843389987945557\n",
      "      vf_loss: 255.6082763671875\n",
      "    sample_time_ms: 18329.336\n",
      "    update_time_ms: 5.202\n",
      "  iterations_since_restore: 749\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.8815891879443\n",
      "  time_since_restore: 18881.983360528946\n",
      "  time_this_iter_s: 21.501118421554565\n",
      "  time_total_s: 18881.983360528946\n",
      "  timestamp: 1553727922\n",
      "  timesteps_since_restore: 7490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7490000\n",
      "  training_iteration: 749\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18881 s, 749 iter, 7490000 ts, 704 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-05-44\n",
      "  done: false\n",
      "  episode_len_mean: 129.52\n",
      "  episode_reward_max: 787.6589463506473\n",
      "  episode_reward_mean: 714.4236163962654\n",
      "  episode_reward_min: -56.431492312141756\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 55859\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.033\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 7500000\n",
      "    num_steps_trained: 7500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5627574324607849\n",
      "      kl: 0.021137669682502747\n",
      "      policy_loss: -0.0007278592674992979\n",
      "      total_loss: 235.5809326171875\n",
      "      vf_explained_var: 0.9823417663574219\n",
      "      vf_loss: 235.58108520507812\n",
      "    sample_time_ms: 18267.627\n",
      "    update_time_ms: 5.138\n",
      "  iterations_since_restore: 750\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.2118081981327\n",
      "  time_since_restore: 18904.10161304474\n",
      "  time_this_iter_s: 22.118252515792847\n",
      "  time_total_s: 18904.10161304474\n",
      "  timestamp: 1553727944\n",
      "  timesteps_since_restore: 7500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7500000\n",
      "  training_iteration: 750\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18904 s, 750 iter, 7500000 ts, 714 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-06-06\n",
      "  done: false\n",
      "  episode_len_mean: 130.64\n",
      "  episode_reward_max: 794.2825359236451\n",
      "  episode_reward_mean: 707.684115202462\n",
      "  episode_reward_min: -67.61959964043922\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 55938\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.339\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 7510000\n",
      "    num_steps_trained: 7510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5233334302902222\n",
      "      kl: 0.015301854349672794\n",
      "      policy_loss: -0.0005374113097786903\n",
      "      total_loss: 415.1482238769531\n",
      "      vf_explained_var: 0.9661073088645935\n",
      "      vf_loss: 415.14837646484375\n",
      "    sample_time_ms: 18220.999\n",
      "    update_time_ms: 5.196\n",
      "  iterations_since_restore: 751\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.8420576012309\n",
      "  time_since_restore: 18926.327907323837\n",
      "  time_this_iter_s: 22.22629427909851\n",
      "  time_total_s: 18926.327907323837\n",
      "  timestamp: 1553727966\n",
      "  timesteps_since_restore: 7510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7510000\n",
      "  training_iteration: 751\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18926 s, 751 iter, 7510000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-06-28\n",
      "  done: false\n",
      "  episode_len_mean: 130.67\n",
      "  episode_reward_max: 796.5081782630513\n",
      "  episode_reward_mean: 696.4064815513898\n",
      "  episode_reward_min: -109.8223814940952\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 56015\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.277\n",
      "    load_time_ms: 1.465\n",
      "    num_steps_sampled: 7520000\n",
      "    num_steps_trained: 7520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6200503706932068\n",
      "      kl: 0.014370400458574295\n",
      "      policy_loss: 0.0005735537852160633\n",
      "      total_loss: 313.07818603515625\n",
      "      vf_explained_var: 0.9765080213546753\n",
      "      vf_loss: 313.07720947265625\n",
      "    sample_time_ms: 18195.345\n",
      "    update_time_ms: 5.21\n",
      "  iterations_since_restore: 752\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.20324077569495\n",
      "  time_since_restore: 18948.032860040665\n",
      "  time_this_iter_s: 21.704952716827393\n",
      "  time_total_s: 18948.032860040665\n",
      "  timestamp: 1553727988\n",
      "  timesteps_since_restore: 7520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7520000\n",
      "  training_iteration: 752\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18948 s, 752 iter, 7520000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-06-49\n",
      "  done: false\n",
      "  episode_len_mean: 129.16\n",
      "  episode_reward_max: 796.5081782630513\n",
      "  episode_reward_mean: 703.9097738820532\n",
      "  episode_reward_min: -109.8223814940952\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 56092\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.656\n",
      "    load_time_ms: 1.464\n",
      "    num_steps_sampled: 7530000\n",
      "    num_steps_trained: 7530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.553296685218811\n",
      "      kl: 0.01816953718662262\n",
      "      policy_loss: -0.0008084644214250147\n",
      "      total_loss: 180.39784240722656\n",
      "      vf_explained_var: 0.9874266386032104\n",
      "      vf_loss: 180.39820861816406\n",
      "    sample_time_ms: 18141.372\n",
      "    update_time_ms: 5.077\n",
      "  iterations_since_restore: 753\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.95488694102664\n",
      "  time_since_restore: 18969.669757127762\n",
      "  time_this_iter_s: 21.636897087097168\n",
      "  time_total_s: 18969.669757127762\n",
      "  timestamp: 1553728009\n",
      "  timesteps_since_restore: 7530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7530000\n",
      "  training_iteration: 753\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18969 s, 753 iter, 7530000 ts, 704 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-07-12\n",
      "  done: false\n",
      "  episode_len_mean: 133.34\n",
      "  episode_reward_max: 795.0725695655857\n",
      "  episode_reward_mean: 681.9508787194205\n",
      "  episode_reward_min: -73.67442559375522\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 56169\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.01\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 7540000\n",
      "    num_steps_trained: 7540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6843897700309753\n",
      "      kl: 0.02265242300927639\n",
      "      policy_loss: -0.0035427422262728214\n",
      "      total_loss: 428.76080322265625\n",
      "      vf_explained_var: 0.9688711166381836\n",
      "      vf_loss: 428.76373291015625\n",
      "    sample_time_ms: 18150.811\n",
      "    update_time_ms: 5.03\n",
      "  iterations_since_restore: 754\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.97543935971026\n",
      "  time_since_restore: 18991.753090143204\n",
      "  time_this_iter_s: 22.083333015441895\n",
      "  time_total_s: 18991.753090143204\n",
      "  timestamp: 1553728032\n",
      "  timesteps_since_restore: 7540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7540000\n",
      "  training_iteration: 754\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 18991 s, 754 iter, 7540000 ts, 682 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-07-34\n",
      "  done: false\n",
      "  episode_len_mean: 128.44\n",
      "  episode_reward_max: 795.0725695655857\n",
      "  episode_reward_mean: 722.3318909057739\n",
      "  episode_reward_min: -69.50526159991972\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 56249\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.664\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 7550000\n",
      "    num_steps_trained: 7550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3424152135848999\n",
      "      kl: 0.017961226403713226\n",
      "      policy_loss: -0.0019305042224004865\n",
      "      total_loss: 185.7936248779297\n",
      "      vf_explained_var: 0.9842378497123718\n",
      "      vf_loss: 185.7950897216797\n",
      "    sample_time_ms: 18235.196\n",
      "    update_time_ms: 5.166\n",
      "  iterations_since_restore: 755\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.16594545288694\n",
      "  time_since_restore: 19014.53137421608\n",
      "  time_this_iter_s: 22.778284072875977\n",
      "  time_total_s: 19014.53137421608\n",
      "  timestamp: 1553728054\n",
      "  timesteps_since_restore: 7550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7550000\n",
      "  training_iteration: 755\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19014 s, 755 iter, 7550000 ts, 722 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-07-57\n",
      "  done: false\n",
      "  episode_len_mean: 129.6\n",
      "  episode_reward_max: 791.4684010067612\n",
      "  episode_reward_mean: 699.3808523801093\n",
      "  episode_reward_min: -69.50526159991972\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 56326\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.292\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 7560000\n",
      "    num_steps_trained: 7560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6261281371116638\n",
      "      kl: 0.03384805843234062\n",
      "      policy_loss: -0.001917384215630591\n",
      "      total_loss: 183.0077362060547\n",
      "      vf_explained_var: 0.9884979128837585\n",
      "      vf_loss: 183.00881958007812\n",
      "    sample_time_ms: 18243.547\n",
      "    update_time_ms: 5.002\n",
      "  iterations_since_restore: 756\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.69042619005484\n",
      "  time_since_restore: 19036.790848255157\n",
      "  time_this_iter_s: 22.25947403907776\n",
      "  time_total_s: 19036.790848255157\n",
      "  timestamp: 1553728077\n",
      "  timesteps_since_restore: 7560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7560000\n",
      "  training_iteration: 756\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19036 s, 756 iter, 7560000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-08-19\n",
      "  done: false\n",
      "  episode_len_mean: 131.78\n",
      "  episode_reward_max: 791.2749383864065\n",
      "  episode_reward_mean: 705.0036246125652\n",
      "  episode_reward_min: -65.70341862230583\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 56403\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.035\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 7570000\n",
      "    num_steps_trained: 7570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5693548321723938\n",
      "      kl: 0.01645919680595398\n",
      "      policy_loss: -3.0279923066700576e-06\n",
      "      total_loss: 141.28225708007812\n",
      "      vf_explained_var: 0.9898144602775574\n",
      "      vf_loss: 141.28184509277344\n",
      "    sample_time_ms: 18311.082\n",
      "    update_time_ms: 4.823\n",
      "  iterations_since_restore: 757\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.50181230628266\n",
      "  time_since_restore: 19059.201612710953\n",
      "  time_this_iter_s: 22.410764455795288\n",
      "  time_total_s: 19059.201612710953\n",
      "  timestamp: 1553728099\n",
      "  timesteps_since_restore: 7570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7570000\n",
      "  training_iteration: 757\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19059 s, 757 iter, 7570000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 132.08\n",
      "  episode_reward_max: 798.580085576442\n",
      "  episode_reward_mean: 701.9107527968123\n",
      "  episode_reward_min: -82.54177078058947\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 56479\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.8\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 7580000\n",
      "    num_steps_trained: 7580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6584820747375488\n",
      "      kl: 0.024041900411248207\n",
      "      policy_loss: -0.0035340716131031513\n",
      "      total_loss: 297.0343933105469\n",
      "      vf_explained_var: 0.9839792251586914\n",
      "      vf_loss: 297.0373229980469\n",
      "    sample_time_ms: 18291.755\n",
      "    update_time_ms: 4.859\n",
      "  iterations_since_restore: 758\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.9553763984062\n",
      "  time_since_restore: 19081.0676779747\n",
      "  time_this_iter_s: 21.86606526374817\n",
      "  time_total_s: 19081.0676779747\n",
      "  timestamp: 1553728121\n",
      "  timesteps_since_restore: 7580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7580000\n",
      "  training_iteration: 758\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19081 s, 758 iter, 7580000 ts, 702 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-09-03\n",
      "  done: false\n",
      "  episode_len_mean: 134.93\n",
      "  episode_reward_max: 798.5205965927174\n",
      "  episode_reward_mean: 675.9640007770894\n",
      "  episode_reward_min: -87.12583326575924\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 56553\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.595\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 7590000\n",
      "    num_steps_trained: 7590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8035790920257568\n",
      "      kl: 0.017747661098837852\n",
      "      policy_loss: -0.002389201894402504\n",
      "      total_loss: 522.8125\n",
      "      vf_explained_var: 0.9623939394950867\n",
      "      vf_loss: 522.8143920898438\n",
      "    sample_time_ms: 18331.035\n",
      "    update_time_ms: 5.118\n",
      "  iterations_since_restore: 759\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.98200038854463\n",
      "  time_since_restore: 19102.98951458931\n",
      "  time_this_iter_s: 21.921836614608765\n",
      "  time_total_s: 19102.98951458931\n",
      "  timestamp: 1553728143\n",
      "  timesteps_since_restore: 7590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7590000\n",
      "  training_iteration: 759\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19102 s, 759 iter, 7590000 ts, 676 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-09-26\n",
      "  done: false\n",
      "  episode_len_mean: 133.2\n",
      "  episode_reward_max: 798.5205965927174\n",
      "  episode_reward_mean: 684.5623067145362\n",
      "  episode_reward_min: -96.69934380844795\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 56629\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.382\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 7600000\n",
      "    num_steps_trained: 7600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6859402060508728\n",
      "      kl: 0.02373906970024109\n",
      "      policy_loss: -0.003400140907615423\n",
      "      total_loss: 329.46185302734375\n",
      "      vf_explained_var: 0.9797261357307434\n",
      "      vf_loss: 329.4646301269531\n",
      "    sample_time_ms: 18342.234\n",
      "    update_time_ms: 5.063\n",
      "  iterations_since_restore: 760\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.2811533572682\n",
      "  time_since_restore: 19125.448657035828\n",
      "  time_this_iter_s: 22.459142446517944\n",
      "  time_total_s: 19125.448657035828\n",
      "  timestamp: 1553728166\n",
      "  timesteps_since_restore: 7600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7600000\n",
      "  training_iteration: 760\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19125 s, 760 iter, 7600000 ts, 685 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-09-48\n",
      "  done: false\n",
      "  episode_len_mean: 130.94\n",
      "  episode_reward_max: 790.7970134670978\n",
      "  episode_reward_mean: 710.7305807175087\n",
      "  episode_reward_min: -56.95203512646495\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 56707\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.166\n",
      "    load_time_ms: 1.4\n",
      "    num_steps_sampled: 7610000\n",
      "    num_steps_trained: 7610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5078005790710449\n",
      "      kl: 0.030860496684908867\n",
      "      policy_loss: -0.0033051674254238605\n",
      "      total_loss: 108.48216247558594\n",
      "      vf_explained_var: 0.9919278025627136\n",
      "      vf_loss: 108.48468780517578\n",
      "    sample_time_ms: 18347.184\n",
      "    update_time_ms: 5.076\n",
      "  iterations_since_restore: 761\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.3652903587543\n",
      "  time_since_restore: 19147.72039103508\n",
      "  time_this_iter_s: 22.27173399925232\n",
      "  time_total_s: 19147.72039103508\n",
      "  timestamp: 1553728188\n",
      "  timesteps_since_restore: 7610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7610000\n",
      "  training_iteration: 761\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19147 s, 761 iter, 7610000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-10-10\n",
      "  done: false\n",
      "  episode_len_mean: 129.86\n",
      "  episode_reward_max: 790.7970134670978\n",
      "  episode_reward_mean: 671.646250984961\n",
      "  episode_reward_min: -109.40424608656366\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 56785\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3752.603\n",
      "    load_time_ms: 1.421\n",
      "    num_steps_sampled: 7620000\n",
      "    num_steps_trained: 7620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6831604838371277\n",
      "      kl: 0.017242752015590668\n",
      "      policy_loss: -0.0024366043508052826\n",
      "      total_loss: 409.218505859375\n",
      "      vf_explained_var: 0.9733493328094482\n",
      "      vf_loss: 409.220458984375\n",
      "    sample_time_ms: 18437.645\n",
      "    update_time_ms: 5.256\n",
      "  iterations_since_restore: 762\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 335.8231254924805\n",
      "  time_since_restore: 19170.177920103073\n",
      "  time_this_iter_s: 22.457529067993164\n",
      "  time_total_s: 19170.177920103073\n",
      "  timestamp: 1553728210\n",
      "  timesteps_since_restore: 7620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7620000\n",
      "  training_iteration: 762\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19170 s, 762 iter, 7620000 ts, 672 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-10-32\n",
      "  done: false\n",
      "  episode_len_mean: 131.08\n",
      "  episode_reward_max: 788.9145418326252\n",
      "  episode_reward_mean: 686.6468691140203\n",
      "  episode_reward_min: -117.38078241651542\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 56863\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.752\n",
      "    load_time_ms: 1.433\n",
      "    num_steps_sampled: 7630000\n",
      "    num_steps_trained: 7630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025157099589705467\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5447667241096497\n",
      "      kl: 0.08031150698661804\n",
      "      policy_loss: -0.0061857569962739944\n",
      "      total_loss: 328.7507629394531\n",
      "      vf_explained_var: 0.9738585352897644\n",
      "      vf_loss: 328.75494384765625\n",
      "    sample_time_ms: 18452.471\n",
      "    update_time_ms: 5.255\n",
      "  iterations_since_restore: 763\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.32343455701016\n",
      "  time_since_restore: 19192.002978801727\n",
      "  time_this_iter_s: 21.825058698654175\n",
      "  time_total_s: 19192.002978801727\n",
      "  timestamp: 1553728232\n",
      "  timesteps_since_restore: 7630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7630000\n",
      "  training_iteration: 763\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19192 s, 763 iter, 7630000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-10-54\n",
      "  done: false\n",
      "  episode_len_mean: 132.0\n",
      "  episode_reward_max: 793.9401433048681\n",
      "  episode_reward_mean: 692.2986249546597\n",
      "  episode_reward_min: -101.02456099360016\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 56940\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3763.663\n",
      "    load_time_ms: 1.394\n",
      "    num_steps_sampled: 7640000\n",
      "    num_steps_trained: 7640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037735652178525925\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7394244074821472\n",
      "      kl: 0.016647720709443092\n",
      "      policy_loss: -0.0034430341329425573\n",
      "      total_loss: 475.34844970703125\n",
      "      vf_explained_var: 0.9659945368766785\n",
      "      vf_loss: 475.351318359375\n",
      "    sample_time_ms: 18438.474\n",
      "    update_time_ms: 5.269\n",
      "  iterations_since_restore: 764\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.14931247732983\n",
      "  time_since_restore: 19214.015315532684\n",
      "  time_this_iter_s: 22.01233673095703\n",
      "  time_total_s: 19214.015315532684\n",
      "  timestamp: 1553728254\n",
      "  timesteps_since_restore: 7640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7640000\n",
      "  training_iteration: 764\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19214 s, 764 iter, 7640000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-11-16\n",
      "  done: false\n",
      "  episode_len_mean: 129.59\n",
      "  episode_reward_max: 793.9401433048681\n",
      "  episode_reward_mean: 683.561626912786\n",
      "  episode_reward_min: -101.02456099360016\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 57019\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3769.146\n",
      "    load_time_ms: 1.327\n",
      "    num_steps_sampled: 7650000\n",
      "    num_steps_trained: 7650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037735652178525925\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5471988320350647\n",
      "      kl: 0.025862714275717735\n",
      "      policy_loss: -0.005266590975224972\n",
      "      total_loss: 430.86492919921875\n",
      "      vf_explained_var: 0.9697667360305786\n",
      "      vf_loss: 430.8692321777344\n",
      "    sample_time_ms: 18368.044\n",
      "    update_time_ms: 5.208\n",
      "  iterations_since_restore: 765\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.78081345639293\n",
      "  time_since_restore: 19236.13900232315\n",
      "  time_this_iter_s: 22.12368679046631\n",
      "  time_total_s: 19236.13900232315\n",
      "  timestamp: 1553728276\n",
      "  timesteps_since_restore: 7650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7650000\n",
      "  training_iteration: 765\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19236 s, 765 iter, 7650000 ts, 684 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-11-39\n",
      "  done: false\n",
      "  episode_len_mean: 134.33\n",
      "  episode_reward_max: 794.9113983456921\n",
      "  episode_reward_mean: 669.8324412957696\n",
      "  episode_reward_min: -120.7796735025367\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 57093\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3750.999\n",
      "    load_time_ms: 1.36\n",
      "    num_steps_sampled: 7660000\n",
      "    num_steps_trained: 7660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037735652178525925\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9396998286247253\n",
      "      kl: 0.01839791238307953\n",
      "      policy_loss: -0.0011314284056425095\n",
      "      total_loss: 537.1566772460938\n",
      "      vf_explained_var: 0.9717822074890137\n",
      "      vf_loss: 537.1571655273438\n",
      "    sample_time_ms: 18408.875\n",
      "    update_time_ms: 5.206\n",
      "  iterations_since_restore: 766\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.91622064788476\n",
      "  time_since_restore: 19258.626526594162\n",
      "  time_this_iter_s: 22.487524271011353\n",
      "  time_total_s: 19258.626526594162\n",
      "  timestamp: 1553728299\n",
      "  timesteps_since_restore: 7660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7660000\n",
      "  training_iteration: 766\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19258 s, 766 iter, 7660000 ts, 670 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-12-01\n",
      "  done: false\n",
      "  episode_len_mean: 131.52\n",
      "  episode_reward_max: 797.1783025731302\n",
      "  episode_reward_mean: 692.1769519601439\n",
      "  episode_reward_min: -120.7796735025367\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 57172\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3748.745\n",
      "    load_time_ms: 1.365\n",
      "    num_steps_sampled: 7670000\n",
      "    num_steps_trained: 7670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037735652178525925\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.45433351397514343\n",
      "      kl: 0.02555224671959877\n",
      "      policy_loss: -0.0011675533605739474\n",
      "      total_loss: 262.40570068359375\n",
      "      vf_explained_var: 0.9781531095504761\n",
      "      vf_loss: 262.4059143066406\n",
      "    sample_time_ms: 18390.745\n",
      "    update_time_ms: 5.25\n",
      "  iterations_since_restore: 767\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.0884759800718\n",
      "  time_since_restore: 19280.833607673645\n",
      "  time_this_iter_s: 22.207081079483032\n",
      "  time_total_s: 19280.833607673645\n",
      "  timestamp: 1553728321\n",
      "  timesteps_since_restore: 7670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7670000\n",
      "  training_iteration: 767\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19280 s, 767 iter, 7670000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-12-23\n",
      "  done: false\n",
      "  episode_len_mean: 130.27\n",
      "  episode_reward_max: 778.0903673422001\n",
      "  episode_reward_mean: 711.4326973173198\n",
      "  episode_reward_min: -51.21634726377624\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 57249\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3748.412\n",
      "    load_time_ms: 1.404\n",
      "    num_steps_sampled: 7680000\n",
      "    num_steps_trained: 7680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037735652178525925\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5991546511650085\n",
      "      kl: 0.021837089210748672\n",
      "      policy_loss: -0.0028011866379529238\n",
      "      total_loss: 330.77117919921875\n",
      "      vf_explained_var: 0.9749259948730469\n",
      "      vf_loss: 330.77313232421875\n",
      "    sample_time_ms: 18432.047\n",
      "    update_time_ms: 5.337\n",
      "  iterations_since_restore: 768\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.71634865865985\n",
      "  time_since_restore: 19303.113402843475\n",
      "  time_this_iter_s: 22.279795169830322\n",
      "  time_total_s: 19303.113402843475\n",
      "  timestamp: 1553728343\n",
      "  timesteps_since_restore: 7680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7680000\n",
      "  training_iteration: 768\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19303 s, 768 iter, 7680000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-12-47\n",
      "  done: false\n",
      "  episode_len_mean: 127.3\n",
      "  episode_reward_max: 792.2877467846934\n",
      "  episode_reward_mean: 716.2678820364416\n",
      "  episode_reward_min: -70.95430461600046\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 57328\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3751.082\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 7690000\n",
      "    num_steps_trained: 7690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037735652178525925\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.42423853278160095\n",
      "      kl: 0.020063521340489388\n",
      "      policy_loss: -0.0022008437663316727\n",
      "      total_loss: 231.2176971435547\n",
      "      vf_explained_var: 0.9859192967414856\n",
      "      vf_loss: 231.21914672851562\n",
      "    sample_time_ms: 18554.786\n",
      "    update_time_ms: 5.246\n",
      "  iterations_since_restore: 769\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.1339410182208\n",
      "  time_since_restore: 19326.289205789566\n",
      "  time_this_iter_s: 23.1758029460907\n",
      "  time_total_s: 19326.289205789566\n",
      "  timestamp: 1553728367\n",
      "  timesteps_since_restore: 7690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7690000\n",
      "  training_iteration: 769\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19326 s, 769 iter, 7690000 ts, 716 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-13-09\n",
      "  done: false\n",
      "  episode_len_mean: 126.67\n",
      "  episode_reward_max: 786.3912854198587\n",
      "  episode_reward_mean: 689.6042028899443\n",
      "  episode_reward_min: -70.95430461600046\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 57407\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.483\n",
      "    load_time_ms: 1.418\n",
      "    num_steps_sampled: 7700000\n",
      "    num_steps_trained: 7700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037735652178525925\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6618503332138062\n",
      "      kl: 0.013014288619160652\n",
      "      policy_loss: -0.0018241634825244546\n",
      "      total_loss: 631.9862060546875\n",
      "      vf_explained_var: 0.9556517004966736\n",
      "      vf_loss: 631.9874877929688\n",
      "    sample_time_ms: 18553.837\n",
      "    update_time_ms: 5.168\n",
      "  iterations_since_restore: 770\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.80210144497215\n",
      "  time_since_restore: 19348.522217035294\n",
      "  time_this_iter_s: 22.23301124572754\n",
      "  time_total_s: 19348.522217035294\n",
      "  timestamp: 1553728389\n",
      "  timesteps_since_restore: 7700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7700000\n",
      "  training_iteration: 770\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19348 s, 770 iter, 7700000 ts, 690 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-13-31\n",
      "  done: false\n",
      "  episode_len_mean: 129.61\n",
      "  episode_reward_max: 781.8750270646251\n",
      "  episode_reward_mean: 713.5594535405535\n",
      "  episode_reward_min: -56.45112245024097\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 57484\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3732.878\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 7710000\n",
      "    num_steps_trained: 7710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.037735652178525925\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5927982926368713\n",
      "      kl: 0.159526064991951\n",
      "      policy_loss: -0.0028588275890797377\n",
      "      total_loss: 83.36931610107422\n",
      "      vf_explained_var: 0.99379962682724\n",
      "      vf_loss: 83.36615753173828\n",
      "    sample_time_ms: 18562.995\n",
      "    update_time_ms: 5.192\n",
      "  iterations_since_restore: 771\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.77972677027674\n",
      "  time_since_restore: 19370.91764855385\n",
      "  time_this_iter_s: 22.395431518554688\n",
      "  time_total_s: 19370.91764855385\n",
      "  timestamp: 1553728411\n",
      "  timesteps_since_restore: 7710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7710000\n",
      "  training_iteration: 771\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19370 s, 771 iter, 7710000 ts, 714 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-13-54\n",
      "  done: false\n",
      "  episode_len_mean: 126.53\n",
      "  episode_reward_max: 797.971164505787\n",
      "  episode_reward_mean: 729.0217809830636\n",
      "  episode_reward_min: -83.01250506605011\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 57564\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.703\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 7720000\n",
      "    num_steps_trained: 7720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.056603480130434036\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.46376723051071167\n",
      "      kl: 0.009830287657678127\n",
      "      policy_loss: -0.0028906892985105515\n",
      "      total_loss: 47.47254943847656\n",
      "      vf_explained_var: 0.9965196251869202\n",
      "      vf_loss: 47.47488784790039\n",
      "    sample_time_ms: 18560.1\n",
      "    update_time_ms: 5.02\n",
      "  iterations_since_restore: 772\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.51089049153177\n",
      "  time_since_restore: 19393.32296705246\n",
      "  time_this_iter_s: 22.40531849861145\n",
      "  time_total_s: 19393.32296705246\n",
      "  timestamp: 1553728434\n",
      "  timesteps_since_restore: 7720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7720000\n",
      "  training_iteration: 772\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19393 s, 772 iter, 7720000 ts, 729 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-14-16\n",
      "  done: false\n",
      "  episode_len_mean: 124.65\n",
      "  episode_reward_max: 783.2429604590375\n",
      "  episode_reward_mean: 690.9899362467572\n",
      "  episode_reward_min: -102.05457074232879\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 57643\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.736\n",
      "    load_time_ms: 1.44\n",
      "    num_steps_sampled: 7730000\n",
      "    num_steps_trained: 7730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028301740065217018\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6762693524360657\n",
      "      kl: 0.017699413001537323\n",
      "      policy_loss: -0.005236730445176363\n",
      "      total_loss: 454.9311828613281\n",
      "      vf_explained_var: 0.9701818823814392\n",
      "      vf_loss: 454.9358825683594\n",
      "    sample_time_ms: 18581.051\n",
      "    update_time_ms: 4.984\n",
      "  iterations_since_restore: 773\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.4949681233788\n",
      "  time_since_restore: 19415.359423160553\n",
      "  time_this_iter_s: 22.03645610809326\n",
      "  time_total_s: 19415.359423160553\n",
      "  timestamp: 1553728456\n",
      "  timesteps_since_restore: 7730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7730000\n",
      "  training_iteration: 773\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19415 s, 773 iter, 7730000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-14-38\n",
      "  done: false\n",
      "  episode_len_mean: 127.64\n",
      "  episode_reward_max: 788.0362996012868\n",
      "  episode_reward_mean: 685.8640507656175\n",
      "  episode_reward_min: -102.05457074232879\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 57722\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.778\n",
      "    load_time_ms: 1.481\n",
      "    num_steps_sampled: 7740000\n",
      "    num_steps_trained: 7740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028301740065217018\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6511975526809692\n",
      "      kl: 0.01704757660627365\n",
      "      policy_loss: -0.0013945094542577863\n",
      "      total_loss: 271.63470458984375\n",
      "      vf_explained_var: 0.9792490005493164\n",
      "      vf_loss: 271.6356201171875\n",
      "    sample_time_ms: 18625.704\n",
      "    update_time_ms: 5.151\n",
      "  iterations_since_restore: 774\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.9320253828089\n",
      "  time_since_restore: 19437.781260967255\n",
      "  time_this_iter_s: 22.42183780670166\n",
      "  time_total_s: 19437.781260967255\n",
      "  timestamp: 1553728478\n",
      "  timesteps_since_restore: 7740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7740000\n",
      "  training_iteration: 774\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19437 s, 774 iter, 7740000 ts, 686 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-15-01\n",
      "  done: false\n",
      "  episode_len_mean: 129.02\n",
      "  episode_reward_max: 795.0202324165849\n",
      "  episode_reward_mean: 716.5287271815758\n",
      "  episode_reward_min: -72.81507962077062\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 57799\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.087\n",
      "    load_time_ms: 1.539\n",
      "    num_steps_sampled: 7750000\n",
      "    num_steps_trained: 7750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028301740065217018\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6144144535064697\n",
      "      kl: 0.016237083822488785\n",
      "      policy_loss: -4.2734620365081355e-05\n",
      "      total_loss: 244.49960327148438\n",
      "      vf_explained_var: 0.9774409532546997\n",
      "      vf_loss: 244.4991455078125\n",
      "    sample_time_ms: 18689.18\n",
      "    update_time_ms: 5.181\n",
      "  iterations_since_restore: 775\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.264363590788\n",
      "  time_since_restore: 19460.568274736404\n",
      "  time_this_iter_s: 22.78701376914978\n",
      "  time_total_s: 19460.568274736404\n",
      "  timestamp: 1553728501\n",
      "  timesteps_since_restore: 7750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7750000\n",
      "  training_iteration: 775\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19460 s, 775 iter, 7750000 ts, 717 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-15-24\n",
      "  done: false\n",
      "  episode_len_mean: 129.93\n",
      "  episode_reward_max: 795.0202324165849\n",
      "  episode_reward_mean: 692.9946712798619\n",
      "  episode_reward_min: -72.81507962077062\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 57877\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.282\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 7760000\n",
      "    num_steps_trained: 7760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028301740065217018\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.727612316608429\n",
      "      kl: 0.01247217133641243\n",
      "      policy_loss: -0.0007463888614438474\n",
      "      total_loss: 218.79324340820312\n",
      "      vf_explained_var: 0.9850743412971497\n",
      "      vf_loss: 218.79364013671875\n",
      "    sample_time_ms: 18727.807\n",
      "    update_time_ms: 5.301\n",
      "  iterations_since_restore: 776\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.4973356399311\n",
      "  time_since_restore: 19483.50576853752\n",
      "  time_this_iter_s: 22.937493801116943\n",
      "  time_total_s: 19483.50576853752\n",
      "  timestamp: 1553728524\n",
      "  timesteps_since_restore: 7760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7760000\n",
      "  training_iteration: 776\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19483 s, 776 iter, 7760000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-15-47\n",
      "  done: false\n",
      "  episode_len_mean: 128.87\n",
      "  episode_reward_max: 786.7831677873446\n",
      "  episode_reward_mean: 706.2048077031981\n",
      "  episode_reward_min: -62.982700613221084\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 57955\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.488\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 7770000\n",
      "    num_steps_trained: 7770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028301740065217018\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6522711515426636\n",
      "      kl: 0.009261884726583958\n",
      "      policy_loss: -0.001137190731242299\n",
      "      total_loss: 212.71083068847656\n",
      "      vf_explained_var: 0.9823556542396545\n",
      "      vf_loss: 212.7117462158203\n",
      "    sample_time_ms: 18740.788\n",
      "    update_time_ms: 5.34\n",
      "  iterations_since_restore: 777\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.10240385159904\n",
      "  time_since_restore: 19505.894824028015\n",
      "  time_this_iter_s: 22.389055490493774\n",
      "  time_total_s: 19505.894824028015\n",
      "  timestamp: 1553728547\n",
      "  timesteps_since_restore: 7770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7770000\n",
      "  training_iteration: 777\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19505 s, 777 iter, 7770000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-16-09\n",
      "  done: false\n",
      "  episode_len_mean: 131.25\n",
      "  episode_reward_max: 780.3290583221404\n",
      "  episode_reward_mean: 667.8195423284171\n",
      "  episode_reward_min: -77.84482972329155\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 58033\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.915\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 7780000\n",
      "    num_steps_trained: 7780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014150870032608509\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8555077910423279\n",
      "      kl: 0.018446486443281174\n",
      "      policy_loss: 0.0003242362872697413\n",
      "      total_loss: 406.71832275390625\n",
      "      vf_explained_var: 0.973810076713562\n",
      "      vf_loss: 406.7178039550781\n",
      "    sample_time_ms: 18767.858\n",
      "    update_time_ms: 5.264\n",
      "  iterations_since_restore: 778\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 333.9097711642085\n",
      "  time_since_restore: 19528.50618505478\n",
      "  time_this_iter_s: 22.611361026763916\n",
      "  time_total_s: 19528.50618505478\n",
      "  timestamp: 1553728569\n",
      "  timesteps_since_restore: 7780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7780000\n",
      "  training_iteration: 778\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19528 s, 778 iter, 7780000 ts, 668 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-16-32\n",
      "  done: false\n",
      "  episode_len_mean: 130.35\n",
      "  episode_reward_max: 781.8531186923575\n",
      "  episode_reward_mean: 687.1736637266057\n",
      "  episode_reward_min: -77.84482972329155\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 58111\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.554\n",
      "    load_time_ms: 1.512\n",
      "    num_steps_sampled: 7790000\n",
      "    num_steps_trained: 7790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014150870032608509\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5836375951766968\n",
      "      kl: 0.3011268079280853\n",
      "      policy_loss: 9.900255099637434e-05\n",
      "      total_loss: 74.1988525390625\n",
      "      vf_explained_var: 0.99428790807724\n",
      "      vf_loss: 74.19449615478516\n",
      "    sample_time_ms: 18755.989\n",
      "    update_time_ms: 5.517\n",
      "  iterations_since_restore: 779\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.58683186330285\n",
      "  time_since_restore: 19551.5000538826\n",
      "  time_this_iter_s: 22.993868827819824\n",
      "  time_total_s: 19551.5000538826\n",
      "  timestamp: 1553728592\n",
      "  timesteps_since_restore: 7790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7790000\n",
      "  training_iteration: 779\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19551 s, 779 iter, 7790000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-16-55\n",
      "  done: false\n",
      "  episode_len_mean: 129.76\n",
      "  episode_reward_max: 784.9471323843076\n",
      "  episode_reward_mean: 718.5418182443696\n",
      "  episode_reward_min: -45.45692613364727\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 58189\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3760.018\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 7800000\n",
      "    num_steps_trained: 7800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.021226301789283752\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7130658030509949\n",
      "      kl: 0.015067482367157936\n",
      "      policy_loss: -0.004897071048617363\n",
      "      total_loss: 258.4764099121094\n",
      "      vf_explained_var: 0.981469988822937\n",
      "      vf_loss: 258.48101806640625\n",
      "    sample_time_ms: 18782.133\n",
      "    update_time_ms: 5.579\n",
      "  iterations_since_restore: 780\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.2709091221848\n",
      "  time_since_restore: 19574.190952301025\n",
      "  time_this_iter_s: 22.690898418426514\n",
      "  time_total_s: 19574.190952301025\n",
      "  timestamp: 1553728615\n",
      "  timesteps_since_restore: 7800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7800000\n",
      "  training_iteration: 780\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19574 s, 780 iter, 7800000 ts, 719 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-17-17\n",
      "  done: false\n",
      "  episode_len_mean: 129.67\n",
      "  episode_reward_max: 790.354176191486\n",
      "  episode_reward_mean: 730.201751139692\n",
      "  episode_reward_min: 161.34208558153813\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 58267\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3758.443\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 7810000\n",
      "    num_steps_trained: 7810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.021226301789283752\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.61777263879776\n",
      "      kl: 0.016973547637462616\n",
      "      policy_loss: -0.0008459427626803517\n",
      "      total_loss: 101.79071044921875\n",
      "      vf_explained_var: 0.9923291206359863\n",
      "      vf_loss: 101.79119110107422\n",
      "    sample_time_ms: 18767.004\n",
      "    update_time_ms: 5.59\n",
      "  iterations_since_restore: 781\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 365.100875569846\n",
      "  time_since_restore: 19596.42138838768\n",
      "  time_this_iter_s: 22.230436086654663\n",
      "  time_total_s: 19596.42138838768\n",
      "  timestamp: 1553728637\n",
      "  timesteps_since_restore: 7810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7810000\n",
      "  training_iteration: 781\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19596 s, 781 iter, 7810000 ts, 730 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-17-40\n",
      "  done: false\n",
      "  episode_len_mean: 127.63\n",
      "  episode_reward_max: 790.354176191486\n",
      "  episode_reward_mean: 711.0137183667542\n",
      "  episode_reward_min: -46.98013840524035\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 58344\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.368\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 7820000\n",
      "    num_steps_trained: 7820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.021226301789283752\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7260037064552307\n",
      "      kl: 0.012263333424925804\n",
      "      policy_loss: -0.004331432282924652\n",
      "      total_loss: 204.7957305908203\n",
      "      vf_explained_var: 0.9854785203933716\n",
      "      vf_loss: 204.7998046875\n",
      "    sample_time_ms: 18807.854\n",
      "    update_time_ms: 5.568\n",
      "  iterations_since_restore: 782\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.5068591833771\n",
      "  time_since_restore: 19619.26463317871\n",
      "  time_this_iter_s: 22.843244791030884\n",
      "  time_total_s: 19619.26463317871\n",
      "  timestamp: 1553728660\n",
      "  timesteps_since_restore: 7820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7820000\n",
      "  training_iteration: 782\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19619 s, 782 iter, 7820000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-18-03\n",
      "  done: false\n",
      "  episode_len_mean: 125.51\n",
      "  episode_reward_max: 788.0756510542695\n",
      "  episode_reward_mean: 689.2990898895997\n",
      "  episode_reward_min: -118.03154366928729\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 58426\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3762.996\n",
      "    load_time_ms: 1.523\n",
      "    num_steps_sampled: 7830000\n",
      "    num_steps_trained: 7830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.021226301789283752\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6083747744560242\n",
      "      kl: 0.02232041396200657\n",
      "      policy_loss: -0.005808972753584385\n",
      "      total_loss: 362.80548095703125\n",
      "      vf_explained_var: 0.9718080163002014\n",
      "      vf_loss: 362.81085205078125\n",
      "    sample_time_ms: 18860.4\n",
      "    update_time_ms: 5.555\n",
      "  iterations_since_restore: 783\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.64954494479986\n",
      "  time_since_restore: 19641.84350514412\n",
      "  time_this_iter_s: 22.578871965408325\n",
      "  time_total_s: 19641.84350514412\n",
      "  timestamp: 1553728683\n",
      "  timesteps_since_restore: 7830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7830000\n",
      "  training_iteration: 783\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19641 s, 783 iter, 7830000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-18-25\n",
      "  done: false\n",
      "  episode_len_mean: 125.72\n",
      "  episode_reward_max: 788.5096843445888\n",
      "  episode_reward_mean: 710.5591321076569\n",
      "  episode_reward_min: -95.00050528268793\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 58505\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3776.115\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 7840000\n",
      "    num_steps_trained: 7840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.021226301789283752\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5486330986022949\n",
      "      kl: 0.053129855543375015\n",
      "      policy_loss: -0.001189631875604391\n",
      "      total_loss: 178.1737518310547\n",
      "      vf_explained_var: 0.9858642816543579\n",
      "      vf_loss: 178.1737823486328\n",
      "    sample_time_ms: 18856.857\n",
      "    update_time_ms: 5.603\n",
      "  iterations_since_restore: 784\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.27956605382843\n",
      "  time_since_restore: 19664.361825466156\n",
      "  time_this_iter_s: 22.518320322036743\n",
      "  time_total_s: 19664.361825466156\n",
      "  timestamp: 1553728705\n",
      "  timesteps_since_restore: 7840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7840000\n",
      "  training_iteration: 784\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19664 s, 784 iter, 7840000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-18-48\n",
      "  done: false\n",
      "  episode_len_mean: 127.5\n",
      "  episode_reward_max: 793.1187254424096\n",
      "  episode_reward_mean: 719.9673869837535\n",
      "  episode_reward_min: -39.39881647449212\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 58584\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.839\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 7850000\n",
      "    num_steps_trained: 7850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03183945640921593\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6736592054367065\n",
      "      kl: 0.012105894275009632\n",
      "      policy_loss: -0.00116978760343045\n",
      "      total_loss: 148.74571228027344\n",
      "      vf_explained_var: 0.9898077845573425\n",
      "      vf_loss: 148.7465057373047\n",
      "    sample_time_ms: 18804.529\n",
      "    update_time_ms: 5.638\n",
      "  iterations_since_restore: 785\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.98369349187686\n",
      "  time_since_restore: 19686.540457487106\n",
      "  time_this_iter_s: 22.178632020950317\n",
      "  time_total_s: 19686.540457487106\n",
      "  timestamp: 1553728728\n",
      "  timesteps_since_restore: 7850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7850000\n",
      "  training_iteration: 785\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19686 s, 785 iter, 7850000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-19-10\n",
      "  done: false\n",
      "  episode_len_mean: 128.76\n",
      "  episode_reward_max: 793.1187254424096\n",
      "  episode_reward_mean: 709.8926469875825\n",
      "  episode_reward_min: -75.19572694939926\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 58662\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.429\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 7860000\n",
      "    num_steps_trained: 7860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03183945640921593\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6570450663566589\n",
      "      kl: 0.01351119950413704\n",
      "      policy_loss: -0.002122315810993314\n",
      "      total_loss: 124.57371520996094\n",
      "      vf_explained_var: 0.990040123462677\n",
      "      vf_loss: 124.57540893554688\n",
      "    sample_time_ms: 18734.31\n",
      "    update_time_ms: 5.649\n",
      "  iterations_since_restore: 786\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.9463234937911\n",
      "  time_since_restore: 19708.69039273262\n",
      "  time_this_iter_s: 22.149935245513916\n",
      "  time_total_s: 19708.69039273262\n",
      "  timestamp: 1553728750\n",
      "  timesteps_since_restore: 7860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7860000\n",
      "  training_iteration: 786\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19708 s, 786 iter, 7860000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-19-32\n",
      "  done: false\n",
      "  episode_len_mean: 125.2\n",
      "  episode_reward_max: 787.8157592565784\n",
      "  episode_reward_mean: 703.443691092217\n",
      "  episode_reward_min: -88.10762853297541\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 58743\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3752.939\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 7870000\n",
      "    num_steps_trained: 7870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03183945640921593\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.592430830001831\n",
      "      kl: 0.01626514457166195\n",
      "      policy_loss: -0.003782864660024643\n",
      "      total_loss: 541.2849731445312\n",
      "      vf_explained_var: 0.9591134190559387\n",
      "      vf_loss: 541.2882690429688\n",
      "    sample_time_ms: 18679.456\n",
      "    update_time_ms: 5.676\n",
      "  iterations_since_restore: 787\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.7218455461085\n",
      "  time_since_restore: 19730.46731901169\n",
      "  time_this_iter_s: 21.776926279067993\n",
      "  time_total_s: 19730.46731901169\n",
      "  timestamp: 1553728772\n",
      "  timesteps_since_restore: 7870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7870000\n",
      "  training_iteration: 787\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19730 s, 787 iter, 7870000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-19-53\n",
      "  done: false\n",
      "  episode_len_mean: 128.01\n",
      "  episode_reward_max: 789.6970034476097\n",
      "  episode_reward_mean: 703.4722395383262\n",
      "  episode_reward_min: -113.69615781850003\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 58821\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.805\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 7880000\n",
      "    num_steps_trained: 7880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03183945640921593\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6265873908996582\n",
      "      kl: 0.017507605254650116\n",
      "      policy_loss: -0.000873902696184814\n",
      "      total_loss: 273.9290466308594\n",
      "      vf_explained_var: 0.976527750492096\n",
      "      vf_loss: 273.92938232421875\n",
      "    sample_time_ms: 18608.428\n",
      "    update_time_ms: 6.075\n",
      "  iterations_since_restore: 788\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.7361197691632\n",
      "  time_since_restore: 19752.280784606934\n",
      "  time_this_iter_s: 21.81346559524536\n",
      "  time_total_s: 19752.280784606934\n",
      "  timestamp: 1553728793\n",
      "  timesteps_since_restore: 7880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7880000\n",
      "  training_iteration: 788\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19752 s, 788 iter, 7880000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-20-16\n",
      "  done: false\n",
      "  episode_len_mean: 126.89\n",
      "  episode_reward_max: 793.3623864728643\n",
      "  episode_reward_mean: 728.5223708993788\n",
      "  episode_reward_min: 23.13583771851131\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 58900\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.815\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 7890000\n",
      "    num_steps_trained: 7890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03183945640921593\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5069093108177185\n",
      "      kl: 0.011373951099812984\n",
      "      policy_loss: -0.001929836580529809\n",
      "      total_loss: 62.44746017456055\n",
      "      vf_explained_var: 0.9954001307487488\n",
      "      vf_loss: 62.44901657104492\n",
      "    sample_time_ms: 18508.539\n",
      "    update_time_ms: 5.846\n",
      "  iterations_since_restore: 789\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.2611854496894\n",
      "  time_since_restore: 19774.307339429855\n",
      "  time_this_iter_s: 22.026554822921753\n",
      "  time_total_s: 19774.307339429855\n",
      "  timestamp: 1553728816\n",
      "  timesteps_since_restore: 7890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7890000\n",
      "  training_iteration: 789\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19774 s, 789 iter, 7890000 ts, 729 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-20-38\n",
      "  done: false\n",
      "  episode_len_mean: 125.59\n",
      "  episode_reward_max: 776.408366388562\n",
      "  episode_reward_mean: 715.8885080596716\n",
      "  episode_reward_min: -79.43737100524893\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 58981\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.49\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 7900000\n",
      "    num_steps_trained: 7900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03183945640921593\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5849888920783997\n",
      "      kl: 0.02036481350660324\n",
      "      policy_loss: -0.006969479378312826\n",
      "      total_loss: 323.8030700683594\n",
      "      vf_explained_var: 0.9739233255386353\n",
      "      vf_loss: 323.80938720703125\n",
      "    sample_time_ms: 18456.426\n",
      "    update_time_ms: 5.906\n",
      "  iterations_since_restore: 790\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.94425402983586\n",
      "  time_since_restore: 19796.284778118134\n",
      "  time_this_iter_s: 21.9774386882782\n",
      "  time_total_s: 19796.284778118134\n",
      "  timestamp: 1553728838\n",
      "  timesteps_since_restore: 7900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7900000\n",
      "  training_iteration: 790\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19796 s, 790 iter, 7900000 ts, 716 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-21-00\n",
      "  done: false\n",
      "  episode_len_mean: 128.66\n",
      "  episode_reward_max: 794.6886121184531\n",
      "  episode_reward_mean: 740.9692265988083\n",
      "  episode_reward_min: 682.5436955340111\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 59058\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.969\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 7910000\n",
      "    num_steps_trained: 7910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03183945640921593\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5784686207771301\n",
      "      kl: 0.04651660844683647\n",
      "      policy_loss: -0.003778151934966445\n",
      "      total_loss: 21.776601791381836\n",
      "      vf_explained_var: 0.998618483543396\n",
      "      vf_loss: 21.778900146484375\n",
      "    sample_time_ms: 18452.672\n",
      "    update_time_ms: 5.881\n",
      "  iterations_since_restore: 791\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 370.4846132994041\n",
      "  time_since_restore: 19818.44217967987\n",
      "  time_this_iter_s: 22.15740156173706\n",
      "  time_total_s: 19818.44217967987\n",
      "  timestamp: 1553728860\n",
      "  timesteps_since_restore: 7910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7910000\n",
      "  training_iteration: 791\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19818 s, 791 iter, 7910000 ts, 741 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-21-22\n",
      "  done: false\n",
      "  episode_len_mean: 128.94\n",
      "  episode_reward_max: 794.6886121184531\n",
      "  episode_reward_mean: 727.5478338664354\n",
      "  episode_reward_min: 24.353447753245973\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 59136\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.347\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 7920000\n",
      "    num_steps_trained: 7920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04775918275117874\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6869862675666809\n",
      "      kl: 0.009973695501685143\n",
      "      policy_loss: -0.0014204081380739808\n",
      "      total_loss: 48.54036331176758\n",
      "      vf_explained_var: 0.9960260391235352\n",
      "      vf_loss: 48.54130935668945\n",
      "    sample_time_ms: 18367.249\n",
      "    update_time_ms: 5.941\n",
      "  iterations_since_restore: 792\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 363.7739169332178\n",
      "  time_since_restore: 19840.38513803482\n",
      "  time_this_iter_s: 21.94295835494995\n",
      "  time_total_s: 19840.38513803482\n",
      "  timestamp: 1553728882\n",
      "  timesteps_since_restore: 7920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7920000\n",
      "  training_iteration: 792\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19840 s, 792 iter, 7920000 ts, 728 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-21-45\n",
      "  done: false\n",
      "  episode_len_mean: 128.24\n",
      "  episode_reward_max: 791.2271539753814\n",
      "  episode_reward_mean: 721.2442461394269\n",
      "  episode_reward_min: -60.59273003737741\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 59215\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.705\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 7930000\n",
      "    num_steps_trained: 7930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02387959137558937\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6225376725196838\n",
      "      kl: 0.009169514290988445\n",
      "      policy_loss: -0.0021703147795051336\n",
      "      total_loss: 231.4032440185547\n",
      "      vf_explained_var: 0.9821301698684692\n",
      "      vf_loss: 231.4051971435547\n",
      "    sample_time_ms: 18394.702\n",
      "    update_time_ms: 6.018\n",
      "  iterations_since_restore: 793\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.62212306971344\n",
      "  time_since_restore: 19863.203555822372\n",
      "  time_this_iter_s: 22.81841778755188\n",
      "  time_total_s: 19863.203555822372\n",
      "  timestamp: 1553728905\n",
      "  timesteps_since_restore: 7930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7930000\n",
      "  training_iteration: 793\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19863 s, 793 iter, 7930000 ts, 721 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-22-06\n",
      "  done: false\n",
      "  episode_len_mean: 127.99\n",
      "  episode_reward_max: 791.2271539753814\n",
      "  episode_reward_mean: 722.4317146191361\n",
      "  episode_reward_min: -83.2011967458482\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 59293\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.272\n",
      "    load_time_ms: 1.45\n",
      "    num_steps_sampled: 7940000\n",
      "    num_steps_trained: 7940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6244580149650574\n",
      "      kl: 0.02416151575744152\n",
      "      policy_loss: -0.008390513248741627\n",
      "      total_loss: 96.63626098632812\n",
      "      vf_explained_var: 0.9924717545509338\n",
      "      vf_loss: 96.64435577392578\n",
      "    sample_time_ms: 18338.243\n",
      "    update_time_ms: 5.815\n",
      "  iterations_since_restore: 794\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.2158573095679\n",
      "  time_since_restore: 19885.01849913597\n",
      "  time_this_iter_s: 21.814943313598633\n",
      "  time_total_s: 19885.01849913597\n",
      "  timestamp: 1553728926\n",
      "  timesteps_since_restore: 7940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7940000\n",
      "  training_iteration: 794\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19885 s, 794 iter, 7940000 ts, 722 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-22-29\n",
      "  done: false\n",
      "  episode_len_mean: 128.14\n",
      "  episode_reward_max: 797.5054765445269\n",
      "  episode_reward_mean: 710.2914864193745\n",
      "  episode_reward_min: -83.2011967458482\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 59371\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.859\n",
      "    load_time_ms: 1.419\n",
      "    num_steps_sampled: 7950000\n",
      "    num_steps_trained: 7950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6220331192016602\n",
      "      kl: 0.020209163427352905\n",
      "      policy_loss: -0.002179250121116638\n",
      "      total_loss: 97.39276885986328\n",
      "      vf_explained_var: 0.9921790957450867\n",
      "      vf_loss: 97.39469909667969\n",
      "    sample_time_ms: 18401.785\n",
      "    update_time_ms: 5.708\n",
      "  iterations_since_restore: 795\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.1457432096872\n",
      "  time_since_restore: 19907.81999731064\n",
      "  time_this_iter_s: 22.80149817466736\n",
      "  time_total_s: 19907.81999731064\n",
      "  timestamp: 1553728949\n",
      "  timesteps_since_restore: 7950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7950000\n",
      "  training_iteration: 795\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19907 s, 795 iter, 7950000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-22-51\n",
      "  done: false\n",
      "  episode_len_mean: 132.23\n",
      "  episode_reward_max: 796.6829506526766\n",
      "  episode_reward_mean: 731.8368185550806\n",
      "  episode_reward_min: 191.6670629391677\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 59447\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.175\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 7960000\n",
      "    num_steps_trained: 7960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7804887294769287\n",
      "      kl: 0.029016414657235146\n",
      "      policy_loss: -0.0009668551501818001\n",
      "      total_loss: 100.79523468017578\n",
      "      vf_explained_var: 0.9927436709403992\n",
      "      vf_loss: 100.79586029052734\n",
      "    sample_time_ms: 18366.935\n",
      "    update_time_ms: 5.577\n",
      "  iterations_since_restore: 796\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 365.9184092775405\n",
      "  time_since_restore: 19929.642554283142\n",
      "  time_this_iter_s: 21.822556972503662\n",
      "  time_total_s: 19929.642554283142\n",
      "  timestamp: 1553728971\n",
      "  timesteps_since_restore: 7960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7960000\n",
      "  training_iteration: 796\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19929 s, 796 iter, 7960000 ts, 732 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-23-14\n",
      "  done: false\n",
      "  episode_len_mean: 130.75\n",
      "  episode_reward_max: 796.6829506526766\n",
      "  episode_reward_mean: 718.2155231596237\n",
      "  episode_reward_min: -58.767528032207395\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 59525\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.196\n",
      "    load_time_ms: 1.413\n",
      "    num_steps_sampled: 7970000\n",
      "    num_steps_trained: 7970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.699238121509552\n",
      "      kl: 0.01852717623114586\n",
      "      policy_loss: -0.0018577147275209427\n",
      "      total_loss: 244.5050048828125\n",
      "      vf_explained_var: 0.9804012775421143\n",
      "      vf_loss: 244.5066375732422\n",
      "    sample_time_ms: 18432.339\n",
      "    update_time_ms: 5.56\n",
      "  iterations_since_restore: 797\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.10776157981184\n",
      "  time_since_restore: 19952.06379532814\n",
      "  time_this_iter_s: 22.42124104499817\n",
      "  time_total_s: 19952.06379532814\n",
      "  timestamp: 1553728994\n",
      "  timesteps_since_restore: 7970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7970000\n",
      "  training_iteration: 797\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19952 s, 797 iter, 7970000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-23-36\n",
      "  done: false\n",
      "  episode_len_mean: 127.76\n",
      "  episode_reward_max: 786.8933591228515\n",
      "  episode_reward_mean: 710.4116362020213\n",
      "  episode_reward_min: -60.03830102534016\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 59604\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3700.128\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 7980000\n",
      "    num_steps_trained: 7980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6150192022323608\n",
      "      kl: 0.02480791136622429\n",
      "      policy_loss: -0.0037913441192358732\n",
      "      total_loss: 235.9374237060547\n",
      "      vf_explained_var: 0.9821070432662964\n",
      "      vf_loss: 235.94093322753906\n",
      "    sample_time_ms: 18517.38\n",
      "    update_time_ms: 5.237\n",
      "  iterations_since_restore: 798\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.20581810101083\n",
      "  time_since_restore: 19974.70465016365\n",
      "  time_this_iter_s: 22.640854835510254\n",
      "  time_total_s: 19974.70465016365\n",
      "  timestamp: 1553729016\n",
      "  timesteps_since_restore: 7980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7980000\n",
      "  training_iteration: 798\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19974 s, 798 iter, 7980000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-23-58\n",
      "  done: false\n",
      "  episode_len_mean: 126.42\n",
      "  episode_reward_max: 789.2098263514126\n",
      "  episode_reward_mean: 687.8584422804099\n",
      "  episode_reward_min: -95.00664057282036\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 59684\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.533\n",
      "    load_time_ms: 1.439\n",
      "    num_steps_sampled: 7990000\n",
      "    num_steps_trained: 7990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8031524419784546\n",
      "      kl: 0.024677205830812454\n",
      "      policy_loss: -0.00877418089658022\n",
      "      total_loss: 627.9617309570312\n",
      "      vf_explained_var: 0.9485136866569519\n",
      "      vf_loss: 627.9702758789062\n",
      "    sample_time_ms: 18500.825\n",
      "    update_time_ms: 5.167\n",
      "  iterations_since_restore: 799\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.9292211402049\n",
      "  time_since_restore: 19996.66233086586\n",
      "  time_this_iter_s: 21.957680702209473\n",
      "  time_total_s: 19996.66233086586\n",
      "  timestamp: 1553729038\n",
      "  timesteps_since_restore: 7990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7990000\n",
      "  training_iteration: 799\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 19996 s, 799 iter, 7990000 ts, 688 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-24-22\n",
      "  done: false\n",
      "  episode_len_mean: 127.21\n",
      "  episode_reward_max: 790.6319203389947\n",
      "  episode_reward_mean: 709.4372621330715\n",
      "  episode_reward_min: -95.00664057282036\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 59763\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.161\n",
      "    load_time_ms: 1.456\n",
      "    num_steps_sampled: 8000000\n",
      "    num_steps_trained: 8000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.638227105140686\n",
      "      kl: 0.023997275158762932\n",
      "      policy_loss: -0.0010700959246605635\n",
      "      total_loss: 149.67832946777344\n",
      "      vf_explained_var: 0.9887034296989441\n",
      "      vf_loss: 149.67910766601562\n",
      "    sample_time_ms: 18649.827\n",
      "    update_time_ms: 5.048\n",
      "  iterations_since_restore: 800\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.71863106653575\n",
      "  time_since_restore: 20020.08637547493\n",
      "  time_this_iter_s: 23.424044609069824\n",
      "  time_total_s: 20020.08637547493\n",
      "  timestamp: 1553729062\n",
      "  timesteps_since_restore: 8000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8000000\n",
      "  training_iteration: 800\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20020 s, 800 iter, 8000000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-24-45\n",
      "  done: false\n",
      "  episode_len_mean: 127.23\n",
      "  episode_reward_max: 790.6319203389947\n",
      "  episode_reward_mean: 695.3665386270401\n",
      "  episode_reward_min: -58.88193296324826\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 59842\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.364\n",
      "    load_time_ms: 1.46\n",
      "    num_steps_sampled: 8010000\n",
      "    num_steps_trained: 8010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7199293375015259\n",
      "      kl: 0.03237926587462425\n",
      "      policy_loss: -0.004592854995280504\n",
      "      total_loss: 551.1946411132812\n",
      "      vf_explained_var: 0.9609329104423523\n",
      "      vf_loss: 551.1987915039062\n",
      "    sample_time_ms: 18745.303\n",
      "    update_time_ms: 5.058\n",
      "  iterations_since_restore: 801\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.68326931352016\n",
      "  time_since_restore: 20043.192742586136\n",
      "  time_this_iter_s: 23.106367111206055\n",
      "  time_total_s: 20043.192742586136\n",
      "  timestamp: 1553729085\n",
      "  timesteps_since_restore: 8010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8010000\n",
      "  training_iteration: 801\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20043 s, 801 iter, 8010000 ts, 695 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-25-08\n",
      "  done: false\n",
      "  episode_len_mean: 127.65\n",
      "  episode_reward_max: 789.807493714227\n",
      "  episode_reward_mean: 686.6143980093896\n",
      "  episode_reward_min: -58.88193296324826\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 59921\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.383\n",
      "    load_time_ms: 1.454\n",
      "    num_steps_sampled: 8020000\n",
      "    num_steps_trained: 8020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5532707571983337\n",
      "      kl: 0.026127992197871208\n",
      "      policy_loss: 1.0471122550370637e-05\n",
      "      total_loss: 224.19300842285156\n",
      "      vf_explained_var: 0.9846872091293335\n",
      "      vf_loss: 224.1927032470703\n",
      "    sample_time_ms: 18839.552\n",
      "    update_time_ms: 4.95\n",
      "  iterations_since_restore: 802\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.307199004695\n",
      "  time_since_restore: 20066.07763171196\n",
      "  time_this_iter_s: 22.884889125823975\n",
      "  time_total_s: 20066.07763171196\n",
      "  timestamp: 1553729108\n",
      "  timesteps_since_restore: 8020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8020000\n",
      "  training_iteration: 802\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20066 s, 802 iter, 8020000 ts, 687 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-25-30\n",
      "  done: false\n",
      "  episode_len_mean: 128.92\n",
      "  episode_reward_max: 787.6335039940426\n",
      "  episode_reward_mean: 700.6131418937919\n",
      "  episode_reward_min: -57.18591167404114\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 59999\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.748\n",
      "    load_time_ms: 1.441\n",
      "    num_steps_sampled: 8030000\n",
      "    num_steps_trained: 8030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6661993265151978\n",
      "      kl: 0.0153057174757123\n",
      "      policy_loss: -0.0017344012157991529\n",
      "      total_loss: 360.5059509277344\n",
      "      vf_explained_var: 0.974254310131073\n",
      "      vf_loss: 360.5074768066406\n",
      "    sample_time_ms: 18774.561\n",
      "    update_time_ms: 4.936\n",
      "  iterations_since_restore: 803\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.30657094689604\n",
      "  time_since_restore: 20088.24052786827\n",
      "  time_this_iter_s: 22.162896156311035\n",
      "  time_total_s: 20088.24052786827\n",
      "  timestamp: 1553729130\n",
      "  timesteps_since_restore: 8030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8030000\n",
      "  training_iteration: 803\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20088 s, 803 iter, 8030000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-25-52\n",
      "  done: false\n",
      "  episode_len_mean: 126.17\n",
      "  episode_reward_max: 800.1491004409145\n",
      "  episode_reward_mean: 713.3142207224325\n",
      "  episode_reward_min: -83.18185282593159\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 60078\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.451\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 8040000\n",
      "    num_steps_trained: 8040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5655195713043213\n",
      "      kl: 0.03861939534544945\n",
      "      policy_loss: -0.0015710594598203897\n",
      "      total_loss: 349.42071533203125\n",
      "      vf_explained_var: 0.9690033197402954\n",
      "      vf_loss: 349.421875\n",
      "    sample_time_ms: 18831.885\n",
      "    update_time_ms: 4.933\n",
      "  iterations_since_restore: 804\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.65711036121627\n",
      "  time_since_restore: 20110.585314035416\n",
      "  time_this_iter_s: 22.344786167144775\n",
      "  time_total_s: 20110.585314035416\n",
      "  timestamp: 1553729152\n",
      "  timesteps_since_restore: 8040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8040000\n",
      "  training_iteration: 804\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20110 s, 804 iter, 8040000 ts, 713 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-26-15\n",
      "  done: false\n",
      "  episode_len_mean: 129.45\n",
      "  episode_reward_max: 792.9005515295726\n",
      "  episode_reward_mean: 713.7651125321051\n",
      "  episode_reward_min: -88.71805822975692\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 60155\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.457\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 8050000\n",
      "    num_steps_trained: 8050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.011939795687794685\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5907096862792969\n",
      "      kl: 0.041855067014694214\n",
      "      policy_loss: 9.14702070531348e-07\n",
      "      total_loss: 197.33457946777344\n",
      "      vf_explained_var: 0.9853357076644897\n",
      "      vf_loss: 197.33407592773438\n",
      "    sample_time_ms: 18782.428\n",
      "    update_time_ms: 5.061\n",
      "  iterations_since_restore: 805\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 356.88255626605263\n",
      "  time_since_restore: 20132.916506528854\n",
      "  time_this_iter_s: 22.33119249343872\n",
      "  time_total_s: 20132.916506528854\n",
      "  timestamp: 1553729175\n",
      "  timesteps_since_restore: 8050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8050000\n",
      "  training_iteration: 805\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20132 s, 805 iter, 8050000 ts, 714 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-26-37\n",
      "  done: false\n",
      "  episode_len_mean: 130.36\n",
      "  episode_reward_max: 792.0269175131627\n",
      "  episode_reward_mean: 732.3023443436177\n",
      "  episode_reward_min: -88.71805822975692\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 60233\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.691\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 8060000\n",
      "    num_steps_trained: 8060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017909692600369453\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6145904660224915\n",
      "      kl: 0.11956354230642319\n",
      "      policy_loss: -0.0013767415657639503\n",
      "      total_loss: 12.102763175964355\n",
      "      vf_explained_var: 0.9991351366043091\n",
      "      vf_loss: 12.101999282836914\n",
      "    sample_time_ms: 18798.661\n",
      "    update_time_ms: 5.187\n",
      "  iterations_since_restore: 806\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 366.15117217180887\n",
      "  time_since_restore: 20154.847683906555\n",
      "  time_this_iter_s: 21.931177377700806\n",
      "  time_total_s: 20154.847683906555\n",
      "  timestamp: 1553729197\n",
      "  timesteps_since_restore: 8060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8060000\n",
      "  training_iteration: 806\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20154 s, 806 iter, 8060000 ts, 732 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-26-59\n",
      "  done: false\n",
      "  episode_len_mean: 127.6\n",
      "  episode_reward_max: 788.667379027772\n",
      "  episode_reward_mean: 725.4150144474737\n",
      "  episode_reward_min: -82.8820678427019\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 60313\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3694.694\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 8070000\n",
      "    num_steps_trained: 8070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.026864541694521904\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4999508559703827\n",
      "      kl: 0.011911342851817608\n",
      "      policy_loss: -0.001415333361364901\n",
      "      total_loss: 100.60101318359375\n",
      "      vf_explained_var: 0.9923219680786133\n",
      "      vf_loss: 100.60210418701172\n",
      "    sample_time_ms: 18793.974\n",
      "    update_time_ms: 5.188\n",
      "  iterations_since_restore: 807\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.70750722373674\n",
      "  time_since_restore: 20177.21112704277\n",
      "  time_this_iter_s: 22.36344313621521\n",
      "  time_total_s: 20177.21112704277\n",
      "  timestamp: 1553729219\n",
      "  timesteps_since_restore: 8070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8070000\n",
      "  training_iteration: 807\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20177 s, 807 iter, 8070000 ts, 725 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-27-21\n",
      "  done: false\n",
      "  episode_len_mean: 124.85\n",
      "  episode_reward_max: 797.4298286054795\n",
      "  episode_reward_mean: 717.4671225862231\n",
      "  episode_reward_min: -82.8820678427019\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 60393\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3696.996\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 8080000\n",
      "    num_steps_trained: 8080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.026864541694521904\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.47927749156951904\n",
      "      kl: 0.016399789601564407\n",
      "      policy_loss: -0.0023303329944610596\n",
      "      total_loss: 88.70439910888672\n",
      "      vf_explained_var: 0.9933967590332031\n",
      "      vf_loss: 88.70629119873047\n",
      "    sample_time_ms: 18709.659\n",
      "    update_time_ms: 5.327\n",
      "  iterations_since_restore: 808\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.73356129311156\n",
      "  time_since_restore: 20199.03599858284\n",
      "  time_this_iter_s: 21.82487154006958\n",
      "  time_total_s: 20199.03599858284\n",
      "  timestamp: 1553729241\n",
      "  timesteps_since_restore: 8080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8080000\n",
      "  training_iteration: 808\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20199 s, 808 iter, 8080000 ts, 717 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-27-44\n",
      "  done: false\n",
      "  episode_len_mean: 126.14\n",
      "  episode_reward_max: 797.4298286054795\n",
      "  episode_reward_mean: 708.2120760000126\n",
      "  episode_reward_min: -111.007628587648\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 60474\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3682.928\n",
      "    load_time_ms: 1.656\n",
      "    num_steps_sampled: 8090000\n",
      "    num_steps_trained: 8090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.026864541694521904\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6207329034805298\n",
      "      kl: 0.03271730616688728\n",
      "      policy_loss: -0.009759108535945415\n",
      "      total_loss: 366.6505432128906\n",
      "      vf_explained_var: 0.9710476994514465\n",
      "      vf_loss: 366.659423828125\n",
      "    sample_time_ms: 18809.759\n",
      "    update_time_ms: 5.283\n",
      "  iterations_since_restore: 809\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.1060380000063\n",
      "  time_since_restore: 20221.851494312286\n",
      "  time_this_iter_s: 22.81549572944641\n",
      "  time_total_s: 20221.851494312286\n",
      "  timestamp: 1553729264\n",
      "  timesteps_since_restore: 8090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8090000\n",
      "  training_iteration: 809\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20221 s, 809 iter, 8090000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-28-06\n",
      "  done: false\n",
      "  episode_len_mean: 126.14\n",
      "  episode_reward_max: 797.3088588714412\n",
      "  episode_reward_mean: 689.1805363624586\n",
      "  episode_reward_min: -111.007628587648\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 60553\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.131\n",
      "    load_time_ms: 1.684\n",
      "    num_steps_sampled: 8100000\n",
      "    num_steps_trained: 8100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.026864541694521904\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6097794771194458\n",
      "      kl: 0.04034211114048958\n",
      "      policy_loss: -0.0012866484466940165\n",
      "      total_loss: 370.87188720703125\n",
      "      vf_explained_var: 0.967529296875\n",
      "      vf_loss: 370.87213134765625\n",
      "    sample_time_ms: 18718.227\n",
      "    update_time_ms: 5.264\n",
      "  iterations_since_restore: 810\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.5902681812293\n",
      "  time_since_restore: 20244.380834817886\n",
      "  time_this_iter_s: 22.529340505599976\n",
      "  time_total_s: 20244.380834817886\n",
      "  timestamp: 1553729286\n",
      "  timesteps_since_restore: 8100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8100000\n",
      "  training_iteration: 810\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20244 s, 810 iter, 8100000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-28-29\n",
      "  done: false\n",
      "  episode_len_mean: 129.15\n",
      "  episode_reward_max: 780.6784261569171\n",
      "  episode_reward_mean: 706.3686541491013\n",
      "  episode_reward_min: -103.17283110255867\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 60629\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3684.431\n",
      "    load_time_ms: 1.746\n",
      "    num_steps_sampled: 8110000\n",
      "    num_steps_trained: 8110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7023762464523315\n",
      "      kl: 0.03321462497115135\n",
      "      policy_loss: -0.0042956252582371235\n",
      "      total_loss: 148.16200256347656\n",
      "      vf_explained_var: 0.9888808131217957\n",
      "      vf_loss: 148.1649627685547\n",
      "    sample_time_ms: 18634.386\n",
      "    update_time_ms: 5.34\n",
      "  iterations_since_restore: 811\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.1843270745508\n",
      "  time_since_restore: 20266.642113685608\n",
      "  time_this_iter_s: 22.261278867721558\n",
      "  time_total_s: 20266.642113685608\n",
      "  timestamp: 1553729309\n",
      "  timesteps_since_restore: 8110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8110000\n",
      "  training_iteration: 811\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20266 s, 811 iter, 8110000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-28-51\n",
      "  done: false\n",
      "  episode_len_mean: 128.27\n",
      "  episode_reward_max: 785.7744614529548\n",
      "  episode_reward_mean: 718.9035081091043\n",
      "  episode_reward_min: -69.43385831705882\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 60709\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3683.509\n",
      "    load_time_ms: 1.753\n",
      "    num_steps_sampled: 8120000\n",
      "    num_steps_trained: 8120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.55238938331604\n",
      "      kl: 0.013116464950144291\n",
      "      policy_loss: -0.0016595539636909962\n",
      "      total_loss: 139.93569946289062\n",
      "      vf_explained_var: 0.9885464310646057\n",
      "      vf_loss: 139.93682861328125\n",
      "    sample_time_ms: 18559.721\n",
      "    update_time_ms: 5.472\n",
      "  iterations_since_restore: 812\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.45175405455217\n",
      "  time_since_restore: 20288.774322271347\n",
      "  time_this_iter_s: 22.132208585739136\n",
      "  time_total_s: 20288.774322271347\n",
      "  timestamp: 1553729331\n",
      "  timesteps_since_restore: 8120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8120000\n",
      "  training_iteration: 812\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20288 s, 812 iter, 8120000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-29-12\n",
      "  done: false\n",
      "  episode_len_mean: 127.84\n",
      "  episode_reward_max: 795.28405018717\n",
      "  episode_reward_mean: 719.1022728242522\n",
      "  episode_reward_min: -69.43385831705882\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 60787\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3685.223\n",
      "    load_time_ms: 1.744\n",
      "    num_steps_sampled: 8130000\n",
      "    num_steps_trained: 8130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.54522305727005\n",
      "      kl: 0.01911117136478424\n",
      "      policy_loss: -0.0009165527299046516\n",
      "      total_loss: 89.07469177246094\n",
      "      vf_explained_var: 0.9928497076034546\n",
      "      vf_loss: 89.07483673095703\n",
      "    sample_time_ms: 18487.629\n",
      "    update_time_ms: 5.535\n",
      "  iterations_since_restore: 813\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.55113641212614\n",
      "  time_since_restore: 20310.23388695717\n",
      "  time_this_iter_s: 21.459564685821533\n",
      "  time_total_s: 20310.23388695717\n",
      "  timestamp: 1553729352\n",
      "  timesteps_since_restore: 8130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8130000\n",
      "  training_iteration: 813\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20310 s, 813 iter, 8130000 ts, 719 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-29-35\n",
      "  done: false\n",
      "  episode_len_mean: 127.66\n",
      "  episode_reward_max: 795.28405018717\n",
      "  episode_reward_mean: 682.5532261091972\n",
      "  episode_reward_min: -86.52531412520084\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 60866\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3680.662\n",
      "    load_time_ms: 1.764\n",
      "    num_steps_sampled: 8140000\n",
      "    num_steps_trained: 8140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8501510620117188\n",
      "      kl: 0.01959763653576374\n",
      "      policy_loss: -0.003990530036389828\n",
      "      total_loss: 729.5357666015625\n",
      "      vf_explained_var: 0.9542869329452515\n",
      "      vf_loss: 729.5389404296875\n",
      "    sample_time_ms: 18565.277\n",
      "    update_time_ms: 5.647\n",
      "  iterations_since_restore: 814\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.2766130545987\n",
      "  time_since_restore: 20333.311104297638\n",
      "  time_this_iter_s: 23.07721734046936\n",
      "  time_total_s: 20333.311104297638\n",
      "  timestamp: 1553729375\n",
      "  timesteps_since_restore: 8140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8140000\n",
      "  training_iteration: 814\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20333 s, 814 iter, 8140000 ts, 683 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-29-58\n",
      "  done: false\n",
      "  episode_len_mean: 129.63\n",
      "  episode_reward_max: 794.9652601468175\n",
      "  episode_reward_mean: 722.4952404650437\n",
      "  episode_reward_min: -66.48483762549989\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 60943\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3697.232\n",
      "    load_time_ms: 1.767\n",
      "    num_steps_sampled: 8150000\n",
      "    num_steps_trained: 8150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5811297297477722\n",
      "      kl: 0.016918551176786423\n",
      "      policy_loss: -0.0047221314162015915\n",
      "      total_loss: 148.75294494628906\n",
      "      vf_explained_var: 0.9900618195533752\n",
      "      vf_loss: 148.75697326660156\n",
      "    sample_time_ms: 18554.754\n",
      "    update_time_ms: 5.527\n",
      "  iterations_since_restore: 815\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.24762023252185\n",
      "  time_since_restore: 20355.700023412704\n",
      "  time_this_iter_s: 22.38891911506653\n",
      "  time_total_s: 20355.700023412704\n",
      "  timestamp: 1553729398\n",
      "  timesteps_since_restore: 8150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8150000\n",
      "  training_iteration: 815\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20355 s, 815 iter, 8150000 ts, 722 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-30-20\n",
      "  done: false\n",
      "  episode_len_mean: 125.41\n",
      "  episode_reward_max: 789.4139571238549\n",
      "  episode_reward_mean: 723.0691368593415\n",
      "  episode_reward_min: -59.68762790924754\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 61023\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.69\n",
      "    load_time_ms: 1.789\n",
      "    num_steps_sampled: 8160000\n",
      "    num_steps_trained: 8160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5372554063796997\n",
      "      kl: 0.021437183022499084\n",
      "      policy_loss: -0.002789940219372511\n",
      "      total_loss: 315.6877136230469\n",
      "      vf_explained_var: 0.9729675054550171\n",
      "      vf_loss: 315.6896667480469\n",
      "    sample_time_ms: 18589.689\n",
      "    update_time_ms: 5.511\n",
      "  iterations_since_restore: 816\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.53456842967074\n",
      "  time_since_restore: 20378.063604831696\n",
      "  time_this_iter_s: 22.36358141899109\n",
      "  time_total_s: 20378.063604831696\n",
      "  timestamp: 1553729420\n",
      "  timesteps_since_restore: 8160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8160000\n",
      "  training_iteration: 816\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20378 s, 816 iter, 8160000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-30-43\n",
      "  done: false\n",
      "  episode_len_mean: 125.08\n",
      "  episode_reward_max: 789.0527529850583\n",
      "  episode_reward_mean: 702.5277151487354\n",
      "  episode_reward_min: -61.307370212494504\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 61103\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.556\n",
      "    load_time_ms: 1.746\n",
      "    num_steps_sampled: 8170000\n",
      "    num_steps_trained: 8170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5161011219024658\n",
      "      kl: 0.016081348061561584\n",
      "      policy_loss: -0.0027619600296020508\n",
      "      total_loss: 194.66339111328125\n",
      "      vf_explained_var: 0.9839816093444824\n",
      "      vf_loss: 194.66551208496094\n",
      "    sample_time_ms: 18639.829\n",
      "    update_time_ms: 5.65\n",
      "  iterations_since_restore: 817\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.2638575743679\n",
      "  time_since_restore: 20400.99051976204\n",
      "  time_this_iter_s: 22.926914930343628\n",
      "  time_total_s: 20400.99051976204\n",
      "  timestamp: 1553729443\n",
      "  timesteps_since_restore: 8170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8170000\n",
      "  training_iteration: 817\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20400 s, 817 iter, 8170000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-31-06\n",
      "  done: false\n",
      "  episode_len_mean: 128.27\n",
      "  episode_reward_max: 789.0527529850583\n",
      "  episode_reward_mean: 719.8950367126931\n",
      "  episode_reward_min: -61.307370212494504\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 61180\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.102\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 8180000\n",
      "    num_steps_trained: 8180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6957013010978699\n",
      "      kl: 0.019170580431818962\n",
      "      policy_loss: -0.0012771186884492636\n",
      "      total_loss: 138.62986755371094\n",
      "      vf_explained_var: 0.9881728887557983\n",
      "      vf_loss: 138.63037109375\n",
      "    sample_time_ms: 18725.074\n",
      "    update_time_ms: 5.47\n",
      "  iterations_since_restore: 818\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.94751835634656\n",
      "  time_since_restore: 20423.668994903564\n",
      "  time_this_iter_s: 22.67847514152527\n",
      "  time_total_s: 20423.668994903564\n",
      "  timestamp: 1553729466\n",
      "  timesteps_since_restore: 8180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8180000\n",
      "  training_iteration: 818\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20423 s, 818 iter, 8180000 ts, 720 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-31-29\n",
      "  done: false\n",
      "  episode_len_mean: 131.26\n",
      "  episode_reward_max: 795.586675675915\n",
      "  episode_reward_mean: 692.1302474525836\n",
      "  episode_reward_min: -102.37850675527984\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 61258\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.294\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 8190000\n",
      "    num_steps_trained: 8190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7686121463775635\n",
      "      kl: 0.017846904695034027\n",
      "      policy_loss: -0.0006329421303234994\n",
      "      total_loss: 532.5147094726562\n",
      "      vf_explained_var: 0.9646670818328857\n",
      "      vf_loss: 532.5146484375\n",
      "    sample_time_ms: 18738.348\n",
      "    update_time_ms: 5.654\n",
      "  iterations_since_restore: 819\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.0651237262917\n",
      "  time_since_restore: 20446.69129061699\n",
      "  time_this_iter_s: 23.022295713424683\n",
      "  time_total_s: 20446.69129061699\n",
      "  timestamp: 1553729489\n",
      "  timesteps_since_restore: 8190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8190000\n",
      "  training_iteration: 819\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20446 s, 819 iter, 8190000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-31-51\n",
      "  done: false\n",
      "  episode_len_mean: 130.02\n",
      "  episode_reward_max: 795.586675675915\n",
      "  episode_reward_mean: 700.6889892713932\n",
      "  episode_reward_min: -102.37850675527984\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 61336\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.732\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 8200000\n",
      "    num_steps_trained: 8200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5670694708824158\n",
      "      kl: 0.032184913754463196\n",
      "      policy_loss: -0.0004810545651707798\n",
      "      total_loss: 204.39979553222656\n",
      "      vf_explained_var: 0.9813966155052185\n",
      "      vf_loss: 204.3989715576172\n",
      "    sample_time_ms: 18718.373\n",
      "    update_time_ms: 5.682\n",
      "  iterations_since_restore: 820\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.34449463569655\n",
      "  time_since_restore: 20469.022708177567\n",
      "  time_this_iter_s: 22.331417560577393\n",
      "  time_total_s: 20469.022708177567\n",
      "  timestamp: 1553729511\n",
      "  timesteps_since_restore: 8200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8200000\n",
      "  training_iteration: 820\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20469 s, 820 iter, 8200000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-32-14\n",
      "  done: false\n",
      "  episode_len_mean: 127.25\n",
      "  episode_reward_max: 792.4822029689013\n",
      "  episode_reward_mean: 704.7811339756554\n",
      "  episode_reward_min: -115.46797208770958\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 61416\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.519\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 8210000\n",
      "    num_steps_trained: 8210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5346765518188477\n",
      "      kl: 0.03435913845896721\n",
      "      policy_loss: -0.0008881334797479212\n",
      "      total_loss: 330.0859375\n",
      "      vf_explained_var: 0.9736307859420776\n",
      "      vf_loss: 330.08544921875\n",
      "    sample_time_ms: 18727.464\n",
      "    update_time_ms: 5.552\n",
      "  iterations_since_restore: 821\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.3905669878277\n",
      "  time_since_restore: 20491.38563656807\n",
      "  time_this_iter_s: 22.36292839050293\n",
      "  time_total_s: 20491.38563656807\n",
      "  timestamp: 1553729534\n",
      "  timesteps_since_restore: 8210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8210000\n",
      "  training_iteration: 821\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20491 s, 821 iter, 8210000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-32-36\n",
      "  done: false\n",
      "  episode_len_mean: 127.96\n",
      "  episode_reward_max: 784.2891205001138\n",
      "  episode_reward_mean: 710.3794092965204\n",
      "  episode_reward_min: -74.06623032984064\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 61495\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.803\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 8220000\n",
      "    num_steps_trained: 8220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5674586296081543\n",
      "      kl: 0.01980740576982498\n",
      "      policy_loss: -0.004697486292570829\n",
      "      total_loss: 156.53892517089844\n",
      "      vf_explained_var: 0.9882595539093018\n",
      "      vf_loss: 156.54281616210938\n",
      "    sample_time_ms: 18773.744\n",
      "    update_time_ms: 5.593\n",
      "  iterations_since_restore: 822\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.1897046482602\n",
      "  time_since_restore: 20514.00441980362\n",
      "  time_this_iter_s: 22.618783235549927\n",
      "  time_total_s: 20514.00441980362\n",
      "  timestamp: 1553729556\n",
      "  timesteps_since_restore: 8220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8220000\n",
      "  training_iteration: 822\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20514 s, 822 iter, 8220000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-32-59\n",
      "  done: false\n",
      "  episode_len_mean: 125.36\n",
      "  episode_reward_max: 784.5018795115261\n",
      "  episode_reward_mean: 689.1967616462728\n",
      "  episode_reward_min: -118.8962392565449\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 61575\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.21\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 8230000\n",
      "    num_steps_trained: 8230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8005508184432983\n",
      "      kl: 0.021931443363428116\n",
      "      policy_loss: -0.0016287412727251649\n",
      "      total_loss: 425.8318786621094\n",
      "      vf_explained_var: 0.9720011949539185\n",
      "      vf_loss: 425.8326416015625\n",
      "    sample_time_ms: 18877.034\n",
      "    update_time_ms: 5.52\n",
      "  iterations_since_restore: 823\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.5983808231364\n",
      "  time_since_restore: 20536.48973751068\n",
      "  time_this_iter_s: 22.485317707061768\n",
      "  time_total_s: 20536.48973751068\n",
      "  timestamp: 1553729579\n",
      "  timesteps_since_restore: 8230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8230000\n",
      "  training_iteration: 823\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20536 s, 823 iter, 8230000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-33-21\n",
      "  done: false\n",
      "  episode_len_mean: 127.63\n",
      "  episode_reward_max: 785.8236052637874\n",
      "  episode_reward_mean: 666.2554811038254\n",
      "  episode_reward_min: -118.8962392565449\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 61653\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3728.293\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 8240000\n",
      "    num_steps_trained: 8240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6554533839225769\n",
      "      kl: 0.018383890390396118\n",
      "      policy_loss: -0.003967620898038149\n",
      "      total_loss: 257.0506896972656\n",
      "      vf_explained_var: 0.9799534678459167\n",
      "      vf_loss: 257.0539245605469\n",
      "    sample_time_ms: 18759.461\n",
      "    update_time_ms: 5.4\n",
      "  iterations_since_restore: 824\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 333.12774055191267\n",
      "  time_since_restore: 20558.453134059906\n",
      "  time_this_iter_s: 21.963396549224854\n",
      "  time_total_s: 20558.453134059906\n",
      "  timestamp: 1553729601\n",
      "  timesteps_since_restore: 8240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8240000\n",
      "  training_iteration: 824\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20558 s, 824 iter, 8240000 ts, 666 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-33-44\n",
      "  done: false\n",
      "  episode_len_mean: 129.48\n",
      "  episode_reward_max: 788.891071304809\n",
      "  episode_reward_mean: 698.7957711654794\n",
      "  episode_reward_min: -102.14761858302407\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 61731\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.207\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 8250000\n",
      "    num_steps_trained: 8250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6788041591644287\n",
      "      kl: 0.023733196780085564\n",
      "      policy_loss: -0.003396922955289483\n",
      "      total_loss: 332.18414306640625\n",
      "      vf_explained_var: 0.9748202562332153\n",
      "      vf_loss: 332.18658447265625\n",
      "    sample_time_ms: 18808.338\n",
      "    update_time_ms: 5.481\n",
      "  iterations_since_restore: 825\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.3978855827397\n",
      "  time_since_restore: 20581.165120840073\n",
      "  time_this_iter_s: 22.711986780166626\n",
      "  time_total_s: 20581.165120840073\n",
      "  timestamp: 1553729624\n",
      "  timesteps_since_restore: 8250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8250000\n",
      "  training_iteration: 825\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20581 s, 825 iter, 8250000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-34-06\n",
      "  done: false\n",
      "  episode_len_mean: 129.99\n",
      "  episode_reward_max: 790.0479548094617\n",
      "  episode_reward_mean: 709.2384681236741\n",
      "  episode_reward_min: -102.14761858302407\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 61808\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.295\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 8260000\n",
      "    num_steps_trained: 8260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5898267030715942\n",
      "      kl: 0.02336929365992546\n",
      "      policy_loss: -0.0009959813905879855\n",
      "      total_loss: 64.96463012695312\n",
      "      vf_explained_var: 0.9948139786720276\n",
      "      vf_loss: 64.96469116210938\n",
      "    sample_time_ms: 18846.091\n",
      "    update_time_ms: 5.465\n",
      "  iterations_since_restore: 826\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.61923406183706\n",
      "  time_since_restore: 20603.887263536453\n",
      "  time_this_iter_s: 22.722142696380615\n",
      "  time_total_s: 20603.887263536453\n",
      "  timestamp: 1553729646\n",
      "  timesteps_since_restore: 8260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8260000\n",
      "  training_iteration: 826\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20603 s, 826 iter, 8260000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-34-29\n",
      "  done: false\n",
      "  episode_len_mean: 130.65\n",
      "  episode_reward_max: 798.2989704931399\n",
      "  episode_reward_mean: 727.3715459872598\n",
      "  episode_reward_min: -50.05443658515591\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 61886\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.893\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 8270000\n",
      "    num_steps_trained: 8270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5461153984069824\n",
      "      kl: 0.016482790932059288\n",
      "      policy_loss: -0.0060424176044762135\n",
      "      total_loss: 187.61874389648438\n",
      "      vf_explained_var: 0.9840453863143921\n",
      "      vf_loss: 187.62411499023438\n",
      "    sample_time_ms: 18774.076\n",
      "    update_time_ms: 5.348\n",
      "  iterations_since_restore: 827\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 363.68577299362994\n",
      "  time_since_restore: 20626.064867019653\n",
      "  time_this_iter_s: 22.177603483200073\n",
      "  time_total_s: 20626.064867019653\n",
      "  timestamp: 1553729669\n",
      "  timesteps_since_restore: 8270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8270000\n",
      "  training_iteration: 827\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20626 s, 827 iter, 8270000 ts, 727 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-34-50\n",
      "  done: false\n",
      "  episode_len_mean: 127.22\n",
      "  episode_reward_max: 795.9814290050433\n",
      "  episode_reward_mean: 726.2319209782638\n",
      "  episode_reward_min: -60.381814516392126\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 61966\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.638\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 8280000\n",
      "    num_steps_trained: 8280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5288255214691162\n",
      "      kl: 0.017893608659505844\n",
      "      policy_loss: -0.0014619833091273904\n",
      "      total_loss: 239.98187255859375\n",
      "      vf_explained_var: 0.9799422025680542\n",
      "      vf_loss: 239.982666015625\n",
      "    sample_time_ms: 18627.122\n",
      "    update_time_ms: 5.358\n",
      "  iterations_since_restore: 828\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 363.11596048913196\n",
      "  time_since_restore: 20647.281923532486\n",
      "  time_this_iter_s: 21.21705651283264\n",
      "  time_total_s: 20647.281923532486\n",
      "  timestamp: 1553729690\n",
      "  timesteps_since_restore: 8280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8280000\n",
      "  training_iteration: 828\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20647 s, 828 iter, 8280000 ts, 726 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-35-12\n",
      "  done: false\n",
      "  episode_len_mean: 128.32\n",
      "  episode_reward_max: 788.8173326690483\n",
      "  episode_reward_mean: 716.400194120106\n",
      "  episode_reward_min: -89.32422789821106\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 62044\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.179\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 8290000\n",
      "    num_steps_trained: 8290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.582220196723938\n",
      "      kl: 0.021173739805817604\n",
      "      policy_loss: 0.0011693942360579967\n",
      "      total_loss: 195.38070678710938\n",
      "      vf_explained_var: 0.9861918687820435\n",
      "      vf_loss: 195.3787078857422\n",
      "    sample_time_ms: 18502.906\n",
      "    update_time_ms: 5.265\n",
      "  iterations_since_restore: 829\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.2000970600531\n",
      "  time_since_restore: 20669.00293660164\n",
      "  time_this_iter_s: 21.721013069152832\n",
      "  time_total_s: 20669.00293660164\n",
      "  timestamp: 1553729712\n",
      "  timesteps_since_restore: 8290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8290000\n",
      "  training_iteration: 829\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20669 s, 829 iter, 8290000 ts, 716 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-35-34\n",
      "  done: false\n",
      "  episode_len_mean: 126.65\n",
      "  episode_reward_max: 787.172102520805\n",
      "  episode_reward_mean: 695.5422141692724\n",
      "  episode_reward_min: -89.32422789821106\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 62123\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.172\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 8300000\n",
      "    num_steps_trained: 8300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5919728875160217\n",
      "      kl: 0.01550345215946436\n",
      "      policy_loss: -0.00045425997814163566\n",
      "      total_loss: 301.4422607421875\n",
      "      vf_explained_var: 0.9778985977172852\n",
      "      vf_loss: 301.4420471191406\n",
      "    sample_time_ms: 18487.84\n",
      "    update_time_ms: 5.725\n",
      "  iterations_since_restore: 830\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.7711070846362\n",
      "  time_since_restore: 20691.212884426117\n",
      "  time_this_iter_s: 22.20994782447815\n",
      "  time_total_s: 20691.212884426117\n",
      "  timestamp: 1553729734\n",
      "  timesteps_since_restore: 8300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8300000\n",
      "  training_iteration: 830\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20691 s, 830 iter, 8300000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-35-56\n",
      "  done: false\n",
      "  episode_len_mean: 130.46\n",
      "  episode_reward_max: 787.172102520805\n",
      "  episode_reward_mean: 696.458049883675\n",
      "  episode_reward_min: -99.60310183246575\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 62199\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.913\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 8310000\n",
      "    num_steps_trained: 8310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6837502717971802\n",
      "      kl: 0.015731560066342354\n",
      "      policy_loss: -0.0002486180455889553\n",
      "      total_loss: 171.1188201904297\n",
      "      vf_explained_var: 0.9861473441123962\n",
      "      vf_loss: 171.11842346191406\n",
      "    sample_time_ms: 18394.106\n",
      "    update_time_ms: 5.798\n",
      "  iterations_since_restore: 831\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.2290249418375\n",
      "  time_since_restore: 20712.83180809021\n",
      "  time_this_iter_s: 21.618923664093018\n",
      "  time_total_s: 20712.83180809021\n",
      "  timestamp: 1553729756\n",
      "  timesteps_since_restore: 8310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8310000\n",
      "  training_iteration: 831\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20712 s, 831 iter, 8310000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-36-17\n",
      "  done: false\n",
      "  episode_len_mean: 127.39\n",
      "  episode_reward_max: 787.7415256515944\n",
      "  episode_reward_mean: 688.5423200143753\n",
      "  episode_reward_min: -125.26934704440968\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 62281\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.365\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 8320000\n",
      "    num_steps_trained: 8320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04029681161046028\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5402395725250244\n",
      "      kl: 0.05178169161081314\n",
      "      policy_loss: -0.008509962819516659\n",
      "      total_loss: 631.6228637695312\n",
      "      vf_explained_var: 0.9543846249580383\n",
      "      vf_loss: 631.6292724609375\n",
      "    sample_time_ms: 18315.664\n",
      "    update_time_ms: 5.65\n",
      "  iterations_since_restore: 832\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.27116000718763\n",
      "  time_since_restore: 20734.646654367447\n",
      "  time_this_iter_s: 21.81484627723694\n",
      "  time_total_s: 20734.646654367447\n",
      "  timestamp: 1553729777\n",
      "  timesteps_since_restore: 8320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8320000\n",
      "  training_iteration: 832\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20734 s, 832 iter, 8320000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-36-39\n",
      "  done: false\n",
      "  episode_len_mean: 127.13\n",
      "  episode_reward_max: 799.3119599078617\n",
      "  episode_reward_mean: 724.4555038825637\n",
      "  episode_reward_min: -96.08318337534\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 62360\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.671\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 8330000\n",
      "    num_steps_trained: 8330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.37106823921203613\n",
      "      kl: 0.02059192582964897\n",
      "      policy_loss: -0.00514483917504549\n",
      "      total_loss: 103.8716812133789\n",
      "      vf_explained_var: 0.9920979142189026\n",
      "      vf_loss: 103.87556457519531\n",
      "    sample_time_ms: 18232.084\n",
      "    update_time_ms: 5.592\n",
      "  iterations_since_restore: 833\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 362.2277519412819\n",
      "  time_since_restore: 20756.29945540428\n",
      "  time_this_iter_s: 21.652801036834717\n",
      "  time_total_s: 20756.29945540428\n",
      "  timestamp: 1553729799\n",
      "  timesteps_since_restore: 8330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8330000\n",
      "  training_iteration: 833\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20756 s, 833 iter, 8330000 ts, 724 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-37-02\n",
      "  done: false\n",
      "  episode_len_mean: 128.09\n",
      "  episode_reward_max: 786.5245622271106\n",
      "  episode_reward_mean: 711.9671455801827\n",
      "  episode_reward_min: -62.96051614468959\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 62439\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.369\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 8340000\n",
      "    num_steps_trained: 8340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5676358342170715\n",
      "      kl: 0.021126123145222664\n",
      "      policy_loss: -0.0042784009128808975\n",
      "      total_loss: 239.75250244140625\n",
      "      vf_explained_var: 0.9828622341156006\n",
      "      vf_loss: 239.75550842285156\n",
      "    sample_time_ms: 18270.874\n",
      "    update_time_ms: 5.641\n",
      "  iterations_since_restore: 834\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.9835727900913\n",
      "  time_since_restore: 20778.65011882782\n",
      "  time_this_iter_s: 22.350663423538208\n",
      "  time_total_s: 20778.65011882782\n",
      "  timestamp: 1553729822\n",
      "  timesteps_since_restore: 8340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8340000\n",
      "  training_iteration: 834\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20778 s, 834 iter, 8340000 ts, 712 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-37-24\n",
      "  done: false\n",
      "  episode_len_mean: 130.24\n",
      "  episode_reward_max: 786.5706128942085\n",
      "  episode_reward_mean: 692.4950738049888\n",
      "  episode_reward_min: -82.61415703309224\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 62516\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3733.063\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 8350000\n",
      "    num_steps_trained: 8350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.727782130241394\n",
      "      kl: 0.015714382752776146\n",
      "      policy_loss: -0.0004772580286953598\n",
      "      total_loss: 418.5078125\n",
      "      vf_explained_var: 0.9709237813949585\n",
      "      vf_loss: 418.5073547363281\n",
      "    sample_time_ms: 18198.289\n",
      "    update_time_ms: 5.584\n",
      "  iterations_since_restore: 835\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.24753690249435\n",
      "  time_since_restore: 20800.73357439041\n",
      "  time_this_iter_s: 22.083455562591553\n",
      "  time_total_s: 20800.73357439041\n",
      "  timestamp: 1553729844\n",
      "  timesteps_since_restore: 8350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8350000\n",
      "  training_iteration: 835\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20800 s, 835 iter, 8350000 ts, 692 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-37-45\n",
      "  done: false\n",
      "  episode_len_mean: 129.79\n",
      "  episode_reward_max: 797.5141536332383\n",
      "  episode_reward_mean: 684.0978988258\n",
      "  episode_reward_min: -97.23643593790042\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 62594\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.317\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 8360000\n",
      "    num_steps_trained: 8360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5602695941925049\n",
      "      kl: 0.02168823964893818\n",
      "      policy_loss: -0.0036273610312491655\n",
      "      total_loss: 281.2252197265625\n",
      "      vf_explained_var: 0.9801933169364929\n",
      "      vf_loss: 281.2275085449219\n",
      "    sample_time_ms: 18061.44\n",
      "    update_time_ms: 5.479\n",
      "  iterations_since_restore: 836\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.04894941289996\n",
      "  time_since_restore: 20822.04673719406\n",
      "  time_this_iter_s: 21.313162803649902\n",
      "  time_total_s: 20822.04673719406\n",
      "  timestamp: 1553729865\n",
      "  timesteps_since_restore: 8360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8360000\n",
      "  training_iteration: 836\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20822 s, 836 iter, 8360000 ts, 684 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-38-07\n",
      "  done: false\n",
      "  episode_len_mean: 129.37\n",
      "  episode_reward_max: 793.5559325621545\n",
      "  episode_reward_mean: 708.0480159117968\n",
      "  episode_reward_min: -97.23643593790042\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 62671\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.784\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 8370000\n",
      "    num_steps_trained: 8370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7875550985336304\n",
      "      kl: 0.01747029833495617\n",
      "      policy_loss: -0.0013531058793887496\n",
      "      total_loss: 183.73223876953125\n",
      "      vf_explained_var: 0.986405611038208\n",
      "      vf_loss: 183.73252868652344\n",
      "    sample_time_ms: 18068.601\n",
      "    update_time_ms: 5.506\n",
      "  iterations_since_restore: 837\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.0240079558984\n",
      "  time_since_restore: 20844.30690741539\n",
      "  time_this_iter_s: 22.260170221328735\n",
      "  time_total_s: 20844.30690741539\n",
      "  timestamp: 1553729887\n",
      "  timesteps_since_restore: 8370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8370000\n",
      "  training_iteration: 837\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20844 s, 837 iter, 8370000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 137.78\n",
      "  episode_reward_max: 794.735737969957\n",
      "  episode_reward_mean: 682.873353552274\n",
      "  episode_reward_min: -90.52406769761458\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 62743\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.052\n",
      "    load_time_ms: 1.575\n",
      "    num_steps_sampled: 8380000\n",
      "    num_steps_trained: 8380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.026487112045288\n",
      "      kl: 0.0241770688444376\n",
      "      policy_loss: -0.0026223817840218544\n",
      "      total_loss: 522.970947265625\n",
      "      vf_explained_var: 0.9654051661491394\n",
      "      vf_loss: 522.9721069335938\n",
      "    sample_time_ms: 18165.792\n",
      "    update_time_ms: 5.488\n",
      "  iterations_since_restore: 838\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.436676776137\n",
      "  time_since_restore: 20866.499173879623\n",
      "  time_this_iter_s: 22.1922664642334\n",
      "  time_total_s: 20866.499173879623\n",
      "  timestamp: 1553729910\n",
      "  timesteps_since_restore: 8380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8380000\n",
      "  training_iteration: 838\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20866 s, 838 iter, 8380000 ts, 683 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-38-52\n",
      "  done: false\n",
      "  episode_len_mean: 134.11\n",
      "  episode_reward_max: 786.1485134551368\n",
      "  episode_reward_mean: 696.3629614010126\n",
      "  episode_reward_min: -60.70724519704828\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 62822\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.891\n",
      "    load_time_ms: 1.624\n",
      "    num_steps_sampled: 8390000\n",
      "    num_steps_trained: 8390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5281617641448975\n",
      "      kl: 0.01748107559978962\n",
      "      policy_loss: -0.0015062510501593351\n",
      "      total_loss: 131.51551818847656\n",
      "      vf_explained_var: 0.9906405210494995\n",
      "      vf_loss: 131.51597595214844\n",
      "    sample_time_ms: 18191.742\n",
      "    update_time_ms: 5.439\n",
      "  iterations_since_restore: 839\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.18148070050637\n",
      "  time_since_restore: 20888.460080623627\n",
      "  time_this_iter_s: 21.960906744003296\n",
      "  time_total_s: 20888.460080623627\n",
      "  timestamp: 1553729932\n",
      "  timesteps_since_restore: 8390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8390000\n",
      "  training_iteration: 839\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20888 s, 839 iter, 8390000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-39-14\n",
      "  done: false\n",
      "  episode_len_mean: 133.62\n",
      "  episode_reward_max: 784.9596688718659\n",
      "  episode_reward_mean: 682.4236438420058\n",
      "  episode_reward_min: -68.55217408435917\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 62897\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.617\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 8400000\n",
      "    num_steps_trained: 8400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8214589357376099\n",
      "      kl: 0.019322071224451065\n",
      "      policy_loss: -0.0002638903970364481\n",
      "      total_loss: 402.1430969238281\n",
      "      vf_explained_var: 0.9768850803375244\n",
      "      vf_loss: 402.1422119140625\n",
      "    sample_time_ms: 18178.759\n",
      "    update_time_ms: 5.158\n",
      "  iterations_since_restore: 840\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.21182192100287\n",
      "  time_since_restore: 20910.49184679985\n",
      "  time_this_iter_s: 22.031766176223755\n",
      "  time_total_s: 20910.49184679985\n",
      "  timestamp: 1553729954\n",
      "  timesteps_since_restore: 8400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8400000\n",
      "  training_iteration: 840\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20910 s, 840 iter, 8400000 ts, 682 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-39-36\n",
      "  done: false\n",
      "  episode_len_mean: 135.54\n",
      "  episode_reward_max: 799.95753760373\n",
      "  episode_reward_mean: 684.0578791529435\n",
      "  episode_reward_min: -77.22088274303263\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 62974\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3703.81\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 8410000\n",
      "    num_steps_trained: 8410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06044521555304527\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6253944039344788\n",
      "      kl: 0.08670144528150558\n",
      "      policy_loss: -0.0006046795751899481\n",
      "      total_loss: 267.11328125\n",
      "      vf_explained_var: 0.9808398485183716\n",
      "      vf_loss: 267.1086730957031\n",
      "    sample_time_ms: 18265.194\n",
      "    update_time_ms: 5.089\n",
      "  iterations_since_restore: 841\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.02893957647177\n",
      "  time_since_restore: 20932.77783870697\n",
      "  time_this_iter_s: 22.28599190711975\n",
      "  time_total_s: 20932.77783870697\n",
      "  timestamp: 1553729976\n",
      "  timesteps_since_restore: 8410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8410000\n",
      "  training_iteration: 841\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20932 s, 841 iter, 8410000 ts, 684 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-39-58\n",
      "  done: false\n",
      "  episode_len_mean: 127.71\n",
      "  episode_reward_max: 797.2251157511294\n",
      "  episode_reward_mean: 714.9392277966748\n",
      "  episode_reward_min: -80.68397039824517\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 63052\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.853\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 8420000\n",
      "    num_steps_trained: 8420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5156921148300171\n",
      "      kl: 0.01919718272984028\n",
      "      policy_loss: -0.004874874837696552\n",
      "      total_loss: 292.2252502441406\n",
      "      vf_explained_var: 0.9756994247436523\n",
      "      vf_loss: 292.2283935546875\n",
      "    sample_time_ms: 18320.647\n",
      "    update_time_ms: 5.171\n",
      "  iterations_since_restore: 842\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.4696138983374\n",
      "  time_since_restore: 20955.220296144485\n",
      "  time_this_iter_s: 22.44245743751526\n",
      "  time_total_s: 20955.220296144485\n",
      "  timestamp: 1553729998\n",
      "  timesteps_since_restore: 8420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8420000\n",
      "  training_iteration: 842\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20955 s, 842 iter, 8420000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-40-20\n",
      "  done: false\n",
      "  episode_len_mean: 128.94\n",
      "  episode_reward_max: 796.2486361383051\n",
      "  episode_reward_mean: 720.644412066269\n",
      "  episode_reward_min: -71.12809002155927\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 63131\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.584\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 8430000\n",
      "    num_steps_trained: 8430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6785098910331726\n",
      "      kl: 0.015653852373361588\n",
      "      policy_loss: -0.00023755268193781376\n",
      "      total_loss: 203.92539978027344\n",
      "      vf_explained_var: 0.9834103584289551\n",
      "      vf_loss: 203.92420959472656\n",
      "    sample_time_ms: 18351.651\n",
      "    update_time_ms: 5.197\n",
      "  iterations_since_restore: 843\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 360.3222060331345\n",
      "  time_since_restore: 20977.153282642365\n",
      "  time_this_iter_s: 21.93298649787903\n",
      "  time_total_s: 20977.153282642365\n",
      "  timestamp: 1553730020\n",
      "  timesteps_since_restore: 8430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8430000\n",
      "  training_iteration: 843\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20977 s, 843 iter, 8430000 ts, 721 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-40-43\n",
      "  done: false\n",
      "  episode_len_mean: 131.14\n",
      "  episode_reward_max: 796.2486361383051\n",
      "  episode_reward_mean: 699.9110435273819\n",
      "  episode_reward_min: -71.12809002155927\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 63207\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.181\n",
      "    load_time_ms: 1.719\n",
      "    num_steps_sampled: 8440000\n",
      "    num_steps_trained: 8440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6856856942176819\n",
      "      kl: 0.01681184209883213\n",
      "      policy_loss: -0.0020996560342609882\n",
      "      total_loss: 120.18306732177734\n",
      "      vf_explained_var: 0.9919310212135315\n",
      "      vf_loss: 120.18363189697266\n",
      "    sample_time_ms: 18355.543\n",
      "    update_time_ms: 5.165\n",
      "  iterations_since_restore: 844\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.95552176369097\n",
      "  time_since_restore: 20999.526082754135\n",
      "  time_this_iter_s: 22.37280011177063\n",
      "  time_total_s: 20999.526082754135\n",
      "  timestamp: 1553730043\n",
      "  timesteps_since_restore: 8440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8440000\n",
      "  training_iteration: 844\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 20999 s, 844 iter, 8440000 ts, 700 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-41-05\n",
      "  done: false\n",
      "  episode_len_mean: 135.01\n",
      "  episode_reward_max: 788.4734662001065\n",
      "  episode_reward_mean: 704.7977420879726\n",
      "  episode_reward_min: -85.14532488548168\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 63283\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.619\n",
      "    load_time_ms: 1.736\n",
      "    num_steps_sampled: 8450000\n",
      "    num_steps_trained: 8450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7114944458007812\n",
      "      kl: 0.025104066357016563\n",
      "      policy_loss: -0.00804260652512312\n",
      "      total_loss: 353.0469055175781\n",
      "      vf_explained_var: 0.974144458770752\n",
      "      vf_loss: 353.05267333984375\n",
      "    sample_time_ms: 18377.445\n",
      "    update_time_ms: 5.214\n",
      "  iterations_since_restore: 845\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.3988710439862\n",
      "  time_since_restore: 21021.724302768707\n",
      "  time_this_iter_s: 22.198220014572144\n",
      "  time_total_s: 21021.724302768707\n",
      "  timestamp: 1553730065\n",
      "  timesteps_since_restore: 8450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8450000\n",
      "  training_iteration: 845\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21021 s, 845 iter, 8450000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-41-27\n",
      "  done: false\n",
      "  episode_len_mean: 136.43\n",
      "  episode_reward_max: 795.4411789808715\n",
      "  episode_reward_mean: 683.2553004694065\n",
      "  episode_reward_min: -56.548033689641045\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 63358\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.33\n",
      "    load_time_ms: 1.755\n",
      "    num_steps_sampled: 8460000\n",
      "    num_steps_trained: 8460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9306953549385071\n",
      "      kl: 0.013923048973083496\n",
      "      policy_loss: -0.0014678138541057706\n",
      "      total_loss: 738.386962890625\n",
      "      vf_explained_var: 0.9533038139343262\n",
      "      vf_loss: 738.3871459960938\n",
      "    sample_time_ms: 18392.185\n",
      "    update_time_ms: 5.347\n",
      "  iterations_since_restore: 846\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.6276502347033\n",
      "  time_since_restore: 21043.454996824265\n",
      "  time_this_iter_s: 21.73069405555725\n",
      "  time_total_s: 21043.454996824265\n",
      "  timestamp: 1553730087\n",
      "  timesteps_since_restore: 8460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8460000\n",
      "  training_iteration: 846\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21043 s, 846 iter, 8460000 ts, 683 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-41-48\n",
      "  done: false\n",
      "  episode_len_mean: 127.93\n",
      "  episode_reward_max: 795.8839076504399\n",
      "  episode_reward_mean: 695.3024413041638\n",
      "  episode_reward_min: -124.5522064806413\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 63437\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.96\n",
      "    load_time_ms: 1.828\n",
      "    num_steps_sampled: 8470000\n",
      "    num_steps_trained: 8470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6639829874038696\n",
      "      kl: 0.013404090888798237\n",
      "      policy_loss: -0.0041008638218045235\n",
      "      total_loss: 506.8338928222656\n",
      "      vf_explained_var: 0.9583975076675415\n",
      "      vf_loss: 506.83673095703125\n",
      "    sample_time_ms: 18316.533\n",
      "    update_time_ms: 5.291\n",
      "  iterations_since_restore: 847\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.6512206520818\n",
      "  time_since_restore: 21064.973983049393\n",
      "  time_this_iter_s: 21.518986225128174\n",
      "  time_total_s: 21064.973983049393\n",
      "  timestamp: 1553730108\n",
      "  timesteps_since_restore: 8470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8470000\n",
      "  training_iteration: 847\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21064 s, 847 iter, 8470000 ts, 695 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 129.5\n",
      "  episode_reward_max: 795.8839076504399\n",
      "  episode_reward_mean: 708.1334413780133\n",
      "  episode_reward_min: -110.56584186267351\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 63516\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.351\n",
      "    load_time_ms: 1.798\n",
      "    num_steps_sampled: 8480000\n",
      "    num_steps_trained: 8480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6399106979370117\n",
      "      kl: 0.012600408867001534\n",
      "      policy_loss: -0.000686555344145745\n",
      "      total_loss: 169.72862243652344\n",
      "      vf_explained_var: 0.9885023236274719\n",
      "      vf_loss: 169.72816467285156\n",
      "    sample_time_ms: 18364.145\n",
      "    update_time_ms: 5.47\n",
      "  iterations_since_restore: 848\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.0667206890068\n",
      "  time_since_restore: 21087.66780591011\n",
      "  time_this_iter_s: 22.693822860717773\n",
      "  time_total_s: 21087.66780591011\n",
      "  timestamp: 1553730131\n",
      "  timesteps_since_restore: 8480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8480000\n",
      "  training_iteration: 848\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21087 s, 848 iter, 8480000 ts, 708 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-42-33\n",
      "  done: false\n",
      "  episode_len_mean: 128.86\n",
      "  episode_reward_max: 788.7999060735445\n",
      "  episode_reward_mean: 706.7002068967752\n",
      "  episode_reward_min: -67.02368067504995\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 63595\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.554\n",
      "    load_time_ms: 1.745\n",
      "    num_steps_sampled: 8490000\n",
      "    num_steps_trained: 8490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5457262992858887\n",
      "      kl: 0.0226809773594141\n",
      "      policy_loss: -0.0022575403563678265\n",
      "      total_loss: 135.6270751953125\n",
      "      vf_explained_var: 0.9885757565498352\n",
      "      vf_loss: 135.62728881835938\n",
      "    sample_time_ms: 18321.999\n",
      "    update_time_ms: 5.489\n",
      "  iterations_since_restore: 849\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.3501034483876\n",
      "  time_since_restore: 21109.21914100647\n",
      "  time_this_iter_s: 21.551335096359253\n",
      "  time_total_s: 21109.21914100647\n",
      "  timestamp: 1553730153\n",
      "  timesteps_since_restore: 8490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8490000\n",
      "  training_iteration: 849\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21109 s, 849 iter, 8490000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-42-54\n",
      "  done: false\n",
      "  episode_len_mean: 130.32\n",
      "  episode_reward_max: 793.9605650574921\n",
      "  episode_reward_mean: 710.6887681458323\n",
      "  episode_reward_min: -67.02368067504995\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 63672\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3733.305\n",
      "    load_time_ms: 1.769\n",
      "    num_steps_sampled: 8500000\n",
      "    num_steps_trained: 8500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6665796041488647\n",
      "      kl: 0.03191259130835533\n",
      "      policy_loss: -0.0017958451062440872\n",
      "      total_loss: 226.10516357421875\n",
      "      vf_explained_var: 0.9826960563659668\n",
      "      vf_loss: 226.10406494140625\n",
      "    sample_time_ms: 18279.66\n",
      "    update_time_ms: 5.388\n",
      "  iterations_since_restore: 850\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 355.34438407291606\n",
      "  time_since_restore: 21130.88705921173\n",
      "  time_this_iter_s: 21.66791820526123\n",
      "  time_total_s: 21130.88705921173\n",
      "  timestamp: 1553730174\n",
      "  timesteps_since_restore: 8500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8500000\n",
      "  training_iteration: 850\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21130 s, 850 iter, 8500000 ts, 711 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-43-17\n",
      "  done: false\n",
      "  episode_len_mean: 130.11\n",
      "  episode_reward_max: 798.2349024737207\n",
      "  episode_reward_mean: 714.3034218501646\n",
      "  episode_reward_min: -25.02433902023455\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 63749\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3731.677\n",
      "    load_time_ms: 1.724\n",
      "    num_steps_sampled: 8510000\n",
      "    num_steps_trained: 8510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6621382236480713\n",
      "      kl: 0.016056271269917488\n",
      "      policy_loss: -0.004575381521135569\n",
      "      total_loss: 129.8583526611328\n",
      "      vf_explained_var: 0.9920536875724792\n",
      "      vf_loss: 129.8614501953125\n",
      "    sample_time_ms: 18285.51\n",
      "    update_time_ms: 5.636\n",
      "  iterations_since_restore: 851\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.15171092508245\n",
      "  time_since_restore: 21153.215420007706\n",
      "  time_this_iter_s: 22.32836079597473\n",
      "  time_total_s: 21153.215420007706\n",
      "  timestamp: 1553730197\n",
      "  timesteps_since_restore: 8510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8510000\n",
      "  training_iteration: 851\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21153 s, 851 iter, 8510000 ts, 714 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-43-39\n",
      "  done: false\n",
      "  episode_len_mean: 131.59\n",
      "  episode_reward_max: 793.2342900178392\n",
      "  episode_reward_mean: 706.1507277585589\n",
      "  episode_reward_min: -65.82124630322733\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 63827\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.014\n",
      "    load_time_ms: 1.692\n",
      "    num_steps_sampled: 8520000\n",
      "    num_steps_trained: 8520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6912304759025574\n",
      "      kl: 0.010163598693907261\n",
      "      policy_loss: -0.0005733795114792883\n",
      "      total_loss: 321.78619384765625\n",
      "      vf_explained_var: 0.9747218489646912\n",
      "      vf_loss: 321.78582763671875\n",
      "    sample_time_ms: 18263.787\n",
      "    update_time_ms: 5.483\n",
      "  iterations_since_restore: 852\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.0753638792796\n",
      "  time_since_restore: 21175.381979703903\n",
      "  time_this_iter_s: 22.16655969619751\n",
      "  time_total_s: 21175.381979703903\n",
      "  timestamp: 1553730219\n",
      "  timesteps_since_restore: 8520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8520000\n",
      "  training_iteration: 852\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21175 s, 852 iter, 8520000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-44-01\n",
      "  done: false\n",
      "  episode_len_mean: 129.19\n",
      "  episode_reward_max: 783.0280152731979\n",
      "  episode_reward_mean: 691.74740662343\n",
      "  episode_reward_min: -65.82124630322733\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 63905\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.33\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 8530000\n",
      "    num_steps_trained: 8530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7762320041656494\n",
      "      kl: 0.013416177593171597\n",
      "      policy_loss: -0.004940364044159651\n",
      "      total_loss: 661.9202880859375\n",
      "      vf_explained_var: 0.9530085921287537\n",
      "      vf_loss: 661.9239501953125\n",
      "    sample_time_ms: 18215.5\n",
      "    update_time_ms: 5.591\n",
      "  iterations_since_restore: 853\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.8737033117149\n",
      "  time_since_restore: 21196.83153939247\n",
      "  time_this_iter_s: 21.449559688568115\n",
      "  time_total_s: 21196.83153939247\n",
      "  timestamp: 1553730241\n",
      "  timesteps_since_restore: 8530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8530000\n",
      "  training_iteration: 853\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21196 s, 853 iter, 8530000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-44-22\n",
      "  done: false\n",
      "  episode_len_mean: 127.88\n",
      "  episode_reward_max: 790.8983464211885\n",
      "  episode_reward_mean: 682.7902803951496\n",
      "  episode_reward_min: -69.13506401438642\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 63984\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3729.503\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 8540000\n",
      "    num_steps_trained: 8540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6829345226287842\n",
      "      kl: 0.01574590802192688\n",
      "      policy_loss: -0.004075393546372652\n",
      "      total_loss: 406.3194580078125\n",
      "      vf_explained_var: 0.9652795791625977\n",
      "      vf_loss: 406.32208251953125\n",
      "    sample_time_ms: 18147.646\n",
      "    update_time_ms: 5.514\n",
      "  iterations_since_restore: 854\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.3951401975748\n",
      "  time_since_restore: 21218.559324264526\n",
      "  time_this_iter_s: 21.727784872055054\n",
      "  time_total_s: 21218.559324264526\n",
      "  timestamp: 1553730262\n",
      "  timesteps_since_restore: 8540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8540000\n",
      "  training_iteration: 854\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21218 s, 854 iter, 8540000 ts, 683 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-44-44\n",
      "  done: false\n",
      "  episode_len_mean: 127.65\n",
      "  episode_reward_max: 793.9895958413116\n",
      "  episode_reward_mean: 696.8608285254356\n",
      "  episode_reward_min: -85.69976621393182\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 64062\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3731.413\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 8550000\n",
      "    num_steps_trained: 8550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7369679808616638\n",
      "      kl: 0.0155289676040411\n",
      "      policy_loss: -0.0007688917103223503\n",
      "      total_loss: 274.2795104980469\n",
      "      vf_explained_var: 0.9828817844390869\n",
      "      vf_loss: 274.2788391113281\n",
      "    sample_time_ms: 18078.687\n",
      "    update_time_ms: 5.546\n",
      "  iterations_since_restore: 855\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.43041426271776\n",
      "  time_since_restore: 21240.096724271774\n",
      "  time_this_iter_s: 21.537400007247925\n",
      "  time_total_s: 21240.096724271774\n",
      "  timestamp: 1553730284\n",
      "  timesteps_since_restore: 8550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8550000\n",
      "  training_iteration: 855\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21240 s, 855 iter, 8550000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-45-06\n",
      "  done: false\n",
      "  episode_len_mean: 133.62\n",
      "  episode_reward_max: 789.8936038177228\n",
      "  episode_reward_mean: 701.8113088800098\n",
      "  episode_reward_min: -85.69976621393182\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 64137\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.82\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 8560000\n",
      "    num_steps_trained: 8560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8844761252403259\n",
      "      kl: 0.012439550831913948\n",
      "      policy_loss: -0.0005775828612968326\n",
      "      total_loss: 250.8292694091797\n",
      "      vf_explained_var: 0.9841480851173401\n",
      "      vf_loss: 250.82867431640625\n",
      "    sample_time_ms: 18131.413\n",
      "    update_time_ms: 5.619\n",
      "  iterations_since_restore: 856\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.90565444000487\n",
      "  time_since_restore: 21262.097896575928\n",
      "  time_this_iter_s: 22.001172304153442\n",
      "  time_total_s: 21262.097896575928\n",
      "  timestamp: 1553730306\n",
      "  timesteps_since_restore: 8560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8560000\n",
      "  training_iteration: 856\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21262 s, 856 iter, 8560000 ts, 702 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-45-28\n",
      "  done: false\n",
      "  episode_len_mean: 133.39\n",
      "  episode_reward_max: 797.5395131957513\n",
      "  episode_reward_mean: 697.5559872316576\n",
      "  episode_reward_min: -92.70244373856384\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 64215\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.411\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 8570000\n",
      "    num_steps_trained: 8570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6616261005401611\n",
      "      kl: 0.01565002277493477\n",
      "      policy_loss: -0.0024262021761387587\n",
      "      total_loss: 464.12109375\n",
      "      vf_explained_var: 0.9657747149467468\n",
      "      vf_loss: 464.1221008300781\n",
      "    sample_time_ms: 18209.064\n",
      "    update_time_ms: 5.6\n",
      "  iterations_since_restore: 857\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.77799361582873\n",
      "  time_since_restore: 21284.494768857956\n",
      "  time_this_iter_s: 22.3968722820282\n",
      "  time_total_s: 21284.494768857956\n",
      "  timestamp: 1553730328\n",
      "  timesteps_since_restore: 8570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8570000\n",
      "  training_iteration: 857\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21284 s, 857 iter, 8570000 ts, 698 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-45-51\n",
      "  done: false\n",
      "  episode_len_mean: 131.56\n",
      "  episode_reward_max: 797.5395131957513\n",
      "  episode_reward_mean: 709.7541723440046\n",
      "  episode_reward_min: -47.865763673724075\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 64292\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.898\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 8580000\n",
      "    num_steps_trained: 8580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7040625214576721\n",
      "      kl: 0.018975380808115005\n",
      "      policy_loss: 0.00012385730224195868\n",
      "      total_loss: 300.7856140136719\n",
      "      vf_explained_var: 0.9795718193054199\n",
      "      vf_loss: 300.78375244140625\n",
      "    sample_time_ms: 18166.977\n",
      "    update_time_ms: 5.442\n",
      "  iterations_since_restore: 858\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.87708617200224\n",
      "  time_since_restore: 21306.76038002968\n",
      "  time_this_iter_s: 22.265611171722412\n",
      "  time_total_s: 21306.76038002968\n",
      "  timestamp: 1553730351\n",
      "  timesteps_since_restore: 8580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8580000\n",
      "  training_iteration: 858\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21306 s, 858 iter, 8580000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-46-13\n",
      "  done: false\n",
      "  episode_len_mean: 132.15\n",
      "  episode_reward_max: 787.2261366575613\n",
      "  episode_reward_mean: 689.3217089985608\n",
      "  episode_reward_min: -106.95272704950554\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 64370\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3715.663\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 8590000\n",
      "    num_steps_trained: 8590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8205869793891907\n",
      "      kl: 0.017624875530600548\n",
      "      policy_loss: -0.0041068377904593945\n",
      "      total_loss: 656.556884765625\n",
      "      vf_explained_var: 0.9469688534736633\n",
      "      vf_loss: 656.5593872070312\n",
      "    sample_time_ms: 18212.378\n",
      "    update_time_ms: 5.794\n",
      "  iterations_since_restore: 859\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.6608544992804\n",
      "  time_since_restore: 21328.76597738266\n",
      "  time_this_iter_s: 22.005597352981567\n",
      "  time_total_s: 21328.76597738266\n",
      "  timestamp: 1553730373\n",
      "  timesteps_since_restore: 8590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8590000\n",
      "  training_iteration: 859\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21328 s, 859 iter, 8590000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 134.69\n",
      "  episode_reward_max: 781.6660955387449\n",
      "  episode_reward_mean: 689.0246039988654\n",
      "  episode_reward_min: -93.01898909919815\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 64445\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.545\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 8600000\n",
      "    num_steps_trained: 8600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.09066783636808395\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0395275354385376\n",
      "      kl: 0.008731028996407986\n",
      "      policy_loss: -0.0011690246174111962\n",
      "      total_loss: 341.05999755859375\n",
      "      vf_explained_var: 0.9773039221763611\n",
      "      vf_loss: 341.0603332519531\n",
      "    sample_time_ms: 18271.39\n",
      "    update_time_ms: 5.768\n",
      "  iterations_since_restore: 860\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.5123019994327\n",
      "  time_since_restore: 21350.97967815399\n",
      "  time_this_iter_s: 22.213700771331787\n",
      "  time_total_s: 21350.97967815399\n",
      "  timestamp: 1553730395\n",
      "  timesteps_since_restore: 8600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8600000\n",
      "  training_iteration: 860\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21350 s, 860 iter, 8600000 ts, 689 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-46-57\n",
      "  done: false\n",
      "  episode_len_mean: 133.15\n",
      "  episode_reward_max: 792.1349994778851\n",
      "  episode_reward_mean: 640.8331723711062\n",
      "  episode_reward_min: -111.2716872413383\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 64522\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.076\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 8610000\n",
      "    num_steps_trained: 8610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0655407905578613\n",
      "      kl: 0.0238531231880188\n",
      "      policy_loss: -0.004799703601747751\n",
      "      total_loss: 635.2568359375\n",
      "      vf_explained_var: 0.9575523734092712\n",
      "      vf_loss: 635.260498046875\n",
      "    sample_time_ms: 18264.644\n",
      "    update_time_ms: 5.495\n",
      "  iterations_since_restore: 861\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 320.416586185553\n",
      "  time_since_restore: 21373.485122203827\n",
      "  time_this_iter_s: 22.505444049835205\n",
      "  time_total_s: 21373.485122203827\n",
      "  timestamp: 1553730417\n",
      "  timesteps_since_restore: 8610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8610000\n",
      "  training_iteration: 861\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21373 s, 861 iter, 8610000 ts, 641 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-47-18\n",
      "  done: false\n",
      "  episode_len_mean: 138.29\n",
      "  episode_reward_max: 792.6473351758286\n",
      "  episode_reward_mean: 674.5505581547338\n",
      "  episode_reward_min: -60.10759457054456\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 64595\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3737.29\n",
      "    load_time_ms: 1.583\n",
      "    num_steps_sampled: 8620000\n",
      "    num_steps_trained: 8620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1339036226272583\n",
      "      kl: 0.02040921151638031\n",
      "      policy_loss: -0.001666185911744833\n",
      "      total_loss: 347.7755432128906\n",
      "      vf_explained_var: 0.9742500185966492\n",
      "      vf_loss: 347.7762451171875\n",
      "    sample_time_ms: 18143.434\n",
      "    update_time_ms: 5.683\n",
      "  iterations_since_restore: 862\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.27527907736703\n",
      "  time_since_restore: 21394.454044103622\n",
      "  time_this_iter_s: 20.968921899795532\n",
      "  time_total_s: 21394.454044103622\n",
      "  timestamp: 1553730438\n",
      "  timesteps_since_restore: 8620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8620000\n",
      "  training_iteration: 862\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21394 s, 862 iter, 8620000 ts, 675 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-47-40\n",
      "  done: false\n",
      "  episode_len_mean: 137.79\n",
      "  episode_reward_max: 791.2198516661891\n",
      "  episode_reward_mean: 685.7560350566969\n",
      "  episode_reward_min: -69.89403495696013\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 64671\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.041\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 8630000\n",
      "    num_steps_trained: 8630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7377515435218811\n",
      "      kl: 0.018171485513448715\n",
      "      policy_loss: 0.0015537304570898414\n",
      "      total_loss: 488.32171630859375\n",
      "      vf_explained_var: 0.969610869884491\n",
      "      vf_loss: 488.3193054199219\n",
      "    sample_time_ms: 18179.735\n",
      "    update_time_ms: 5.693\n",
      "  iterations_since_restore: 863\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.87801752834844\n",
      "  time_since_restore: 21416.2862136364\n",
      "  time_this_iter_s: 21.83216953277588\n",
      "  time_total_s: 21416.2862136364\n",
      "  timestamp: 1553730460\n",
      "  timesteps_since_restore: 8630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8630000\n",
      "  training_iteration: 863\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21416 s, 863 iter, 8630000 ts, 686 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-48-02\n",
      "  done: false\n",
      "  episode_len_mean: 129.25\n",
      "  episode_reward_max: 793.8433661954888\n",
      "  episode_reward_mean: 667.6204343998553\n",
      "  episode_reward_min: -87.96392773439787\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 64749\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.31\n",
      "    load_time_ms: 1.621\n",
      "    num_steps_sampled: 8640000\n",
      "    num_steps_trained: 8640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8927038311958313\n",
      "      kl: 0.020464487373828888\n",
      "      policy_loss: -0.007768770679831505\n",
      "      total_loss: 509.9789733886719\n",
      "      vf_explained_var: 0.9643366932868958\n",
      "      vf_loss: 509.98577880859375\n",
      "    sample_time_ms: 18194.089\n",
      "    update_time_ms: 5.8\n",
      "  iterations_since_restore: 864\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 333.81021719992765\n",
      "  time_since_restore: 21438.121967554092\n",
      "  time_this_iter_s: 21.835753917694092\n",
      "  time_total_s: 21438.121967554092\n",
      "  timestamp: 1553730482\n",
      "  timesteps_since_restore: 8640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8640000\n",
      "  training_iteration: 864\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21438 s, 864 iter, 8640000 ts, 668 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-48-23\n",
      "  done: false\n",
      "  episode_len_mean: 132.21\n",
      "  episode_reward_max: 788.3053791874465\n",
      "  episode_reward_mean: 665.1929924264072\n",
      "  episode_reward_min: -111.28784862162108\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 64825\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3734.31\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 8650000\n",
      "    num_steps_trained: 8650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9218716621398926\n",
      "      kl: 0.024885330349206924\n",
      "      policy_loss: 9.011840302264318e-05\n",
      "      total_loss: 181.4304656982422\n",
      "      vf_explained_var: 0.9890567064285278\n",
      "      vf_loss: 181.4292449951172\n",
      "    sample_time_ms: 18120.78\n",
      "    update_time_ms: 5.781\n",
      "  iterations_since_restore: 865\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 332.59649621320364\n",
      "  time_since_restore: 21458.907629728317\n",
      "  time_this_iter_s: 20.785662174224854\n",
      "  time_total_s: 21458.907629728317\n",
      "  timestamp: 1553730503\n",
      "  timesteps_since_restore: 8650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8650000\n",
      "  training_iteration: 865\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21458 s, 865 iter, 8650000 ts, 665 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-48-45\n",
      "  done: false\n",
      "  episode_len_mean: 131.35\n",
      "  episode_reward_max: 794.1492960820888\n",
      "  episode_reward_mean: 665.8590937022765\n",
      "  episode_reward_min: -111.28784862162108\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 64901\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3734.956\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 8660000\n",
      "    num_steps_trained: 8660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8619792461395264\n",
      "      kl: 0.020038161426782608\n",
      "      policy_loss: 0.0003059781447518617\n",
      "      total_loss: 223.89483642578125\n",
      "      vf_explained_var: 0.986348569393158\n",
      "      vf_loss: 223.8936309814453\n",
      "    sample_time_ms: 18109.946\n",
      "    update_time_ms: 5.657\n",
      "  iterations_since_restore: 866\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 332.9295468511383\n",
      "  time_since_restore: 21480.80636572838\n",
      "  time_this_iter_s: 21.898736000061035\n",
      "  time_total_s: 21480.80636572838\n",
      "  timestamp: 1553730525\n",
      "  timesteps_since_restore: 8660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8660000\n",
      "  training_iteration: 866\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21480 s, 866 iter, 8660000 ts, 666 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-49-07\n",
      "  done: false\n",
      "  episode_len_mean: 132.97\n",
      "  episode_reward_max: 794.1492960820888\n",
      "  episode_reward_mean: 700.4957646957432\n",
      "  episode_reward_min: -76.27434754032699\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 64978\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.829\n",
      "    load_time_ms: 1.62\n",
      "    num_steps_sampled: 8670000\n",
      "    num_steps_trained: 8670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7261274456977844\n",
      "      kl: 0.015684448182582855\n",
      "      policy_loss: 0.00033090481883846223\n",
      "      total_loss: 261.6070251464844\n",
      "      vf_explained_var: 0.977918267250061\n",
      "      vf_loss: 261.6059875488281\n",
      "    sample_time_ms: 18040.433\n",
      "    update_time_ms: 5.845\n",
      "  iterations_since_restore: 867\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.24788234787155\n",
      "  time_since_restore: 21502.36229991913\n",
      "  time_this_iter_s: 21.555934190750122\n",
      "  time_total_s: 21502.36229991913\n",
      "  timestamp: 1553730547\n",
      "  timesteps_since_restore: 8670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8670000\n",
      "  training_iteration: 867\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21502 s, 867 iter, 8670000 ts, 700 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-49-28\n",
      "  done: false\n",
      "  episode_len_mean: 130.74\n",
      "  episode_reward_max: 792.08332564322\n",
      "  episode_reward_mean: 709.7546275601923\n",
      "  episode_reward_min: -99.99878731477177\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 65056\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.961\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 8680000\n",
      "    num_steps_trained: 8680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7058150768280029\n",
      "      kl: 0.018338171765208244\n",
      "      policy_loss: -0.0013895808951929212\n",
      "      total_loss: 156.18211364746094\n",
      "      vf_explained_var: 0.9897642731666565\n",
      "      vf_loss: 156.1826934814453\n",
      "    sample_time_ms: 17938.284\n",
      "    update_time_ms: 5.903\n",
      "  iterations_since_restore: 868\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.87731378009624\n",
      "  time_since_restore: 21523.809461593628\n",
      "  time_this_iter_s: 21.44716167449951\n",
      "  time_total_s: 21523.809461593628\n",
      "  timestamp: 1553730568\n",
      "  timesteps_since_restore: 8680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8680000\n",
      "  training_iteration: 868\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21523 s, 868 iter, 8680000 ts, 710 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-49-50\n",
      "  done: false\n",
      "  episode_len_mean: 133.34\n",
      "  episode_reward_max: 785.9746131018286\n",
      "  episode_reward_mean: 698.3652853275981\n",
      "  episode_reward_min: -99.99878731477177\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 65132\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.269\n",
      "    load_time_ms: 1.577\n",
      "    num_steps_sampled: 8690000\n",
      "    num_steps_trained: 8690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.778560221195221\n",
      "      kl: 0.034747641533613205\n",
      "      policy_loss: -0.0018670497229322791\n",
      "      total_loss: 103.12152099609375\n",
      "      vf_explained_var: 0.9928595423698425\n",
      "      vf_loss: 103.12181854248047\n",
      "    sample_time_ms: 17907.18\n",
      "    update_time_ms: 5.473\n",
      "  iterations_since_restore: 869\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.18264266379913\n",
      "  time_since_restore: 21545.501839399338\n",
      "  time_this_iter_s: 21.69237780570984\n",
      "  time_total_s: 21545.501839399338\n",
      "  timestamp: 1553730590\n",
      "  timesteps_since_restore: 8690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8690000\n",
      "  training_iteration: 869\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21545 s, 869 iter, 8690000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-50-12\n",
      "  done: false\n",
      "  episode_len_mean: 138.36\n",
      "  episode_reward_max: 785.4852456023643\n",
      "  episode_reward_mean: 693.3198546946705\n",
      "  episode_reward_min: -57.21799891227508\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 65205\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.4\n",
      "    load_time_ms: 1.645\n",
      "    num_steps_sampled: 8700000\n",
      "    num_steps_trained: 8700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0949426889419556\n",
      "      kl: 0.014293699525296688\n",
      "      policy_loss: -0.0019547988194972277\n",
      "      total_loss: 283.3714294433594\n",
      "      vf_explained_var: 0.9826763868331909\n",
      "      vf_loss: 283.37274169921875\n",
      "    sample_time_ms: 17894.566\n",
      "    update_time_ms: 5.392\n",
      "  iterations_since_restore: 870\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.65992734733516\n",
      "  time_since_restore: 21567.62218761444\n",
      "  time_this_iter_s: 22.12034821510315\n",
      "  time_total_s: 21567.62218761444\n",
      "  timestamp: 1553730612\n",
      "  timesteps_since_restore: 8700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8700000\n",
      "  training_iteration: 870\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21567 s, 870 iter, 8700000 ts, 693 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-50-34\n",
      "  done: false\n",
      "  episode_len_mean: 140.96\n",
      "  episode_reward_max: 797.1842545252943\n",
      "  episode_reward_mean: 670.7862822706652\n",
      "  episode_reward_min: -83.25913266854403\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 65279\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.459\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 8710000\n",
      "    num_steps_trained: 8710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0387582778930664\n",
      "      kl: 0.015294218435883522\n",
      "      policy_loss: -0.0008447490981779993\n",
      "      total_loss: 269.0459289550781\n",
      "      vf_explained_var: 0.9827149510383606\n",
      "      vf_loss: 269.04608154296875\n",
      "    sample_time_ms: 17850.435\n",
      "    update_time_ms: 5.517\n",
      "  iterations_since_restore: 871\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 335.39314113533254\n",
      "  time_since_restore: 21589.445536613464\n",
      "  time_this_iter_s: 21.823348999023438\n",
      "  time_total_s: 21589.445536613464\n",
      "  timestamp: 1553730634\n",
      "  timesteps_since_restore: 8710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8710000\n",
      "  training_iteration: 871\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21589 s, 871 iter, 8710000 ts, 671 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-50-56\n",
      "  done: false\n",
      "  episode_len_mean: 141.86\n",
      "  episode_reward_max: 790.3304955329195\n",
      "  episode_reward_mean: 655.4755725796509\n",
      "  episode_reward_min: -83.25913266854403\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 65352\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.861\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 8720000\n",
      "    num_steps_trained: 8720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.26839280128479\n",
      "      kl: 0.01172281801700592\n",
      "      policy_loss: -0.0009996808366850019\n",
      "      total_loss: 443.66827392578125\n",
      "      vf_explained_var: 0.9746534824371338\n",
      "      vf_loss: 443.6687316894531\n",
      "    sample_time_ms: 17961.385\n",
      "    update_time_ms: 5.42\n",
      "  iterations_since_restore: 872\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 327.73778628982546\n",
      "  time_since_restore: 21611.686134576797\n",
      "  time_this_iter_s: 22.24059796333313\n",
      "  time_total_s: 21611.686134576797\n",
      "  timestamp: 1553730656\n",
      "  timesteps_since_restore: 8720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8720000\n",
      "  training_iteration: 872\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21611 s, 872 iter, 8720000 ts, 655 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-51-18\n",
      "  done: false\n",
      "  episode_len_mean: 142.7\n",
      "  episode_reward_max: 789.2671187486671\n",
      "  episode_reward_mean: 674.4921202124425\n",
      "  episode_reward_min: -55.33993928522784\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 65425\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3737.349\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 8730000\n",
      "    num_steps_trained: 8730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.084758996963501\n",
      "      kl: 0.02075546234846115\n",
      "      policy_loss: -0.004125599749386311\n",
      "      total_loss: 388.8701171875\n",
      "      vf_explained_var: 0.9684725999832153\n",
      "      vf_loss: 388.873291015625\n",
      "    sample_time_ms: 17997.474\n",
      "    update_time_ms: 5.37\n",
      "  iterations_since_restore: 873\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.24606010622125\n",
      "  time_since_restore: 21633.891669273376\n",
      "  time_this_iter_s: 22.20553469657898\n",
      "  time_total_s: 21633.891669273376\n",
      "  timestamp: 1553730678\n",
      "  timesteps_since_restore: 8730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8730000\n",
      "  training_iteration: 873\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21633 s, 873 iter, 8730000 ts, 674 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-51-41\n",
      "  done: false\n",
      "  episode_len_mean: 137.09\n",
      "  episode_reward_max: 808.0596593218576\n",
      "  episode_reward_mean: 688.2414286959068\n",
      "  episode_reward_min: -55.33993928522784\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 65499\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.746\n",
      "    load_time_ms: 1.794\n",
      "    num_steps_sampled: 8740000\n",
      "    num_steps_trained: 8740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0956180095672607\n",
      "      kl: 0.014579705893993378\n",
      "      policy_loss: -0.0019256650703027844\n",
      "      total_loss: 269.35748291015625\n",
      "      vf_explained_var: 0.9828357100486755\n",
      "      vf_loss: 269.3587951660156\n",
      "    sample_time_ms: 18076.364\n",
      "    update_time_ms: 5.515\n",
      "  iterations_since_restore: 874\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 344.1207143479535\n",
      "  time_since_restore: 21656.5394821167\n",
      "  time_this_iter_s: 22.647812843322754\n",
      "  time_total_s: 21656.5394821167\n",
      "  timestamp: 1553730701\n",
      "  timesteps_since_restore: 8740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8740000\n",
      "  training_iteration: 874\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21656 s, 874 iter, 8740000 ts, 688 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-52-04\n",
      "  done: false\n",
      "  episode_len_mean: 138.88\n",
      "  episode_reward_max: 808.0596593218576\n",
      "  episode_reward_mean: 698.8426337830351\n",
      "  episode_reward_min: -92.56027757343138\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 65575\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3741.49\n",
      "    load_time_ms: 1.827\n",
      "    num_steps_sampled: 8750000\n",
      "    num_steps_trained: 8750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8844804763793945\n",
      "      kl: 0.022818826138973236\n",
      "      policy_loss: -0.0008150776848196983\n",
      "      total_loss: 266.9865417480469\n",
      "      vf_explained_var: 0.9787427186965942\n",
      "      vf_loss: 266.986328125\n",
      "    sample_time_ms: 18255.801\n",
      "    update_time_ms: 5.453\n",
      "  iterations_since_restore: 875\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.42131689151756\n",
      "  time_since_restore: 21679.136826992035\n",
      "  time_this_iter_s: 22.597344875335693\n",
      "  time_total_s: 21679.136826992035\n",
      "  timestamp: 1553730724\n",
      "  timesteps_since_restore: 8750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8750000\n",
      "  training_iteration: 875\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21679 s, 875 iter, 8750000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-52-26\n",
      "  done: false\n",
      "  episode_len_mean: 145.87\n",
      "  episode_reward_max: 800.5645383029394\n",
      "  episode_reward_mean: 660.5097255842265\n",
      "  episode_reward_min: -92.56027757343138\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 65643\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.903\n",
      "    load_time_ms: 1.873\n",
      "    num_steps_sampled: 8760000\n",
      "    num_steps_trained: 8760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5499886274337769\n",
      "      kl: 0.014507572166621685\n",
      "      policy_loss: 0.0002855830534826964\n",
      "      total_loss: 319.5904846191406\n",
      "      vf_explained_var: 0.9841701984405518\n",
      "      vf_loss: 319.58953857421875\n",
      "    sample_time_ms: 18252.752\n",
      "    update_time_ms: 5.58\n",
      "  iterations_since_restore: 876\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 330.2548627921133\n",
      "  time_since_restore: 21701.192853212357\n",
      "  time_this_iter_s: 22.056026220321655\n",
      "  time_total_s: 21701.192853212357\n",
      "  timestamp: 1553730746\n",
      "  timesteps_since_restore: 8760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8760000\n",
      "  training_iteration: 876\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21701 s, 876 iter, 8760000 ts, 661 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-52-48\n",
      "  done: false\n",
      "  episode_len_mean: 154.71\n",
      "  episode_reward_max: 800.5645383029394\n",
      "  episode_reward_mean: 632.4802701336959\n",
      "  episode_reward_min: -109.29777993305751\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 65709\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3764.697\n",
      "    load_time_ms: 1.857\n",
      "    num_steps_sampled: 8770000\n",
      "    num_steps_trained: 8770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5727845430374146\n",
      "      kl: 0.014349836856126785\n",
      "      policy_loss: -0.0005431511672213674\n",
      "      total_loss: 513.2310791015625\n",
      "      vf_explained_var: 0.9714387655258179\n",
      "      vf_loss: 513.23095703125\n",
      "    sample_time_ms: 18277.907\n",
      "    update_time_ms: 5.454\n",
      "  iterations_since_restore: 877\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 316.2401350668479\n",
      "  time_since_restore: 21723.045885324478\n",
      "  time_this_iter_s: 21.853032112121582\n",
      "  time_total_s: 21723.045885324478\n",
      "  timestamp: 1553730768\n",
      "  timesteps_since_restore: 8770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8770000\n",
      "  training_iteration: 877\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21723 s, 877 iter, 8770000 ts, 632 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-53-10\n",
      "  done: false\n",
      "  episode_len_mean: 153.75\n",
      "  episode_reward_max: 791.0473010861477\n",
      "  episode_reward_mean: 656.1209807964505\n",
      "  episode_reward_min: -109.29777993305751\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 65781\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.224\n",
      "    load_time_ms: 1.93\n",
      "    num_steps_sampled: 8780000\n",
      "    num_steps_trained: 8780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1495310068130493\n",
      "      kl: 0.014450395479798317\n",
      "      policy_loss: -0.0031721568666398525\n",
      "      total_loss: 156.87649536132812\n",
      "      vf_explained_var: 0.9898030161857605\n",
      "      vf_loss: 156.87901306152344\n",
      "    sample_time_ms: 18375.294\n",
      "    update_time_ms: 5.324\n",
      "  iterations_since_restore: 878\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 328.0604903982252\n",
      "  time_since_restore: 21745.25030851364\n",
      "  time_this_iter_s: 22.204423189163208\n",
      "  time_total_s: 21745.25030851364\n",
      "  timestamp: 1553730790\n",
      "  timesteps_since_restore: 8780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8780000\n",
      "  training_iteration: 878\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21745 s, 878 iter, 8780000 ts, 656 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-53-32\n",
      "  done: false\n",
      "  episode_len_mean: 140.2\n",
      "  episode_reward_max: 788.4946339945677\n",
      "  episode_reward_mean: 679.533617555304\n",
      "  episode_reward_min: -67.85099893347038\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 65856\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3748.002\n",
      "    load_time_ms: 1.979\n",
      "    num_steps_sampled: 8790000\n",
      "    num_steps_trained: 8790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9009925723075867\n",
      "      kl: 0.013367469422519207\n",
      "      policy_loss: -0.002566250041127205\n",
      "      total_loss: 171.20602416992188\n",
      "      vf_explained_var: 0.9903765916824341\n",
      "      vf_loss: 171.2080078125\n",
      "    sample_time_ms: 18402.981\n",
      "    update_time_ms: 5.524\n",
      "  iterations_since_restore: 879\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.766808777652\n",
      "  time_since_restore: 21767.27011036873\n",
      "  time_this_iter_s: 22.01980185508728\n",
      "  time_total_s: 21767.27011036873\n",
      "  timestamp: 1553730812\n",
      "  timesteps_since_restore: 8790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8790000\n",
      "  training_iteration: 879\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21767 s, 879 iter, 8790000 ts, 680 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-53-54\n",
      "  done: false\n",
      "  episode_len_mean: 133.14\n",
      "  episode_reward_max: 793.8518555989419\n",
      "  episode_reward_mean: 681.6102419200464\n",
      "  episode_reward_min: -81.8674255957832\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 65934\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3748.123\n",
      "    load_time_ms: 1.908\n",
      "    num_steps_sampled: 8800000\n",
      "    num_steps_trained: 8800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7322846055030823\n",
      "      kl: 0.012695902027189732\n",
      "      policy_loss: -0.0013410414103418589\n",
      "      total_loss: 135.1444549560547\n",
      "      vf_explained_var: 0.9922064542770386\n",
      "      vf_loss: 135.1452178955078\n",
      "    sample_time_ms: 18399.83\n",
      "    update_time_ms: 5.578\n",
      "  iterations_since_restore: 880\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.8051209600232\n",
      "  time_since_restore: 21789.35773587227\n",
      "  time_this_iter_s: 22.08762550354004\n",
      "  time_total_s: 21789.35773587227\n",
      "  timestamp: 1553730834\n",
      "  timesteps_since_restore: 8800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8800000\n",
      "  training_iteration: 880\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21789 s, 880 iter, 8800000 ts, 682 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-54-16\n",
      "  done: false\n",
      "  episode_len_mean: 132.04\n",
      "  episode_reward_max: 793.8518555989419\n",
      "  episode_reward_mean: 732.305548634164\n",
      "  episode_reward_min: 228.7886970415815\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 66009\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3751.247\n",
      "    load_time_ms: 1.953\n",
      "    num_steps_sampled: 8810000\n",
      "    num_steps_trained: 8810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8632296323776245\n",
      "      kl: 0.030060334131121635\n",
      "      policy_loss: -0.0012069358490407467\n",
      "      total_loss: 307.5788879394531\n",
      "      vf_explained_var: 0.9770208597183228\n",
      "      vf_loss: 307.5787048339844\n",
      "    sample_time_ms: 18396.319\n",
      "    update_time_ms: 5.48\n",
      "  iterations_since_restore: 881\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 366.15277431708193\n",
      "  time_since_restore: 21811.177150964737\n",
      "  time_this_iter_s: 21.81941509246826\n",
      "  time_total_s: 21811.177150964737\n",
      "  timestamp: 1553730856\n",
      "  timesteps_since_restore: 8810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8810000\n",
      "  training_iteration: 881\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21811 s, 881 iter, 8810000 ts, 732 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-54-38\n",
      "  done: false\n",
      "  episode_len_mean: 142.54\n",
      "  episode_reward_max: 789.7706164983883\n",
      "  episode_reward_mean: 700.6786441660361\n",
      "  episode_reward_min: -88.50066365339251\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 66080\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3734.637\n",
      "    load_time_ms: 1.947\n",
      "    num_steps_sampled: 8820000\n",
      "    num_steps_trained: 8820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.16091787815094\n",
      "      kl: 0.010527231730520725\n",
      "      policy_loss: -0.0015730839222669601\n",
      "      total_loss: 267.6103820800781\n",
      "      vf_explained_var: 0.9848397970199585\n",
      "      vf_loss: 267.6114807128906\n",
      "    sample_time_ms: 18352.057\n",
      "    update_time_ms: 5.386\n",
      "  iterations_since_restore: 882\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 350.3393220830182\n",
      "  time_since_restore: 21832.80896639824\n",
      "  time_this_iter_s: 21.631815433502197\n",
      "  time_total_s: 21832.80896639824\n",
      "  timestamp: 1553730878\n",
      "  timesteps_since_restore: 8820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8820000\n",
      "  training_iteration: 882\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21832 s, 882 iter, 8820000 ts, 701 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-55-00\n",
      "  done: false\n",
      "  episode_len_mean: 134.02\n",
      "  episode_reward_max: 796.8254350981227\n",
      "  episode_reward_mean: 698.1302032027733\n",
      "  episode_reward_min: -88.50066365339251\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 66158\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3737.515\n",
      "    load_time_ms: 1.924\n",
      "    num_steps_sampled: 8830000\n",
      "    num_steps_trained: 8830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7277309894561768\n",
      "      kl: 0.023754632100462914\n",
      "      policy_loss: -0.0029419325292110443\n",
      "      total_loss: 74.95307159423828\n",
      "      vf_explained_var: 0.9946932792663574\n",
      "      vf_loss: 74.95494079589844\n",
      "    sample_time_ms: 18330.118\n",
      "    update_time_ms: 5.432\n",
      "  iterations_since_restore: 883\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.0651016013867\n",
      "  time_since_restore: 21854.823456048965\n",
      "  time_this_iter_s: 22.01448965072632\n",
      "  time_total_s: 21854.823456048965\n",
      "  timestamp: 1553730900\n",
      "  timesteps_since_restore: 8830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8830000\n",
      "  training_iteration: 883\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21854 s, 883 iter, 8830000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-55-22\n",
      "  done: false\n",
      "  episode_len_mean: 133.9\n",
      "  episode_reward_max: 796.8254350981227\n",
      "  episode_reward_mean: 697.2774765821715\n",
      "  episode_reward_min: -76.81745784404902\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 66233\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.419\n",
      "    load_time_ms: 1.747\n",
      "    num_steps_sampled: 8840000\n",
      "    num_steps_trained: 8840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8453162908554077\n",
      "      kl: 0.014183814637362957\n",
      "      policy_loss: 0.000568788789678365\n",
      "      total_loss: 162.92872619628906\n",
      "      vf_explained_var: 0.9899759292602539\n",
      "      vf_loss: 162.92752075195312\n",
      "    sample_time_ms: 18255.246\n",
      "    update_time_ms: 5.288\n",
      "  iterations_since_restore: 884\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.6387382910857\n",
      "  time_since_restore: 21876.739130973816\n",
      "  time_this_iter_s: 21.915674924850464\n",
      "  time_total_s: 21876.739130973816\n",
      "  timestamp: 1553730922\n",
      "  timesteps_since_restore: 8840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8840000\n",
      "  training_iteration: 884\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21876 s, 884 iter, 8840000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 140.88\n",
      "  episode_reward_max: 794.5427961583225\n",
      "  episode_reward_mean: 675.6379383368628\n",
      "  episode_reward_min: -81.14057396423382\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 66305\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3739.412\n",
      "    load_time_ms: 1.782\n",
      "    num_steps_sampled: 8850000\n",
      "    num_steps_trained: 8850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.27717125415802\n",
      "      kl: 0.016315460205078125\n",
      "      policy_loss: -0.0011255642166361213\n",
      "      total_loss: 421.2967834472656\n",
      "      vf_explained_var: 0.9744030833244324\n",
      "      vf_loss: 421.29718017578125\n",
      "    sample_time_ms: 18198.061\n",
      "    update_time_ms: 5.34\n",
      "  iterations_since_restore: 885\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.8189691684315\n",
      "  time_since_restore: 21898.768440961838\n",
      "  time_this_iter_s: 22.02930998802185\n",
      "  time_total_s: 21898.768440961838\n",
      "  timestamp: 1553730944\n",
      "  timesteps_since_restore: 8850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8850000\n",
      "  training_iteration: 885\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21898 s, 885 iter, 8850000 ts, 676 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-56-06\n",
      "  done: false\n",
      "  episode_len_mean: 144.86\n",
      "  episode_reward_max: 784.4240527959715\n",
      "  episode_reward_mean: 658.3089058639365\n",
      "  episode_reward_min: -97.93170667140528\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 66377\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.391\n",
      "    load_time_ms: 1.758\n",
      "    num_steps_sampled: 8860000\n",
      "    num_steps_trained: 8860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1313018798828125\n",
      "      kl: 0.015142596326768398\n",
      "      policy_loss: -0.0016931646969169378\n",
      "      total_loss: 264.29345703125\n",
      "      vf_explained_var: 0.9826844334602356\n",
      "      vf_loss: 264.29443359375\n",
      "    sample_time_ms: 18237.429\n",
      "    update_time_ms: 5.197\n",
      "  iterations_since_restore: 886\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 329.15445293196825\n",
      "  time_since_restore: 21921.06437444687\n",
      "  time_this_iter_s: 22.295933485031128\n",
      "  time_total_s: 21921.06437444687\n",
      "  timestamp: 1553730966\n",
      "  timesteps_since_restore: 8860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8860000\n",
      "  training_iteration: 886\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21921 s, 886 iter, 8860000 ts, 658 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 148.02\n",
      "  episode_reward_max: 789.018569788034\n",
      "  episode_reward_mean: 651.0533116173558\n",
      "  episode_reward_min: -97.93170667140528\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 66446\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.957\n",
      "    load_time_ms: 1.716\n",
      "    num_steps_sampled: 8870000\n",
      "    num_steps_trained: 8870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.388198733329773\n",
      "      kl: 0.014041442424058914\n",
      "      policy_loss: -0.0017371498979628086\n",
      "      total_loss: 359.13720703125\n",
      "      vf_explained_var: 0.9811111092567444\n",
      "      vf_loss: 359.1383361816406\n",
      "    sample_time_ms: 18288.569\n",
      "    update_time_ms: 5.118\n",
      "  iterations_since_restore: 887\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 325.52665580867784\n",
      "  time_since_restore: 21943.493945598602\n",
      "  time_this_iter_s: 22.4295711517334\n",
      "  time_total_s: 21943.493945598602\n",
      "  timestamp: 1553730988\n",
      "  timesteps_since_restore: 8870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8870000\n",
      "  training_iteration: 887\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21943 s, 887 iter, 8870000 ts, 651 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-56-51\n",
      "  done: false\n",
      "  episode_len_mean: 138.38\n",
      "  episode_reward_max: 793.1144610398396\n",
      "  episode_reward_mean: 680.7814193908633\n",
      "  episode_reward_min: -39.405174271564675\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 66525\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.808\n",
      "    load_time_ms: 1.647\n",
      "    num_steps_sampled: 8880000\n",
      "    num_steps_trained: 8880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.04533391818404198\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5985181927680969\n",
      "      kl: 0.049049098044633865\n",
      "      policy_loss: 0.0010632012272253633\n",
      "      total_loss: 110.18328094482422\n",
      "      vf_explained_var: 0.9916530251502991\n",
      "      vf_loss: 110.17998504638672\n",
      "    sample_time_ms: 18284.475\n",
      "    update_time_ms: 5.248\n",
      "  iterations_since_restore: 888\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.39070969543155\n",
      "  time_since_restore: 21965.654366016388\n",
      "  time_this_iter_s: 22.160420417785645\n",
      "  time_total_s: 21965.654366016388\n",
      "  timestamp: 1553731011\n",
      "  timesteps_since_restore: 8880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8880000\n",
      "  training_iteration: 888\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21965 s, 888 iter, 8880000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-57-13\n",
      "  done: false\n",
      "  episode_len_mean: 134.22\n",
      "  episode_reward_max: 793.1144610398396\n",
      "  episode_reward_mean: 699.404427546909\n",
      "  episode_reward_min: -47.58096163307329\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 66597\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.852\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 8890000\n",
      "    num_steps_trained: 8890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.028048038482666\n",
      "      kl: 0.011850332841277122\n",
      "      policy_loss: -0.0012684892863035202\n",
      "      total_loss: 204.89480590820312\n",
      "      vf_explained_var: 0.9867016673088074\n",
      "      vf_loss: 204.89527893066406\n",
      "    sample_time_ms: 18318.228\n",
      "    update_time_ms: 5.168\n",
      "  iterations_since_restore: 889\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.70221377345456\n",
      "  time_since_restore: 21987.98229932785\n",
      "  time_this_iter_s: 22.327933311462402\n",
      "  time_total_s: 21987.98229932785\n",
      "  timestamp: 1553731033\n",
      "  timesteps_since_restore: 8890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8890000\n",
      "  training_iteration: 889\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 21987 s, 889 iter, 8890000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-57-35\n",
      "  done: false\n",
      "  episode_len_mean: 138.12\n",
      "  episode_reward_max: 788.6523149541766\n",
      "  episode_reward_mean: 697.8681924879259\n",
      "  episode_reward_min: -79.20929225340821\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 66675\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.18\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 8900000\n",
      "    num_steps_trained: 8900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6338897347450256\n",
      "      kl: 0.017670517787337303\n",
      "      policy_loss: -0.00529041513800621\n",
      "      total_loss: 214.0351104736328\n",
      "      vf_explained_var: 0.9860621690750122\n",
      "      vf_loss: 214.03916931152344\n",
      "    sample_time_ms: 18325.327\n",
      "    update_time_ms: 5.232\n",
      "  iterations_since_restore: 890\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.934096243963\n",
      "  time_since_restore: 22010.13576555252\n",
      "  time_this_iter_s: 22.15346622467041\n",
      "  time_total_s: 22010.13576555252\n",
      "  timestamp: 1553731055\n",
      "  timesteps_since_restore: 8900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8900000\n",
      "  training_iteration: 890\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22010 s, 890 iter, 8900000 ts, 698 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 133.51\n",
      "  episode_reward_max: 804.0992517024358\n",
      "  episode_reward_mean: 680.9258540086016\n",
      "  episode_reward_min: -109.40059324041431\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 66750\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3747.338\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 8910000\n",
      "    num_steps_trained: 8910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9879719614982605\n",
      "      kl: 0.024619344621896744\n",
      "      policy_loss: -0.008418739773333073\n",
      "      total_loss: 603.467529296875\n",
      "      vf_explained_var: 0.9609273076057434\n",
      "      vf_loss: 603.4743041992188\n",
      "    sample_time_ms: 18270.874\n",
      "    update_time_ms: 5.163\n",
      "  iterations_since_restore: 891\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.46292700430087\n",
      "  time_since_restore: 22031.610095262527\n",
      "  time_this_iter_s: 21.474329710006714\n",
      "  time_total_s: 22031.610095262527\n",
      "  timestamp: 1553731077\n",
      "  timesteps_since_restore: 8910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8910000\n",
      "  training_iteration: 891\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22031 s, 891 iter, 8910000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-58-19\n",
      "  done: false\n",
      "  episode_len_mean: 136.92\n",
      "  episode_reward_max: 804.0992517024358\n",
      "  episode_reward_mean: 658.1060806579827\n",
      "  episode_reward_min: -86.87620481144322\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66823\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3750.257\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 8920000\n",
      "    num_steps_trained: 8920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.232663869857788\n",
      "      kl: 0.010886700823903084\n",
      "      policy_loss: -0.001254903618246317\n",
      "      total_loss: 309.1579895019531\n",
      "      vf_explained_var: 0.9803807139396667\n",
      "      vf_loss: 309.1585388183594\n",
      "    sample_time_ms: 18314.999\n",
      "    update_time_ms: 5.158\n",
      "  iterations_since_restore: 892\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 329.05304032899136\n",
      "  time_since_restore: 22053.711031913757\n",
      "  time_this_iter_s: 22.10093665122986\n",
      "  time_total_s: 22053.711031913757\n",
      "  timestamp: 1553731099\n",
      "  timesteps_since_restore: 8920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8920000\n",
      "  training_iteration: 892\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22053 s, 892 iter, 8920000 ts, 658 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-58-41\n",
      "  done: false\n",
      "  episode_len_mean: 143.04\n",
      "  episode_reward_max: 801.208950621601\n",
      "  episode_reward_mean: 642.4097880185121\n",
      "  episode_reward_min: -91.17282830374867\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 66896\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3747.992\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 8930000\n",
      "    num_steps_trained: 8930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0639809370040894\n",
      "      kl: 0.011800320819020271\n",
      "      policy_loss: -0.0014791160356253386\n",
      "      total_loss: 216.3476104736328\n",
      "      vf_explained_var: 0.9879522919654846\n",
      "      vf_loss: 216.34825134277344\n",
      "    sample_time_ms: 18272.55\n",
      "    update_time_ms: 5.131\n",
      "  iterations_since_restore: 893\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 321.204894009256\n",
      "  time_since_restore: 22075.28046154976\n",
      "  time_this_iter_s: 21.569429636001587\n",
      "  time_total_s: 22075.28046154976\n",
      "  timestamp: 1553731121\n",
      "  timesteps_since_restore: 8930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8930000\n",
      "  training_iteration: 893\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22075 s, 893 iter, 8930000 ts, 642 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-59-02\n",
      "  done: false\n",
      "  episode_len_mean: 136.24\n",
      "  episode_reward_max: 801.208950621601\n",
      "  episode_reward_mean: 672.4182240514949\n",
      "  episode_reward_min: -91.17282830374867\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 66970\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.528\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 8940000\n",
      "    num_steps_trained: 8940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0429787635803223\n",
      "      kl: 0.01579548791050911\n",
      "      policy_loss: -0.0008486072765663266\n",
      "      total_loss: 388.2112731933594\n",
      "      vf_explained_var: 0.9769740700721741\n",
      "      vf_loss: 388.2110290527344\n",
      "    sample_time_ms: 18255.594\n",
      "    update_time_ms: 4.984\n",
      "  iterations_since_restore: 894\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.20911202574746\n",
      "  time_since_restore: 22096.999308109283\n",
      "  time_this_iter_s: 21.718846559524536\n",
      "  time_total_s: 22096.999308109283\n",
      "  timestamp: 1553731142\n",
      "  timesteps_since_restore: 8940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8940000\n",
      "  training_iteration: 894\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22096 s, 894 iter, 8940000 ts, 672 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-59-24\n",
      "  done: false\n",
      "  episode_len_mean: 140.61\n",
      "  episode_reward_max: 789.2375585872028\n",
      "  episode_reward_mean: 676.8610227447265\n",
      "  episode_reward_min: -75.43082334015101\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 67043\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3751.989\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 8950000\n",
      "    num_steps_trained: 8950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0614367723464966\n",
      "      kl: 0.014221458695828915\n",
      "      policy_loss: -0.0020921947434544563\n",
      "      total_loss: 159.82139587402344\n",
      "      vf_explained_var: 0.9900102019309998\n",
      "      vf_loss: 159.82252502441406\n",
      "    sample_time_ms: 18214.734\n",
      "    update_time_ms: 4.901\n",
      "  iterations_since_restore: 895\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.4305113723633\n",
      "  time_since_restore: 22118.681672811508\n",
      "  time_this_iter_s: 21.68236470222473\n",
      "  time_total_s: 22118.681672811508\n",
      "  timestamp: 1553731164\n",
      "  timesteps_since_restore: 8950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8950000\n",
      "  training_iteration: 895\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22118 s, 895 iter, 8950000 ts, 677 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_00-59-46\n",
      "  done: false\n",
      "  episode_len_mean: 140.03\n",
      "  episode_reward_max: 786.2342594518552\n",
      "  episode_reward_mean: 651.8245248677032\n",
      "  episode_reward_min: -87.69043922959524\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 67118\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3750.713\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 8960000\n",
      "    num_steps_trained: 8960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1010233163833618\n",
      "      kl: 0.011503763496875763\n",
      "      policy_loss: -0.0019255838124081492\n",
      "      total_loss: 245.61898803710938\n",
      "      vf_explained_var: 0.984808087348938\n",
      "      vf_loss: 245.62008666992188\n",
      "    sample_time_ms: 18197.803\n",
      "    update_time_ms: 4.946\n",
      "  iterations_since_restore: 896\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 325.9122624338516\n",
      "  time_since_restore: 22140.800267457962\n",
      "  time_this_iter_s: 22.118594646453857\n",
      "  time_total_s: 22140.800267457962\n",
      "  timestamp: 1553731186\n",
      "  timesteps_since_restore: 8960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8960000\n",
      "  training_iteration: 896\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22140 s, 896 iter, 8960000 ts, 652 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-00-08\n",
      "  done: false\n",
      "  episode_len_mean: 135.26\n",
      "  episode_reward_max: 792.0616913624132\n",
      "  episode_reward_mean: 652.7222241189586\n",
      "  episode_reward_min: -87.69043922959524\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 67193\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.907\n",
      "    load_time_ms: 1.517\n",
      "    num_steps_sampled: 8970000\n",
      "    num_steps_trained: 8970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1299188137054443\n",
      "      kl: 0.021989474073052406\n",
      "      policy_loss: -0.005249733570963144\n",
      "      total_loss: 203.25408935546875\n",
      "      vf_explained_var: 0.988195538520813\n",
      "      vf_loss: 203.25784301757812\n",
      "    sample_time_ms: 18150.999\n",
      "    update_time_ms: 5.055\n",
      "  iterations_since_restore: 897\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 326.3611120594794\n",
      "  time_since_restore: 22162.711325645447\n",
      "  time_this_iter_s: 21.91105818748474\n",
      "  time_total_s: 22162.711325645447\n",
      "  timestamp: 1553731208\n",
      "  timesteps_since_restore: 8970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8970000\n",
      "  training_iteration: 897\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22162 s, 897 iter, 8970000 ts, 653 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-00-30\n",
      "  done: false\n",
      "  episode_len_mean: 151.49\n",
      "  episode_reward_max: 798.8209931853829\n",
      "  episode_reward_mean: 645.3909142089313\n",
      "  episode_reward_min: -82.85685835090847\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 67258\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.724\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 8980000\n",
      "    num_steps_trained: 8980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6706494092941284\n",
      "      kl: 0.015640467405319214\n",
      "      policy_loss: -0.0013139878865331411\n",
      "      total_loss: 411.71575927734375\n",
      "      vf_explained_var: 0.9770855903625488\n",
      "      vf_loss: 411.7160339355469\n",
      "    sample_time_ms: 18152.395\n",
      "    update_time_ms: 4.969\n",
      "  iterations_since_restore: 898\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 322.6954571044657\n",
      "  time_since_restore: 22184.896415948868\n",
      "  time_this_iter_s: 22.18509030342102\n",
      "  time_total_s: 22184.896415948868\n",
      "  timestamp: 1553731230\n",
      "  timesteps_since_restore: 8980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8980000\n",
      "  training_iteration: 898\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22184 s, 898 iter, 8980000 ts, 645 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-00-52\n",
      "  done: false\n",
      "  episode_len_mean: 157.21\n",
      "  episode_reward_max: 798.8209931853829\n",
      "  episode_reward_mean: 648.2108367621979\n",
      "  episode_reward_min: -82.85685835090847\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 67326\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.062\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 8990000\n",
      "    num_steps_trained: 8990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4551364183425903\n",
      "      kl: 0.02150413952767849\n",
      "      policy_loss: -0.0039483532309532166\n",
      "      total_loss: 236.44444274902344\n",
      "      vf_explained_var: 0.9862516522407532\n",
      "      vf_loss: 236.44691467285156\n",
      "    sample_time_ms: 18093.869\n",
      "    update_time_ms: 4.787\n",
      "  iterations_since_restore: 899\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.1054183810989\n",
      "  time_since_restore: 22206.622935533524\n",
      "  time_this_iter_s: 21.72651958465576\n",
      "  time_total_s: 22206.622935533524\n",
      "  timestamp: 1553731252\n",
      "  timesteps_since_restore: 8990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8990000\n",
      "  training_iteration: 899\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22206 s, 899 iter, 8990000 ts, 648 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-01-14\n",
      "  done: false\n",
      "  episode_len_mean: 147.0\n",
      "  episode_reward_max: 794.5504488395827\n",
      "  episode_reward_mean: 672.4894282381097\n",
      "  episode_reward_min: -102.16912223510803\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 67400\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.073\n",
      "    load_time_ms: 1.543\n",
      "    num_steps_sampled: 9000000\n",
      "    num_steps_trained: 9000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0984028577804565\n",
      "      kl: 0.017759637907147408\n",
      "      policy_loss: -0.0019977812189608812\n",
      "      total_loss: 434.1837463378906\n",
      "      vf_explained_var: 0.9682930111885071\n",
      "      vf_loss: 434.1845397949219\n",
      "    sample_time_ms: 18042.579\n",
      "    update_time_ms: 4.8\n",
      "  iterations_since_restore: 900\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.24471411905483\n",
      "  time_since_restore: 22228.265510559082\n",
      "  time_this_iter_s: 21.64257502555847\n",
      "  time_total_s: 22228.265510559082\n",
      "  timestamp: 1553731274\n",
      "  timesteps_since_restore: 9000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9000000\n",
      "  training_iteration: 900\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22228 s, 900 iter, 9000000 ts, 672 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-01-36\n",
      "  done: false\n",
      "  episode_len_mean: 129.83\n",
      "  episode_reward_max: 790.641569236774\n",
      "  episode_reward_mean: 681.5711249361578\n",
      "  episode_reward_min: -102.16912223510803\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 67478\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.568\n",
      "    load_time_ms: 1.545\n",
      "    num_steps_sampled: 9010000\n",
      "    num_steps_trained: 9010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6920166015625\n",
      "      kl: 0.01656617596745491\n",
      "      policy_loss: -0.003969463985413313\n",
      "      total_loss: 413.7501220703125\n",
      "      vf_explained_var: 0.971280038356781\n",
      "      vf_loss: 413.75299072265625\n",
      "    sample_time_ms: 18164.383\n",
      "    update_time_ms: 4.951\n",
      "  iterations_since_restore: 901\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.7855624680789\n",
      "  time_since_restore: 22250.746253490448\n",
      "  time_this_iter_s: 22.480742931365967\n",
      "  time_total_s: 22250.746253490448\n",
      "  timestamp: 1553731296\n",
      "  timesteps_since_restore: 9010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9010000\n",
      "  training_iteration: 901\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22250 s, 901 iter, 9010000 ts, 682 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-01-59\n",
      "  done: false\n",
      "  episode_len_mean: 131.12\n",
      "  episode_reward_max: 790.641569236774\n",
      "  episode_reward_mean: 704.8500864692668\n",
      "  episode_reward_min: -14.535837937992653\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 67555\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.676\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 9020000\n",
      "    num_steps_trained: 9020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.06800085306167603\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7623259425163269\n",
      "      kl: 0.009874780662357807\n",
      "      policy_loss: 0.000771290622651577\n",
      "      total_loss: 153.10421752929688\n",
      "      vf_explained_var: 0.9884875416755676\n",
      "      vf_loss: 153.10275268554688\n",
      "    sample_time_ms: 18200.492\n",
      "    update_time_ms: 5.04\n",
      "  iterations_since_restore: 902\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.42504323463334\n",
      "  time_since_restore: 22273.198895454407\n",
      "  time_this_iter_s: 22.45264196395874\n",
      "  time_total_s: 22273.198895454407\n",
      "  timestamp: 1553731319\n",
      "  timesteps_since_restore: 9020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9020000\n",
      "  training_iteration: 902\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22273 s, 902 iter, 9020000 ts, 705 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-02-21\n",
      "  done: false\n",
      "  episode_len_mean: 133.44\n",
      "  episode_reward_max: 778.4809733980453\n",
      "  episode_reward_mean: 673.5364498290147\n",
      "  episode_reward_min: -77.36692728301645\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 67631\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.468\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 9030000\n",
      "    num_steps_trained: 9030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.071664571762085\n",
      "      kl: 0.017360467463731766\n",
      "      policy_loss: -0.0028403615579009056\n",
      "      total_loss: 354.5821838378906\n",
      "      vf_explained_var: 0.976814866065979\n",
      "      vf_loss: 354.5844421386719\n",
      "    sample_time_ms: 18292.203\n",
      "    update_time_ms: 5.111\n",
      "  iterations_since_restore: 903\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.76822491450747\n",
      "  time_since_restore: 22295.67145705223\n",
      "  time_this_iter_s: 22.472561597824097\n",
      "  time_total_s: 22295.67145705223\n",
      "  timestamp: 1553731341\n",
      "  timesteps_since_restore: 9030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9030000\n",
      "  training_iteration: 903\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22295 s, 903 iter, 9030000 ts, 674 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-02-44\n",
      "  done: false\n",
      "  episode_len_mean: 141.5\n",
      "  episode_reward_max: 784.9147505545935\n",
      "  episode_reward_mean: 657.391116247241\n",
      "  episode_reward_min: -103.77662384959271\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 67703\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.192\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 9040000\n",
      "    num_steps_trained: 9040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.267236351966858\n",
      "      kl: 0.013913934119045734\n",
      "      policy_loss: -0.0019937120378017426\n",
      "      total_loss: 352.5793151855469\n",
      "      vf_explained_var: 0.9797792434692383\n",
      "      vf_loss: 352.5808410644531\n",
      "    sample_time_ms: 18348.045\n",
      "    update_time_ms: 5.236\n",
      "  iterations_since_restore: 904\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 328.69555812362046\n",
      "  time_since_restore: 22317.95907664299\n",
      "  time_this_iter_s: 22.287619590759277\n",
      "  time_total_s: 22317.95907664299\n",
      "  timestamp: 1553731364\n",
      "  timesteps_since_restore: 9040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9040000\n",
      "  training_iteration: 904\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22317 s, 904 iter, 9040000 ts, 657 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-03-06\n",
      "  done: false\n",
      "  episode_len_mean: 141.2\n",
      "  episode_reward_max: 796.2813188053767\n",
      "  episode_reward_mean: 686.5422318886472\n",
      "  episode_reward_min: -103.77662384959271\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 67777\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.755\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 9050000\n",
      "    num_steps_trained: 9050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0459113121032715\n",
      "      kl: 0.016364727169275284\n",
      "      policy_loss: -0.0021148924715816975\n",
      "      total_loss: 311.21234130859375\n",
      "      vf_explained_var: 0.9785124659538269\n",
      "      vf_loss: 311.21392822265625\n",
      "    sample_time_ms: 18427.505\n",
      "    update_time_ms: 5.424\n",
      "  iterations_since_restore: 905\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.2711159443237\n",
      "  time_since_restore: 22340.36072254181\n",
      "  time_this_iter_s: 22.40164589881897\n",
      "  time_total_s: 22340.36072254181\n",
      "  timestamp: 1553731386\n",
      "  timesteps_since_restore: 9050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9050000\n",
      "  training_iteration: 905\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22340 s, 905 iter, 9050000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-03-28\n",
      "  done: false\n",
      "  episode_len_mean: 144.6\n",
      "  episode_reward_max: 796.2813188053767\n",
      "  episode_reward_mean: 652.6842406297297\n",
      "  episode_reward_min: -70.84216537884109\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 67847\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.161\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 9060000\n",
      "    num_steps_trained: 9060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5568900108337402\n",
      "      kl: 0.020907875150442123\n",
      "      policy_loss: -0.004570025485008955\n",
      "      total_loss: 262.271728515625\n",
      "      vf_explained_var: 0.9851365685462952\n",
      "      vf_loss: 262.2756042480469\n",
      "    sample_time_ms: 18362.577\n",
      "    update_time_ms: 5.439\n",
      "  iterations_since_restore: 906\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 326.3421203148648\n",
      "  time_since_restore: 22362.03877401352\n",
      "  time_this_iter_s: 21.678051471710205\n",
      "  time_total_s: 22362.03877401352\n",
      "  timestamp: 1553731408\n",
      "  timesteps_since_restore: 9060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9060000\n",
      "  training_iteration: 906\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22362 s, 906 iter, 9060000 ts, 653 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-03-49\n",
      "  done: false\n",
      "  episode_len_mean: 153.31\n",
      "  episode_reward_max: 801.737574863036\n",
      "  episode_reward_mean: 625.7192334964191\n",
      "  episode_reward_min: -84.69127116435477\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 67917\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3732.753\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 9070000\n",
      "    num_steps_trained: 9070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.51828134059906\n",
      "      kl: 0.01619335636496544\n",
      "      policy_loss: -0.0024824889842420816\n",
      "      total_loss: 164.4548797607422\n",
      "      vf_explained_var: 0.9911898374557495\n",
      "      vf_loss: 164.4568328857422\n",
      "    sample_time_ms: 18325.981\n",
      "    update_time_ms: 5.416\n",
      "  iterations_since_restore: 907\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 312.85961674820953\n",
      "  time_since_restore: 22383.5526535511\n",
      "  time_this_iter_s: 21.513879537582397\n",
      "  time_total_s: 22383.5526535511\n",
      "  timestamp: 1553731429\n",
      "  timesteps_since_restore: 9070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9070000\n",
      "  training_iteration: 907\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22383 s, 907 iter, 9070000 ts, 626 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-04-12\n",
      "  done: false\n",
      "  episode_len_mean: 153.99\n",
      "  episode_reward_max: 801.737574863036\n",
      "  episode_reward_mean: 657.0446298688079\n",
      "  episode_reward_min: -84.69127116435477\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 67986\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.565\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 9080000\n",
      "    num_steps_trained: 9080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3180971145629883\n",
      "      kl: 0.022065524011850357\n",
      "      policy_loss: -0.004098182078450918\n",
      "      total_loss: 465.5378723144531\n",
      "      vf_explained_var: 0.9733591079711914\n",
      "      vf_loss: 465.541259765625\n",
      "    sample_time_ms: 18338.104\n",
      "    update_time_ms: 5.605\n",
      "  iterations_since_restore: 908\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 328.5223149344038\n",
      "  time_since_restore: 22405.885722637177\n",
      "  time_this_iter_s: 22.33306908607483\n",
      "  time_total_s: 22405.885722637177\n",
      "  timestamp: 1553731452\n",
      "  timesteps_since_restore: 9080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9080000\n",
      "  training_iteration: 908\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22405 s, 908 iter, 9080000 ts, 657 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-04-34\n",
      "  done: false\n",
      "  episode_len_mean: 140.6\n",
      "  episode_reward_max: 789.5346469530926\n",
      "  episode_reward_mean: 682.8938046215593\n",
      "  episode_reward_min: -76.76378306523483\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 68061\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3738.549\n",
      "    load_time_ms: 1.388\n",
      "    num_steps_sampled: 9090000\n",
      "    num_steps_trained: 9090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9884119033813477\n",
      "      kl: 0.015195822343230247\n",
      "      policy_loss: -0.0028422230388969183\n",
      "      total_loss: 367.1747741699219\n",
      "      vf_explained_var: 0.9739646911621094\n",
      "      vf_loss: 367.1770935058594\n",
      "    sample_time_ms: 18363.596\n",
      "    update_time_ms: 5.722\n",
      "  iterations_since_restore: 909\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.4469023107797\n",
      "  time_since_restore: 22427.89348602295\n",
      "  time_this_iter_s: 22.007763385772705\n",
      "  time_total_s: 22427.89348602295\n",
      "  timestamp: 1553731474\n",
      "  timesteps_since_restore: 9090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9090000\n",
      "  training_iteration: 909\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22427 s, 909 iter, 9090000 ts, 683 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-04-56\n",
      "  done: false\n",
      "  episode_len_mean: 137.88\n",
      "  episode_reward_max: 789.5346469530926\n",
      "  episode_reward_mean: 664.4019042216855\n",
      "  episode_reward_min: -87.15368186521074\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 68134\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.127\n",
      "    load_time_ms: 1.362\n",
      "    num_steps_sampled: 9100000\n",
      "    num_steps_trained: 9100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.36686372756958\n",
      "      kl: 0.013001315295696259\n",
      "      policy_loss: -0.0032771688420325518\n",
      "      total_loss: 441.29827880859375\n",
      "      vf_explained_var: 0.9730443954467773\n",
      "      vf_loss: 441.3011779785156\n",
      "    sample_time_ms: 18423.713\n",
      "    update_time_ms: 5.644\n",
      "  iterations_since_restore: 910\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 332.20095211084276\n",
      "  time_since_restore: 22450.280202627182\n",
      "  time_this_iter_s: 22.386716604232788\n",
      "  time_total_s: 22450.280202627182\n",
      "  timestamp: 1553731496\n",
      "  timesteps_since_restore: 9100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9100000\n",
      "  training_iteration: 910\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22450 s, 910 iter, 9100000 ts, 664 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-05-18\n",
      "  done: false\n",
      "  episode_len_mean: 144.0\n",
      "  episode_reward_max: 795.5079027626524\n",
      "  episode_reward_mean: 655.571595031282\n",
      "  episode_reward_min: -87.15368186521074\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68206\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.6\n",
      "    load_time_ms: 1.374\n",
      "    num_steps_sampled: 9110000\n",
      "    num_steps_trained: 9110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.197886347770691\n",
      "      kl: 0.014883349649608135\n",
      "      policy_loss: -0.0014235114213079214\n",
      "      total_loss: 322.43841552734375\n",
      "      vf_explained_var: 0.9794233441352844\n",
      "      vf_loss: 322.4393005371094\n",
      "    sample_time_ms: 18385.861\n",
      "    update_time_ms: 5.563\n",
      "  iterations_since_restore: 911\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 327.785797515641\n",
      "  time_since_restore: 22472.386308431625\n",
      "  time_this_iter_s: 22.10610580444336\n",
      "  time_total_s: 22472.386308431625\n",
      "  timestamp: 1553731518\n",
      "  timesteps_since_restore: 9110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9110000\n",
      "  training_iteration: 911\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22472 s, 911 iter, 9110000 ts, 656 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-05-40\n",
      "  done: false\n",
      "  episode_len_mean: 144.27\n",
      "  episode_reward_max: 795.5079027626524\n",
      "  episode_reward_mean: 676.3167795378644\n",
      "  episode_reward_min: -65.15566088341478\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68278\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3752.076\n",
      "    load_time_ms: 1.428\n",
      "    num_steps_sampled: 9120000\n",
      "    num_steps_trained: 9120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2569656372070312\n",
      "      kl: 0.017486615106463432\n",
      "      policy_loss: -0.0019513186998665333\n",
      "      total_loss: 326.9856872558594\n",
      "      vf_explained_var: 0.9782010316848755\n",
      "      vf_loss: 326.9870300292969\n",
      "    sample_time_ms: 18342.287\n",
      "    update_time_ms: 5.659\n",
      "  iterations_since_restore: 912\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.15838976893224\n",
      "  time_since_restore: 22494.39394044876\n",
      "  time_this_iter_s: 22.00763201713562\n",
      "  time_total_s: 22494.39394044876\n",
      "  timestamp: 1553731540\n",
      "  timesteps_since_restore: 9120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9120000\n",
      "  training_iteration: 912\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22494 s, 912 iter, 9120000 ts, 676 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-06-02\n",
      "  done: false\n",
      "  episode_len_mean: 141.18\n",
      "  episode_reward_max: 794.578558508578\n",
      "  episode_reward_mean: 685.5070202696307\n",
      "  episode_reward_min: -65.15566088341478\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 68354\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3755.403\n",
      "    load_time_ms: 1.442\n",
      "    num_steps_sampled: 9130000\n",
      "    num_steps_trained: 9130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8837272524833679\n",
      "      kl: 0.018345903605222702\n",
      "      policy_loss: -0.003781203180551529\n",
      "      total_loss: 251.3907470703125\n",
      "      vf_explained_var: 0.9810182452201843\n",
      "      vf_loss: 251.3938751220703\n",
      "    sample_time_ms: 18272.776\n",
      "    update_time_ms: 5.657\n",
      "  iterations_since_restore: 913\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.75351013481543\n",
      "  time_since_restore: 22516.206654548645\n",
      "  time_this_iter_s: 21.812714099884033\n",
      "  time_total_s: 22516.206654548645\n",
      "  timestamp: 1553731562\n",
      "  timesteps_since_restore: 9130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9130000\n",
      "  training_iteration: 913\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22516 s, 913 iter, 9130000 ts, 686 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-06-24\n",
      "  done: false\n",
      "  episode_len_mean: 139.91\n",
      "  episode_reward_max: 794.578558508578\n",
      "  episode_reward_mean: 694.2483494859765\n",
      "  episode_reward_min: -20.844411610991443\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 68425\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3755.061\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 9140000\n",
      "    num_steps_trained: 9140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2787973880767822\n",
      "      kl: 0.01159703265875578\n",
      "      policy_loss: -0.0012942353496327996\n",
      "      total_loss: 324.8293151855469\n",
      "      vf_explained_var: 0.9792312383651733\n",
      "      vf_loss: 324.8302307128906\n",
      "    sample_time_ms: 18191.506\n",
      "    update_time_ms: 5.837\n",
      "  iterations_since_restore: 914\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.12417474298826\n",
      "  time_since_restore: 22537.67920398712\n",
      "  time_this_iter_s: 21.472549438476562\n",
      "  time_total_s: 22537.67920398712\n",
      "  timestamp: 1553731584\n",
      "  timesteps_since_restore: 9140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9140000\n",
      "  training_iteration: 914\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22537 s, 914 iter, 9140000 ts, 694 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-06-46\n",
      "  done: false\n",
      "  episode_len_mean: 139.8\n",
      "  episode_reward_max: 790.1778006798398\n",
      "  episode_reward_mean: 691.5186884770561\n",
      "  episode_reward_min: -64.53762578861088\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 68500\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3755.822\n",
      "    load_time_ms: 1.484\n",
      "    num_steps_sampled: 9150000\n",
      "    num_steps_trained: 9150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0077483654022217\n",
      "      kl: 0.03567807748913765\n",
      "      policy_loss: -0.0039831711910665035\n",
      "      total_loss: 145.90809631347656\n",
      "      vf_explained_var: 0.9905006289482117\n",
      "      vf_loss: 145.91085815429688\n",
      "    sample_time_ms: 18144.095\n",
      "    update_time_ms: 5.659\n",
      "  iterations_since_restore: 915\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.75934423852806\n",
      "  time_since_restore: 22559.61577296257\n",
      "  time_this_iter_s: 21.93656897544861\n",
      "  time_total_s: 22559.61577296257\n",
      "  timestamp: 1553731606\n",
      "  timesteps_since_restore: 9150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9150000\n",
      "  training_iteration: 915\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22559 s, 915 iter, 9150000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-07-08\n",
      "  done: false\n",
      "  episode_len_mean: 140.59\n",
      "  episode_reward_max: 793.9804345521242\n",
      "  episode_reward_mean: 690.4225739639804\n",
      "  episode_reward_min: -97.60544740901298\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68572\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.746\n",
      "    load_time_ms: 1.549\n",
      "    num_steps_sampled: 9160000\n",
      "    num_steps_trained: 9160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.297040343284607\n",
      "      kl: 0.011883234605193138\n",
      "      policy_loss: -0.002114532282575965\n",
      "      total_loss: 405.1617736816406\n",
      "      vf_explained_var: 0.97420734167099\n",
      "      vf_loss: 405.16351318359375\n",
      "    sample_time_ms: 18210.967\n",
      "    update_time_ms: 5.687\n",
      "  iterations_since_restore: 916\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.2112869819902\n",
      "  time_since_restore: 22581.76579761505\n",
      "  time_this_iter_s: 22.15002465248108\n",
      "  time_total_s: 22581.76579761505\n",
      "  timestamp: 1553731628\n",
      "  timesteps_since_restore: 9160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9160000\n",
      "  training_iteration: 916\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22581 s, 916 iter, 9160000 ts, 690 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-07-30\n",
      "  done: false\n",
      "  episode_len_mean: 142.76\n",
      "  episode_reward_max: 782.6877308566964\n",
      "  episode_reward_mean: 690.566870460021\n",
      "  episode_reward_min: -97.60544740901298\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 68646\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3738.144\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 9170000\n",
      "    num_steps_trained: 9170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.122168779373169\n",
      "      kl: 0.02526073344051838\n",
      "      policy_loss: -0.0015804318245500326\n",
      "      total_loss: 302.72705078125\n",
      "      vf_explained_var: 0.9770034551620483\n",
      "      vf_loss: 302.7277526855469\n",
      "    sample_time_ms: 18261.628\n",
      "    update_time_ms: 5.671\n",
      "  iterations_since_restore: 917\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.2834352300105\n",
      "  time_since_restore: 22603.80888748169\n",
      "  time_this_iter_s: 22.043089866638184\n",
      "  time_total_s: 22603.80888748169\n",
      "  timestamp: 1553731650\n",
      "  timesteps_since_restore: 9170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9170000\n",
      "  training_iteration: 917\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22603 s, 917 iter, 9170000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-07-51\n",
      "  done: false\n",
      "  episode_len_mean: 142.83\n",
      "  episode_reward_max: 794.6577238441645\n",
      "  episode_reward_mean: 692.4422234368093\n",
      "  episode_reward_min: -93.7525757335163\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 68716\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.426\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 9180000\n",
      "    num_steps_trained: 9180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03400042653083801\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4717330932617188\n",
      "      kl: 0.008007269352674484\n",
      "      policy_loss: -0.0020643137395381927\n",
      "      total_loss: 308.31134033203125\n",
      "      vf_explained_var: 0.9798511862754822\n",
      "      vf_loss: 308.3131408691406\n",
      "    sample_time_ms: 18164.148\n",
      "    update_time_ms: 5.808\n",
      "  iterations_since_restore: 918\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 346.2211117184046\n",
      "  time_since_restore: 22625.142954587936\n",
      "  time_this_iter_s: 21.33406710624695\n",
      "  time_total_s: 22625.142954587936\n",
      "  timestamp: 1553731671\n",
      "  timesteps_since_restore: 9180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9180000\n",
      "  training_iteration: 918\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22625 s, 918 iter, 9180000 ts, 692 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-08-13\n",
      "  done: false\n",
      "  episode_len_mean: 146.45\n",
      "  episode_reward_max: 803.225949683783\n",
      "  episode_reward_mean: 658.8548971105979\n",
      "  episode_reward_min: -65.66791204053419\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 68788\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3735.846\n",
      "    load_time_ms: 1.706\n",
      "    num_steps_sampled: 9190000\n",
      "    num_steps_trained: 9190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.412072777748108\n",
      "      kl: 0.02358015440404415\n",
      "      policy_loss: -0.005928430240601301\n",
      "      total_loss: 351.111083984375\n",
      "      vf_explained_var: 0.9801109433174133\n",
      "      vf_loss: 351.11663818359375\n",
      "    sample_time_ms: 18143.701\n",
      "    update_time_ms: 5.855\n",
      "  iterations_since_restore: 919\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 329.4274485552989\n",
      "  time_since_restore: 22646.955226898193\n",
      "  time_this_iter_s: 21.812272310256958\n",
      "  time_total_s: 22646.955226898193\n",
      "  timestamp: 1553731693\n",
      "  timesteps_since_restore: 9190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9190000\n",
      "  training_iteration: 919\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22646 s, 919 iter, 9190000 ts, 659 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-08-35\n",
      "  done: false\n",
      "  episode_len_mean: 150.86\n",
      "  episode_reward_max: 803.225949683783\n",
      "  episode_reward_mean: 610.0737411092565\n",
      "  episode_reward_min: -122.7284923812241\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 68857\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3721.026\n",
      "    load_time_ms: 1.72\n",
      "    num_steps_sampled: 9200000\n",
      "    num_steps_trained: 9200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.6718151569366455\n",
      "      kl: 0.022950271144509315\n",
      "      policy_loss: -0.00468382379040122\n",
      "      total_loss: 1106.6158447265625\n",
      "      vf_explained_var: 0.9362399578094482\n",
      "      vf_loss: 1106.6202392578125\n",
      "    sample_time_ms: 18107.722\n",
      "    update_time_ms: 5.797\n",
      "  iterations_since_restore: 920\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 305.03687055462825\n",
      "  time_since_restore: 22668.83402991295\n",
      "  time_this_iter_s: 21.87880301475525\n",
      "  time_total_s: 22668.83402991295\n",
      "  timestamp: 1553731715\n",
      "  timesteps_since_restore: 9200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9200000\n",
      "  training_iteration: 920\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22668 s, 920 iter, 9200000 ts, 610 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-08-57\n",
      "  done: false\n",
      "  episode_len_mean: 140.95\n",
      "  episode_reward_max: 788.4681393283233\n",
      "  episode_reward_mean: 639.6384456408937\n",
      "  episode_reward_min: -123.0026814922971\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 68934\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3741.756\n",
      "    load_time_ms: 1.744\n",
      "    num_steps_sampled: 9210000\n",
      "    num_steps_trained: 9210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9898352026939392\n",
      "      kl: 0.013544266112148762\n",
      "      policy_loss: -0.0029245608020573854\n",
      "      total_loss: 426.6824951171875\n",
      "      vf_explained_var: 0.9732409715652466\n",
      "      vf_loss: 426.6851501464844\n",
      "    sample_time_ms: 18098.039\n",
      "    update_time_ms: 5.928\n",
      "  iterations_since_restore: 921\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 319.81922282044684\n",
      "  time_since_restore: 22691.053255081177\n",
      "  time_this_iter_s: 22.21922516822815\n",
      "  time_total_s: 22691.053255081177\n",
      "  timestamp: 1553731737\n",
      "  timesteps_since_restore: 9210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9210000\n",
      "  training_iteration: 921\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22691 s, 921 iter, 9210000 ts, 640 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-09-19\n",
      "  done: false\n",
      "  episode_len_mean: 143.46\n",
      "  episode_reward_max: 788.4681393283233\n",
      "  episode_reward_mean: 668.9476012016365\n",
      "  episode_reward_min: -123.0026814922971\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 69002\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.113\n",
      "    load_time_ms: 1.74\n",
      "    num_steps_sampled: 9220000\n",
      "    num_steps_trained: 9220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.410085678100586\n",
      "      kl: 0.0267177727073431\n",
      "      policy_loss: -0.005922750569880009\n",
      "      total_loss: 304.3151550292969\n",
      "      vf_explained_var: 0.9831089377403259\n",
      "      vf_loss: 304.32061767578125\n",
      "    sample_time_ms: 18080.214\n",
      "    update_time_ms: 5.93\n",
      "  iterations_since_restore: 922\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.47380060081827\n",
      "  time_since_restore: 22712.88392305374\n",
      "  time_this_iter_s: 21.830667972564697\n",
      "  time_total_s: 22712.88392305374\n",
      "  timestamp: 1553731759\n",
      "  timesteps_since_restore: 9220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9220000\n",
      "  training_iteration: 922\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22712 s, 922 iter, 9220000 ts, 669 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-09-41\n",
      "  done: false\n",
      "  episode_len_mean: 143.82\n",
      "  episode_reward_max: 781.9691392995666\n",
      "  episode_reward_mean: 670.4408979869612\n",
      "  episode_reward_min: -105.28023437793529\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 69078\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.435\n",
      "    load_time_ms: 1.746\n",
      "    num_steps_sampled: 9230000\n",
      "    num_steps_trained: 9230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0551159381866455\n",
      "      kl: 0.013624319806694984\n",
      "      policy_loss: -0.001686949748545885\n",
      "      total_loss: 464.0457763671875\n",
      "      vf_explained_var: 0.9687658548355103\n",
      "      vf_loss: 464.0472106933594\n",
      "    sample_time_ms: 18054.156\n",
      "    update_time_ms: 5.826\n",
      "  iterations_since_restore: 923\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 335.2204489934806\n",
      "  time_since_restore: 22734.417961359024\n",
      "  time_this_iter_s: 21.534038305282593\n",
      "  time_total_s: 22734.417961359024\n",
      "  timestamp: 1553731781\n",
      "  timesteps_since_restore: 9230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9230000\n",
      "  training_iteration: 923\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22734 s, 923 iter, 9230000 ts, 670 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-10-03\n",
      "  done: false\n",
      "  episode_len_mean: 132.41\n",
      "  episode_reward_max: 776.387254132979\n",
      "  episode_reward_mean: 672.1570523245736\n",
      "  episode_reward_min: -115.4094067947104\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 69154\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.101\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 9240000\n",
      "    num_steps_trained: 9240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9615128636360168\n",
      "      kl: 0.029923085123300552\n",
      "      policy_loss: 0.00011340251512592658\n",
      "      total_loss: 495.4586486816406\n",
      "      vf_explained_var: 0.9664349555969238\n",
      "      vf_loss: 495.4579772949219\n",
      "    sample_time_ms: 18076.617\n",
      "    update_time_ms: 5.622\n",
      "  iterations_since_restore: 924\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.0785261622868\n",
      "  time_since_restore: 22756.106654167175\n",
      "  time_this_iter_s: 21.688692808151245\n",
      "  time_total_s: 22756.106654167175\n",
      "  timestamp: 1553731803\n",
      "  timesteps_since_restore: 9240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9240000\n",
      "  training_iteration: 924\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22756 s, 924 iter, 9240000 ts, 672 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-10-25\n",
      "  done: false\n",
      "  episode_len_mean: 134.63\n",
      "  episode_reward_max: 782.9830735750825\n",
      "  episode_reward_mean: 683.8679671672846\n",
      "  episode_reward_min: -93.10912872771165\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 69230\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3759.214\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 9250000\n",
      "    num_steps_trained: 9250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9610081315040588\n",
      "      kl: 0.014540285803377628\n",
      "      policy_loss: -0.0016104320529848337\n",
      "      total_loss: 451.2838439941406\n",
      "      vf_explained_var: 0.9655642509460449\n",
      "      vf_loss: 451.28515625\n",
      "    sample_time_ms: 18112.86\n",
      "    update_time_ms: 5.622\n",
      "  iterations_since_restore: 925\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.93398358364243\n",
      "  time_since_restore: 22778.594006061554\n",
      "  time_this_iter_s: 22.487351894378662\n",
      "  time_total_s: 22778.594006061554\n",
      "  timestamp: 1553731825\n",
      "  timesteps_since_restore: 9250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9250000\n",
      "  training_iteration: 925\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22778 s, 925 iter, 9250000 ts, 684 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-10-47\n",
      "  done: false\n",
      "  episode_len_mean: 136.57\n",
      "  episode_reward_max: 785.8642930048406\n",
      "  episode_reward_mean: 676.6350089822768\n",
      "  episode_reward_min: -93.10912872771165\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 69305\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3758.634\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 9260000\n",
      "    num_steps_trained: 9260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.989834725856781\n",
      "      kl: 0.03436256945133209\n",
      "      policy_loss: -0.0010593731421977282\n",
      "      total_loss: 212.9973907470703\n",
      "      vf_explained_var: 0.9851052761077881\n",
      "      vf_loss: 212.9978790283203\n",
      "    sample_time_ms: 18120.192\n",
      "    update_time_ms: 5.526\n",
      "  iterations_since_restore: 926\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 338.3175044911384\n",
      "  time_since_restore: 22800.807498455048\n",
      "  time_this_iter_s: 22.213492393493652\n",
      "  time_total_s: 22800.807498455048\n",
      "  timestamp: 1553731847\n",
      "  timesteps_since_restore: 9260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9260000\n",
      "  training_iteration: 926\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22800 s, 926 iter, 9260000 ts, 677 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-11-10\n",
      "  done: false\n",
      "  episode_len_mean: 135.52\n",
      "  episode_reward_max: 794.7111823536906\n",
      "  episode_reward_mean: 681.8629810069973\n",
      "  episode_reward_min: -77.68636010366518\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 69381\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3758.235\n",
      "    load_time_ms: 1.655\n",
      "    num_steps_sampled: 9270000\n",
      "    num_steps_trained: 9270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8095535039901733\n",
      "      kl: 0.026447538286447525\n",
      "      policy_loss: -0.001318394672125578\n",
      "      total_loss: 233.56991577148438\n",
      "      vf_explained_var: 0.984100341796875\n",
      "      vf_loss: 233.57078552246094\n",
      "    sample_time_ms: 18201.636\n",
      "    update_time_ms: 5.532\n",
      "  iterations_since_restore: 927\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.93149050349876\n",
      "  time_since_restore: 22823.659391641617\n",
      "  time_this_iter_s: 22.851893186569214\n",
      "  time_total_s: 22823.659391641617\n",
      "  timestamp: 1553731870\n",
      "  timesteps_since_restore: 9270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9270000\n",
      "  training_iteration: 927\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22823 s, 927 iter, 9270000 ts, 682 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-11-33\n",
      "  done: false\n",
      "  episode_len_mean: 139.1\n",
      "  episode_reward_max: 784.3527773061746\n",
      "  episode_reward_mean: 690.1356209143914\n",
      "  episode_reward_min: -58.96663724639069\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 69455\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.5\n",
      "    load_time_ms: 1.661\n",
      "    num_steps_sampled: 9280000\n",
      "    num_steps_trained: 9280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9852058291435242\n",
      "      kl: 0.03380830958485603\n",
      "      policy_loss: -0.0008793045417405665\n",
      "      total_loss: 188.32931518554688\n",
      "      vf_explained_var: 0.9870507717132568\n",
      "      vf_loss: 188.32962036132812\n",
      "    sample_time_ms: 18334.549\n",
      "    update_time_ms: 5.231\n",
      "  iterations_since_restore: 928\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.0678104571957\n",
      "  time_since_restore: 22846.300456762314\n",
      "  time_this_iter_s: 22.64106512069702\n",
      "  time_total_s: 22846.300456762314\n",
      "  timestamp: 1553731893\n",
      "  timesteps_since_restore: 9280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9280000\n",
      "  training_iteration: 928\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22846 s, 928 iter, 9280000 ts, 690 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-11-56\n",
      "  done: false\n",
      "  episode_len_mean: 145.18\n",
      "  episode_reward_max: 777.5253442066459\n",
      "  episode_reward_mean: 680.5418040314883\n",
      "  episode_reward_min: -59.75387428030837\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 69526\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3770.572\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 9290000\n",
      "    num_steps_trained: 9290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2250053882598877\n",
      "      kl: 0.012812964618206024\n",
      "      policy_loss: -0.0016837960574775934\n",
      "      total_loss: 622.8927001953125\n",
      "      vf_explained_var: 0.9558442234992981\n",
      "      vf_loss: 622.8942260742188\n",
      "    sample_time_ms: 18395.007\n",
      "    update_time_ms: 5.223\n",
      "  iterations_since_restore: 929\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.27090201574407\n",
      "  time_since_restore: 22868.85542201996\n",
      "  time_this_iter_s: 22.554965257644653\n",
      "  time_total_s: 22868.85542201996\n",
      "  timestamp: 1553731916\n",
      "  timesteps_since_restore: 9290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9290000\n",
      "  training_iteration: 929\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22868 s, 929 iter, 9290000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-12-17\n",
      "  done: false\n",
      "  episode_len_mean: 148.76\n",
      "  episode_reward_max: 791.0172361470866\n",
      "  episode_reward_mean: 657.0181408225352\n",
      "  episode_reward_min: -99.43640388492078\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 69596\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3767.046\n",
      "    load_time_ms: 1.571\n",
      "    num_steps_sampled: 9300000\n",
      "    num_steps_trained: 9300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.373822569847107\n",
      "      kl: 0.016399163752794266\n",
      "      policy_loss: -0.0017499291570857167\n",
      "      total_loss: 305.77264404296875\n",
      "      vf_explained_var: 0.981925368309021\n",
      "      vf_loss: 305.7740783691406\n",
      "    sample_time_ms: 18394.778\n",
      "    update_time_ms: 5.406\n",
      "  iterations_since_restore: 930\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 328.5090704112676\n",
      "  time_since_restore: 22890.696849822998\n",
      "  time_this_iter_s: 21.84142780303955\n",
      "  time_total_s: 22890.696849822998\n",
      "  timestamp: 1553731937\n",
      "  timesteps_since_restore: 9300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9300000\n",
      "  training_iteration: 930\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22890 s, 930 iter, 9300000 ts, 657 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-12-40\n",
      "  done: false\n",
      "  episode_len_mean: 141.25\n",
      "  episode_reward_max: 806.9416912403461\n",
      "  episode_reward_mean: 668.5717019577002\n",
      "  episode_reward_min: -99.43640388492078\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 69672\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.25\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 9310000\n",
      "    num_steps_trained: 9310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.866958737373352\n",
      "      kl: 0.016158653423190117\n",
      "      policy_loss: -0.0008148860651999712\n",
      "      total_loss: 127.17704772949219\n",
      "      vf_explained_var: 0.9922648668289185\n",
      "      vf_loss: 127.17758178710938\n",
      "    sample_time_ms: 18448.719\n",
      "    update_time_ms: 5.24\n",
      "  iterations_since_restore: 931\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.28585097885\n",
      "  time_since_restore: 22913.242792606354\n",
      "  time_this_iter_s: 22.545942783355713\n",
      "  time_total_s: 22913.242792606354\n",
      "  timestamp: 1553731960\n",
      "  timesteps_since_restore: 9310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9310000\n",
      "  training_iteration: 931\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22913 s, 931 iter, 9310000 ts, 669 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-13-03\n",
      "  done: false\n",
      "  episode_len_mean: 136.11\n",
      "  episode_reward_max: 806.9416912403461\n",
      "  episode_reward_mean: 685.7446056244324\n",
      "  episode_reward_min: -23.506430319461685\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 69747\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3746.332\n",
      "    load_time_ms: 1.48\n",
      "    num_steps_sampled: 9320000\n",
      "    num_steps_trained: 9320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.055261254310608\n",
      "      kl: 0.016854984685778618\n",
      "      policy_loss: -0.0007922794320620596\n",
      "      total_loss: 195.315185546875\n",
      "      vf_explained_var: 0.9877333045005798\n",
      "      vf_loss: 195.31568908691406\n",
      "    sample_time_ms: 18537.062\n",
      "    update_time_ms: 5.56\n",
      "  iterations_since_restore: 932\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.8723028122162\n",
      "  time_since_restore: 22935.958814382553\n",
      "  time_this_iter_s: 22.71602177619934\n",
      "  time_total_s: 22935.958814382553\n",
      "  timestamp: 1553731983\n",
      "  timesteps_since_restore: 9320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9320000\n",
      "  training_iteration: 932\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22935 s, 932 iter, 9320000 ts, 686 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-13-25\n",
      "  done: false\n",
      "  episode_len_mean: 140.98\n",
      "  episode_reward_max: 804.6793404134116\n",
      "  episode_reward_mean: 680.3956131970766\n",
      "  episode_reward_min: -23.506430319461685\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 69818\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.576\n",
      "    load_time_ms: 1.427\n",
      "    num_steps_sampled: 9330000\n",
      "    num_steps_trained: 9330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1188265085220337\n",
      "      kl: 0.02970806509256363\n",
      "      policy_loss: -0.002068710047751665\n",
      "      total_loss: 280.3938293457031\n",
      "      vf_explained_var: 0.983214259147644\n",
      "      vf_loss: 280.39544677734375\n",
      "    sample_time_ms: 18602.326\n",
      "    update_time_ms: 5.566\n",
      "  iterations_since_restore: 933\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.1978065985383\n",
      "  time_since_restore: 22958.365884065628\n",
      "  time_this_iter_s: 22.40706968307495\n",
      "  time_total_s: 22958.365884065628\n",
      "  timestamp: 1553732005\n",
      "  timesteps_since_restore: 9330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9330000\n",
      "  training_iteration: 933\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22958 s, 933 iter, 9330000 ts, 680 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-13-48\n",
      "  done: false\n",
      "  episode_len_mean: 140.06\n",
      "  episode_reward_max: 804.6793404134116\n",
      "  episode_reward_mean: 670.3724116863715\n",
      "  episode_reward_min: -63.84878498904527\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 69894\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3768.584\n",
      "    load_time_ms: 1.424\n",
      "    num_steps_sampled: 9340000\n",
      "    num_steps_trained: 9340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0533417463302612\n",
      "      kl: 0.01968594640493393\n",
      "      policy_loss: -0.0008755351300351322\n",
      "      total_loss: 219.87184143066406\n",
      "      vf_explained_var: 0.9863011240959167\n",
      "      vf_loss: 219.8723907470703\n",
      "    sample_time_ms: 18705.013\n",
      "    update_time_ms: 5.568\n",
      "  iterations_since_restore: 934\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 335.18620584318575\n",
      "  time_since_restore: 22981.083608865738\n",
      "  time_this_iter_s: 22.717724800109863\n",
      "  time_total_s: 22981.083608865738\n",
      "  timestamp: 1553732028\n",
      "  timesteps_since_restore: 9340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9340000\n",
      "  training_iteration: 934\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 22981 s, 934 iter, 9340000 ts, 670 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-14-10\n",
      "  done: false\n",
      "  episode_len_mean: 132.27\n",
      "  episode_reward_max: 783.1699072665944\n",
      "  episode_reward_mean: 672.8359615629332\n",
      "  episode_reward_min: -92.63155077214267\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 69970\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3751.238\n",
      "    load_time_ms: 1.425\n",
      "    num_steps_sampled: 9350000\n",
      "    num_steps_trained: 9350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.017000213265419006\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8814517259597778\n",
      "      kl: 0.07263956218957901\n",
      "      policy_loss: -0.008582877926528454\n",
      "      total_loss: 528.4722290039062\n",
      "      vf_explained_var: 0.962590217590332\n",
      "      vf_loss: 528.4796752929688\n",
      "    sample_time_ms: 18683.851\n",
      "    update_time_ms: 5.548\n",
      "  iterations_since_restore: 935\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 336.4179807814668\n",
      "  time_since_restore: 23003.184046030045\n",
      "  time_this_iter_s: 22.10043716430664\n",
      "  time_total_s: 23003.184046030045\n",
      "  timestamp: 1553732050\n",
      "  timesteps_since_restore: 9350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9350000\n",
      "  training_iteration: 935\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23003 s, 935 iter, 9350000 ts, 673 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-14-32\n",
      "  done: false\n",
      "  episode_len_mean: 135.18\n",
      "  episode_reward_max: 789.2292259458824\n",
      "  episode_reward_mean: 686.894688095317\n",
      "  episode_reward_min: -72.35041952502688\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 70045\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3749.465\n",
      "    load_time_ms: 1.415\n",
      "    num_steps_sampled: 9360000\n",
      "    num_steps_trained: 9360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.968533456325531\n",
      "      kl: 0.01825006864964962\n",
      "      policy_loss: -0.001125037670135498\n",
      "      total_loss: 211.17425537109375\n",
      "      vf_explained_var: 0.9865650534629822\n",
      "      vf_loss: 211.17491149902344\n",
      "    sample_time_ms: 18683.163\n",
      "    update_time_ms: 5.523\n",
      "  iterations_since_restore: 936\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.44734404765853\n",
      "  time_since_restore: 23025.370473861694\n",
      "  time_this_iter_s: 22.18642783164978\n",
      "  time_total_s: 23025.370473861694\n",
      "  timestamp: 1553732072\n",
      "  timesteps_since_restore: 9360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9360000\n",
      "  training_iteration: 936\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23025 s, 936 iter, 9360000 ts, 687 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-14-54\n",
      "  done: false\n",
      "  episode_len_mean: 131.68\n",
      "  episode_reward_max: 789.2292259458824\n",
      "  episode_reward_mean: 695.9830115936534\n",
      "  episode_reward_min: -110.76850403439762\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 70119\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3745.715\n",
      "    load_time_ms: 1.42\n",
      "    num_steps_sampled: 9370000\n",
      "    num_steps_trained: 9370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0453720092773438\n",
      "      kl: 0.014989242888987064\n",
      "      policy_loss: -0.00022016256116330624\n",
      "      total_loss: 278.89923095703125\n",
      "      vf_explained_var: 0.9826585054397583\n",
      "      vf_loss: 278.8990783691406\n",
      "    sample_time_ms: 18588.692\n",
      "    update_time_ms: 5.602\n",
      "  iterations_since_restore: 937\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.9915057968267\n",
      "  time_since_restore: 23047.24063897133\n",
      "  time_this_iter_s: 21.8701651096344\n",
      "  time_total_s: 23047.24063897133\n",
      "  timestamp: 1553732094\n",
      "  timesteps_since_restore: 9370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9370000\n",
      "  training_iteration: 937\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23047 s, 937 iter, 9370000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-15-16\n",
      "  done: false\n",
      "  episode_len_mean: 147.09\n",
      "  episode_reward_max: 782.0964832072647\n",
      "  episode_reward_mean: 685.4322149652792\n",
      "  episode_reward_min: -82.99074039173391\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 70189\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3747.979\n",
      "    load_time_ms: 1.442\n",
      "    num_steps_sampled: 9380000\n",
      "    num_steps_trained: 9380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2333941459655762\n",
      "      kl: 0.013803267851471901\n",
      "      policy_loss: 6.932573887752369e-05\n",
      "      total_loss: 353.4150085449219\n",
      "      vf_explained_var: 0.9800076484680176\n",
      "      vf_loss: 353.41461181640625\n",
      "    sample_time_ms: 18485.383\n",
      "    update_time_ms: 5.539\n",
      "  iterations_since_restore: 938\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 342.71610748263964\n",
      "  time_since_restore: 23068.87377691269\n",
      "  time_this_iter_s: 21.633137941360474\n",
      "  time_total_s: 23068.87377691269\n",
      "  timestamp: 1553732116\n",
      "  timesteps_since_restore: 9380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9380000\n",
      "  training_iteration: 938\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23068 s, 938 iter, 9380000 ts, 685 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-15-38\n",
      "  done: false\n",
      "  episode_len_mean: 141.68\n",
      "  episode_reward_max: 788.1656143230908\n",
      "  episode_reward_mean: 652.4089079129684\n",
      "  episode_reward_min: -134.7653308183193\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 70265\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3731.855\n",
      "    load_time_ms: 1.444\n",
      "    num_steps_sampled: 9390000\n",
      "    num_steps_trained: 9390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0879015922546387\n",
      "      kl: 0.014091569930315018\n",
      "      policy_loss: -0.0032383983489125967\n",
      "      total_loss: 572.8251342773438\n",
      "      vf_explained_var: 0.9623982310295105\n",
      "      vf_loss: 572.8280029296875\n",
      "    sample_time_ms: 18451.602\n",
      "    update_time_ms: 5.45\n",
      "  iterations_since_restore: 939\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 326.2044539564842\n",
      "  time_since_restore: 23090.929728746414\n",
      "  time_this_iter_s: 22.055951833724976\n",
      "  time_total_s: 23090.929728746414\n",
      "  timestamp: 1553732138\n",
      "  timesteps_since_restore: 9390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9390000\n",
      "  training_iteration: 939\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23090 s, 939 iter, 9390000 ts, 652 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-16-00\n",
      "  done: false\n",
      "  episode_len_mean: 138.14\n",
      "  episode_reward_max: 792.7219170093371\n",
      "  episode_reward_mean: 659.4700248975827\n",
      "  episode_reward_min: -134.7653308183193\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 70338\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3736.996\n",
      "    load_time_ms: 1.451\n",
      "    num_steps_sampled: 9400000\n",
      "    num_steps_trained: 9400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.111478567123413\n",
      "      kl: 0.022260116413235664\n",
      "      policy_loss: -0.0017006777925416827\n",
      "      total_loss: 230.6111297607422\n",
      "      vf_explained_var: 0.9858685731887817\n",
      "      vf_loss: 230.61227416992188\n",
      "    sample_time_ms: 18457.574\n",
      "    update_time_ms: 5.505\n",
      "  iterations_since_restore: 940\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 329.7350124487912\n",
      "  time_since_restore: 23112.884018421173\n",
      "  time_this_iter_s: 21.95428967475891\n",
      "  time_total_s: 23112.884018421173\n",
      "  timestamp: 1553732160\n",
      "  timesteps_since_restore: 9400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9400000\n",
      "  training_iteration: 940\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23112 s, 940 iter, 9400000 ts, 659 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-16-23\n",
      "  done: false\n",
      "  episode_len_mean: 145.37\n",
      "  episode_reward_max: 794.3529834363503\n",
      "  episode_reward_mean: 648.6989413704449\n",
      "  episode_reward_min: -87.41204637351989\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 70408\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.023\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 9410000\n",
      "    num_steps_trained: 9410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.425061583518982\n",
      "      kl: 0.02152116969227791\n",
      "      policy_loss: -0.0011996966786682606\n",
      "      total_loss: 516.8006591796875\n",
      "      vf_explained_var: 0.969788670539856\n",
      "      vf_loss: 516.80126953125\n",
      "    sample_time_ms: 18453.663\n",
      "    update_time_ms: 5.583\n",
      "  iterations_since_restore: 941\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.34947068522246\n",
      "  time_since_restore: 23135.423157691956\n",
      "  time_this_iter_s: 22.53913927078247\n",
      "  time_total_s: 23135.423157691956\n",
      "  timestamp: 1553732183\n",
      "  timesteps_since_restore: 9410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9410000\n",
      "  training_iteration: 941\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23135 s, 941 iter, 9410000 ts, 649 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 138.9\n",
      "  episode_reward_max: 795.2542831546292\n",
      "  episode_reward_mean: 648.1503290070243\n",
      "  episode_reward_min: -131.36920798276242\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 70486\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3740.784\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 9420000\n",
      "    num_steps_trained: 9420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8113863468170166\n",
      "      kl: 0.027158431708812714\n",
      "      policy_loss: -0.005938125308603048\n",
      "      total_loss: 338.91046142578125\n",
      "      vf_explained_var: 0.9748746156692505\n",
      "      vf_loss: 338.91571044921875\n",
      "    sample_time_ms: 18352.285\n",
      "    update_time_ms: 5.205\n",
      "  iterations_since_restore: 942\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.07516450351216\n",
      "  time_since_restore: 23157.13131403923\n",
      "  time_this_iter_s: 21.70815634727478\n",
      "  time_total_s: 23157.13131403923\n",
      "  timestamp: 1553732204\n",
      "  timesteps_since_restore: 9420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9420000\n",
      "  training_iteration: 942\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23157 s, 942 iter, 9420000 ts, 648 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-17-06\n",
      "  done: false\n",
      "  episode_len_mean: 136.21\n",
      "  episode_reward_max: 789.2996553189552\n",
      "  episode_reward_mean: 681.391395119565\n",
      "  episode_reward_min: -72.8268199383065\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 70560\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3722.156\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 9430000\n",
      "    num_steps_trained: 9430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0950583219528198\n",
      "      kl: 0.01257906574755907\n",
      "      policy_loss: -0.0014736277516931295\n",
      "      total_loss: 232.1414337158203\n",
      "      vf_explained_var: 0.9863051176071167\n",
      "      vf_loss: 232.142578125\n",
      "    sample_time_ms: 18311.992\n",
      "    update_time_ms: 5.182\n",
      "  iterations_since_restore: 943\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 340.6956975597825\n",
      "  time_since_restore: 23178.95157933235\n",
      "  time_this_iter_s: 21.820265293121338\n",
      "  time_total_s: 23178.95157933235\n",
      "  timestamp: 1553732226\n",
      "  timesteps_since_restore: 9430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9430000\n",
      "  training_iteration: 943\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23178 s, 943 iter, 9430000 ts, 681 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-17-29\n",
      "  done: false\n",
      "  episode_len_mean: 142.71\n",
      "  episode_reward_max: 789.2996553189552\n",
      "  episode_reward_mean: 675.1489893559377\n",
      "  episode_reward_min: -122.16279522893718\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 70632\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3726.5\n",
      "    load_time_ms: 1.591\n",
      "    num_steps_sampled: 9440000\n",
      "    num_steps_trained: 9440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.171021819114685\n",
      "      kl: 0.025137081742286682\n",
      "      policy_loss: -0.003243398619815707\n",
      "      total_loss: 328.3473205566406\n",
      "      vf_explained_var: 0.9780664443969727\n",
      "      vf_loss: 328.3499450683594\n",
      "    sample_time_ms: 18276.161\n",
      "    update_time_ms: 5.165\n",
      "  iterations_since_restore: 944\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.5744946779689\n",
      "  time_since_restore: 23201.356375694275\n",
      "  time_this_iter_s: 22.404796361923218\n",
      "  time_total_s: 23201.356375694275\n",
      "  timestamp: 1553732249\n",
      "  timesteps_since_restore: 9440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9440000\n",
      "  training_iteration: 944\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23201 s, 944 iter, 9440000 ts, 675 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 139.94\n",
      "  episode_reward_max: 783.0687495230745\n",
      "  episode_reward_mean: 665.0011560229634\n",
      "  episode_reward_min: -122.16279522893718\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 70707\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3724.662\n",
      "    load_time_ms: 1.665\n",
      "    num_steps_sampled: 9450000\n",
      "    num_steps_trained: 9450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.078373670578003\n",
      "      kl: 0.012395570054650307\n",
      "      policy_loss: -0.004005834925919771\n",
      "      total_loss: 457.8862609863281\n",
      "      vf_explained_var: 0.9703579545021057\n",
      "      vf_loss: 457.8899841308594\n",
      "    sample_time_ms: 18255.921\n",
      "    update_time_ms: 5.168\n",
      "  iterations_since_restore: 945\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 332.5005780114817\n",
      "  time_since_restore: 23223.23742198944\n",
      "  time_this_iter_s: 21.881046295166016\n",
      "  time_total_s: 23223.23742198944\n",
      "  timestamp: 1553732270\n",
      "  timesteps_since_restore: 9450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9450000\n",
      "  training_iteration: 945\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23223 s, 945 iter, 9450000 ts, 665 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 135.9\n",
      "  episode_reward_max: 799.666315919888\n",
      "  episode_reward_mean: 683.2352136926714\n",
      "  episode_reward_min: -114.26533262227049\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 70783\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3723.762\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 9460000\n",
      "    num_steps_trained: 9460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8510206937789917\n",
      "      kl: 0.01530765276402235\n",
      "      policy_loss: 2.3232629246194847e-05\n",
      "      total_loss: 260.8758850097656\n",
      "      vf_explained_var: 0.9791104197502136\n",
      "      vf_loss: 260.87548828125\n",
      "    sample_time_ms: 18217.123\n",
      "    update_time_ms: 5.183\n",
      "  iterations_since_restore: 946\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 341.6176068463358\n",
      "  time_since_restore: 23245.027401685715\n",
      "  time_this_iter_s: 21.789979696273804\n",
      "  time_total_s: 23245.027401685715\n",
      "  timestamp: 1553732292\n",
      "  timesteps_since_restore: 9460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9460000\n",
      "  training_iteration: 946\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23245 s, 946 iter, 9460000 ts, 683 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-18-34\n",
      "  done: false\n",
      "  episode_len_mean: 137.46\n",
      "  episode_reward_max: 799.666315919888\n",
      "  episode_reward_mean: 706.8422498357087\n",
      "  episode_reward_min: -40.63276805999689\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 70857\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3727.702\n",
      "    load_time_ms: 1.635\n",
      "    num_steps_sampled: 9470000\n",
      "    num_steps_trained: 9470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9674620032310486\n",
      "      kl: 0.015093793161213398\n",
      "      policy_loss: -0.0019010966643691063\n",
      "      total_loss: 371.50885009765625\n",
      "      vf_explained_var: 0.9745665192604065\n",
      "      vf_loss: 371.5103759765625\n",
      "    sample_time_ms: 18170.55\n",
      "    update_time_ms: 5.039\n",
      "  iterations_since_restore: 947\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.42112491785423\n",
      "  time_since_restore: 23266.46990132332\n",
      "  time_this_iter_s: 21.44249963760376\n",
      "  time_total_s: 23266.46990132332\n",
      "  timestamp: 1553732314\n",
      "  timesteps_since_restore: 9470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9470000\n",
      "  training_iteration: 947\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23266 s, 947 iter, 9470000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-18-56\n",
      "  done: false\n",
      "  episode_len_mean: 140.75\n",
      "  episode_reward_max: 795.1855750023275\n",
      "  episode_reward_mean: 639.4614590297589\n",
      "  episode_reward_min: -108.04034282937035\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 70928\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3744.613\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 9480000\n",
      "    num_steps_trained: 9480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.357409119606018\n",
      "      kl: 0.019739922136068344\n",
      "      policy_loss: -0.0018056321423500776\n",
      "      total_loss: 465.86749267578125\n",
      "      vf_explained_var: 0.9745846390724182\n",
      "      vf_loss: 465.8688049316406\n",
      "    sample_time_ms: 18209.34\n",
      "    update_time_ms: 5.051\n",
      "  iterations_since_restore: 948\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 319.73072951487944\n",
      "  time_since_restore: 23288.661457300186\n",
      "  time_this_iter_s: 22.191555976867676\n",
      "  time_total_s: 23288.661457300186\n",
      "  timestamp: 1553732336\n",
      "  timesteps_since_restore: 9480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9480000\n",
      "  training_iteration: 948\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23288 s, 948 iter, 9480000 ts, 639 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-19-18\n",
      "  done: false\n",
      "  episode_len_mean: 145.75\n",
      "  episode_reward_max: 786.8540683830745\n",
      "  episode_reward_mean: 649.9358456793186\n",
      "  episode_reward_min: -108.04034282937035\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 71001\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3743.635\n",
      "    load_time_ms: 1.67\n",
      "    num_steps_sampled: 9490000\n",
      "    num_steps_trained: 9490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0713951587677002\n",
      "      kl: 0.037233997136354446\n",
      "      policy_loss: -0.00299964495934546\n",
      "      total_loss: 216.6688690185547\n",
      "      vf_explained_var: 0.9864292740821838\n",
      "      vf_loss: 216.6708984375\n",
      "    sample_time_ms: 18159.723\n",
      "    update_time_ms: 5.141\n",
      "  iterations_since_restore: 949\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.96792283965937\n",
      "  time_since_restore: 23310.213323116302\n",
      "  time_this_iter_s: 21.551865816116333\n",
      "  time_total_s: 23310.213323116302\n",
      "  timestamp: 1553732358\n",
      "  timesteps_since_restore: 9490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9490000\n",
      "  training_iteration: 949\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23310 s, 949 iter, 9490000 ts, 650 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-19-41\n",
      "  done: false\n",
      "  episode_len_mean: 132.4\n",
      "  episode_reward_max: 790.4967309793062\n",
      "  episode_reward_mean: 697.3297660037318\n",
      "  episode_reward_min: -126.97197032751762\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 71076\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.082\n",
      "    load_time_ms: 1.667\n",
      "    num_steps_sampled: 9500000\n",
      "    num_steps_trained: 9500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9532942175865173\n",
      "      kl: 0.012087001465260983\n",
      "      policy_loss: -0.0013331705704331398\n",
      "      total_loss: 218.58816528320312\n",
      "      vf_explained_var: 0.9868482947349548\n",
      "      vf_loss: 218.5891876220703\n",
      "    sample_time_ms: 18251.765\n",
      "    update_time_ms: 4.896\n",
      "  iterations_since_restore: 950\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.6648830018659\n",
      "  time_since_restore: 23333.06866812706\n",
      "  time_this_iter_s: 22.855345010757446\n",
      "  time_total_s: 23333.06866812706\n",
      "  timestamp: 1553732381\n",
      "  timesteps_since_restore: 9500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9500000\n",
      "  training_iteration: 950\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23333 s, 950 iter, 9500000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-20-02\n",
      "  done: false\n",
      "  episode_len_mean: 145.96\n",
      "  episode_reward_max: 798.3543606375727\n",
      "  episode_reward_mean: 642.7805186666351\n",
      "  episode_reward_min: -127.83490082421187\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 71144\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3742.463\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 9510000\n",
      "    num_steps_trained: 9510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5353933572769165\n",
      "      kl: 0.023566562682390213\n",
      "      policy_loss: -0.0027166346553713083\n",
      "      total_loss: 418.91082763671875\n",
      "      vf_explained_var: 0.9788311719894409\n",
      "      vf_loss: 418.9129638671875\n",
      "    sample_time_ms: 18179.496\n",
      "    update_time_ms: 4.807\n",
      "  iterations_since_restore: 951\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 321.39025933331754\n",
      "  time_since_restore: 23354.888288259506\n",
      "  time_this_iter_s: 21.81962013244629\n",
      "  time_total_s: 23354.888288259506\n",
      "  timestamp: 1553732402\n",
      "  timesteps_since_restore: 9510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9510000\n",
      "  training_iteration: 951\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23354 s, 951 iter, 9510000 ts, 643 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-20-24\n",
      "  done: false\n",
      "  episode_len_mean: 149.61\n",
      "  episode_reward_max: 798.3543606375727\n",
      "  episode_reward_mean: 667.1319927629297\n",
      "  episode_reward_min: -115.43347092970443\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 71214\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3738.916\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 9520000\n",
      "    num_steps_trained: 9520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.097300410270691\n",
      "      kl: 0.017430324107408524\n",
      "      policy_loss: -0.001140546053647995\n",
      "      total_loss: 271.0504455566406\n",
      "      vf_explained_var: 0.9851387143135071\n",
      "      vf_loss: 271.0511169433594\n",
      "    sample_time_ms: 18201.458\n",
      "    update_time_ms: 5.066\n",
      "  iterations_since_restore: 952\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 333.56599638146486\n",
      "  time_since_restore: 23376.78342151642\n",
      "  time_this_iter_s: 21.89513325691223\n",
      "  time_total_s: 23376.78342151642\n",
      "  timestamp: 1553732424\n",
      "  timesteps_since_restore: 9520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9520000\n",
      "  training_iteration: 952\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23376 s, 952 iter, 9520000 ts, 667 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-20-47\n",
      "  done: false\n",
      "  episode_len_mean: 144.91\n",
      "  episode_reward_max: 802.3028995516576\n",
      "  episode_reward_mean: 648.5613512092361\n",
      "  episode_reward_min: -117.34365026920047\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 71285\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3733.406\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 9530000\n",
      "    num_steps_trained: 9530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.5163675546646118\n",
      "      kl: 0.011983555741608143\n",
      "      policy_loss: -0.0016734435921534896\n",
      "      total_loss: 384.7828674316406\n",
      "      vf_explained_var: 0.9775385856628418\n",
      "      vf_loss: 384.7841796875\n",
      "    sample_time_ms: 18273.182\n",
      "    update_time_ms: 5.216\n",
      "  iterations_since_restore: 953\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 324.280675604618\n",
      "  time_since_restore: 23399.26773071289\n",
      "  time_this_iter_s: 22.484309196472168\n",
      "  time_total_s: 23399.26773071289\n",
      "  timestamp: 1553732447\n",
      "  timesteps_since_restore: 9530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9530000\n",
      "  training_iteration: 953\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23399 s, 953 iter, 9530000 ts, 649 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-21-09\n",
      "  done: false\n",
      "  episode_len_mean: 141.41\n",
      "  episode_reward_max: 802.3028995516576\n",
      "  episode_reward_mean: 662.0919626936857\n",
      "  episode_reward_min: -132.57161023404902\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 71360\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.492\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 9540000\n",
      "    num_steps_trained: 9540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0559158325195312\n",
      "      kl: 0.037770457565784454\n",
      "      policy_loss: -0.0027448313776403666\n",
      "      total_loss: 324.37579345703125\n",
      "      vf_explained_var: 0.9767354130744934\n",
      "      vf_loss: 324.3775939941406\n",
      "    sample_time_ms: 18284.766\n",
      "    update_time_ms: 5.214\n",
      "  iterations_since_restore: 954\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 331.0459813468427\n",
      "  time_since_restore: 23421.759880065918\n",
      "  time_this_iter_s: 22.492149353027344\n",
      "  time_total_s: 23421.759880065918\n",
      "  timestamp: 1553732469\n",
      "  timesteps_since_restore: 9540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9540000\n",
      "  training_iteration: 954\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23421 s, 954 iter, 9540000 ts, 662 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-21-31\n",
      "  done: false\n",
      "  episode_len_mean: 134.06\n",
      "  episode_reward_max: 789.4543851118184\n",
      "  episode_reward_mean: 674.920560876622\n",
      "  episode_reward_min: -132.57161023404902\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 71436\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.247\n",
      "    load_time_ms: 1.538\n",
      "    num_steps_sampled: 9550000\n",
      "    num_steps_trained: 9550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0775606632232666\n",
      "      kl: 0.01044805534183979\n",
      "      policy_loss: -0.0023550118785351515\n",
      "      total_loss: 527.97265625\n",
      "      vf_explained_var: 0.9622897505760193\n",
      "      vf_loss: 527.9747314453125\n",
      "    sample_time_ms: 18289.445\n",
      "    update_time_ms: 5.227\n",
      "  iterations_since_restore: 955\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 337.460280438311\n",
      "  time_since_restore: 23443.68607020378\n",
      "  time_this_iter_s: 21.92619013786316\n",
      "  time_total_s: 23443.68607020378\n",
      "  timestamp: 1553732491\n",
      "  timesteps_since_restore: 9550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9550000\n",
      "  training_iteration: 955\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23443 s, 955 iter, 9550000 ts, 675 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-21-54\n",
      "  done: false\n",
      "  episode_len_mean: 132.16\n",
      "  episode_reward_max: 792.9447201801192\n",
      "  episode_reward_mean: 659.6635728097963\n",
      "  episode_reward_min: -99.50409693945178\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 71514\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3732.506\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 9560000\n",
      "    num_steps_trained: 9560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0682920217514038\n",
      "      kl: 0.01167208794504404\n",
      "      policy_loss: -0.0008406038978137076\n",
      "      total_loss: 506.2995300292969\n",
      "      vf_explained_var: 0.968323826789856\n",
      "      vf_loss: 506.3000793457031\n",
      "    sample_time_ms: 18339.791\n",
      "    update_time_ms: 5.221\n",
      "  iterations_since_restore: 956\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 329.83178640489814\n",
      "  time_since_restore: 23466.004536151886\n",
      "  time_this_iter_s: 22.31846594810486\n",
      "  time_total_s: 23466.004536151886\n",
      "  timestamp: 1553732514\n",
      "  timesteps_since_restore: 9560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9560000\n",
      "  training_iteration: 956\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23466 s, 956 iter, 9560000 ts, 660 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-22-16\n",
      "  done: false\n",
      "  episode_len_mean: 140.78\n",
      "  episode_reward_max: 793.551141617108\n",
      "  episode_reward_mean: 630.432917402238\n",
      "  episode_reward_min: -114.29442957847544\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 71585\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3730.661\n",
      "    load_time_ms: 1.635\n",
      "    num_steps_sampled: 9570000\n",
      "    num_steps_trained: 9570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.429462194442749\n",
      "      kl: 0.023056482896208763\n",
      "      policy_loss: -0.002641575876623392\n",
      "      total_loss: 698.9857177734375\n",
      "      vf_explained_var: 0.9587247967720032\n",
      "      vf_loss: 698.98779296875\n",
      "    sample_time_ms: 18439.248\n",
      "    update_time_ms: 5.267\n",
      "  iterations_since_restore: 957\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 315.216458701119\n",
      "  time_since_restore: 23488.42435836792\n",
      "  time_this_iter_s: 22.419822216033936\n",
      "  time_total_s: 23488.42435836792\n",
      "  timestamp: 1553732536\n",
      "  timesteps_since_restore: 9570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9570000\n",
      "  training_iteration: 957\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23488 s, 957 iter, 9570000 ts, 630 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-22-39\n",
      "  done: false\n",
      "  episode_len_mean: 141.65\n",
      "  episode_reward_max: 793.551141617108\n",
      "  episode_reward_mean: 660.3247142668995\n",
      "  episode_reward_min: -80.59073037659186\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 71659\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.416\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 9580000\n",
      "    num_steps_trained: 9580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0720574855804443\n",
      "      kl: 0.015421760268509388\n",
      "      policy_loss: -0.0019687567837536335\n",
      "      total_loss: 177.9213409423828\n",
      "      vf_explained_var: 0.9895595908164978\n",
      "      vf_loss: 177.9229278564453\n",
      "    sample_time_ms: 18513.846\n",
      "    update_time_ms: 5.324\n",
      "  iterations_since_restore: 958\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 330.16235713344975\n",
      "  time_since_restore: 23511.17854142189\n",
      "  time_this_iter_s: 22.754183053970337\n",
      "  time_total_s: 23511.17854142189\n",
      "  timestamp: 1553732559\n",
      "  timesteps_since_restore: 9580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9580000\n",
      "  training_iteration: 958\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23511 s, 958 iter, 9580000 ts, 660 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-23-01\n",
      "  done: false\n",
      "  episode_len_mean: 130.75\n",
      "  episode_reward_max: 797.496219710508\n",
      "  episode_reward_mean: 707.0991726231798\n",
      "  episode_reward_min: -93.05900842771557\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 71738\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.521\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 9590000\n",
      "    num_steps_trained: 9590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6209306120872498\n",
      "      kl: 0.017195239663124084\n",
      "      policy_loss: -0.0011580375721678138\n",
      "      total_loss: 258.4756164550781\n",
      "      vf_explained_var: 0.9806039333343506\n",
      "      vf_loss: 258.4763488769531\n",
      "    sample_time_ms: 18598.311\n",
      "    update_time_ms: 5.359\n",
      "  iterations_since_restore: 959\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.5495863115898\n",
      "  time_since_restore: 23533.584148406982\n",
      "  time_this_iter_s: 22.405606985092163\n",
      "  time_total_s: 23533.584148406982\n",
      "  timestamp: 1553732581\n",
      "  timesteps_since_restore: 9590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9590000\n",
      "  training_iteration: 959\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23533 s, 959 iter, 9590000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-23-23\n",
      "  done: false\n",
      "  episode_len_mean: 132.51\n",
      "  episode_reward_max: 797.496219710508\n",
      "  episode_reward_mean: 708.9317595141182\n",
      "  episode_reward_min: -59.06376832568682\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 71812\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.221\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 9600000\n",
      "    num_steps_trained: 9600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0704337358474731\n",
      "      kl: 0.02677069790661335\n",
      "      policy_loss: -0.0038998681120574474\n",
      "      total_loss: 194.25753784179688\n",
      "      vf_explained_var: 0.9880684018135071\n",
      "      vf_loss: 194.2607421875\n",
      "    sample_time_ms: 18451.302\n",
      "    update_time_ms: 5.447\n",
      "  iterations_since_restore: 960\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.4658797570591\n",
      "  time_since_restore: 23554.96168589592\n",
      "  time_this_iter_s: 21.377537488937378\n",
      "  time_total_s: 23554.96168589592\n",
      "  timestamp: 1553732603\n",
      "  timesteps_since_restore: 9600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9600000\n",
      "  training_iteration: 960\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23554 s, 960 iter, 9600000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-23-45\n",
      "  done: false\n",
      "  episode_len_mean: 138.39\n",
      "  episode_reward_max: 795.5961108001018\n",
      "  episode_reward_mean: 678.2084093918794\n",
      "  episode_reward_min: -88.94933574629503\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 71887\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.297\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 9610000\n",
      "    num_steps_trained: 9610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0083909034729004\n",
      "      kl: 0.020998798310756683\n",
      "      policy_loss: -0.0020946692675352097\n",
      "      total_loss: 490.5631408691406\n",
      "      vf_explained_var: 0.9687351584434509\n",
      "      vf_loss: 490.56475830078125\n",
      "    sample_time_ms: 18468.082\n",
      "    update_time_ms: 5.577\n",
      "  iterations_since_restore: 961\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.10420469593976\n",
      "  time_since_restore: 23576.91891670227\n",
      "  time_this_iter_s: 21.957230806350708\n",
      "  time_total_s: 23576.91891670227\n",
      "  timestamp: 1553732625\n",
      "  timesteps_since_restore: 9610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9610000\n",
      "  training_iteration: 961\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23576 s, 961 iter, 9610000 ts, 678 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-24-07\n",
      "  done: false\n",
      "  episode_len_mean: 135.72\n",
      "  episode_reward_max: 796.0722627788086\n",
      "  episode_reward_mean: 695.8532715036556\n",
      "  episode_reward_min: -136.5266165140114\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 71963\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.59\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 9620000\n",
      "    num_steps_trained: 9620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8906373977661133\n",
      "      kl: 0.014506135135889053\n",
      "      policy_loss: -0.0014062990667298436\n",
      "      total_loss: 524.4573364257812\n",
      "      vf_explained_var: 0.9633350968360901\n",
      "      vf_loss: 524.4583129882812\n",
      "    sample_time_ms: 18482.947\n",
      "    update_time_ms: 5.247\n",
      "  iterations_since_restore: 962\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.92663575182786\n",
      "  time_since_restore: 23598.98149752617\n",
      "  time_this_iter_s: 22.062580823898315\n",
      "  time_total_s: 23598.98149752617\n",
      "  timestamp: 1553732647\n",
      "  timesteps_since_restore: 9620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9620000\n",
      "  training_iteration: 962\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23598 s, 962 iter, 9620000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-24-29\n",
      "  done: false\n",
      "  episode_len_mean: 130.99\n",
      "  episode_reward_max: 790.7316153046431\n",
      "  episode_reward_mean: 686.1762487829545\n",
      "  episode_reward_min: -109.78990914346446\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 72042\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.236\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 9630000\n",
      "    num_steps_trained: 9630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8938746452331543\n",
      "      kl: 0.014883984811604023\n",
      "      policy_loss: -0.0023380769416689873\n",
      "      total_loss: 355.7307434082031\n",
      "      vf_explained_var: 0.9735453724861145\n",
      "      vf_loss: 355.7326965332031\n",
      "    sample_time_ms: 18452.903\n",
      "    update_time_ms: 5.08\n",
      "  iterations_since_restore: 963\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 343.0881243914773\n",
      "  time_since_restore: 23621.12991833687\n",
      "  time_this_iter_s: 22.148420810699463\n",
      "  time_total_s: 23621.12991833687\n",
      "  timestamp: 1553732669\n",
      "  timesteps_since_restore: 9630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9630000\n",
      "  training_iteration: 963\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23621 s, 963 iter, 9630000 ts, 686 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-24-51\n",
      "  done: false\n",
      "  episode_len_mean: 134.01\n",
      "  episode_reward_max: 780.2105741059942\n",
      "  episode_reward_mean: 695.3445353539087\n",
      "  episode_reward_min: -109.78990914346446\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 72117\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3702.251\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 9640000\n",
      "    num_steps_trained: 9640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0378170013427734\n",
      "      kl: 0.022025899961590767\n",
      "      policy_loss: -0.0018322679679840803\n",
      "      total_loss: 355.7066345214844\n",
      "      vf_explained_var: 0.9757758975028992\n",
      "      vf_loss: 355.7078857421875\n",
      "    sample_time_ms: 18383.374\n",
      "    update_time_ms: 5.106\n",
      "  iterations_since_restore: 964\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.67226767695433\n",
      "  time_since_restore: 23642.867150068283\n",
      "  time_this_iter_s: 21.737231731414795\n",
      "  time_total_s: 23642.867150068283\n",
      "  timestamp: 1553732691\n",
      "  timesteps_since_restore: 9640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9640000\n",
      "  training_iteration: 964\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23642 s, 964 iter, 9640000 ts, 695 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-25-13\n",
      "  done: false\n",
      "  episode_len_mean: 135.13\n",
      "  episode_reward_max: 787.6198329220299\n",
      "  episode_reward_mean: 716.3109510956019\n",
      "  episode_reward_min: -59.44198423705194\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 72193\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.158\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 9650000\n",
      "    num_steps_trained: 9650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025500327348709106\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8178680539131165\n",
      "      kl: 0.04282539337873459\n",
      "      policy_loss: -0.005145001690834761\n",
      "      total_loss: 227.0965576171875\n",
      "      vf_explained_var: 0.9816718697547913\n",
      "      vf_loss: 227.1005859375\n",
      "    sample_time_ms: 18380.698\n",
      "    update_time_ms: 5.231\n",
      "  iterations_since_restore: 965\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.15547554780096\n",
      "  time_since_restore: 23664.75678753853\n",
      "  time_this_iter_s: 21.88963747024536\n",
      "  time_total_s: 23664.75678753853\n",
      "  timestamp: 1553732713\n",
      "  timesteps_since_restore: 9650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9650000\n",
      "  training_iteration: 965\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23664 s, 965 iter, 9650000 ts, 716 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-25-35\n",
      "  done: false\n",
      "  episode_len_mean: 132.76\n",
      "  episode_reward_max: 794.9270177030204\n",
      "  episode_reward_mean: 698.0590604179923\n",
      "  episode_reward_min: -95.1656717297069\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 72270\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3698.098\n",
      "    load_time_ms: 1.562\n",
      "    num_steps_sampled: 9660000\n",
      "    num_steps_trained: 9660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03825049102306366\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1276071071624756\n",
      "      kl: 0.03574887290596962\n",
      "      policy_loss: -0.005091178230941296\n",
      "      total_loss: 528.4466552734375\n",
      "      vf_explained_var: 0.9602411985397339\n",
      "      vf_loss: 528.450439453125\n",
      "    sample_time_ms: 18343.642\n",
      "    update_time_ms: 5.448\n",
      "  iterations_since_restore: 966\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.02953020899616\n",
      "  time_since_restore: 23686.67745614052\n",
      "  time_this_iter_s: 21.920668601989746\n",
      "  time_total_s: 23686.67745614052\n",
      "  timestamp: 1553732735\n",
      "  timesteps_since_restore: 9660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9660000\n",
      "  training_iteration: 966\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23686 s, 966 iter, 9660000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-25-57\n",
      "  done: false\n",
      "  episode_len_mean: 136.17\n",
      "  episode_reward_max: 794.9270177030204\n",
      "  episode_reward_mean: 678.1015807048193\n",
      "  episode_reward_min: -95.1656717297069\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 72345\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3711.646\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 9670000\n",
      "    num_steps_trained: 9670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.03825049102306366\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1197595596313477\n",
      "      kl: 0.009966058656573296\n",
      "      policy_loss: -0.002256611129269004\n",
      "      total_loss: 292.59930419921875\n",
      "      vf_explained_var: 0.9799214005470276\n",
      "      vf_loss: 292.6011657714844\n",
      "    sample_time_ms: 18295.748\n",
      "    update_time_ms: 5.44\n",
      "  iterations_since_restore: 967\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.0507903524096\n",
      "  time_since_restore: 23708.751668453217\n",
      "  time_this_iter_s: 22.074212312698364\n",
      "  time_total_s: 23708.751668453217\n",
      "  timestamp: 1553732757\n",
      "  timesteps_since_restore: 9670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9670000\n",
      "  training_iteration: 967\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23708 s, 967 iter, 9670000 ts, 678 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-26-19\n",
      "  done: false\n",
      "  episode_len_mean: 128.7\n",
      "  episode_reward_max: 796.3288890399725\n",
      "  episode_reward_mean: 702.8355225700777\n",
      "  episode_reward_min: -67.76080441527091\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 72423\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3705.943\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 9680000\n",
      "    num_steps_trained: 9680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.80035799741745\n",
      "      kl: 0.019420718774199486\n",
      "      policy_loss: -0.002995844930410385\n",
      "      total_loss: 376.93280029296875\n",
      "      vf_explained_var: 0.9694415330886841\n",
      "      vf_loss: 376.9354248046875\n",
      "    sample_time_ms: 18186.968\n",
      "    update_time_ms: 5.329\n",
      "  iterations_since_restore: 968\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.41776128503886\n",
      "  time_since_restore: 23730.359429359436\n",
      "  time_this_iter_s: 21.607760906219482\n",
      "  time_total_s: 23730.359429359436\n",
      "  timestamp: 1553732779\n",
      "  timesteps_since_restore: 9680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9680000\n",
      "  training_iteration: 968\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23730 s, 968 iter, 9680000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-26-40\n",
      "  done: false\n",
      "  episode_len_mean: 131.02\n",
      "  episode_reward_max: 796.3288890399725\n",
      "  episode_reward_mean: 729.580398203659\n",
      "  episode_reward_min: 386.36869905411675\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 72500\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3701.799\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 9690000\n",
      "    num_steps_trained: 9690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8594422936439514\n",
      "      kl: 0.028998050838708878\n",
      "      policy_loss: -0.003328524297103286\n",
      "      total_loss: 115.35133361816406\n",
      "      vf_explained_var: 0.9910113215446472\n",
      "      vf_loss: 115.35411834716797\n",
      "    sample_time_ms: 18121.16\n",
      "    update_time_ms: 5.298\n",
      "  iterations_since_restore: 969\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.79019910182944\n",
      "  time_since_restore: 23752.064230918884\n",
      "  time_this_iter_s: 21.704801559448242\n",
      "  time_total_s: 23752.064230918884\n",
      "  timestamp: 1553732800\n",
      "  timesteps_since_restore: 9690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9690000\n",
      "  training_iteration: 969\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23752 s, 969 iter, 9690000 ts, 730 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-27-02\n",
      "  done: false\n",
      "  episode_len_mean: 128.78\n",
      "  episode_reward_max: 794.1219287527296\n",
      "  episode_reward_mean: 728.2428682802176\n",
      "  episode_reward_min: 521.7909484836276\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 72579\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3699.034\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 9700000\n",
      "    num_steps_trained: 9700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7099016904830933\n",
      "      kl: 0.014998486265540123\n",
      "      policy_loss: -0.0016893401043489575\n",
      "      total_loss: 69.70496368408203\n",
      "      vf_explained_var: 0.9942266941070557\n",
      "      vf_loss: 69.70637512207031\n",
      "    sample_time_ms: 18176.46\n",
      "    update_time_ms: 5.342\n",
      "  iterations_since_restore: 970\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 364.12143414010876\n",
      "  time_since_restore: 23773.962486982346\n",
      "  time_this_iter_s: 21.898256063461304\n",
      "  time_total_s: 23773.962486982346\n",
      "  timestamp: 1553732822\n",
      "  timesteps_since_restore: 9700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9700000\n",
      "  training_iteration: 970\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23773 s, 970 iter, 9700000 ts, 728 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-27-24\n",
      "  done: false\n",
      "  episode_len_mean: 132.6\n",
      "  episode_reward_max: 794.1219287527296\n",
      "  episode_reward_mean: 716.9770436722933\n",
      "  episode_reward_min: -71.55085365509916\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 72654\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3695.343\n",
      "    load_time_ms: 1.49\n",
      "    num_steps_sampled: 9710000\n",
      "    num_steps_trained: 9710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0832639932632446\n",
      "      kl: 0.014338534325361252\n",
      "      policy_loss: -0.003998554311692715\n",
      "      total_loss: 151.43397521972656\n",
      "      vf_explained_var: 0.9896883964538574\n",
      "      vf_loss: 151.43768310546875\n",
      "    sample_time_ms: 18118.026\n",
      "    update_time_ms: 5.273\n",
      "  iterations_since_restore: 971\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.4885218361467\n",
      "  time_since_restore: 23795.29837822914\n",
      "  time_this_iter_s: 21.335891246795654\n",
      "  time_total_s: 23795.29837822914\n",
      "  timestamp: 1553732844\n",
      "  timesteps_since_restore: 9710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9710000\n",
      "  training_iteration: 971\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23795 s, 971 iter, 9710000 ts, 717 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-27-45\n",
      "  done: false\n",
      "  episode_len_mean: 132.5\n",
      "  episode_reward_max: 789.3742191669359\n",
      "  episode_reward_mean: 669.2175319576235\n",
      "  episode_reward_min: -102.19774756309403\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 72732\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3691.291\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 9720000\n",
      "    num_steps_trained: 9720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1695650815963745\n",
      "      kl: 0.018018964678049088\n",
      "      policy_loss: -0.0021927766501903534\n",
      "      total_loss: 698.4467163085938\n",
      "      vf_explained_var: 0.9494411945343018\n",
      "      vf_loss: 698.4486083984375\n",
      "    sample_time_ms: 18077.871\n",
      "    update_time_ms: 5.32\n",
      "  iterations_since_restore: 972\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 334.60876597881173\n",
      "  time_since_restore: 23816.920512914658\n",
      "  time_this_iter_s: 21.622134685516357\n",
      "  time_total_s: 23816.920512914658\n",
      "  timestamp: 1553732865\n",
      "  timesteps_since_restore: 9720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9720000\n",
      "  training_iteration: 972\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23816 s, 972 iter, 9720000 ts, 669 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-28-07\n",
      "  done: false\n",
      "  episode_len_mean: 132.06\n",
      "  episode_reward_max: 789.3742191669359\n",
      "  episode_reward_mean: 678.0717645831256\n",
      "  episode_reward_min: -102.19774756309403\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 72809\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3692.672\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 9730000\n",
      "    num_steps_trained: 9730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0405757427215576\n",
      "      kl: 0.014560586772859097\n",
      "      policy_loss: -0.003549169283360243\n",
      "      total_loss: 248.6291046142578\n",
      "      vf_explained_var: 0.9825233221054077\n",
      "      vf_loss: 248.63235473632812\n",
      "    sample_time_ms: 18006.032\n",
      "    update_time_ms: 5.372\n",
      "  iterations_since_restore: 973\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 339.0358822915628\n",
      "  time_since_restore: 23838.364680290222\n",
      "  time_this_iter_s: 21.444167375564575\n",
      "  time_total_s: 23838.364680290222\n",
      "  timestamp: 1553732887\n",
      "  timesteps_since_restore: 9730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9730000\n",
      "  training_iteration: 973\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23838 s, 973 iter, 9730000 ts, 678 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-28-28\n",
      "  done: false\n",
      "  episode_len_mean: 130.84\n",
      "  episode_reward_max: 787.0906212930091\n",
      "  episode_reward_mean: 732.1127557270004\n",
      "  episode_reward_min: 528.9903260126307\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 72886\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3710.44\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 9740000\n",
      "    num_steps_trained: 9740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8469604253768921\n",
      "      kl: 0.024673985317349434\n",
      "      policy_loss: -0.0021635894663631916\n",
      "      total_loss: 150.75128173828125\n",
      "      vf_explained_var: 0.9894428849220276\n",
      "      vf_loss: 150.75296020507812\n",
      "    sample_time_ms: 17977.047\n",
      "    update_time_ms: 5.423\n",
      "  iterations_since_restore: 974\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 366.0563778635002\n",
      "  time_since_restore: 23859.990139245987\n",
      "  time_this_iter_s: 21.62545895576477\n",
      "  time_total_s: 23859.990139245987\n",
      "  timestamp: 1553732908\n",
      "  timesteps_since_restore: 9740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9740000\n",
      "  training_iteration: 974\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23859 s, 974 iter, 9740000 ts, 732 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-28-50\n",
      "  done: false\n",
      "  episode_len_mean: 132.3\n",
      "  episode_reward_max: 783.2998409170697\n",
      "  episode_reward_mean: 703.2162825455042\n",
      "  episode_reward_min: -98.16080901049648\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 72963\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.521\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 9750000\n",
      "    num_steps_trained: 9750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.013773798942566\n",
      "      kl: 0.019574742764234543\n",
      "      policy_loss: -0.0023454392794519663\n",
      "      total_loss: 346.0767822265625\n",
      "      vf_explained_var: 0.97562575340271\n",
      "      vf_loss: 346.0787658691406\n",
      "    sample_time_ms: 17956.683\n",
      "    update_time_ms: 5.289\n",
      "  iterations_since_restore: 975\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.6081412727521\n",
      "  time_since_restore: 23881.665848493576\n",
      "  time_this_iter_s: 21.67570924758911\n",
      "  time_total_s: 23881.665848493576\n",
      "  timestamp: 1553732930\n",
      "  timesteps_since_restore: 9750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9750000\n",
      "  training_iteration: 975\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23881 s, 975 iter, 9750000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-29-12\n",
      "  done: false\n",
      "  episode_len_mean: 133.14\n",
      "  episode_reward_max: 781.666919983712\n",
      "  episode_reward_mean: 696.8489990858966\n",
      "  episode_reward_min: -62.36981206033619\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 73038\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3706.647\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 9760000\n",
      "    num_steps_trained: 9760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.001967430114746\n",
      "      kl: 0.014909319579601288\n",
      "      policy_loss: -0.001947036013007164\n",
      "      total_loss: 181.8916473388672\n",
      "      vf_explained_var: 0.9864045977592468\n",
      "      vf_loss: 181.893310546875\n",
      "    sample_time_ms: 17909.201\n",
      "    update_time_ms: 5.099\n",
      "  iterations_since_restore: 976\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.4244995429483\n",
      "  time_since_restore: 23903.079684257507\n",
      "  time_this_iter_s: 21.413835763931274\n",
      "  time_total_s: 23903.079684257507\n",
      "  timestamp: 1553732952\n",
      "  timesteps_since_restore: 9760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9760000\n",
      "  training_iteration: 976\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23903 s, 976 iter, 9760000 ts, 697 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-29-33\n",
      "  done: false\n",
      "  episode_len_mean: 134.08\n",
      "  episode_reward_max: 793.8445586730896\n",
      "  episode_reward_mean: 702.5205156639078\n",
      "  episode_reward_min: -70.20067664713054\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 73116\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3690.193\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 9770000\n",
      "    num_steps_trained: 9770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0143502950668335\n",
      "      kl: 0.011418420821428299\n",
      "      policy_loss: -0.0019822472240775824\n",
      "      total_loss: 249.0908966064453\n",
      "      vf_explained_var: 0.9800217747688293\n",
      "      vf_loss: 249.09262084960938\n",
      "    sample_time_ms: 17875.122\n",
      "    update_time_ms: 5.22\n",
      "  iterations_since_restore: 977\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.26025783195377\n",
      "  time_since_restore: 23924.65121793747\n",
      "  time_this_iter_s: 21.571533679962158\n",
      "  time_total_s: 23924.65121793747\n",
      "  timestamp: 1553732973\n",
      "  timesteps_since_restore: 9770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9770000\n",
      "  training_iteration: 977\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23924 s, 977 iter, 9770000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 132.45\n",
      "  episode_reward_max: 795.4303000146025\n",
      "  episode_reward_mean: 706.1354077892366\n",
      "  episode_reward_min: -64.97515665902856\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 73192\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.657\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 9780000\n",
      "    num_steps_trained: 9780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9363734126091003\n",
      "      kl: 0.02232278510928154\n",
      "      policy_loss: -0.005223501939326525\n",
      "      total_loss: 279.36279296875\n",
      "      vf_explained_var: 0.9794943332672119\n",
      "      vf_loss: 279.3675842285156\n",
      "    sample_time_ms: 17900.666\n",
      "    update_time_ms: 5.431\n",
      "  iterations_since_restore: 978\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.0677038946183\n",
      "  time_since_restore: 23946.738196611404\n",
      "  time_this_iter_s: 22.086978673934937\n",
      "  time_total_s: 23946.738196611404\n",
      "  timestamp: 1553732995\n",
      "  timesteps_since_restore: 9780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9780000\n",
      "  training_iteration: 978\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23946 s, 978 iter, 9780000 ts, 706 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-30-17\n",
      "  done: false\n",
      "  episode_len_mean: 132.29\n",
      "  episode_reward_max: 788.7568782821708\n",
      "  episode_reward_mean: 698.9765775681019\n",
      "  episode_reward_min: -133.8693519431127\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 73270\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3713.785\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 9790000\n",
      "    num_steps_trained: 9790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8439419865608215\n",
      "      kl: 0.01727464608848095\n",
      "      policy_loss: -0.0034659577067941427\n",
      "      total_loss: 177.73648071289062\n",
      "      vf_explained_var: 0.9876263737678528\n",
      "      vf_loss: 177.73963928222656\n",
      "    sample_time_ms: 17916.586\n",
      "    update_time_ms: 5.287\n",
      "  iterations_since_restore: 979\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 349.48828878405095\n",
      "  time_since_restore: 23968.615585803986\n",
      "  time_this_iter_s: 21.877389192581177\n",
      "  time_total_s: 23968.615585803986\n",
      "  timestamp: 1553733017\n",
      "  timesteps_since_restore: 9790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9790000\n",
      "  training_iteration: 979\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23968 s, 979 iter, 9790000 ts, 699 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-30-39\n",
      "  done: false\n",
      "  episode_len_mean: 129.14\n",
      "  episode_reward_max: 788.6201283442517\n",
      "  episode_reward_mean: 714.7985858795479\n",
      "  episode_reward_min: -133.8693519431127\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 73346\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3712.238\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 9800000\n",
      "    num_steps_trained: 9800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8117541074752808\n",
      "      kl: 0.021517513319849968\n",
      "      policy_loss: -0.003103753784671426\n",
      "      total_loss: 171.72872924804688\n",
      "      vf_explained_var: 0.9871342778205872\n",
      "      vf_loss: 171.73143005371094\n",
      "    sample_time_ms: 17921.439\n",
      "    update_time_ms: 5.3\n",
      "  iterations_since_restore: 980\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.399292939774\n",
      "  time_since_restore: 23990.54686808586\n",
      "  time_this_iter_s: 21.93128228187561\n",
      "  time_total_s: 23990.54686808586\n",
      "  timestamp: 1553733039\n",
      "  timesteps_since_restore: 9800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9800000\n",
      "  training_iteration: 980\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 23990 s, 980 iter, 9800000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-31-01\n",
      "  done: false\n",
      "  episode_len_mean: 130.45\n",
      "  episode_reward_max: 788.6201283442517\n",
      "  episode_reward_mean: 706.9081401430664\n",
      "  episode_reward_min: -123.8646649324687\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 73425\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3716.476\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 9810000\n",
      "    num_steps_trained: 9810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8317395448684692\n",
      "      kl: 0.028937583789229393\n",
      "      policy_loss: -0.005782311782240868\n",
      "      total_loss: 277.5934143066406\n",
      "      vf_explained_var: 0.9791163802146912\n",
      "      vf_loss: 277.5986328125\n",
      "    sample_time_ms: 17928.243\n",
      "    update_time_ms: 5.259\n",
      "  iterations_since_restore: 981\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.4540700715332\n",
      "  time_since_restore: 24011.99343252182\n",
      "  time_this_iter_s: 21.446564435958862\n",
      "  time_total_s: 24011.99343252182\n",
      "  timestamp: 1553733061\n",
      "  timesteps_since_restore: 9810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9810000\n",
      "  training_iteration: 981\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24011 s, 981 iter, 9810000 ts, 707 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-31-22\n",
      "  done: false\n",
      "  episode_len_mean: 127.48\n",
      "  episode_reward_max: 783.6784545639987\n",
      "  episode_reward_mean: 706.2846174805659\n",
      "  episode_reward_min: -123.8646649324687\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 73504\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.261\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 9820000\n",
      "    num_steps_trained: 9820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.821003258228302\n",
      "      kl: 0.012190497480332851\n",
      "      policy_loss: -0.0018270108848810196\n",
      "      total_loss: 98.2343521118164\n",
      "      vf_explained_var: 0.9917606711387634\n",
      "      vf_loss: 98.2359390258789\n",
      "    sample_time_ms: 17875.169\n",
      "    update_time_ms: 5.85\n",
      "  iterations_since_restore: 982\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 353.1423087402829\n",
      "  time_since_restore: 24033.11668777466\n",
      "  time_this_iter_s: 21.123255252838135\n",
      "  time_total_s: 24033.11668777466\n",
      "  timestamp: 1553733082\n",
      "  timesteps_since_restore: 9820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9820000\n",
      "  training_iteration: 982\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24033 s, 982 iter, 9820000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-31-44\n",
      "  done: false\n",
      "  episode_len_mean: 133.63\n",
      "  episode_reward_max: 791.8664316894825\n",
      "  episode_reward_mean: 714.9615703776232\n",
      "  episode_reward_min: -84.66733352455975\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 73578\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3719.308\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 9830000\n",
      "    num_steps_trained: 9830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.042642593383789\n",
      "      kl: 0.01254639308899641\n",
      "      policy_loss: -0.0031279807444661856\n",
      "      total_loss: 120.12773895263672\n",
      "      vf_explained_var: 0.990697979927063\n",
      "      vf_loss: 120.13063049316406\n",
      "    sample_time_ms: 17939.992\n",
      "    update_time_ms: 5.902\n",
      "  iterations_since_restore: 983\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.4807851888116\n",
      "  time_since_restore: 24055.211044311523\n",
      "  time_this_iter_s: 22.094356536865234\n",
      "  time_total_s: 24055.211044311523\n",
      "  timestamp: 1553733104\n",
      "  timesteps_since_restore: 9830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9830000\n",
      "  training_iteration: 983\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24055 s, 983 iter, 9830000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-32-07\n",
      "  done: false\n",
      "  episode_len_mean: 133.26\n",
      "  episode_reward_max: 794.6099575894347\n",
      "  episode_reward_mean: 709.8333873813625\n",
      "  episode_reward_min: -110.63032343028448\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 73655\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.497\n",
      "    load_time_ms: 1.504\n",
      "    num_steps_sampled: 9840000\n",
      "    num_steps_trained: 9840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7821590304374695\n",
      "      kl: 0.013261310756206512\n",
      "      policy_loss: -0.00206303340382874\n",
      "      total_loss: 221.29747009277344\n",
      "      vf_explained_var: 0.9844874739646912\n",
      "      vf_loss: 221.29930114746094\n",
      "    sample_time_ms: 18046.869\n",
      "    update_time_ms: 5.87\n",
      "  iterations_since_restore: 984\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.9166936906812\n",
      "  time_since_restore: 24077.756140947342\n",
      "  time_this_iter_s: 22.54509663581848\n",
      "  time_total_s: 24077.756140947342\n",
      "  timestamp: 1553733127\n",
      "  timesteps_since_restore: 9840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9840000\n",
      "  training_iteration: 984\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24077 s, 984 iter, 9840000 ts, 710 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-32-29\n",
      "  done: false\n",
      "  episode_len_mean: 132.36\n",
      "  episode_reward_max: 794.6099575894347\n",
      "  episode_reward_mean: 717.421872994941\n",
      "  episode_reward_min: -60.74083524538912\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 73733\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3704.193\n",
      "    load_time_ms: 1.52\n",
      "    num_steps_sampled: 9850000\n",
      "    num_steps_trained: 9850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7819920778274536\n",
      "      kl: 0.03739117830991745\n",
      "      policy_loss: -0.0018119814340025187\n",
      "      total_loss: 155.99758911132812\n",
      "      vf_explained_var: 0.9878195524215698\n",
      "      vf_loss: 155.99867248535156\n",
      "    sample_time_ms: 18137.433\n",
      "    update_time_ms: 5.942\n",
      "  iterations_since_restore: 985\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.71093649747047\n",
      "  time_since_restore: 24100.335416078568\n",
      "  time_this_iter_s: 22.579275131225586\n",
      "  time_total_s: 24100.335416078568\n",
      "  timestamp: 1553733149\n",
      "  timesteps_since_restore: 9850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9850000\n",
      "  training_iteration: 985\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24100 s, 985 iter, 9850000 ts, 717 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-32-51\n",
      "  done: false\n",
      "  episode_len_mean: 132.45\n",
      "  episode_reward_max: 796.3166981690822\n",
      "  episode_reward_mean: 708.5643940563151\n",
      "  episode_reward_min: -98.14604540816515\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 73808\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3707.571\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 9860000\n",
      "    num_steps_trained: 9860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.061521053314209\n",
      "      kl: 0.014093865640461445\n",
      "      policy_loss: -0.0012488641077652574\n",
      "      total_loss: 504.64447021484375\n",
      "      vf_explained_var: 0.9617223739624023\n",
      "      vf_loss: 504.6454772949219\n",
      "    sample_time_ms: 18192.565\n",
      "    update_time_ms: 5.949\n",
      "  iterations_since_restore: 986\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 354.28219702815755\n",
      "  time_since_restore: 24122.33344602585\n",
      "  time_this_iter_s: 21.998029947280884\n",
      "  time_total_s: 24122.33344602585\n",
      "  timestamp: 1553733171\n",
      "  timesteps_since_restore: 9860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9860000\n",
      "  training_iteration: 986\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24122 s, 986 iter, 9860000 ts, 709 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-33-13\n",
      "  done: false\n",
      "  episode_len_mean: 132.86\n",
      "  episode_reward_max: 796.3166981690822\n",
      "  episode_reward_mean: 705.7815798600591\n",
      "  episode_reward_min: -112.1669986505294\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 73886\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3708.066\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 9870000\n",
      "    num_steps_trained: 9870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8627064824104309\n",
      "      kl: 0.022499384358525276\n",
      "      policy_loss: -1.0673434189811815e-05\n",
      "      total_loss: 235.2783966064453\n",
      "      vf_explained_var: 0.982907235622406\n",
      "      vf_loss: 235.27793884277344\n",
      "    sample_time_ms: 18210.979\n",
      "    update_time_ms: 5.783\n",
      "  iterations_since_restore: 987\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 352.89078993002954\n",
      "  time_since_restore: 24144.09015059471\n",
      "  time_this_iter_s: 21.756704568862915\n",
      "  time_total_s: 24144.09015059471\n",
      "  timestamp: 1553733193\n",
      "  timesteps_since_restore: 9870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9870000\n",
      "  training_iteration: 987\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24144 s, 987 iter, 9870000 ts, 706 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-33-36\n",
      "  done: false\n",
      "  episode_len_mean: 127.82\n",
      "  episode_reward_max: 784.8168101538063\n",
      "  episode_reward_mean: 718.9252294999773\n",
      "  episode_reward_min: -76.20498510151242\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 73965\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3686.898\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 9880000\n",
      "    num_steps_trained: 9880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8088984489440918\n",
      "      kl: 0.019685912877321243\n",
      "      policy_loss: -0.0016244540456682444\n",
      "      total_loss: 199.77919006347656\n",
      "      vf_explained_var: 0.983265221118927\n",
      "      vf_loss: 199.7804412841797\n",
      "    sample_time_ms: 18291.101\n",
      "    update_time_ms: 5.717\n",
      "  iterations_since_restore: 988\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 359.46261474998863\n",
      "  time_since_restore: 24166.767183303833\n",
      "  time_this_iter_s: 22.677032709121704\n",
      "  time_total_s: 24166.767183303833\n",
      "  timestamp: 1553733216\n",
      "  timesteps_since_restore: 9880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9880000\n",
      "  training_iteration: 988\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24166 s, 988 iter, 9880000 ts, 719 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-33-58\n",
      "  done: false\n",
      "  episode_len_mean: 133.0\n",
      "  episode_reward_max: 787.2979923128335\n",
      "  episode_reward_mean: 703.6232819775611\n",
      "  episode_reward_min: -76.20498510151242\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 74040\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3709.286\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 9890000\n",
      "    num_steps_trained: 9890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.067781686782837\n",
      "      kl: 0.014945919625461102\n",
      "      policy_loss: -0.0024858361575752497\n",
      "      total_loss: 225.8678436279297\n",
      "      vf_explained_var: 0.9824888706207275\n",
      "      vf_loss: 225.8700408935547\n",
      "    sample_time_ms: 18321.707\n",
      "    update_time_ms: 5.989\n",
      "  iterations_since_restore: 989\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.8116409887807\n",
      "  time_since_restore: 24189.174736261368\n",
      "  time_this_iter_s: 22.40755295753479\n",
      "  time_total_s: 24189.174736261368\n",
      "  timestamp: 1553733238\n",
      "  timesteps_since_restore: 9890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9890000\n",
      "  training_iteration: 989\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24189 s, 989 iter, 9890000 ts, 704 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-34-20\n",
      "  done: false\n",
      "  episode_len_mean: 127.92\n",
      "  episode_reward_max: 787.8460850504433\n",
      "  episode_reward_mean: 697.5877244614986\n",
      "  episode_reward_min: -89.7640772517754\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 74119\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3714.687\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 9900000\n",
      "    num_steps_trained: 9900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8064212203025818\n",
      "      kl: 0.013590800575911999\n",
      "      policy_loss: -0.0010026206728070974\n",
      "      total_loss: 346.4015197753906\n",
      "      vf_explained_var: 0.9702374339103699\n",
      "      vf_loss: 346.4022521972656\n",
      "    sample_time_ms: 18346.264\n",
      "    update_time_ms: 6.031\n",
      "  iterations_since_restore: 990\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.7938622307492\n",
      "  time_since_restore: 24211.407952547073\n",
      "  time_this_iter_s: 22.233216285705566\n",
      "  time_total_s: 24211.407952547073\n",
      "  timestamp: 1553733260\n",
      "  timesteps_since_restore: 9900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9900000\n",
      "  training_iteration: 990\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24211 s, 990 iter, 9900000 ts, 698 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-34-42\n",
      "  done: false\n",
      "  episode_len_mean: 128.25\n",
      "  episode_reward_max: 794.9103043799904\n",
      "  episode_reward_mean: 691.0757892992336\n",
      "  episode_reward_min: -139.72744193861058\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 74198\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3718.884\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 9910000\n",
      "    num_steps_trained: 9910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8224872946739197\n",
      "      kl: 0.02463100478053093\n",
      "      policy_loss: -0.005452875979244709\n",
      "      total_loss: 324.0623474121094\n",
      "      vf_explained_var: 0.978997528553009\n",
      "      vf_loss: 324.06732177734375\n",
      "    sample_time_ms: 18386.91\n",
      "    update_time_ms: 6.205\n",
      "  iterations_since_restore: 991\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.5378946496168\n",
      "  time_since_restore: 24233.303951501846\n",
      "  time_this_iter_s: 21.89599895477295\n",
      "  time_total_s: 24233.303951501846\n",
      "  timestamp: 1553733282\n",
      "  timesteps_since_restore: 9910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9910000\n",
      "  training_iteration: 991\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24233 s, 991 iter, 9910000 ts, 691 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-35-04\n",
      "  done: false\n",
      "  episode_len_mean: 125.11\n",
      "  episode_reward_max: 794.9103043799904\n",
      "  episode_reward_mean: 695.8433702124529\n",
      "  episode_reward_min: -139.72744193861058\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 74278\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3720.308\n",
      "    load_time_ms: 1.491\n",
      "    num_steps_sampled: 9920000\n",
      "    num_steps_trained: 9920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.01912524551153183\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5853562951087952\n",
      "      kl: 0.047804515808820724\n",
      "      policy_loss: -0.013179893605411053\n",
      "      total_loss: 221.4244842529297\n",
      "      vf_explained_var: 0.9823173880577087\n",
      "      vf_loss: 221.43675231933594\n",
      "    sample_time_ms: 18481.604\n",
      "    update_time_ms: 5.627\n",
      "  iterations_since_restore: 992\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 347.92168510622645\n",
      "  time_since_restore: 24255.38284635544\n",
      "  time_this_iter_s: 22.07889485359192\n",
      "  time_total_s: 24255.38284635544\n",
      "  timestamp: 1553733304\n",
      "  timesteps_since_restore: 9920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9920000\n",
      "  training_iteration: 992\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24255 s, 992 iter, 9920000 ts, 696 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-35-27\n",
      "  done: false\n",
      "  episode_len_mean: 130.69\n",
      "  episode_reward_max: 787.8925353042798\n",
      "  episode_reward_mean: 722.2558119166233\n",
      "  episode_reward_min: 235.98495587732367\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 74354\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3749.779\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 9930000\n",
      "    num_steps_trained: 9930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028687868267297745\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8937830924987793\n",
      "      kl: 0.017514405772089958\n",
      "      policy_loss: -0.0033836234360933304\n",
      "      total_loss: 100.81580352783203\n",
      "      vf_explained_var: 0.9921951293945312\n",
      "      vf_loss: 100.81868743896484\n",
      "    sample_time_ms: 18468.432\n",
      "    update_time_ms: 5.56\n",
      "  iterations_since_restore: 993\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.12790595831166\n",
      "  time_since_restore: 24277.63902902603\n",
      "  time_this_iter_s: 22.25618267059326\n",
      "  time_total_s: 24277.63902902603\n",
      "  timestamp: 1553733327\n",
      "  timesteps_since_restore: 9930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9930000\n",
      "  training_iteration: 993\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24277 s, 993 iter, 9930000 ts, 722 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-35-49\n",
      "  done: false\n",
      "  episode_len_mean: 129.81\n",
      "  episode_reward_max: 786.1712329914743\n",
      "  episode_reward_mean: 690.4925345495328\n",
      "  episode_reward_min: -55.74363611401773\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 74432\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3753.009\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 9940000\n",
      "    num_steps_trained: 9940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028687868267297745\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9146149754524231\n",
      "      kl: 0.0196099691092968\n",
      "      policy_loss: -0.004755971487611532\n",
      "      total_loss: 570.517822265625\n",
      "      vf_explained_var: 0.9566169381141663\n",
      "      vf_loss: 570.5220336914062\n",
      "    sample_time_ms: 18450.212\n",
      "    update_time_ms: 5.538\n",
      "  iterations_since_restore: 994\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 345.2462672747664\n",
      "  time_since_restore: 24300.03004717827\n",
      "  time_this_iter_s: 22.39101815223694\n",
      "  time_total_s: 24300.03004717827\n",
      "  timestamp: 1553733349\n",
      "  timesteps_since_restore: 9940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9940000\n",
      "  training_iteration: 994\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24300 s, 994 iter, 9940000 ts, 690 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-36-12\n",
      "  done: false\n",
      "  episode_len_mean: 134.54\n",
      "  episode_reward_max: 791.6800608931242\n",
      "  episode_reward_mean: 702.8703705586076\n",
      "  episode_reward_min: -55.74363611401773\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 74505\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3755.454\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 9950000\n",
      "    num_steps_trained: 9950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028687868267297745\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0625592470169067\n",
      "      kl: 0.026119228452444077\n",
      "      policy_loss: -0.003109244629740715\n",
      "      total_loss: 186.98780822753906\n",
      "      vf_explained_var: 0.9864587783813477\n",
      "      vf_loss: 186.9901580810547\n",
      "    sample_time_ms: 18424.688\n",
      "    update_time_ms: 5.492\n",
      "  iterations_since_restore: 995\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 351.4351852793038\n",
      "  time_since_restore: 24322.37706542015\n",
      "  time_this_iter_s: 22.347018241882324\n",
      "  time_total_s: 24322.37706542015\n",
      "  timestamp: 1553733372\n",
      "  timesteps_since_restore: 9950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9950000\n",
      "  training_iteration: 995\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24322 s, 995 iter, 9950000 ts, 703 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-36-34\n",
      "  done: false\n",
      "  episode_len_mean: 136.16\n",
      "  episode_reward_max: 791.6800608931242\n",
      "  episode_reward_mean: 717.5784267215184\n",
      "  episode_reward_min: 155.99720865512734\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 74583\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3756.84\n",
      "    load_time_ms: 1.548\n",
      "    num_steps_sampled: 9960000\n",
      "    num_steps_trained: 9960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028687868267297745\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7913187742233276\n",
      "      kl: 0.02261200360953808\n",
      "      policy_loss: -0.0015492003876715899\n",
      "      total_loss: 100.45918273925781\n",
      "      vf_explained_var: 0.9917194843292236\n",
      "      vf_loss: 100.4600830078125\n",
      "    sample_time_ms: 18443.45\n",
      "    update_time_ms: 5.485\n",
      "  iterations_since_restore: 996\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.78921336075933\n",
      "  time_since_restore: 24344.579397201538\n",
      "  time_this_iter_s: 22.20233178138733\n",
      "  time_total_s: 24344.579397201538\n",
      "  timestamp: 1553733394\n",
      "  timesteps_since_restore: 9960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9960000\n",
      "  training_iteration: 996\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24344 s, 996 iter, 9960000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-36-56\n",
      "  done: false\n",
      "  episode_len_mean: 129.15\n",
      "  episode_reward_max: 788.8342288590751\n",
      "  episode_reward_mean: 717.869087954029\n",
      "  episode_reward_min: -95.79418440274408\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 74662\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3777.335\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 9970000\n",
      "    num_steps_trained: 9970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.028687868267297745\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7946769595146179\n",
      "      kl: 0.009795320220291615\n",
      "      policy_loss: -0.002764302771538496\n",
      "      total_loss: 207.34608459472656\n",
      "      vf_explained_var: 0.9824348092079163\n",
      "      vf_loss: 207.3485565185547\n",
      "    sample_time_ms: 18481.55\n",
      "    update_time_ms: 5.534\n",
      "  iterations_since_restore: 997\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 358.9345439770145\n",
      "  time_since_restore: 24366.931359291077\n",
      "  time_this_iter_s: 22.351962089538574\n",
      "  time_total_s: 24366.931359291077\n",
      "  timestamp: 1553733416\n",
      "  timesteps_since_restore: 9970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9970000\n",
      "  training_iteration: 997\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24366 s, 997 iter, 9970000 ts, 718 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-37-18\n",
      "  done: false\n",
      "  episode_len_mean: 128.54\n",
      "  episode_reward_max: 801.7627650610083\n",
      "  episode_reward_mean: 722.5100604656202\n",
      "  episode_reward_min: 32.25845439665315\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 74739\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3783.43\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 9980000\n",
      "    num_steps_trained: 9980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014343934133648872\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6956654787063599\n",
      "      kl: 0.02072654291987419\n",
      "      policy_loss: -0.0024086807388812304\n",
      "      total_loss: 66.57820129394531\n",
      "      vf_explained_var: 0.9943395853042603\n",
      "      vf_loss: 66.58031463623047\n",
      "    sample_time_ms: 18387.923\n",
      "    update_time_ms: 5.502\n",
      "  iterations_since_restore: 998\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 361.25503023281004\n",
      "  time_since_restore: 24388.735786914825\n",
      "  time_this_iter_s: 21.80442762374878\n",
      "  time_total_s: 24388.735786914825\n",
      "  timestamp: 1553733438\n",
      "  timesteps_since_restore: 9980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9980000\n",
      "  training_iteration: 998\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24388 s, 998 iter, 9980000 ts, 723 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-37-40\n",
      "  done: false\n",
      "  episode_len_mean: 129.9\n",
      "  episode_reward_max: 792.6257264599923\n",
      "  episode_reward_mean: 715.2005339644842\n",
      "  episode_reward_min: -82.28060897193546\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 74817\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.844\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 9990000\n",
      "    num_steps_trained: 9990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014343934133648872\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8559705018997192\n",
      "      kl: 0.019261298701167107\n",
      "      policy_loss: -0.0013060161145403981\n",
      "      total_loss: 203.167236328125\n",
      "      vf_explained_var: 0.9846185445785522\n",
      "      vf_loss: 203.16827392578125\n",
      "    sample_time_ms: 18355.44\n",
      "    update_time_ms: 5.272\n",
      "  iterations_since_restore: 999\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 357.60026698224203\n",
      "  time_since_restore: 24410.60452771187\n",
      "  time_this_iter_s: 21.868740797042847\n",
      "  time_total_s: 24410.60452771187\n",
      "  timestamp: 1553733460\n",
      "  timesteps_since_restore: 9990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9990000\n",
      "  training_iteration: 999\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=4068], 24410 s, 999 iter, 9990000 ts, 715 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-03-28_01-38-02\n",
      "  done: true\n",
      "  episode_len_mean: 129.56\n",
      "  episode_reward_max: 795.3037335642651\n",
      "  episode_reward_mean: 697.8401131484428\n",
      "  episode_reward_min: -85.66595604176263\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 74895\n",
      "  experiment_id: f959ca97c66b498388a02f90a5450ca0\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3761.24\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 10000000\n",
      "    num_steps_trained: 10000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.014343934133648872\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8233752846717834\n",
      "      kl: 0.01954023540019989\n",
      "      policy_loss: -0.004133702255785465\n",
      "      total_loss: 177.20187377929688\n",
      "      vf_explained_var: 0.9885734915733337\n",
      "      vf_loss: 177.2057342529297\n",
      "    sample_time_ms: 18382.688\n",
      "    update_time_ms: 5.12\n",
      "  iterations_since_restore: 1000\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 4068\n",
      "  policy_reward_mean:\n",
      "    rl_0: 348.92005657422146\n",
      "  time_since_restore: 24433.10409760475\n",
      "  time_this_iter_s: 22.4995698928833\n",
      "  time_total_s: 24433.10409760475\n",
      "  timestamp: 1553733482\n",
      "  timesteps_since_restore: 10000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000000\n",
      "  training_iteration: 1000\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tTERMINATED [pid=4068], 24433 s, 1000 iter, 10000000 ts, 698 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tTERMINATED [pid=4068], 24433 s, 1000 iter, 10000000 ts, 698 rew\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,  # RL algorithm to run\n",
    "        \"env\": gym_name,  # environment name generated earlier\n",
    "        \"config\": {  # configuration params (must match \"run\" value)\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 1,  # number of iterations between checkpoints\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 1000,  # number of iterations to stop after\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flow_2)",
   "language": "python",
   "name": "flow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
