{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING I3W\n",
    "\n",
    "\n",
    "# A) Create Envorinment, Vehicles etc\n",
    "\n",
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scenarios:\n",
      "['Scenario', 'BayBridgeScenario', 'BayBridgeTollScenario', 'BottleneckScenario', 'Figure8Scenario', 'SimpleGridScenario', 'HighwayScenario', 'LoopScenario', 'MergeScenario', 'TwoLoopsOneMergingScenario', 'MultiLoopScenario', 'IntersectionScenarioTW']\n",
      "\n",
      "Available environments:\n",
      "['MultiEnv', 'MultiAgentAccelEnv', 'MultiWaveAttenuationPOEnv', 'MultiAgentIntersectionEnv', 'MultiAgentTeamSpiritIntersectionEnv', 'MultiAgentIntersectionEnv_baseline_1', 'MultiAgentIntersectionEnv_baseline_2', 'MultiAgentIntersectionEnv_baseline_3', 'MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit']\n"
     ]
    }
   ],
   "source": [
    "# Define horizon as a variable to ensure consistent use across notebook (length of one rollout)\n",
    "HORIZON=500                                 #103 max Horizon, wenn es vor verlassen abbrechen soll!, default war 500\n",
    "\n",
    "# name of the experiment\n",
    "experiment_name = \"IntersectionExample\"\n",
    "\n",
    "# scenario class\n",
    "import flow.scenarios as scenarios\n",
    "print(\"Available scenarios:\")\n",
    "print(scenarios.__all__)\n",
    "scenario_name = \"IntersectionTWScenario\"\n",
    "\n",
    "# environment class\n",
    "import flow.multiagent_envs as flowenvs\n",
    "print(\"\\nAvailable environments:\")\n",
    "print(flowenvs.__all__)\n",
    "env_name = \"MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import NetParams\n",
    "from flow.scenarios.intersection import ADDITIONAL_NET_PARAMS\n",
    "\n",
    "additionalNetParams = {\n",
    "            \"edge_length\": 40,\n",
    "            \"lanes\": 1,\n",
    "            \"speed_limit\": 30\n",
    "        }\n",
    "\n",
    "net_params = NetParams( no_internal_links=False,                  #default: True   !! damit Kreuzungen nicht Ã¼berspr. werden\n",
    "                        inflows=None,                             #default: None\n",
    "                        osm_path=None,                            #default: None\n",
    "                        netfile=None,                             #default: None\n",
    "                        additional_params=additionalNetParams     #default: None   !!\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitialConfig Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import InitialConfig\n",
    "\n",
    "initial_config = InitialConfig( shuffle=True,                            #default: False         !!\n",
    "                                spacing=\"custom\",                        #default: \"uniform\"     !!\n",
    "                                min_gap=10,                              #default: 0\n",
    "                                perturbation=29.99,                      #default: 0.0            !!        \n",
    "                                x0=0,                                    #default: 0\n",
    "                                bunching=0,                              #default: 0\n",
    "                                lanes_distribution=float(\"inf\"),         #default: float(\"inf\")\n",
    "                                edges_distribution=\"all\",                #default: \"all\"\n",
    "                                additional_params=None )                 #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMO Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sumo_params = SumoParams( port = None,                  #default: None\n",
    "                          sim_step=0.1,                 #default: 0.1\n",
    "                          emission_path=None,           #default: None\n",
    "                          lateral_resolution=None,      #default: None\n",
    "                          no_step_log=True,             #default: True\n",
    "                          render=False,                 #default: False\n",
    "                          save_render=False,            #default: False\n",
    "                          sight_radius=25,              #default: 25\n",
    "                          show_radius=False,            #default: False\n",
    "                          pxpm=2,                       #default: 2\n",
    "                          overtake_right=False,         #default: False    \n",
    "                          seed=None,                    #default: None\n",
    "                          restart_instance=False,       #default: False\n",
    "                          print_warnings=True,          #default: True\n",
    "                          teleport_time=-1,             #default: -1\n",
    "                          num_clients=1,                #default: 1\n",
    "                          sumo_binary=None )            #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "additionalEnvParams = {\n",
    "        # maximum acceleration of autonomous vehicles\n",
    "        \"max_accel\": 3,\n",
    "        # maximum deceleration of autonomous vehicles\n",
    "        \"max_decel\": 3,\n",
    "        # desired velocity for all vehicles in the network, in m/s\n",
    "        \"target_velocity\": 30,\n",
    "        # initial teamspirit\n",
    "        \"ap_teamspirit_0\": -1,\n",
    "        \"ap_teamspirit_1\": -1,\n",
    "        # shuffle teamspirit?\n",
    "        \"ap_teamspirit_shuffle\": False    \n",
    "    }\n",
    "\n",
    "env_params = EnvParams( additional_params=additionalEnvParams, #default: None    !!\n",
    "                        horizon=HORIZON,                       #default: 500     !!\n",
    "                        warmup_steps=0,                        #default: 0       \n",
    "                        sims_per_step=1,                       #default: 1\n",
    "                        evaluate=False )                       #default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import VehicleParams\n",
    "\n",
    "# import vehicles dynamics models\n",
    "#from flow.controllers import SumoCarFollowingController\n",
    "from flow.controllers import ContinuousRouter\n",
    "#from flow.controllers.lane_change_controllers import SumoLaneChangeController\n",
    "from flow.controllers.lane_change_controllers import StaticLaneChanger\n",
    "from flow.controllers import RLController\n",
    "from flow.core.params import SumoLaneChangeParams\n",
    "from flow.core.params import SumoCarFollowingParams\n",
    "from random import *\n",
    "\n",
    "vehicles = VehicleParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add RL-Agent controlled vehicles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car following parameters, default: None\n",
    "cf_parameter = SumoCarFollowingParams(\n",
    "                speed_mode=\"aggressive\")\n",
    "# lane change parameters, default: None\n",
    "lc_parameter =  None\n",
    "\n",
    "vehicles.add( # name of the vehicle\n",
    "                veh_id = \"rl\",\n",
    "              # acceleration controller, default: (SumoCarFollowingController, {})\n",
    "                acceleration_controller=(RLController, {}),\n",
    "              # lane_change_controller, default: (SumoLaneChangeController, {})\n",
    "                lane_change_controller=(StaticLaneChanger,{}),\n",
    "              # routing controller, default: None\n",
    "                routing_controller=(ContinuousRouter, {}),\n",
    "              # initial speed, default: 0\n",
    "                initial_speed=0,\n",
    "              # number of vehicles, default: 1 \n",
    "                num_vehicles=2,\n",
    "                \n",
    "                car_following_params=cf_parameter\n",
    "              # speed mode, default: \"right_of_way\"\n",
    "                #speed_mode=\"aggressive\",\n",
    "              # lane change mode, default: \"no_lat_collide\"\n",
    "                #lane_change_mode=\"aggressive\", \n",
    "              # car following parameter, default: None\n",
    "                #sumo_car_following_params=cf_parameter,\n",
    "              # lane change parameter, default: None\n",
    "                #sumo_lc_params=lc_parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict( # name of the experiment\n",
    "                      exp_tag=experiment_name,\n",
    "                    # name of the flow environment the experiment is running on\n",
    "                      env_name=env_name,\n",
    "                    # name of the scenario class the experiment uses\n",
    "                      scenario=scenario_name,\n",
    "                    # simulator that is used by the experiment\n",
    "                      simulator='traci',\n",
    "                    # sumo-related parameters (see flow.core.params.SumoParams)\n",
    "                      sim=sumo_params,\n",
    "                    # environment related parameters (see flow.core.params.EnvParams)\n",
    "                      env=env_params,\n",
    "                    # network-related parameters (see flow.core.params.NetParams and\n",
    "                    # the scenario's documentation or ADDITIONAL_NET_PARAMS component)\n",
    "                      net=net_params,\n",
    "                    # vehicles to be placed in the network at the start of a rollout \n",
    "                    # (see flow.core.vehicles.Vehicles)\n",
    "                      veh=vehicles,\n",
    "                   # (optional) parameters affecting the positioning of vehicles upon \n",
    "                   # initialization/reset (see flow.core.params.InitialConfig)\n",
    "                      initial=initial_config\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo.ppo_policy_graph import PPOPolicyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-04-09_13-11-00_30240/logs.\n",
      "Waiting for redis server at 127.0.0.1:24259 to respond...\n",
      "Waiting for redis server at 127.0.0.1:62896 to respond...\n",
      "Starting the Plasma object store with 6.554658406 GB memory using /dev/shm.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=1c71038f05007dc71caeb68d84db6ade856d9270dd1ec1a0\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.16.123.117',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-04-09_13-11-00_30240/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-04-09_13-11-00_30240/sockets/raylet'],\n",
       " 'redis_address': '172.16.123.117:24259',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui.ipynb?token=1c71038f05007dc71caeb68d84db6ade856d9270dd1ec1a0'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "N_CPUS = 2\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 20\n",
    "\n",
    "ray.init(redirect_output=True, num_cpus=N_CPUS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm or model to train. This may refer to \"\n",
    "#      \"the name of a built-on algorithm (e.g. RLLib's DQN \"\n",
    "#      \"or PPO), or a user-defined trainable function or \"\n",
    "#      \"class registered in the tune registry.\")\n",
    "alg_run = \"PPO\"\n",
    "\n",
    "agent_cls = get_agent_class(alg_run)\n",
    "config = agent_cls._default_config.copy()\n",
    "config[\"num_workers\"] = N_CPUS  # number of parallel workers\n",
    "config[\"train_batch_size\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.999  # discount rate default 0.999\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [100, 50, 25]})  # size of hidden layers in network defaule 64 32\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "#config[\"sgd_minibatch_size\"] = min(16 * 1024, config[\"train_batch_size\"])  # stochastic gradient descent\n",
    "#config[\"sample_batch_size\"] = config[\"train_batch_size\"]/config[\"num_workers\"] # 200 default, trotzdem zu hoch?\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "config['env_config']['run'] = alg_run\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, gym_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(gym_name, create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Starting SUMO on port 52973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Teamspirit:\n",
      "0.976419485470094\n",
      "-0.4442784097254695\n"
     ]
    }
   ],
   "source": [
    "# multi agent policy mapping\n",
    "test_env = create_env()\n",
    "obs_space = test_env.observation_space\n",
    "act_space = test_env.action_space\n",
    "\n",
    "def gen_policy():\n",
    "    return (PPOPolicyGraph, obs_space, act_space, {})\n",
    "\n",
    "# Setup PG with an ensemble of `num_policies` different policy graphs\n",
    "policy_graphs = {'rl_0': gen_policy()}\n",
    "    \n",
    "def policy_mapping_fn(agent_id):\n",
    "    return 'rl_0'\n",
    "\n",
    "config.update({\n",
    "        'multiagent': {\n",
    "            'policy_graphs': policy_graphs,\n",
    "            'policy_mapping_fn': tune.function(policy_mapping_fn),\n",
    "            'policies_to_train': ['rl_0']\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "\n",
      "Created LogSyncer for /home/thorsten/ray_results/IntersectionExample/PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0_2019-04-09_13-11-02cdaml41i -> \n",
      "WARNING: Falling back to serializing objects of type <class 'numpy.dtype'> by using pickle. This may be inefficient.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-11-57\n",
      "  done: false\n",
      "  episode_len_mean: 485.95\n",
      "  episode_reward_max: 123.0041521056342\n",
      "  episode_reward_mean: -8.499962313751194\n",
      "  episode_reward_min: -200.90302216972958\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 20\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6407.958\n",
      "    load_time_ms: 54.135\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20000004768371582\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4233288764953613\n",
      "      kl: 0.0008070566109381616\n",
      "      policy_loss: -0.0017539882101118565\n",
      "      total_loss: 51.7591438293457\n",
      "      vf_explained_var: 0.10599080473184586\n",
      "      vf_loss: 51.76073455810547\n",
      "    sample_time_ms: 20352.314\n",
      "    update_time_ms: 586.967\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -4.249981156875593\n",
      "  time_since_restore: 27.47398614883423\n",
      "  time_this_iter_s: 27.47398614883423\n",
      "  time_total_s: 27.47398614883423\n",
      "  timestamp: 1554808317\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 27 s, 1 iter, 10000 ts, -8.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-12-24\n",
      "  done: false\n",
      "  episode_len_mean: 466.23809523809524\n",
      "  episode_reward_max: 123.0041521056342\n",
      "  episode_reward_mean: -32.22888522573097\n",
      "  episode_reward_min: -212.94198867973563\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 42\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5775.597\n",
      "    load_time_ms: 27.781\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10000002384185791\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4183303117752075\n",
      "      kl: 0.0026181384455412626\n",
      "      policy_loss: -0.0022669066675007343\n",
      "      total_loss: 109.3974609375\n",
      "      vf_explained_var: 0.14223776757717133\n",
      "      vf_loss: 109.39945220947266\n",
      "    sample_time_ms: 21332.533\n",
      "    update_time_ms: 297.843\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -16.114442612865485\n",
      "  time_since_restore: 54.95775604248047\n",
      "  time_this_iter_s: 27.48376989364624\n",
      "  time_total_s: 54.95775604248047\n",
      "  timestamp: 1554808344\n",
      "  timesteps_since_restore: 20000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 54 s, 2 iter, 20000 ts, -32.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-12-52\n",
      "  done: false\n",
      "  episode_len_mean: 446.04545454545456\n",
      "  episode_reward_max: 145.03232374845246\n",
      "  episode_reward_mean: -39.6564319836885\n",
      "  episode_reward_min: -212.94198867973563\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 66\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5369.552\n",
      "    load_time_ms: 19.028\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.050000011920928955\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4095711708068848\n",
      "      kl: 0.006126821972429752\n",
      "      policy_loss: -0.003037484595552087\n",
      "      total_loss: 183.893798828125\n",
      "      vf_explained_var: 0.14314278960227966\n",
      "      vf_loss: 183.8965301513672\n",
      "    sample_time_ms: 21701.448\n",
      "    update_time_ms: 200.417\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -19.82821599184425\n",
      "  time_since_restore: 81.97865891456604\n",
      "  time_this_iter_s: 27.02090287208557\n",
      "  time_total_s: 81.97865891456604\n",
      "  timestamp: 1554808372\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 3\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 81 s, 3 iter, 30000 ts, -39.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-13-19\n",
      "  done: false\n",
      "  episode_len_mean: 422.02127659574467\n",
      "  episode_reward_max: 145.03232374845246\n",
      "  episode_reward_mean: -51.57156180840915\n",
      "  episode_reward_min: -212.94198867973563\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 94\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5095.594\n",
      "    load_time_ms: 14.877\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.025000005960464478\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4060282707214355\n",
      "      kl: 0.006029496900737286\n",
      "      policy_loss: -0.0030528700444847345\n",
      "      total_loss: 227.60992431640625\n",
      "      vf_explained_var: 0.31428438425064087\n",
      "      vf_loss: 227.61282348632812\n",
      "    sample_time_ms: 22108.38\n",
      "    update_time_ms: 151.736\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -25.78578090420456\n",
      "  time_since_restore: 109.60885882377625\n",
      "  time_this_iter_s: 27.630199909210205\n",
      "  time_total_s: 109.60885882377625\n",
      "  timestamp: 1554808399\n",
      "  timesteps_since_restore: 40000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 4\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 109 s, 4 iter, 40000 ts, -51.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-13-45\n",
      "  done: false\n",
      "  episode_len_mean: 373.68\n",
      "  episode_reward_max: 145.03232374845246\n",
      "  episode_reward_mean: -50.67686437721194\n",
      "  episode_reward_min: -212.94198867973563\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 126\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4930.521\n",
      "    load_time_ms: 12.172\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 50000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.012500002980232239\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3864383697509766\n",
      "      kl: 0.010883291251957417\n",
      "      policy_loss: -0.0033636880107223988\n",
      "      total_loss: 260.7073974609375\n",
      "      vf_explained_var: 0.2709121108055115\n",
      "      vf_loss: 260.71063232421875\n",
      "    sample_time_ms: 21918.929\n",
      "    update_time_ms: 122.492\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -25.338432188605957\n",
      "  time_since_restore: 135.0646378993988\n",
      "  time_this_iter_s: 25.45577907562256\n",
      "  time_total_s: 135.0646378993988\n",
      "  timestamp: 1554808425\n",
      "  timesteps_since_restore: 50000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 5\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 135 s, 5 iter, 50000 ts, -50.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-14-11\n",
      "  done: false\n",
      "  episode_len_mean: 297.34\n",
      "  episode_reward_max: 157.88026843530776\n",
      "  episode_reward_mean: -50.07914276241572\n",
      "  episode_reward_min: -212.38164665177027\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 167\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4877.544\n",
      "    load_time_ms: 10.471\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.012500002980232239\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.380710482597351\n",
      "      kl: 0.008414514362812042\n",
      "      policy_loss: -0.002822562586516142\n",
      "      total_loss: 448.85748291015625\n",
      "      vf_explained_var: 0.30932188034057617\n",
      "      vf_loss: 448.86016845703125\n",
      "    sample_time_ms: 21878.048\n",
      "    update_time_ms: 102.884\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -25.03957138120786\n",
      "  time_since_restore: 161.37684178352356\n",
      "  time_this_iter_s: 26.312203884124756\n",
      "  time_total_s: 161.37684178352356\n",
      "  timestamp: 1554808451\n",
      "  timesteps_since_restore: 60000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 6\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 161 s, 6 iter, 60000 ts, -50.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-14-36\n",
      "  done: false\n",
      "  episode_len_mean: 227.39\n",
      "  episode_reward_max: 157.88026843530776\n",
      "  episode_reward_mean: -54.41776850779584\n",
      "  episode_reward_min: -212.38164665177027\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 217\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4779.989\n",
      "    load_time_ms: 9.167\n",
      "    num_steps_sampled: 70000\n",
      "    num_steps_trained: 70000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.006250001490116119\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.383337378501892\n",
      "      kl: 0.007434678263962269\n",
      "      policy_loss: -0.0020860556978732347\n",
      "      total_loss: 528.5306396484375\n",
      "      vf_explained_var: 0.3559248149394989\n",
      "      vf_loss: 528.53271484375\n",
      "    sample_time_ms: 21706.737\n",
      "    update_time_ms: 88.936\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -27.20888425389792\n",
      "  time_since_restore: 186.27342343330383\n",
      "  time_this_iter_s: 24.896581649780273\n",
      "  time_total_s: 186.27342343330383\n",
      "  timestamp: 1554808476\n",
      "  timesteps_since_restore: 70000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 70000\n",
      "  training_iteration: 7\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 186 s, 7 iter, 70000 ts, -54.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-15-01\n",
      "  done: false\n",
      "  episode_len_mean: 201.94\n",
      "  episode_reward_max: 132.27795643782466\n",
      "  episode_reward_mean: -48.18022049683726\n",
      "  episode_reward_min: -211.43873573865267\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 267\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4702.266\n",
      "    load_time_ms: 8.235\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0031250007450580597\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3817377090454102\n",
      "      kl: 0.005358195398002863\n",
      "      policy_loss: -0.0018956523854285479\n",
      "      total_loss: 556.4226684570312\n",
      "      vf_explained_var: 0.3770095705986023\n",
      "      vf_loss: 556.424560546875\n",
      "    sample_time_ms: 21543.367\n",
      "    update_time_ms: 78.359\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -24.090110248418622\n",
      "  time_since_restore: 210.85710954666138\n",
      "  time_this_iter_s: 24.583686113357544\n",
      "  time_total_s: 210.85710954666138\n",
      "  timestamp: 1554808501\n",
      "  timesteps_since_restore: 80000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 8\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 210 s, 8 iter, 80000 ts, -48.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-15-25\n",
      "  done: false\n",
      "  episode_len_mean: 186.36\n",
      "  episode_reward_max: 122.58905587066599\n",
      "  episode_reward_mean: -47.306093749149916\n",
      "  episode_reward_min: -210.74163418412127\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 323\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4649.273\n",
      "    load_time_ms: 7.489\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0015625003725290298\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3719691038131714\n",
      "      kl: 0.008195644244551659\n",
      "      policy_loss: -0.0030661923810839653\n",
      "      total_loss: 656.5288696289062\n",
      "      vf_explained_var: 0.3790294826030731\n",
      "      vf_loss: 656.5318603515625\n",
      "    sample_time_ms: 21413.285\n",
      "    update_time_ms: 70.447\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -23.653046874574958\n",
      "  time_since_restore: 235.48394751548767\n",
      "  time_this_iter_s: 24.626837968826294\n",
      "  time_total_s: 235.48394751548767\n",
      "  timestamp: 1554808525\n",
      "  timesteps_since_restore: 90000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 9\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 235 s, 9 iter, 90000 ts, -47.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-15-52\n",
      "  done: false\n",
      "  episode_len_mean: 169.58\n",
      "  episode_reward_max: 106.33157897953784\n",
      "  episode_reward_mean: -55.52900732583796\n",
      "  episode_reward_min: -213.2367595468922\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 383\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4642.131\n",
      "    load_time_ms: 6.917\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0007812501862645149\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3677352666854858\n",
      "      kl: 0.007755328435450792\n",
      "      policy_loss: -0.0019807612989097834\n",
      "      total_loss: 657.2618408203125\n",
      "      vf_explained_var: 0.3767036199569702\n",
      "      vf_loss: 657.2637939453125\n",
      "    sample_time_ms: 21431.64\n",
      "    update_time_ms: 63.958\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -27.76450366291898\n",
      "  time_since_restore: 261.68231105804443\n",
      "  time_this_iter_s: 26.198363542556763\n",
      "  time_total_s: 261.68231105804443\n",
      "  timestamp: 1554808552\n",
      "  timesteps_since_restore: 100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 10\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 261 s, 10 iter, 100000 ts, -55.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-16-21\n",
      "  done: false\n",
      "  episode_len_mean: 161.61\n",
      "  episode_reward_max: 100.78826665440077\n",
      "  episode_reward_mean: -52.440004880118934\n",
      "  episode_reward_min: -208.23114062178718\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 447\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4445.614\n",
      "    load_time_ms: 1.73\n",
      "    num_steps_sampled: 110000\n",
      "    num_steps_trained: 110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00039062509313225746\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3647818565368652\n",
      "      kl: 0.00386752188205719\n",
      "      policy_loss: -0.0005341600044630468\n",
      "      total_loss: 734.5462646484375\n",
      "      vf_explained_var: 0.3651774525642395\n",
      "      vf_loss: 734.5467529296875\n",
      "    sample_time_ms: 21887.172\n",
      "    update_time_ms: 5.91\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -26.220002440059474\n",
      "  time_since_restore: 291.06344175338745\n",
      "  time_this_iter_s: 29.381130695343018\n",
      "  time_total_s: 291.06344175338745\n",
      "  timestamp: 1554808581\n",
      "  timesteps_since_restore: 110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 110000\n",
      "  training_iteration: 11\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 291 s, 11 iter, 110000 ts, -52.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-16-48\n",
      "  done: false\n",
      "  episode_len_mean: 166.75\n",
      "  episode_reward_max: 87.01025356992736\n",
      "  episode_reward_mean: -42.394484607244785\n",
      "  episode_reward_min: -206.2418071304367\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 505\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4402.868\n",
      "    load_time_ms: 1.738\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00019531254656612873\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3685646057128906\n",
      "      kl: 0.005091942846775055\n",
      "      policy_loss: -0.0008750286651775241\n",
      "      total_loss: 712.6026611328125\n",
      "      vf_explained_var: 0.4160993993282318\n",
      "      vf_loss: 712.6035766601562\n",
      "    sample_time_ms: 21925.715\n",
      "    update_time_ms: 5.985\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -21.19724230362239\n",
      "  time_since_restore: 318.5089681148529\n",
      "  time_this_iter_s: 27.445526361465454\n",
      "  time_total_s: 318.5089681148529\n",
      "  timestamp: 1554808608\n",
      "  timesteps_since_restore: 120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 12\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 318 s, 12 iter, 120000 ts, -42.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-17-16\n",
      "  done: false\n",
      "  episode_len_mean: 159.83\n",
      "  episode_reward_max: 80.85883310207157\n",
      "  episode_reward_mean: -59.070067515164936\n",
      "  episode_reward_min: -208.29209884730744\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 570\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4368.006\n",
      "    load_time_ms: 1.741\n",
      "    num_steps_sampled: 130000\n",
      "    num_steps_trained: 130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.765627328306437e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3616195917129517\n",
      "      kl: 0.00641414150595665\n",
      "      policy_loss: -0.0026010721921920776\n",
      "      total_loss: 814.6236572265625\n",
      "      vf_explained_var: 0.4199068248271942\n",
      "      vf_loss: 814.626220703125\n",
      "    sample_time_ms: 21985.674\n",
      "    update_time_ms: 6.266\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -29.535033757582465\n",
      "  time_since_restore: 345.78589272499084\n",
      "  time_this_iter_s: 27.27692461013794\n",
      "  time_total_s: 345.78589272499084\n",
      "  timestamp: 1554808636\n",
      "  timesteps_since_restore: 130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 130000\n",
      "  training_iteration: 13\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 345 s, 13 iter, 130000 ts, -59.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-17-41\n",
      "  done: false\n",
      "  episode_len_mean: 150.74\n",
      "  episode_reward_max: 92.20003891637805\n",
      "  episode_reward_mean: -69.63181494168148\n",
      "  episode_reward_min: -211.42155494767243\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 637\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4357.564\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.882813664153218e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.347786545753479\n",
      "      kl: 0.006554834544658661\n",
      "      policy_loss: -0.0014410542789846659\n",
      "      total_loss: 826.16845703125\n",
      "      vf_explained_var: 0.4496823251247406\n",
      "      vf_loss: 826.169921875\n",
      "    sample_time_ms: 21756.869\n",
      "    update_time_ms: 6.19\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.81590747084075\n",
      "  time_since_restore: 371.0233371257782\n",
      "  time_this_iter_s: 25.237444400787354\n",
      "  time_total_s: 371.0233371257782\n",
      "  timestamp: 1554808661\n",
      "  timesteps_since_restore: 140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 14\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 371 s, 14 iter, 140000 ts, -69.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-18-06\n",
      "  done: false\n",
      "  episode_len_mean: 135.25\n",
      "  episode_reward_max: 80.32868234441437\n",
      "  episode_reward_mean: -84.21884477650369\n",
      "  episode_reward_min: -207.48194571321483\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 712\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4351.227\n",
      "    load_time_ms: 1.747\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406832076609e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3555657863616943\n",
      "      kl: 0.00427269795909524\n",
      "      policy_loss: -0.0014626368647441268\n",
      "      total_loss: 877.4373168945312\n",
      "      vf_explained_var: 0.5110371708869934\n",
      "      vf_loss: 877.4389038085938\n",
      "    sample_time_ms: 21702.716\n",
      "    update_time_ms: 6.254\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.10942238825184\n",
      "  time_since_restore: 395.8757493495941\n",
      "  time_this_iter_s: 24.852412223815918\n",
      "  time_total_s: 395.8757493495941\n",
      "  timestamp: 1554808686\n",
      "  timesteps_since_restore: 150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 15\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 395 s, 15 iter, 150000 ts, -84.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-18-31\n",
      "  done: false\n",
      "  episode_len_mean: 134.67\n",
      "  episode_reward_max: 70.82583127941187\n",
      "  episode_reward_mean: -74.77613441819334\n",
      "  episode_reward_min: -210.37661887154917\n",
      "  episodes_this_iter: 74\n",
      "  episodes_total: 786\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4304.536\n",
      "    load_time_ms: 1.74\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2207034160383046e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3485230207443237\n",
      "      kl: 0.00677295820787549\n",
      "      policy_loss: -0.001733770128339529\n",
      "      total_loss: 889.4120483398438\n",
      "      vf_explained_var: 0.4686715602874756\n",
      "      vf_loss: 889.4137573242188\n",
      "    sample_time_ms: 21619.432\n",
      "    update_time_ms: 6.301\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.38806720909666\n",
      "  time_since_restore: 420.88715410232544\n",
      "  time_this_iter_s: 25.011404752731323\n",
      "  time_total_s: 420.88715410232544\n",
      "  timestamp: 1554808711\n",
      "  timesteps_since_restore: 160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 16\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 420 s, 16 iter, 160000 ts, -74.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-18-56\n",
      "  done: false\n",
      "  episode_len_mean: 131.66\n",
      "  episode_reward_max: 70.42767800017589\n",
      "  episode_reward_mean: -75.5627476129271\n",
      "  episode_reward_min: -205.24244449241382\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 862\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4299.872\n",
      "    load_time_ms: 1.774\n",
      "    num_steps_sampled: 170000\n",
      "    num_steps_trained: 170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.103517080191523e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3468657732009888\n",
      "      kl: 0.004225405398756266\n",
      "      policy_loss: -0.0024400283582508564\n",
      "      total_loss: 876.1751098632812\n",
      "      vf_explained_var: 0.47006484866142273\n",
      "      vf_loss: 876.1776733398438\n",
      "    sample_time_ms: 21591.03\n",
      "    update_time_ms: 6.31\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.78137380646354\n",
      "  time_since_restore: 445.4550528526306\n",
      "  time_this_iter_s: 24.567898750305176\n",
      "  time_total_s: 445.4550528526306\n",
      "  timestamp: 1554808736\n",
      "  timesteps_since_restore: 170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 170000\n",
      "  training_iteration: 17\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 445 s, 17 iter, 170000 ts, -75.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-19-21\n",
      "  done: false\n",
      "  episode_len_mean: 128.27\n",
      "  episode_reward_max: 74.68561202316242\n",
      "  episode_reward_mean: -77.55967695286567\n",
      "  episode_reward_min: -207.48201026013686\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 939\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4305.085\n",
      "    load_time_ms: 1.759\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0517585400957614e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3433126211166382\n",
      "      kl: 0.004785922355949879\n",
      "      policy_loss: -0.0012616569874808192\n",
      "      total_loss: 946.9166870117188\n",
      "      vf_explained_var: 0.47409674525260925\n",
      "      vf_loss: 946.9180908203125\n",
      "    sample_time_ms: 21657.785\n",
      "    update_time_ms: 6.49\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.779838476432836\n",
      "  time_since_restore: 470.76004672050476\n",
      "  time_this_iter_s: 25.304993867874146\n",
      "  time_total_s: 470.76004672050476\n",
      "  timestamp: 1554808761\n",
      "  timesteps_since_restore: 180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 18\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 470 s, 18 iter, 180000 ts, -77.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-19-52\n",
      "  done: false\n",
      "  episode_len_mean: 125.51\n",
      "  episode_reward_max: 60.51282815681031\n",
      "  episode_reward_mean: -78.06204958638274\n",
      "  episode_reward_min: -206.63077320738176\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 1019\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4467.029\n",
      "    load_time_ms: 1.827\n",
      "    num_steps_sampled: 190000\n",
      "    num_steps_trained: 190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5258792700478807e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3435450792312622\n",
      "      kl: 0.006778412032872438\n",
      "      policy_loss: -0.0025315135717391968\n",
      "      total_loss: 968.9403076171875\n",
      "      vf_explained_var: 0.5691983103752136\n",
      "      vf_loss: 968.9429321289062\n",
      "    sample_time_ms: 22108.598\n",
      "    update_time_ms: 6.276\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.03102479319137\n",
      "  time_since_restore: 501.5142822265625\n",
      "  time_this_iter_s: 30.75423550605774\n",
      "  time_total_s: 501.5142822265625\n",
      "  timestamp: 1554808792\n",
      "  timesteps_since_restore: 190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 190000\n",
      "  training_iteration: 19\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 501 s, 19 iter, 190000 ts, -78.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-20-23\n",
      "  done: false\n",
      "  episode_len_mean: 127.96\n",
      "  episode_reward_max: 59.49925130721364\n",
      "  episode_reward_mean: -65.31493611345824\n",
      "  episode_reward_min: -203.66386075799875\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 1097\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4689.144\n",
      "    load_time_ms: 1.856\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.629396350239404e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3339611291885376\n",
      "      kl: 0.006954931188374758\n",
      "      policy_loss: -0.0026593278162181377\n",
      "      total_loss: 994.2201538085938\n",
      "      vf_explained_var: 0.53030925989151\n",
      "      vf_loss: 994.2227783203125\n",
      "    sample_time_ms: 22370.605\n",
      "    update_time_ms: 6.481\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -32.65746805672912\n",
      "  time_since_restore: 532.5604288578033\n",
      "  time_this_iter_s: 31.046146631240845\n",
      "  time_total_s: 532.5604288578033\n",
      "  timestamp: 1554808823\n",
      "  timesteps_since_restore: 200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 20\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 532 s, 20 iter, 200000 ts, -65.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-20-57\n",
      "  done: false\n",
      "  episode_len_mean: 123.27\n",
      "  episode_reward_max: 45.511679134814166\n",
      "  episode_reward_mean: -67.57139626000044\n",
      "  episode_reward_min: -204.554295878169\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 1178\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4683.735\n",
      "    load_time_ms: 1.783\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.814698175119702e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3358968496322632\n",
      "      kl: 0.007030341774225235\n",
      "      policy_loss: -0.002907942747697234\n",
      "      total_loss: 963.73779296875\n",
      "      vf_explained_var: 0.4280337393283844\n",
      "      vf_loss: 963.7406005859375\n",
      "    sample_time_ms: 22817.569\n",
      "    update_time_ms: 6.759\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.78569813000023\n",
      "  time_since_restore: 566.3550233840942\n",
      "  time_this_iter_s: 33.794594526290894\n",
      "  time_total_s: 566.3550233840942\n",
      "  timestamp: 1554808857\n",
      "  timesteps_since_restore: 210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 21\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 566 s, 21 iter, 210000 ts, -67.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-21-21\n",
      "  done: false\n",
      "  episode_len_mean: 117.63\n",
      "  episode_reward_max: 62.73081598320505\n",
      "  episode_reward_mean: -71.7889069665056\n",
      "  episode_reward_min: -206.84527056337703\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 1259\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4631.72\n",
      "    load_time_ms: 1.819\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.907349087559851e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.329553484916687\n",
      "      kl: 0.0080961799249053\n",
      "      policy_loss: -0.0028062909841537476\n",
      "      total_loss: 991.7139282226562\n",
      "      vf_explained_var: 0.45929795503616333\n",
      "      vf_loss: 991.7167358398438\n",
      "    sample_time_ms: 22530.555\n",
      "    update_time_ms: 6.415\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.89445348325279\n",
      "  time_since_restore: 590.4074075222015\n",
      "  time_this_iter_s: 24.0523841381073\n",
      "  time_total_s: 590.4074075222015\n",
      "  timestamp: 1554808881\n",
      "  timesteps_since_restore: 220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 22\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 590 s, 22 iter, 220000 ts, -71.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-21-48\n",
      "  done: false\n",
      "  episode_len_mean: 117.31\n",
      "  episode_reward_max: 57.47674114286373\n",
      "  episode_reward_mean: -65.95592695123185\n",
      "  episode_reward_min: -204.47302819650196\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 1345\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4767.5\n",
      "    load_time_ms: 1.804\n",
      "    num_steps_sampled: 230000\n",
      "    num_steps_trained: 230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.536745437799254e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3195055723190308\n",
      "      kl: 0.008901417255401611\n",
      "      policy_loss: -0.0035670858342200518\n",
      "      total_loss: 1066.1038818359375\n",
      "      vf_explained_var: 0.4819578528404236\n",
      "      vf_loss: 1066.107421875\n",
      "    sample_time_ms: 22337.447\n",
      "    update_time_ms: 6.141\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -32.97796347561592\n",
      "  time_since_restore: 617.1147272586823\n",
      "  time_this_iter_s: 26.707319736480713\n",
      "  time_total_s: 617.1147272586823\n",
      "  timestamp: 1554808908\n",
      "  timesteps_since_restore: 230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 230000\n",
      "  training_iteration: 23\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 617 s, 23 iter, 230000 ts, -66 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-22-12\n",
      "  done: false\n",
      "  episode_len_mean: 104.61\n",
      "  episode_reward_max: 48.58869970544772\n",
      "  episode_reward_mean: -90.47337937454\n",
      "  episode_reward_min: -203.37411957080235\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 1439\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4769.643\n",
      "    load_time_ms: 1.811\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.768372718899627e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.304598331451416\n",
      "      kl: 0.006355709861963987\n",
      "      policy_loss: -0.002509327372536063\n",
      "      total_loss: 1119.1629638671875\n",
      "      vf_explained_var: 0.41703614592552185\n",
      "      vf_loss: 1119.1654052734375\n",
      "    sample_time_ms: 22270.746\n",
      "    update_time_ms: 6.228\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.23668968727001\n",
      "  time_since_restore: 641.7065110206604\n",
      "  time_this_iter_s: 24.59178376197815\n",
      "  time_total_s: 641.7065110206604\n",
      "  timestamp: 1554808932\n",
      "  timesteps_since_restore: 240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 24\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 641 s, 24 iter, 240000 ts, -90.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-22-37\n",
      "  done: false\n",
      "  episode_len_mean: 105.74\n",
      "  episode_reward_max: 43.390052238224875\n",
      "  episode_reward_mean: -83.2998219631665\n",
      "  episode_reward_min: -203.41583488221875\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 1532\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4769.322\n",
      "    load_time_ms: 1.786\n",
      "    num_steps_sampled: 250000\n",
      "    num_steps_trained: 250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3841863594498136e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2974714040756226\n",
      "      kl: 0.006321268621832132\n",
      "      policy_loss: -0.002198399743065238\n",
      "      total_loss: 1081.716064453125\n",
      "      vf_explained_var: 0.4642568826675415\n",
      "      vf_loss: 1081.7181396484375\n",
      "    sample_time_ms: 22311.849\n",
      "    update_time_ms: 6.317\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.649910981583254\n",
      "  time_since_restore: 666.9685273170471\n",
      "  time_this_iter_s: 25.26201629638672\n",
      "  time_total_s: 666.9685273170471\n",
      "  timestamp: 1554808957\n",
      "  timesteps_since_restore: 250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 250000\n",
      "  training_iteration: 25\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 666 s, 25 iter, 250000 ts, -83.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-23-09\n",
      "  done: false\n",
      "  episode_len_mean: 110.58\n",
      "  episode_reward_max: 51.004695417862266\n",
      "  episode_reward_mean: -71.82947398628986\n",
      "  episode_reward_min: -204.3580894248651\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 1624\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4937.286\n",
      "    load_time_ms: 1.763\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1920931797249068e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2975622415542603\n",
      "      kl: 0.006903012748807669\n",
      "      policy_loss: -0.0027583427727222443\n",
      "      total_loss: 1142.688720703125\n",
      "      vf_explained_var: 0.4039919972419739\n",
      "      vf_loss: 1142.6915283203125\n",
      "    sample_time_ms: 22757.039\n",
      "    update_time_ms: 6.332\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.91473699314493\n",
      "  time_since_restore: 698.114185333252\n",
      "  time_this_iter_s: 31.145658016204834\n",
      "  time_total_s: 698.114185333252\n",
      "  timestamp: 1554808989\n",
      "  timesteps_since_restore: 260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 26\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 698 s, 26 iter, 260000 ts, -71.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-23-40\n",
      "  done: false\n",
      "  episode_len_mean: 109.3\n",
      "  episode_reward_max: 55.608738389056924\n",
      "  episode_reward_mean: -69.860339611886\n",
      "  episode_reward_min: -205.8295560922513\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 1716\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5014.029\n",
      "    load_time_ms: 1.745\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.960465898624534e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2907048463821411\n",
      "      kl: 0.004938818514347076\n",
      "      policy_loss: -0.0005261412588879466\n",
      "      total_loss: 1136.8912353515625\n",
      "      vf_explained_var: 0.4498477280139923\n",
      "      vf_loss: 1136.8917236328125\n",
      "    sample_time_ms: 23328.593\n",
      "    update_time_ms: 6.466\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.930169805943\n",
      "  time_since_restore: 729.1667757034302\n",
      "  time_this_iter_s: 31.052590370178223\n",
      "  time_total_s: 729.1667757034302\n",
      "  timestamp: 1554809020\n",
      "  timesteps_since_restore: 270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 27\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 729 s, 27 iter, 270000 ts, -69.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-24-05\n",
      "  done: false\n",
      "  episode_len_mean: 110.98\n",
      "  episode_reward_max: 52.018286963408\n",
      "  episode_reward_mean: -63.471653389786134\n",
      "  episode_reward_min: -203.09993689942326\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 1806\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5012.303\n",
      "    load_time_ms: 1.784\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.980232949312267e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2882546186447144\n",
      "      kl: 0.00465485779568553\n",
      "      policy_loss: -0.0006573972059413791\n",
      "      total_loss: 1144.738037109375\n",
      "      vf_explained_var: 0.4369441270828247\n",
      "      vf_loss: 1144.738525390625\n",
      "    sample_time_ms: 23342.331\n",
      "    update_time_ms: 6.461\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -31.735826694893056\n",
      "  time_since_restore: 754.593514919281\n",
      "  time_this_iter_s: 25.42673921585083\n",
      "  time_total_s: 754.593514919281\n",
      "  timestamp: 1554809045\n",
      "  timesteps_since_restore: 280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 28\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 754 s, 28 iter, 280000 ts, -63.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-24-31\n",
      "  done: false\n",
      "  episode_len_mean: 111.24\n",
      "  episode_reward_max: 65.17390019190145\n",
      "  episode_reward_mean: -53.31208762725389\n",
      "  episode_reward_min: -204.59304849108452\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 1897\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4848.059\n",
      "    load_time_ms: 1.722\n",
      "    num_steps_sampled: 290000\n",
      "    num_steps_trained: 290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4901164746561335e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.29396653175354\n",
      "      kl: 0.0030895136296749115\n",
      "      policy_loss: -0.0010674095246940851\n",
      "      total_loss: 1124.1844482421875\n",
      "      vf_explained_var: 0.4008503258228302\n",
      "      vf_loss: 1124.185546875\n",
      "    sample_time_ms: 22973.154\n",
      "    update_time_ms: 6.485\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -26.656043813626948\n",
      "  time_since_restore: 780.0107982158661\n",
      "  time_this_iter_s: 25.417283296585083\n",
      "  time_total_s: 780.0107982158661\n",
      "  timestamp: 1554809071\n",
      "  timesteps_since_restore: 290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 290000\n",
      "  training_iteration: 29\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 780 s, 29 iter, 290000 ts, -53.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-24-56\n",
      "  done: false\n",
      "  episode_len_mean: 98.41584158415841\n",
      "  episode_reward_max: 45.73141404955655\n",
      "  episode_reward_mean: -84.89934989667434\n",
      "  episode_reward_min: -203.5124840425217\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 1998\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4601.483\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.450582373280668e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.289655089378357\n",
      "      kl: 0.004909326788038015\n",
      "      policy_loss: -0.0015784796560183167\n",
      "      total_loss: 1101.2779541015625\n",
      "      vf_explained_var: 0.4773902893066406\n",
      "      vf_loss: 1101.2796630859375\n",
      "    sample_time_ms: 22613.476\n",
      "    update_time_ms: 6.299\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.449674948337176\n",
      "  time_since_restore: 804.990213394165\n",
      "  time_this_iter_s: 24.97941517829895\n",
      "  time_total_s: 804.990213394165\n",
      "  timestamp: 1554809096\n",
      "  timesteps_since_restore: 300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 30\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 804 s, 30 iter, 300000 ts, -84.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-25-25\n",
      "  done: false\n",
      "  episode_len_mean: 106.91\n",
      "  episode_reward_max: 57.64779866614255\n",
      "  episode_reward_mean: -70.18505259960922\n",
      "  episode_reward_min: -202.99739084102183\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 2089\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4618.167\n",
      "    load_time_ms: 1.678\n",
      "    num_steps_sampled: 310000\n",
      "    num_steps_trained: 310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.725291186640334e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2649966478347778\n",
      "      kl: 0.0045312843285501\n",
      "      policy_loss: -0.0015549001982435584\n",
      "      total_loss: 1195.597412109375\n",
      "      vf_explained_var: 0.45412102341651917\n",
      "      vf_loss: 1195.598876953125\n",
      "    sample_time_ms: 22152.198\n",
      "    update_time_ms: 6.065\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.09252629980461\n",
      "  time_since_restore: 834.3397467136383\n",
      "  time_this_iter_s: 29.349533319473267\n",
      "  time_total_s: 834.3397467136383\n",
      "  timestamp: 1554809125\n",
      "  timesteps_since_restore: 310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 310000\n",
      "  training_iteration: 31\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 834 s, 31 iter, 310000 ts, -70.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-25-51\n",
      "  done: false\n",
      "  episode_len_mean: 111.9\n",
      "  episode_reward_max: 43.63411609370023\n",
      "  episode_reward_mean: -56.06343748036691\n",
      "  episode_reward_min: -202.10423560275\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 2181\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4622.075\n",
      "    load_time_ms: 1.751\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.862645593320167e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2507855892181396\n",
      "      kl: 0.006957800127565861\n",
      "      policy_loss: -0.003338832873851061\n",
      "      total_loss: 1208.757568359375\n",
      "      vf_explained_var: 0.44480469822883606\n",
      "      vf_loss: 1208.7608642578125\n",
      "    sample_time_ms: 22372.176\n",
      "    update_time_ms: 6.016\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -28.031718740183454\n",
      "  time_since_restore: 860.6327633857727\n",
      "  time_this_iter_s: 26.2930166721344\n",
      "  time_total_s: 860.6327633857727\n",
      "  timestamp: 1554809151\n",
      "  timesteps_since_restore: 320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 32\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 860 s, 32 iter, 320000 ts, -56.1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-26-16\n",
      "  done: false\n",
      "  episode_len_mean: 103.78\n",
      "  episode_reward_max: 60.768172368314126\n",
      "  episode_reward_mean: -67.23992727357248\n",
      "  episode_reward_min: -202.27829937848736\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 2277\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4503.441\n",
      "    load_time_ms: 1.766\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.313227966600834e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2451201677322388\n",
      "      kl: 0.0038572573103010654\n",
      "      policy_loss: -0.0020013332832604647\n",
      "      total_loss: 1148.1849365234375\n",
      "      vf_explained_var: 0.523297905921936\n",
      "      vf_loss: 1148.18701171875\n",
      "    sample_time_ms: 22277.217\n",
      "    update_time_ms: 5.962\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.61996363678625\n",
      "  time_since_restore: 885.1959662437439\n",
      "  time_this_iter_s: 24.56320285797119\n",
      "  time_total_s: 885.1959662437439\n",
      "  timestamp: 1554809176\n",
      "  timesteps_since_restore: 330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 33\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 885 s, 33 iter, 330000 ts, -67.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 108.97\n",
      "  episode_reward_max: 67.9229266400995\n",
      "  episode_reward_mean: -51.76841310213804\n",
      "  episode_reward_min: -203.0265757714992\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 2369\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4508.401\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.656613983300417e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2400134801864624\n",
      "      kl: 0.005268986336886883\n",
      "      policy_loss: -0.0010529498104006052\n",
      "      total_loss: 1132.91064453125\n",
      "      vf_explained_var: 0.5628798007965088\n",
      "      vf_loss: 1132.91162109375\n",
      "    sample_time_ms: 22613.406\n",
      "    update_time_ms: 6.151\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -25.88420655106901\n",
      "  time_since_restore: 913.2011964321136\n",
      "  time_this_iter_s: 28.00523018836975\n",
      "  time_total_s: 913.2011964321136\n",
      "  timestamp: 1554809204\n",
      "  timesteps_since_restore: 340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 34\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 913 s, 34 iter, 340000 ts, -51.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-27-09\n",
      "  done: false\n",
      "  episode_len_mean: 107.26\n",
      "  episode_reward_max: 68.23759737071515\n",
      "  episode_reward_mean: -50.65353719139456\n",
      "  episode_reward_min: -201.0435431099029\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 2463\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4505.127\n",
      "    load_time_ms: 1.738\n",
      "    num_steps_sampled: 350000\n",
      "    num_steps_trained: 350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3283069916502086e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2376315593719482\n",
      "      kl: 0.004306452348828316\n",
      "      policy_loss: -0.00179478176869452\n",
      "      total_loss: 1197.87353515625\n",
      "      vf_explained_var: 0.5675925016403198\n",
      "      vf_loss: 1197.8753662109375\n",
      "    sample_time_ms: 22575.804\n",
      "    update_time_ms: 6.24\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -25.326768595697285\n",
      "  time_since_restore: 938.0551209449768\n",
      "  time_this_iter_s: 24.85392451286316\n",
      "  time_total_s: 938.0551209449768\n",
      "  timestamp: 1554809229\n",
      "  timesteps_since_restore: 350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 350000\n",
      "  training_iteration: 35\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 938 s, 35 iter, 350000 ts, -50.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-27-35\n",
      "  done: false\n",
      "  episode_len_mean: 102.49\n",
      "  episode_reward_max: 60.223126775184056\n",
      "  episode_reward_mean: -63.40286349029906\n",
      "  episode_reward_min: -203.29756608068988\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 2562\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4473.656\n",
      "    load_time_ms: 1.771\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1641534958251043e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2253849506378174\n",
      "      kl: 0.004911523777991533\n",
      "      policy_loss: -0.0013248316245153546\n",
      "      total_loss: 1228.49365234375\n",
      "      vf_explained_var: 0.5490255951881409\n",
      "      vf_loss: 1228.4949951171875\n",
      "    sample_time_ms: 22101.035\n",
      "    update_time_ms: 6.317\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -31.701431745149534\n",
      "  time_since_restore: 964.139830827713\n",
      "  time_this_iter_s: 26.084709882736206\n",
      "  time_total_s: 964.139830827713\n",
      "  timestamp: 1554809255\n",
      "  timesteps_since_restore: 360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 36\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 964 s, 36 iter, 360000 ts, -63.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 96.66019417475728\n",
      "  episode_reward_max: 66.95338404408187\n",
      "  episode_reward_mean: -68.28731944602062\n",
      "  episode_reward_min: -202.3324528189178\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 2665\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4662.466\n",
      "    load_time_ms: 1.767\n",
      "    num_steps_sampled: 370000\n",
      "    num_steps_trained: 370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.8207674791255215e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2205922603607178\n",
      "      kl: 0.006010645534843206\n",
      "      policy_loss: -0.0022299564443528652\n",
      "      total_loss: 1118.504638671875\n",
      "      vf_explained_var: 0.585049033164978\n",
      "      vf_loss: 1118.5068359375\n",
      "    sample_time_ms: 22378.453\n",
      "    update_time_ms: 6.249\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.14365972301031\n",
      "  time_since_restore: 999.8537287712097\n",
      "  time_this_iter_s: 35.713897943496704\n",
      "  time_total_s: 999.8537287712097\n",
      "  timestamp: 1554809291\n",
      "  timesteps_since_restore: 370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 370000\n",
      "  training_iteration: 37\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 999 s, 37 iter, 370000 ts, -68.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-28-39\n",
      "  done: false\n",
      "  episode_len_mean: 102.52\n",
      "  episode_reward_max: 78.71508191967652\n",
      "  episode_reward_mean: -57.793969353536106\n",
      "  episode_reward_min: -203.0652460025433\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 2762\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4684.964\n",
      "    load_time_ms: 1.736\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9103837395627608e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1977487802505493\n",
      "      kl: 0.0037991260178387165\n",
      "      policy_loss: -0.000947968102991581\n",
      "      total_loss: 1169.00537109375\n",
      "      vf_explained_var: 0.5368849039077759\n",
      "      vf_loss: 1169.0062255859375\n",
      "    sample_time_ms: 22613.48\n",
      "    update_time_ms: 6.187\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -28.896984676768056\n",
      "  time_since_restore: 1027.8535509109497\n",
      "  time_this_iter_s: 27.99982213973999\n",
      "  time_total_s: 1027.8535509109497\n",
      "  timestamp: 1554809319\n",
      "  timesteps_since_restore: 380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 38\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1027 s, 38 iter, 380000 ts, -57.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-29-04\n",
      "  done: false\n",
      "  episode_len_mean: 106.39\n",
      "  episode_reward_max: 73.30477179951754\n",
      "  episode_reward_mean: -53.15155035871268\n",
      "  episode_reward_min: -203.53502362976653\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 2856\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4732.046\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4551918697813804e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.196708083152771\n",
      "      kl: 0.004398655146360397\n",
      "      policy_loss: -0.0019461807096377015\n",
      "      total_loss: 1200.6314697265625\n",
      "      vf_explained_var: 0.48067453503608704\n",
      "      vf_loss: 1200.63330078125\n",
      "    sample_time_ms: 22559.692\n",
      "    update_time_ms: 6.192\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -26.575775179356334\n",
      "  time_since_restore: 1053.203274011612\n",
      "  time_this_iter_s: 25.34972310066223\n",
      "  time_total_s: 1053.203274011612\n",
      "  timestamp: 1554809344\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 39\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1053 s, 39 iter, 390000 ts, -53.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-29-30\n",
      "  done: false\n",
      "  episode_len_mean: 102.05\n",
      "  episode_reward_max: 63.8630667381359\n",
      "  episode_reward_mean: -63.460557549864355\n",
      "  episode_reward_min: -203.36107699531362\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 2954\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4725.701\n",
      "    load_time_ms: 1.739\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.275959348906902e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.178621768951416\n",
      "      kl: 0.005117684602737427\n",
      "      policy_loss: -0.001443394343368709\n",
      "      total_loss: 1239.70458984375\n",
      "      vf_explained_var: 0.4979853928089142\n",
      "      vf_loss: 1239.7061767578125\n",
      "    sample_time_ms: 22672.679\n",
      "    update_time_ms: 6.191\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -31.730278774932184\n",
      "  time_since_restore: 1079.2528948783875\n",
      "  time_this_iter_s: 26.049620866775513\n",
      "  time_total_s: 1079.2528948783875\n",
      "  timestamp: 1554809370\n",
      "  timesteps_since_restore: 400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 40\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1079 s, 40 iter, 400000 ts, -63.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-29-56\n",
      "  done: false\n",
      "  episode_len_mean: 106.27\n",
      "  episode_reward_max: 69.14657059603846\n",
      "  episode_reward_mean: -44.018249193452355\n",
      "  episode_reward_min: -203.42689467708527\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 3047\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4692.758\n",
      "    load_time_ms: 1.749\n",
      "    num_steps_sampled: 410000\n",
      "    num_steps_trained: 410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.637979674453451e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.163641095161438\n",
      "      kl: 0.004667460918426514\n",
      "      policy_loss: -0.001217645243741572\n",
      "      total_loss: 1229.4774169921875\n",
      "      vf_explained_var: 0.44677019119262695\n",
      "      vf_loss: 1229.478515625\n",
      "    sample_time_ms: 22322.048\n",
      "    update_time_ms: 6.373\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -22.00912459672619\n",
      "  time_since_restore: 1104.7661247253418\n",
      "  time_this_iter_s: 25.513229846954346\n",
      "  time_total_s: 1104.7661247253418\n",
      "  timestamp: 1554809396\n",
      "  timesteps_since_restore: 410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 410000\n",
      "  training_iteration: 41\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1104 s, 41 iter, 410000 ts, -44 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-30-22\n",
      "  done: false\n",
      "  episode_len_mean: 105.67\n",
      "  episode_reward_max: 71.63814830501313\n",
      "  episode_reward_mean: -44.066445781584534\n",
      "  episode_reward_min: -203.98625510875183\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 3142\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4693.391\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8189898372267255e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1564209461212158\n",
      "      kl: 0.0052231838926672935\n",
      "      policy_loss: -0.0011887536384165287\n",
      "      total_loss: 1255.217529296875\n",
      "      vf_explained_var: 0.41320112347602844\n",
      "      vf_loss: 1255.21875\n",
      "    sample_time_ms: 22291.297\n",
      "    update_time_ms: 6.403\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -22.033222890792263\n",
      "  time_since_restore: 1130.7525763511658\n",
      "  time_this_iter_s: 25.986451625823975\n",
      "  time_total_s: 1130.7525763511658\n",
      "  timestamp: 1554809422\n",
      "  timesteps_since_restore: 420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 42\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1130 s, 42 iter, 420000 ts, -44.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-30-47\n",
      "  done: false\n",
      "  episode_len_mean: 110.51\n",
      "  episode_reward_max: 74.11721362137237\n",
      "  episode_reward_mean: -30.39734910079314\n",
      "  episode_reward_min: -204.6558612998017\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 3233\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4687.325\n",
      "    load_time_ms: 1.652\n",
      "    num_steps_sampled: 430000\n",
      "    num_steps_trained: 430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.094949186133627e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.159204125404358\n",
      "      kl: 0.004188602324575186\n",
      "      policy_loss: -0.0015504962066188455\n",
      "      total_loss: 1162.385986328125\n",
      "      vf_explained_var: 0.40149250626564026\n",
      "      vf_loss: 1162.3875732421875\n",
      "    sample_time_ms: 22310.904\n",
      "    update_time_ms: 6.486\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -15.198674550396575\n",
      "  time_since_restore: 1155.4559273719788\n",
      "  time_this_iter_s: 24.70335102081299\n",
      "  time_total_s: 1155.4559273719788\n",
      "  timestamp: 1554809447\n",
      "  timesteps_since_restore: 430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 430000\n",
      "  training_iteration: 43\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1155 s, 43 iter, 430000 ts, -30.4 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 107.98\n",
      "  episode_reward_max: 78.88430261738985\n",
      "  episode_reward_mean: -40.688788269471154\n",
      "  episode_reward_min: -205.90763808229485\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 3326\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4696.059\n",
      "    load_time_ms: 1.772\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.5474745930668137e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1462059020996094\n",
      "      kl: 0.004547902848571539\n",
      "      policy_loss: -0.0016135374316945672\n",
      "      total_loss: 1210.069091796875\n",
      "      vf_explained_var: 0.4250567555427551\n",
      "      vf_loss: 1210.0706787109375\n",
      "    sample_time_ms: 22085.148\n",
      "    update_time_ms: 6.299\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -20.34439413473557\n",
      "  time_since_restore: 1181.29208445549\n",
      "  time_this_iter_s: 25.836157083511353\n",
      "  time_total_s: 1181.29208445549\n",
      "  timestamp: 1554809473\n",
      "  timesteps_since_restore: 440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 44\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1181 s, 44 iter, 440000 ts, -40.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-31-38\n",
      "  done: false\n",
      "  episode_len_mean: 100.65\n",
      "  episode_reward_max: 69.71867971347858\n",
      "  episode_reward_mean: -58.05889508311407\n",
      "  episode_reward_min: -203.89129731715929\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 3425\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4728.104\n",
      "    load_time_ms: 1.718\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2737372965334068e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1356183290481567\n",
      "      kl: 0.0052560195326805115\n",
      "      policy_loss: -0.002097527962177992\n",
      "      total_loss: 1179.47900390625\n",
      "      vf_explained_var: 0.4725320339202881\n",
      "      vf_loss: 1179.481201171875\n",
      "    sample_time_ms: 22127.306\n",
      "    update_time_ms: 5.964\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -29.029447541557033\n",
      "  time_since_restore: 1206.8843212127686\n",
      "  time_this_iter_s: 25.592236757278442\n",
      "  time_total_s: 1206.8843212127686\n",
      "  timestamp: 1554809498\n",
      "  timesteps_since_restore: 450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 45\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1206 s, 45 iter, 450000 ts, -58.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-32-10\n",
      "  done: false\n",
      "  episode_len_mean: 106.72\n",
      "  episode_reward_max: 72.76087679295682\n",
      "  episode_reward_mean: -49.1412309768456\n",
      "  episode_reward_min: -204.83842419818183\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 3518\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4606.97\n",
      "    load_time_ms: 1.738\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1368686482667034e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.129170298576355\n",
      "      kl: 0.004947388079017401\n",
      "      policy_loss: -0.0017705151112750173\n",
      "      total_loss: 1214.802734375\n",
      "      vf_explained_var: 0.48780402541160583\n",
      "      vf_loss: 1214.8045654296875\n",
      "    sample_time_ms: 22818.758\n",
      "    update_time_ms: 5.858\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -24.570615488422803\n",
      "  time_since_restore: 1238.6680924892426\n",
      "  time_this_iter_s: 31.783771276474\n",
      "  time_total_s: 1238.6680924892426\n",
      "  timestamp: 1554809530\n",
      "  timesteps_since_restore: 460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 46\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1238 s, 46 iter, 460000 ts, -49.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-32-36\n",
      "  done: false\n",
      "  episode_len_mean: 99.0\n",
      "  episode_reward_max: 81.24165954442248\n",
      "  episode_reward_mean: -59.08215462437685\n",
      "  episode_reward_min: -203.74522977003613\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 3620\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4375.154\n",
      "    load_time_ms: 1.743\n",
      "    num_steps_sampled: 470000\n",
      "    num_steps_trained: 470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.684343241333517e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1145966053009033\n",
      "      kl: 0.0035188905894756317\n",
      "      policy_loss: -0.0005853166803717613\n",
      "      total_loss: 1139.4896240234375\n",
      "      vf_explained_var: 0.548133909702301\n",
      "      vf_loss: 1139.490234375\n",
      "    sample_time_ms: 22091.622\n",
      "    update_time_ms: 5.736\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -29.541077312188417\n",
      "  time_since_restore: 1264.79168343544\n",
      "  time_this_iter_s: 26.12359094619751\n",
      "  time_total_s: 1264.79168343544\n",
      "  timestamp: 1554809556\n",
      "  timesteps_since_restore: 470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 470000\n",
      "  training_iteration: 47\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1264 s, 47 iter, 470000 ts, -59.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-33-02\n",
      "  done: false\n",
      "  episode_len_mean: 103.96\n",
      "  episode_reward_max: 77.65952187322004\n",
      "  episode_reward_mean: -46.81642391622668\n",
      "  episode_reward_min: -203.21842095430884\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 3716\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4352.062\n",
      "    load_time_ms: 1.719\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.8421716206667585e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1082245111465454\n",
      "      kl: 0.005106916185468435\n",
      "      policy_loss: -0.0011437362991273403\n",
      "      total_loss: 1154.5582275390625\n",
      "      vf_explained_var: 0.5021228790283203\n",
      "      vf_loss: 1154.559326171875\n",
      "    sample_time_ms: 21904.318\n",
      "    update_time_ms: 5.622\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -23.40821195811334\n",
      "  time_since_restore: 1290.688705444336\n",
      "  time_this_iter_s: 25.897022008895874\n",
      "  time_total_s: 1290.688705444336\n",
      "  timestamp: 1554809582\n",
      "  timesteps_since_restore: 480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 48\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1290 s, 48 iter, 480000 ts, -46.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-33-28\n",
      "  done: false\n",
      "  episode_len_mean: 104.14\n",
      "  episode_reward_max: 66.77489971035352\n",
      "  episode_reward_mean: -52.07672470273396\n",
      "  episode_reward_min: -204.43909642628654\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 3812\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4329.013\n",
      "    load_time_ms: 1.695\n",
      "    num_steps_sampled: 490000\n",
      "    num_steps_trained: 490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4210858103333793e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0945690870285034\n",
      "      kl: 0.0065459259785711765\n",
      "      policy_loss: -0.0017890852177515626\n",
      "      total_loss: 1253.650146484375\n",
      "      vf_explained_var: 0.5213577747344971\n",
      "      vf_loss: 1253.65185546875\n",
      "    sample_time_ms: 22013.494\n",
      "    update_time_ms: 5.603\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -26.03836235136698\n",
      "  time_since_restore: 1316.9037187099457\n",
      "  time_this_iter_s: 26.21501326560974\n",
      "  time_total_s: 1316.9037187099457\n",
      "  timestamp: 1554809608\n",
      "  timesteps_since_restore: 490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 490000\n",
      "  training_iteration: 49\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1316 s, 49 iter, 490000 ts, -52.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-33-54\n",
      "  done: false\n",
      "  episode_len_mean: 103.3\n",
      "  episode_reward_max: 63.46602818085465\n",
      "  episode_reward_mean: -59.91273278871914\n",
      "  episode_reward_min: -204.18160275508856\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 3910\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4342.332\n",
      "    load_time_ms: 1.821\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.105429051666896e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0888195037841797\n",
      "      kl: 0.006299504078924656\n",
      "      policy_loss: -0.0015314498450607061\n",
      "      total_loss: 1278.7410888671875\n",
      "      vf_explained_var: 0.5387841463088989\n",
      "      vf_loss: 1278.7425537109375\n",
      "    sample_time_ms: 21978.861\n",
      "    update_time_ms: 5.735\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -29.956366394359566\n",
      "  time_since_restore: 1342.7438702583313\n",
      "  time_this_iter_s: 25.84015154838562\n",
      "  time_total_s: 1342.7438702583313\n",
      "  timestamp: 1554809634\n",
      "  timesteps_since_restore: 500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 50\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1342 s, 50 iter, 500000 ts, -59.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-34-20\n",
      "  done: false\n",
      "  episode_len_mean: 97.06862745098039\n",
      "  episode_reward_max: 53.05825814277717\n",
      "  episode_reward_mean: -66.77478152406987\n",
      "  episode_reward_min: -204.45437654862926\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 4012\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4349.335\n",
      "    load_time_ms: 1.819\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.552714525833448e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.081869125366211\n",
      "      kl: 0.003704096656292677\n",
      "      policy_loss: -0.0009256770135834813\n",
      "      total_loss: 1238.5379638671875\n",
      "      vf_explained_var: 0.5537271499633789\n",
      "      vf_loss: 1238.538818359375\n",
      "    sample_time_ms: 21996.462\n",
      "    update_time_ms: 5.38\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.38739076203493\n",
      "  time_since_restore: 1368.4987840652466\n",
      "  time_this_iter_s: 25.754913806915283\n",
      "  time_total_s: 1368.4987840652466\n",
      "  timestamp: 1554809660\n",
      "  timesteps_since_restore: 510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 51\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1368 s, 51 iter, 510000 ts, -66.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-34-47\n",
      "  done: false\n",
      "  episode_len_mean: 99.07\n",
      "  episode_reward_max: 55.55652159494887\n",
      "  episode_reward_mean: -57.0712551594569\n",
      "  episode_reward_min: -201.73297965711294\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 4112\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4357.556\n",
      "    load_time_ms: 1.852\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.776357262916724e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0902695655822754\n",
      "      kl: 0.0023428332060575485\n",
      "      policy_loss: -0.0004585163842421025\n",
      "      total_loss: 1272.8707275390625\n",
      "      vf_explained_var: 0.4950397312641144\n",
      "      vf_loss: 1272.8712158203125\n",
      "    sample_time_ms: 22034.734\n",
      "    update_time_ms: 5.344\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -28.53562757972845\n",
      "  time_since_restore: 1394.951821565628\n",
      "  time_this_iter_s: 26.45303750038147\n",
      "  time_total_s: 1394.951821565628\n",
      "  timestamp: 1554809687\n",
      "  timesteps_since_restore: 520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 52\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1394 s, 52 iter, 520000 ts, -57.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-35-13\n",
      "  done: false\n",
      "  episode_len_mean: 102.67\n",
      "  episode_reward_max: 51.15563736785044\n",
      "  episode_reward_mean: -52.04644680958611\n",
      "  episode_reward_min: -203.39999796497176\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 4211\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4374.467\n",
      "    load_time_ms: 1.843\n",
      "    num_steps_sampled: 530000\n",
      "    num_steps_trained: 530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.88178631458362e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0846991539001465\n",
      "      kl: 0.004587765317410231\n",
      "      policy_loss: -0.0015780386747792363\n",
      "      total_loss: 1244.845947265625\n",
      "      vf_explained_var: 0.5400010943412781\n",
      "      vf_loss: 1244.8475341796875\n",
      "    sample_time_ms: 22211.795\n",
      "    update_time_ms: 5.401\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -26.023223404793043\n",
      "  time_since_restore: 1421.5930571556091\n",
      "  time_this_iter_s: 26.64123558998108\n",
      "  time_total_s: 1421.5930571556091\n",
      "  timestamp: 1554809713\n",
      "  timesteps_since_restore: 530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 530000\n",
      "  training_iteration: 53\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1421 s, 53 iter, 530000 ts, -52 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-35-38\n",
      "  done: false\n",
      "  episode_len_mean: 101.16\n",
      "  episode_reward_max: 46.7854455209598\n",
      "  episode_reward_mean: -55.068187087004524\n",
      "  episode_reward_min: -203.305278736526\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 4310\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4358.106\n",
      "    load_time_ms: 1.715\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.44089315729181e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.058762550354004\n",
      "      kl: 0.005550812464207411\n",
      "      policy_loss: -0.0026634098030626774\n",
      "      total_loss: 1308.7996826171875\n",
      "      vf_explained_var: 0.5241267681121826\n",
      "      vf_loss: 1308.80224609375\n",
      "    sample_time_ms: 22164.079\n",
      "    update_time_ms: 5.437\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -27.53409354350226\n",
      "  time_since_restore: 1446.7841360569\n",
      "  time_this_iter_s: 25.191078901290894\n",
      "  time_total_s: 1446.7841360569\n",
      "  timestamp: 1554809738\n",
      "  timesteps_since_restore: 540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 54\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1446 s, 54 iter, 540000 ts, -55.1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-36-07\n",
      "  done: false\n",
      "  episode_len_mean: 103.97\n",
      "  episode_reward_max: 49.343749531203066\n",
      "  episode_reward_mean: -43.081170708716535\n",
      "  episode_reward_min: -203.6717731693624\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 4406\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4333.217\n",
      "    load_time_ms: 1.74\n",
      "    num_steps_sampled: 550000\n",
      "    num_steps_trained: 550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.220446578645905e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.054858684539795\n",
      "      kl: 0.005582212004810572\n",
      "      policy_loss: -0.0005996286636218429\n",
      "      total_loss: 1320.48681640625\n",
      "      vf_explained_var: 0.4547688066959381\n",
      "      vf_loss: 1320.4874267578125\n",
      "    sample_time_ms: 22498.957\n",
      "    update_time_ms: 5.466\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -21.54058535435827\n",
      "  time_since_restore: 1475.476755142212\n",
      "  time_this_iter_s: 28.69261908531189\n",
      "  time_total_s: 1475.476755142212\n",
      "  timestamp: 1554809767\n",
      "  timesteps_since_restore: 550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 550000\n",
      "  training_iteration: 55\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1475 s, 55 iter, 550000 ts, -43.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-36-34\n",
      "  done: false\n",
      "  episode_len_mean: 100.36\n",
      "  episode_reward_max: 46.282717551064856\n",
      "  episode_reward_mean: -55.06509889675568\n",
      "  episode_reward_min: -204.8575438112579\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 4505\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4321.459\n",
      "    load_time_ms: 1.699\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1102232893229526e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0537713766098022\n",
      "      kl: 0.0034554775338619947\n",
      "      policy_loss: -0.000931258371565491\n",
      "      total_loss: 1335.4134521484375\n",
      "      vf_explained_var: 0.44364821910858154\n",
      "      vf_loss: 1335.4144287109375\n",
      "    sample_time_ms: 22055.534\n",
      "    update_time_ms: 5.591\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -27.53254944837784\n",
      "  time_since_restore: 1502.7112836837769\n",
      "  time_this_iter_s: 27.23452854156494\n",
      "  time_total_s: 1502.7112836837769\n",
      "  timestamp: 1554809794\n",
      "  timesteps_since_restore: 560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 56\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1502 s, 56 iter, 560000 ts, -55.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-36-59\n",
      "  done: false\n",
      "  episode_len_mean: 106.73\n",
      "  episode_reward_max: 40.89575939668461\n",
      "  episode_reward_mean: -36.78857620913079\n",
      "  episode_reward_min: -202.7375725668848\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 4599\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4288.546\n",
      "    load_time_ms: 1.735\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.551116446614763e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0469647645950317\n",
      "      kl: 0.0065439739264547825\n",
      "      policy_loss: -0.0026392831932753325\n",
      "      total_loss: 1374.4473876953125\n",
      "      vf_explained_var: 0.3817480504512787\n",
      "      vf_loss: 1374.4500732421875\n",
      "    sample_time_ms: 21948.641\n",
      "    update_time_ms: 5.709\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -18.394288104565398\n",
      "  time_since_restore: 1527.4414467811584\n",
      "  time_this_iter_s: 24.730163097381592\n",
      "  time_total_s: 1527.4414467811584\n",
      "  timestamp: 1554809819\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 57\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1527 s, 57 iter, 570000 ts, -36.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-37-24\n",
      "  done: false\n",
      "  episode_len_mean: 104.25\n",
      "  episode_reward_max: 44.913327456712906\n",
      "  episode_reward_mean: -39.78985926290644\n",
      "  episode_reward_min: -203.8391783540257\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 4696\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4298.575\n",
      "    load_time_ms: 1.744\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7755582233073814e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0408486127853394\n",
      "      kl: 0.00636352738365531\n",
      "      policy_loss: -0.0017018956132233143\n",
      "      total_loss: 1306.16015625\n",
      "      vf_explained_var: 0.3249404728412628\n",
      "      vf_loss: 1306.16162109375\n",
      "    sample_time_ms: 21863.768\n",
      "    update_time_ms: 5.703\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -19.89492963145322\n",
      "  time_since_restore: 1552.5870735645294\n",
      "  time_this_iter_s: 25.14562678337097\n",
      "  time_total_s: 1552.5870735645294\n",
      "  timestamp: 1554809844\n",
      "  timesteps_since_restore: 580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 58\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1552 s, 58 iter, 580000 ts, -39.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-37-54\n",
      "  done: false\n",
      "  episode_len_mean: 98.5049504950495\n",
      "  episode_reward_max: 37.66257056638576\n",
      "  episode_reward_mean: -58.766669954067254\n",
      "  episode_reward_min: -205.03821325947655\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 4797\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4389.849\n",
      "    load_time_ms: 1.75\n",
      "    num_steps_sampled: 590000\n",
      "    num_steps_trained: 590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3877791116536907e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0168306827545166\n",
      "      kl: 0.006387719418853521\n",
      "      policy_loss: -0.0025130051653832197\n",
      "      total_loss: 1342.90380859375\n",
      "      vf_explained_var: 0.3833464980125427\n",
      "      vf_loss: 1342.9063720703125\n",
      "    sample_time_ms: 22098.177\n",
      "    update_time_ms: 5.903\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -29.38333497703363\n",
      "  time_since_restore: 1582.0589230060577\n",
      "  time_this_iter_s: 29.47184944152832\n",
      "  time_total_s: 1582.0589230060577\n",
      "  timestamp: 1554809874\n",
      "  timesteps_since_restore: 590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 590000\n",
      "  training_iteration: 59\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1582 s, 59 iter, 590000 ts, -58.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-38-26\n",
      "  done: false\n",
      "  episode_len_mean: 102.07\n",
      "  episode_reward_max: 40.32881267518755\n",
      "  episode_reward_mean: -45.73957874744926\n",
      "  episode_reward_min: -203.70298285893472\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 4895\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4409.674\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.9388955582684535e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9975562691688538\n",
      "      kl: 0.004720120690762997\n",
      "      policy_loss: -0.0013190933968871832\n",
      "      total_loss: 1426.6063232421875\n",
      "      vf_explained_var: 0.3034715950489044\n",
      "      vf_loss: 1426.6077880859375\n",
      "    sample_time_ms: 22718.685\n",
      "    update_time_ms: 6.339\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -22.869789373724625\n",
      "  time_since_restore: 1614.3001759052277\n",
      "  time_this_iter_s: 32.24125289916992\n",
      "  time_total_s: 1614.3001759052277\n",
      "  timestamp: 1554809906\n",
      "  timesteps_since_restore: 600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 60\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1614 s, 60 iter, 600000 ts, -45.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-38-53\n",
      "  done: false\n",
      "  episode_len_mean: 99.15841584158416\n",
      "  episode_reward_max: 45.143505880240504\n",
      "  episode_reward_mean: -54.198587135743416\n",
      "  episode_reward_min: -203.49129793454688\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 4996\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4491.573\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 610000\n",
      "    num_steps_trained: 610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694477791342267e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9955657720565796\n",
      "      kl: 0.00418449379503727\n",
      "      policy_loss: -0.00023663960746489465\n",
      "      total_loss: 1383.4898681640625\n",
      "      vf_explained_var: 0.3240918815135956\n",
      "      vf_loss: 1383.4901123046875\n",
      "    sample_time_ms: 22695.562\n",
      "    update_time_ms: 6.424\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -27.099293567871715\n",
      "  time_since_restore: 1640.64572930336\n",
      "  time_this_iter_s: 26.345553398132324\n",
      "  time_total_s: 1640.64572930336\n",
      "  timestamp: 1554809933\n",
      "  timesteps_since_restore: 610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 610000\n",
      "  training_iteration: 61\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1640 s, 61 iter, 610000 ts, -54.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-39-22\n",
      "  done: false\n",
      "  episode_len_mean: 99.61386138613861\n",
      "  episode_reward_max: 39.330234168094094\n",
      "  episode_reward_mean: -53.86892435841506\n",
      "  episode_reward_min: -202.61218696622313\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 5097\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4539.398\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347238895671134e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9978402853012085\n",
      "      kl: 0.0047828396782279015\n",
      "      policy_loss: -0.000920521910302341\n",
      "      total_loss: 1351.4925537109375\n",
      "      vf_explained_var: 0.3559649884700775\n",
      "      vf_loss: 1351.493408203125\n",
      "    sample_time_ms: 22941.718\n",
      "    update_time_ms: 6.465\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -26.934462179207525\n",
      "  time_since_restore: 1670.0380511283875\n",
      "  time_this_iter_s: 29.392321825027466\n",
      "  time_total_s: 1670.0380511283875\n",
      "  timestamp: 1554809962\n",
      "  timesteps_since_restore: 620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 62\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1670 s, 62 iter, 620000 ts, -53.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-39-48\n",
      "  done: false\n",
      "  episode_len_mean: 97.44117647058823\n",
      "  episode_reward_max: 29.300727807244645\n",
      "  episode_reward_mean: -62.454242828762894\n",
      "  episode_reward_min: -201.85215166572203\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 5199\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4533.742\n",
      "    load_time_ms: 1.625\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673619447835567e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9652265906333923\n",
      "      kl: 0.0058530112728476524\n",
      "      policy_loss: -0.0016215518116950989\n",
      "      total_loss: 1391.2762451171875\n",
      "      vf_explained_var: 0.3960295021533966\n",
      "      vf_loss: 1391.27783203125\n",
      "    sample_time_ms: 22903.695\n",
      "    update_time_ms: 6.298\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -31.227121414381447\n",
      "  time_since_restore: 1696.2425045967102\n",
      "  time_this_iter_s: 26.204453468322754\n",
      "  time_total_s: 1696.2425045967102\n",
      "  timestamp: 1554809988\n",
      "  timesteps_since_restore: 630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 63\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1696 s, 63 iter, 630000 ts, -62.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-40-13\n",
      "  done: false\n",
      "  episode_len_mean: 94.76190476190476\n",
      "  episode_reward_max: 31.22641916618795\n",
      "  episode_reward_mean: -65.89913897127977\n",
      "  episode_reward_min: -201.91770875700874\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 5304\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4538.4\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 640000\n",
      "    num_steps_trained: 640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.3368097239177834e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9472418427467346\n",
      "      kl: 0.0062034414149820805\n",
      "      policy_loss: -0.0019048789981752634\n",
      "      total_loss: 1344.26220703125\n",
      "      vf_explained_var: 0.4140503704547882\n",
      "      vf_loss: 1344.26416015625\n",
      "    sample_time_ms: 22862.835\n",
      "    update_time_ms: 6.171\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -32.94956948563989\n",
      "  time_since_restore: 1721.0718569755554\n",
      "  time_this_iter_s: 24.829352378845215\n",
      "  time_total_s: 1721.0718569755554\n",
      "  timestamp: 1554810013\n",
      "  timesteps_since_restore: 640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 640000\n",
      "  training_iteration: 64\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1721 s, 64 iter, 640000 ts, -65.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-40-37\n",
      "  done: false\n",
      "  episode_len_mean: 94.61682242990655\n",
      "  episode_reward_max: 29.84653895418417\n",
      "  episode_reward_mean: -66.44567658547358\n",
      "  episode_reward_min: -201.55386058459317\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 5411\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4541.107\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 650000\n",
      "    num_steps_trained: 650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1684048619588917e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9430149793624878\n",
      "      kl: 0.005454009864479303\n",
      "      policy_loss: -0.0020120511762797832\n",
      "      total_loss: 1330.6217041015625\n",
      "      vf_explained_var: 0.4276930093765259\n",
      "      vf_loss: 1330.623779296875\n",
      "    sample_time_ms: 22358.367\n",
      "    update_time_ms: 6.274\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.22283829273679\n",
      "  time_since_restore: 1744.7480494976044\n",
      "  time_this_iter_s: 23.67619252204895\n",
      "  time_total_s: 1744.7480494976044\n",
      "  timestamp: 1554810037\n",
      "  timesteps_since_restore: 650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 650000\n",
      "  training_iteration: 65\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1744 s, 65 iter, 650000 ts, -66.4 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-41-03\n",
      "  done: false\n",
      "  episode_len_mean: 94.97115384615384\n",
      "  episode_reward_max: 31.830785021328516\n",
      "  episode_reward_mean: -68.80393622429686\n",
      "  episode_reward_min: -203.68874930578795\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5515\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4541.04\n",
      "    load_time_ms: 1.583\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842024309794459e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9410213828086853\n",
      "      kl: 0.0038620501291006804\n",
      "      policy_loss: -0.0009526694193482399\n",
      "      total_loss: 1386.31005859375\n",
      "      vf_explained_var: 0.47105103731155396\n",
      "      vf_loss: 1386.3111572265625\n",
      "    sample_time_ms: 22194.964\n",
      "    update_time_ms: 6.238\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.40196811214843\n",
      "  time_since_restore: 1770.3475167751312\n",
      "  time_this_iter_s: 25.599467277526855\n",
      "  time_total_s: 1770.3475167751312\n",
      "  timestamp: 1554810063\n",
      "  timesteps_since_restore: 660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 66\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1770 s, 66 iter, 660000 ts, -68.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-41-28\n",
      "  done: false\n",
      "  episode_len_mean: 100.48\n",
      "  episode_reward_max: 33.11301329275618\n",
      "  episode_reward_mean: -50.24565918063581\n",
      "  episode_reward_min: -203.16922738258535\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 5615\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4549.059\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 670000\n",
      "    num_steps_trained: 670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.421012154897229e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9358865022659302\n",
      "      kl: 0.006858435925096273\n",
      "      policy_loss: -0.0021816319786012173\n",
      "      total_loss: 1377.8106689453125\n",
      "      vf_explained_var: 0.4216375946998596\n",
      "      vf_loss: 1377.8128662109375\n",
      "    sample_time_ms: 22238.485\n",
      "    update_time_ms: 6.142\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -25.122829590317906\n",
      "  time_since_restore: 1795.5893020629883\n",
      "  time_this_iter_s: 25.241785287857056\n",
      "  time_total_s: 1795.5893020629883\n",
      "  timestamp: 1554810088\n",
      "  timesteps_since_restore: 670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 670000\n",
      "  training_iteration: 67\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1795 s, 67 iter, 670000 ts, -50.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-41-52\n",
      "  done: false\n",
      "  episode_len_mean: 95.12380952380953\n",
      "  episode_reward_max: 30.98985932388397\n",
      "  episode_reward_mean: -67.26480807122762\n",
      "  episode_reward_min: -202.12687975323084\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 5720\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4535.715\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7105060774486146e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9239476323127747\n",
      "      kl: 0.005924254190176725\n",
      "      policy_loss: -0.0018883009906858206\n",
      "      total_loss: 1322.6593017578125\n",
      "      vf_explained_var: 0.46661484241485596\n",
      "      vf_loss: 1322.6610107421875\n",
      "    sample_time_ms: 22190.149\n",
      "    update_time_ms: 6.262\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.63240403561381\n",
      "  time_since_restore: 1820.1202511787415\n",
      "  time_this_iter_s: 24.530949115753174\n",
      "  time_total_s: 1820.1202511787415\n",
      "  timestamp: 1554810112\n",
      "  timesteps_since_restore: 680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 68\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1820 s, 68 iter, 680000 ts, -67.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-42-17\n",
      "  done: false\n",
      "  episode_len_mean: 96.06666666666666\n",
      "  episode_reward_max: 31.010516234651828\n",
      "  episode_reward_mean: -64.36850279049541\n",
      "  episode_reward_min: -202.390591834996\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 5825\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4420.717\n",
      "    load_time_ms: 1.618\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3552530387243073e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9232110381126404\n",
      "      kl: 0.005886986386030912\n",
      "      policy_loss: -0.001425471855327487\n",
      "      total_loss: 1349.8262939453125\n",
      "      vf_explained_var: 0.4712238907814026\n",
      "      vf_loss: 1349.8277587890625\n",
      "    sample_time_ms: 21781.076\n",
      "    update_time_ms: 6.215\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -32.1842513952477\n",
      "  time_since_restore: 1844.3494744300842\n",
      "  time_this_iter_s: 24.229223251342773\n",
      "  time_total_s: 1844.3494744300842\n",
      "  timestamp: 1554810137\n",
      "  timesteps_since_restore: 690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 69\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1844 s, 69 iter, 690000 ts, -64.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-42-41\n",
      "  done: false\n",
      "  episode_len_mean: 95.74038461538461\n",
      "  episode_reward_max: 33.01763255150917\n",
      "  episode_reward_mean: -63.95376203037816\n",
      "  episode_reward_min: -202.39440620446595\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5929\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4380.492\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.776265193621537e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9309754967689514\n",
      "      kl: 0.004281153436750174\n",
      "      policy_loss: -0.0015133768320083618\n",
      "      total_loss: 1309.98681640625\n",
      "      vf_explained_var: 0.45925405621528625\n",
      "      vf_loss: 1309.98828125\n",
      "    sample_time_ms: 21072.501\n",
      "    update_time_ms: 5.795\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -31.976881015189072\n",
      "  time_since_restore: 1869.0991559028625\n",
      "  time_this_iter_s: 24.74968147277832\n",
      "  time_total_s: 1869.0991559028625\n",
      "  timestamp: 1554810161\n",
      "  timesteps_since_restore: 700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 70\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1869 s, 70 iter, 700000 ts, -64 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-43-06\n",
      "  done: false\n",
      "  episode_len_mean: 94.65094339622641\n",
      "  episode_reward_max: 30.22451712628606\n",
      "  episode_reward_mean: -65.2384583380912\n",
      "  episode_reward_min: -202.51230409914288\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 6035\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4285.764\n",
      "    load_time_ms: 1.613\n",
      "    num_steps_sampled: 710000\n",
      "    num_steps_trained: 710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.3881325968107683e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9223096966743469\n",
      "      kl: 0.005640849936753511\n",
      "      policy_loss: -0.0015313720796257257\n",
      "      total_loss: 1391.4886474609375\n",
      "      vf_explained_var: 0.42455512285232544\n",
      "      vf_loss: 1391.490234375\n",
      "    sample_time_ms: 21025.348\n",
      "    update_time_ms: 5.675\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -32.61922916904559\n",
      "  time_since_restore: 1894.0253276824951\n",
      "  time_this_iter_s: 24.92617177963257\n",
      "  time_total_s: 1894.0253276824951\n",
      "  timestamp: 1554810186\n",
      "  timesteps_since_restore: 710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 710000\n",
      "  training_iteration: 71\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1894 s, 71 iter, 710000 ts, -65.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-43-32\n",
      "  done: false\n",
      "  episode_len_mean: 94.5\n",
      "  episode_reward_max: 26.23425882429872\n",
      "  episode_reward_mean: -68.66893861776144\n",
      "  episode_reward_min: -201.99571281157378\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 6139\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4239.172\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6940662984053842e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9059934616088867\n",
      "      kl: 0.006988817360252142\n",
      "      policy_loss: -0.0021148251835256815\n",
      "      total_loss: 1402.1085205078125\n",
      "      vf_explained_var: 0.42968496680259705\n",
      "      vf_loss: 1402.1107177734375\n",
      "    sample_time_ms: 20683.03\n",
      "    update_time_ms: 5.741\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.334469308880735\n",
      "  time_since_restore: 1919.5290968418121\n",
      "  time_this_iter_s: 25.503769159317017\n",
      "  time_total_s: 1919.5290968418121\n",
      "  timestamp: 1554810212\n",
      "  timesteps_since_restore: 720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 72\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1919 s, 72 iter, 720000 ts, -68.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-43-58\n",
      "  done: false\n",
      "  episode_len_mean: 95.11320754716981\n",
      "  episode_reward_max: 27.456152918548323\n",
      "  episode_reward_mean: -66.04524845445368\n",
      "  episode_reward_min: -202.46609605414704\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 6245\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4231.324\n",
      "    load_time_ms: 1.629\n",
      "    num_steps_sampled: 730000\n",
      "    num_steps_trained: 730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.470331492026921e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8968561887741089\n",
      "      kl: 0.004797164350748062\n",
      "      policy_loss: -0.0009607416577637196\n",
      "      total_loss: 1351.832275390625\n",
      "      vf_explained_var: 0.445841521024704\n",
      "      vf_loss: 1351.8333740234375\n",
      "    sample_time_ms: 20666.948\n",
      "    update_time_ms: 5.917\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.02262422722684\n",
      "  time_since_restore: 1945.4924635887146\n",
      "  time_this_iter_s: 25.963366746902466\n",
      "  time_total_s: 1945.4924635887146\n",
      "  timestamp: 1554810238\n",
      "  timesteps_since_restore: 730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 730000\n",
      "  training_iteration: 73\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1945 s, 73 iter, 730000 ts, -66 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-44-23\n",
      "  done: false\n",
      "  episode_len_mean: 94.41509433962264\n",
      "  episode_reward_max: 22.96914292703882\n",
      "  episode_reward_mean: -66.31799829243269\n",
      "  episode_reward_min: -202.67337802556438\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 6351\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4257.412\n",
      "    load_time_ms: 1.684\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.2351657460134604e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8862440586090088\n",
      "      kl: 0.005029506515711546\n",
      "      policy_loss: -0.0015850032214075327\n",
      "      total_loss: 1330.22998046875\n",
      "      vf_explained_var: 0.4187515377998352\n",
      "      vf_loss: 1330.2315673828125\n",
      "    sample_time_ms: 20681.317\n",
      "    update_time_ms: 5.912\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.158999146216345\n",
      "  time_since_restore: 1970.728890657425\n",
      "  time_this_iter_s: 25.236427068710327\n",
      "  time_total_s: 1970.728890657425\n",
      "  timestamp: 1554810263\n",
      "  timesteps_since_restore: 740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 74\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1970 s, 74 iter, 740000 ts, -66.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-44-48\n",
      "  done: false\n",
      "  episode_len_mean: 96.02884615384616\n",
      "  episode_reward_max: 19.531246423390783\n",
      "  episode_reward_mean: -63.947057286626766\n",
      "  episode_reward_min: -202.63130881811108\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 6455\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4243.935\n",
      "    load_time_ms: 1.706\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1175828730067302e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8632673621177673\n",
      "      kl: 0.005001331213861704\n",
      "      policy_loss: -0.0011024981504306197\n",
      "      total_loss: 1433.231201171875\n",
      "      vf_explained_var: 0.3914385437965393\n",
      "      vf_loss: 1433.232177734375\n",
      "    sample_time_ms: 20805.578\n",
      "    update_time_ms: 5.837\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -31.973528643313387\n",
      "  time_since_restore: 1995.5130410194397\n",
      "  time_this_iter_s: 24.78415036201477\n",
      "  time_total_s: 1995.5130410194397\n",
      "  timestamp: 1554810288\n",
      "  timesteps_since_restore: 750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 75\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 1995 s, 75 iter, 750000 ts, -63.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-45-13\n",
      "  done: false\n",
      "  episode_len_mean: 90.30630630630631\n",
      "  episode_reward_max: 21.481946675030343\n",
      "  episode_reward_mean: -77.54213193085874\n",
      "  episode_reward_min: -202.51573355551307\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 6566\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4247.679\n",
      "    load_time_ms: 1.706\n",
      "    num_steps_sampled: 760000\n",
      "    num_steps_trained: 760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0587914365033651e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8571481704711914\n",
      "      kl: 0.006015871185809374\n",
      "      policy_loss: -0.002281009452417493\n",
      "      total_loss: 1361.908447265625\n",
      "      vf_explained_var: 0.43070924282073975\n",
      "      vf_loss: 1361.91064453125\n",
      "    sample_time_ms: 20710.498\n",
      "    update_time_ms: 5.884\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.77106596542936\n",
      "  time_since_restore: 2020.2020931243896\n",
      "  time_this_iter_s: 24.68905210494995\n",
      "  time_total_s: 2020.2020931243896\n",
      "  timestamp: 1554810313\n",
      "  timesteps_since_restore: 760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 760000\n",
      "  training_iteration: 76\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2020 s, 76 iter, 760000 ts, -77.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-45-38\n",
      "  done: false\n",
      "  episode_len_mean: 93.4392523364486\n",
      "  episode_reward_max: 20.174919777410935\n",
      "  episode_reward_mean: -68.14959590190334\n",
      "  episode_reward_min: -202.37220308616924\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 6673\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4247.27\n",
      "    load_time_ms: 1.667\n",
      "    num_steps_sampled: 770000\n",
      "    num_steps_trained: 770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.2939571825168255e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8554137945175171\n",
      "      kl: 0.005289954133331776\n",
      "      policy_loss: -0.0010674090590327978\n",
      "      total_loss: 1313.54150390625\n",
      "      vf_explained_var: 0.43004393577575684\n",
      "      vf_loss: 1313.5426025390625\n",
      "    sample_time_ms: 20654.656\n",
      "    update_time_ms: 5.83\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.074797950951684\n",
      "  time_since_restore: 2044.8802733421326\n",
      "  time_this_iter_s: 24.67818021774292\n",
      "  time_total_s: 2044.8802733421326\n",
      "  timestamp: 1554810338\n",
      "  timesteps_since_restore: 770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 770000\n",
      "  training_iteration: 77\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2044 s, 77 iter, 770000 ts, -68.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-46-02\n",
      "  done: false\n",
      "  episode_len_mean: 88.69026548672566\n",
      "  episode_reward_max: 18.914854599808983\n",
      "  episode_reward_mean: -85.67498328145057\n",
      "  episode_reward_min: -203.01072989558463\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 6786\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4250.819\n",
      "    load_time_ms: 1.709\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.6469785912584127e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8383052349090576\n",
      "      kl: 0.005945699289441109\n",
      "      policy_loss: -0.0011876631760969758\n",
      "      total_loss: 1358.2125244140625\n",
      "      vf_explained_var: 0.46158188581466675\n",
      "      vf_loss: 1358.2137451171875\n",
      "    sample_time_ms: 20681.556\n",
      "    update_time_ms: 5.784\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.83749164072528\n",
      "  time_since_restore: 2069.7137200832367\n",
      "  time_this_iter_s: 24.833446741104126\n",
      "  time_total_s: 2069.7137200832367\n",
      "  timestamp: 1554810362\n",
      "  timesteps_since_restore: 780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 78\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2069 s, 78 iter, 780000 ts, -85.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-46-29\n",
      "  done: false\n",
      "  episode_len_mean: 93.32710280373831\n",
      "  episode_reward_max: 18.877238313654903\n",
      "  episode_reward_mean: -69.25224201999147\n",
      "  episode_reward_min: -201.82996223218652\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 6893\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4319.756\n",
      "    load_time_ms: 1.725\n",
      "    num_steps_sampled: 790000\n",
      "    num_steps_trained: 790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3234892956292064e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8425794839859009\n",
      "      kl: 0.005578184965997934\n",
      "      policy_loss: -0.001282021403312683\n",
      "      total_loss: 1371.1158447265625\n",
      "      vf_explained_var: 0.3943439722061157\n",
      "      vf_loss: 1371.116943359375\n",
      "    sample_time_ms: 20831.851\n",
      "    update_time_ms: 5.684\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.62612100999575\n",
      "  time_since_restore: 2096.1382071971893\n",
      "  time_this_iter_s: 26.424487113952637\n",
      "  time_total_s: 2096.1382071971893\n",
      "  timestamp: 1554810389\n",
      "  timesteps_since_restore: 790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 790000\n",
      "  training_iteration: 79\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2096 s, 79 iter, 790000 ts, -69.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-46-57\n",
      "  done: false\n",
      "  episode_len_mean: 100.62\n",
      "  episode_reward_max: 20.34271561929551\n",
      "  episode_reward_mean: -53.077561489537835\n",
      "  episode_reward_min: -202.2868146677725\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 6992\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4335.667\n",
      "    load_time_ms: 1.725\n",
      "    num_steps_sampled: 800000\n",
      "    num_steps_trained: 800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.617446478146032e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8427311778068542\n",
      "      kl: 0.004145412240177393\n",
      "      policy_loss: -0.0005150377983227372\n",
      "      total_loss: 1428.3497314453125\n",
      "      vf_explained_var: 0.34653303027153015\n",
      "      vf_loss: 1428.3502197265625\n",
      "    sample_time_ms: 21135.025\n",
      "    update_time_ms: 6.892\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -26.538780744768918\n",
      "  time_since_restore: 2124.0892901420593\n",
      "  time_this_iter_s: 27.951082944869995\n",
      "  time_total_s: 2124.0892901420593\n",
      "  timestamp: 1554810417\n",
      "  timesteps_since_restore: 800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 800000\n",
      "  training_iteration: 80\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2124 s, 80 iter, 800000 ts, -53.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-47-23\n",
      "  done: false\n",
      "  episode_len_mean: 92.62037037037037\n",
      "  episode_reward_max: 21.28163795717896\n",
      "  episode_reward_mean: -75.08059353466325\n",
      "  episode_reward_min: -201.93975139433005\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 7100\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4475.108\n",
      "    load_time_ms: 1.794\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.308723239073016e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8406602144241333\n",
      "      kl: 0.005424166563898325\n",
      "      policy_loss: -0.0010715308599174023\n",
      "      total_loss: 1247.646728515625\n",
      "      vf_explained_var: 0.48554727435112\n",
      "      vf_loss: 1247.6478271484375\n",
      "    sample_time_ms: 21157.943\n",
      "    update_time_ms: 7.099\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.54029676733163\n",
      "  time_since_restore: 2150.644957780838\n",
      "  time_this_iter_s: 26.555667638778687\n",
      "  time_total_s: 2150.644957780838\n",
      "  timestamp: 1554810443\n",
      "  timesteps_since_restore: 810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 81\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2150 s, 81 iter, 810000 ts, -75.1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-47-49\n",
      "  done: false\n",
      "  episode_len_mean: 97.7843137254902\n",
      "  episode_reward_max: 23.786416796915425\n",
      "  episode_reward_mean: -58.363244948499194\n",
      "  episode_reward_min: -203.70146304790006\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 7202\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4463.251\n",
      "    load_time_ms: 1.792\n",
      "    num_steps_sampled: 820000\n",
      "    num_steps_trained: 820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.654361619536508e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8472520709037781\n",
      "      kl: 0.0048398603685200214\n",
      "      policy_loss: -0.0009178169420920312\n",
      "      total_loss: 1396.052978515625\n",
      "      vf_explained_var: 0.37273576855659485\n",
      "      vf_loss: 1396.053955078125\n",
      "    sample_time_ms: 21145.761\n",
      "    update_time_ms: 7.027\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -29.181622474249597\n",
      "  time_since_restore: 2175.9058887958527\n",
      "  time_this_iter_s: 25.26093101501465\n",
      "  time_total_s: 2175.9058887958527\n",
      "  timestamp: 1554810469\n",
      "  timesteps_since_restore: 820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 820000\n",
      "  training_iteration: 82\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2175 s, 82 iter, 820000 ts, -58.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-48-15\n",
      "  done: false\n",
      "  episode_len_mean: 91.97247706422019\n",
      "  episode_reward_max: 25.310804770614173\n",
      "  episode_reward_mean: -75.18780807326915\n",
      "  episode_reward_min: -202.2905760913917\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 7311\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4476.321\n",
      "    load_time_ms: 1.72\n",
      "    num_steps_sampled: 830000\n",
      "    num_steps_trained: 830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.27180809768254e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8408868312835693\n",
      "      kl: 0.005488715134561062\n",
      "      policy_loss: -0.0010671118507161736\n",
      "      total_loss: 1295.2255859375\n",
      "      vf_explained_var: 0.46409422159194946\n",
      "      vf_loss: 1295.226806640625\n",
      "    sample_time_ms: 21106.361\n",
      "    update_time_ms: 7.65\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.59390403663458\n",
      "  time_since_restore: 2201.6130516529083\n",
      "  time_this_iter_s: 25.707162857055664\n",
      "  time_total_s: 2201.6130516529083\n",
      "  timestamp: 1554810495\n",
      "  timesteps_since_restore: 830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 830000\n",
      "  training_iteration: 83\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2201 s, 83 iter, 830000 ts, -75.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-48-40\n",
      "  done: false\n",
      "  episode_len_mean: 96.46601941747574\n",
      "  episode_reward_max: 24.44659982924847\n",
      "  episode_reward_mean: -60.343967399374044\n",
      "  episode_reward_min: -203.27332255398227\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 7414\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4479.537\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.13590404884127e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8498907089233398\n",
      "      kl: 0.004289453383535147\n",
      "      policy_loss: -0.0014322430361062288\n",
      "      total_loss: 1392.9044189453125\n",
      "      vf_explained_var: 0.36669614911079407\n",
      "      vf_loss: 1392.9058837890625\n",
      "    sample_time_ms: 21104.402\n",
      "    update_time_ms: 7.7\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -30.17198369968703\n",
      "  time_since_restore: 2226.856554031372\n",
      "  time_this_iter_s: 25.243502378463745\n",
      "  time_total_s: 2226.856554031372\n",
      "  timestamp: 1554810520\n",
      "  timesteps_since_restore: 840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 84\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2226 s, 84 iter, 840000 ts, -60.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-49-09\n",
      "  done: false\n",
      "  episode_len_mean: 100.34653465346534\n",
      "  episode_reward_max: 23.52268786981621\n",
      "  episode_reward_mean: -52.44167031960741\n",
      "  episode_reward_min: -202.08349387323432\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 7515\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4580.139\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 850000\n",
      "    num_steps_trained: 850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.067952024420635e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8435885906219482\n",
      "      kl: 0.0056764609180390835\n",
      "      policy_loss: -0.002085037063807249\n",
      "      total_loss: 1392.4512939453125\n",
      "      vf_explained_var: 0.3590649366378784\n",
      "      vf_loss: 1392.453369140625\n",
      "    sample_time_ms: 21399.139\n",
      "    update_time_ms: 7.657\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -26.220835159803716\n",
      "  time_since_restore: 2255.6044466495514\n",
      "  time_this_iter_s: 28.74789261817932\n",
      "  time_total_s: 2255.6044466495514\n",
      "  timestamp: 1554810549\n",
      "  timesteps_since_restore: 850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 850000\n",
      "  training_iteration: 85\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2255 s, 85 iter, 850000 ts, -52.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-49-39\n",
      "  done: false\n",
      "  episode_len_mean: 99.62\n",
      "  episode_reward_max: 24.588349775724723\n",
      "  episode_reward_mean: -54.60825109398371\n",
      "  episode_reward_min: -202.57857002694175\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 7615\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4590.067\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 860000\n",
      "    num_steps_trained: 860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0339760122103175e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8330186605453491\n",
      "      kl: 0.005717768333852291\n",
      "      policy_loss: -0.001063407282344997\n",
      "      total_loss: 1420.8212890625\n",
      "      vf_explained_var: 0.36431047320365906\n",
      "      vf_loss: 1420.822265625\n",
      "    sample_time_ms: 21983.474\n",
      "    update_time_ms: 7.795\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -27.30412554699186\n",
      "  time_since_restore: 2286.2357409000397\n",
      "  time_this_iter_s: 30.63129425048828\n",
      "  time_total_s: 2286.2357409000397\n",
      "  timestamp: 1554810579\n",
      "  timesteps_since_restore: 860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 860000\n",
      "  training_iteration: 86\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2286 s, 86 iter, 860000 ts, -54.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-50-07\n",
      "  done: false\n",
      "  episode_len_mean: 92.70370370370371\n",
      "  episode_reward_max: 26.391072902676996\n",
      "  episode_reward_mean: -72.28958742809962\n",
      "  episode_reward_min: -202.8307724919642\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 7723\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4590.027\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.1698800610515874e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8248167634010315\n",
      "      kl: 0.004779214505106211\n",
      "      policy_loss: -0.0021821013651788235\n",
      "      total_loss: 1322.5924072265625\n",
      "      vf_explained_var: 0.4541299343109131\n",
      "      vf_loss: 1322.5946044921875\n",
      "    sample_time_ms: 22250.036\n",
      "    update_time_ms: 7.906\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.144793714049804\n",
      "  time_since_restore: 2313.581480741501\n",
      "  time_this_iter_s: 27.34573984146118\n",
      "  time_total_s: 2313.581480741501\n",
      "  timestamp: 1554810607\n",
      "  timesteps_since_restore: 870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 87\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2313 s, 87 iter, 870000 ts, -72.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-50-37\n",
      "  done: false\n",
      "  episode_len_mean: 89.84821428571429\n",
      "  episode_reward_max: 22.68885308197593\n",
      "  episode_reward_mean: -81.87764846887914\n",
      "  episode_reward_min: -202.88804404512916\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 7835\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4652.612\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.5849400305257937e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8167470097541809\n",
      "      kl: 0.003662643488496542\n",
      "      policy_loss: -0.0004845750518143177\n",
      "      total_loss: 1319.4681396484375\n",
      "      vf_explained_var: 0.4450209140777588\n",
      "      vf_loss: 1319.468505859375\n",
      "    sample_time_ms: 22689.907\n",
      "    update_time_ms: 8.109\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.93882423443957\n",
      "  time_since_restore: 2343.44290971756\n",
      "  time_this_iter_s: 29.86142897605896\n",
      "  time_total_s: 2343.44290971756\n",
      "  timestamp: 1554810637\n",
      "  timesteps_since_restore: 880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 88\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2343 s, 88 iter, 880000 ts, -81.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-51-01\n",
      "  done: false\n",
      "  episode_len_mean: 90.11818181818182\n",
      "  episode_reward_max: 20.77449338049013\n",
      "  episode_reward_mean: -80.13434883137374\n",
      "  episode_reward_min: -202.10872666996391\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 7945\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4587.717\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 890000\n",
      "    num_steps_trained: 890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2924700152628968e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.809503436088562\n",
      "      kl: 0.006607650779187679\n",
      "      policy_loss: -0.002368329092860222\n",
      "      total_loss: 1333.42529296875\n",
      "      vf_explained_var: 0.46741151809692383\n",
      "      vf_loss: 1333.427734375\n",
      "    sample_time_ms: 22557.159\n",
      "    update_time_ms: 8.037\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.06717441568686\n",
      "  time_since_restore: 2367.885939359665\n",
      "  time_this_iter_s: 24.443029642105103\n",
      "  time_total_s: 2367.885939359665\n",
      "  timestamp: 1554810661\n",
      "  timesteps_since_restore: 890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 890000\n",
      "  training_iteration: 89\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2367 s, 89 iter, 890000 ts, -80.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-51-25\n",
      "  done: false\n",
      "  episode_len_mean: 102.43\n",
      "  episode_reward_max: 23.135169807976446\n",
      "  episode_reward_mean: -47.32570961926411\n",
      "  episode_reward_min: -202.49758978030565\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 8042\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4568.872\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.462350076314484e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8138663172721863\n",
      "      kl: 0.0039367713034152985\n",
      "      policy_loss: -0.0006271511083468795\n",
      "      total_loss: 1430.0350341796875\n",
      "      vf_explained_var: 0.3636220097541809\n",
      "      vf_loss: 1430.0355224609375\n",
      "    sample_time_ms: 22219.889\n",
      "    update_time_ms: 6.606\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -23.662854809632044\n",
      "  time_since_restore: 2392.2616176605225\n",
      "  time_this_iter_s: 24.375678300857544\n",
      "  time_total_s: 2392.2616176605225\n",
      "  timestamp: 1554810685\n",
      "  timesteps_since_restore: 900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 90\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2392 s, 90 iter, 900000 ts, -47.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-51-49\n",
      "  done: false\n",
      "  episode_len_mean: 101.62\n",
      "  episode_reward_max: 21.207782656562678\n",
      "  episode_reward_mean: -47.26063801333388\n",
      "  episode_reward_min: -202.21931817577695\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 8140\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4426.678\n",
      "    load_time_ms: 1.526\n",
      "    num_steps_sampled: 910000\n",
      "    num_steps_trained: 910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.231175038157242e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.809399425983429\n",
      "      kl: 0.004713853355497122\n",
      "      policy_loss: -0.001095946179702878\n",
      "      total_loss: 1499.9993896484375\n",
      "      vf_explained_var: 0.3293927311897278\n",
      "      vf_loss: 1500.0003662109375\n",
      "    sample_time_ms: 22031.678\n",
      "    update_time_ms: 6.368\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -23.630319006666944\n",
      "  time_since_restore: 2415.5045926570892\n",
      "  time_this_iter_s: 23.242974996566772\n",
      "  time_total_s: 2415.5045926570892\n",
      "  timestamp: 1554810709\n",
      "  timesteps_since_restore: 910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 910000\n",
      "  training_iteration: 91\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2415 s, 91 iter, 910000 ts, -47.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-52-13\n",
      "  done: false\n",
      "  episode_len_mean: 98.35643564356435\n",
      "  episode_reward_max: 20.016298608138015\n",
      "  episode_reward_mean: -58.95792497326795\n",
      "  episode_reward_min: -201.7654345886114\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 8241\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4418.211\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.615587519078621e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8104059100151062\n",
      "      kl: 0.004135179799050093\n",
      "      policy_loss: 9.69012689893134e-05\n",
      "      total_loss: 1458.9598388671875\n",
      "      vf_explained_var: 0.41385072469711304\n",
      "      vf_loss: 1458.9595947265625\n",
      "    sample_time_ms: 21945.435\n",
      "    update_time_ms: 6.523\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -29.478962486633986\n",
      "  time_since_restore: 2439.8222539424896\n",
      "  time_this_iter_s: 24.31766128540039\n",
      "  time_total_s: 2439.8222539424896\n",
      "  timestamp: 1554810733\n",
      "  timesteps_since_restore: 920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 92\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2439 s, 92 iter, 920000 ts, -59 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-52-37\n",
      "  done: false\n",
      "  episode_len_mean: 94.93396226415095\n",
      "  episode_reward_max: 20.871463203140422\n",
      "  episode_reward_mean: -66.91782162817799\n",
      "  episode_reward_min: -201.6255191237148\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 8347\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4383.603\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.077937595393105e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8112401962280273\n",
      "      kl: 0.005716491024941206\n",
      "      policy_loss: -0.0021885570604354143\n",
      "      total_loss: 1435.714111328125\n",
      "      vf_explained_var: 0.4409423768520355\n",
      "      vf_loss: 1435.71630859375\n",
      "    sample_time_ms: 21787.241\n",
      "    update_time_ms: 5.803\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.458910814089\n",
      "  time_since_restore: 2463.5967831611633\n",
      "  time_this_iter_s: 23.774529218673706\n",
      "  time_total_s: 2463.5967831611633\n",
      "  timestamp: 1554810757\n",
      "  timesteps_since_restore: 930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 93\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2463 s, 93 iter, 930000 ts, -66.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-53-01\n",
      "  done: false\n",
      "  episode_len_mean: 93.48113207547169\n",
      "  episode_reward_max: 19.19911800398603\n",
      "  episode_reward_mean: -72.71155183096764\n",
      "  episode_reward_min: -201.70402695453993\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 8453\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4344.758\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 940000\n",
      "    num_steps_trained: 940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.0389687976965526e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7976839542388916\n",
      "      kl: 0.005232976749539375\n",
      "      policy_loss: -0.0013582942774519324\n",
      "      total_loss: 1429.2200927734375\n",
      "      vf_explained_var: 0.46782028675079346\n",
      "      vf_loss: 1429.2213134765625\n",
      "    sample_time_ms: 21712.45\n",
      "    update_time_ms: 5.749\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.35577591548381\n",
      "  time_since_restore: 2487.705851793289\n",
      "  time_this_iter_s: 24.109068632125854\n",
      "  time_total_s: 2487.705851793289\n",
      "  timestamp: 1554810781\n",
      "  timesteps_since_restore: 940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 940000\n",
      "  training_iteration: 94\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2487 s, 94 iter, 940000 ts, -72.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-53-25\n",
      "  done: false\n",
      "  episode_len_mean: 91.15315315315316\n",
      "  episode_reward_max: 19.15639301244613\n",
      "  episode_reward_mean: -76.16872860695027\n",
      "  episode_reward_min: -202.1852327248344\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 8564\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4249.843\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 950000\n",
      "    num_steps_trained: 950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0194843988482763e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7847568392753601\n",
      "      kl: 0.003804944222792983\n",
      "      policy_loss: -0.0010086694965139031\n",
      "      total_loss: 1368.461669921875\n",
      "      vf_explained_var: 0.4861702024936676\n",
      "      vf_loss: 1368.462646484375\n",
      "    sample_time_ms: 21361.334\n",
      "    update_time_ms: 5.781\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.08436430347513\n",
      "  time_since_restore: 2511.9848957061768\n",
      "  time_this_iter_s: 24.279043912887573\n",
      "  time_total_s: 2511.9848957061768\n",
      "  timestamp: 1554810805\n",
      "  timesteps_since_restore: 950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 950000\n",
      "  training_iteration: 95\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2511 s, 95 iter, 950000 ts, -76.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-53-54\n",
      "  done: false\n",
      "  episode_len_mean: 93.17757009345794\n",
      "  episode_reward_max: 18.049660931550495\n",
      "  episode_reward_mean: -69.82959320234734\n",
      "  episode_reward_min: -202.28399713763906\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 8671\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4361.459\n",
      "    load_time_ms: 1.675\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0097421994241382e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7903825640678406\n",
      "      kl: 0.006343415006995201\n",
      "      policy_loss: -0.0020004999823868275\n",
      "      total_loss: 1361.89404296875\n",
      "      vf_explained_var: 0.47008559107780457\n",
      "      vf_loss: 1361.89599609375\n",
      "    sample_time_ms: 21069.165\n",
      "    update_time_ms: 5.559\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.914796601173656\n",
      "  time_since_restore: 2540.809586048126\n",
      "  time_this_iter_s: 28.824690341949463\n",
      "  time_total_s: 2540.809586048126\n",
      "  timestamp: 1554810834\n",
      "  timesteps_since_restore: 960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 96\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2540 s, 96 iter, 960000 ts, -69.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-54-18\n",
      "  done: false\n",
      "  episode_len_mean: 98.84158415841584\n",
      "  episode_reward_max: 18.236984345885325\n",
      "  episode_reward_mean: -56.54315831742678\n",
      "  episode_reward_min: -201.99517222701826\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 8772\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4364.79\n",
      "    load_time_ms: 1.659\n",
      "    num_steps_sampled: 970000\n",
      "    num_steps_trained: 970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.048710997120691e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7807376384735107\n",
      "      kl: 0.005368008743971586\n",
      "      policy_loss: -0.0009596557938493788\n",
      "      total_loss: 1500.340576171875\n",
      "      vf_explained_var: 0.38170483708381653\n",
      "      vf_loss: 1500.3414306640625\n",
      "    sample_time_ms: 20744.125\n",
      "    update_time_ms: 5.567\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -28.271579158713394\n",
      "  time_since_restore: 2564.937420129776\n",
      "  time_this_iter_s: 24.12783408164978\n",
      "  time_total_s: 2564.937420129776\n",
      "  timestamp: 1554810858\n",
      "  timesteps_since_restore: 970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 970000\n",
      "  training_iteration: 97\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2564 s, 97 iter, 970000 ts, -56.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-54-43\n",
      "  done: false\n",
      "  episode_len_mean: 90.35454545454546\n",
      "  episode_reward_max: 15.335283187907388\n",
      "  episode_reward_mean: -77.65931072168493\n",
      "  episode_reward_min: -202.18043071138104\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 8882\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4297.831\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 980000\n",
      "    num_steps_trained: 980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.5243554985603454e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7727394104003906\n",
      "      kl: 0.005413609091192484\n",
      "      policy_loss: -0.001954768318682909\n",
      "      total_loss: 1461.2982177734375\n",
      "      vf_explained_var: 0.41504189372062683\n",
      "      vf_loss: 1461.300537109375\n",
      "    sample_time_ms: 20295.61\n",
      "    update_time_ms: 6.647\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.82965536084248\n",
      "  time_since_restore: 2589.653036594391\n",
      "  time_this_iter_s: 24.715616464614868\n",
      "  time_total_s: 2589.653036594391\n",
      "  timestamp: 1554810883\n",
      "  timesteps_since_restore: 980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 980000\n",
      "  training_iteration: 98\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2589 s, 98 iter, 980000 ts, -77.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-55-08\n",
      "  done: false\n",
      "  episode_len_mean: 87.13793103448276\n",
      "  episode_reward_max: 14.923458044732934\n",
      "  episode_reward_mean: -88.89090505849583\n",
      "  episode_reward_min: -201.59687398396633\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 8998\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4288.924\n",
      "    load_time_ms: 1.675\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2621777492801727e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7608442306518555\n",
      "      kl: 0.005272991955280304\n",
      "      policy_loss: -0.0016012376872822642\n",
      "      total_loss: 1288.5115966796875\n",
      "      vf_explained_var: 0.5016191005706787\n",
      "      vf_loss: 1288.51318359375\n",
      "    sample_time_ms: 20320.729\n",
      "    update_time_ms: 6.756\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.44545252924793\n",
      "  time_since_restore: 2614.262196779251\n",
      "  time_this_iter_s: 24.60916018486023\n",
      "  time_total_s: 2614.262196779251\n",
      "  timestamp: 1554810908\n",
      "  timesteps_since_restore: 990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 99\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2614 s, 99 iter, 990000 ts, -88.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-55-34\n",
      "  done: false\n",
      "  episode_len_mean: 91.2\n",
      "  episode_reward_max: 14.083311083676136\n",
      "  episode_reward_mean: -75.86682830912966\n",
      "  episode_reward_min: -201.23993386493157\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 9108\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4404.143\n",
      "    load_time_ms: 1.716\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.3108887464008635e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7535067796707153\n",
      "      kl: 0.004181527066975832\n",
      "      policy_loss: -0.00027323493850417435\n",
      "      total_loss: 1392.6075439453125\n",
      "      vf_explained_var: 0.4708426892757416\n",
      "      vf_loss: 1392.6080322265625\n",
      "    sample_time_ms: 20390.074\n",
      "    update_time_ms: 6.913\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.93341415456484\n",
      "  time_since_restore: 2640.487959623337\n",
      "  time_this_iter_s: 26.225762844085693\n",
      "  time_total_s: 2640.487959623337\n",
      "  timestamp: 1554810934\n",
      "  timesteps_since_restore: 1000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 100\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2640 s, 100 iter, 1000000 ts, -75.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-56-02\n",
      "  done: false\n",
      "  episode_len_mean: 93.44339622641509\n",
      "  episode_reward_max: 13.544955837195678\n",
      "  episode_reward_mean: -70.02026120741583\n",
      "  episode_reward_min: -201.32040822122963\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 9214\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4410.447\n",
      "    load_time_ms: 1.717\n",
      "    num_steps_sampled: 1010000\n",
      "    num_steps_trained: 1010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.1554443732004317e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7452145218849182\n",
      "      kl: 0.005241906736046076\n",
      "      policy_loss: -0.001215618452988565\n",
      "      total_loss: 1372.108154296875\n",
      "      vf_explained_var: 0.4692055284976959\n",
      "      vf_loss: 1372.109375\n",
      "    sample_time_ms: 20873.925\n",
      "    update_time_ms: 7.068\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.01013060370793\n",
      "  time_since_restore: 2668.6347863674164\n",
      "  time_this_iter_s: 28.14682674407959\n",
      "  time_total_s: 2668.6347863674164\n",
      "  timestamp: 1554810962\n",
      "  timesteps_since_restore: 1010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1010000\n",
      "  training_iteration: 101\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2668 s, 101 iter, 1010000 ts, -70 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 90.09009009009009\n",
      "  episode_reward_max: 14.106218429517654\n",
      "  episode_reward_mean: -79.72859604968409\n",
      "  episode_reward_min: -201.15683118651054\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 9325\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4542.518\n",
      "    load_time_ms: 1.707\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5777221866002159e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7356601357460022\n",
      "      kl: 0.005261532962322235\n",
      "      policy_loss: -0.0007602327968925238\n",
      "      total_loss: 1341.1383056640625\n",
      "      vf_explained_var: 0.4933713376522064\n",
      "      vf_loss: 1341.13916015625\n",
      "    sample_time_ms: 20965.989\n",
      "    update_time_ms: 6.914\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.86429802484204\n",
      "  time_since_restore: 2695.1995463371277\n",
      "  time_this_iter_s: 26.564759969711304\n",
      "  time_total_s: 2695.1995463371277\n",
      "  timestamp: 1554810989\n",
      "  timesteps_since_restore: 1020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 102\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2695 s, 102 iter, 1020000 ts, -79.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-56-56\n",
      "  done: false\n",
      "  episode_len_mean: 94.84761904761905\n",
      "  episode_reward_max: 17.29877167097174\n",
      "  episode_reward_mean: -67.0170028654003\n",
      "  episode_reward_min: -201.17333283759478\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 9430\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4639.564\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 1030000\n",
      "    num_steps_trained: 1030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.888610933001079e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7307636141777039\n",
      "      kl: 0.004998000804334879\n",
      "      policy_loss: -0.0006135260919108987\n",
      "      total_loss: 1418.1708984375\n",
      "      vf_explained_var: 0.44998258352279663\n",
      "      vf_loss: 1418.171630859375\n",
      "    sample_time_ms: 21186.633\n",
      "    update_time_ms: 6.871\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.50850143270015\n",
      "  time_since_restore: 2722.147851705551\n",
      "  time_this_iter_s: 26.948305368423462\n",
      "  time_total_s: 2722.147851705551\n",
      "  timestamp: 1554811016\n",
      "  timesteps_since_restore: 1030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1030000\n",
      "  training_iteration: 103\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2722 s, 103 iter, 1030000 ts, -67 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-57-23\n",
      "  done: false\n",
      "  episode_len_mean: 94.25233644859813\n",
      "  episode_reward_max: 16.211275892775944\n",
      "  episode_reward_mean: -66.9781045684831\n",
      "  episode_reward_min: -201.43490230944857\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 9537\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4852.004\n",
      "    load_time_ms: 1.61\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.9443054665005397e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7240200638771057\n",
      "      kl: 0.005560462828725576\n",
      "      policy_loss: -0.0015806066803634167\n",
      "      total_loss: 1461.16650390625\n",
      "      vf_explained_var: 0.4161209762096405\n",
      "      vf_loss: 1461.1680908203125\n",
      "    sample_time_ms: 21316.664\n",
      "    update_time_ms: 6.998\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.489052284241545\n",
      "  time_since_restore: 2749.6839797496796\n",
      "  time_this_iter_s: 27.536128044128418\n",
      "  time_total_s: 2749.6839797496796\n",
      "  timestamp: 1554811043\n",
      "  timesteps_since_restore: 1040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 104\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2749 s, 104 iter, 1040000 ts, -67 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-57-53\n",
      "  done: false\n",
      "  episode_len_mean: 94.20560747663552\n",
      "  episode_reward_max: 14.524800957246455\n",
      "  episode_reward_mean: -68.03063646888234\n",
      "  episode_reward_min: -201.04506852584575\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 9644\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4853.163\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.9721527332502698e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7148193717002869\n",
      "      kl: 0.006158728618174791\n",
      "      policy_loss: -0.0016652628546580672\n",
      "      total_loss: 1394.7625732421875\n",
      "      vf_explained_var: 0.45522767305374146\n",
      "      vf_loss: 1394.7642822265625\n",
      "    sample_time_ms: 21841.249\n",
      "    update_time_ms: 7.117\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.01531823444116\n",
      "  time_since_restore: 2779.221018075943\n",
      "  time_this_iter_s: 29.537038326263428\n",
      "  time_total_s: 2779.221018075943\n",
      "  timestamp: 1554811073\n",
      "  timesteps_since_restore: 1050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 105\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2779 s, 105 iter, 1050000 ts, -68 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-58-22\n",
      "  done: false\n",
      "  episode_len_mean: 92.14018691588785\n",
      "  episode_reward_max: 14.851853442473562\n",
      "  episode_reward_mean: -73.03962332133149\n",
      "  episode_reward_min: -201.20916389145452\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 9751\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4737.179\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 1060000\n",
      "    num_steps_trained: 1060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.860763666251349e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7063418030738831\n",
      "      kl: 0.007378404028713703\n",
      "      policy_loss: -0.0020358574111014605\n",
      "      total_loss: 1369.300048828125\n",
      "      vf_explained_var: 0.4700121283531189\n",
      "      vf_loss: 1369.3021240234375\n",
      "    sample_time_ms: 21957.681\n",
      "    update_time_ms: 7.139\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.519811660665745\n",
      "  time_since_restore: 2808.0486183166504\n",
      "  time_this_iter_s: 28.827600240707397\n",
      "  time_total_s: 2808.0486183166504\n",
      "  timestamp: 1554811102\n",
      "  timesteps_since_restore: 1060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1060000\n",
      "  training_iteration: 106\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2808 s, 106 iter, 1060000 ts, -73 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-58-48\n",
      "  done: false\n",
      "  episode_len_mean: 94.98113207547169\n",
      "  episode_reward_max: 13.212754320273039\n",
      "  episode_reward_mean: -66.63885047570619\n",
      "  episode_reward_min: -201.46848582390584\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 9857\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4840.23\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 1070000\n",
      "    num_steps_trained: 1070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.9303818331256746e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.702870786190033\n",
      "      kl: 0.004763740114867687\n",
      "      policy_loss: -0.0012839249102398753\n",
      "      total_loss: 1382.637451171875\n",
      "      vf_explained_var: 0.45435217022895813\n",
      "      vf_loss: 1382.638671875\n",
      "    sample_time_ms: 22031.683\n",
      "    update_time_ms: 7.011\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.31942523785309\n",
      "  time_since_restore: 2833.949125766754\n",
      "  time_this_iter_s: 25.90050745010376\n",
      "  time_total_s: 2833.949125766754\n",
      "  timestamp: 1554811128\n",
      "  timesteps_since_restore: 1070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1070000\n",
      "  training_iteration: 107\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2833 s, 107 iter, 1070000 ts, -66.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-59-12\n",
      "  done: false\n",
      "  episode_len_mean: 83.18333333333334\n",
      "  episode_reward_max: 13.203823118985351\n",
      "  episode_reward_mean: -98.4742426921904\n",
      "  episode_reward_min: -200.8741510004479\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 9977\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4846.49\n",
      "    load_time_ms: 1.691\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4651909165628373e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7001216411590576\n",
      "      kl: 0.004361668601632118\n",
      "      policy_loss: -0.0008928672759793699\n",
      "      total_loss: 1312.91748046875\n",
      "      vf_explained_var: 0.5259613394737244\n",
      "      vf_loss: 1312.91845703125\n",
      "    sample_time_ms: 21982.822\n",
      "    update_time_ms: 5.762\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.23712134609518\n",
      "  time_since_restore: 2858.2288019657135\n",
      "  time_this_iter_s: 24.27967619895935\n",
      "  time_total_s: 2858.2288019657135\n",
      "  timestamp: 1554811152\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 108\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2858 s, 108 iter, 1080000 ts, -98.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_13-59-36\n",
      "  done: false\n",
      "  episode_len_mean: 91.85321100917432\n",
      "  episode_reward_max: 12.887953478583832\n",
      "  episode_reward_mean: -75.56262462262679\n",
      "  episode_reward_min: -201.09537817012693\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 10086\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4849.177\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 1090000\n",
      "    num_steps_trained: 1090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2325954582814187e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6948843002319336\n",
      "      kl: 0.004746666178107262\n",
      "      policy_loss: -0.00019881052139680833\n",
      "      total_loss: 1453.90478515625\n",
      "      vf_explained_var: 0.44305986166000366\n",
      "      vf_loss: 1453.9049072265625\n",
      "    sample_time_ms: 21909.44\n",
      "    update_time_ms: 5.867\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.78131231131339\n",
      "  time_since_restore: 2882.128294467926\n",
      "  time_this_iter_s: 23.899492502212524\n",
      "  time_total_s: 2882.128294467926\n",
      "  timestamp: 1554811176\n",
      "  timesteps_since_restore: 1090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1090000\n",
      "  training_iteration: 109\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2882 s, 109 iter, 1090000 ts, -75.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-00-01\n",
      "  done: false\n",
      "  episode_len_mean: 92.25\n",
      "  episode_reward_max: 10.638865122192843\n",
      "  episode_reward_mean: -72.45650105302485\n",
      "  episode_reward_min: -200.99637221002686\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 10194\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4730.22\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 1100000\n",
      "    num_steps_trained: 1100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.162977291407093e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6865118741989136\n",
      "      kl: 0.0056592789478600025\n",
      "      policy_loss: -0.002412928966805339\n",
      "      total_loss: 1420.468505859375\n",
      "      vf_explained_var: 0.4571181535720825\n",
      "      vf_loss: 1420.470947265625\n",
      "    sample_time_ms: 21875.674\n",
      "    update_time_ms: 5.706\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.228250526512426\n",
      "  time_since_restore: 2906.8249344825745\n",
      "  time_this_iter_s: 24.696640014648438\n",
      "  time_total_s: 2906.8249344825745\n",
      "  timestamp: 1554811201\n",
      "  timesteps_since_restore: 1100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1100000\n",
      "  training_iteration: 110\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2906 s, 110 iter, 1100000 ts, -72.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-00-26\n",
      "  done: false\n",
      "  episode_len_mean: 92.35185185185185\n",
      "  episode_reward_max: 10.126430522627935\n",
      "  episode_reward_mean: -73.06752990636221\n",
      "  episode_reward_min: -201.32301554234076\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 10302\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4725.019\n",
      "    load_time_ms: 1.692\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0814886457035466e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6726891994476318\n",
      "      kl: 0.008999135345220566\n",
      "      policy_loss: -0.0025880178436636925\n",
      "      total_loss: 1445.6876220703125\n",
      "      vf_explained_var: 0.45318514108657837\n",
      "      vf_loss: 1445.6903076171875\n",
      "    sample_time_ms: 21547.713\n",
      "    update_time_ms: 5.705\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.53376495318111\n",
      "  time_since_restore: 2931.6407222747803\n",
      "  time_this_iter_s: 24.81578779220581\n",
      "  time_total_s: 2931.6407222747803\n",
      "  timestamp: 1554811226\n",
      "  timesteps_since_restore: 1110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 111\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2931 s, 111 iter, 1110000 ts, -73.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-00-51\n",
      "  done: false\n",
      "  episode_len_mean: 91.72727272727273\n",
      "  episode_reward_max: 10.320626612479083\n",
      "  episode_reward_mean: -74.32031163060043\n",
      "  episode_reward_min: -201.0028638161682\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 10412\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4596.489\n",
      "    load_time_ms: 1.731\n",
      "    num_steps_sampled: 1120000\n",
      "    num_steps_trained: 1120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5407443228517733e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6785162091255188\n",
      "      kl: 0.004756656941026449\n",
      "      policy_loss: -0.0018933732062578201\n",
      "      total_loss: 1507.730712890625\n",
      "      vf_explained_var: 0.4212597608566284\n",
      "      vf_loss: 1507.7327880859375\n",
      "    sample_time_ms: 21549.568\n",
      "    update_time_ms: 5.598\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.16015581530022\n",
      "  time_since_restore: 2956.9328966140747\n",
      "  time_this_iter_s: 25.292174339294434\n",
      "  time_total_s: 2956.9328966140747\n",
      "  timestamp: 1554811251\n",
      "  timesteps_since_restore: 1120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1120000\n",
      "  training_iteration: 112\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2956 s, 112 iter, 1120000 ts, -74.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-01-15\n",
      "  done: false\n",
      "  episode_len_mean: 88.31858407079646\n",
      "  episode_reward_max: 8.974797597101727\n",
      "  episode_reward_mean: -85.60346331206931\n",
      "  episode_reward_min: -200.9446361473236\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 10525\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4500.615\n",
      "    load_time_ms: 1.733\n",
      "    num_steps_sampled: 1130000\n",
      "    num_steps_trained: 1130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.703721614258867e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6684615612030029\n",
      "      kl: 0.0049285865388810635\n",
      "      policy_loss: -0.0011198555584996939\n",
      "      total_loss: 1386.939697265625\n",
      "      vf_explained_var: 0.48801979422569275\n",
      "      vf_loss: 1386.9407958984375\n",
      "    sample_time_ms: 21296.104\n",
      "    update_time_ms: 5.624\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.801731656034654\n",
      "  time_since_restore: 2980.387311935425\n",
      "  time_this_iter_s: 23.454415321350098\n",
      "  time_total_s: 2980.387311935425\n",
      "  timestamp: 1554811275\n",
      "  timesteps_since_restore: 1130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1130000\n",
      "  training_iteration: 113\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 2980 s, 113 iter, 1130000 ts, -85.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-01-38\n",
      "  done: false\n",
      "  episode_len_mean: 89.54954954954955\n",
      "  episode_reward_max: 10.073178500607742\n",
      "  episode_reward_mean: -79.03862179997014\n",
      "  episode_reward_min: -200.9305255220726\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 10636\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4291.066\n",
      "    load_time_ms: 1.784\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.8518608071294333e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6684631109237671\n",
      "      kl: 0.004773502703756094\n",
      "      policy_loss: -0.0015488710487261415\n",
      "      total_loss: 1410.7508544921875\n",
      "      vf_explained_var: 0.4593009054660797\n",
      "      vf_loss: 1410.7523193359375\n",
      "    sample_time_ms: 21130.437\n",
      "    update_time_ms: 5.584\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.519310899985065\n",
      "  time_since_restore: 3004.1711049079895\n",
      "  time_this_iter_s: 23.783792972564697\n",
      "  time_total_s: 3004.1711049079895\n",
      "  timestamp: 1554811298\n",
      "  timesteps_since_restore: 1140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 114\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3004 s, 114 iter, 1140000 ts, -79 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-02-02\n",
      "  done: false\n",
      "  episode_len_mean: 90.61818181818182\n",
      "  episode_reward_max: 9.967566887979107\n",
      "  episode_reward_mean: -79.23509168915716\n",
      "  episode_reward_min: -201.04336419517898\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 10746\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4305.658\n",
      "    load_time_ms: 1.82\n",
      "    num_steps_sampled: 1150000\n",
      "    num_steps_trained: 1150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.9259304035647166e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6574600338935852\n",
      "      kl: 0.003993293270468712\n",
      "      policy_loss: -0.0009722694521769881\n",
      "      total_loss: 1403.0242919921875\n",
      "      vf_explained_var: 0.44806405901908875\n",
      "      vf_loss: 1403.0252685546875\n",
      "    sample_time_ms: 20542.736\n",
      "    update_time_ms: 5.617\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.6175458445786\n",
      "  time_since_restore: 3027.9741218090057\n",
      "  time_this_iter_s: 23.803016901016235\n",
      "  time_total_s: 3027.9741218090057\n",
      "  timestamp: 1554811322\n",
      "  timesteps_since_restore: 1150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1150000\n",
      "  training_iteration: 115\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3027 s, 115 iter, 1150000 ts, -79.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-02-31\n",
      "  done: false\n",
      "  episode_len_mean: 92.87962962962963\n",
      "  episode_reward_max: 11.773926690028972\n",
      "  episode_reward_mean: -72.28571432815535\n",
      "  episode_reward_min: -201.4421616627027\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 10854\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4293.724\n",
      "    load_time_ms: 1.818\n",
      "    num_steps_sampled: 1160000\n",
      "    num_steps_trained: 1160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.629652017823583e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.641748309135437\n",
      "      kl: 0.006262464448809624\n",
      "      policy_loss: -0.0016866514924913645\n",
      "      total_loss: 1476.253662109375\n",
      "      vf_explained_var: 0.41198328137397766\n",
      "      vf_loss: 1476.25537109375\n",
      "    sample_time_ms: 20508.813\n",
      "    update_time_ms: 5.539\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.142857164077675\n",
      "  time_since_restore: 3056.34233045578\n",
      "  time_this_iter_s: 28.368208646774292\n",
      "  time_total_s: 3056.34233045578\n",
      "  timestamp: 1554811351\n",
      "  timesteps_since_restore: 1160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1160000\n",
      "  training_iteration: 116\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3056 s, 116 iter, 1160000 ts, -72.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-02-54\n",
      "  done: false\n",
      "  episode_len_mean: 93.85046728971963\n",
      "  episode_reward_max: 10.079716014473215\n",
      "  episode_reward_mean: -70.23512878197421\n",
      "  episode_reward_min: -201.25751657734418\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 10961\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4180.288\n",
      "    load_time_ms: 1.711\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.8148260089117916e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6436289548873901\n",
      "      kl: 0.004443586803972721\n",
      "      policy_loss: -0.00152000249363482\n",
      "      total_loss: 1476.440673828125\n",
      "      vf_explained_var: 0.3923780024051666\n",
      "      vf_loss: 1476.4422607421875\n",
      "    sample_time_ms: 20407.708\n",
      "    update_time_ms: 5.578\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.117564390987106\n",
      "  time_since_restore: 3080.0947601795197\n",
      "  time_this_iter_s: 23.752429723739624\n",
      "  time_total_s: 3080.0947601795197\n",
      "  timestamp: 1554811374\n",
      "  timesteps_since_restore: 1170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 117\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3080 s, 117 iter, 1170000 ts, -70.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-03-18\n",
      "  done: false\n",
      "  episode_len_mean: 90.53636363636363\n",
      "  episode_reward_max: 12.470980368967838\n",
      "  episode_reward_mean: -76.63550749221304\n",
      "  episode_reward_min: -200.58100006744047\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 11071\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4175.971\n",
      "    load_time_ms: 1.703\n",
      "    num_steps_sampled: 1180000\n",
      "    num_steps_trained: 1180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4074130044558958e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6376120448112488\n",
      "      kl: 0.008367870934307575\n",
      "      policy_loss: -0.003405024530366063\n",
      "      total_loss: 1466.2882080078125\n",
      "      vf_explained_var: 0.3871391713619232\n",
      "      vf_loss: 1466.2918701171875\n",
      "    sample_time_ms: 20333.758\n",
      "    update_time_ms: 5.517\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.317753746106526\n",
      "  time_since_restore: 3103.590049982071\n",
      "  time_this_iter_s: 23.49528980255127\n",
      "  time_total_s: 3103.590049982071\n",
      "  timestamp: 1554811398\n",
      "  timesteps_since_restore: 1180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1180000\n",
      "  training_iteration: 118\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3103 s, 118 iter, 1180000 ts, -76.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-03-42\n",
      "  done: false\n",
      "  episode_len_mean: 90.74774774774775\n",
      "  episode_reward_max: 12.25806354058453\n",
      "  episode_reward_mean: -79.86433540043275\n",
      "  episode_reward_min: -200.96411593953837\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 11182\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4179.566\n",
      "    load_time_ms: 1.774\n",
      "    num_steps_sampled: 1190000\n",
      "    num_steps_trained: 1190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2037065022279479e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6238279938697815\n",
      "      kl: 0.0076059880666434765\n",
      "      policy_loss: -0.0027227981481701136\n",
      "      total_loss: 1441.398193359375\n",
      "      vf_explained_var: 0.43320879340171814\n",
      "      vf_loss: 1441.4010009765625\n",
      "    sample_time_ms: 20300.883\n",
      "    update_time_ms: 5.361\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.93216770021637\n",
      "  time_since_restore: 3127.1998541355133\n",
      "  time_this_iter_s: 23.609804153442383\n",
      "  time_total_s: 3127.1998541355133\n",
      "  timestamp: 1554811422\n",
      "  timesteps_since_restore: 1190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1190000\n",
      "  training_iteration: 119\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3127 s, 119 iter, 1190000 ts, -79.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-04-06\n",
      "  done: false\n",
      "  episode_len_mean: 90.46363636363637\n",
      "  episode_reward_max: 10.520507504619285\n",
      "  episode_reward_mean: -79.73284138893487\n",
      "  episode_reward_min: -201.25338287228325\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 11292\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4177.501\n",
      "    load_time_ms: 1.747\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.0185325111397395e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6085778474807739\n",
      "      kl: 0.007076913956552744\n",
      "      policy_loss: -0.0016099050408229232\n",
      "      total_loss: 1385.6744384765625\n",
      "      vf_explained_var: 0.44420018792152405\n",
      "      vf_loss: 1385.6761474609375\n",
      "    sample_time_ms: 20285.775\n",
      "    update_time_ms: 5.306\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.86642069446744\n",
      "  time_since_restore: 3151.7224435806274\n",
      "  time_this_iter_s: 24.522589445114136\n",
      "  time_total_s: 3151.7224435806274\n",
      "  timestamp: 1554811446\n",
      "  timesteps_since_restore: 1200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 120\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3151 s, 120 iter, 1200000 ts, -79.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-04-30\n",
      "  done: false\n",
      "  episode_len_mean: 86.9396551724138\n",
      "  episode_reward_max: 10.543910174312362\n",
      "  episode_reward_mean: -89.52818074823477\n",
      "  episode_reward_min: -201.1740065404848\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 11408\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4175.276\n",
      "    load_time_ms: 1.809\n",
      "    num_steps_sampled: 1210000\n",
      "    num_steps_trained: 1210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0092662555698698e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6085827350616455\n",
      "      kl: 0.006973233073949814\n",
      "      policy_loss: -0.002883837791159749\n",
      "      total_loss: 1322.2642822265625\n",
      "      vf_explained_var: 0.49343156814575195\n",
      "      vf_loss: 1322.26708984375\n",
      "    sample_time_ms: 20194.154\n",
      "    update_time_ms: 5.366\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.7640903741174\n",
      "  time_since_restore: 3175.600809812546\n",
      "  time_this_iter_s: 23.878366231918335\n",
      "  time_total_s: 3175.600809812546\n",
      "  timestamp: 1554811470\n",
      "  timesteps_since_restore: 1210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1210000\n",
      "  training_iteration: 121\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3175 s, 121 iter, 1210000 ts, -89.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-04-53\n",
      "  done: false\n",
      "  episode_len_mean: 91.02752293577981\n",
      "  episode_reward_max: 9.73517125856017\n",
      "  episode_reward_mean: -76.60189202808108\n",
      "  episode_reward_min: -200.68220977723766\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 11517\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4173.912\n",
      "    load_time_ms: 1.768\n",
      "    num_steps_sampled: 1220000\n",
      "    num_steps_trained: 1220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5046331277849349e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5928190350532532\n",
      "      kl: 0.007278570905327797\n",
      "      policy_loss: -0.0027300615329295397\n",
      "      total_loss: 1396.46533203125\n",
      "      vf_explained_var: 0.454641729593277\n",
      "      vf_loss: 1396.4681396484375\n",
      "    sample_time_ms: 19999.343\n",
      "    update_time_ms: 5.352\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.30094601404055\n",
      "  time_since_restore: 3198.928158760071\n",
      "  time_this_iter_s: 23.327348947525024\n",
      "  time_total_s: 3198.928158760071\n",
      "  timestamp: 1554811493\n",
      "  timesteps_since_restore: 1220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1220000\n",
      "  training_iteration: 122\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3198 s, 122 iter, 1220000 ts, -76.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-05-18\n",
      "  done: false\n",
      "  episode_len_mean: 94.54285714285714\n",
      "  episode_reward_max: 8.696356852358972\n",
      "  episode_reward_mean: -69.17423010287679\n",
      "  episode_reward_min: -201.00567599628408\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 11622\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4173.926\n",
      "    load_time_ms: 1.801\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.523165638924674e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5864006280899048\n",
      "      kl: 0.005352736450731754\n",
      "      policy_loss: -0.001257753581739962\n",
      "      total_loss: 1491.5322265625\n",
      "      vf_explained_var: 0.4243628680706024\n",
      "      vf_loss: 1491.5335693359375\n",
      "    sample_time_ms: 20085.755\n",
      "    update_time_ms: 5.425\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.58711505143839\n",
      "  time_since_restore: 3223.2497091293335\n",
      "  time_this_iter_s: 24.321550369262695\n",
      "  time_total_s: 3223.2497091293335\n",
      "  timestamp: 1554811518\n",
      "  timesteps_since_restore: 1230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 123\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3223 s, 123 iter, 1230000 ts, -69.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-05-42\n",
      "  done: false\n",
      "  episode_len_mean: 89.19469026548673\n",
      "  episode_reward_max: 8.905845322412418\n",
      "  episode_reward_mean: -82.83973063948339\n",
      "  episode_reward_min: -200.57095371952303\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 11735\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4172.982\n",
      "    load_time_ms: 1.75\n",
      "    num_steps_sampled: 1240000\n",
      "    num_steps_trained: 1240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.761582819462337e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5763477087020874\n",
      "      kl: 0.0042583835311234\n",
      "      policy_loss: -0.0005129331257194281\n",
      "      total_loss: 1424.371337890625\n",
      "      vf_explained_var: 0.46207037568092346\n",
      "      vf_loss: 1424.371826171875\n",
      "    sample_time_ms: 20118.67\n",
      "    update_time_ms: 5.395\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.41986531974169\n",
      "  time_since_restore: 3247.3503065109253\n",
      "  time_this_iter_s: 24.100597381591797\n",
      "  time_total_s: 3247.3503065109253\n",
      "  timestamp: 1554811542\n",
      "  timesteps_since_restore: 1240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1240000\n",
      "  training_iteration: 124\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3247 s, 124 iter, 1240000 ts, -82.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-06-06\n",
      "  done: false\n",
      "  episode_len_mean: 89.67857142857143\n",
      "  episode_reward_max: 8.099607070386373\n",
      "  episode_reward_mean: -80.56820629857555\n",
      "  episode_reward_min: -200.6270679038837\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 11847\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4152.794\n",
      "    load_time_ms: 1.74\n",
      "    num_steps_sampled: 1250000\n",
      "    num_steps_trained: 1250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8807914097311686e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5796895027160645\n",
      "      kl: 0.005059698596596718\n",
      "      policy_loss: -0.0016704683657735586\n",
      "      total_loss: 1374.5018310546875\n",
      "      vf_explained_var: 0.4581191837787628\n",
      "      vf_loss: 1374.5032958984375\n",
      "    sample_time_ms: 20189.466\n",
      "    update_time_ms: 5.205\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.284103149287766\n",
      "  time_since_restore: 3271.6610219478607\n",
      "  time_this_iter_s: 24.310715436935425\n",
      "  time_total_s: 3271.6610219478607\n",
      "  timestamp: 1554811566\n",
      "  timesteps_since_restore: 1250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1250000\n",
      "  training_iteration: 125\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3271 s, 125 iter, 1250000 ts, -80.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-06-30\n",
      "  done: false\n",
      "  episode_len_mean: 89.1875\n",
      "  episode_reward_max: 8.204192255749941\n",
      "  episode_reward_mean: -81.58688026364045\n",
      "  episode_reward_min: -200.5879473139545\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 11959\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4150.331\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.403955647357379e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.576238214969635\n",
      "      kl: 0.005156892351806164\n",
      "      policy_loss: -0.0019432008266448975\n",
      "      total_loss: 1393.2659912109375\n",
      "      vf_explained_var: 0.44839906692504883\n",
      "      vf_loss: 1393.2679443359375\n",
      "    sample_time_ms: 19755.047\n",
      "    update_time_ms: 5.419\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.79344013182024\n",
      "  time_since_restore: 3295.662501811981\n",
      "  time_this_iter_s: 24.001479864120483\n",
      "  time_total_s: 3295.662501811981\n",
      "  timestamp: 1554811590\n",
      "  timesteps_since_restore: 1260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 126\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3295 s, 126 iter, 1260000 ts, -81.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-06-53\n",
      "  done: false\n",
      "  episode_len_mean: 89.72072072072072\n",
      "  episode_reward_max: 8.235544137456897\n",
      "  episode_reward_mean: -81.033761603594\n",
      "  episode_reward_min: -200.70810966595616\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 12070\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4144.377\n",
      "    load_time_ms: 1.667\n",
      "    num_steps_sampled: 1270000\n",
      "    num_steps_trained: 1270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.701977123029457e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.575576663017273\n",
      "      kl: 0.0062291440553963184\n",
      "      policy_loss: -0.002444624900817871\n",
      "      total_loss: 1398.8634033203125\n",
      "      vf_explained_var: 0.460130900144577\n",
      "      vf_loss: 1398.86572265625\n",
      "    sample_time_ms: 19660.931\n",
      "    update_time_ms: 5.501\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.516880801797\n",
      "  time_since_restore: 3318.4145834445953\n",
      "  time_this_iter_s: 22.752081632614136\n",
      "  time_total_s: 3318.4145834445953\n",
      "  timestamp: 1554811613\n",
      "  timesteps_since_restore: 1270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1270000\n",
      "  training_iteration: 127\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3318 s, 127 iter, 1270000 ts, -81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-07-18\n",
      "  done: false\n",
      "  episode_len_mean: 82.82644628099173\n",
      "  episode_reward_max: 7.495489375582039\n",
      "  episode_reward_mean: -99.14331190983748\n",
      "  episode_reward_min: -200.7613853429547\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 12191\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4238.121\n",
      "    load_time_ms: 1.712\n",
      "    num_steps_sampled: 1280000\n",
      "    num_steps_trained: 1280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3509892621639607e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5655191540718079\n",
      "      kl: 0.006191942375153303\n",
      "      policy_loss: -0.0014650978846475482\n",
      "      total_loss: 1362.7467041015625\n",
      "      vf_explained_var: 0.5288986563682556\n",
      "      vf_loss: 1362.7481689453125\n",
      "    sample_time_ms: 19721.497\n",
      "    update_time_ms: 5.55\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.57165595491874\n",
      "  time_since_restore: 3343.4570546150208\n",
      "  time_this_iter_s: 25.042471170425415\n",
      "  time_total_s: 3343.4570546150208\n",
      "  timestamp: 1554811638\n",
      "  timesteps_since_restore: 1280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1280000\n",
      "  training_iteration: 128\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3343 s, 128 iter, 1280000 ts, -99.1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-07-43\n",
      "  done: false\n",
      "  episode_len_mean: 99.43\n",
      "  episode_reward_max: 7.2591075337985735\n",
      "  episode_reward_mean: -57.04698642384553\n",
      "  episode_reward_min: -200.7021090440061\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 12291\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4227.969\n",
      "    load_time_ms: 1.636\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1754946310819804e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5695739388465881\n",
      "      kl: 0.007411550264805555\n",
      "      policy_loss: -0.0025158654898405075\n",
      "      total_loss: 1437.813720703125\n",
      "      vf_explained_var: 0.41832923889160156\n",
      "      vf_loss: 1437.816162109375\n",
      "    sample_time_ms: 19802.261\n",
      "    update_time_ms: 5.67\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -28.523493211922766\n",
      "  time_since_restore: 3367.7697200775146\n",
      "  time_this_iter_s: 24.312665462493896\n",
      "  time_total_s: 3367.7697200775146\n",
      "  timestamp: 1554811663\n",
      "  timesteps_since_restore: 1290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 129\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3367 s, 129 iter, 1290000 ts, -57 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-08-07\n",
      "  done: false\n",
      "  episode_len_mean: 90.41964285714286\n",
      "  episode_reward_max: 7.3302416739118375\n",
      "  episode_reward_mean: -80.632633777633\n",
      "  episode_reward_min: -200.4827146694494\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 12403\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4231.076\n",
      "    load_time_ms: 1.604\n",
      "    num_steps_sampled: 1300000\n",
      "    num_steps_trained: 1300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.87746614891758e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5495852828025818\n",
      "      kl: 0.006260564085096121\n",
      "      policy_loss: -0.0016730546485632658\n",
      "      total_loss: 1382.7652587890625\n",
      "      vf_explained_var: 0.4796208143234253\n",
      "      vf_loss: 1382.766845703125\n",
      "    sample_time_ms: 19737.383\n",
      "    update_time_ms: 5.803\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.3163168888165\n",
      "  time_since_restore: 3391.678850412369\n",
      "  time_this_iter_s: 23.909130334854126\n",
      "  time_total_s: 3391.678850412369\n",
      "  timestamp: 1554811687\n",
      "  timesteps_since_restore: 1300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1300000\n",
      "  training_iteration: 130\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3391 s, 130 iter, 1300000 ts, -80.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-08-31\n",
      "  done: false\n",
      "  episode_len_mean: 92.90566037735849\n",
      "  episode_reward_max: 8.011723978459024\n",
      "  episode_reward_mean: -71.39815571047389\n",
      "  episode_reward_min: -200.49654771886014\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 12509\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4234.614\n",
      "    load_time_ms: 1.616\n",
      "    num_steps_sampled: 1310000\n",
      "    num_steps_trained: 1310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.93873307445879e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5400283932685852\n",
      "      kl: 0.0051874807104468346\n",
      "      policy_loss: -0.0013749463250860572\n",
      "      total_loss: 1472.529296875\n",
      "      vf_explained_var: 0.4223276674747467\n",
      "      vf_loss: 1472.5306396484375\n",
      "    sample_time_ms: 19770.278\n",
      "    update_time_ms: 5.589\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.69907785523696\n",
      "  time_since_restore: 3415.9212040901184\n",
      "  time_this_iter_s: 24.242353677749634\n",
      "  time_total_s: 3415.9212040901184\n",
      "  timestamp: 1554811711\n",
      "  timesteps_since_restore: 1310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1310000\n",
      "  training_iteration: 131\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3415 s, 131 iter, 1310000 ts, -71.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-08-56\n",
      "  done: false\n",
      "  episode_len_mean: 90.22321428571429\n",
      "  episode_reward_max: 6.830491861021536\n",
      "  episode_reward_mean: -80.05070688717119\n",
      "  episode_reward_min: -200.4498964882058\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 12621\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4311.876\n",
      "    load_time_ms: 1.687\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4693735437217167e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5382491946220398\n",
      "      kl: 0.005343020427972078\n",
      "      policy_loss: -0.0010946488473564386\n",
      "      total_loss: 1423.9947509765625\n",
      "      vf_explained_var: 0.43741264939308167\n",
      "      vf_loss: 1423.995849609375\n",
      "    sample_time_ms: 19852.565\n",
      "    update_time_ms: 5.806\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.025353443585594\n",
      "  time_since_restore: 3440.8478276729584\n",
      "  time_this_iter_s: 24.926623582839966\n",
      "  time_total_s: 3440.8478276729584\n",
      "  timestamp: 1554811736\n",
      "  timesteps_since_restore: 1320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 132\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3440 s, 132 iter, 1320000 ts, -80.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-09-20\n",
      "  done: false\n",
      "  episode_len_mean: 83.60504201680672\n",
      "  episode_reward_max: 7.762989973244586\n",
      "  episode_reward_mean: -99.39233646667148\n",
      "  episode_reward_min: -200.62609025563614\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 12740\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4312.051\n",
      "    load_time_ms: 1.678\n",
      "    num_steps_sampled: 1330000\n",
      "    num_steps_trained: 1330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.346867718608583e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5276400446891785\n",
      "      kl: 0.004985780455172062\n",
      "      policy_loss: -0.0013144296826794744\n",
      "      total_loss: 1336.8446044921875\n",
      "      vf_explained_var: 0.5064560174942017\n",
      "      vf_loss: 1336.8458251953125\n",
      "    sample_time_ms: 19876.909\n",
      "    update_time_ms: 5.687\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.696168233335754\n",
      "  time_since_restore: 3465.4145057201385\n",
      "  time_this_iter_s: 24.566678047180176\n",
      "  time_total_s: 3465.4145057201385\n",
      "  timestamp: 1554811760\n",
      "  timesteps_since_restore: 1330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1330000\n",
      "  training_iteration: 133\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3465 s, 133 iter, 1330000 ts, -99.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-09-45\n",
      "  done: false\n",
      "  episode_len_mean: 89.75\n",
      "  episode_reward_max: 7.461549153822463\n",
      "  episode_reward_mean: -83.86948904324979\n",
      "  episode_reward_min: -200.6686016920333\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 12852\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4319.073\n",
      "    load_time_ms: 1.711\n",
      "    num_steps_sampled: 1340000\n",
      "    num_steps_trained: 1340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6733637943810755e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5185015797615051\n",
      "      kl: 0.008375751785933971\n",
      "      policy_loss: -0.0020104916766285896\n",
      "      total_loss: 1385.0006103515625\n",
      "      vf_explained_var: 0.49867844581604004\n",
      "      vf_loss: 1385.0025634765625\n",
      "    sample_time_ms: 19911.089\n",
      "    update_time_ms: 5.69\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.93474452162489\n",
      "  time_since_restore: 3489.9290356636047\n",
      "  time_this_iter_s: 24.514529943466187\n",
      "  time_total_s: 3489.9290356636047\n",
      "  timestamp: 1554811785\n",
      "  timesteps_since_restore: 1340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1340000\n",
      "  training_iteration: 134\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3489 s, 134 iter, 1340000 ts, -83.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-10-12\n",
      "  done: false\n",
      "  episode_len_mean: 92.1743119266055\n",
      "  episode_reward_max: 7.988025274376085\n",
      "  episode_reward_mean: -73.00808400832524\n",
      "  episode_reward_min: -200.32959172270756\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 12961\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4352.762\n",
      "    load_time_ms: 1.673\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8366818971905377e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5168645977973938\n",
      "      kl: 0.006562141235917807\n",
      "      policy_loss: -0.0028194456826895475\n",
      "      total_loss: 1426.4217529296875\n",
      "      vf_explained_var: 0.4511100649833679\n",
      "      vf_loss: 1426.424560546875\n",
      "    sample_time_ms: 20128.04\n",
      "    update_time_ms: 5.903\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.50404200416262\n",
      "  time_since_restore: 3516.7451713085175\n",
      "  time_this_iter_s: 26.81613564491272\n",
      "  time_total_s: 3516.7451713085175\n",
      "  timestamp: 1554811812\n",
      "  timesteps_since_restore: 1350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 135\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3516 s, 135 iter, 1350000 ts, -73 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-10-37\n",
      "  done: false\n",
      "  episode_len_mean: 88.49549549549549\n",
      "  episode_reward_max: 6.474143341527744\n",
      "  episode_reward_mean: -86.42182669281783\n",
      "  episode_reward_min: -200.35153464386977\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 13072\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4355.025\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 1360000\n",
      "    num_steps_trained: 1360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.184110135184851e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5054977536201477\n",
      "      kl: 0.00635699275881052\n",
      "      policy_loss: -0.0010775598930194974\n",
      "      total_loss: 1360.6470947265625\n",
      "      vf_explained_var: 0.48752066493034363\n",
      "      vf_loss: 1360.64794921875\n",
      "    sample_time_ms: 20222.66\n",
      "    update_time_ms: 5.856\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.21091334640893\n",
      "  time_since_restore: 3541.713198900223\n",
      "  time_this_iter_s: 24.968027591705322\n",
      "  time_total_s: 3541.713198900223\n",
      "  timestamp: 1554811837\n",
      "  timesteps_since_restore: 1360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1360000\n",
      "  training_iteration: 136\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3541 s, 136 iter, 1360000 ts, -86.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-11-03\n",
      "  done: false\n",
      "  episode_len_mean: 89.97321428571429\n",
      "  episode_reward_max: 6.777318531260474\n",
      "  episode_reward_mean: -81.60403577119233\n",
      "  episode_reward_min: -200.26667924060945\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 13184\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4361.442\n",
      "    load_time_ms: 1.7\n",
      "    num_steps_sampled: 1370000\n",
      "    num_steps_trained: 1370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.5920550675924255e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5074676871299744\n",
      "      kl: 0.005777306854724884\n",
      "      policy_loss: -0.0021570497192442417\n",
      "      total_loss: 1403.5753173828125\n",
      "      vf_explained_var: 0.48116132616996765\n",
      "      vf_loss: 1403.5772705078125\n",
      "    sample_time_ms: 20505.006\n",
      "    update_time_ms: 5.795\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.80201788559617\n",
      "  time_since_restore: 3567.3537945747375\n",
      "  time_this_iter_s: 25.64059567451477\n",
      "  time_total_s: 3567.3537945747375\n",
      "  timestamp: 1554811863\n",
      "  timesteps_since_restore: 1370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1370000\n",
      "  training_iteration: 137\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3567 s, 137 iter, 1370000 ts, -81.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-11-28\n",
      "  done: false\n",
      "  episode_len_mean: 87.75438596491227\n",
      "  episode_reward_max: 7.229439832467568\n",
      "  episode_reward_mean: -87.8863339946974\n",
      "  episode_reward_min: -200.52098734270572\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 13298\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4286.443\n",
      "    load_time_ms: 1.664\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2953268845640504e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5062771439552307\n",
      "      kl: 0.006511659361422062\n",
      "      policy_loss: -0.0010620775865390897\n",
      "      total_loss: 1393.0106201171875\n",
      "      vf_explained_var: 0.4612603187561035\n",
      "      vf_loss: 1393.011474609375\n",
      "    sample_time_ms: 20574.964\n",
      "    update_time_ms: 5.729\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.94316699734868\n",
      "  time_since_restore: 3592.3410840034485\n",
      "  time_this_iter_s: 24.987289428710938\n",
      "  time_total_s: 3592.3410840034485\n",
      "  timestamp: 1554811888\n",
      "  timesteps_since_restore: 1380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 138\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3592 s, 138 iter, 1380000 ts, -87.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-11-53\n",
      "  done: false\n",
      "  episode_len_mean: 87.47787610619469\n",
      "  episode_reward_max: 6.395915911162001\n",
      "  episode_reward_mean: -86.6573874128552\n",
      "  episode_reward_min: -200.44436003375625\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 13411\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4323.436\n",
      "    load_time_ms: 1.712\n",
      "    num_steps_sampled: 1390000\n",
      "    num_steps_trained: 1390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1476634422820252e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5002812147140503\n",
      "      kl: 0.0072896708734333515\n",
      "      policy_loss: -0.0013852196279913187\n",
      "      total_loss: 1365.01806640625\n",
      "      vf_explained_var: 0.4897818863391876\n",
      "      vf_loss: 1365.01953125\n",
      "    sample_time_ms: 20658.437\n",
      "    update_time_ms: 5.559\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.3286937064276\n",
      "  time_since_restore: 3617.8575191497803\n",
      "  time_this_iter_s: 25.516435146331787\n",
      "  time_total_s: 3617.8575191497803\n",
      "  timestamp: 1554811913\n",
      "  timesteps_since_restore: 1390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1390000\n",
      "  training_iteration: 139\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3617 s, 139 iter, 1390000 ts, -86.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-12-17\n",
      "  done: false\n",
      "  episode_len_mean: 86.94017094017094\n",
      "  episode_reward_max: 6.9403164476752295\n",
      "  episode_reward_mean: -88.98763519562172\n",
      "  episode_reward_min: -200.317571291991\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 13528\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4322.889\n",
      "    load_time_ms: 1.775\n",
      "    num_steps_sampled: 1400000\n",
      "    num_steps_trained: 1400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.74532370373175e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48776695132255554\n",
      "      kl: 0.006457045208662748\n",
      "      policy_loss: -0.001490337192080915\n",
      "      total_loss: 1307.9779052734375\n",
      "      vf_explained_var: 0.5386092066764832\n",
      "      vf_loss: 1307.9796142578125\n",
      "    sample_time_ms: 20675.698\n",
      "    update_time_ms: 5.861\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.49381759781086\n",
      "  time_since_restore: 3641.938529253006\n",
      "  time_this_iter_s: 24.081010103225708\n",
      "  time_total_s: 3641.938529253006\n",
      "  timestamp: 1554811937\n",
      "  timesteps_since_restore: 1400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1400000\n",
      "  training_iteration: 140\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3641 s, 140 iter, 1400000 ts, -89 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-12-41\n",
      "  done: false\n",
      "  episode_len_mean: 86.46551724137932\n",
      "  episode_reward_max: 6.323600731319942\n",
      "  episode_reward_mean: -91.30756062756946\n",
      "  episode_reward_min: -200.40456319354\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 13644\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4320.159\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.872661851865875e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48148491978645325\n",
      "      kl: 0.005870245397090912\n",
      "      policy_loss: -0.0013852509437128901\n",
      "      total_loss: 1369.4903564453125\n",
      "      vf_explained_var: 0.5179959535598755\n",
      "      vf_loss: 1369.4918212890625\n",
      "    sample_time_ms: 20656.295\n",
      "    update_time_ms: 6.068\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.653780313784736\n",
      "  time_since_restore: 3665.959460735321\n",
      "  time_this_iter_s: 24.020931482315063\n",
      "  time_total_s: 3665.959460735321\n",
      "  timestamp: 1554811961\n",
      "  timesteps_since_restore: 1410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 141\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3665 s, 141 iter, 1410000 ts, -91.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-13-06\n",
      "  done: false\n",
      "  episode_len_mean: 90.91743119266054\n",
      "  episode_reward_max: 7.047811471117021\n",
      "  episode_reward_mean: -77.1447757956751\n",
      "  episode_reward_min: -200.27862091533206\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 13753\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4241.913\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 1420000\n",
      "    num_steps_trained: 1420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4293244336113134e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.47442689538002014\n",
      "      kl: 0.006880016066133976\n",
      "      policy_loss: -0.0018740525702014565\n",
      "      total_loss: 1454.7193603515625\n",
      "      vf_explained_var: 0.45555025339126587\n",
      "      vf_loss: 1454.7213134765625\n",
      "    sample_time_ms: 20749.174\n",
      "    update_time_ms: 5.996\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.572387897837565\n",
      "  time_since_restore: 3691.030976295471\n",
      "  time_this_iter_s: 25.071515560150146\n",
      "  time_total_s: 3691.030976295471\n",
      "  timestamp: 1554811986\n",
      "  timesteps_since_restore: 1420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1420000\n",
      "  training_iteration: 142\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3691 s, 142 iter, 1420000 ts, -77.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-13-30\n",
      "  done: false\n",
      "  episode_len_mean: 86.99137931034483\n",
      "  episode_reward_max: 8.208340648519501\n",
      "  episode_reward_mean: -87.6472776373393\n",
      "  episode_reward_min: -200.30369027582114\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 13869\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4239.752\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 1430000\n",
      "    num_steps_trained: 1430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.146622168056567e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4631726145744324\n",
      "      kl: 0.005029669962823391\n",
      "      policy_loss: -0.0008021270041354001\n",
      "      total_loss: 1412.86279296875\n",
      "      vf_explained_var: 0.4812152683734894\n",
      "      vf_loss: 1412.863525390625\n",
      "    sample_time_ms: 20696.047\n",
      "    update_time_ms: 6.039\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.82363881866965\n",
      "  time_since_restore: 3715.0417580604553\n",
      "  time_this_iter_s: 24.01078176498413\n",
      "  time_total_s: 3715.0417580604553\n",
      "  timestamp: 1554812010\n",
      "  timesteps_since_restore: 1430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1430000\n",
      "  training_iteration: 143\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3715 s, 143 iter, 1430000 ts, -87.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-13-55\n",
      "  done: false\n",
      "  episode_len_mean: 88.22321428571429\n",
      "  episode_reward_max: 7.7717779009665655\n",
      "  episode_reward_mean: -87.8042868997941\n",
      "  episode_reward_min: -200.22823049114388\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 13981\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4235.631\n",
      "    load_time_ms: 1.57\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6433760072445244e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4535863399505615\n",
      "      kl: 0.0066632782109081745\n",
      "      policy_loss: -0.0019299000268802047\n",
      "      total_loss: 1406.975341796875\n",
      "      vf_explained_var: 0.49583113193511963\n",
      "      vf_loss: 1406.9771728515625\n",
      "    sample_time_ms: 20654.549\n",
      "    update_time_ms: 5.997\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.90214344989706\n",
      "  time_since_restore: 3739.1018676757812\n",
      "  time_this_iter_s: 24.060109615325928\n",
      "  time_total_s: 3739.1018676757812\n",
      "  timestamp: 1554812035\n",
      "  timesteps_since_restore: 1440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 144\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3739 s, 144 iter, 1440000 ts, -87.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-14-21\n",
      "  done: false\n",
      "  episode_len_mean: 94.19626168224299\n",
      "  episode_reward_max: 7.744306652348826\n",
      "  episode_reward_mean: -68.74162317977482\n",
      "  episode_reward_min: -200.22193907564665\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 14088\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4217.123\n",
      "    load_time_ms: 1.58\n",
      "    num_steps_sampled: 1450000\n",
      "    num_steps_trained: 1450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8216880036222622e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.45043256878852844\n",
      "      kl: 0.006161588244140148\n",
      "      policy_loss: -0.0012231034925207496\n",
      "      total_loss: 1424.445068359375\n",
      "      vf_explained_var: 0.4335927665233612\n",
      "      vf_loss: 1424.4462890625\n",
      "    sample_time_ms: 20620.765\n",
      "    update_time_ms: 5.847\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.37081158988741\n",
      "  time_since_restore: 3765.3953268527985\n",
      "  time_this_iter_s: 26.293459177017212\n",
      "  time_total_s: 3765.3953268527985\n",
      "  timestamp: 1554812061\n",
      "  timesteps_since_restore: 1450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1450000\n",
      "  training_iteration: 145\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3765 s, 145 iter, 1450000 ts, -68.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-14-45\n",
      "  done: false\n",
      "  episode_len_mean: 92.41666666666667\n",
      "  episode_reward_max: 6.535632525940627\n",
      "  episode_reward_mean: -76.47738347020116\n",
      "  episode_reward_min: -200.41517482177238\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 14196\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4214.343\n",
      "    load_time_ms: 1.618\n",
      "    num_steps_sampled: 1460000\n",
      "    num_steps_trained: 1460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.407790785948902e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4379827678203583\n",
      "      kl: 0.005962305702269077\n",
      "      policy_loss: -0.0020644045434892178\n",
      "      total_loss: 1386.6781005859375\n",
      "      vf_explained_var: 0.4430955648422241\n",
      "      vf_loss: 1386.68017578125\n",
      "    sample_time_ms: 20526.858\n",
      "    update_time_ms: 5.826\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.238691735100595\n",
      "  time_since_restore: 3789.398455142975\n",
      "  time_this_iter_s: 24.00312829017639\n",
      "  time_total_s: 3789.398455142975\n",
      "  timestamp: 1554812085\n",
      "  timesteps_since_restore: 1460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1460000\n",
      "  training_iteration: 146\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3789 s, 146 iter, 1460000 ts, -76.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-15-17\n",
      "  done: false\n",
      "  episode_len_mean: 82.46280991735537\n",
      "  episode_reward_max: 7.542172922612817\n",
      "  episode_reward_mean: -101.06527683130601\n",
      "  episode_reward_min: -200.27122005957017\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 14317\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4380.239\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.203895392974451e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4249061048030853\n",
      "      kl: 0.003982802387326956\n",
      "      policy_loss: -0.00023448982392437756\n",
      "      total_loss: 1301.830810546875\n",
      "      vf_explained_var: 0.5321295261383057\n",
      "      vf_loss: 1301.8311767578125\n",
      "    sample_time_ms: 20949.96\n",
      "    update_time_ms: 5.847\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.532638415653004\n",
      "  time_since_restore: 3820.9274015426636\n",
      "  time_this_iter_s: 31.52894639968872\n",
      "  time_total_s: 3820.9274015426636\n",
      "  timestamp: 1554812117\n",
      "  timesteps_since_restore: 1470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 147\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3820 s, 147 iter, 1470000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-15-43\n",
      "  done: false\n",
      "  episode_len_mean: 87.74782608695652\n",
      "  episode_reward_max: 6.99584410889326\n",
      "  episode_reward_mean: -86.80764264158809\n",
      "  episode_reward_min: -200.29037391580258\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 14432\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4358.162\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 1480000\n",
      "    num_steps_trained: 1480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.802596928649634e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.430248498916626\n",
      "      kl: 0.0055666216649115086\n",
      "      policy_loss: -0.0019630242604762316\n",
      "      total_loss: 1381.160400390625\n",
      "      vf_explained_var: 0.4923362135887146\n",
      "      vf_loss: 1381.1622314453125\n",
      "    sample_time_ms: 21086.377\n",
      "    update_time_ms: 5.991\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.40382132079404\n",
      "  time_since_restore: 3847.061018228531\n",
      "  time_this_iter_s: 26.13361668586731\n",
      "  time_total_s: 3847.061018228531\n",
      "  timestamp: 1554812143\n",
      "  timesteps_since_restore: 1480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1480000\n",
      "  training_iteration: 148\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3847 s, 148 iter, 1480000 ts, -86.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-16-07\n",
      "  done: false\n",
      "  episode_len_mean: 90.06363636363636\n",
      "  episode_reward_max: 8.410645928128996\n",
      "  episode_reward_mean: -80.35777355040165\n",
      "  episode_reward_min: -200.1318464391199\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 14542\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4327.025\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 1490000\n",
      "    num_steps_trained: 1490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.401298464324817e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4198397994041443\n",
      "      kl: 0.006536674685776234\n",
      "      policy_loss: -0.0011830800212919712\n",
      "      total_loss: 1436.310546875\n",
      "      vf_explained_var: 0.4697219133377075\n",
      "      vf_loss: 1436.3116455078125\n",
      "    sample_time_ms: 21011.077\n",
      "    update_time_ms: 5.999\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.17888677520082\n",
      "  time_since_restore: 3871.5139014720917\n",
      "  time_this_iter_s: 24.45288324356079\n",
      "  time_total_s: 3871.5139014720917\n",
      "  timestamp: 1554812167\n",
      "  timesteps_since_restore: 1490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1490000\n",
      "  training_iteration: 149\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3871 s, 149 iter, 1490000 ts, -80.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-16-32\n",
      "  done: false\n",
      "  episode_len_mean: 83.13333333333334\n",
      "  episode_reward_max: 7.904371470771968\n",
      "  episode_reward_mean: -98.1322138507479\n",
      "  episode_reward_min: -200.18534041383816\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 14662\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4329.632\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.40174999833106995\n",
      "      kl: 0.006670753005892038\n",
      "      policy_loss: -0.0017988604959100485\n",
      "      total_loss: 1337.3604736328125\n",
      "      vf_explained_var: 0.5389527082443237\n",
      "      vf_loss: 1337.3624267578125\n",
      "    sample_time_ms: 21090.339\n",
      "    update_time_ms: 5.694\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.06610692537395\n",
      "  time_since_restore: 3896.406997203827\n",
      "  time_this_iter_s: 24.89309573173523\n",
      "  time_total_s: 3896.406997203827\n",
      "  timestamp: 1554812192\n",
      "  timesteps_since_restore: 1500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 150\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3896 s, 150 iter, 1500000 ts, -98.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-16-56\n",
      "  done: false\n",
      "  episode_len_mean: 96.87378640776699\n",
      "  episode_reward_max: 8.828299412320671\n",
      "  episode_reward_mean: -63.827285429506325\n",
      "  episode_reward_min: -200.10380904706668\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 14765\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4332.763\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 1510000\n",
      "    num_steps_trained: 1510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3975749611854553\n",
      "      kl: 0.007491372991353273\n",
      "      policy_loss: -0.002335286233574152\n",
      "      total_loss: 1432.0850830078125\n",
      "      vf_explained_var: 0.4188728332519531\n",
      "      vf_loss: 1432.0875244140625\n",
      "    sample_time_ms: 21068.518\n",
      "    update_time_ms: 5.766\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -31.913642714753163\n",
      "  time_since_restore: 3920.2449893951416\n",
      "  time_this_iter_s: 23.837992191314697\n",
      "  time_total_s: 3920.2449893951416\n",
      "  timestamp: 1554812216\n",
      "  timesteps_since_restore: 1510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1510000\n",
      "  training_iteration: 151\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3920 s, 151 iter, 1510000 ts, -63.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-17-21\n",
      "  done: false\n",
      "  episode_len_mean: 87.30434782608695\n",
      "  episode_reward_max: 8.680045569941662\n",
      "  episode_reward_mean: -87.02592671426044\n",
      "  episode_reward_min: -200.28356513186742\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 14880\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4336.497\n",
      "    load_time_ms: 1.638\n",
      "    num_steps_sampled: 1520000\n",
      "    num_steps_trained: 1520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3919532001018524\n",
      "      kl: 0.005742210429161787\n",
      "      policy_loss: -0.0009836700046434999\n",
      "      total_loss: 1355.0010986328125\n",
      "      vf_explained_var: 0.49982061982154846\n",
      "      vf_loss: 1355.002197265625\n",
      "    sample_time_ms: 21010.46\n",
      "    update_time_ms: 5.746\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.51296335713023\n",
      "  time_since_restore: 3944.7743802070618\n",
      "  time_this_iter_s: 24.529390811920166\n",
      "  time_total_s: 3944.7743802070618\n",
      "  timestamp: 1554812241\n",
      "  timesteps_since_restore: 1520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1520000\n",
      "  training_iteration: 152\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3944 s, 152 iter, 1520000 ts, -87 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-17-46\n",
      "  done: false\n",
      "  episode_len_mean: 88.88495575221239\n",
      "  episode_reward_max: 7.6555696015517025\n",
      "  episode_reward_mean: -83.40773584144442\n",
      "  episode_reward_min: -200.17930836242311\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 14993\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4337.664\n",
      "    load_time_ms: 1.65\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3908700942993164\n",
      "      kl: 0.004375812131911516\n",
      "      policy_loss: -0.0006910321535542607\n",
      "      total_loss: 1416.2095947265625\n",
      "      vf_explained_var: 0.4531577527523041\n",
      "      vf_loss: 1416.2103271484375\n",
      "    sample_time_ms: 21172.717\n",
      "    update_time_ms: 5.74\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.70386792072222\n",
      "  time_since_restore: 3970.421573162079\n",
      "  time_this_iter_s: 25.64719295501709\n",
      "  time_total_s: 3970.421573162079\n",
      "  timestamp: 1554812266\n",
      "  timesteps_since_restore: 1530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 153\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3970 s, 153 iter, 1530000 ts, -83.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-18-10\n",
      "  done: false\n",
      "  episode_len_mean: 87.39473684210526\n",
      "  episode_reward_max: 7.642701963597329\n",
      "  episode_reward_mean: -86.231102769284\n",
      "  episode_reward_min: -200.20665225004265\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 15107\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4338.855\n",
      "    load_time_ms: 1.655\n",
      "    num_steps_sampled: 1540000\n",
      "    num_steps_trained: 1540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3766547441482544\n",
      "      kl: 0.007009952329099178\n",
      "      policy_loss: -0.0014377370243892074\n",
      "      total_loss: 1355.1287841796875\n",
      "      vf_explained_var: 0.499641090631485\n",
      "      vf_loss: 1355.1302490234375\n",
      "    sample_time_ms: 21176.203\n",
      "    update_time_ms: 5.759\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.115551384641996\n",
      "  time_since_restore: 3994.52419090271\n",
      "  time_this_iter_s: 24.102617740631104\n",
      "  time_total_s: 3994.52419090271\n",
      "  timestamp: 1554812290\n",
      "  timesteps_since_restore: 1540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1540000\n",
      "  training_iteration: 154\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 3994 s, 154 iter, 1540000 ts, -86.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-18-34\n",
      "  done: false\n",
      "  episode_len_mean: 89.23214285714286\n",
      "  episode_reward_max: 7.228048956325394\n",
      "  episode_reward_mean: -82.66931904659292\n",
      "  episode_reward_min: -200.21733781737663\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 15219\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4327.182\n",
      "    load_time_ms: 1.686\n",
      "    num_steps_sampled: 1550000\n",
      "    num_steps_trained: 1550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3707539141178131\n",
      "      kl: 0.00557762011885643\n",
      "      policy_loss: -0.0013121970696374774\n",
      "      total_loss: 1370.0377197265625\n",
      "      vf_explained_var: 0.5012130737304688\n",
      "      vf_loss: 1370.038818359375\n",
      "    sample_time_ms: 20918.954\n",
      "    update_time_ms: 5.926\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.33465952329646\n",
      "  time_since_restore: 4018.130364894867\n",
      "  time_this_iter_s: 23.606173992156982\n",
      "  time_total_s: 4018.130364894867\n",
      "  timestamp: 1554812314\n",
      "  timesteps_since_restore: 1550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1550000\n",
      "  training_iteration: 155\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4018 s, 155 iter, 1550000 ts, -82.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-18-58\n",
      "  done: false\n",
      "  episode_len_mean: 89.36283185840708\n",
      "  episode_reward_max: 6.853893656808428\n",
      "  episode_reward_mean: -81.65455588821067\n",
      "  episode_reward_min: -200.11656001666307\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 15332\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4328.403\n",
      "    load_time_ms: 1.646\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.36424392461776733\n",
      "      kl: 0.004872207064181566\n",
      "      policy_loss: -0.0003019925788976252\n",
      "      total_loss: 1402.7298583984375\n",
      "      vf_explained_var: 0.47142493724823\n",
      "      vf_loss: 1402.730224609375\n",
      "    sample_time_ms: 20886.443\n",
      "    update_time_ms: 5.885\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.82727794410532\n",
      "  time_since_restore: 4041.820620536804\n",
      "  time_this_iter_s: 23.690255641937256\n",
      "  time_total_s: 4041.820620536804\n",
      "  timestamp: 1554812338\n",
      "  timesteps_since_restore: 1560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 156\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4041 s, 156 iter, 1560000 ts, -81.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-19-22\n",
      "  done: false\n",
      "  episode_len_mean: 86.79824561403508\n",
      "  episode_reward_max: 8.284739785671317\n",
      "  episode_reward_mean: -87.33637841354094\n",
      "  episode_reward_min: -200.1834146754062\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 15446\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4160.082\n",
      "    load_time_ms: 1.656\n",
      "    num_steps_sampled: 1570000\n",
      "    num_steps_trained: 1570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3509944677352905\n",
      "      kl: 0.005499625112861395\n",
      "      policy_loss: -0.0010952443117275834\n",
      "      total_loss: 1417.018798828125\n",
      "      vf_explained_var: 0.49260133504867554\n",
      "      vf_loss: 1417.02001953125\n",
      "    sample_time_ms: 20297.129\n",
      "    update_time_ms: 5.882\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.668189206770464\n",
      "  time_since_restore: 4065.7745270729065\n",
      "  time_this_iter_s: 23.953906536102295\n",
      "  time_total_s: 4065.7745270729065\n",
      "  timestamp: 1554812362\n",
      "  timesteps_since_restore: 1570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1570000\n",
      "  training_iteration: 157\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4065 s, 157 iter, 1570000 ts, -87.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-19-46\n",
      "  done: false\n",
      "  episode_len_mean: 89.74107142857143\n",
      "  episode_reward_max: 7.696632938334163\n",
      "  episode_reward_mean: -81.95895060869645\n",
      "  episode_reward_min: -200.1283416712502\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 15558\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4167.73\n",
      "    load_time_ms: 1.684\n",
      "    num_steps_sampled: 1580000\n",
      "    num_steps_trained: 1580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3461938500404358\n",
      "      kl: 0.008182263933122158\n",
      "      policy_loss: -0.0023761813063174486\n",
      "      total_loss: 1445.3934326171875\n",
      "      vf_explained_var: 0.47208237648010254\n",
      "      vf_loss: 1445.3958740234375\n",
      "    sample_time_ms: 20052.091\n",
      "    update_time_ms: 5.716\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.97947530434823\n",
      "  time_since_restore: 4089.5315823554993\n",
      "  time_this_iter_s: 23.757055282592773\n",
      "  time_total_s: 4089.5315823554993\n",
      "  timestamp: 1554812386\n",
      "  timesteps_since_restore: 1580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1580000\n",
      "  training_iteration: 158\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4089 s, 158 iter, 1580000 ts, -82 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-20-10\n",
      "  done: false\n",
      "  episode_len_mean: 80.09677419354838\n",
      "  episode_reward_max: 6.731748280547766\n",
      "  episode_reward_mean: -108.43567402904424\n",
      "  episode_reward_min: -200.24172298497427\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 15682\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4162.759\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3291178047657013\n",
      "      kl: 0.00705459201708436\n",
      "      policy_loss: -0.00014962293789722025\n",
      "      total_loss: 1287.629638671875\n",
      "      vf_explained_var: 0.5515305995941162\n",
      "      vf_loss: 1287.6297607421875\n",
      "    sample_time_ms: 20005.449\n",
      "    update_time_ms: 5.674\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -54.21783701452213\n",
      "  time_since_restore: 4113.466614246368\n",
      "  time_this_iter_s: 23.93503189086914\n",
      "  time_total_s: 4113.466614246368\n",
      "  timestamp: 1554812410\n",
      "  timesteps_since_restore: 1590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 159\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4113 s, 159 iter, 1590000 ts, -108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-20-35\n",
      "  done: false\n",
      "  episode_len_mean: 85.20338983050847\n",
      "  episode_reward_max: 6.479584224715126\n",
      "  episode_reward_mean: -91.49030062254067\n",
      "  episode_reward_min: -200.0972517419204\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 15800\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4159.219\n",
      "    load_time_ms: 1.75\n",
      "    num_steps_sampled: 1600000\n",
      "    num_steps_trained: 1600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3327788710594177\n",
      "      kl: 0.007540848106145859\n",
      "      policy_loss: -0.0019588652066886425\n",
      "      total_loss: 1378.5565185546875\n",
      "      vf_explained_var: 0.5005791187286377\n",
      "      vf_loss: 1378.558349609375\n",
      "    sample_time_ms: 20034.015\n",
      "    update_time_ms: 5.779\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.74515031127032\n",
      "  time_since_restore: 4138.614673376083\n",
      "  time_this_iter_s: 25.148059129714966\n",
      "  time_total_s: 4138.614673376083\n",
      "  timestamp: 1554812435\n",
      "  timesteps_since_restore: 1600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1600000\n",
      "  training_iteration: 160\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4138 s, 160 iter, 1600000 ts, -91.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-21-03\n",
      "  done: false\n",
      "  episode_len_mean: 87.56521739130434\n",
      "  episode_reward_max: 7.174711101959087\n",
      "  episode_reward_mean: -86.8148458888353\n",
      "  episode_reward_min: -200.1712515667041\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 15915\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4187.136\n",
      "    load_time_ms: 1.7\n",
      "    num_steps_sampled: 1610000\n",
      "    num_steps_trained: 1610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.32506662607192993\n",
      "      kl: 0.007866689004004002\n",
      "      policy_loss: -0.001986246556043625\n",
      "      total_loss: 1380.4046630859375\n",
      "      vf_explained_var: 0.5116827487945557\n",
      "      vf_loss: 1380.4066162109375\n",
      "    sample_time_ms: 20391.884\n",
      "    update_time_ms: 5.641\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.40742294441765\n",
      "  time_since_restore: 4166.307604312897\n",
      "  time_this_iter_s: 27.692930936813354\n",
      "  time_total_s: 4166.307604312897\n",
      "  timestamp: 1554812463\n",
      "  timesteps_since_restore: 1610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1610000\n",
      "  training_iteration: 161\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4166 s, 161 iter, 1610000 ts, -86.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 88.8108108108108\n",
      "  episode_reward_max: 7.517001402899017\n",
      "  episode_reward_mean: -82.85639289749638\n",
      "  episode_reward_min: -200.11160457887613\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 16026\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4194.084\n",
      "    load_time_ms: 1.745\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.31588324904441833\n",
      "      kl: 0.006779830437153578\n",
      "      policy_loss: -0.0016762095037847757\n",
      "      total_loss: 1419.6524658203125\n",
      "      vf_explained_var: 0.4692104160785675\n",
      "      vf_loss: 1419.654052734375\n",
      "    sample_time_ms: 20417.309\n",
      "    update_time_ms: 5.588\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.42819644874821\n",
      "  time_since_restore: 4191.16110086441\n",
      "  time_this_iter_s: 24.853496551513672\n",
      "  time_total_s: 4191.16110086441\n",
      "  timestamp: 1554812487\n",
      "  timesteps_since_restore: 1620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 162\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4191 s, 162 iter, 1620000 ts, -82.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-21-52\n",
      "  done: false\n",
      "  episode_len_mean: 86.36206896551724\n",
      "  episode_reward_max: 7.456574862124295\n",
      "  episode_reward_mean: -89.51853027361453\n",
      "  episode_reward_min: -200.1642528149324\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 16142\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4205.734\n",
      "    load_time_ms: 1.735\n",
      "    num_steps_sampled: 1630000\n",
      "    num_steps_trained: 1630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3054463863372803\n",
      "      kl: 0.005676256492733955\n",
      "      policy_loss: -0.0004338304861448705\n",
      "      total_loss: 1347.6295166015625\n",
      "      vf_explained_var: 0.5155690312385559\n",
      "      vf_loss: 1347.6300048828125\n",
      "    sample_time_ms: 20279.767\n",
      "    update_time_ms: 5.681\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.75926513680727\n",
      "  time_since_restore: 4215.55066037178\n",
      "  time_this_iter_s: 24.389559507369995\n",
      "  time_total_s: 4215.55066037178\n",
      "  timestamp: 1554812512\n",
      "  timesteps_since_restore: 1630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1630000\n",
      "  training_iteration: 163\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4215 s, 163 iter, 1630000 ts, -89.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-22-16\n",
      "  done: false\n",
      "  episode_len_mean: 92.80733944954129\n",
      "  episode_reward_max: 7.827699686822615\n",
      "  episode_reward_mean: -73.88344557652462\n",
      "  episode_reward_min: -200.09282969157675\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 16251\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4204.093\n",
      "    load_time_ms: 1.755\n",
      "    num_steps_sampled: 1640000\n",
      "    num_steps_trained: 1640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3037593960762024\n",
      "      kl: 0.006477155722677708\n",
      "      policy_loss: -0.001511643291451037\n",
      "      total_loss: 1439.525634765625\n",
      "      vf_explained_var: 0.45880308747291565\n",
      "      vf_loss: 1439.527099609375\n",
      "    sample_time_ms: 20271.104\n",
      "    update_time_ms: 5.771\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.94172278826232\n",
      "  time_since_restore: 4239.554886341095\n",
      "  time_this_iter_s: 24.004225969314575\n",
      "  time_total_s: 4239.554886341095\n",
      "  timestamp: 1554812536\n",
      "  timesteps_since_restore: 1640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1640000\n",
      "  training_iteration: 164\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4239 s, 164 iter, 1640000 ts, -73.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-22-40\n",
      "  done: false\n",
      "  episode_len_mean: 87.99115044247787\n",
      "  episode_reward_max: 6.977899036599448\n",
      "  episode_reward_mean: -85.94183714778187\n",
      "  episode_reward_min: -200.15288105509572\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 16364\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4199.179\n",
      "    load_time_ms: 1.844\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2979850172996521\n",
      "      kl: 0.005071421153843403\n",
      "      policy_loss: 0.00037170364521443844\n",
      "      total_loss: 1317.0203857421875\n",
      "      vf_explained_var: 0.5415449738502502\n",
      "      vf_loss: 1317.02001953125\n",
      "    sample_time_ms: 20323.634\n",
      "    update_time_ms: 5.62\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.97091857389092\n",
      "  time_since_restore: 4263.6372265815735\n",
      "  time_this_iter_s: 24.082340240478516\n",
      "  time_total_s: 4263.6372265815735\n",
      "  timestamp: 1554812560\n",
      "  timesteps_since_restore: 1650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 165\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4263 s, 165 iter, 1650000 ts, -85.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-23-05\n",
      "  done: false\n",
      "  episode_len_mean: 88.77876106194691\n",
      "  episode_reward_max: 6.945826890179542\n",
      "  episode_reward_mean: -82.77134986352402\n",
      "  episode_reward_min: -200.0887059290851\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 16477\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4200.729\n",
      "    load_time_ms: 1.905\n",
      "    num_steps_sampled: 1660000\n",
      "    num_steps_trained: 1660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2909829318523407\n",
      "      kl: 0.0062798988074064255\n",
      "      policy_loss: 0.0006760916439816356\n",
      "      total_loss: 1435.3177490234375\n",
      "      vf_explained_var: 0.45720604062080383\n",
      "      vf_loss: 1435.317138671875\n",
      "    sample_time_ms: 20393.378\n",
      "    update_time_ms: 5.522\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.38567493176202\n",
      "  time_since_restore: 4288.042077064514\n",
      "  time_this_iter_s: 24.404850482940674\n",
      "  time_total_s: 4288.042077064514\n",
      "  timestamp: 1554812585\n",
      "  timesteps_since_restore: 1660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1660000\n",
      "  training_iteration: 166\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4288 s, 166 iter, 1660000 ts, -82.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-23-28\n",
      "  done: false\n",
      "  episode_len_mean: 86.68695652173913\n",
      "  episode_reward_max: 6.196779032384237\n",
      "  episode_reward_mean: -87.7395803262411\n",
      "  episode_reward_min: -200.11019550640958\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 16592\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4202.932\n",
      "    load_time_ms: 1.895\n",
      "    num_steps_sampled: 1670000\n",
      "    num_steps_trained: 1670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2801063656806946\n",
      "      kl: 0.0072240340523421764\n",
      "      policy_loss: -0.0014792707515880466\n",
      "      total_loss: 1284.666015625\n",
      "      vf_explained_var: 0.5351908206939697\n",
      "      vf_loss: 1284.667724609375\n",
      "    sample_time_ms: 20379.047\n",
      "    update_time_ms: 5.523\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.86979016312055\n",
      "  time_since_restore: 4311.874697685242\n",
      "  time_this_iter_s: 23.83262062072754\n",
      "  time_total_s: 4311.874697685242\n",
      "  timestamp: 1554812608\n",
      "  timesteps_since_restore: 1670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1670000\n",
      "  training_iteration: 167\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4311 s, 167 iter, 1670000 ts, -87.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-23-53\n",
      "  done: false\n",
      "  episode_len_mean: 86.95652173913044\n",
      "  episode_reward_max: 7.304315490614126\n",
      "  episode_reward_mean: -90.65243341036962\n",
      "  episode_reward_min: -200.12135598406115\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 16707\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4201.605\n",
      "    load_time_ms: 1.909\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.26950719952583313\n",
      "      kl: 0.006754268426448107\n",
      "      policy_loss: -0.0012575536966323853\n",
      "      total_loss: 1380.5009765625\n",
      "      vf_explained_var: 0.49850159883499146\n",
      "      vf_loss: 1380.5023193359375\n",
      "    sample_time_ms: 20448.156\n",
      "    update_time_ms: 5.631\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.3262167051848\n",
      "  time_since_restore: 4336.31227684021\n",
      "  time_this_iter_s: 24.43757915496826\n",
      "  time_total_s: 4336.31227684021\n",
      "  timestamp: 1554812633\n",
      "  timesteps_since_restore: 1680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 168\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4336 s, 168 iter, 1680000 ts, -90.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-24-16\n",
      "  done: false\n",
      "  episode_len_mean: 86.88695652173914\n",
      "  episode_reward_max: 7.442985131040804\n",
      "  episode_reward_mean: -88.87575285668545\n",
      "  episode_reward_min: -200.06833468914033\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 16822\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4203.381\n",
      "    load_time_ms: 1.878\n",
      "    num_steps_sampled: 1690000\n",
      "    num_steps_trained: 1690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2639233469963074\n",
      "      kl: 0.006961391307413578\n",
      "      policy_loss: -0.0007262554718181491\n",
      "      total_loss: 1351.756591796875\n",
      "      vf_explained_var: 0.5250928401947021\n",
      "      vf_loss: 1351.75732421875\n",
      "    sample_time_ms: 20409.265\n",
      "    update_time_ms: 5.7\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.43787642834273\n",
      "  time_since_restore: 4359.880272388458\n",
      "  time_this_iter_s: 23.56799554824829\n",
      "  time_total_s: 4359.880272388458\n",
      "  timestamp: 1554812656\n",
      "  timesteps_since_restore: 1690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1690000\n",
      "  training_iteration: 169\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4359 s, 169 iter, 1690000 ts, -88.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-24-41\n",
      "  done: false\n",
      "  episode_len_mean: 81.57377049180327\n",
      "  episode_reward_max: 6.881339515131547\n",
      "  episode_reward_mean: -103.83129633943287\n",
      "  episode_reward_min: -200.06727215809528\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 16944\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4233.022\n",
      "    load_time_ms: 1.786\n",
      "    num_steps_sampled: 1700000\n",
      "    num_steps_trained: 1700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.24662566184997559\n",
      "      kl: 0.007705855183303356\n",
      "      policy_loss: -0.0020908373408019543\n",
      "      total_loss: 1203.303466796875\n",
      "      vf_explained_var: 0.600246250629425\n",
      "      vf_loss: 1203.3055419921875\n",
      "    sample_time_ms: 20331.399\n",
      "    update_time_ms: 5.511\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.91564816971645\n",
      "  time_since_restore: 4384.544336080551\n",
      "  time_this_iter_s: 24.664063692092896\n",
      "  time_total_s: 4384.544336080551\n",
      "  timestamp: 1554812681\n",
      "  timesteps_since_restore: 1700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1700000\n",
      "  training_iteration: 170\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4384 s, 170 iter, 1700000 ts, -104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-25-10\n",
      "  done: false\n",
      "  episode_len_mean: 90.35135135135135\n",
      "  episode_reward_max: 7.059806787884854\n",
      "  episode_reward_mean: -78.68379968348282\n",
      "  episode_reward_min: -200.07735086099387\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 17055\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4207.631\n",
      "    load_time_ms: 1.832\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2468833476305008\n",
      "      kl: 0.006817316170781851\n",
      "      policy_loss: -0.0009128516539931297\n",
      "      total_loss: 1399.7012939453125\n",
      "      vf_explained_var: 0.4496161639690399\n",
      "      vf_loss: 1399.7022705078125\n",
      "    sample_time_ms: 20425.794\n",
      "    update_time_ms: 5.824\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.341899841741416\n",
      "  time_since_restore: 4412.929337501526\n",
      "  time_this_iter_s: 28.38500142097473\n",
      "  time_total_s: 4412.929337501526\n",
      "  timestamp: 1554812710\n",
      "  timesteps_since_restore: 1710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 171\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4412 s, 171 iter, 1710000 ts, -78.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-25-34\n",
      "  done: false\n",
      "  episode_len_mean: 89.39285714285714\n",
      "  episode_reward_max: 6.878592501297089\n",
      "  episode_reward_mean: -81.55004605525052\n",
      "  episode_reward_min: -200.14301396270503\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 17167\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4190.608\n",
      "    load_time_ms: 1.794\n",
      "    num_steps_sampled: 1720000\n",
      "    num_steps_trained: 1720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.23189303278923035\n",
      "      kl: 0.0075109172612428665\n",
      "      policy_loss: -0.0025708568282425404\n",
      "      total_loss: 1368.034912109375\n",
      "      vf_explained_var: 0.481270432472229\n",
      "      vf_loss: 1368.0374755859375\n",
      "    sample_time_ms: 20359.923\n",
      "    update_time_ms: 5.91\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.77502302762527\n",
      "  time_since_restore: 4436.951534509659\n",
      "  time_this_iter_s: 24.022197008132935\n",
      "  time_total_s: 4436.951534509659\n",
      "  timestamp: 1554812734\n",
      "  timesteps_since_restore: 1720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1720000\n",
      "  training_iteration: 172\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4436 s, 172 iter, 1720000 ts, -81.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-25-58\n",
      "  done: false\n",
      "  episode_len_mean: 97.31372549019608\n",
      "  episode_reward_max: 6.247297292289614\n",
      "  episode_reward_mean: -61.34224109891518\n",
      "  episode_reward_min: -200.03730364062835\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 17269\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4176.227\n",
      "    load_time_ms: 1.838\n",
      "    num_steps_sampled: 1730000\n",
      "    num_steps_trained: 1730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.23724254965782166\n",
      "      kl: 0.005961887538433075\n",
      "      policy_loss: -0.0006644907407462597\n",
      "      total_loss: 1496.713134765625\n",
      "      vf_explained_var: 0.3932589888572693\n",
      "      vf_loss: 1496.7138671875\n",
      "    sample_time_ms: 20330.553\n",
      "    update_time_ms: 5.908\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -30.67112054945759\n",
      "  time_since_restore: 4460.9028351306915\n",
      "  time_this_iter_s: 23.951300621032715\n",
      "  time_total_s: 4460.9028351306915\n",
      "  timestamp: 1554812758\n",
      "  timesteps_since_restore: 1730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1730000\n",
      "  training_iteration: 173\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4460 s, 173 iter, 1730000 ts, -61.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-26-22\n",
      "  done: false\n",
      "  episode_len_mean: 87.00862068965517\n",
      "  episode_reward_max: 6.865041350362766\n",
      "  episode_reward_mean: -87.54591346019635\n",
      "  episode_reward_min: -200.05422150941294\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 17385\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4165.168\n",
      "    load_time_ms: 1.819\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2207394689321518\n",
      "      kl: 0.006838714238256216\n",
      "      policy_loss: -0.0021936383564025164\n",
      "      total_loss: 1377.9833984375\n",
      "      vf_explained_var: 0.48745283484458923\n",
      "      vf_loss: 1377.9857177734375\n",
      "    sample_time_ms: 20334.617\n",
      "    update_time_ms: 5.798\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.77295673009817\n",
      "  time_since_restore: 4484.835134744644\n",
      "  time_this_iter_s: 23.932299613952637\n",
      "  time_total_s: 4484.835134744644\n",
      "  timestamp: 1554812782\n",
      "  timesteps_since_restore: 1740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 174\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4484 s, 174 iter, 1740000 ts, -87.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-26-46\n",
      "  done: false\n",
      "  episode_len_mean: 82.9\n",
      "  episode_reward_max: 6.672136870655839\n",
      "  episode_reward_mean: -100.04115065360041\n",
      "  episode_reward_min: -200.05286144063024\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 17505\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4158.123\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 1750000\n",
      "    num_steps_trained: 1750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.19741684198379517\n",
      "      kl: 0.0072426567785441875\n",
      "      policy_loss: -0.0015517175197601318\n",
      "      total_loss: 1336.7506103515625\n",
      "      vf_explained_var: 0.5321813821792603\n",
      "      vf_loss: 1336.7520751953125\n",
      "    sample_time_ms: 20335.184\n",
      "    update_time_ms: 5.776\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.020575326800206\n",
      "  time_since_restore: 4508.847905397415\n",
      "  time_this_iter_s: 24.012770652770996\n",
      "  time_total_s: 4508.847905397415\n",
      "  timestamp: 1554812806\n",
      "  timesteps_since_restore: 1750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1750000\n",
      "  training_iteration: 175\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4508 s, 175 iter, 1750000 ts, -100 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-27-10\n",
      "  done: false\n",
      "  episode_len_mean: 87.67543859649123\n",
      "  episode_reward_max: 6.24031941680375\n",
      "  episode_reward_mean: -87.43550827255312\n",
      "  episode_reward_min: -200.07496622979642\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 17619\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4148.116\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 1760000\n",
      "    num_steps_trained: 1760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1918819099664688\n",
      "      kl: 0.007669141516089439\n",
      "      policy_loss: -0.002814006060361862\n",
      "      total_loss: 1359.80810546875\n",
      "      vf_explained_var: 0.5277284383773804\n",
      "      vf_loss: 1359.8109130859375\n",
      "    sample_time_ms: 20281.358\n",
      "    update_time_ms: 5.805\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.717754136276575\n",
      "  time_since_restore: 4532.612229585648\n",
      "  time_this_iter_s: 23.764324188232422\n",
      "  time_total_s: 4532.612229585648\n",
      "  timestamp: 1554812830\n",
      "  timesteps_since_restore: 1760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1760000\n",
      "  training_iteration: 176\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4532 s, 176 iter, 1760000 ts, -87.4 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-27-34\n",
      "  done: false\n",
      "  episode_len_mean: 94.38679245283019\n",
      "  episode_reward_max: 6.904307403277452\n",
      "  episode_reward_mean: -69.8241610369107\n",
      "  episode_reward_min: -200.0522264923896\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 17725\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4167.819\n",
      "    load_time_ms: 1.671\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.19548174738883972\n",
      "      kl: 0.006936319172382355\n",
      "      policy_loss: -0.0007537542260251939\n",
      "      total_loss: 1481.4215087890625\n",
      "      vf_explained_var: 0.4162760376930237\n",
      "      vf_loss: 1481.4222412109375\n",
      "    sample_time_ms: 20285.391\n",
      "    update_time_ms: 5.792\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.912080518455355\n",
      "  time_since_restore: 4556.682662248611\n",
      "  time_this_iter_s: 24.070432662963867\n",
      "  time_total_s: 4556.682662248611\n",
      "  timestamp: 1554812854\n",
      "  timesteps_since_restore: 1770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 177\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4556 s, 177 iter, 1770000 ts, -69.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-27-59\n",
      "  done: false\n",
      "  episode_len_mean: 88.93805309734513\n",
      "  episode_reward_max: 6.665975053519647\n",
      "  episode_reward_mean: -82.90525774966737\n",
      "  episode_reward_min: -200.0362010923929\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 17838\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4206.535\n",
      "    load_time_ms: 1.669\n",
      "    num_steps_sampled: 1780000\n",
      "    num_steps_trained: 1780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.18314655125141144\n",
      "      kl: 0.006678283214569092\n",
      "      policy_loss: -0.00045379987568594515\n",
      "      total_loss: 1322.499267578125\n",
      "      vf_explained_var: 0.5342287421226501\n",
      "      vf_loss: 1322.499755859375\n",
      "    sample_time_ms: 20380.234\n",
      "    update_time_ms: 6.008\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.45262887483369\n",
      "  time_since_restore: 4582.455345630646\n",
      "  time_this_iter_s: 25.7726833820343\n",
      "  time_total_s: 4582.455345630646\n",
      "  timestamp: 1554812879\n",
      "  timesteps_since_restore: 1780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1780000\n",
      "  training_iteration: 178\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4582 s, 178 iter, 1780000 ts, -82.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-28-23\n",
      "  done: false\n",
      "  episode_len_mean: 92.33333333333333\n",
      "  episode_reward_max: 6.2888153291587745\n",
      "  episode_reward_mean: -76.09210484957693\n",
      "  episode_reward_min: -200.05177628727574\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 17946\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4193.855\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 1790000\n",
      "    num_steps_trained: 1790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.17548571527004242\n",
      "      kl: 0.006038021761924028\n",
      "      policy_loss: -0.0005919136456213892\n",
      "      total_loss: 1420.0869140625\n",
      "      vf_explained_var: 0.46929559111595154\n",
      "      vf_loss: 1420.0875244140625\n",
      "    sample_time_ms: 20434.218\n",
      "    update_time_ms: 6.118\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.04605242478847\n",
      "  time_since_restore: 4606.435940742493\n",
      "  time_this_iter_s: 23.980595111846924\n",
      "  time_total_s: 4606.435940742493\n",
      "  timestamp: 1554812903\n",
      "  timesteps_since_restore: 1790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1790000\n",
      "  training_iteration: 179\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4606 s, 179 iter, 1790000 ts, -76.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-28-47\n",
      "  done: false\n",
      "  episode_len_mean: 87.45614035087719\n",
      "  episode_reward_max: 6.451758901766324\n",
      "  episode_reward_mean: -87.19528929889502\n",
      "  episode_reward_min: -200.03269782309314\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 18060\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4155.084\n",
      "    load_time_ms: 1.712\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.16444621980190277\n",
      "      kl: 0.007862165570259094\n",
      "      policy_loss: -0.0007577118813060224\n",
      "      total_loss: 1405.499755859375\n",
      "      vf_explained_var: 0.48494604229927063\n",
      "      vf_loss: 1405.5006103515625\n",
      "    sample_time_ms: 20326.925\n",
      "    update_time_ms: 6.22\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.5976446494475\n",
      "  time_since_restore: 4629.636590480804\n",
      "  time_this_iter_s: 23.200649738311768\n",
      "  time_total_s: 4629.636590480804\n",
      "  timestamp: 1554812927\n",
      "  timesteps_since_restore: 1800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 180\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4629 s, 180 iter, 1800000 ts, -87.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-29-11\n",
      "  done: false\n",
      "  episode_len_mean: 88.19298245614036\n",
      "  episode_reward_max: 7.02930314113697\n",
      "  episode_reward_mean: -85.43941986092689\n",
      "  episode_reward_min: -200.03704369828125\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 18174\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4141.473\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 1810000\n",
      "    num_steps_trained: 1810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14979243278503418\n",
      "      kl: 0.006136960815638304\n",
      "      policy_loss: -0.0007604379788972437\n",
      "      total_loss: 1389.7099609375\n",
      "      vf_explained_var: 0.4746266007423401\n",
      "      vf_loss: 1389.710693359375\n",
      "    sample_time_ms: 19888.01\n",
      "    update_time_ms: 5.759\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.71970993046345\n",
      "  time_since_restore: 4653.492963314056\n",
      "  time_this_iter_s: 23.856372833251953\n",
      "  time_total_s: 4653.492963314056\n",
      "  timestamp: 1554812951\n",
      "  timesteps_since_restore: 1810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1810000\n",
      "  training_iteration: 181\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4653 s, 181 iter, 1810000 ts, -85.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-29-35\n",
      "  done: false\n",
      "  episode_len_mean: 88.1842105263158\n",
      "  episode_reward_max: 6.1404688078398095\n",
      "  episode_reward_mean: -86.06537020561414\n",
      "  episode_reward_min: -200.0493067188376\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 18288\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4134.516\n",
      "    load_time_ms: 1.75\n",
      "    num_steps_sampled: 1820000\n",
      "    num_steps_trained: 1820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14202670753002167\n",
      "      kl: 0.007721717469394207\n",
      "      policy_loss: -0.0015003529842942953\n",
      "      total_loss: 1428.8489990234375\n",
      "      vf_explained_var: 0.46135497093200684\n",
      "      vf_loss: 1428.8505859375\n",
      "    sample_time_ms: 19879.51\n",
      "    update_time_ms: 5.674\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.03268510280708\n",
      "  time_since_restore: 4677.362596511841\n",
      "  time_this_iter_s: 23.869633197784424\n",
      "  time_total_s: 4677.362596511841\n",
      "  timestamp: 1554812975\n",
      "  timesteps_since_restore: 1820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1820000\n",
      "  training_iteration: 182\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4677 s, 182 iter, 1820000 ts, -86.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-29-58\n",
      "  done: false\n",
      "  episode_len_mean: 88.90178571428571\n",
      "  episode_reward_max: 6.619117984382555\n",
      "  episode_reward_mean: -84.06867785097913\n",
      "  episode_reward_min: -200.04522383452797\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 18400\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4126.559\n",
      "    load_time_ms: 1.782\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.13374407589435577\n",
      "      kl: 0.006814158987253904\n",
      "      policy_loss: -0.0013938111951574683\n",
      "      total_loss: 1321.223388671875\n",
      "      vf_explained_var: 0.507826030254364\n",
      "      vf_loss: 1321.224609375\n",
      "    sample_time_ms: 19823.729\n",
      "    update_time_ms: 5.764\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.034338925489564\n",
      "  time_since_restore: 4700.676146030426\n",
      "  time_this_iter_s: 23.313549518585205\n",
      "  time_total_s: 4700.676146030426\n",
      "  timestamp: 1554812998\n",
      "  timesteps_since_restore: 1830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 183\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4700 s, 183 iter, 1830000 ts, -84.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-30-22\n",
      "  done: false\n",
      "  episode_len_mean: 88.59292035398231\n",
      "  episode_reward_max: 7.522037579842676\n",
      "  episode_reward_mean: -82.91739778647913\n",
      "  episode_reward_min: -200.06207845418\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 18513\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4127.085\n",
      "    load_time_ms: 1.769\n",
      "    num_steps_sampled: 1840000\n",
      "    num_steps_trained: 1840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1220584511756897\n",
      "      kl: 0.006660623475909233\n",
      "      policy_loss: -0.00035440234933048487\n",
      "      total_loss: 1403.70849609375\n",
      "      vf_explained_var: 0.4539458453655243\n",
      "      vf_loss: 1403.708984375\n",
      "    sample_time_ms: 19817.578\n",
      "    update_time_ms: 5.883\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.45869889323957\n",
      "  time_since_restore: 4724.550018072128\n",
      "  time_this_iter_s: 23.87387204170227\n",
      "  time_total_s: 4724.550018072128\n",
      "  timestamp: 1554813022\n",
      "  timesteps_since_restore: 1840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1840000\n",
      "  training_iteration: 184\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4724 s, 184 iter, 1840000 ts, -82.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-30-46\n",
      "  done: false\n",
      "  episode_len_mean: 82.9327731092437\n",
      "  episode_reward_max: 7.334331089016603\n",
      "  episode_reward_mean: -100.59876697194542\n",
      "  episode_reward_min: -200.05885615767806\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 18632\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4121.298\n",
      "    load_time_ms: 1.782\n",
      "    num_steps_sampled: 1850000\n",
      "    num_steps_trained: 1850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.10547176748514175\n",
      "      kl: 0.007742198649793863\n",
      "      policy_loss: -0.001416472252458334\n",
      "      total_loss: 1398.63037109375\n",
      "      vf_explained_var: 0.509288489818573\n",
      "      vf_loss: 1398.6318359375\n",
      "    sample_time_ms: 19801.292\n",
      "    update_time_ms: 5.845\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.29938348597271\n",
      "  time_since_restore: 4748.34187579155\n",
      "  time_this_iter_s: 23.791857719421387\n",
      "  time_total_s: 4748.34187579155\n",
      "  timestamp: 1554813046\n",
      "  timesteps_since_restore: 1850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1850000\n",
      "  training_iteration: 185\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4748 s, 185 iter, 1850000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-31-10\n",
      "  done: false\n",
      "  episode_len_mean: 89.50442477876106\n",
      "  episode_reward_max: 6.606575934338919\n",
      "  episode_reward_mean: -81.57158156590896\n",
      "  episode_reward_min: -200.06407875307275\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 18745\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4123.805\n",
      "    load_time_ms: 1.793\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1071452870965004\n",
      "      kl: 0.008501137606799603\n",
      "      policy_loss: -0.0006439778371714056\n",
      "      total_loss: 1429.0587158203125\n",
      "      vf_explained_var: 0.46395188570022583\n",
      "      vf_loss: 1429.0594482421875\n",
      "    sample_time_ms: 19854.084\n",
      "    update_time_ms: 5.776\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.78579078295448\n",
      "  time_since_restore: 4772.6574585437775\n",
      "  time_this_iter_s: 24.315582752227783\n",
      "  time_total_s: 4772.6574585437775\n",
      "  timestamp: 1554813070\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 186\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4772 s, 186 iter, 1860000 ts, -81.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-31-33\n",
      "  done: false\n",
      "  episode_len_mean: 88.10619469026548\n",
      "  episode_reward_max: 6.905188650185927\n",
      "  episode_reward_mean: -84.91313485779538\n",
      "  episode_reward_min: -200.0437892685651\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 18858\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4091.13\n",
      "    load_time_ms: 1.718\n",
      "    num_steps_sampled: 1870000\n",
      "    num_steps_trained: 1870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09473321586847305\n",
      "      kl: 0.007611276116222143\n",
      "      policy_loss: -0.0019330340437591076\n",
      "      total_loss: 1404.401611328125\n",
      "      vf_explained_var: 0.5005845427513123\n",
      "      vf_loss: 1404.4036865234375\n",
      "    sample_time_ms: 19801.701\n",
      "    update_time_ms: 5.854\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.456567428897685\n",
      "  time_since_restore: 4795.874403953552\n",
      "  time_this_iter_s: 23.21694540977478\n",
      "  time_total_s: 4795.874403953552\n",
      "  timestamp: 1554813093\n",
      "  timesteps_since_restore: 1870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1870000\n",
      "  training_iteration: 187\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4795 s, 187 iter, 1870000 ts, -84.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-31-58\n",
      "  done: false\n",
      "  episode_len_mean: 91.44954128440367\n",
      "  episode_reward_max: 6.976991924026711\n",
      "  episode_reward_mean: -75.10092060886734\n",
      "  episode_reward_min: -200.0417481872576\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 18967\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4035.521\n",
      "    load_time_ms: 1.728\n",
      "    num_steps_sampled: 1880000\n",
      "    num_steps_trained: 1880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09081617742776871\n",
      "      kl: 0.005979857407510281\n",
      "      policy_loss: -0.0005822418606840074\n",
      "      total_loss: 1442.644775390625\n",
      "      vf_explained_var: 0.4461990296840668\n",
      "      vf_loss: 1442.6453857421875\n",
      "    sample_time_ms: 19706.774\n",
      "    update_time_ms: 5.617\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.55046030443368\n",
      "  time_since_restore: 4820.14160656929\n",
      "  time_this_iter_s: 24.267202615737915\n",
      "  time_total_s: 4820.14160656929\n",
      "  timestamp: 1554813118\n",
      "  timesteps_since_restore: 1880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1880000\n",
      "  training_iteration: 188\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4820 s, 188 iter, 1880000 ts, -75.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-32-22\n",
      "  done: false\n",
      "  episode_len_mean: 84.95798319327731\n",
      "  episode_reward_max: 6.427759217047813\n",
      "  episode_reward_mean: -93.88393021984346\n",
      "  episode_reward_min: -200.03795030384487\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 19086\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4090.636\n",
      "    load_time_ms: 1.709\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06740066409111023\n",
      "      kl: 0.008938901126384735\n",
      "      policy_loss: -0.0015496048144996166\n",
      "      total_loss: 1341.0872802734375\n",
      "      vf_explained_var: 0.5203394889831543\n",
      "      vf_loss: 1341.0887451171875\n",
      "    sample_time_ms: 19654.638\n",
      "    update_time_ms: 5.701\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.94196510992174\n",
      "  time_since_restore: 4844.152078866959\n",
      "  time_this_iter_s: 24.010472297668457\n",
      "  time_total_s: 4844.152078866959\n",
      "  timestamp: 1554813142\n",
      "  timesteps_since_restore: 1890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 189\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4844 s, 189 iter, 1890000 ts, -93.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-32-46\n",
      "  done: false\n",
      "  episode_len_mean: 90.02752293577981\n",
      "  episode_reward_max: 5.91682520531714\n",
      "  episode_reward_mean: -81.01170092827115\n",
      "  episode_reward_min: -200.03941009040932\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 19195\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4092.029\n",
      "    load_time_ms: 1.711\n",
      "    num_steps_sampled: 1900000\n",
      "    num_steps_trained: 1900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.07074061036109924\n",
      "      kl: 0.008890040218830109\n",
      "      policy_loss: -0.00026354537112638354\n",
      "      total_loss: 1375.6900634765625\n",
      "      vf_explained_var: 0.4843372404575348\n",
      "      vf_loss: 1375.6903076171875\n",
      "    sample_time_ms: 19782.471\n",
      "    update_time_ms: 5.623\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.505850464135584\n",
      "  time_since_restore: 4868.643467664719\n",
      "  time_this_iter_s: 24.49138879776001\n",
      "  time_total_s: 4868.643467664719\n",
      "  timestamp: 1554813166\n",
      "  timesteps_since_restore: 1900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1900000\n",
      "  training_iteration: 190\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4868 s, 190 iter, 1900000 ts, -81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-33-14\n",
      "  done: false\n",
      "  episode_len_mean: 84.03305785123968\n",
      "  episode_reward_max: 7.012456844612388\n",
      "  episode_reward_mean: -95.70063895750428\n",
      "  episode_reward_min: -200.06759405394544\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 19316\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4097.227\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 1910000\n",
      "    num_steps_trained: 1910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.05466572567820549\n",
      "      kl: 0.0074416259303689\n",
      "      policy_loss: 0.00019707530736923218\n",
      "      total_loss: 1285.927734375\n",
      "      vf_explained_var: 0.5639936923980713\n",
      "      vf_loss: 1285.927490234375\n",
      "    sample_time_ms: 20132.991\n",
      "    update_time_ms: 5.856\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.850319478752134\n",
      "  time_since_restore: 4896.057076692581\n",
      "  time_this_iter_s: 27.41360902786255\n",
      "  time_total_s: 4896.057076692581\n",
      "  timestamp: 1554813194\n",
      "  timesteps_since_restore: 1910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1910000\n",
      "  training_iteration: 191\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4896 s, 191 iter, 1910000 ts, -95.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-33-40\n",
      "  done: false\n",
      "  episode_len_mean: 86.04347826086956\n",
      "  episode_reward_max: 5.87516297666917\n",
      "  episode_reward_mean: -90.78480478875909\n",
      "  episode_reward_min: -200.07345918725525\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 19431\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4119.816\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.05399278551340103\n",
      "      kl: 0.007388684898614883\n",
      "      policy_loss: -0.0012887991033494473\n",
      "      total_loss: 1384.7353515625\n",
      "      vf_explained_var: 0.5057106614112854\n",
      "      vf_loss: 1384.73681640625\n",
      "    sample_time_ms: 20320.89\n",
      "    update_time_ms: 5.884\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.39240239437955\n",
      "  time_since_restore: 4922.029679298401\n",
      "  time_this_iter_s: 25.972602605819702\n",
      "  time_total_s: 4922.029679298401\n",
      "  timestamp: 1554813220\n",
      "  timesteps_since_restore: 1920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 192\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4922 s, 192 iter, 1920000 ts, -90.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-34-06\n",
      "  done: false\n",
      "  episode_len_mean: 91.21818181818182\n",
      "  episode_reward_max: 6.576533937872898\n",
      "  episode_reward_mean: -77.98969644506528\n",
      "  episode_reward_min: -200.06318833522351\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 19541\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4145.991\n",
      "    load_time_ms: 1.528\n",
      "    num_steps_sampled: 1930000\n",
      "    num_steps_trained: 1930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.04513543099164963\n",
      "      kl: 0.0050500440411269665\n",
      "      policy_loss: 0.0008738961769267917\n",
      "      total_loss: 1373.144775390625\n",
      "      vf_explained_var: 0.45943304896354675\n",
      "      vf_loss: 1373.143798828125\n",
      "    sample_time_ms: 20582.451\n",
      "    update_time_ms: 5.717\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.994848222532646\n",
      "  time_since_restore: 4948.218046665192\n",
      "  time_this_iter_s: 26.18836736679077\n",
      "  time_total_s: 4948.218046665192\n",
      "  timestamp: 1554813246\n",
      "  timesteps_since_restore: 1930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1930000\n",
      "  training_iteration: 193\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4948 s, 193 iter, 1930000 ts, -78 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-34-30\n",
      "  done: false\n",
      "  episode_len_mean: 86.36206896551724\n",
      "  episode_reward_max: 6.210101750636425\n",
      "  episode_reward_mean: -87.99357450246876\n",
      "  episode_reward_min: -200.0435492851741\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 19657\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4145.903\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 1940000\n",
      "    num_steps_trained: 1940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.03135902062058449\n",
      "      kl: 0.008072548545897007\n",
      "      policy_loss: -0.0007321570883505046\n",
      "      total_loss: 1390.1336669921875\n",
      "      vf_explained_var: 0.5148402452468872\n",
      "      vf_loss: 1390.134521484375\n",
      "    sample_time_ms: 20581.394\n",
      "    update_time_ms: 5.592\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.99678725123438\n",
      "  time_since_restore: 4972.0847425460815\n",
      "  time_this_iter_s: 23.866695880889893\n",
      "  time_total_s: 4972.0847425460815\n",
      "  timestamp: 1554813270\n",
      "  timesteps_since_restore: 1940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1940000\n",
      "  training_iteration: 194\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4972 s, 194 iter, 1940000 ts, -88 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-34-53\n",
      "  done: false\n",
      "  episode_len_mean: 92.20370370370371\n",
      "  episode_reward_max: 5.462469802009991\n",
      "  episode_reward_mean: -76.04278104798321\n",
      "  episode_reward_min: -200.06505021904206\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 19765\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4147.485\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.025964323431253433\n",
      "      kl: 0.008235311135649681\n",
      "      policy_loss: -0.0005859780358150601\n",
      "      total_loss: 1407.458984375\n",
      "      vf_explained_var: 0.4591712951660156\n",
      "      vf_loss: 1407.4593505859375\n",
      "    sample_time_ms: 20551.115\n",
      "    update_time_ms: 5.601\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.0213905239916\n",
      "  time_since_restore: 4995.589957952499\n",
      "  time_this_iter_s: 23.505215406417847\n",
      "  time_total_s: 4995.589957952499\n",
      "  timestamp: 1554813293\n",
      "  timesteps_since_restore: 1950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 195\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 4995 s, 195 iter, 1950000 ts, -76 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-35-16\n",
      "  done: false\n",
      "  episode_len_mean: 88.16666666666667\n",
      "  episode_reward_max: 5.418876738527423\n",
      "  episode_reward_mean: -84.37625257708044\n",
      "  episode_reward_min: -200.0553371324101\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 19879\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4144.069\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 1960000\n",
      "    num_steps_trained: 1960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.01384457852691412\n",
      "      kl: 0.008890613913536072\n",
      "      policy_loss: -0.00047565108980052173\n",
      "      total_loss: 1389.9068603515625\n",
      "      vf_explained_var: 0.49786505103111267\n",
      "      vf_loss: 1389.9072265625\n",
      "    sample_time_ms: 20433.22\n",
      "    update_time_ms: 5.737\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.18812628854022\n",
      "  time_since_restore: 5018.694082260132\n",
      "  time_this_iter_s: 23.104124307632446\n",
      "  time_total_s: 5018.694082260132\n",
      "  timestamp: 1554813316\n",
      "  timesteps_since_restore: 1960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1960000\n",
      "  training_iteration: 196\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5018 s, 196 iter, 1960000 ts, -84.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-35-39\n",
      "  done: false\n",
      "  episode_len_mean: 86.39655172413794\n",
      "  episode_reward_max: 7.123942246471488\n",
      "  episode_reward_mean: -90.05394365260707\n",
      "  episode_reward_min: -200.06028023664283\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 19995\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4143.491\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 1970000\n",
      "    num_steps_trained: 1970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.004233319777995348\n",
      "      kl: 0.007120548747479916\n",
      "      policy_loss: -0.0010772228706628084\n",
      "      total_loss: 1298.405029296875\n",
      "      vf_explained_var: 0.5203872919082642\n",
      "      vf_loss: 1298.406005859375\n",
      "    sample_time_ms: 20329.797\n",
      "    update_time_ms: 5.677\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.02697182630353\n",
      "  time_since_restore: 5040.871532917023\n",
      "  time_this_iter_s: 22.17745065689087\n",
      "  time_total_s: 5040.871532917023\n",
      "  timestamp: 1554813339\n",
      "  timesteps_since_restore: 1970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1970000\n",
      "  training_iteration: 197\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5040 s, 197 iter, 1970000 ts, -90.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-36-02\n",
      "  done: false\n",
      "  episode_len_mean: 86.8\n",
      "  episode_reward_max: 5.699526805832864\n",
      "  episode_reward_mean: -89.0190860672968\n",
      "  episode_reward_min: -200.0413913988466\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 20110\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4148.216\n",
      "    load_time_ms: 1.533\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0015686778351664543\n",
      "      kl: 0.0078408382833004\n",
      "      policy_loss: -0.0006564141367562115\n",
      "      total_loss: 1406.7955322265625\n",
      "      vf_explained_var: 0.49615204334259033\n",
      "      vf_loss: 1406.7960205078125\n",
      "    sample_time_ms: 20214.581\n",
      "    update_time_ms: 5.765\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.50954303364839\n",
      "  time_since_restore: 5064.031035423279\n",
      "  time_this_iter_s: 23.159502506256104\n",
      "  time_total_s: 5064.031035423279\n",
      "  timestamp: 1554813362\n",
      "  timesteps_since_restore: 1980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 198\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5064 s, 198 iter, 1980000 ts, -89 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-36-25\n",
      "  done: false\n",
      "  episode_len_mean: 93.48598130841121\n",
      "  episode_reward_max: 5.214538615239096\n",
      "  episode_reward_mean: -69.5748762224599\n",
      "  episode_reward_min: -200.0752615824191\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 20217\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4099.455\n",
      "    load_time_ms: 1.492\n",
      "    num_steps_sampled: 1990000\n",
      "    num_steps_trained: 1990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0019206299912184477\n",
      "      kl: 0.0077630518935620785\n",
      "      policy_loss: -0.0022786695044487715\n",
      "      total_loss: 1424.817138671875\n",
      "      vf_explained_var: 0.46424269676208496\n",
      "      vf_loss: 1424.8194580078125\n",
      "    sample_time_ms: 20223.799\n",
      "    update_time_ms: 5.746\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.78743811122995\n",
      "  time_since_restore: 5087.644759654999\n",
      "  time_this_iter_s: 23.61372423171997\n",
      "  time_total_s: 5087.644759654999\n",
      "  timestamp: 1554813385\n",
      "  timesteps_since_restore: 1990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1990000\n",
      "  training_iteration: 199\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5087 s, 199 iter, 1990000 ts, -69.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-36-49\n",
      "  done: false\n",
      "  episode_len_mean: 93.11111111111111\n",
      "  episode_reward_max: 5.981277011226606\n",
      "  episode_reward_mean: -70.37926899432652\n",
      "  episode_reward_min: -200.0211844445809\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20325\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4098.715\n",
      "    load_time_ms: 1.475\n",
      "    num_steps_sampled: 2000000\n",
      "    num_steps_trained: 2000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.005530636291950941\n",
      "      kl: 0.0069718086160719395\n",
      "      policy_loss: 2.9634206839546096e-06\n",
      "      total_loss: 1471.85302734375\n",
      "      vf_explained_var: 0.4333989918231964\n",
      "      vf_loss: 1471.8529052734375\n",
      "    sample_time_ms: 20092.28\n",
      "    update_time_ms: 5.751\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.18963449716326\n",
      "  time_since_restore: 5110.812861204147\n",
      "  time_this_iter_s: 23.16810154914856\n",
      "  time_total_s: 5110.812861204147\n",
      "  timestamp: 1554813409\n",
      "  timesteps_since_restore: 2000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2000000\n",
      "  training_iteration: 200\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5110 s, 200 iter, 2000000 ts, -70.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-37-12\n",
      "  done: false\n",
      "  episode_len_mean: 86.62608695652175\n",
      "  episode_reward_max: 5.449080414335418\n",
      "  episode_reward_mean: -88.75894748495388\n",
      "  episode_reward_min: -200.0676575692708\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 20440\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4091.723\n",
      "    load_time_ms: 1.474\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.006846241652965546\n",
      "      kl: 0.006486778147518635\n",
      "      policy_loss: -0.0008045132271945477\n",
      "      total_loss: 1351.4266357421875\n",
      "      vf_explained_var: 0.5160555839538574\n",
      "      vf_loss: 1351.427490234375\n",
      "    sample_time_ms: 19660.59\n",
      "    update_time_ms: 5.65\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.379473742476925\n",
      "  time_since_restore: 5133.838196754456\n",
      "  time_this_iter_s: 23.025335550308228\n",
      "  time_total_s: 5133.838196754456\n",
      "  timestamp: 1554813432\n",
      "  timesteps_since_restore: 2010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 201\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5133 s, 201 iter, 2010000 ts, -88.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-37-35\n",
      "  done: false\n",
      "  episode_len_mean: 87.46491228070175\n",
      "  episode_reward_max: 5.929842213384575\n",
      "  episode_reward_mean: -87.79999853384439\n",
      "  episode_reward_min: -200.0445920985763\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 20554\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4070.0\n",
      "    load_time_ms: 1.489\n",
      "    num_steps_sampled: 2020000\n",
      "    num_steps_trained: 2020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.01465810276567936\n",
      "      kl: 0.007478468585759401\n",
      "      policy_loss: -0.0006937580183148384\n",
      "      total_loss: 1395.271484375\n",
      "      vf_explained_var: 0.5110005140304565\n",
      "      vf_loss: 1395.272216796875\n",
      "    sample_time_ms: 19423.793\n",
      "    update_time_ms: 5.632\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.899999266922194\n",
      "  time_since_restore: 5157.227082967758\n",
      "  time_this_iter_s: 23.388886213302612\n",
      "  time_total_s: 5157.227082967758\n",
      "  timestamp: 1554813455\n",
      "  timesteps_since_restore: 2020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2020000\n",
      "  training_iteration: 202\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5157 s, 202 iter, 2020000 ts, -87.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-37-59\n",
      "  done: false\n",
      "  episode_len_mean: 89.8108108108108\n",
      "  episode_reward_max: 4.545261794328638\n",
      "  episode_reward_mean: -79.38709183246188\n",
      "  episode_reward_min: -200.05387388893445\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 20665\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4045.527\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 2030000\n",
      "    num_steps_trained: 2030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.02021714113652706\n",
      "      kl: 0.007570416666567326\n",
      "      policy_loss: -6.246910925256088e-05\n",
      "      total_loss: 1387.478515625\n",
      "      vf_explained_var: 0.49023139476776123\n",
      "      vf_loss: 1387.478759765625\n",
      "    sample_time_ms: 19205.236\n",
      "    update_time_ms: 5.614\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.69354591623094\n",
      "  time_since_restore: 5180.988281011581\n",
      "  time_this_iter_s: 23.761198043823242\n",
      "  time_total_s: 5180.988281011581\n",
      "  timestamp: 1554813479\n",
      "  timesteps_since_restore: 2030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2030000\n",
      "  training_iteration: 203\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5180 s, 203 iter, 2030000 ts, -79.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-38-22\n",
      "  done: false\n",
      "  episode_len_mean: 92.24074074074075\n",
      "  episode_reward_max: 6.046882188879195\n",
      "  episode_reward_mean: -73.77190007129272\n",
      "  episode_reward_min: -200.05605840574367\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 20773\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4042.335\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.02333027310669422\n",
      "      kl: 0.008333898149430752\n",
      "      policy_loss: -0.0006228058482520282\n",
      "      total_loss: 1448.790283203125\n",
      "      vf_explained_var: 0.4646037220954895\n",
      "      vf_loss: 1448.7908935546875\n",
      "    sample_time_ms: 19153.725\n",
      "    update_time_ms: 5.594\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.88595003564636\n",
      "  time_since_restore: 5204.30460357666\n",
      "  time_this_iter_s: 23.316322565078735\n",
      "  time_total_s: 5204.30460357666\n",
      "  timestamp: 1554813502\n",
      "  timesteps_since_restore: 2040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 204\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5204 s, 204 iter, 2040000 ts, -73.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-38-46\n",
      "  done: false\n",
      "  episode_len_mean: 87.12173913043478\n",
      "  episode_reward_max: 5.9582460973534115\n",
      "  episode_reward_mean: -86.72139616638238\n",
      "  episode_reward_min: -200.0711306133868\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 20888\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4039.393\n",
      "    load_time_ms: 1.525\n",
      "    num_steps_sampled: 2050000\n",
      "    num_steps_trained: 2050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.03578464314341545\n",
      "      kl: 0.009052514098584652\n",
      "      policy_loss: -0.001488984446041286\n",
      "      total_loss: 1406.7471923828125\n",
      "      vf_explained_var: 0.4593697190284729\n",
      "      vf_loss: 1406.748779296875\n",
      "    sample_time_ms: 19156.777\n",
      "    update_time_ms: 5.616\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.3606980831912\n",
      "  time_since_restore: 5227.81266951561\n",
      "  time_this_iter_s: 23.508065938949585\n",
      "  time_total_s: 5227.81266951561\n",
      "  timestamp: 1554813526\n",
      "  timesteps_since_restore: 2050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2050000\n",
      "  training_iteration: 205\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5227 s, 205 iter, 2050000 ts, -86.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-39-08\n",
      "  done: false\n",
      "  episode_len_mean: 83.19834710743801\n",
      "  episode_reward_max: 6.026841957494586\n",
      "  episode_reward_mean: -97.52048348870755\n",
      "  episode_reward_min: -200.0589236084271\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 21009\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4036.744\n",
      "    load_time_ms: 1.483\n",
      "    num_steps_sampled: 2060000\n",
      "    num_steps_trained: 2060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.05047134310007095\n",
      "      kl: 0.007282715756446123\n",
      "      policy_loss: -0.00011759585322579369\n",
      "      total_loss: 1341.9862060546875\n",
      "      vf_explained_var: 0.5313159227371216\n",
      "      vf_loss: 1341.986328125\n",
      "    sample_time_ms: 19097.82\n",
      "    update_time_ms: 5.683\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.76024174435377\n",
      "  time_since_restore: 5250.3023290634155\n",
      "  time_this_iter_s: 22.489659547805786\n",
      "  time_total_s: 5250.3023290634155\n",
      "  timestamp: 1554813548\n",
      "  timesteps_since_restore: 2060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2060000\n",
      "  training_iteration: 206\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5250 s, 206 iter, 2060000 ts, -97.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-39-33\n",
      "  done: false\n",
      "  episode_len_mean: 86.26724137931035\n",
      "  episode_reward_max: 6.088276935385286\n",
      "  episode_reward_mean: -89.55555006483081\n",
      "  episode_reward_min: -200.03083710748564\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 21125\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4042.31\n",
      "    load_time_ms: 1.511\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.05559351667761803\n",
      "      kl: 0.008771355263888836\n",
      "      policy_loss: -0.001072045648470521\n",
      "      total_loss: 1381.2880859375\n",
      "      vf_explained_var: 0.5068551301956177\n",
      "      vf_loss: 1381.2890625\n",
      "    sample_time_ms: 19323.533\n",
      "    update_time_ms: 5.744\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.777775032415406\n",
      "  time_since_restore: 5274.792568206787\n",
      "  time_this_iter_s: 24.490239143371582\n",
      "  time_total_s: 5274.792568206787\n",
      "  timestamp: 1554813573\n",
      "  timesteps_since_restore: 2070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 207\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5274 s, 207 iter, 2070000 ts, -89.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-39-56\n",
      "  done: false\n",
      "  episode_len_mean: 87.71929824561404\n",
      "  episode_reward_max: 6.384490573266783\n",
      "  episode_reward_mean: -85.91805416370514\n",
      "  episode_reward_min: -200.07568677107957\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 21239\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4038.322\n",
      "    load_time_ms: 1.524\n",
      "    num_steps_sampled: 2080000\n",
      "    num_steps_trained: 2080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.06407199800014496\n",
      "      kl: 0.008828969672322273\n",
      "      policy_loss: -0.001117735169827938\n",
      "      total_loss: 1451.5908203125\n",
      "      vf_explained_var: 0.47973769903182983\n",
      "      vf_loss: 1451.5919189453125\n",
      "    sample_time_ms: 19332.022\n",
      "    update_time_ms: 5.714\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.95902708185256\n",
      "  time_since_restore: 5298.000352859497\n",
      "  time_this_iter_s: 23.20778465270996\n",
      "  time_total_s: 5298.000352859497\n",
      "  timestamp: 1554813596\n",
      "  timesteps_since_restore: 2080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2080000\n",
      "  training_iteration: 208\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5298 s, 208 iter, 2080000 ts, -85.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-40-20\n",
      "  done: false\n",
      "  episode_len_mean: 87.91150442477876\n",
      "  episode_reward_max: 5.552939536294699\n",
      "  episode_reward_mean: -86.87648904912079\n",
      "  episode_reward_min: -200.06037577797443\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 21352\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4034.173\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 2090000\n",
      "    num_steps_trained: 2090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07085493206977844\n",
      "      kl: 0.009788251481950283\n",
      "      policy_loss: 0.0005698312888853252\n",
      "      total_loss: 1452.319580078125\n",
      "      vf_explained_var: 0.44483068585395813\n",
      "      vf_loss: 1452.3189697265625\n",
      "    sample_time_ms: 19356.939\n",
      "    update_time_ms: 5.448\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.438244524560396\n",
      "  time_since_restore: 5321.820973157883\n",
      "  time_this_iter_s: 23.82062029838562\n",
      "  time_total_s: 5321.820973157883\n",
      "  timestamp: 1554813620\n",
      "  timesteps_since_restore: 2090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2090000\n",
      "  training_iteration: 209\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5321 s, 209 iter, 2090000 ts, -86.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-40-43\n",
      "  done: false\n",
      "  episode_len_mean: 84.42372881355932\n",
      "  episode_reward_max: 5.821803249031643\n",
      "  episode_reward_mean: -95.04817166815454\n",
      "  episode_reward_min: -200.0512149441444\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 21470\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4033.393\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07784973829984665\n",
      "      kl: 0.00777012575417757\n",
      "      policy_loss: 0.0008450091117992997\n",
      "      total_loss: 1367.437744140625\n",
      "      vf_explained_var: 0.5035943388938904\n",
      "      vf_loss: 1367.4368896484375\n",
      "    sample_time_ms: 19364.004\n",
      "    update_time_ms: 5.534\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.52408583407729\n",
      "  time_since_restore: 5345.053321361542\n",
      "  time_this_iter_s: 23.232348203659058\n",
      "  time_total_s: 5345.053321361542\n",
      "  timestamp: 1554813643\n",
      "  timesteps_since_restore: 2100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 210\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5345 s, 210 iter, 2100000 ts, -95 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-41-07\n",
      "  done: false\n",
      "  episode_len_mean: 84.74789915966386\n",
      "  episode_reward_max: 5.887107472393604\n",
      "  episode_reward_mean: -94.13809616450968\n",
      "  episode_reward_min: -200.07580757990536\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 21589\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4031.279\n",
      "    load_time_ms: 1.65\n",
      "    num_steps_sampled: 2110000\n",
      "    num_steps_trained: 2110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08813593536615372\n",
      "      kl: 0.007008179556578398\n",
      "      policy_loss: -0.00029219724819995463\n",
      "      total_loss: 1387.2515869140625\n",
      "      vf_explained_var: 0.5109673142433167\n",
      "      vf_loss: 1387.251953125\n",
      "    sample_time_ms: 19410.549\n",
      "    update_time_ms: 5.498\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.06904808225485\n",
      "  time_since_restore: 5368.523873329163\n",
      "  time_this_iter_s: 23.47055196762085\n",
      "  time_total_s: 5368.523873329163\n",
      "  timestamp: 1554813667\n",
      "  timesteps_since_restore: 2110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2110000\n",
      "  training_iteration: 211\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5368 s, 211 iter, 2110000 ts, -94.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-41-31\n",
      "  done: false\n",
      "  episode_len_mean: 89.98214285714286\n",
      "  episode_reward_max: 6.20868509999593\n",
      "  episode_reward_mean: -80.38809905639404\n",
      "  episode_reward_min: -200.09724107808813\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 21701\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4033.953\n",
      "    load_time_ms: 1.641\n",
      "    num_steps_sampled: 2120000\n",
      "    num_steps_trained: 2120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09156481176614761\n",
      "      kl: 0.006232903804630041\n",
      "      policy_loss: -0.00010424336505820975\n",
      "      total_loss: 1400.4862060546875\n",
      "      vf_explained_var: 0.4878145754337311\n",
      "      vf_loss: 1400.486328125\n",
      "    sample_time_ms: 19447.137\n",
      "    update_time_ms: 5.601\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.19404952819702\n",
      "  time_since_restore: 5392.303717374802\n",
      "  time_this_iter_s: 23.779844045639038\n",
      "  time_total_s: 5392.303717374802\n",
      "  timestamp: 1554813691\n",
      "  timesteps_since_restore: 2120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2120000\n",
      "  training_iteration: 212\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5392 s, 212 iter, 2120000 ts, -80.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-41-55\n",
      "  done: false\n",
      "  episode_len_mean: 86.97391304347826\n",
      "  episode_reward_max: 5.872018120800138\n",
      "  episode_reward_mean: -87.06120505102797\n",
      "  episode_reward_min: -200.05686817379797\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 21816\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4032.328\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09978904575109482\n",
      "      kl: 0.008599054999649525\n",
      "      policy_loss: -0.0019794567488133907\n",
      "      total_loss: 1347.3978271484375\n",
      "      vf_explained_var: 0.5265515446662903\n",
      "      vf_loss: 1347.3997802734375\n",
      "    sample_time_ms: 19458.18\n",
      "    update_time_ms: 5.632\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.53060252551399\n",
      "  time_since_restore: 5416.1576046943665\n",
      "  time_this_iter_s: 23.85388731956482\n",
      "  time_total_s: 5416.1576046943665\n",
      "  timestamp: 1554813715\n",
      "  timesteps_since_restore: 2130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 213\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5416 s, 213 iter, 2130000 ts, -87.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-42-19\n",
      "  done: false\n",
      "  episode_len_mean: 87.99115044247787\n",
      "  episode_reward_max: 6.357846001309749\n",
      "  episode_reward_mean: -86.82266592254199\n",
      "  episode_reward_min: -200.08741319435154\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 21929\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4037.93\n",
      "    load_time_ms: 1.631\n",
      "    num_steps_sampled: 2140000\n",
      "    num_steps_trained: 2140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10765758156776428\n",
      "      kl: 0.008060870692133904\n",
      "      policy_loss: -0.0008089284528978169\n",
      "      total_loss: 1396.050048828125\n",
      "      vf_explained_var: 0.5285910367965698\n",
      "      vf_loss: 1396.0509033203125\n",
      "    sample_time_ms: 19555.355\n",
      "    update_time_ms: 5.626\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.411332961271\n",
      "  time_since_restore: 5440.501574277878\n",
      "  time_this_iter_s: 24.343969583511353\n",
      "  time_total_s: 5440.501574277878\n",
      "  timestamp: 1554813739\n",
      "  timesteps_since_restore: 2140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2140000\n",
      "  training_iteration: 214\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5440 s, 214 iter, 2140000 ts, -86.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-42-42\n",
      "  done: false\n",
      "  episode_len_mean: 85.00847457627118\n",
      "  episode_reward_max: 6.093580030641624\n",
      "  episode_reward_mean: -94.49277170638987\n",
      "  episode_reward_min: -200.05432000893592\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 22047\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4046.55\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 2150000\n",
      "    num_steps_trained: 2150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11636711657047272\n",
      "      kl: 0.009899156168103218\n",
      "      policy_loss: -0.002755922731012106\n",
      "      total_loss: 1375.152099609375\n",
      "      vf_explained_var: 0.5369910001754761\n",
      "      vf_loss: 1375.1549072265625\n",
      "    sample_time_ms: 19518.597\n",
      "    update_time_ms: 5.575\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.24638585319493\n",
      "  time_since_restore: 5463.728644371033\n",
      "  time_this_iter_s: 23.227070093154907\n",
      "  time_total_s: 5463.728644371033\n",
      "  timestamp: 1554813762\n",
      "  timesteps_since_restore: 2150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2150000\n",
      "  training_iteration: 215\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5463 s, 215 iter, 2150000 ts, -94.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-43-06\n",
      "  done: false\n",
      "  episode_len_mean: 89.46846846846847\n",
      "  episode_reward_max: 5.6681052059049275\n",
      "  episode_reward_mean: -82.9801182900369\n",
      "  episode_reward_min: -200.08012831164876\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 22158\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4053.25\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11558765918016434\n",
      "      kl: 0.006582813337445259\n",
      "      policy_loss: 0.0006263561663217843\n",
      "      total_loss: 1447.679931640625\n",
      "      vf_explained_var: 0.48536673188209534\n",
      "      vf_loss: 1447.6793212890625\n",
      "    sample_time_ms: 19632.317\n",
      "    update_time_ms: 5.372\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.49005914501846\n",
      "  time_since_restore: 5487.422347307205\n",
      "  time_this_iter_s: 23.693702936172485\n",
      "  time_total_s: 5487.422347307205\n",
      "  timestamp: 1554813786\n",
      "  timesteps_since_restore: 2160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 216\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5487 s, 216 iter, 2160000 ts, -83 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-43-29\n",
      "  done: false\n",
      "  episode_len_mean: 93.65420560747664\n",
      "  episode_reward_max: 5.174188198869027\n",
      "  episode_reward_mean: -70.95624223094995\n",
      "  episode_reward_min: -200.05063667382396\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 22265\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4049.613\n",
      "    load_time_ms: 1.704\n",
      "    num_steps_sampled: 2170000\n",
      "    num_steps_trained: 2170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12111495435237885\n",
      "      kl: 0.006556257139891386\n",
      "      policy_loss: 0.0005482370033860207\n",
      "      total_loss: 1541.8055419921875\n",
      "      vf_explained_var: 0.3997756838798523\n",
      "      vf_loss: 1541.804931640625\n",
      "    sample_time_ms: 19508.586\n",
      "    update_time_ms: 5.293\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.47812111547497\n",
      "  time_since_restore: 5510.640158176422\n",
      "  time_this_iter_s: 23.21781086921692\n",
      "  time_total_s: 5510.640158176422\n",
      "  timestamp: 1554813809\n",
      "  timesteps_since_restore: 2170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2170000\n",
      "  training_iteration: 217\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5510 s, 217 iter, 2170000 ts, -71 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-43-53\n",
      "  done: false\n",
      "  episode_len_mean: 90.89090909090909\n",
      "  episode_reward_max: 5.957361457759461\n",
      "  episode_reward_mean: -78.51180458171916\n",
      "  episode_reward_min: -200.107420215141\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 22375\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4046.269\n",
      "    load_time_ms: 1.754\n",
      "    num_steps_sampled: 2180000\n",
      "    num_steps_trained: 2180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12867984175682068\n",
      "      kl: 0.009186764247715473\n",
      "      policy_loss: -4.993837501388043e-05\n",
      "      total_loss: 1405.533203125\n",
      "      vf_explained_var: 0.49188604950904846\n",
      "      vf_loss: 1405.533203125\n",
      "    sample_time_ms: 19535.436\n",
      "    update_time_ms: 5.36\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.25590229085959\n",
      "  time_since_restore: 5534.083874464035\n",
      "  time_this_iter_s: 23.443716287612915\n",
      "  time_total_s: 5534.083874464035\n",
      "  timestamp: 1554813833\n",
      "  timesteps_since_restore: 2180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2180000\n",
      "  training_iteration: 218\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5534 s, 218 iter, 2180000 ts, -78.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-44-16\n",
      "  done: false\n",
      "  episode_len_mean: 89.00884955752213\n",
      "  episode_reward_max: 5.604339337884099\n",
      "  episode_reward_mean: -83.15710924810281\n",
      "  episode_reward_min: -200.063108217688\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 22488\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4046.123\n",
      "    load_time_ms: 1.663\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.13718560338020325\n",
      "      kl: 0.008448612876236439\n",
      "      policy_loss: -0.00042893775389529765\n",
      "      total_loss: 1437.5234375\n",
      "      vf_explained_var: 0.4698536694049835\n",
      "      vf_loss: 1437.5238037109375\n",
      "    sample_time_ms: 19471.285\n",
      "    update_time_ms: 5.416\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.57855462405142\n",
      "  time_since_restore: 5557.259313344955\n",
      "  time_this_iter_s: 23.17543888092041\n",
      "  time_total_s: 5557.259313344955\n",
      "  timestamp: 1554813856\n",
      "  timesteps_since_restore: 2190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 219\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5557 s, 219 iter, 2190000 ts, -83.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-44-40\n",
      "  done: false\n",
      "  episode_len_mean: 81.24590163934427\n",
      "  episode_reward_max: 5.8905594028987105\n",
      "  episode_reward_mean: -103.11559352049179\n",
      "  episode_reward_min: -200.10348420120698\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 22610\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4081.048\n",
      "    load_time_ms: 1.751\n",
      "    num_steps_sampled: 2200000\n",
      "    num_steps_trained: 2200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15679430961608887\n",
      "      kl: 0.0065633999183773994\n",
      "      policy_loss: -0.00010395346180303022\n",
      "      total_loss: 1376.7274169921875\n",
      "      vf_explained_var: 0.5056353807449341\n",
      "      vf_loss: 1376.7274169921875\n",
      "    sample_time_ms: 19548.958\n",
      "    update_time_ms: 5.293\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.5577967602459\n",
      "  time_since_restore: 5581.617712497711\n",
      "  time_this_iter_s: 24.358399152755737\n",
      "  time_total_s: 5581.617712497711\n",
      "  timestamp: 1554813880\n",
      "  timesteps_since_restore: 2200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2200000\n",
      "  training_iteration: 220\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5581 s, 220 iter, 2200000 ts, -103 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-45-08\n",
      "  done: false\n",
      "  episode_len_mean: 88.50877192982456\n",
      "  episode_reward_max: 5.533612325501016\n",
      "  episode_reward_mean: -86.01668412782999\n",
      "  episode_reward_min: -200.077107765989\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 22724\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4217.043\n",
      "    load_time_ms: 1.699\n",
      "    num_steps_sampled: 2210000\n",
      "    num_steps_trained: 2210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15455980598926544\n",
      "      kl: 0.008721902035176754\n",
      "      policy_loss: 0.0010790704982355237\n",
      "      total_loss: 1394.146240234375\n",
      "      vf_explained_var: 0.49569693207740784\n",
      "      vf_loss: 1394.145263671875\n",
      "    sample_time_ms: 19780.032\n",
      "    update_time_ms: 5.608\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.00834206391498\n",
      "  time_since_restore: 5608.762153148651\n",
      "  time_this_iter_s: 27.14444065093994\n",
      "  time_total_s: 5608.762153148651\n",
      "  timestamp: 1554813908\n",
      "  timesteps_since_restore: 2210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2210000\n",
      "  training_iteration: 221\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5608 s, 221 iter, 2210000 ts, -86 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-45-33\n",
      "  done: false\n",
      "  episode_len_mean: 85.0\n",
      "  episode_reward_max: 5.073032600827024\n",
      "  episode_reward_mean: -93.34734888635903\n",
      "  episode_reward_min: -200.0516678834045\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 22840\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4220.952\n",
      "    load_time_ms: 1.69\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1751224547624588\n",
      "      kl: 0.009625321254134178\n",
      "      policy_loss: 0.001257454976439476\n",
      "      total_loss: 1395.7657470703125\n",
      "      vf_explained_var: 0.49587318301200867\n",
      "      vf_loss: 1395.764404296875\n",
      "    sample_time_ms: 19952.189\n",
      "    update_time_ms: 5.466\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.67367444317952\n",
      "  time_since_restore: 5634.300575733185\n",
      "  time_this_iter_s: 25.53842258453369\n",
      "  time_total_s: 5634.300575733185\n",
      "  timestamp: 1554813933\n",
      "  timesteps_since_restore: 2220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 222\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5634 s, 222 iter, 2220000 ts, -93.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-45-58\n",
      "  done: false\n",
      "  episode_len_mean: 91.16363636363636\n",
      "  episode_reward_max: 5.85833955093646\n",
      "  episode_reward_mean: -78.15264729801328\n",
      "  episode_reward_min: -200.06660443853298\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 22950\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4224.032\n",
      "    load_time_ms: 1.67\n",
      "    num_steps_sampled: 2230000\n",
      "    num_steps_trained: 2230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18050681054592133\n",
      "      kl: 0.011829683557152748\n",
      "      policy_loss: -0.00042462674900889397\n",
      "      total_loss: 1465.516845703125\n",
      "      vf_explained_var: 0.4514975845813751\n",
      "      vf_loss: 1465.5172119140625\n",
      "    sample_time_ms: 20015.738\n",
      "    update_time_ms: 5.578\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.07632364900664\n",
      "  time_since_restore: 5658.819926261902\n",
      "  time_this_iter_s: 24.51935052871704\n",
      "  time_total_s: 5658.819926261902\n",
      "  timestamp: 1554813958\n",
      "  timesteps_since_restore: 2230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2230000\n",
      "  training_iteration: 223\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5658 s, 223 iter, 2230000 ts, -78.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-46-21\n",
      "  done: false\n",
      "  episode_len_mean: 88.94690265486726\n",
      "  episode_reward_max: 5.716901024757449\n",
      "  episode_reward_mean: -81.30847424008208\n",
      "  episode_reward_min: -200.05372373500413\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 23063\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4218.066\n",
      "    load_time_ms: 1.704\n",
      "    num_steps_sampled: 2240000\n",
      "    num_steps_trained: 2240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18398517370224\n",
      "      kl: 0.011487351730465889\n",
      "      policy_loss: -0.0021818350069224834\n",
      "      total_loss: 1421.017578125\n",
      "      vf_explained_var: 0.4743979573249817\n",
      "      vf_loss: 1421.019775390625\n",
      "    sample_time_ms: 19951.849\n",
      "    update_time_ms: 5.672\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.65423712004104\n",
      "  time_since_restore: 5682.469975948334\n",
      "  time_this_iter_s: 23.650049686431885\n",
      "  time_total_s: 5682.469975948334\n",
      "  timestamp: 1554813981\n",
      "  timesteps_since_restore: 2240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2240000\n",
      "  training_iteration: 224\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5682 s, 224 iter, 2240000 ts, -81.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-46-45\n",
      "  done: false\n",
      "  episode_len_mean: 84.21848739495799\n",
      "  episode_reward_max: 5.342479837452431\n",
      "  episode_reward_mean: -94.21959506599538\n",
      "  episode_reward_min: -200.06296730353492\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 23182\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4218.137\n",
      "    load_time_ms: 1.714\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2057107537984848\n",
      "      kl: 0.010978483594954014\n",
      "      policy_loss: -0.00013683154247701168\n",
      "      total_loss: 1294.1494140625\n",
      "      vf_explained_var: 0.5294672846794128\n",
      "      vf_loss: 1294.149658203125\n",
      "    sample_time_ms: 19955.864\n",
      "    update_time_ms: 5.605\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.10979753299768\n",
      "  time_since_restore: 5705.7376074790955\n",
      "  time_this_iter_s: 23.26763153076172\n",
      "  time_total_s: 5705.7376074790955\n",
      "  timestamp: 1554814005\n",
      "  timesteps_since_restore: 2250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 225\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5705 s, 225 iter, 2250000 ts, -94.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-47-08\n",
      "  done: false\n",
      "  episode_len_mean: 84.41525423728814\n",
      "  episode_reward_max: 4.257465132389832\n",
      "  episode_reward_mean: -95.24366134409387\n",
      "  episode_reward_min: -200.10236972748424\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 23300\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4213.799\n",
      "    load_time_ms: 1.714\n",
      "    num_steps_sampled: 2260000\n",
      "    num_steps_trained: 2260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21674206852912903\n",
      "      kl: 0.009810457937419415\n",
      "      policy_loss: 0.0006133306305855513\n",
      "      total_loss: 1355.2821044921875\n",
      "      vf_explained_var: 0.5424214601516724\n",
      "      vf_loss: 1355.2816162109375\n",
      "    sample_time_ms: 19880.266\n",
      "    update_time_ms: 5.699\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.62183067204694\n",
      "  time_since_restore: 5728.631224155426\n",
      "  time_this_iter_s: 22.893616676330566\n",
      "  time_total_s: 5728.631224155426\n",
      "  timestamp: 1554814028\n",
      "  timesteps_since_restore: 2260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2260000\n",
      "  training_iteration: 226\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5728 s, 226 iter, 2260000 ts, -95.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-47-31\n",
      "  done: false\n",
      "  episode_len_mean: 86.27350427350427\n",
      "  episode_reward_max: 4.905248070039956\n",
      "  episode_reward_mean: -90.89388252001282\n",
      "  episode_reward_min: -200.04891351758556\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 23417\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4214.795\n",
      "    load_time_ms: 1.756\n",
      "    num_steps_sampled: 2270000\n",
      "    num_steps_trained: 2270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22256726026535034\n",
      "      kl: 0.009435624815523624\n",
      "      policy_loss: 0.00023189187049865723\n",
      "      total_loss: 1380.9412841796875\n",
      "      vf_explained_var: 0.5235162377357483\n",
      "      vf_loss: 1380.941162109375\n",
      "    sample_time_ms: 19870.24\n",
      "    update_time_ms: 5.615\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.44694126000642\n",
      "  time_since_restore: 5751.760372161865\n",
      "  time_this_iter_s: 23.12914800643921\n",
      "  time_total_s: 5751.760372161865\n",
      "  timestamp: 1554814051\n",
      "  timesteps_since_restore: 2270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2270000\n",
      "  training_iteration: 227\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5751 s, 227 iter, 2270000 ts, -90.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-47-54\n",
      "  done: false\n",
      "  episode_len_mean: 80.8130081300813\n",
      "  episode_reward_max: 7.897377485954982\n",
      "  episode_reward_mean: -105.69754122016771\n",
      "  episode_reward_min: -200.06584441945472\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 23540\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4218.483\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.25137755274772644\n",
      "      kl: 0.012172498740255833\n",
      "      policy_loss: 0.0014417377533391118\n",
      "      total_loss: 1340.9610595703125\n",
      "      vf_explained_var: 0.5491021871566772\n",
      "      vf_loss: 1340.9595947265625\n",
      "    sample_time_ms: 19811.637\n",
      "    update_time_ms: 5.436\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.84877061008387\n",
      "  time_since_restore: 5774.648570537567\n",
      "  time_this_iter_s: 22.888198375701904\n",
      "  time_total_s: 5774.648570537567\n",
      "  timestamp: 1554814074\n",
      "  timesteps_since_restore: 2280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 228\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5774 s, 228 iter, 2280000 ts, -106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-48-17\n",
      "  done: false\n",
      "  episode_len_mean: 85.64102564102564\n",
      "  episode_reward_max: 6.12864083476349\n",
      "  episode_reward_mean: -90.68117562467228\n",
      "  episode_reward_min: -200.05159629156805\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 23657\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4219.356\n",
      "    load_time_ms: 1.711\n",
      "    num_steps_sampled: 2290000\n",
      "    num_steps_trained: 2290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.23552654683589935\n",
      "      kl: 0.00837098341435194\n",
      "      policy_loss: 0.00035881498479284346\n",
      "      total_loss: 1359.6893310546875\n",
      "      vf_explained_var: 0.5070210695266724\n",
      "      vf_loss: 1359.6888427734375\n",
      "    sample_time_ms: 19826.052\n",
      "    update_time_ms: 5.395\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.340587812336125\n",
      "  time_since_restore: 5797.977843284607\n",
      "  time_this_iter_s: 23.329272747039795\n",
      "  time_total_s: 5797.977843284607\n",
      "  timestamp: 1554814097\n",
      "  timesteps_since_restore: 2290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2290000\n",
      "  training_iteration: 229\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5797 s, 229 iter, 2290000 ts, -90.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-48-41\n",
      "  done: false\n",
      "  episode_len_mean: 97.26470588235294\n",
      "  episode_reward_max: 5.1086977648489595\n",
      "  episode_reward_mean: -61.05055224100425\n",
      "  episode_reward_min: -200.09006292522213\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 23759\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4185.137\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 2300000\n",
      "    num_steps_trained: 2300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2383134812116623\n",
      "      kl: 0.011902732774615288\n",
      "      policy_loss: 0.0017917787190526724\n",
      "      total_loss: 1511.1328125\n",
      "      vf_explained_var: 0.4174451529979706\n",
      "      vf_loss: 1511.1309814453125\n",
      "    sample_time_ms: 19849.57\n",
      "    update_time_ms: 5.54\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -30.525276120502113\n",
      "  time_since_restore: 5822.231654882431\n",
      "  time_this_iter_s: 24.253811597824097\n",
      "  time_total_s: 5822.231654882431\n",
      "  timestamp: 1554814121\n",
      "  timesteps_since_restore: 2300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2300000\n",
      "  training_iteration: 230\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5822 s, 230 iter, 2300000 ts, -61.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-49-06\n",
      "  done: false\n",
      "  episode_len_mean: 82.28688524590164\n",
      "  episode_reward_max: 5.115157033019147\n",
      "  episode_reward_mean: -101.89225388322606\n",
      "  episode_reward_min: -200.08874483577713\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 23881\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4051.581\n",
      "    load_time_ms: 1.731\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2651759684085846\n",
      "      kl: 0.009924951009452343\n",
      "      policy_loss: -0.0013065304374322295\n",
      "      total_loss: 1290.0777587890625\n",
      "      vf_explained_var: 0.5508829951286316\n",
      "      vf_loss: 1290.0791015625\n",
      "    sample_time_ms: 19686.586\n",
      "    update_time_ms: 5.129\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.94612694161303\n",
      "  time_since_restore: 5846.405236721039\n",
      "  time_this_iter_s: 24.173581838607788\n",
      "  time_total_s: 5846.405236721039\n",
      "  timestamp: 1554814146\n",
      "  timesteps_since_restore: 2310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 231\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5846 s, 231 iter, 2310000 ts, -102 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-49-28\n",
      "  done: false\n",
      "  episode_len_mean: 86.44827586206897\n",
      "  episode_reward_max: 5.330489900008209\n",
      "  episode_reward_mean: -89.39831038991798\n",
      "  episode_reward_min: -200.07603677915785\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 23997\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4046.205\n",
      "    load_time_ms: 1.784\n",
      "    num_steps_sampled: 2320000\n",
      "    num_steps_trained: 2320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2681059241294861\n",
      "      kl: 0.008702438324689865\n",
      "      policy_loss: -2.1770596504211426e-05\n",
      "      total_loss: 1431.613037109375\n",
      "      vf_explained_var: 0.468283087015152\n",
      "      vf_loss: 1431.613037109375\n",
      "    sample_time_ms: 19380.063\n",
      "    update_time_ms: 6.182\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.699155194959\n",
      "  time_since_restore: 5868.839525222778\n",
      "  time_this_iter_s: 22.434288501739502\n",
      "  time_total_s: 5868.839525222778\n",
      "  timestamp: 1554814168\n",
      "  timesteps_since_restore: 2320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2320000\n",
      "  training_iteration: 232\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5868 s, 232 iter, 2320000 ts, -89.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-49-51\n",
      "  done: false\n",
      "  episode_len_mean: 90.2090909090909\n",
      "  episode_reward_max: 6.164839452605279\n",
      "  episode_reward_mean: -80.06010395526678\n",
      "  episode_reward_min: -200.04614391147385\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 24107\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4048.141\n",
      "    load_time_ms: 1.814\n",
      "    num_steps_sampled: 2330000\n",
      "    num_steps_trained: 2330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.27921751141548157\n",
      "      kl: 0.009380907751619816\n",
      "      policy_loss: 0.0006243723910301924\n",
      "      total_loss: 1430.7615966796875\n",
      "      vf_explained_var: 0.47158876061439514\n",
      "      vf_loss: 1430.760986328125\n",
      "    sample_time_ms: 19261.894\n",
      "    update_time_ms: 6.14\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.03005197763339\n",
      "  time_since_restore: 5892.197424888611\n",
      "  time_this_iter_s: 23.35789966583252\n",
      "  time_total_s: 5892.197424888611\n",
      "  timestamp: 1554814191\n",
      "  timesteps_since_restore: 2330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2330000\n",
      "  training_iteration: 233\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5892 s, 233 iter, 2330000 ts, -80.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-50-14\n",
      "  done: false\n",
      "  episode_len_mean: 88.06140350877193\n",
      "  episode_reward_max: 5.184684470589399\n",
      "  episode_reward_mean: -86.14416986071636\n",
      "  episode_reward_min: -200.06273737937195\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 24221\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4048.435\n",
      "    load_time_ms: 1.783\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.291837602853775\n",
      "      kl: 0.009135781787335873\n",
      "      policy_loss: 0.0014337527099996805\n",
      "      total_loss: 1380.7730712890625\n",
      "      vf_explained_var: 0.48162728548049927\n",
      "      vf_loss: 1380.771484375\n",
      "    sample_time_ms: 19194.968\n",
      "    update_time_ms: 6.089\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.07208493035818\n",
      "  time_since_restore: 5915.177279949188\n",
      "  time_this_iter_s: 22.979855060577393\n",
      "  time_total_s: 5915.177279949188\n",
      "  timestamp: 1554814214\n",
      "  timesteps_since_restore: 2340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 234\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5915 s, 234 iter, 2340000 ts, -86.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-50-39\n",
      "  done: false\n",
      "  episode_len_mean: 89.8018018018018\n",
      "  episode_reward_max: 5.841946235673381\n",
      "  episode_reward_mean: -81.27819067268211\n",
      "  episode_reward_min: -200.08841828216592\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 24332\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4041.515\n",
      "    load_time_ms: 1.764\n",
      "    num_steps_sampled: 2350000\n",
      "    num_steps_trained: 2350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.289346843957901\n",
      "      kl: 0.010512694716453552\n",
      "      policy_loss: 0.00046298711095005274\n",
      "      total_loss: 1406.0325927734375\n",
      "      vf_explained_var: 0.47820213437080383\n",
      "      vf_loss: 1406.0322265625\n",
      "    sample_time_ms: 19288.536\n",
      "    update_time_ms: 6.169\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.63909533634105\n",
      "  time_since_restore: 5939.310576200485\n",
      "  time_this_iter_s: 24.133296251296997\n",
      "  time_total_s: 5939.310576200485\n",
      "  timestamp: 1554814239\n",
      "  timesteps_since_restore: 2350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2350000\n",
      "  training_iteration: 235\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5939 s, 235 iter, 2350000 ts, -81.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-51-02\n",
      "  done: false\n",
      "  episode_len_mean: 88.19130434782609\n",
      "  episode_reward_max: 8.207727106853975\n",
      "  episode_reward_mean: -85.3997289829725\n",
      "  episode_reward_min: -200.07616165953087\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 24447\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4042.564\n",
      "    load_time_ms: 1.709\n",
      "    num_steps_sampled: 2360000\n",
      "    num_steps_trained: 2360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2998649775981903\n",
      "      kl: 0.011670708656311035\n",
      "      policy_loss: 0.0009361192351207137\n",
      "      total_loss: 1329.5460205078125\n",
      "      vf_explained_var: 0.5449644327163696\n",
      "      vf_loss: 1329.5450439453125\n",
      "    sample_time_ms: 19334.19\n",
      "    update_time_ms: 6.057\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.69986449148626\n",
      "  time_since_restore: 5962.667172431946\n",
      "  time_this_iter_s: 23.35659623146057\n",
      "  time_total_s: 5962.667172431946\n",
      "  timestamp: 1554814262\n",
      "  timesteps_since_restore: 2360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2360000\n",
      "  training_iteration: 236\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5962 s, 236 iter, 2360000 ts, -85.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-51-26\n",
      "  done: false\n",
      "  episode_len_mean: 90.88990825688073\n",
      "  episode_reward_max: 7.185631910276186\n",
      "  episode_reward_mean: -77.10686791956643\n",
      "  episode_reward_min: -200.06863056603464\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 24556\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4040.202\n",
      "    load_time_ms: 1.663\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.29621177911758423\n",
      "      kl: 0.008866519667208195\n",
      "      policy_loss: 0.0008565890602767467\n",
      "      total_loss: 1461.93212890625\n",
      "      vf_explained_var: 0.44178345799446106\n",
      "      vf_loss: 1461.9310302734375\n",
      "    sample_time_ms: 19393.255\n",
      "    update_time_ms: 6.305\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.55343395978321\n",
      "  time_since_restore: 5986.364337921143\n",
      "  time_this_iter_s: 23.697165489196777\n",
      "  time_total_s: 5986.364337921143\n",
      "  timestamp: 1554814286\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 237\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 5986 s, 237 iter, 2370000 ts, -77.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-51-49\n",
      "  done: false\n",
      "  episode_len_mean: 88.52631578947368\n",
      "  episode_reward_max: 6.4671211083668565\n",
      "  episode_reward_mean: -82.557792182833\n",
      "  episode_reward_min: -200.07296162953287\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 24670\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4038.743\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 2380000\n",
      "    num_steps_trained: 2380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.31078633666038513\n",
      "      kl: 0.010312343016266823\n",
      "      policy_loss: 0.0002569380449131131\n",
      "      total_loss: 1352.8997802734375\n",
      "      vf_explained_var: 0.5015813112258911\n",
      "      vf_loss: 1352.8995361328125\n",
      "    sample_time_ms: 19414.824\n",
      "    update_time_ms: 6.392\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.2788960914165\n",
      "  time_since_restore: 6009.457959890366\n",
      "  time_this_iter_s: 23.093621969223022\n",
      "  time_total_s: 6009.457959890366\n",
      "  timestamp: 1554814309\n",
      "  timesteps_since_restore: 2380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2380000\n",
      "  training_iteration: 238\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6009 s, 238 iter, 2380000 ts, -82.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-52-12\n",
      "  done: false\n",
      "  episode_len_mean: 96.63725490196079\n",
      "  episode_reward_max: 5.649176357484331\n",
      "  episode_reward_mean: -62.496352988835504\n",
      "  episode_reward_min: -200.03961523060258\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 24772\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4040.003\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 2390000\n",
      "    num_steps_trained: 2390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.313016414642334\n",
      "      kl: 0.010805664584040642\n",
      "      policy_loss: 0.00022887400700710714\n",
      "      total_loss: 1494.9136962890625\n",
      "      vf_explained_var: 0.4066542685031891\n",
      "      vf_loss: 1494.913330078125\n",
      "    sample_time_ms: 19433.956\n",
      "    update_time_ms: 6.529\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -31.248176494417738\n",
      "  time_since_restore: 6032.9901576042175\n",
      "  time_this_iter_s: 23.53219771385193\n",
      "  time_total_s: 6032.9901576042175\n",
      "  timestamp: 1554814332\n",
      "  timesteps_since_restore: 2390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2390000\n",
      "  training_iteration: 239\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6032 s, 239 iter, 2390000 ts, -62.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-52-37\n",
      "  done: false\n",
      "  episode_len_mean: 85.66666666666667\n",
      "  episode_reward_max: 5.620856707038811\n",
      "  episode_reward_mean: -92.2175152225165\n",
      "  episode_reward_min: -200.10776302165104\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 24889\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4039.599\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.32820311188697815\n",
      "      kl: 0.010660791769623756\n",
      "      policy_loss: -0.0005579027929343283\n",
      "      total_loss: 1332.058349609375\n",
      "      vf_explained_var: 0.511970043182373\n",
      "      vf_loss: 1332.058837890625\n",
      "    sample_time_ms: 19433.396\n",
      "    update_time_ms: 6.639\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.10875761125825\n",
      "  time_since_restore: 6057.23344373703\n",
      "  time_this_iter_s: 24.2432861328125\n",
      "  time_total_s: 6057.23344373703\n",
      "  timestamp: 1554814357\n",
      "  timesteps_since_restore: 2400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 240\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6057 s, 240 iter, 2400000 ts, -92.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-53-00\n",
      "  done: false\n",
      "  episode_len_mean: 88.95575221238938\n",
      "  episode_reward_max: 6.042038175639124\n",
      "  episode_reward_mean: -82.817362655937\n",
      "  episode_reward_min: -200.0628668898048\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 25002\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4041.304\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 2410000\n",
      "    num_steps_trained: 2410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3289169371128082\n",
      "      kl: 0.008273446001112461\n",
      "      policy_loss: 0.001464890199713409\n",
      "      total_loss: 1337.332763671875\n",
      "      vf_explained_var: 0.46473410725593567\n",
      "      vf_loss: 1337.331298828125\n",
      "    sample_time_ms: 19321.908\n",
      "    update_time_ms: 6.783\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.4086813279685\n",
      "  time_since_restore: 6080.310550928116\n",
      "  time_this_iter_s: 23.077107191085815\n",
      "  time_total_s: 6080.310550928116\n",
      "  timestamp: 1554814380\n",
      "  timesteps_since_restore: 2410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2410000\n",
      "  training_iteration: 241\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6080 s, 241 iter, 2410000 ts, -82.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-53-24\n",
      "  done: false\n",
      "  episode_len_mean: 89.77477477477477\n",
      "  episode_reward_max: 6.999532289005327\n",
      "  episode_reward_mean: -81.20276674963189\n",
      "  episode_reward_min: -200.08202868528093\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 25113\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4043.23\n",
      "    load_time_ms: 1.514\n",
      "    num_steps_sampled: 2420000\n",
      "    num_steps_trained: 2420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3395402431488037\n",
      "      kl: 0.01042497344315052\n",
      "      policy_loss: 0.0016664827708154917\n",
      "      total_loss: 1398.171142578125\n",
      "      vf_explained_var: 0.4929603636264801\n",
      "      vf_loss: 1398.16943359375\n",
      "    sample_time_ms: 19451.953\n",
      "    update_time_ms: 5.776\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.60138337481594\n",
      "  time_since_restore: 6104.0514233112335\n",
      "  time_this_iter_s: 23.740872383117676\n",
      "  time_total_s: 6104.0514233112335\n",
      "  timestamp: 1554814404\n",
      "  timesteps_since_restore: 2420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2420000\n",
      "  training_iteration: 242\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6104 s, 242 iter, 2420000 ts, -81.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-53-47\n",
      "  done: false\n",
      "  episode_len_mean: 91.89908256880734\n",
      "  episode_reward_max: 4.555499147281958\n",
      "  episode_reward_mean: -75.10823702822726\n",
      "  episode_reward_min: -200.0763767258681\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 25222\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4035.529\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.33997493982315063\n",
      "      kl: 0.010150950402021408\n",
      "      policy_loss: 0.0011968502076342702\n",
      "      total_loss: 1354.381591796875\n",
      "      vf_explained_var: 0.46435225009918213\n",
      "      vf_loss: 1354.38037109375\n",
      "    sample_time_ms: 19431.018\n",
      "    update_time_ms: 5.736\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.55411851411364\n",
      "  time_since_restore: 6127.123953819275\n",
      "  time_this_iter_s: 23.072530508041382\n",
      "  time_total_s: 6127.123953819275\n",
      "  timestamp: 1554814427\n",
      "  timesteps_since_restore: 2430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 243\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6127 s, 243 iter, 2430000 ts, -75.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-54-10\n",
      "  done: false\n",
      "  episode_len_mean: 88.57522123893806\n",
      "  episode_reward_max: 6.772157811339603\n",
      "  episode_reward_mean: -85.08992705704928\n",
      "  episode_reward_min: -200.08584107692218\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 25335\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4036.202\n",
      "    load_time_ms: 1.47\n",
      "    num_steps_sampled: 2440000\n",
      "    num_steps_trained: 2440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35565105080604553\n",
      "      kl: 0.011428186669945717\n",
      "      policy_loss: 0.0016554364701732993\n",
      "      total_loss: 1360.7208251953125\n",
      "      vf_explained_var: 0.4945053160190582\n",
      "      vf_loss: 1360.7191162109375\n",
      "    sample_time_ms: 19472.928\n",
      "    update_time_ms: 5.765\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.54496352852463\n",
      "  time_since_restore: 6150.5280294418335\n",
      "  time_this_iter_s: 23.404075622558594\n",
      "  time_total_s: 6150.5280294418335\n",
      "  timestamp: 1554814450\n",
      "  timesteps_since_restore: 2440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2440000\n",
      "  training_iteration: 244\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6150 s, 244 iter, 2440000 ts, -85.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-54-34\n",
      "  done: false\n",
      "  episode_len_mean: 84.21186440677967\n",
      "  episode_reward_max: 5.437033281461144\n",
      "  episode_reward_mean: -96.52661818809672\n",
      "  episode_reward_min: -200.06074656572702\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 25453\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4035.529\n",
      "    load_time_ms: 1.493\n",
      "    num_steps_sampled: 2450000\n",
      "    num_steps_trained: 2450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.36600828170776367\n",
      "      kl: 0.010293951258063316\n",
      "      policy_loss: 0.000791235244832933\n",
      "      total_loss: 1289.3634033203125\n",
      "      vf_explained_var: 0.5426000952720642\n",
      "      vf_loss: 1289.36279296875\n",
      "    sample_time_ms: 19431.65\n",
      "    update_time_ms: 5.869\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.26330909404838\n",
      "  time_since_restore: 6174.243620872498\n",
      "  time_this_iter_s: 23.715591430664062\n",
      "  time_total_s: 6174.243620872498\n",
      "  timestamp: 1554814474\n",
      "  timesteps_since_restore: 2450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2450000\n",
      "  training_iteration: 245\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6174 s, 245 iter, 2450000 ts, -96.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-54-57\n",
      "  done: false\n",
      "  episode_len_mean: 89.21238938053098\n",
      "  episode_reward_max: 6.022675228941733\n",
      "  episode_reward_mean: -82.65308648963278\n",
      "  episode_reward_min: -200.07267435645988\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 25566\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4035.836\n",
      "    load_time_ms: 1.557\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.379422664642334\n",
      "      kl: 0.0077519044280052185\n",
      "      policy_loss: 0.0017376454779878259\n",
      "      total_loss: 1329.6280517578125\n",
      "      vf_explained_var: 0.49180006980895996\n",
      "      vf_loss: 1329.6263427734375\n",
      "    sample_time_ms: 19355.041\n",
      "    update_time_ms: 5.989\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.32654324481639\n",
      "  time_since_restore: 6196.841333150864\n",
      "  time_this_iter_s: 22.59771227836609\n",
      "  time_total_s: 6196.841333150864\n",
      "  timestamp: 1554814497\n",
      "  timesteps_since_restore: 2460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 246\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6196 s, 246 iter, 2460000 ts, -82.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 90.07207207207207\n",
      "  episode_reward_max: 5.796571394041827\n",
      "  episode_reward_mean: -81.18169706133104\n",
      "  episode_reward_min: -200.12747650896938\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 25677\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4034.12\n",
      "    load_time_ms: 1.518\n",
      "    num_steps_sampled: 2470000\n",
      "    num_steps_trained: 2470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38967397809028625\n",
      "      kl: 0.011092131026089191\n",
      "      policy_loss: 0.0012754857307299972\n",
      "      total_loss: 1414.7681884765625\n",
      "      vf_explained_var: 0.4496663808822632\n",
      "      vf_loss: 1414.766845703125\n",
      "    sample_time_ms: 19300.869\n",
      "    update_time_ms: 5.868\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.59084853066553\n",
      "  time_since_restore: 6219.976016044617\n",
      "  time_this_iter_s: 23.13468289375305\n",
      "  time_total_s: 6219.976016044617\n",
      "  timestamp: 1554814520\n",
      "  timesteps_since_restore: 2470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2470000\n",
      "  training_iteration: 247\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6219 s, 247 iter, 2470000 ts, -81.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 92.22018348623853\n",
      "  episode_reward_max: 6.517712013060658\n",
      "  episode_reward_mean: -74.95672016894001\n",
      "  episode_reward_min: -200.08465165945682\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 25786\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4032.667\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 2480000\n",
      "    num_steps_trained: 2480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39890342950820923\n",
      "      kl: 0.011886208318173885\n",
      "      policy_loss: 0.0005118584376759827\n",
      "      total_loss: 1443.887939453125\n",
      "      vf_explained_var: 0.4569808840751648\n",
      "      vf_loss: 1443.887451171875\n",
      "    sample_time_ms: 19329.316\n",
      "    update_time_ms: 6.008\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.478360084470005\n",
      "  time_since_restore: 6243.339637994766\n",
      "  time_this_iter_s: 23.363621950149536\n",
      "  time_total_s: 6243.339637994766\n",
      "  timestamp: 1554814543\n",
      "  timesteps_since_restore: 2480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2480000\n",
      "  training_iteration: 248\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6243 s, 248 iter, 2480000 ts, -75 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-56-05\n",
      "  done: false\n",
      "  episode_len_mean: 84.13675213675214\n",
      "  episode_reward_max: 5.489963897191119\n",
      "  episode_reward_mean: -97.69441161277958\n",
      "  episode_reward_min: -200.07840039051177\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 25903\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4031.563\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4160456955432892\n",
      "      kl: 0.009183070622384548\n",
      "      policy_loss: 0.0022699458058923483\n",
      "      total_loss: 1378.7659912109375\n",
      "      vf_explained_var: 0.48476579785346985\n",
      "      vf_loss: 1378.763671875\n",
      "    sample_time_ms: 19204.097\n",
      "    update_time_ms: 5.948\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.84720580638978\n",
      "  time_since_restore: 6265.6113069057465\n",
      "  time_this_iter_s: 22.271668910980225\n",
      "  time_total_s: 6265.6113069057465\n",
      "  timestamp: 1554814565\n",
      "  timesteps_since_restore: 2490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 249\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6265 s, 249 iter, 2490000 ts, -97.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 87.87719298245614\n",
      "  episode_reward_max: 5.030475795964085\n",
      "  episode_reward_mean: -86.29568124705389\n",
      "  episode_reward_min: -200.07438711313137\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 26017\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4031.306\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 2500000\n",
      "    num_steps_trained: 2500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4179212152957916\n",
      "      kl: 0.009132105857133865\n",
      "      policy_loss: 0.0013552401214838028\n",
      "      total_loss: 1321.6434326171875\n",
      "      vf_explained_var: 0.5129980444908142\n",
      "      vf_loss: 1321.64208984375\n",
      "    sample_time_ms: 19129.487\n",
      "    update_time_ms: 5.791\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.147840623526946\n",
      "  time_since_restore: 6289.106185436249\n",
      "  time_this_iter_s: 23.49487853050232\n",
      "  time_total_s: 6289.106185436249\n",
      "  timestamp: 1554814589\n",
      "  timesteps_since_restore: 2500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2500000\n",
      "  training_iteration: 250\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6289 s, 250 iter, 2500000 ts, -86.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-56-52\n",
      "  done: false\n",
      "  episode_len_mean: 90.94594594594595\n",
      "  episode_reward_max: 7.080846243781355\n",
      "  episode_reward_mean: -77.63638417741267\n",
      "  episode_reward_min: -200.1057544408814\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 26128\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4029.308\n",
      "    load_time_ms: 1.667\n",
      "    num_steps_sampled: 2510000\n",
      "    num_steps_trained: 2510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4178805351257324\n",
      "      kl: 0.01038123294711113\n",
      "      policy_loss: 0.0012939264997839928\n",
      "      total_loss: 1386.2191162109375\n",
      "      vf_explained_var: 0.5031304359436035\n",
      "      vf_loss: 1386.2178955078125\n",
      "    sample_time_ms: 19100.278\n",
      "    update_time_ms: 5.803\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.818192088706326\n",
      "  time_since_restore: 6311.87301659584\n",
      "  time_this_iter_s: 22.766831159591675\n",
      "  time_total_s: 6311.87301659584\n",
      "  timestamp: 1554814612\n",
      "  timesteps_since_restore: 2510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2510000\n",
      "  training_iteration: 251\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6311 s, 251 iter, 2510000 ts, -77.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 95.05714285714286\n",
      "  episode_reward_max: 5.128169265104237\n",
      "  episode_reward_mean: -68.10639918338597\n",
      "  episode_reward_min: -200.05637972573302\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 26233\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4026.171\n",
      "    load_time_ms: 1.723\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.41512495279312134\n",
      "      kl: 0.012706786394119263\n",
      "      policy_loss: 0.0013256886741146445\n",
      "      total_loss: 1455.2528076171875\n",
      "      vf_explained_var: 0.42856237292289734\n",
      "      vf_loss: 1455.2513427734375\n",
      "    sample_time_ms: 19018.331\n",
      "    update_time_ms: 5.757\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.053199591692994\n",
      "  time_since_restore: 6334.762829065323\n",
      "  time_this_iter_s: 22.889812469482422\n",
      "  time_total_s: 6334.762829065323\n",
      "  timestamp: 1554814635\n",
      "  timesteps_since_restore: 2520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 252\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6334 s, 252 iter, 2520000 ts, -68.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-57-39\n",
      "  done: false\n",
      "  episode_len_mean: 91.9908256880734\n",
      "  episode_reward_max: 5.633776530496743\n",
      "  episode_reward_mean: -75.5468648511618\n",
      "  episode_reward_min: -200.08291996670346\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 26342\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4031.876\n",
      "    load_time_ms: 1.698\n",
      "    num_steps_sampled: 2530000\n",
      "    num_steps_trained: 2530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42340096831321716\n",
      "      kl: 0.01122378185391426\n",
      "      policy_loss: 1.6565983969485387e-05\n",
      "      total_loss: 1474.7596435546875\n",
      "      vf_explained_var: 0.4402239918708801\n",
      "      vf_loss: 1474.7596435546875\n",
      "    sample_time_ms: 19082.576\n",
      "    update_time_ms: 5.745\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.773432425580886\n",
      "  time_since_restore: 6358.5336124897\n",
      "  time_this_iter_s: 23.77078342437744\n",
      "  time_total_s: 6358.5336124897\n",
      "  timestamp: 1554814659\n",
      "  timesteps_since_restore: 2530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2530000\n",
      "  training_iteration: 253\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6358 s, 253 iter, 2530000 ts, -75.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-58-02\n",
      "  done: false\n",
      "  episode_len_mean: 81.4297520661157\n",
      "  episode_reward_max: 5.2916242617648885\n",
      "  episode_reward_mean: -104.32658353560396\n",
      "  episode_reward_min: -200.11852236275882\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 26463\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4030.801\n",
      "    load_time_ms: 1.707\n",
      "    num_steps_sampled: 2540000\n",
      "    num_steps_trained: 2540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43008989095687866\n",
      "      kl: 0.009311242029070854\n",
      "      policy_loss: 0.002032569842413068\n",
      "      total_loss: 1185.11572265625\n",
      "      vf_explained_var: 0.5850363969802856\n",
      "      vf_loss: 1185.113525390625\n",
      "    sample_time_ms: 19117.681\n",
      "    update_time_ms: 5.8\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.16329176780199\n",
      "  time_since_restore: 6382.281231641769\n",
      "  time_this_iter_s: 23.747619152069092\n",
      "  time_total_s: 6382.281231641769\n",
      "  timestamp: 1554814682\n",
      "  timesteps_since_restore: 2540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2540000\n",
      "  training_iteration: 254\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6382 s, 254 iter, 2540000 ts, -104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-58-26\n",
      "  done: false\n",
      "  episode_len_mean: 88.37719298245614\n",
      "  episode_reward_max: 5.303492383057158\n",
      "  episode_reward_mean: -84.32621487897987\n",
      "  episode_reward_min: -200.06917888342758\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 26577\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4071.897\n",
      "    load_time_ms: 1.737\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43476438522338867\n",
      "      kl: 0.0104895681142807\n",
      "      policy_loss: 0.000691909808665514\n",
      "      total_loss: 1379.666015625\n",
      "      vf_explained_var: 0.5165629982948303\n",
      "      vf_loss: 1379.665283203125\n",
      "    sample_time_ms: 19084.488\n",
      "    update_time_ms: 5.689\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.16310743948995\n",
      "  time_since_restore: 6406.076395750046\n",
      "  time_this_iter_s: 23.795164108276367\n",
      "  time_total_s: 6406.076395750046\n",
      "  timestamp: 1554814706\n",
      "  timesteps_since_restore: 2550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 255\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6406 s, 255 iter, 2550000 ts, -84.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-58-50\n",
      "  done: false\n",
      "  episode_len_mean: 92.09174311926606\n",
      "  episode_reward_max: 7.438157348038729\n",
      "  episode_reward_mean: -75.03391286367348\n",
      "  episode_reward_min: -200.11073300306526\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 26686\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4067.843\n",
      "    load_time_ms: 1.72\n",
      "    num_steps_sampled: 2560000\n",
      "    num_steps_trained: 2560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43818870186805725\n",
      "      kl: 0.0107817891985178\n",
      "      policy_loss: 0.0008027599542401731\n",
      "      total_loss: 1522.22900390625\n",
      "      vf_explained_var: 0.421356737613678\n",
      "      vf_loss: 1522.2281494140625\n",
      "    sample_time_ms: 19228.234\n",
      "    update_time_ms: 5.62\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.51695643183674\n",
      "  time_since_restore: 6430.069298744202\n",
      "  time_this_iter_s: 23.992902994155884\n",
      "  time_total_s: 6430.069298744202\n",
      "  timestamp: 1554814730\n",
      "  timesteps_since_restore: 2560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2560000\n",
      "  training_iteration: 256\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6430 s, 256 iter, 2560000 ts, -75 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-59-13\n",
      "  done: false\n",
      "  episode_len_mean: 82.52066115702479\n",
      "  episode_reward_max: 6.21647330678446\n",
      "  episode_reward_mean: -99.13419373115379\n",
      "  episode_reward_min: -200.06324136706473\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 26807\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4070.365\n",
      "    load_time_ms: 1.755\n",
      "    num_steps_sampled: 2570000\n",
      "    num_steps_trained: 2570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.448914110660553\n",
      "      kl: 0.011732221581041813\n",
      "      policy_loss: 0.0006957069272175431\n",
      "      total_loss: 1378.009033203125\n",
      "      vf_explained_var: 0.5216508507728577\n",
      "      vf_loss: 1378.0081787109375\n",
      "    sample_time_ms: 19206.854\n",
      "    update_time_ms: 5.613\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.567096865576886\n",
      "  time_since_restore: 6453.017066955566\n",
      "  time_this_iter_s: 22.947768211364746\n",
      "  time_total_s: 6453.017066955566\n",
      "  timestamp: 1554814753\n",
      "  timesteps_since_restore: 2570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2570000\n",
      "  training_iteration: 257\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6453 s, 257 iter, 2570000 ts, -99.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_14-59-37\n",
      "  done: false\n",
      "  episode_len_mean: 82.42148760330579\n",
      "  episode_reward_max: 4.953175856000858\n",
      "  episode_reward_mean: -100.74688167070792\n",
      "  episode_reward_min: -200.0555597124481\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 26928\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4072.782\n",
      "    load_time_ms: 1.709\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4607435464859009\n",
      "      kl: 0.012669787742197514\n",
      "      policy_loss: 0.0015247443225234747\n",
      "      total_loss: 1277.70654296875\n",
      "      vf_explained_var: 0.5643923878669739\n",
      "      vf_loss: 1277.7049560546875\n",
      "    sample_time_ms: 19195.082\n",
      "    update_time_ms: 5.473\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.37344083535398\n",
      "  time_since_restore: 6476.2869784832\n",
      "  time_this_iter_s: 23.269911527633667\n",
      "  time_total_s: 6476.2869784832\n",
      "  timestamp: 1554814777\n",
      "  timesteps_since_restore: 2580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 258\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6476 s, 258 iter, 2580000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-00-05\n",
      "  done: false\n",
      "  episode_len_mean: 83.9\n",
      "  episode_reward_max: 7.599343075219462\n",
      "  episode_reward_mean: -96.5995310697453\n",
      "  episode_reward_min: -200.10745368161292\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 27048\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4102.784\n",
      "    load_time_ms: 1.69\n",
      "    num_steps_sampled: 2590000\n",
      "    num_steps_trained: 2590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4650260806083679\n",
      "      kl: 0.011173787526786327\n",
      "      policy_loss: 0.001489157322794199\n",
      "      total_loss: 1343.8900146484375\n",
      "      vf_explained_var: 0.542293131351471\n",
      "      vf_loss: 1343.888427734375\n",
      "    sample_time_ms: 19753.235\n",
      "    update_time_ms: 5.542\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.29976553487265\n",
      "  time_since_restore: 6504.44186258316\n",
      "  time_this_iter_s: 28.154884099960327\n",
      "  time_total_s: 6504.44186258316\n",
      "  timestamp: 1554814805\n",
      "  timesteps_since_restore: 2590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2590000\n",
      "  training_iteration: 259\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6504 s, 259 iter, 2590000 ts, -96.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-00-30\n",
      "  done: false\n",
      "  episode_len_mean: 86.94736842105263\n",
      "  episode_reward_max: 4.6443965304029975\n",
      "  episode_reward_mean: -87.82002078312262\n",
      "  episode_reward_min: -200.05742009800258\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 27162\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4101.856\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 2600000\n",
      "    num_steps_trained: 2600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.46574530005455017\n",
      "      kl: 0.012030192650854588\n",
      "      policy_loss: 0.0004284379829186946\n",
      "      total_loss: 1412.053466796875\n",
      "      vf_explained_var: 0.4789169430732727\n",
      "      vf_loss: 1412.0531005859375\n",
      "    sample_time_ms: 19923.83\n",
      "    update_time_ms: 5.419\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.910010391561315\n",
      "  time_since_restore: 6529.633126974106\n",
      "  time_this_iter_s: 25.191264390945435\n",
      "  time_total_s: 6529.633126974106\n",
      "  timestamp: 1554814830\n",
      "  timesteps_since_restore: 2600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2600000\n",
      "  training_iteration: 260\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6529 s, 260 iter, 2600000 ts, -87.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-00-58\n",
      "  done: false\n",
      "  episode_len_mean: 87.5701754385965\n",
      "  episode_reward_max: 5.003856040312964\n",
      "  episode_reward_mean: -86.11669519834724\n",
      "  episode_reward_min: -200.066407543484\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 27276\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4137.841\n",
      "    load_time_ms: 1.681\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48056626319885254\n",
      "      kl: 0.013917391188442707\n",
      "      policy_loss: 0.002621613210067153\n",
      "      total_loss: 1429.5706787109375\n",
      "      vf_explained_var: 0.4917653501033783\n",
      "      vf_loss: 1429.568115234375\n",
      "    sample_time_ms: 20368.845\n",
      "    update_time_ms: 5.336\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.05834759917362\n",
      "  time_since_restore: 6557.207865715027\n",
      "  time_this_iter_s: 27.57473874092102\n",
      "  time_total_s: 6557.207865715027\n",
      "  timestamp: 1554814858\n",
      "  timesteps_since_restore: 2610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 261\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6557 s, 261 iter, 2610000 ts, -86.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-01-24\n",
      "  done: false\n",
      "  episode_len_mean: 83.08196721311475\n",
      "  episode_reward_max: 6.241156759800509\n",
      "  episode_reward_mean: -98.59691104310372\n",
      "  episode_reward_min: -200.04031998059907\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 27398\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4242.872\n",
      "    load_time_ms: 1.7\n",
      "    num_steps_sampled: 2620000\n",
      "    num_steps_trained: 2620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49320679903030396\n",
      "      kl: 0.011906241998076439\n",
      "      policy_loss: 0.0009077338618226349\n",
      "      total_loss: 1306.3778076171875\n",
      "      vf_explained_var: 0.5566768050193787\n",
      "      vf_loss: 1306.376953125\n",
      "    sample_time_ms: 20653.975\n",
      "    update_time_ms: 5.445\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.29845552155187\n",
      "  time_since_restore: 6584.002713680267\n",
      "  time_this_iter_s: 26.79484796524048\n",
      "  time_total_s: 6584.002713680267\n",
      "  timestamp: 1554814884\n",
      "  timesteps_since_restore: 2620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2620000\n",
      "  training_iteration: 262\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6584 s, 262 iter, 2620000 ts, -98.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-01-53\n",
      "  done: false\n",
      "  episode_len_mean: 91.73394495412845\n",
      "  episode_reward_max: 4.653840367143006\n",
      "  episode_reward_mean: -75.40537674767509\n",
      "  episode_reward_min: -200.05679973266916\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 27507\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4248.009\n",
      "    load_time_ms: 1.715\n",
      "    num_steps_sampled: 2630000\n",
      "    num_steps_trained: 2630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49555665254592896\n",
      "      kl: 0.010823440738022327\n",
      "      policy_loss: 0.002776387147605419\n",
      "      total_loss: 1464.275390625\n",
      "      vf_explained_var: 0.48098793625831604\n",
      "      vf_loss: 1464.2725830078125\n",
      "    sample_time_ms: 21111.223\n",
      "    update_time_ms: 5.461\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.702688373837546\n",
      "  time_since_restore: 6612.396055698395\n",
      "  time_this_iter_s: 28.39334201812744\n",
      "  time_total_s: 6612.396055698395\n",
      "  timestamp: 1554814913\n",
      "  timesteps_since_restore: 2630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2630000\n",
      "  training_iteration: 263\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6612 s, 263 iter, 2630000 ts, -75.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-02-17\n",
      "  done: false\n",
      "  episode_len_mean: 86.10434782608695\n",
      "  episode_reward_max: 4.391700131981988\n",
      "  episode_reward_mean: -90.76515970004294\n",
      "  episode_reward_min: -200.0760945071005\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 27622\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4265.035\n",
      "    load_time_ms: 1.719\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5222237706184387\n",
      "      kl: 0.01377790980041027\n",
      "      policy_loss: 0.0005227342480793595\n",
      "      total_loss: 1341.230224609375\n",
      "      vf_explained_var: 0.5278705954551697\n",
      "      vf_loss: 1341.2296142578125\n",
      "    sample_time_ms: 21092.75\n",
      "    update_time_ms: 5.358\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.382579850021465\n",
      "  time_since_restore: 6636.127022266388\n",
      "  time_this_iter_s: 23.730966567993164\n",
      "  time_total_s: 6636.127022266388\n",
      "  timestamp: 1554814937\n",
      "  timesteps_since_restore: 2640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 264\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6636 s, 264 iter, 2640000 ts, -90.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-02-41\n",
      "  done: false\n",
      "  episode_len_mean: 85.6068376068376\n",
      "  episode_reward_max: 4.633385064695101\n",
      "  episode_reward_mean: -92.23141000399157\n",
      "  episode_reward_min: -200.0921713075607\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 27739\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4241.051\n",
      "    load_time_ms: 1.708\n",
      "    num_steps_sampled: 2650000\n",
      "    num_steps_trained: 2650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5245605707168579\n",
      "      kl: 0.01070231944322586\n",
      "      policy_loss: 0.003106202930212021\n",
      "      total_loss: 1421.2568359375\n",
      "      vf_explained_var: 0.5031846761703491\n",
      "      vf_loss: 1421.2537841796875\n",
      "    sample_time_ms: 21137.187\n",
      "    update_time_ms: 5.33\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.11570500199578\n",
      "  time_since_restore: 6660.12421131134\n",
      "  time_this_iter_s: 23.997189044952393\n",
      "  time_total_s: 6660.12421131134\n",
      "  timestamp: 1554814961\n",
      "  timesteps_since_restore: 2650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2650000\n",
      "  training_iteration: 265\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6660 s, 265 iter, 2650000 ts, -92.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-03-05\n",
      "  done: false\n",
      "  episode_len_mean: 94.19811320754717\n",
      "  episode_reward_max: 4.558634728779804\n",
      "  episode_reward_mean: -69.68371114121474\n",
      "  episode_reward_min: -200.09095176346668\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 27845\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4294.539\n",
      "    load_time_ms: 1.668\n",
      "    num_steps_sampled: 2660000\n",
      "    num_steps_trained: 2660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5278893113136292\n",
      "      kl: 0.014891636557877064\n",
      "      policy_loss: 0.0030571152456104755\n",
      "      total_loss: 1440.0191650390625\n",
      "      vf_explained_var: 0.46977126598358154\n",
      "      vf_loss: 1440.0159912109375\n",
      "    sample_time_ms: 21075.139\n",
      "    update_time_ms: 5.241\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.84185557060738\n",
      "  time_since_restore: 6684.0308611392975\n",
      "  time_this_iter_s: 23.906649827957153\n",
      "  time_total_s: 6684.0308611392975\n",
      "  timestamp: 1554814985\n",
      "  timesteps_since_restore: 2660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2660000\n",
      "  training_iteration: 266\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6684 s, 266 iter, 2660000 ts, -69.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-03-28\n",
      "  done: false\n",
      "  episode_len_mean: 91.78181818181818\n",
      "  episode_reward_max: 4.627487404412603\n",
      "  episode_reward_mean: -76.3907667883055\n",
      "  episode_reward_min: -200.07019771899917\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 27955\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4302.608\n",
      "    load_time_ms: 1.684\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5329936742782593\n",
      "      kl: 0.013057667762041092\n",
      "      policy_loss: 0.0017398545751348138\n",
      "      total_loss: 1399.215087890625\n",
      "      vf_explained_var: 0.477500855922699\n",
      "      vf_loss: 1399.21337890625\n",
      "    sample_time_ms: 21152.341\n",
      "    update_time_ms: 5.2\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.19538339415275\n",
      "  time_since_restore: 6707.831568956375\n",
      "  time_this_iter_s: 23.800707817077637\n",
      "  time_total_s: 6707.831568956375\n",
      "  timestamp: 1554815008\n",
      "  timesteps_since_restore: 2670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 267\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6707 s, 267 iter, 2670000 ts, -76.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-03-52\n",
      "  done: false\n",
      "  episode_len_mean: 93.56603773584905\n",
      "  episode_reward_max: 4.707970458476397\n",
      "  episode_reward_mean: -69.74184102115353\n",
      "  episode_reward_min: -200.07259231519512\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 28061\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4331.733\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 2680000\n",
      "    num_steps_trained: 2680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5316677689552307\n",
      "      kl: 0.013275702483952045\n",
      "      policy_loss: 0.0016252717468887568\n",
      "      total_loss: 1499.1461181640625\n",
      "      vf_explained_var: 0.4354725778102875\n",
      "      vf_loss: 1499.14453125\n",
      "    sample_time_ms: 21140.83\n",
      "    update_time_ms: 5.333\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.87092051057676\n",
      "  time_since_restore: 6731.27695608139\n",
      "  time_this_iter_s: 23.44538712501526\n",
      "  time_total_s: 6731.27695608139\n",
      "  timestamp: 1554815032\n",
      "  timesteps_since_restore: 2680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2680000\n",
      "  training_iteration: 268\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6731 s, 268 iter, 2680000 ts, -69.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-04-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.23364485981308\n",
      "  episode_reward_max: 4.880029278688499\n",
      "  episode_reward_mean: -67.41826090761546\n",
      "  episode_reward_min: -200.038630832504\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 28168\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4324.171\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 2690000\n",
      "    num_steps_trained: 2690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.533009946346283\n",
      "      kl: 0.01436823420226574\n",
      "      policy_loss: 0.0013887187233194709\n",
      "      total_loss: 1492.35400390625\n",
      "      vf_explained_var: 0.4082939922809601\n",
      "      vf_loss: 1492.3525390625\n",
      "    sample_time_ms: 20721.351\n",
      "    update_time_ms: 5.344\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.70913045380774\n",
      "  time_since_restore: 6755.159796476364\n",
      "  time_this_iter_s: 23.882840394973755\n",
      "  time_total_s: 6755.159796476364\n",
      "  timestamp: 1554815056\n",
      "  timesteps_since_restore: 2690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2690000\n",
      "  training_iteration: 269\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6755 s, 269 iter, 2690000 ts, -67.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-04-41\n",
      "  done: false\n",
      "  episode_len_mean: 92.43518518518519\n",
      "  episode_reward_max: 4.97977275411572\n",
      "  episode_reward_mean: -75.42000442307325\n",
      "  episode_reward_min: -200.10860082142236\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 28276\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4376.317\n",
      "    load_time_ms: 1.731\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5444386601448059\n",
      "      kl: 0.013889887370169163\n",
      "      policy_loss: 0.0027170218527317047\n",
      "      total_loss: 1434.03564453125\n",
      "      vf_explained_var: 0.4287221431732178\n",
      "      vf_loss: 1434.0328369140625\n",
      "    sample_time_ms: 20658.305\n",
      "    update_time_ms: 5.284\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.71000221153663\n",
      "  time_since_restore: 6780.240132570267\n",
      "  time_this_iter_s: 25.080336093902588\n",
      "  time_total_s: 6780.240132570267\n",
      "  timestamp: 1554815081\n",
      "  timesteps_since_restore: 2700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 270\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6780 s, 270 iter, 2700000 ts, -75.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-05-05\n",
      "  done: false\n",
      "  episode_len_mean: 87.90265486725664\n",
      "  episode_reward_max: 4.682939517057223\n",
      "  episode_reward_mean: -84.77561733766122\n",
      "  episode_reward_min: -200.06287857651748\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 28389\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4346.126\n",
      "    load_time_ms: 1.719\n",
      "    num_steps_sampled: 2710000\n",
      "    num_steps_trained: 2710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5513591170310974\n",
      "      kl: 0.014414802193641663\n",
      "      policy_loss: 0.003945161588490009\n",
      "      total_loss: 1428.77099609375\n",
      "      vf_explained_var: 0.44901975989341736\n",
      "      vf_loss: 1428.7669677734375\n",
      "    sample_time_ms: 20309.198\n",
      "    update_time_ms: 5.479\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.387808668830615\n",
      "  time_since_restore: 6804.024963617325\n",
      "  time_this_iter_s: 23.784831047058105\n",
      "  time_total_s: 6804.024963617325\n",
      "  timestamp: 1554815105\n",
      "  timesteps_since_restore: 2710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2710000\n",
      "  training_iteration: 271\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6804 s, 271 iter, 2710000 ts, -84.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-05-28\n",
      "  done: false\n",
      "  episode_len_mean: 83.91596638655462\n",
      "  episode_reward_max: 4.837228654693055\n",
      "  episode_reward_mean: -95.89589620456552\n",
      "  episode_reward_min: -200.05610566606202\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 28508\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4260.442\n",
      "    load_time_ms: 1.647\n",
      "    num_steps_sampled: 2720000\n",
      "    num_steps_trained: 2720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5653186440467834\n",
      "      kl: 0.015460958704352379\n",
      "      policy_loss: 0.0021204871591180563\n",
      "      total_loss: 1346.622314453125\n",
      "      vf_explained_var: 0.5255569219589233\n",
      "      vf_loss: 1346.6202392578125\n",
      "    sample_time_ms: 20066.967\n",
      "    update_time_ms: 5.402\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.94794810228277\n",
      "  time_since_restore: 6827.5362067222595\n",
      "  time_this_iter_s: 23.511243104934692\n",
      "  time_total_s: 6827.5362067222595\n",
      "  timestamp: 1554815128\n",
      "  timesteps_since_restore: 2720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2720000\n",
      "  training_iteration: 272\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6827 s, 272 iter, 2720000 ts, -95.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-05-54\n",
      "  done: false\n",
      "  episode_len_mean: 91.96363636363637\n",
      "  episode_reward_max: 5.070764086129362\n",
      "  episode_reward_mean: -74.53626713967788\n",
      "  episode_reward_min: -200.05991297122978\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 28618\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4295.102\n",
      "    load_time_ms: 1.776\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5645853877067566\n",
      "      kl: 0.013247871771454811\n",
      "      policy_loss: 0.0015251016011461616\n",
      "      total_loss: 1418.4190673828125\n",
      "      vf_explained_var: 0.45268890261650085\n",
      "      vf_loss: 1418.41748046875\n",
      "    sample_time_ms: 19717.613\n",
      "    update_time_ms: 5.371\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.26813356983894\n",
      "  time_since_restore: 6852.783503293991\n",
      "  time_this_iter_s: 25.247296571731567\n",
      "  time_total_s: 6852.783503293991\n",
      "  timestamp: 1554815154\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 273\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6852 s, 273 iter, 2730000 ts, -74.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-06-19\n",
      "  done: false\n",
      "  episode_len_mean: 83.59322033898304\n",
      "  episode_reward_max: 4.67462395426138\n",
      "  episode_reward_mean: -96.74167064143788\n",
      "  episode_reward_min: -200.05712884567583\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 28736\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4295.31\n",
      "    load_time_ms: 1.786\n",
      "    num_steps_sampled: 2740000\n",
      "    num_steps_trained: 2740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5799056887626648\n",
      "      kl: 0.01224413700401783\n",
      "      policy_loss: 0.00307424901984632\n",
      "      total_loss: 1360.522216796875\n",
      "      vf_explained_var: 0.5037959218025208\n",
      "      vf_loss: 1360.519287109375\n",
      "    sample_time_ms: 19849.156\n",
      "    update_time_ms: 5.477\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.370835320718946\n",
      "  time_since_restore: 6877.832981586456\n",
      "  time_this_iter_s: 25.04947829246521\n",
      "  time_total_s: 6877.832981586456\n",
      "  timestamp: 1554815179\n",
      "  timesteps_since_restore: 2740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2740000\n",
      "  training_iteration: 274\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6877 s, 274 iter, 2740000 ts, -96.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-06-44\n",
      "  done: false\n",
      "  episode_len_mean: 87.86842105263158\n",
      "  episode_reward_max: 4.747915911845867\n",
      "  episode_reward_mean: -85.91427377607756\n",
      "  episode_reward_min: -200.0616611408023\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 28850\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4313.286\n",
      "    load_time_ms: 1.744\n",
      "    num_steps_sampled: 2750000\n",
      "    num_steps_trained: 2750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5856556296348572\n",
      "      kl: 0.012046403251588345\n",
      "      policy_loss: 0.0007402878836728632\n",
      "      total_loss: 1429.1341552734375\n",
      "      vf_explained_var: 0.4820590019226074\n",
      "      vf_loss: 1429.1334228515625\n",
      "    sample_time_ms: 19979.212\n",
      "    update_time_ms: 5.517\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.957136888038775\n",
      "  time_since_restore: 6903.308135509491\n",
      "  time_this_iter_s: 25.475153923034668\n",
      "  time_total_s: 6903.308135509491\n",
      "  timestamp: 1554815204\n",
      "  timesteps_since_restore: 2750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2750000\n",
      "  training_iteration: 275\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6903 s, 275 iter, 2750000 ts, -85.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-07-11\n",
      "  done: false\n",
      "  episode_len_mean: 87.15652173913044\n",
      "  episode_reward_max: 5.20458314715636\n",
      "  episode_reward_mean: -88.78538620535487\n",
      "  episode_reward_min: -200.06161673194367\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 28965\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4264.468\n",
      "    load_time_ms: 1.763\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5909231305122375\n",
      "      kl: 0.014242422766983509\n",
      "      policy_loss: 0.0053284442983567715\n",
      "      total_loss: 1384.491943359375\n",
      "      vf_explained_var: 0.498484343290329\n",
      "      vf_loss: 1384.48681640625\n",
      "    sample_time_ms: 20322.278\n",
      "    update_time_ms: 5.605\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.39269310267744\n",
      "  time_since_restore: 6930.159225225449\n",
      "  time_this_iter_s: 26.85108971595764\n",
      "  time_total_s: 6930.159225225449\n",
      "  timestamp: 1554815231\n",
      "  timesteps_since_restore: 2760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 276\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6930 s, 276 iter, 2760000 ts, -88.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-07-36\n",
      "  done: false\n",
      "  episode_len_mean: 89.58035714285714\n",
      "  episode_reward_max: 5.212437026021775\n",
      "  episode_reward_mean: -80.4892935775692\n",
      "  episode_reward_min: -200.0790800251005\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 29077\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4260.722\n",
      "    load_time_ms: 1.733\n",
      "    num_steps_sampled: 2770000\n",
      "    num_steps_trained: 2770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5949615836143494\n",
      "      kl: 0.01146106980741024\n",
      "      policy_loss: 0.0014509008033201098\n",
      "      total_loss: 1450.8345947265625\n",
      "      vf_explained_var: 0.4788360595703125\n",
      "      vf_loss: 1450.8328857421875\n",
      "    sample_time_ms: 20388.532\n",
      "    update_time_ms: 5.578\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.2446467887846\n",
      "  time_since_restore: 6954.585508823395\n",
      "  time_this_iter_s: 24.426283597946167\n",
      "  time_total_s: 6954.585508823395\n",
      "  timestamp: 1554815256\n",
      "  timesteps_since_restore: 2770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2770000\n",
      "  training_iteration: 277\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6954 s, 277 iter, 2770000 ts, -80.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-08-02\n",
      "  done: false\n",
      "  episode_len_mean: 87.09649122807018\n",
      "  episode_reward_max: 5.479254272010989\n",
      "  episode_reward_mean: -87.45052344992736\n",
      "  episode_reward_min: -200.10040012268564\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 29191\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4296.679\n",
      "    load_time_ms: 1.731\n",
      "    num_steps_sampled: 2780000\n",
      "    num_steps_trained: 2780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6047071218490601\n",
      "      kl: 0.012850536964833736\n",
      "      policy_loss: 0.00200006109662354\n",
      "      total_loss: 1365.821533203125\n",
      "      vf_explained_var: 0.49896207451820374\n",
      "      vf_loss: 1365.8194580078125\n",
      "    sample_time_ms: 20688.436\n",
      "    update_time_ms: 5.448\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.725261724963666\n",
      "  time_since_restore: 6981.388534545898\n",
      "  time_this_iter_s: 26.803025722503662\n",
      "  time_total_s: 6981.388534545898\n",
      "  timestamp: 1554815282\n",
      "  timesteps_since_restore: 2780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2780000\n",
      "  training_iteration: 278\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 6981 s, 278 iter, 2780000 ts, -87.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-08-28\n",
      "  done: false\n",
      "  episode_len_mean: 84.26890756302521\n",
      "  episode_reward_max: 5.293533911153942\n",
      "  episode_reward_mean: -97.5461534204822\n",
      "  episode_reward_min: -200.08600327791459\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 29310\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4310.423\n",
      "    load_time_ms: 1.741\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6180955171585083\n",
      "      kl: 0.011713767424225807\n",
      "      policy_loss: 0.0020843902602791786\n",
      "      total_loss: 1376.031005859375\n",
      "      vf_explained_var: 0.5343504548072815\n",
      "      vf_loss: 1376.0289306640625\n",
      "    sample_time_ms: 20875.951\n",
      "    update_time_ms: 5.509\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.7730767102411\n",
      "  time_since_restore: 7007.284368991852\n",
      "  time_this_iter_s: 25.89583444595337\n",
      "  time_total_s: 7007.284368991852\n",
      "  timestamp: 1554815308\n",
      "  timesteps_since_restore: 2790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 279\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7007 s, 279 iter, 2790000 ts, -97.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-08-53\n",
      "  done: false\n",
      "  episode_len_mean: 88.41228070175438\n",
      "  episode_reward_max: 5.240891526263953\n",
      "  episode_reward_mean: -84.31717831956924\n",
      "  episode_reward_min: -200.06423551893303\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 29424\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4257.043\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 2800000\n",
      "    num_steps_trained: 2800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6253085732460022\n",
      "      kl: 0.014065327122807503\n",
      "      policy_loss: 0.002901550382375717\n",
      "      total_loss: 1390.0050048828125\n",
      "      vf_explained_var: 0.49673324823379517\n",
      "      vf_loss: 1390.002197265625\n",
      "    sample_time_ms: 20851.877\n",
      "    update_time_ms: 5.554\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.15858915978462\n",
      "  time_since_restore: 7031.590226173401\n",
      "  time_this_iter_s: 24.305857181549072\n",
      "  time_total_s: 7031.590226173401\n",
      "  timestamp: 1554815333\n",
      "  timesteps_since_restore: 2800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2800000\n",
      "  training_iteration: 280\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7031 s, 280 iter, 2800000 ts, -84.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-09-17\n",
      "  done: false\n",
      "  episode_len_mean: 87.44736842105263\n",
      "  episode_reward_max: 5.347481021287974\n",
      "  episode_reward_mean: -87.50507441573421\n",
      "  episode_reward_min: -200.05210930448393\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 29538\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4247.711\n",
      "    load_time_ms: 1.644\n",
      "    num_steps_sampled: 2810000\n",
      "    num_steps_trained: 2810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6331406831741333\n",
      "      kl: 0.014056089334189892\n",
      "      policy_loss: 0.0039005253929644823\n",
      "      total_loss: 1418.421142578125\n",
      "      vf_explained_var: 0.5178321003913879\n",
      "      vf_loss: 1418.417236328125\n",
      "    sample_time_ms: 20856.821\n",
      "    update_time_ms: 5.337\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.75253720786711\n",
      "  time_since_restore: 7055.327992916107\n",
      "  time_this_iter_s: 23.7377667427063\n",
      "  time_total_s: 7055.327992916107\n",
      "  timestamp: 1554815357\n",
      "  timesteps_since_restore: 2810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2810000\n",
      "  training_iteration: 281\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7055 s, 281 iter, 2810000 ts, -87.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-09-40\n",
      "  done: false\n",
      "  episode_len_mean: 82.13223140495867\n",
      "  episode_reward_max: 4.838791652164101\n",
      "  episode_reward_mean: -102.687209125852\n",
      "  episode_reward_min: -200.0921480916897\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 29659\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4229.759\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6574206948280334\n",
      "      kl: 0.013818548060953617\n",
      "      policy_loss: 0.004070110619068146\n",
      "      total_loss: 1284.083251953125\n",
      "      vf_explained_var: 0.5350635051727295\n",
      "      vf_loss: 1284.0792236328125\n",
      "    sample_time_ms: 20887.525\n",
      "    update_time_ms: 5.381\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.343604562926\n",
      "  time_since_restore: 7078.9698576927185\n",
      "  time_this_iter_s: 23.641864776611328\n",
      "  time_total_s: 7078.9698576927185\n",
      "  timestamp: 1554815380\n",
      "  timesteps_since_restore: 2820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 282\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7078 s, 282 iter, 2820000 ts, -103 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-10-04\n",
      "  done: false\n",
      "  episode_len_mean: 88.59292035398231\n",
      "  episode_reward_max: 5.272335792489344\n",
      "  episode_reward_mean: -83.06123408129602\n",
      "  episode_reward_min: -200.05831769869025\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 29772\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4185.276\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 2830000\n",
      "    num_steps_trained: 2830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.653199315071106\n",
      "      kl: 0.014129027724266052\n",
      "      policy_loss: 0.0032515465281903744\n",
      "      total_loss: 1434.1075439453125\n",
      "      vf_explained_var: 0.4606326222419739\n",
      "      vf_loss: 1434.1043701171875\n",
      "    sample_time_ms: 20811.445\n",
      "    update_time_ms: 5.297\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.530617040648025\n",
      "  time_since_restore: 7103.0163741111755\n",
      "  time_this_iter_s: 24.04651641845703\n",
      "  time_total_s: 7103.0163741111755\n",
      "  timestamp: 1554815404\n",
      "  timesteps_since_restore: 2830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2830000\n",
      "  training_iteration: 283\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7103 s, 283 iter, 2830000 ts, -83.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-10-27\n",
      "  done: false\n",
      "  episode_len_mean: 90.15178571428571\n",
      "  episode_reward_max: 5.408183451598868\n",
      "  episode_reward_mean: -80.44831794761457\n",
      "  episode_reward_min: -200.09108940626237\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 29884\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4171.325\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 2840000\n",
      "    num_steps_trained: 2840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6590481400489807\n",
      "      kl: 0.013782592490315437\n",
      "      policy_loss: 0.0021470091305673122\n",
      "      total_loss: 1435.5107421875\n",
      "      vf_explained_var: 0.46326348185539246\n",
      "      vf_loss: 1435.5086669921875\n",
      "    sample_time_ms: 20634.661\n",
      "    update_time_ms: 5.245\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.224158973807285\n",
      "  time_since_restore: 7126.161419868469\n",
      "  time_this_iter_s: 23.1450457572937\n",
      "  time_total_s: 7126.161419868469\n",
      "  timestamp: 1554815427\n",
      "  timesteps_since_restore: 2840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2840000\n",
      "  training_iteration: 284\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7126 s, 284 iter, 2840000 ts, -80.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-10-51\n",
      "  done: false\n",
      "  episode_len_mean: 84.09322033898304\n",
      "  episode_reward_max: 5.600161995736599\n",
      "  episode_reward_mean: -96.58947455245173\n",
      "  episode_reward_min: -200.07256538090598\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 30002\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4143.752\n",
      "    load_time_ms: 1.608\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6723914742469788\n",
      "      kl: 0.015410056337714195\n",
      "      policy_loss: 0.004010395146906376\n",
      "      total_loss: 1315.643798828125\n",
      "      vf_explained_var: 0.5467071533203125\n",
      "      vf_loss: 1315.6400146484375\n",
      "    sample_time_ms: 20458.57\n",
      "    update_time_ms: 5.276\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.29473727622586\n",
      "  time_since_restore: 7149.6041605472565\n",
      "  time_this_iter_s: 23.44274067878723\n",
      "  time_total_s: 7149.6041605472565\n",
      "  timestamp: 1554815451\n",
      "  timesteps_since_restore: 2850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 285\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7149 s, 285 iter, 2850000 ts, -96.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-11-15\n",
      "  done: false\n",
      "  episode_len_mean: 86.77391304347826\n",
      "  episode_reward_max: 5.78596593817405\n",
      "  episode_reward_mean: -88.24230990114367\n",
      "  episode_reward_min: -200.06152643866653\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 30117\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4150.056\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 2860000\n",
      "    num_steps_trained: 2860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6674390435218811\n",
      "      kl: 0.017499608919024467\n",
      "      policy_loss: 0.004084696527570486\n",
      "      total_loss: 1273.8741455078125\n",
      "      vf_explained_var: 0.5595391392707825\n",
      "      vf_loss: 1273.8699951171875\n",
      "    sample_time_ms: 20193.255\n",
      "    update_time_ms: 5.249\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.12115495057183\n",
      "  time_since_restore: 7173.861989974976\n",
      "  time_this_iter_s: 24.257829427719116\n",
      "  time_total_s: 7173.861989974976\n",
      "  timestamp: 1554815475\n",
      "  timesteps_since_restore: 2860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2860000\n",
      "  training_iteration: 286\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7173 s, 286 iter, 2860000 ts, -88.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-11-39\n",
      "  done: false\n",
      "  episode_len_mean: 94.54716981132076\n",
      "  episode_reward_max: 5.625324730635166\n",
      "  episode_reward_mean: -66.26944753603544\n",
      "  episode_reward_min: -200.0362991937982\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 30223\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4154.239\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 2870000\n",
      "    num_steps_trained: 2870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.666886568069458\n",
      "      kl: 0.012319546192884445\n",
      "      policy_loss: 0.0028966243844479322\n",
      "      total_loss: 1500.602783203125\n",
      "      vf_explained_var: 0.3956129252910614\n",
      "      vf_loss: 1500.5999755859375\n",
      "    sample_time_ms: 20070.233\n",
      "    update_time_ms: 5.338\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.134723768017714\n",
      "  time_since_restore: 7197.100895404816\n",
      "  time_this_iter_s: 23.238905429840088\n",
      "  time_total_s: 7197.100895404816\n",
      "  timestamp: 1554815499\n",
      "  timesteps_since_restore: 2870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2870000\n",
      "  training_iteration: 287\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7197 s, 287 iter, 2870000 ts, -66.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-12-02\n",
      "  done: false\n",
      "  episode_len_mean: 81.88524590163935\n",
      "  episode_reward_max: 5.444912103180202\n",
      "  episode_reward_mean: -101.50874523249257\n",
      "  episode_reward_min: -200.09120786862894\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 30345\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4095.19\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6977939009666443\n",
      "      kl: 0.0144740529358387\n",
      "      policy_loss: 0.0024193590506911278\n",
      "      total_loss: 1361.992919921875\n",
      "      vf_explained_var: 0.5346807241439819\n",
      "      vf_loss: 1361.9906005859375\n",
      "    sample_time_ms: 19747.338\n",
      "    update_time_ms: 5.46\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.754372616246286\n",
      "  time_since_restore: 7220.0882267951965\n",
      "  time_this_iter_s: 22.98733139038086\n",
      "  time_total_s: 7220.0882267951965\n",
      "  timestamp: 1554815522\n",
      "  timesteps_since_restore: 2880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 288\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7220 s, 288 iter, 2880000 ts, -102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-12-24\n",
      "  done: false\n",
      "  episode_len_mean: 84.0\n",
      "  episode_reward_max: 5.440741192345612\n",
      "  episode_reward_mean: -94.32959530964159\n",
      "  episode_reward_min: -200.0315484510248\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 30464\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4063.408\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 2890000\n",
      "    num_steps_trained: 2890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7016809582710266\n",
      "      kl: 0.015818338841199875\n",
      "      policy_loss: 0.002832520753145218\n",
      "      total_loss: 1376.68798828125\n",
      "      vf_explained_var: 0.5225869417190552\n",
      "      vf_loss: 1376.68505859375\n",
      "    sample_time_ms: 19471.56\n",
      "    update_time_ms: 5.33\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.1647976548208\n",
      "  time_since_restore: 7242.905046701431\n",
      "  time_this_iter_s: 22.81681990623474\n",
      "  time_total_s: 7242.905046701431\n",
      "  timestamp: 1554815544\n",
      "  timesteps_since_restore: 2890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2890000\n",
      "  training_iteration: 289\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7242 s, 289 iter, 2890000 ts, -94.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-12-48\n",
      "  done: false\n",
      "  episode_len_mean: 84.5677966101695\n",
      "  episode_reward_max: 5.070597808680096\n",
      "  episode_reward_mean: -91.5184267934313\n",
      "  episode_reward_min: -200.0412627329158\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 30582\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4078.26\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 2900000\n",
      "    num_steps_trained: 2900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7096248269081116\n",
      "      kl: 0.01770717278122902\n",
      "      policy_loss: 0.0033287624828517437\n",
      "      total_loss: 1400.063720703125\n",
      "      vf_explained_var: 0.4906475245952606\n",
      "      vf_loss: 1400.060546875\n",
      "    sample_time_ms: 19370.34\n",
      "    update_time_ms: 5.404\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.759213396715666\n",
      "  time_since_restore: 7266.34988451004\n",
      "  time_this_iter_s: 23.44483780860901\n",
      "  time_total_s: 7266.34988451004\n",
      "  timestamp: 1554815568\n",
      "  timesteps_since_restore: 2900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2900000\n",
      "  training_iteration: 290\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7266 s, 290 iter, 2900000 ts, -91.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-13-11\n",
      "  done: false\n",
      "  episode_len_mean: 85.99145299145299\n",
      "  episode_reward_max: 5.581888886150564\n",
      "  episode_reward_mean: -90.932496925178\n",
      "  episode_reward_min: -200.08003586677205\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 30699\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4081.358\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7236132621765137\n",
      "      kl: 0.014323992654681206\n",
      "      policy_loss: 0.002204745542258024\n",
      "      total_loss: 1381.3345947265625\n",
      "      vf_explained_var: 0.5109685659408569\n",
      "      vf_loss: 1381.332275390625\n",
      "    sample_time_ms: 19264.823\n",
      "    update_time_ms: 5.493\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.46624846258899\n",
      "  time_since_restore: 7289.065383195877\n",
      "  time_this_iter_s: 22.715498685836792\n",
      "  time_total_s: 7289.065383195877\n",
      "  timestamp: 1554815591\n",
      "  timesteps_since_restore: 2910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 291\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7289 s, 291 iter, 2910000 ts, -90.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-13-35\n",
      "  done: false\n",
      "  episode_len_mean: 81.01626016260163\n",
      "  episode_reward_max: 5.156798455750118\n",
      "  episode_reward_mean: -102.39307460497236\n",
      "  episode_reward_min: -200.0544591882111\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 30822\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4085.911\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 2920000\n",
      "    num_steps_trained: 2920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7313632369041443\n",
      "      kl: 0.013873200863599777\n",
      "      policy_loss: 0.002810452366247773\n",
      "      total_loss: 1245.54443359375\n",
      "      vf_explained_var: 0.5783288478851318\n",
      "      vf_loss: 1245.54150390625\n",
      "    sample_time_ms: 19298.951\n",
      "    update_time_ms: 5.391\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.19653730248617\n",
      "  time_since_restore: 7313.091481924057\n",
      "  time_this_iter_s: 24.02609872817993\n",
      "  time_total_s: 7313.091481924057\n",
      "  timestamp: 1554815615\n",
      "  timesteps_since_restore: 2920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2920000\n",
      "  training_iteration: 292\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7313 s, 292 iter, 2920000 ts, -102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-13-59\n",
      "  done: false\n",
      "  episode_len_mean: 87.59130434782608\n",
      "  episode_reward_max: 5.886707114752454\n",
      "  episode_reward_mean: -83.44435134952131\n",
      "  episode_reward_min: -200.04312962222593\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 30937\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4087.733\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 2930000\n",
      "    num_steps_trained: 2930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7270228862762451\n",
      "      kl: 0.014946365728974342\n",
      "      policy_loss: 0.00461918069049716\n",
      "      total_loss: 1386.2447509765625\n",
      "      vf_explained_var: 0.5009976029396057\n",
      "      vf_loss: 1386.240234375\n",
      "    sample_time_ms: 19335.697\n",
      "    update_time_ms: 5.425\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.722175674760656\n",
      "  time_since_restore: 7337.519756317139\n",
      "  time_this_iter_s: 24.428274393081665\n",
      "  time_total_s: 7337.519756317139\n",
      "  timestamp: 1554815639\n",
      "  timesteps_since_restore: 2930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2930000\n",
      "  training_iteration: 293\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7337 s, 293 iter, 2930000 ts, -83.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-14-23\n",
      "  done: false\n",
      "  episode_len_mean: 91.41284403669725\n",
      "  episode_reward_max: 4.726464952838073\n",
      "  episode_reward_mean: -75.55136586165875\n",
      "  episode_reward_min: -200.08973033421861\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 31046\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4086.16\n",
      "    load_time_ms: 1.643\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7342413067817688\n",
      "      kl: 0.017507072538137436\n",
      "      policy_loss: 0.004272309597581625\n",
      "      total_loss: 1466.314697265625\n",
      "      vf_explained_var: 0.44852906465530396\n",
      "      vf_loss: 1466.310546875\n",
      "    sample_time_ms: 19376.106\n",
      "    update_time_ms: 5.512\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.77568293082938\n",
      "  time_since_restore: 7361.051958084106\n",
      "  time_this_iter_s: 23.532201766967773\n",
      "  time_total_s: 7361.051958084106\n",
      "  timestamp: 1554815663\n",
      "  timesteps_since_restore: 2940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 294\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7361 s, 294 iter, 2940000 ts, -75.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-14-46\n",
      "  done: false\n",
      "  episode_len_mean: 88.82142857142857\n",
      "  episode_reward_max: 5.692846942785325\n",
      "  episode_reward_mean: -83.64278465425271\n",
      "  episode_reward_min: -200.0479863940791\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 31158\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4079.584\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 2950000\n",
      "    num_steps_trained: 2950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7455474138259888\n",
      "      kl: 0.014618809334933758\n",
      "      policy_loss: 0.003888119012117386\n",
      "      total_loss: 1442.6656494140625\n",
      "      vf_explained_var: 0.48591598868370056\n",
      "      vf_loss: 1442.66162109375\n",
      "    sample_time_ms: 19396.797\n",
      "    update_time_ms: 5.435\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.82139232712636\n",
      "  time_since_restore: 7384.634297370911\n",
      "  time_this_iter_s: 23.5823392868042\n",
      "  time_total_s: 7384.634297370911\n",
      "  timestamp: 1554815686\n",
      "  timesteps_since_restore: 2950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2950000\n",
      "  training_iteration: 295\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7384 s, 295 iter, 2950000 ts, -83.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-15-10\n",
      "  done: false\n",
      "  episode_len_mean: 92.56880733944953\n",
      "  episode_reward_max: 5.245995651036577\n",
      "  episode_reward_mean: -73.93910009468024\n",
      "  episode_reward_min: -200.073767032452\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 31267\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4074.194\n",
      "    load_time_ms: 1.601\n",
      "    num_steps_sampled: 2960000\n",
      "    num_steps_trained: 2960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7361869812011719\n",
      "      kl: 0.016457201912999153\n",
      "      policy_loss: 0.0031414146069437265\n",
      "      total_loss: 1409.5133056640625\n",
      "      vf_explained_var: 0.47877785563468933\n",
      "      vf_loss: 1409.51025390625\n",
      "    sample_time_ms: 19356.618\n",
      "    update_time_ms: 5.474\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.96955004734013\n",
      "  time_since_restore: 7408.439708948135\n",
      "  time_this_iter_s: 23.80541157722473\n",
      "  time_total_s: 7408.439708948135\n",
      "  timestamp: 1554815710\n",
      "  timesteps_since_restore: 2960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2960000\n",
      "  training_iteration: 296\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7408 s, 296 iter, 2960000 ts, -73.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-15-34\n",
      "  done: false\n",
      "  episode_len_mean: 83.26666666666667\n",
      "  episode_reward_max: 5.1649347641911305\n",
      "  episode_reward_mean: -98.31556359473376\n",
      "  episode_reward_min: -200.06415765876872\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 31387\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4065.703\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7462540864944458\n",
      "      kl: 0.019163480028510094\n",
      "      policy_loss: 0.005369043909013271\n",
      "      total_loss: 1297.240234375\n",
      "      vf_explained_var: 0.5655932426452637\n",
      "      vf_loss: 1297.2347412109375\n",
      "    sample_time_ms: 19373.508\n",
      "    update_time_ms: 5.467\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.15778179736688\n",
      "  time_since_restore: 7431.759872198105\n",
      "  time_this_iter_s: 23.320163249969482\n",
      "  time_total_s: 7431.759872198105\n",
      "  timestamp: 1554815734\n",
      "  timesteps_since_restore: 2970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 297\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7431 s, 297 iter, 2970000 ts, -98.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-15-58\n",
      "  done: false\n",
      "  episode_len_mean: 78.84251968503936\n",
      "  episode_reward_max: 5.162073403115292\n",
      "  episode_reward_mean: -110.34103160185995\n",
      "  episode_reward_min: -200.09870494450962\n",
      "  episodes_this_iter: 127\n",
      "  episodes_total: 31514\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4057.577\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 2980000\n",
      "    num_steps_trained: 2980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7687071561813354\n",
      "      kl: 0.018840797245502472\n",
      "      policy_loss: 0.0025479416362941265\n",
      "      total_loss: 1252.6103515625\n",
      "      vf_explained_var: 0.5882577896118164\n",
      "      vf_loss: 1252.6077880859375\n",
      "    sample_time_ms: 19497.897\n",
      "    update_time_ms: 5.263\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -55.170515800929984\n",
      "  time_since_restore: 7455.905830383301\n",
      "  time_this_iter_s: 24.145958185195923\n",
      "  time_total_s: 7455.905830383301\n",
      "  timestamp: 1554815758\n",
      "  timesteps_since_restore: 2980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2980000\n",
      "  training_iteration: 298\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7455 s, 298 iter, 2980000 ts, -110 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-16-21\n",
      "  done: false\n",
      "  episode_len_mean: 92.05555555555556\n",
      "  episode_reward_max: 5.364373744443347\n",
      "  episode_reward_mean: -73.45892842478749\n",
      "  episode_reward_min: -200.04301180459433\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 31622\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4054.437\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 2990000\n",
      "    num_steps_trained: 2990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7526994943618774\n",
      "      kl: 0.018427640199661255\n",
      "      policy_loss: 0.005900867283344269\n",
      "      total_loss: 1438.2393798828125\n",
      "      vf_explained_var: 0.46163704991340637\n",
      "      vf_loss: 1438.2333984375\n",
      "    sample_time_ms: 19579.172\n",
      "    update_time_ms: 5.249\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.72946421239375\n",
      "  time_since_restore: 7479.506613969803\n",
      "  time_this_iter_s: 23.600783586502075\n",
      "  time_total_s: 7479.506613969803\n",
      "  timestamp: 1554815781\n",
      "  timesteps_since_restore: 2990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2990000\n",
      "  training_iteration: 299\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7479 s, 299 iter, 2990000 ts, -73.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-16-45\n",
      "  done: false\n",
      "  episode_len_mean: 84.64406779661017\n",
      "  episode_reward_max: 5.339884724296241\n",
      "  episode_reward_mean: -96.32948415263586\n",
      "  episode_reward_min: -200.02838182368416\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 31740\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4038.95\n",
      "    load_time_ms: 1.645\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7757105231285095\n",
      "      kl: 0.017194172367453575\n",
      "      policy_loss: 0.0026184446178376675\n",
      "      total_loss: 1318.0047607421875\n",
      "      vf_explained_var: 0.5310734510421753\n",
      "      vf_loss: 1318.0020751953125\n",
      "    sample_time_ms: 19579.17\n",
      "    update_time_ms: 5.295\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.16474207631793\n",
      "  time_since_restore: 7502.799211502075\n",
      "  time_this_iter_s: 23.29259753227234\n",
      "  time_total_s: 7502.799211502075\n",
      "  timestamp: 1554815805\n",
      "  timesteps_since_restore: 3000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 300\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7502 s, 300 iter, 3000000 ts, -96.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-17-07\n",
      "  done: false\n",
      "  episode_len_mean: 83.92436974789916\n",
      "  episode_reward_max: 5.590977436192821\n",
      "  episode_reward_mean: -95.50378187095701\n",
      "  episode_reward_min: -200.06493250329652\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 31859\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4040.089\n",
      "    load_time_ms: 1.594\n",
      "    num_steps_sampled: 3010000\n",
      "    num_steps_trained: 3010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.781448245048523\n",
      "      kl: 0.016429802402853966\n",
      "      policy_loss: 0.005091470666229725\n",
      "      total_loss: 1262.784912109375\n",
      "      vf_explained_var: 0.5555204749107361\n",
      "      vf_loss: 1262.77978515625\n",
      "    sample_time_ms: 19576.306\n",
      "    update_time_ms: 5.245\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.75189093547851\n",
      "  time_since_restore: 7525.496669054031\n",
      "  time_this_iter_s: 22.697457551956177\n",
      "  time_total_s: 7525.496669054031\n",
      "  timestamp: 1554815827\n",
      "  timesteps_since_restore: 3010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3010000\n",
      "  training_iteration: 301\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7525 s, 301 iter, 3010000 ts, -95.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-17-32\n",
      "  done: false\n",
      "  episode_len_mean: 83.23333333333333\n",
      "  episode_reward_max: 5.639632285941819\n",
      "  episode_reward_mean: -98.3036618892446\n",
      "  episode_reward_min: -200.10846104529327\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 31979\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4035.591\n",
      "    load_time_ms: 1.569\n",
      "    num_steps_sampled: 3020000\n",
      "    num_steps_trained: 3020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7871572971343994\n",
      "      kl: 0.014191636815667152\n",
      "      policy_loss: 0.0028689526952803135\n",
      "      total_loss: 1346.7220458984375\n",
      "      vf_explained_var: 0.5316672921180725\n",
      "      vf_loss: 1346.7191162109375\n",
      "    sample_time_ms: 19586.259\n",
      "    update_time_ms: 5.308\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.1518309446223\n",
      "  time_since_restore: 7549.5799968242645\n",
      "  time_this_iter_s: 24.083327770233154\n",
      "  time_total_s: 7549.5799968242645\n",
      "  timestamp: 1554815852\n",
      "  timesteps_since_restore: 3020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3020000\n",
      "  training_iteration: 302\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7549 s, 302 iter, 3020000 ts, -98.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-17-57\n",
      "  done: false\n",
      "  episode_len_mean: 85.75\n",
      "  episode_reward_max: 4.6294437331522165\n",
      "  episode_reward_mean: -91.36261107725362\n",
      "  episode_reward_min: -200.04196434057496\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 32095\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4133.12\n",
      "    load_time_ms: 1.556\n",
      "    num_steps_sampled: 3030000\n",
      "    num_steps_trained: 3030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.789174497127533\n",
      "      kl: 0.015302927233278751\n",
      "      policy_loss: 0.0046449946239590645\n",
      "      total_loss: 1373.4896240234375\n",
      "      vf_explained_var: 0.5082657337188721\n",
      "      vf_loss: 1373.4849853515625\n",
      "    sample_time_ms: 19570.328\n",
      "    update_time_ms: 5.323\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.68130553862681\n",
      "  time_since_restore: 7574.8376796245575\n",
      "  time_this_iter_s: 25.25768280029297\n",
      "  time_total_s: 7574.8376796245575\n",
      "  timestamp: 1554815877\n",
      "  timesteps_since_restore: 3030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3030000\n",
      "  training_iteration: 303\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7574 s, 303 iter, 3030000 ts, -91.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-18-25\n",
      "  done: false\n",
      "  episode_len_mean: 87.67543859649123\n",
      "  episode_reward_max: 5.510964084478556\n",
      "  episode_reward_mean: -86.11531998653088\n",
      "  episode_reward_min: -200.02964811168658\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 32209\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4257.35\n",
      "    load_time_ms: 1.508\n",
      "    num_steps_sampled: 3040000\n",
      "    num_steps_trained: 3040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.795604407787323\n",
      "      kl: 0.024749035015702248\n",
      "      policy_loss: 0.008947550319135189\n",
      "      total_loss: 1419.3778076171875\n",
      "      vf_explained_var: 0.5123962759971619\n",
      "      vf_loss: 1419.36865234375\n",
      "    sample_time_ms: 19875.002\n",
      "    update_time_ms: 6.473\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.057659993265446\n",
      "  time_since_restore: 7602.667966365814\n",
      "  time_this_iter_s: 27.830286741256714\n",
      "  time_total_s: 7602.667966365814\n",
      "  timestamp: 1554815905\n",
      "  timesteps_since_restore: 3040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3040000\n",
      "  training_iteration: 304\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7602 s, 304 iter, 3040000 ts, -86.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-18-52\n",
      "  done: false\n",
      "  episode_len_mean: 84.63865546218487\n",
      "  episode_reward_max: 5.449293082784205\n",
      "  episode_reward_mean: -92.2007802719399\n",
      "  episode_reward_min: -200.03997397352316\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 32328\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4351.898\n",
      "    load_time_ms: 1.574\n",
      "    num_steps_sampled: 3050000\n",
      "    num_steps_trained: 3050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8040341138839722\n",
      "      kl: 0.019931968301534653\n",
      "      policy_loss: 0.004552294034510851\n",
      "      total_loss: 1315.5362548828125\n",
      "      vf_explained_var: 0.519279956817627\n",
      "      vf_loss: 1315.5316162109375\n",
      "    sample_time_ms: 20114.392\n",
      "    update_time_ms: 6.603\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.10039013596995\n",
      "  time_since_restore: 7629.5949375629425\n",
      "  time_this_iter_s: 26.926971197128296\n",
      "  time_total_s: 7629.5949375629425\n",
      "  timestamp: 1554815932\n",
      "  timesteps_since_restore: 3050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3050000\n",
      "  training_iteration: 305\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7629 s, 305 iter, 3050000 ts, -92.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-19-16\n",
      "  done: false\n",
      "  episode_len_mean: 92.88785046728972\n",
      "  episode_reward_max: 5.634670712042167\n",
      "  episode_reward_mean: -70.78786428728165\n",
      "  episode_reward_min: -200.03248577851923\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 32435\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4362.301\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 3060000\n",
      "    num_steps_trained: 3060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8026094436645508\n",
      "      kl: 0.01737530156970024\n",
      "      policy_loss: 0.004640828352421522\n",
      "      total_loss: 1458.944091796875\n",
      "      vf_explained_var: 0.4488409459590912\n",
      "      vf_loss: 1458.9393310546875\n",
      "    sample_time_ms: 20159.378\n",
      "    update_time_ms: 6.947\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.39393214364083\n",
      "  time_since_restore: 7653.956843614578\n",
      "  time_this_iter_s: 24.361906051635742\n",
      "  time_total_s: 7653.956843614578\n",
      "  timestamp: 1554815956\n",
      "  timesteps_since_restore: 3060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3060000\n",
      "  training_iteration: 306\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7653 s, 306 iter, 3060000 ts, -70.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-19-44\n",
      "  done: false\n",
      "  episode_len_mean: 89.20353982300885\n",
      "  episode_reward_max: 5.92744263706687\n",
      "  episode_reward_mean: -81.3921075370692\n",
      "  episode_reward_min: -200.04294309794903\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 32548\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4449.584\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 3070000\n",
      "    num_steps_trained: 3070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.810136079788208\n",
      "      kl: 0.016771918162703514\n",
      "      policy_loss: 0.004591586533933878\n",
      "      total_loss: 1487.4324951171875\n",
      "      vf_explained_var: 0.4648693799972534\n",
      "      vf_loss: 1487.4278564453125\n",
      "    sample_time_ms: 20567.294\n",
      "    update_time_ms: 7.113\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.69605376853459\n",
      "  time_since_restore: 7682.233698606491\n",
      "  time_this_iter_s: 28.276854991912842\n",
      "  time_total_s: 7682.233698606491\n",
      "  timestamp: 1554815984\n",
      "  timesteps_since_restore: 3070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3070000\n",
      "  training_iteration: 307\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7682 s, 307 iter, 3070000 ts, -81.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-20-09\n",
      "  done: false\n",
      "  episode_len_mean: 95.60952380952381\n",
      "  episode_reward_max: 5.380658391940826\n",
      "  episode_reward_mean: -64.92471147890855\n",
      "  episode_reward_min: -200.06270026854546\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 32653\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4457.578\n",
      "    load_time_ms: 1.632\n",
      "    num_steps_sampled: 3080000\n",
      "    num_steps_trained: 3080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8084369897842407\n",
      "      kl: 0.019307292997837067\n",
      "      policy_loss: 0.0059570446610450745\n",
      "      total_loss: 1471.0972900390625\n",
      "      vf_explained_var: 0.4331536889076233\n",
      "      vf_loss: 1471.0911865234375\n",
      "    sample_time_ms: 20543.867\n",
      "    update_time_ms: 7.219\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -32.46235573945427\n",
      "  time_since_restore: 7706.228275775909\n",
      "  time_this_iter_s: 23.994577169418335\n",
      "  time_total_s: 7706.228275775909\n",
      "  timestamp: 1554816009\n",
      "  timesteps_since_restore: 3080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3080000\n",
      "  training_iteration: 308\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7706 s, 308 iter, 3080000 ts, -64.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-20-33\n",
      "  done: false\n",
      "  episode_len_mean: 86.18260869565218\n",
      "  episode_reward_max: 5.491491601808175\n",
      "  episode_reward_mean: -88.91154699599831\n",
      "  episode_reward_min: -200.04238813177406\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 32768\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4458.428\n",
      "    load_time_ms: 1.653\n",
      "    num_steps_sampled: 3090000\n",
      "    num_steps_trained: 3090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8308760523796082\n",
      "      kl: 0.01651383750140667\n",
      "      policy_loss: 0.0050352164544165134\n",
      "      total_loss: 1434.8697509765625\n",
      "      vf_explained_var: 0.48018255829811096\n",
      "      vf_loss: 1434.86474609375\n",
      "    sample_time_ms: 20600.06\n",
      "    update_time_ms: 7.247\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.455773497999154\n",
      "  time_since_restore: 7730.400514125824\n",
      "  time_this_iter_s: 24.17223834991455\n",
      "  time_total_s: 7730.400514125824\n",
      "  timestamp: 1554816033\n",
      "  timesteps_since_restore: 3090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3090000\n",
      "  training_iteration: 309\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7730 s, 309 iter, 3090000 ts, -88.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-20-57\n",
      "  done: false\n",
      "  episode_len_mean: 88.73451327433628\n",
      "  episode_reward_max: 5.994815410547574\n",
      "  episode_reward_mean: -83.0749432349548\n",
      "  episode_reward_min: -200.06853436345318\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 32881\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4463.351\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 3100000\n",
      "    num_steps_trained: 3100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8231931924819946\n",
      "      kl: 0.019232621416449547\n",
      "      policy_loss: 0.006539902649819851\n",
      "      total_loss: 1460.245361328125\n",
      "      vf_explained_var: 0.42666420340538025\n",
      "      vf_loss: 1460.2388916015625\n",
      "    sample_time_ms: 20652.221\n",
      "    update_time_ms: 7.28\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.5374716174774\n",
      "  time_since_restore: 7754.260321855545\n",
      "  time_this_iter_s: 23.85980772972107\n",
      "  time_total_s: 7754.260321855545\n",
      "  timestamp: 1554816057\n",
      "  timesteps_since_restore: 3100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3100000\n",
      "  training_iteration: 310\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7754 s, 310 iter, 3100000 ts, -83.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-21-22\n",
      "  done: false\n",
      "  episode_len_mean: 89.38392857142857\n",
      "  episode_reward_max: 5.370151569505596\n",
      "  episode_reward_mean: -80.24888948591335\n",
      "  episode_reward_min: -200.0453887499691\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 32993\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4481.052\n",
      "    load_time_ms: 1.602\n",
      "    num_steps_sampled: 3110000\n",
      "    num_steps_trained: 3110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.824852466583252\n",
      "      kl: 0.021454401314258575\n",
      "      policy_loss: 0.008619705215096474\n",
      "      total_loss: 1412.25830078125\n",
      "      vf_explained_var: 0.4593946933746338\n",
      "      vf_loss: 1412.2496337890625\n",
      "    sample_time_ms: 20909.532\n",
      "    update_time_ms: 7.238\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.12444474295669\n",
      "  time_since_restore: 7779.707828044891\n",
      "  time_this_iter_s: 25.447506189346313\n",
      "  time_total_s: 7779.707828044891\n",
      "  timestamp: 1554816082\n",
      "  timesteps_since_restore: 3110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3110000\n",
      "  training_iteration: 311\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7779 s, 311 iter, 3110000 ts, -80.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-21-47\n",
      "  done: false\n",
      "  episode_len_mean: 93.51401869158879\n",
      "  episode_reward_max: 6.177690241740093\n",
      "  episode_reward_mean: -70.80372326017986\n",
      "  episode_reward_min: -200.05517153857537\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 33100\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4486.138\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 3120000\n",
      "    num_steps_trained: 3120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8255981206893921\n",
      "      kl: 0.017640648409724236\n",
      "      policy_loss: 0.004870006814599037\n",
      "      total_loss: 1509.09033203125\n",
      "      vf_explained_var: 0.4224528670310974\n",
      "      vf_loss: 1509.0855712890625\n",
      "    sample_time_ms: 20980.622\n",
      "    update_time_ms: 7.145\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.40186163008993\n",
      "  time_since_restore: 7804.547900676727\n",
      "  time_this_iter_s: 24.840072631835938\n",
      "  time_total_s: 7804.547900676727\n",
      "  timestamp: 1554816107\n",
      "  timesteps_since_restore: 3120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3120000\n",
      "  training_iteration: 312\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7804 s, 312 iter, 3120000 ts, -70.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-22-11\n",
      "  done: false\n",
      "  episode_len_mean: 87.39473684210526\n",
      "  episode_reward_max: 5.48126821497272\n",
      "  episode_reward_mean: -86.01773695707894\n",
      "  episode_reward_min: -200.04175792300788\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 33214\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4401.654\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 3130000\n",
      "    num_steps_trained: 3130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8341387510299683\n",
      "      kl: 0.019390877336263657\n",
      "      policy_loss: 0.0037192320451140404\n",
      "      total_loss: 1431.9903564453125\n",
      "      vf_explained_var: 0.4785771369934082\n",
      "      vf_loss: 1431.9866943359375\n",
      "    sample_time_ms: 20915.85\n",
      "    update_time_ms: 7.087\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.00886847853947\n",
      "  time_since_restore: 7828.299072027206\n",
      "  time_this_iter_s: 23.751171350479126\n",
      "  time_total_s: 7828.299072027206\n",
      "  timestamp: 1554816131\n",
      "  timesteps_since_restore: 3130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3130000\n",
      "  training_iteration: 313\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7828 s, 313 iter, 3130000 ts, -86 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-22-35\n",
      "  done: false\n",
      "  episode_len_mean: 88.97345132743362\n",
      "  episode_reward_max: 5.7614309064041525\n",
      "  episode_reward_mean: -82.98901130590932\n",
      "  episode_reward_min: -200.02504722537003\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 33327\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4282.819\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 3140000\n",
      "    num_steps_trained: 3140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8334523439407349\n",
      "      kl: 0.01859583519399166\n",
      "      policy_loss: 0.006548511795699596\n",
      "      total_loss: 1404.74072265625\n",
      "      vf_explained_var: 0.4849609434604645\n",
      "      vf_loss: 1404.734130859375\n",
      "    sample_time_ms: 20689.597\n",
      "    update_time_ms: 5.818\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.494505652954665\n",
      "  time_since_restore: 7852.666244268417\n",
      "  time_this_iter_s: 24.367172241210938\n",
      "  time_total_s: 7852.666244268417\n",
      "  timestamp: 1554816155\n",
      "  timesteps_since_restore: 3140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3140000\n",
      "  training_iteration: 314\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7852 s, 314 iter, 3140000 ts, -83 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-23-00\n",
      "  done: false\n",
      "  episode_len_mean: 85.35897435897436\n",
      "  episode_reward_max: 5.525135084762274\n",
      "  episode_reward_mean: -90.38933146859094\n",
      "  episode_reward_min: -200.0397835479509\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 33444\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4206.817\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 3150000\n",
      "    num_steps_trained: 3150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8422842025756836\n",
      "      kl: 0.018078036606311798\n",
      "      policy_loss: 0.004811481572687626\n",
      "      total_loss: 1415.0615234375\n",
      "      vf_explained_var: 0.48254698514938354\n",
      "      vf_loss: 1415.0567626953125\n",
      "    sample_time_ms: 20542.46\n",
      "    update_time_ms: 5.925\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.19466573429547\n",
      "  time_since_restore: 7877.364588499069\n",
      "  time_this_iter_s: 24.698344230651855\n",
      "  time_total_s: 7877.364588499069\n",
      "  timestamp: 1554816180\n",
      "  timesteps_since_restore: 3150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3150000\n",
      "  training_iteration: 315\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7877 s, 315 iter, 3150000 ts, -90.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-23-26\n",
      "  done: false\n",
      "  episode_len_mean: 88.66964285714286\n",
      "  episode_reward_max: 5.48036842602525\n",
      "  episode_reward_mean: -82.01174576384412\n",
      "  episode_reward_min: -200.04274158798367\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 33556\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4208.021\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 3160000\n",
      "    num_steps_trained: 3160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.833412766456604\n",
      "      kl: 0.014534118585288525\n",
      "      policy_loss: 0.004364680498838425\n",
      "      total_loss: 1432.871337890625\n",
      "      vf_explained_var: 0.43976762890815735\n",
      "      vf_loss: 1432.866943359375\n",
      "    sample_time_ms: 20659.978\n",
      "    update_time_ms: 5.665\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.00587288192206\n",
      "  time_since_restore: 7902.9225425720215\n",
      "  time_this_iter_s: 25.55795407295227\n",
      "  time_total_s: 7902.9225425720215\n",
      "  timestamp: 1554816206\n",
      "  timesteps_since_restore: 3160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3160000\n",
      "  training_iteration: 316\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7902 s, 316 iter, 3160000 ts, -82 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-23-49\n",
      "  done: false\n",
      "  episode_len_mean: 87.20175438596492\n",
      "  episode_reward_max: 4.601637656496902\n",
      "  episode_reward_mean: -87.90137426877473\n",
      "  episode_reward_min: -200.06526370565538\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 33670\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4121.426\n",
      "    load_time_ms: 1.742\n",
      "    num_steps_sampled: 3170000\n",
      "    num_steps_trained: 3170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8461511135101318\n",
      "      kl: 0.01844054087996483\n",
      "      policy_loss: 0.005646230652928352\n",
      "      total_loss: 1456.4359130859375\n",
      "      vf_explained_var: 0.47760313749313354\n",
      "      vf_loss: 1456.4300537109375\n",
      "    sample_time_ms: 20257.187\n",
      "    update_time_ms: 5.584\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.95068713438738\n",
      "  time_since_restore: 7926.304872751236\n",
      "  time_this_iter_s: 23.382330179214478\n",
      "  time_total_s: 7926.304872751236\n",
      "  timestamp: 1554816229\n",
      "  timesteps_since_restore: 3170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3170000\n",
      "  training_iteration: 317\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7926 s, 317 iter, 3170000 ts, -87.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-24-11\n",
      "  done: false\n",
      "  episode_len_mean: 85.08403361344538\n",
      "  episode_reward_max: 6.021624164783747\n",
      "  episode_reward_mean: -90.50861804427028\n",
      "  episode_reward_min: -200.0338705234986\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 33789\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4139.846\n",
      "    load_time_ms: 1.702\n",
      "    num_steps_sampled: 3180000\n",
      "    num_steps_trained: 3180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8512076139450073\n",
      "      kl: 0.014177844859659672\n",
      "      policy_loss: 0.003748595016077161\n",
      "      total_loss: 1401.60546875\n",
      "      vf_explained_var: 0.5091755986213684\n",
      "      vf_loss: 1401.601806640625\n",
      "    sample_time_ms: 20078.179\n",
      "    update_time_ms: 5.535\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.25430902213514\n",
      "  time_since_restore: 7948.69203877449\n",
      "  time_this_iter_s: 22.387166023254395\n",
      "  time_total_s: 7948.69203877449\n",
      "  timestamp: 1554816251\n",
      "  timesteps_since_restore: 3180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3180000\n",
      "  training_iteration: 318\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7948 s, 318 iter, 3180000 ts, -90.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-24-36\n",
      "  done: false\n",
      "  episode_len_mean: 88.51327433628319\n",
      "  episode_reward_max: 5.595254394355598\n",
      "  episode_reward_mean: -83.31673720572151\n",
      "  episode_reward_min: -200.0474106205827\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 33902\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4139.369\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 3190000\n",
      "    num_steps_trained: 3190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8557916283607483\n",
      "      kl: 0.016958465799689293\n",
      "      policy_loss: 0.005217564292252064\n",
      "      total_loss: 1407.3233642578125\n",
      "      vf_explained_var: 0.4758296012878418\n",
      "      vf_loss: 1407.318115234375\n",
      "    sample_time_ms: 20080.692\n",
      "    update_time_ms: 5.584\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.658368602860754\n",
      "  time_since_restore: 7972.882858276367\n",
      "  time_this_iter_s: 24.19081950187683\n",
      "  time_total_s: 7972.882858276367\n",
      "  timestamp: 1554816276\n",
      "  timesteps_since_restore: 3190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3190000\n",
      "  training_iteration: 319\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7972 s, 319 iter, 3190000 ts, -83.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-24-59\n",
      "  done: false\n",
      "  episode_len_mean: 85.14406779661017\n",
      "  episode_reward_max: 5.711001939767647\n",
      "  episode_reward_mean: -93.30862677026312\n",
      "  episode_reward_min: -200.06096330092637\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 34020\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4139.671\n",
      "    load_time_ms: 1.679\n",
      "    num_steps_sampled: 3200000\n",
      "    num_steps_trained: 3200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8794776797294617\n",
      "      kl: 0.02077561803162098\n",
      "      policy_loss: 0.004772683139890432\n",
      "      total_loss: 1377.6339111328125\n",
      "      vf_explained_var: 0.49608319997787476\n",
      "      vf_loss: 1377.629150390625\n",
      "    sample_time_ms: 20016.444\n",
      "    update_time_ms: 5.829\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.654313385131566\n",
      "  time_since_restore: 7996.10354590416\n",
      "  time_this_iter_s: 23.22068762779236\n",
      "  time_total_s: 7996.10354590416\n",
      "  timestamp: 1554816299\n",
      "  timesteps_since_restore: 3200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3200000\n",
      "  training_iteration: 320\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 7996 s, 320 iter, 3200000 ts, -93.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-25-22\n",
      "  done: false\n",
      "  episode_len_mean: 92.32407407407408\n",
      "  episode_reward_max: 5.711601414706932\n",
      "  episode_reward_mean: -74.27280934590102\n",
      "  episode_reward_min: -200.0574158477355\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 34128\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4121.587\n",
      "    load_time_ms: 1.734\n",
      "    num_steps_sampled: 3210000\n",
      "    num_steps_trained: 3210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8802537322044373\n",
      "      kl: 0.01757473312318325\n",
      "      policy_loss: 0.005486689507961273\n",
      "      total_loss: 1462.4478759765625\n",
      "      vf_explained_var: 0.4423409402370453\n",
      "      vf_loss: 1462.4425048828125\n",
      "    sample_time_ms: 19840.338\n",
      "    update_time_ms: 5.783\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.136404672950526\n",
      "  time_since_restore: 8019.609904766083\n",
      "  time_this_iter_s: 23.506358861923218\n",
      "  time_total_s: 8019.609904766083\n",
      "  timestamp: 1554816322\n",
      "  timesteps_since_restore: 3210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3210000\n",
      "  training_iteration: 321\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8019 s, 321 iter, 3210000 ts, -74.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-25-46\n",
      "  done: false\n",
      "  episode_len_mean: 86.14782608695653\n",
      "  episode_reward_max: 5.514943195940681\n",
      "  episode_reward_mean: -90.62309078007232\n",
      "  episode_reward_min: -200.07899446220748\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 34243\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4118.386\n",
      "    load_time_ms: 1.773\n",
      "    num_steps_sampled: 3220000\n",
      "    num_steps_trained: 3220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8972727656364441\n",
      "      kl: 0.01873295195400715\n",
      "      policy_loss: 0.004556499887257814\n",
      "      total_loss: 1407.0047607421875\n",
      "      vf_explained_var: 0.5126022100448608\n",
      "      vf_loss: 1407.000244140625\n",
      "    sample_time_ms: 19713.757\n",
      "    update_time_ms: 5.904\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.31154539003616\n",
      "  time_since_restore: 8043.157804965973\n",
      "  time_this_iter_s: 23.547900199890137\n",
      "  time_total_s: 8043.157804965973\n",
      "  timestamp: 1554816346\n",
      "  timesteps_since_restore: 3220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3220000\n",
      "  training_iteration: 322\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8043 s, 322 iter, 3220000 ts, -90.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-26-09\n",
      "  done: false\n",
      "  episode_len_mean: 93.29629629629629\n",
      "  episode_reward_max: 6.412973555777518\n",
      "  episode_reward_mean: -72.03090879195666\n",
      "  episode_reward_min: -200.04698466127633\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 34351\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4103.084\n",
      "    load_time_ms: 1.794\n",
      "    num_steps_sampled: 3230000\n",
      "    num_steps_trained: 3230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9017395377159119\n",
      "      kl: 0.025586767122149467\n",
      "      policy_loss: 0.007093325722962618\n",
      "      total_loss: 1538.4544677734375\n",
      "      vf_explained_var: 0.42690521478652954\n",
      "      vf_loss: 1538.447265625\n",
      "    sample_time_ms: 19679.396\n",
      "    update_time_ms: 6.027\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.01545439597833\n",
      "  time_since_restore: 8066.412939310074\n",
      "  time_this_iter_s: 23.255134344100952\n",
      "  time_total_s: 8066.412939310074\n",
      "  timestamp: 1554816369\n",
      "  timesteps_since_restore: 3230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3230000\n",
      "  training_iteration: 323\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8066 s, 323 iter, 3230000 ts, -72 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-26-33\n",
      "  done: false\n",
      "  episode_len_mean: 85.80172413793103\n",
      "  episode_reward_max: 6.173087079411154\n",
      "  episode_reward_mean: -91.59033741757217\n",
      "  episode_reward_min: -200.05732572285365\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 34467\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4098.27\n",
      "    load_time_ms: 1.761\n",
      "    num_steps_sampled: 3240000\n",
      "    num_steps_trained: 3240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9154784083366394\n",
      "      kl: 0.019019892439246178\n",
      "      policy_loss: 0.0065163723193109035\n",
      "      total_loss: 1376.562744140625\n",
      "      vf_explained_var: 0.5049288868904114\n",
      "      vf_loss: 1376.5562744140625\n",
      "    sample_time_ms: 19616.855\n",
      "    update_time_ms: 6.034\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.795168708786086\n",
      "  time_since_restore: 8090.107796669006\n",
      "  time_this_iter_s: 23.694857358932495\n",
      "  time_total_s: 8090.107796669006\n",
      "  timestamp: 1554816393\n",
      "  timesteps_since_restore: 3240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3240000\n",
      "  training_iteration: 324\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8090 s, 324 iter, 3240000 ts, -91.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-26-57\n",
      "  done: false\n",
      "  episode_len_mean: 87.41739130434783\n",
      "  episode_reward_max: 5.573030621965469\n",
      "  episode_reward_mean: -86.79303934123944\n",
      "  episode_reward_min: -200.047482228312\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 34582\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4081.832\n",
      "    load_time_ms: 1.823\n",
      "    num_steps_sampled: 3250000\n",
      "    num_steps_trained: 3250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9273524880409241\n",
      "      kl: 0.026027487590909004\n",
      "      policy_loss: 0.009494191966950893\n",
      "      total_loss: 1347.090087890625\n",
      "      vf_explained_var: 0.5068144798278809\n",
      "      vf_loss: 1347.08056640625\n",
      "    sample_time_ms: 19548.273\n",
      "    update_time_ms: 5.823\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.396519670619725\n",
      "  time_since_restore: 8113.950136423111\n",
      "  time_this_iter_s: 23.842339754104614\n",
      "  time_total_s: 8113.950136423111\n",
      "  timestamp: 1554816417\n",
      "  timesteps_since_restore: 3250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3250000\n",
      "  training_iteration: 325\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8113 s, 325 iter, 3250000 ts, -86.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-27-21\n",
      "  done: false\n",
      "  episode_len_mean: 87.75221238938053\n",
      "  episode_reward_max: 5.637324012926691\n",
      "  episode_reward_mean: -86.64087349906973\n",
      "  episode_reward_min: -200.0702512648655\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 34695\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4062.58\n",
      "    load_time_ms: 1.729\n",
      "    num_steps_sampled: 3260000\n",
      "    num_steps_trained: 3260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9279522895812988\n",
      "      kl: 0.0189974308013916\n",
      "      policy_loss: 0.0057388246059417725\n",
      "      total_loss: 1443.0350341796875\n",
      "      vf_explained_var: 0.47277647256851196\n",
      "      vf_loss: 1443.029296875\n",
      "    sample_time_ms: 19380.279\n",
      "    update_time_ms: 5.718\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.320436749534856\n",
      "  time_since_restore: 8137.6238560676575\n",
      "  time_this_iter_s: 23.67371964454651\n",
      "  time_total_s: 8137.6238560676575\n",
      "  timestamp: 1554816441\n",
      "  timesteps_since_restore: 3260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3260000\n",
      "  training_iteration: 326\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8137 s, 326 iter, 3260000 ts, -86.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-27-51\n",
      "  done: false\n",
      "  episode_len_mean: 90.71818181818182\n",
      "  episode_reward_max: 5.663882946543621\n",
      "  episode_reward_mean: -78.0412715873552\n",
      "  episode_reward_min: -200.07549599255037\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 34805\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4231.85\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 3270000\n",
      "    num_steps_trained: 3270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9252679347991943\n",
      "      kl: 0.020187262445688248\n",
      "      policy_loss: 0.007970327511429787\n",
      "      total_loss: 1434.3665771484375\n",
      "      vf_explained_var: 0.4542630612850189\n",
      "      vf_loss: 1434.3585205078125\n",
      "    sample_time_ms: 19913.476\n",
      "    update_time_ms: 5.625\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.0206357936776\n",
      "  time_since_restore: 8168.028193235397\n",
      "  time_this_iter_s: 30.404337167739868\n",
      "  time_total_s: 8168.028193235397\n",
      "  timestamp: 1554816471\n",
      "  timesteps_since_restore: 3270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3270000\n",
      "  training_iteration: 327\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8168 s, 327 iter, 3270000 ts, -78 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-28-20\n",
      "  done: false\n",
      "  episode_len_mean: 83.74380165289256\n",
      "  episode_reward_max: 5.472211984351995\n",
      "  episode_reward_mean: -96.95854508604526\n",
      "  episode_reward_min: -200.0878786426269\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 34926\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4276.59\n",
      "    load_time_ms: 1.677\n",
      "    num_steps_sampled: 3280000\n",
      "    num_steps_trained: 3280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9482987523078918\n",
      "      kl: 0.02209373004734516\n",
      "      policy_loss: 0.004482645075768232\n",
      "      total_loss: 1263.570068359375\n",
      "      vf_explained_var: 0.5585771203041077\n",
      "      vf_loss: 1263.5655517578125\n",
      "    sample_time_ms: 20517.079\n",
      "    update_time_ms: 5.924\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.47927254302263\n",
      "  time_since_restore: 8196.905541419983\n",
      "  time_this_iter_s: 28.87734818458557\n",
      "  time_total_s: 8196.905541419983\n",
      "  timestamp: 1554816500\n",
      "  timesteps_since_restore: 3280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3280000\n",
      "  training_iteration: 328\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8196 s, 328 iter, 3280000 ts, -97 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-28-46\n",
      "  done: false\n",
      "  episode_len_mean: 86.23275862068965\n",
      "  episode_reward_max: 5.747777316512204\n",
      "  episode_reward_mean: -89.79118589007578\n",
      "  episode_reward_min: -200.08517536917546\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 35042\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4341.374\n",
      "    load_time_ms: 1.667\n",
      "    num_steps_sampled: 3290000\n",
      "    num_steps_trained: 3290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9569852948188782\n",
      "      kl: 0.023411231115460396\n",
      "      policy_loss: 0.00875855889171362\n",
      "      total_loss: 1393.1759033203125\n",
      "      vf_explained_var: 0.4883182644844055\n",
      "      vf_loss: 1393.1671142578125\n",
      "    sample_time_ms: 20602.246\n",
      "    update_time_ms: 5.751\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.89559294503789\n",
      "  time_since_restore: 8222.596973657608\n",
      "  time_this_iter_s: 25.691432237625122\n",
      "  time_total_s: 8222.596973657608\n",
      "  timestamp: 1554816526\n",
      "  timesteps_since_restore: 3290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3290000\n",
      "  training_iteration: 329\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8222 s, 329 iter, 3290000 ts, -89.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-29-17\n",
      "  done: false\n",
      "  episode_len_mean: 85.12068965517241\n",
      "  episode_reward_max: 5.6372708656630905\n",
      "  episode_reward_mean: -93.20112274863644\n",
      "  episode_reward_min: -200.07381974151932\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 35158\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4480.315\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 3300000\n",
      "    num_steps_trained: 3300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9638515114784241\n",
      "      kl: 0.022048546001315117\n",
      "      policy_loss: 0.0045869434252381325\n",
      "      total_loss: 1334.2110595703125\n",
      "      vf_explained_var: 0.5135684609413147\n",
      "      vf_loss: 1334.206298828125\n",
      "    sample_time_ms: 21265.924\n",
      "    update_time_ms: 5.98\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.60056137431823\n",
      "  time_since_restore: 8253.849262475967\n",
      "  time_this_iter_s: 31.252288818359375\n",
      "  time_total_s: 8253.849262475967\n",
      "  timestamp: 1554816557\n",
      "  timesteps_since_restore: 3300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3300000\n",
      "  training_iteration: 330\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8253 s, 330 iter, 3300000 ts, -93.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-29-46\n",
      "  done: false\n",
      "  episode_len_mean: 92.73394495412845\n",
      "  episode_reward_max: 5.243351450275514\n",
      "  episode_reward_mean: -71.6349862328752\n",
      "  episode_reward_min: -200.04465428608594\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 35267\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4593.627\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 3310000\n",
      "    num_steps_trained: 3310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9665234088897705\n",
      "      kl: 0.023295925930142403\n",
      "      policy_loss: 0.00744620943441987\n",
      "      total_loss: 1434.031494140625\n",
      "      vf_explained_var: 0.4330146014690399\n",
      "      vf_loss: 1434.02392578125\n",
      "    sample_time_ms: 21714.313\n",
      "    update_time_ms: 6.025\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.8174931164376\n",
      "  time_since_restore: 8282.975372314453\n",
      "  time_this_iter_s: 29.126109838485718\n",
      "  time_total_s: 8282.975372314453\n",
      "  timestamp: 1554816586\n",
      "  timesteps_since_restore: 3310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3310000\n",
      "  training_iteration: 331\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8282 s, 331 iter, 3310000 ts, -71.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-30-17\n",
      "  done: false\n",
      "  episode_len_mean: 87.36283185840708\n",
      "  episode_reward_max: 5.414103366613172\n",
      "  episode_reward_mean: -86.68634982175813\n",
      "  episode_reward_min: -200.0601538422381\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 35380\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4833.174\n",
      "    load_time_ms: 1.624\n",
      "    num_steps_sampled: 3320000\n",
      "    num_steps_trained: 3320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.996262788772583\n",
      "      kl: 0.028182974085211754\n",
      "      policy_loss: 0.011343969963490963\n",
      "      total_loss: 1310.6671142578125\n",
      "      vf_explained_var: 0.5125905871391296\n",
      "      vf_loss: 1310.6556396484375\n",
      "    sample_time_ms: 22147.06\n",
      "    update_time_ms: 6.054\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.343174910879064\n",
      "  time_since_restore: 8313.2521276474\n",
      "  time_this_iter_s: 30.276755332946777\n",
      "  time_total_s: 8313.2521276474\n",
      "  timestamp: 1554816617\n",
      "  timesteps_since_restore: 3320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3320000\n",
      "  training_iteration: 332\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8313 s, 332 iter, 3320000 ts, -86.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-30-53\n",
      "  done: false\n",
      "  episode_len_mean: 92.60909090909091\n",
      "  episode_reward_max: 4.798700019559467\n",
      "  episode_reward_mean: -70.98292583014917\n",
      "  episode_reward_min: -200.07094565243497\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 35490\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5202.59\n",
      "    load_time_ms: 1.607\n",
      "    num_steps_sampled: 3330000\n",
      "    num_steps_trained: 3330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9926936626434326\n",
      "      kl: 0.022590886801481247\n",
      "      policy_loss: 0.006701013073325157\n",
      "      total_loss: 1439.996337890625\n",
      "      vf_explained_var: 0.43319272994995117\n",
      "      vf_loss: 1439.9896240234375\n",
      "    sample_time_ms: 23097.275\n",
      "    update_time_ms: 6.266\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.49146291507459\n",
      "  time_since_restore: 8349.712210655212\n",
      "  time_this_iter_s: 36.4600830078125\n",
      "  time_total_s: 8349.712210655212\n",
      "  timestamp: 1554816653\n",
      "  timesteps_since_restore: 3330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3330000\n",
      "  training_iteration: 333\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8349 s, 333 iter, 3330000 ts, -71 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-31-31\n",
      "  done: false\n",
      "  episode_len_mean: 88.88288288288288\n",
      "  episode_reward_max: 5.558720714790395\n",
      "  episode_reward_mean: -80.7617018140694\n",
      "  episode_reward_min: -200.05522632871669\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 35601\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5482.795\n",
      "    load_time_ms: 1.752\n",
      "    num_steps_sampled: 3340000\n",
      "    num_steps_trained: 3340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0047703981399536\n",
      "      kl: 0.02551654353737831\n",
      "      policy_loss: 0.010147802531719208\n",
      "      total_loss: 1430.7681884765625\n",
      "      vf_explained_var: 0.4663577079772949\n",
      "      vf_loss: 1430.7578125\n",
      "    sample_time_ms: 24231.555\n",
      "    update_time_ms: 6.383\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.380850907034706\n",
      "  time_since_restore: 8387.55917596817\n",
      "  time_this_iter_s: 37.846965312957764\n",
      "  time_total_s: 8387.55917596817\n",
      "  timestamp: 1554816691\n",
      "  timesteps_since_restore: 3340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3340000\n",
      "  training_iteration: 334\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8387 s, 334 iter, 3340000 ts, -80.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-32-11\n",
      "  done: false\n",
      "  episode_len_mean: 84.15966386554622\n",
      "  episode_reward_max: 5.225900625798214\n",
      "  episode_reward_mean: -94.22579004739798\n",
      "  episode_reward_min: -200.0598129400921\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 35720\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6060.301\n",
      "    load_time_ms: 1.858\n",
      "    num_steps_sampled: 3350000\n",
      "    num_steps_trained: 3350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0240963697433472\n",
      "      kl: 0.028210444375872612\n",
      "      policy_loss: 0.009601227939128876\n",
      "      total_loss: 1346.86474609375\n",
      "      vf_explained_var: 0.5256046652793884\n",
      "      vf_loss: 1346.855224609375\n",
      "    sample_time_ms: 25278.577\n",
      "    update_time_ms: 7.076\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.11289502369898\n",
      "  time_since_restore: 8427.681546926498\n",
      "  time_this_iter_s: 40.12237095832825\n",
      "  time_total_s: 8427.681546926498\n",
      "  timestamp: 1554816731\n",
      "  timesteps_since_restore: 3350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3350000\n",
      "  training_iteration: 335\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8427 s, 335 iter, 3350000 ts, -94.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-32-50\n",
      "  done: false\n",
      "  episode_len_mean: 83.0495867768595\n",
      "  episode_reward_max: 5.293146695369126\n",
      "  episode_reward_mean: -99.11445938184062\n",
      "  episode_reward_min: -200.10275591254506\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 35841\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6346.864\n",
      "    load_time_ms: 1.963\n",
      "    num_steps_sampled: 3360000\n",
      "    num_steps_trained: 3360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0328234434127808\n",
      "      kl: 0.021938174962997437\n",
      "      policy_loss: 0.009282128885388374\n",
      "      total_loss: 1321.95751953125\n",
      "      vf_explained_var: 0.5335983037948608\n",
      "      vf_loss: 1321.9482421875\n",
      "    sample_time_ms: 26470.148\n",
      "    update_time_ms: 7.995\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.55722969092031\n",
      "  time_since_restore: 8466.151927232742\n",
      "  time_this_iter_s: 38.4703803062439\n",
      "  time_total_s: 8466.151927232742\n",
      "  timestamp: 1554816770\n",
      "  timesteps_since_restore: 3360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3360000\n",
      "  training_iteration: 336\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8466 s, 336 iter, 3360000 ts, -99.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-33-33\n",
      "  done: false\n",
      "  episode_len_mean: 84.94871794871794\n",
      "  episode_reward_max: 5.41686783420063\n",
      "  episode_reward_mean: -91.92206741608773\n",
      "  episode_reward_min: -200.05450663145237\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 35958\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6616.907\n",
      "    load_time_ms: 2.05\n",
      "    num_steps_sampled: 3370000\n",
      "    num_steps_trained: 3370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.019765019416809\n",
      "      kl: 0.02714330144226551\n",
      "      policy_loss: 0.012828946113586426\n",
      "      total_loss: 1349.284912109375\n",
      "      vf_explained_var: 0.519920825958252\n",
      "      vf_loss: 1349.2720947265625\n",
      "    sample_time_ms: 27454.044\n",
      "    update_time_ms: 8.279\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.961033708043864\n",
      "  time_since_restore: 8509.103863716125\n",
      "  time_this_iter_s: 42.95193648338318\n",
      "  time_total_s: 8509.103863716125\n",
      "  timestamp: 1554816813\n",
      "  timesteps_since_restore: 3370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3370000\n",
      "  training_iteration: 337\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8509 s, 337 iter, 3370000 ts, -91.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-34-10\n",
      "  done: false\n",
      "  episode_len_mean: 85.05042016806723\n",
      "  episode_reward_max: 5.864536478928038\n",
      "  episode_reward_mean: -93.87875140161358\n",
      "  episode_reward_min: -200.07234260895052\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 36077\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6681.416\n",
      "    load_time_ms: 1.998\n",
      "    num_steps_sampled: 3380000\n",
      "    num_steps_trained: 3380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0230294466018677\n",
      "      kl: 0.022376855835318565\n",
      "      policy_loss: 0.006968164350837469\n",
      "      total_loss: 1289.85595703125\n",
      "      vf_explained_var: 0.5479080080986023\n",
      "      vf_loss: 1289.8489990234375\n",
      "    sample_time_ms: 28252.733\n",
      "    update_time_ms: 8.164\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.939375700806806\n",
      "  time_since_restore: 8546.611919879913\n",
      "  time_this_iter_s: 37.50805616378784\n",
      "  time_total_s: 8546.611919879913\n",
      "  timestamp: 1554816850\n",
      "  timesteps_since_restore: 3380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3380000\n",
      "  training_iteration: 338\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8546 s, 338 iter, 3380000 ts, -93.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-34-54\n",
      "  done: false\n",
      "  episode_len_mean: 82.17355371900827\n",
      "  episode_reward_max: 4.867170373759279\n",
      "  episode_reward_mean: -99.20945212098592\n",
      "  episode_reward_min: -200.0413897140989\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 36198\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7094.644\n",
      "    load_time_ms: 2.087\n",
      "    num_steps_sampled: 3390000\n",
      "    num_steps_trained: 3390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.040280818939209\n",
      "      kl: 0.02327713370323181\n",
      "      policy_loss: 0.005528054665774107\n",
      "      total_loss: 1353.154052734375\n",
      "      vf_explained_var: 0.5502392649650574\n",
      "      vf_loss: 1353.1484375\n",
      "    sample_time_ms: 29656.712\n",
      "    update_time_ms: 8.382\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.604726060492965\n",
      "  time_since_restore: 8590.497465372086\n",
      "  time_this_iter_s: 43.88554549217224\n",
      "  time_total_s: 8590.497465372086\n",
      "  timestamp: 1554816894\n",
      "  timesteps_since_restore: 3390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3390000\n",
      "  training_iteration: 339\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8590 s, 339 iter, 3390000 ts, -99.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-35-31\n",
      "  done: false\n",
      "  episode_len_mean: 91.80733944954129\n",
      "  episode_reward_max: 5.205092800016673\n",
      "  episode_reward_mean: -75.18451945892353\n",
      "  episode_reward_min: -200.06373156881415\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 36307\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7254.655\n",
      "    load_time_ms: 2.134\n",
      "    num_steps_sampled: 3400000\n",
      "    num_steps_trained: 3400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0354403257369995\n",
      "      kl: 0.02286011353135109\n",
      "      policy_loss: 0.005057163070887327\n",
      "      total_loss: 1415.212158203125\n",
      "      vf_explained_var: 0.47423410415649414\n",
      "      vf_loss: 1415.2069091796875\n",
      "    sample_time_ms: 30069.107\n",
      "    update_time_ms: 8.075\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.59225972946176\n",
      "  time_since_restore: 8627.47331237793\n",
      "  time_this_iter_s: 36.975847005844116\n",
      "  time_total_s: 8627.47331237793\n",
      "  timestamp: 1554816931\n",
      "  timesteps_since_restore: 3400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3400000\n",
      "  training_iteration: 340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8627 s, 340 iter, 3400000 ts, -75.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-36-18\n",
      "  done: false\n",
      "  episode_len_mean: 88.05309734513274\n",
      "  episode_reward_max: 5.541149651325068\n",
      "  episode_reward_mean: -84.91767698198827\n",
      "  episode_reward_min: -200.03273370746135\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 36420\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7957.428\n",
      "    load_time_ms: 2.127\n",
      "    num_steps_sampled: 3410000\n",
      "    num_steps_trained: 3410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0380603075027466\n",
      "      kl: 0.024908706545829773\n",
      "      policy_loss: 0.006183441262692213\n",
      "      total_loss: 1394.819580078125\n",
      "      vf_explained_var: 0.5016584396362305\n",
      "      vf_loss: 1394.8133544921875\n",
      "    sample_time_ms: 31175.522\n",
      "    update_time_ms: 8.245\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.45883849099413\n",
      "  time_since_restore: 8674.693315029144\n",
      "  time_this_iter_s: 47.2200026512146\n",
      "  time_total_s: 8674.693315029144\n",
      "  timestamp: 1554816978\n",
      "  timesteps_since_restore: 3410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3410000\n",
      "  training_iteration: 341\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8674 s, 341 iter, 3410000 ts, -84.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-37-02\n",
      "  done: false\n",
      "  episode_len_mean: 91.11009174311927\n",
      "  episode_reward_max: 5.652881454261587\n",
      "  episode_reward_mean: -75.39824202423794\n",
      "  episode_reward_min: -200.03647013124305\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 36529\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7945.341\n",
      "    load_time_ms: 2.087\n",
      "    num_steps_sampled: 3420000\n",
      "    num_steps_trained: 3420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.03675377368927\n",
      "      kl: 0.03073975443840027\n",
      "      policy_loss: 0.009816956706345081\n",
      "      total_loss: 1491.6883544921875\n",
      "      vf_explained_var: 0.44374871253967285\n",
      "      vf_loss: 1491.678466796875\n",
      "    sample_time_ms: 32499.71\n",
      "    update_time_ms: 9.217\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.69912101211897\n",
      "  time_since_restore: 8718.102670431137\n",
      "  time_this_iter_s: 43.4093554019928\n",
      "  time_total_s: 8718.102670431137\n",
      "  timestamp: 1554817022\n",
      "  timesteps_since_restore: 3420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3420000\n",
      "  training_iteration: 342\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8718 s, 342 iter, 3420000 ts, -75.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-37-46\n",
      "  done: false\n",
      "  episode_len_mean: 84.18333333333334\n",
      "  episode_reward_max: 5.589249597727465\n",
      "  episode_reward_mean: -94.72376024725354\n",
      "  episode_reward_min: -200.0731908671811\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 36649\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8078.7\n",
      "    load_time_ms: 2.074\n",
      "    num_steps_sampled: 3430000\n",
      "    num_steps_trained: 3430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0488876104354858\n",
      "      kl: 0.025107121095061302\n",
      "      policy_loss: 0.005336196161806583\n",
      "      total_loss: 1312.479248046875\n",
      "      vf_explained_var: 0.5321945548057556\n",
      "      vf_loss: 1312.4739990234375\n",
      "    sample_time_ms: 33108.58\n",
      "    update_time_ms: 11.707\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.36188012362677\n",
      "  time_since_restore: 8762.014390707016\n",
      "  time_this_iter_s: 43.911720275878906\n",
      "  time_total_s: 8762.014390707016\n",
      "  timestamp: 1554817066\n",
      "  timesteps_since_restore: 3430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3430000\n",
      "  training_iteration: 343\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8762 s, 343 iter, 3430000 ts, -94.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-38-25\n",
      "  done: false\n",
      "  episode_len_mean: 89.76576576576576\n",
      "  episode_reward_max: 5.625097812327085\n",
      "  episode_reward_mean: -79.11436687376099\n",
      "  episode_reward_min: -200.07516084744913\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 36760\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8214.299\n",
      "    load_time_ms: 2.038\n",
      "    num_steps_sampled: 3440000\n",
      "    num_steps_trained: 3440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0497698783874512\n",
      "      kl: 0.019968871027231216\n",
      "      policy_loss: 0.006749917287379503\n",
      "      total_loss: 1361.4466552734375\n",
      "      vf_explained_var: 0.5151153206825256\n",
      "      vf_loss: 1361.43994140625\n",
      "    sample_time_ms: 33122.713\n",
      "    update_time_ms: 12.327\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.5571834368805\n",
      "  time_since_restore: 8801.367025136948\n",
      "  time_this_iter_s: 39.35263442993164\n",
      "  time_total_s: 8801.367025136948\n",
      "  timestamp: 1554817105\n",
      "  timesteps_since_restore: 3440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3440000\n",
      "  training_iteration: 344\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8801 s, 344 iter, 3440000 ts, -79.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-39-16\n",
      "  done: false\n",
      "  episode_len_mean: 88.12280701754386\n",
      "  episode_reward_max: 5.7408218479972\n",
      "  episode_reward_mean: -84.4838843116799\n",
      "  episode_reward_min: -200.05080976298694\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 36874\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7968.727\n",
      "    load_time_ms: 1.887\n",
      "    num_steps_sampled: 3450000\n",
      "    num_steps_trained: 3450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.06020987033844\n",
      "      kl: 0.024985427036881447\n",
      "      policy_loss: 0.009786483831703663\n",
      "      total_loss: 1390.7518310546875\n",
      "      vf_explained_var: 0.4918473958969116\n",
      "      vf_loss: 1390.7421875\n",
      "    sample_time_ms: 34381.109\n",
      "    update_time_ms: 12.568\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.24194215583995\n",
      "  time_since_restore: 8851.608443260193\n",
      "  time_this_iter_s: 50.24141812324524\n",
      "  time_total_s: 8851.608443260193\n",
      "  timestamp: 1554817156\n",
      "  timesteps_since_restore: 3450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3450000\n",
      "  training_iteration: 345\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8851 s, 345 iter, 3450000 ts, -84.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-40-02\n",
      "  done: false\n",
      "  episode_len_mean: 85.92241379310344\n",
      "  episode_reward_max: 5.718039889403613\n",
      "  episode_reward_mean: -87.72966957692853\n",
      "  episode_reward_min: -200.05417656542613\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 36990\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7842.005\n",
      "    load_time_ms: 1.841\n",
      "    num_steps_sampled: 3460000\n",
      "    num_steps_trained: 3460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.067667841911316\n",
      "      kl: 0.025237837806344032\n",
      "      policy_loss: 0.007840314880013466\n",
      "      total_loss: 1319.9583740234375\n",
      "      vf_explained_var: 0.5352197885513306\n",
      "      vf_loss: 1319.9503173828125\n",
      "    sample_time_ms: 35266.323\n",
      "    update_time_ms: 12.101\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.86483478846427\n",
      "  time_since_restore: 8897.662954092026\n",
      "  time_this_iter_s: 46.054510831832886\n",
      "  time_total_s: 8897.662954092026\n",
      "  timestamp: 1554817202\n",
      "  timesteps_since_restore: 3460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3460000\n",
      "  training_iteration: 346\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8897 s, 346 iter, 3460000 ts, -87.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-40-38\n",
      "  done: false\n",
      "  episode_len_mean: 90.38181818181818\n",
      "  episode_reward_max: 4.860781594950225\n",
      "  episode_reward_mean: -78.04203111422297\n",
      "  episode_reward_min: -200.06489624489478\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 37100\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7638.413\n",
      "    load_time_ms: 1.773\n",
      "    num_steps_sampled: 3470000\n",
      "    num_steps_trained: 3470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0740903615951538\n",
      "      kl: 0.02415143884718418\n",
      "      policy_loss: 0.006511087063699961\n",
      "      total_loss: 1469.2352294921875\n",
      "      vf_explained_var: 0.43552789092063904\n",
      "      vf_loss: 1469.228515625\n",
      "    sample_time_ms: 34778.611\n",
      "    update_time_ms: 12.216\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.02101555711149\n",
      "  time_since_restore: 8933.700335264206\n",
      "  time_this_iter_s: 36.037381172180176\n",
      "  time_total_s: 8933.700335264206\n",
      "  timestamp: 1554817238\n",
      "  timesteps_since_restore: 3470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3470000\n",
      "  training_iteration: 347\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8933 s, 347 iter, 3470000 ts, -78 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-41-15\n",
      "  done: false\n",
      "  episode_len_mean: 90.52252252252252\n",
      "  episode_reward_max: 5.72750480498573\n",
      "  episode_reward_mean: -79.40617338448702\n",
      "  episode_reward_min: -200.05650117778035\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 37211\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7641.745\n",
      "    load_time_ms: 1.77\n",
      "    num_steps_sampled: 3480000\n",
      "    num_steps_trained: 3480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0826936960220337\n",
      "      kl: 0.024386350065469742\n",
      "      policy_loss: 0.006955631077289581\n",
      "      total_loss: 1458.30224609375\n",
      "      vf_explained_var: 0.47927016019821167\n",
      "      vf_loss: 1458.2952880859375\n",
      "    sample_time_ms: 34730.444\n",
      "    update_time_ms: 12.341\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.7030866922435\n",
      "  time_since_restore: 8970.759812116623\n",
      "  time_this_iter_s: 37.05947685241699\n",
      "  time_total_s: 8970.759812116623\n",
      "  timestamp: 1554817275\n",
      "  timesteps_since_restore: 3480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3480000\n",
      "  training_iteration: 348\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 8970 s, 348 iter, 3480000 ts, -79.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-41-51\n",
      "  done: false\n",
      "  episode_len_mean: 89.76785714285714\n",
      "  episode_reward_max: 5.235936462201044\n",
      "  episode_reward_mean: -81.03219740930835\n",
      "  episode_reward_min: -200.04062014297892\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 37323\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7453.133\n",
      "    load_time_ms: 1.706\n",
      "    num_steps_sampled: 3490000\n",
      "    num_steps_trained: 3490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0922662019729614\n",
      "      kl: 0.030533557757735252\n",
      "      policy_loss: 0.009518511593341827\n",
      "      total_loss: 1426.271728515625\n",
      "      vf_explained_var: 0.45885077118873596\n",
      "      vf_loss: 1426.26220703125\n",
      "    sample_time_ms: 34085.045\n",
      "    update_time_ms: 12.437\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.51609870465419\n",
      "  time_since_restore: 9006.288174390793\n",
      "  time_this_iter_s: 35.52836227416992\n",
      "  time_total_s: 9006.288174390793\n",
      "  timestamp: 1554817311\n",
      "  timesteps_since_restore: 3490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3490000\n",
      "  training_iteration: 349\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9006 s, 349 iter, 3490000 ts, -81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-42-29\n",
      "  done: false\n",
      "  episode_len_mean: 91.06363636363636\n",
      "  episode_reward_max: 5.642377178740132\n",
      "  episode_reward_mean: -76.3435086824595\n",
      "  episode_reward_min: -200.0541195577693\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 37433\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7644.411\n",
      "    load_time_ms: 1.682\n",
      "    num_steps_sampled: 3500000\n",
      "    num_steps_trained: 3500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0932303667068481\n",
      "      kl: 0.022222815081477165\n",
      "      policy_loss: 0.008021635934710503\n",
      "      total_loss: 1408.03466796875\n",
      "      vf_explained_var: 0.4565635025501251\n",
      "      vf_loss: 1408.0264892578125\n",
      "    sample_time_ms: 34046.751\n",
      "    update_time_ms: 12.377\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.17175434122976\n",
      "  time_since_restore: 9044.792947292328\n",
      "  time_this_iter_s: 38.504772901535034\n",
      "  time_total_s: 9044.792947292328\n",
      "  timestamp: 1554817349\n",
      "  timesteps_since_restore: 3500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3500000\n",
      "  training_iteration: 350\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9044 s, 350 iter, 3500000 ts, -76.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-43-21\n",
      "  done: false\n",
      "  episode_len_mean: 89.71171171171171\n",
      "  episode_reward_max: 5.759257040870489\n",
      "  episode_reward_mean: -79.16069081434216\n",
      "  episode_reward_min: -200.06574263139515\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 37544\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7339.93\n",
      "    load_time_ms: 1.762\n",
      "    num_steps_sampled: 3510000\n",
      "    num_steps_trained: 3510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.0973094701766968\n",
      "      kl: 0.03190017491579056\n",
      "      policy_loss: 0.013234930112957954\n",
      "      total_loss: 1446.922119140625\n",
      "      vf_explained_var: 0.46675363183021545\n",
      "      vf_loss: 1446.9088134765625\n",
      "    sample_time_ms: 34830.983\n",
      "    update_time_ms: 12.732\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.58034540717109\n",
      "  time_since_restore: 9096.86208820343\n",
      "  time_this_iter_s: 52.069140911102295\n",
      "  time_total_s: 9096.86208820343\n",
      "  timestamp: 1554817401\n",
      "  timesteps_since_restore: 3510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3510000\n",
      "  training_iteration: 351\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9096 s, 351 iter, 3510000 ts, -79.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-44-12\n",
      "  done: false\n",
      "  episode_len_mean: 90.05405405405405\n",
      "  episode_reward_max: 5.62413935318849\n",
      "  episode_reward_mean: -79.22011947071483\n",
      "  episode_reward_min: -200.0165449571429\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 37655\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7313.137\n",
      "    load_time_ms: 1.785\n",
      "    num_steps_sampled: 3520000\n",
      "    num_steps_trained: 3520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1003247499465942\n",
      "      kl: 0.025775309652090073\n",
      "      policy_loss: 0.008307604119181633\n",
      "      total_loss: 1462.927734375\n",
      "      vf_explained_var: 0.4525704085826874\n",
      "      vf_loss: 1462.9193115234375\n",
      "    sample_time_ms: 35528.442\n",
      "    update_time_ms: 12.438\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.610059735357446\n",
      "  time_since_restore: 9146.969383716583\n",
      "  time_this_iter_s: 50.107295513153076\n",
      "  time_total_s: 9146.969383716583\n",
      "  timestamp: 1554817452\n",
      "  timesteps_since_restore: 3520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3520000\n",
      "  training_iteration: 352\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9146 s, 352 iter, 3520000 ts, -79.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-44-52\n",
      "  done: false\n",
      "  episode_len_mean: 89.33628318584071\n",
      "  episode_reward_max: 5.647998010007748\n",
      "  episode_reward_mean: -81.55508267572432\n",
      "  episode_reward_min: -200.0598210282542\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 37768\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7029.447\n",
      "    load_time_ms: 1.791\n",
      "    num_steps_sampled: 3530000\n",
      "    num_steps_trained: 3530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.109866976737976\n",
      "      kl: 0.039971496909856796\n",
      "      policy_loss: 0.017460601404309273\n",
      "      total_loss: 1469.034912109375\n",
      "      vf_explained_var: 0.46588853001594543\n",
      "      vf_loss: 1469.017578125\n",
      "    sample_time_ms: 35448.823\n",
      "    update_time_ms: 9.877\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.77754133786217\n",
      "  time_since_restore: 9187.215441465378\n",
      "  time_this_iter_s: 40.246057748794556\n",
      "  time_total_s: 9187.215441465378\n",
      "  timestamp: 1554817492\n",
      "  timesteps_since_restore: 3530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3530000\n",
      "  training_iteration: 353\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9187 s, 353 iter, 3530000 ts, -81.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-45-24\n",
      "  done: false\n",
      "  episode_len_mean: 87.08771929824562\n",
      "  episode_reward_max: 5.362802446618914\n",
      "  episode_reward_mean: -86.2911572541065\n",
      "  episode_reward_min: -200.02733791145752\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 37882\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6748.421\n",
      "    load_time_ms: 1.791\n",
      "    num_steps_sampled: 3540000\n",
      "    num_steps_trained: 3540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.126617670059204\n",
      "      kl: 0.037122078239917755\n",
      "      policy_loss: 0.01368267834186554\n",
      "      total_loss: 1369.4676513671875\n",
      "      vf_explained_var: 0.5125646591186523\n",
      "      vf_loss: 1369.4539794921875\n",
      "    sample_time_ms: 34969.213\n",
      "    update_time_ms: 9.242\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.145578627053254\n",
      "  time_since_restore: 9218.953483343124\n",
      "  time_this_iter_s: 31.738041877746582\n",
      "  time_total_s: 9218.953483343124\n",
      "  timestamp: 1554817524\n",
      "  timesteps_since_restore: 3540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3540000\n",
      "  training_iteration: 354\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9218 s, 354 iter, 3540000 ts, -86.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-46-01\n",
      "  done: false\n",
      "  episode_len_mean: 86.99130434782609\n",
      "  episode_reward_max: 5.097826785444885\n",
      "  episode_reward_mean: -88.6703683842255\n",
      "  episode_reward_min: -200.04171118705327\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 37997\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6595.473\n",
      "    load_time_ms: 1.806\n",
      "    num_steps_sampled: 3550000\n",
      "    num_steps_trained: 3550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1300466060638428\n",
      "      kl: 0.08739782124757767\n",
      "      policy_loss: 0.030248025432229042\n",
      "      total_loss: 1399.645751953125\n",
      "      vf_explained_var: 0.4864426553249359\n",
      "      vf_loss: 1399.6156005859375\n",
      "    sample_time_ms: 33831.478\n",
      "    update_time_ms: 8.645\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.33518419211275\n",
      "  time_since_restore: 9256.266618013382\n",
      "  time_this_iter_s: 37.31313467025757\n",
      "  time_total_s: 9256.266618013382\n",
      "  timestamp: 1554817561\n",
      "  timesteps_since_restore: 3550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3550000\n",
      "  training_iteration: 355\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9256 s, 355 iter, 3550000 ts, -88.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-46-48\n",
      "  done: false\n",
      "  episode_len_mean: 92.07407407407408\n",
      "  episode_reward_max: 5.327449531070966\n",
      "  episode_reward_mean: -73.93525017062859\n",
      "  episode_reward_min: -200.06874666891665\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 38105\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6902.847\n",
      "    load_time_ms: 1.901\n",
      "    num_steps_sampled: 3560000\n",
      "    num_steps_trained: 3560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1292026042938232\n",
      "      kl: 0.023335708305239677\n",
      "      policy_loss: 0.0055669681169092655\n",
      "      total_loss: 1435.29931640625\n",
      "      vf_explained_var: 0.45206207036972046\n",
      "      vf_loss: 1435.293701171875\n",
      "    sample_time_ms: 33635.768\n",
      "    update_time_ms: 8.326\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.967625085314296\n",
      "  time_since_restore: 9303.4406914711\n",
      "  time_this_iter_s: 47.174073457717896\n",
      "  time_total_s: 9303.4406914711\n",
      "  timestamp: 1554817608\n",
      "  timesteps_since_restore: 3560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3560000\n",
      "  training_iteration: 356\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9303 s, 356 iter, 3560000 ts, -73.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 91.54545454545455\n",
      "  episode_reward_max: 5.8571918001112975\n",
      "  episode_reward_mean: -76.42549102953927\n",
      "  episode_reward_min: -200.02512143578883\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 38215\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7323.522\n",
      "    load_time_ms: 2.105\n",
      "    num_steps_sampled: 3570000\n",
      "    num_steps_trained: 3570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1392269134521484\n",
      "      kl: 0.029911117628216743\n",
      "      policy_loss: 0.012518403120338917\n",
      "      total_loss: 1424.779052734375\n",
      "      vf_explained_var: 0.4748751223087311\n",
      "      vf_loss: 1424.7666015625\n",
      "    sample_time_ms: 34214.821\n",
      "    update_time_ms: 9.142\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.21274551476963\n",
      "  time_since_restore: 9349.49669623375\n",
      "  time_this_iter_s: 46.056004762649536\n",
      "  time_total_s: 9349.49669623375\n",
      "  timestamp: 1554817654\n",
      "  timesteps_since_restore: 3570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3570000\n",
      "  training_iteration: 357\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9349 s, 357 iter, 3570000 ts, -76.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-48-22\n",
      "  done: false\n",
      "  episode_len_mean: 90.06363636363636\n",
      "  episode_reward_max: 5.1992548175340545\n",
      "  episode_reward_mean: -78.16056589900461\n",
      "  episode_reward_min: -200.05571279455893\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 38325\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7463.383\n",
      "    load_time_ms: 2.112\n",
      "    num_steps_sampled: 3580000\n",
      "    num_steps_trained: 3580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1519933938980103\n",
      "      kl: 0.3269742727279663\n",
      "      policy_loss: 0.0312824547290802\n",
      "      total_loss: 1378.1610107421875\n",
      "      vf_explained_var: 0.4792478084564209\n",
      "      vf_loss: 1378.1297607421875\n",
      "    sample_time_ms: 35161.956\n",
      "    update_time_ms: 9.588\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.08028294950231\n",
      "  time_since_restore: 9397.433497667313\n",
      "  time_this_iter_s: 47.93680143356323\n",
      "  time_total_s: 9397.433497667313\n",
      "  timestamp: 1554817702\n",
      "  timesteps_since_restore: 3580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3580000\n",
      "  training_iteration: 358\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9397 s, 358 iter, 3580000 ts, -78.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-49-01\n",
      "  done: false\n",
      "  episode_len_mean: 92.17272727272727\n",
      "  episode_reward_max: 5.207380486003693\n",
      "  episode_reward_mean: -72.81642809912424\n",
      "  episode_reward_min: -200.05128794266287\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 38435\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7362.292\n",
      "    load_time_ms: 2.192\n",
      "    num_steps_sampled: 3590000\n",
      "    num_steps_trained: 3590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1508375406265259\n",
      "      kl: 0.026741033419966698\n",
      "      policy_loss: 0.0064119198359549046\n",
      "      total_loss: 1505.51123046875\n",
      "      vf_explained_var: 0.42796415090560913\n",
      "      vf_loss: 1505.5047607421875\n",
      "    sample_time_ms: 35619.931\n",
      "    update_time_ms: 9.534\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.40821404956211\n",
      "  time_since_restore: 9436.545389652252\n",
      "  time_this_iter_s: 39.111891984939575\n",
      "  time_total_s: 9436.545389652252\n",
      "  timestamp: 1554817741\n",
      "  timesteps_since_restore: 3590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3590000\n",
      "  training_iteration: 359\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9436 s, 359 iter, 3590000 ts, -72.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-49-44\n",
      "  done: false\n",
      "  episode_len_mean: 85.92173913043479\n",
      "  episode_reward_max: 5.723921745853767\n",
      "  episode_reward_mean: -90.57942096040094\n",
      "  episode_reward_min: -200.05925608727006\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 38550\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7203.894\n",
      "    load_time_ms: 2.264\n",
      "    num_steps_sampled: 3600000\n",
      "    num_steps_trained: 3600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1592971086502075\n",
      "      kl: 0.03472944349050522\n",
      "      policy_loss: 0.014279327355325222\n",
      "      total_loss: 1419.4862060546875\n",
      "      vf_explained_var: 0.4991990029811859\n",
      "      vf_loss: 1419.4718017578125\n",
      "    sample_time_ms: 36152.139\n",
      "    update_time_ms: 9.969\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.28971048020047\n",
      "  time_since_restore: 9478.810513019562\n",
      "  time_this_iter_s: 42.26512336730957\n",
      "  time_total_s: 9478.810513019562\n",
      "  timestamp: 1554817784\n",
      "  timesteps_since_restore: 3600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3600000\n",
      "  training_iteration: 360\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9478 s, 360 iter, 3600000 ts, -90.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-50-53\n",
      "  done: false\n",
      "  episode_len_mean: 87.81739130434782\n",
      "  episode_reward_max: 5.5964929599803135\n",
      "  episode_reward_mean: -87.03258843911163\n",
      "  episode_reward_min: -200.07023452891218\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 38665\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7684.14\n",
      "    load_time_ms: 2.513\n",
      "    num_steps_sampled: 3610000\n",
      "    num_steps_trained: 3610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1698375940322876\n",
      "      kl: 0.03533220291137695\n",
      "      policy_loss: 0.0131490807980299\n",
      "      total_loss: 1418.0672607421875\n",
      "      vf_explained_var: 0.5098932981491089\n",
      "      vf_loss: 1418.0540771484375\n",
      "    sample_time_ms: 37351.804\n",
      "    update_time_ms: 10.139\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.51629421955582\n",
      "  time_since_restore: 9547.673472166061\n",
      "  time_this_iter_s: 68.86295914649963\n",
      "  time_total_s: 9547.673472166061\n",
      "  timestamp: 1554817853\n",
      "  timesteps_since_restore: 3610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3610000\n",
      "  training_iteration: 361\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9547 s, 361 iter, 3610000 ts, -87 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-51-53\n",
      "  done: false\n",
      "  episode_len_mean: 81.52032520325203\n",
      "  episode_reward_max: 5.598655899513657\n",
      "  episode_reward_mean: -104.13973747565555\n",
      "  episode_reward_min: -200.04883924756365\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 38788\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7980.924\n",
      "    load_time_ms: 2.745\n",
      "    num_steps_sampled: 3620000\n",
      "    num_steps_trained: 3620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1858646869659424\n",
      "      kl: 0.025018585845828056\n",
      "      policy_loss: 0.009849783964455128\n",
      "      total_loss: 1370.51318359375\n",
      "      vf_explained_var: 0.5349338054656982\n",
      "      vf_loss: 1370.503173828125\n",
      "    sample_time_ms: 38030.385\n",
      "    update_time_ms: 11.352\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.069868737827775\n",
      "  time_since_restore: 9607.572775125504\n",
      "  time_this_iter_s: 59.89930295944214\n",
      "  time_total_s: 9607.572775125504\n",
      "  timestamp: 1554817913\n",
      "  timesteps_since_restore: 3620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3620000\n",
      "  training_iteration: 362\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9607 s, 362 iter, 3620000 ts, -104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-53-04\n",
      "  done: false\n",
      "  episode_len_mean: 87.41592920353982\n",
      "  episode_reward_max: 3.7945122637001063\n",
      "  episode_reward_mean: -87.09692654241641\n",
      "  episode_reward_min: -200.03390311208872\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 38901\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9110.035\n",
      "    load_time_ms: 2.902\n",
      "    num_steps_sampled: 3630000\n",
      "    num_steps_trained: 3630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1624765396118164\n",
      "      kl: 0.03647159785032272\n",
      "      policy_loss: 0.0142426248639822\n",
      "      total_loss: 1380.8897705078125\n",
      "      vf_explained_var: 0.5034202337265015\n",
      "      vf_loss: 1380.8753662109375\n",
      "    sample_time_ms: 40034.349\n",
      "    update_time_ms: 12.118\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.54846327120823\n",
      "  time_since_restore: 9679.216274023056\n",
      "  time_this_iter_s: 71.64349889755249\n",
      "  time_total_s: 9679.216274023056\n",
      "  timestamp: 1554817984\n",
      "  timesteps_since_restore: 3630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3630000\n",
      "  training_iteration: 363\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9679 s, 363 iter, 3630000 ts, -87.1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-53-59\n",
      "  done: false\n",
      "  episode_len_mean: 82.9\n",
      "  episode_reward_max: 5.3206532985669925\n",
      "  episode_reward_mean: -98.28748619754879\n",
      "  episode_reward_min: -200.05567045048133\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 39021\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9183.935\n",
      "    load_time_ms: 2.819\n",
      "    num_steps_sampled: 3640000\n",
      "    num_steps_trained: 3640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1805875301361084\n",
      "      kl: 0.03674685209989548\n",
      "      policy_loss: 0.013766519725322723\n",
      "      total_loss: 1319.2135009765625\n",
      "      vf_explained_var: 0.5458095073699951\n",
      "      vf_loss: 1319.1995849609375\n",
      "    sample_time_ms: 42201.904\n",
      "    update_time_ms: 16.752\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.14374309877441\n",
      "  time_since_restore: 9733.415042161942\n",
      "  time_this_iter_s: 54.1987681388855\n",
      "  time_total_s: 9733.415042161942\n",
      "  timestamp: 1554818039\n",
      "  timesteps_since_restore: 3640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3640000\n",
      "  training_iteration: 364\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9733 s, 364 iter, 3640000 ts, -98.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-54-36\n",
      "  done: false\n",
      "  episode_len_mean: 83.90833333333333\n",
      "  episode_reward_max: 5.716884751591888\n",
      "  episode_reward_mean: -96.74173432230755\n",
      "  episode_reward_min: -200.04264646082257\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 39141\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9188.561\n",
      "    load_time_ms: 2.804\n",
      "    num_steps_sampled: 3650000\n",
      "    num_steps_trained: 3650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1881989240646362\n",
      "      kl: 0.03568897396326065\n",
      "      policy_loss: 0.011435285210609436\n",
      "      total_loss: 1357.273193359375\n",
      "      vf_explained_var: 0.5140181183815002\n",
      "      vf_loss: 1357.2615966796875\n",
      "    sample_time_ms: 42198.537\n",
      "    update_time_ms: 16.634\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.370867161153775\n",
      "  time_since_restore: 9770.748512744904\n",
      "  time_this_iter_s: 37.333470582962036\n",
      "  time_total_s: 9770.748512744904\n",
      "  timestamp: 1554818076\n",
      "  timesteps_since_restore: 3650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3650000\n",
      "  training_iteration: 365\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9770 s, 365 iter, 3650000 ts, -96.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-55-18\n",
      "  done: false\n",
      "  episode_len_mean: 87.07826086956521\n",
      "  episode_reward_max: 6.0849146934183365\n",
      "  episode_reward_mean: -87.19457800594775\n",
      "  episode_reward_min: -200.06668395142236\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 39256\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8915.569\n",
      "    load_time_ms: 2.681\n",
      "    num_steps_sampled: 3660000\n",
      "    num_steps_trained: 3660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1840823888778687\n",
      "      kl: 0.031442951411008835\n",
      "      policy_loss: 0.012668735347688198\n",
      "      total_loss: 1414.02734375\n",
      "      vf_explained_var: 0.5084529519081116\n",
      "      vf_loss: 1414.0147705078125\n",
      "    sample_time_ms: 41899.051\n",
      "    update_time_ms: 17.09\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.59728900297389\n",
      "  time_since_restore: 9812.19146156311\n",
      "  time_this_iter_s: 41.44294881820679\n",
      "  time_total_s: 9812.19146156311\n",
      "  timestamp: 1554818118\n",
      "  timesteps_since_restore: 3660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3660000\n",
      "  training_iteration: 366\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9812 s, 366 iter, 3660000 ts, -87.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-56-00\n",
      "  done: false\n",
      "  episode_len_mean: 81.52032520325203\n",
      "  episode_reward_max: 4.249348469209041\n",
      "  episode_reward_mean: -102.26906701854321\n",
      "  episode_reward_min: -200.0493813244699\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 39379\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8572.794\n",
      "    load_time_ms: 2.464\n",
      "    num_steps_sampled: 3670000\n",
      "    num_steps_trained: 3670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1977611780166626\n",
      "      kl: 0.036687254905700684\n",
      "      policy_loss: 0.015345116145908833\n",
      "      total_loss: 1324.2615966796875\n",
      "      vf_explained_var: 0.5554075837135315\n",
      "      vf_loss: 1324.2462158203125\n",
      "    sample_time_ms: 41863.36\n",
      "    update_time_ms: 15.991\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.13453350927161\n",
      "  time_since_restore: 9854.455851078033\n",
      "  time_this_iter_s: 42.264389514923096\n",
      "  time_total_s: 9854.455851078033\n",
      "  timestamp: 1554818160\n",
      "  timesteps_since_restore: 3670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3670000\n",
      "  training_iteration: 367\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9854 s, 367 iter, 3670000 ts, -102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-56-53\n",
      "  done: false\n",
      "  episode_len_mean: 89.54054054054055\n",
      "  episode_reward_max: 5.82015182707212\n",
      "  episode_reward_mean: -81.04665109080878\n",
      "  episode_reward_min: -200.06595023376912\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 39490\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8767.029\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 3680000\n",
      "    num_steps_trained: 3680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.174912929534912\n",
      "      kl: 0.028178909793496132\n",
      "      policy_loss: 0.011755353771150112\n",
      "      total_loss: 1435.369384765625\n",
      "      vf_explained_var: 0.5002431869506836\n",
      "      vf_loss: 1435.3575439453125\n",
      "    sample_time_ms: 42191.89\n",
      "    update_time_ms: 16.43\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.52332554540439\n",
      "  time_since_restore: 9907.643731594086\n",
      "  time_this_iter_s: 53.187880516052246\n",
      "  time_total_s: 9907.643731594086\n",
      "  timestamp: 1554818213\n",
      "  timesteps_since_restore: 3680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3680000\n",
      "  training_iteration: 368\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9907 s, 368 iter, 3680000 ts, -81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-57-42\n",
      "  done: false\n",
      "  episode_len_mean: 85.62711864406779\n",
      "  episode_reward_max: 5.263565030210431\n",
      "  episode_reward_mean: -91.42925306900544\n",
      "  episode_reward_min: -200.07828012136503\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 39608\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8944.393\n",
      "    load_time_ms: 2.498\n",
      "    num_steps_sampled: 3690000\n",
      "    num_steps_trained: 3690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1912927627563477\n",
      "      kl: 0.028426023200154305\n",
      "      policy_loss: 0.009181118570268154\n",
      "      total_loss: 1447.8428955078125\n",
      "      vf_explained_var: 0.48414984345436096\n",
      "      vf_loss: 1447.8338623046875\n",
      "    sample_time_ms: 42941.955\n",
      "    update_time_ms: 16.47\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.71462653450271\n",
      "  time_since_restore: 9956.021721839905\n",
      "  time_this_iter_s: 48.37799024581909\n",
      "  time_total_s: 9956.021721839905\n",
      "  timestamp: 1554818262\n",
      "  timesteps_since_restore: 3690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3690000\n",
      "  training_iteration: 369\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 9956 s, 369 iter, 3690000 ts, -91.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-58-40\n",
      "  done: false\n",
      "  episode_len_mean: 87.51754385964912\n",
      "  episode_reward_max: 5.664401632400622\n",
      "  episode_reward_mean: -83.99497263466867\n",
      "  episode_reward_min: -200.03793364689238\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 39722\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 9348.534\n",
      "    load_time_ms: 2.443\n",
      "    num_steps_sampled: 3700000\n",
      "    num_steps_trained: 3700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.1947122812271118\n",
      "      kl: 0.032881975173950195\n",
      "      policy_loss: 0.01105224434286356\n",
      "      total_loss: 1424.0428466796875\n",
      "      vf_explained_var: 0.48511621356010437\n",
      "      vf_loss: 1424.03173828125\n",
      "    sample_time_ms: 44094.607\n",
      "    update_time_ms: 16.036\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.997486317334335\n",
      "  time_since_restore: 10013.838350772858\n",
      "  time_this_iter_s: 57.81662893295288\n",
      "  time_total_s: 10013.838350772858\n",
      "  timestamp: 1554818320\n",
      "  timesteps_since_restore: 3700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3700000\n",
      "  training_iteration: 370\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10013 s, 370 iter, 3700000 ts, -84 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_15-59-21\n",
      "  done: false\n",
      "  episode_len_mean: 78.53174603174604\n",
      "  episode_reward_max: 4.196897016201039\n",
      "  episode_reward_mean: -111.3940313362476\n",
      "  episode_reward_min: -200.05100378696653\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 39848\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8555.734\n",
      "    load_time_ms: 2.189\n",
      "    num_steps_sampled: 3710000\n",
      "    num_steps_trained: 3710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.213162899017334\n",
      "      kl: 0.03252179175615311\n",
      "      policy_loss: 0.011623426340520382\n",
      "      total_loss: 1163.1956787109375\n",
      "      vf_explained_var: 0.604951024055481\n",
      "      vf_loss: 1163.18408203125\n",
      "    sample_time_ms: 42124.044\n",
      "    update_time_ms: 15.978\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -55.69701566812378\n",
      "  time_since_restore: 10055.027505874634\n",
      "  time_this_iter_s: 41.18915510177612\n",
      "  time_total_s: 10055.027505874634\n",
      "  timestamp: 1554818361\n",
      "  timesteps_since_restore: 3710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3710000\n",
      "  training_iteration: 371\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10055 s, 371 iter, 3710000 ts, -111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-00-06\n",
      "  done: false\n",
      "  episode_len_mean: 87.71304347826087\n",
      "  episode_reward_max: 5.5670283263425535\n",
      "  episode_reward_mean: -85.55680134023419\n",
      "  episode_reward_min: -200.06586433987871\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 39963\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8486.082\n",
      "    load_time_ms: 2.027\n",
      "    num_steps_sampled: 3720000\n",
      "    num_steps_trained: 3720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.207865834236145\n",
      "      kl: 0.037905752658843994\n",
      "      policy_loss: 0.012837336398661137\n",
      "      total_loss: 1367.076904296875\n",
      "      vf_explained_var: 0.5051485896110535\n",
      "      vf_loss: 1367.0638427734375\n",
      "    sample_time_ms: 40705.053\n",
      "    update_time_ms: 14.313\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.7784006701171\n",
      "  time_since_restore: 10100.0081179142\n",
      "  time_this_iter_s: 44.98061203956604\n",
      "  time_total_s: 10100.0081179142\n",
      "  timestamp: 1554818406\n",
      "  timesteps_since_restore: 3720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3720000\n",
      "  training_iteration: 372\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10100 s, 372 iter, 3720000 ts, -85.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-00-52\n",
      "  done: false\n",
      "  episode_len_mean: 80.08\n",
      "  episode_reward_max: 5.761673018837133\n",
      "  episode_reward_mean: -106.89489868848354\n",
      "  episode_reward_min: -200.05367830493174\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 40088\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7685.922\n",
      "    load_time_ms: 1.987\n",
      "    num_steps_sampled: 3730000\n",
      "    num_steps_trained: 3730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.23721444606781\n",
      "      kl: 0.05461877956986427\n",
      "      policy_loss: 0.016065843403339386\n",
      "      total_loss: 1314.9544677734375\n",
      "      vf_explained_var: 0.5539263486862183\n",
      "      vf_loss: 1314.9384765625\n",
      "    sample_time_ms: 38963.295\n",
      "    update_time_ms: 14.146\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -53.44744934424176\n",
      "  time_since_restore: 10146.182988405228\n",
      "  time_this_iter_s: 46.17487049102783\n",
      "  time_total_s: 10146.182988405228\n",
      "  timestamp: 1554818452\n",
      "  timesteps_since_restore: 3730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3730000\n",
      "  training_iteration: 373\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10146 s, 373 iter, 3730000 ts, -107 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-01-43\n",
      "  done: false\n",
      "  episode_len_mean: 88.25892857142857\n",
      "  episode_reward_max: 5.451908828844262\n",
      "  episode_reward_mean: -83.75958055080352\n",
      "  episode_reward_min: -200.05118191121028\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 40200\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7867.745\n",
      "    load_time_ms: 2.134\n",
      "    num_steps_sampled: 3740000\n",
      "    num_steps_trained: 3740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2174957990646362\n",
      "      kl: 0.030953193083405495\n",
      "      policy_loss: 0.012067162431776524\n",
      "      total_loss: 1427.5390625\n",
      "      vf_explained_var: 0.49235814809799194\n",
      "      vf_loss: 1427.52685546875\n",
      "    sample_time_ms: 38431.586\n",
      "    update_time_ms: 10.53\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.879790275401774\n",
      "  time_since_restore: 10196.858406305313\n",
      "  time_this_iter_s: 50.67541790008545\n",
      "  time_total_s: 10196.858406305313\n",
      "  timestamp: 1554818503\n",
      "  timesteps_since_restore: 3740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3740000\n",
      "  training_iteration: 374\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10196 s, 374 iter, 3740000 ts, -83.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-02-28\n",
      "  done: false\n",
      "  episode_len_mean: 94.20560747663552\n",
      "  episode_reward_max: 5.7545865000486565\n",
      "  episode_reward_mean: -69.35974281583015\n",
      "  episode_reward_min: -200.0517644461624\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 40307\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8054.397\n",
      "    load_time_ms: 2.13\n",
      "    num_steps_sampled: 3750000\n",
      "    num_steps_trained: 3750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.216723918914795\n",
      "      kl: 0.03687399625778198\n",
      "      policy_loss: 0.015750428661704063\n",
      "      total_loss: 1391.872314453125\n",
      "      vf_explained_var: 0.45396217703819275\n",
      "      vf_loss: 1391.8565673828125\n",
      "    sample_time_ms: 38992.444\n",
      "    update_time_ms: 11.305\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.67987140791507\n",
      "  time_since_restore: 10241.672335863113\n",
      "  time_this_iter_s: 44.81392955780029\n",
      "  time_total_s: 10241.672335863113\n",
      "  timestamp: 1554818548\n",
      "  timesteps_since_restore: 3750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3750000\n",
      "  training_iteration: 375\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10241 s, 375 iter, 3750000 ts, -69.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-03-12\n",
      "  done: false\n",
      "  episode_len_mean: 82.02459016393442\n",
      "  episode_reward_max: 5.910728596082302\n",
      "  episode_reward_mean: -101.22950044911524\n",
      "  episode_reward_min: -200.08372986232874\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 40429\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8183.753\n",
      "    load_time_ms: 2.19\n",
      "    num_steps_sampled: 3760000\n",
      "    num_steps_trained: 3760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2453711032867432\n",
      "      kl: 0.03178589791059494\n",
      "      policy_loss: 0.010976443067193031\n",
      "      total_loss: 1204.5921630859375\n",
      "      vf_explained_var: 0.5810434818267822\n",
      "      vf_loss: 1204.5811767578125\n",
      "    sample_time_ms: 39137.547\n",
      "    update_time_ms: 11.311\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.614750224557625\n",
      "  time_since_restore: 10285.857763528824\n",
      "  time_this_iter_s: 44.18542766571045\n",
      "  time_total_s: 10285.857763528824\n",
      "  timestamp: 1554818592\n",
      "  timesteps_since_restore: 3760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3760000\n",
      "  training_iteration: 376\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10285 s, 376 iter, 3760000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-03-43\n",
      "  done: false\n",
      "  episode_len_mean: 80.91935483870968\n",
      "  episode_reward_max: 5.1995002961327135\n",
      "  episode_reward_mean: -103.30423131056365\n",
      "  episode_reward_min: -200.05515600238104\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 40553\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 8008.891\n",
      "    load_time_ms: 2.191\n",
      "    num_steps_sampled: 3770000\n",
      "    num_steps_trained: 3770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2545636892318726\n",
      "      kl: 0.03053733892738819\n",
      "      policy_loss: 0.014299402013421059\n",
      "      total_loss: 1246.812744140625\n",
      "      vf_explained_var: 0.5800439119338989\n",
      "      vf_loss: 1246.79833984375\n",
      "    sample_time_ms: 38181.657\n",
      "    update_time_ms: 11.378\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.652115655281825\n",
      "  time_since_restore: 10316.798619031906\n",
      "  time_this_iter_s: 30.940855503082275\n",
      "  time_total_s: 10316.798619031906\n",
      "  timestamp: 1554818623\n",
      "  timesteps_since_restore: 3770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3770000\n",
      "  training_iteration: 377\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10316 s, 377 iter, 3770000 ts, -103 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-04-13\n",
      "  done: false\n",
      "  episode_len_mean: 85.86206896551724\n",
      "  episode_reward_max: 5.699279146455909\n",
      "  episode_reward_mean: -91.58315766584579\n",
      "  episode_reward_min: -200.0639734169481\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 40669\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7664.644\n",
      "    load_time_ms: 2.226\n",
      "    num_steps_sampled: 3780000\n",
      "    num_steps_trained: 3780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2423111200332642\n",
      "      kl: 0.044151462614536285\n",
      "      policy_loss: 0.016428323462605476\n",
      "      total_loss: 1350.884033203125\n",
      "      vf_explained_var: 0.5274772047996521\n",
      "      vf_loss: 1350.8675537109375\n",
      "    sample_time_ms: 36206.49\n",
      "    update_time_ms: 10.226\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.791578832922916\n",
      "  time_since_restore: 10346.761385202408\n",
      "  time_this_iter_s: 29.96276617050171\n",
      "  time_total_s: 10346.761385202408\n",
      "  timestamp: 1554818653\n",
      "  timesteps_since_restore: 3780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3780000\n",
      "  training_iteration: 378\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10346 s, 378 iter, 3780000 ts, -91.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-04-43\n",
      "  done: false\n",
      "  episode_len_mean: 87.82456140350877\n",
      "  episode_reward_max: 5.596129617015099\n",
      "  episode_reward_mean: -84.13424135271671\n",
      "  episode_reward_min: -200.05936481280253\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 40783\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7421.12\n",
      "    load_time_ms: 2.097\n",
      "    num_steps_sampled: 3790000\n",
      "    num_steps_trained: 3790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2318472862243652\n",
      "      kl: 0.02362169697880745\n",
      "      policy_loss: 0.00763335358351469\n",
      "      total_loss: 1378.8232421875\n",
      "      vf_explained_var: 0.5121785402297974\n",
      "      vf_loss: 1378.8155517578125\n",
      "    sample_time_ms: 34602.485\n",
      "    update_time_ms: 10.334\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.06712067635834\n",
      "  time_since_restore: 10376.655564308167\n",
      "  time_this_iter_s: 29.894179105758667\n",
      "  time_total_s: 10376.655564308167\n",
      "  timestamp: 1554818683\n",
      "  timesteps_since_restore: 3790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3790000\n",
      "  training_iteration: 379\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10376 s, 379 iter, 3790000 ts, -84.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-05-13\n",
      "  done: false\n",
      "  episode_len_mean: 84.94017094017094\n",
      "  episode_reward_max: 5.766551867741522\n",
      "  episode_reward_mean: -92.2973592211135\n",
      "  episode_reward_min: -200.0487051193638\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 40900\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6822.038\n",
      "    load_time_ms: 2.105\n",
      "    num_steps_sampled: 3800000\n",
      "    num_steps_trained: 3800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2456181049346924\n",
      "      kl: 0.033405520021915436\n",
      "      policy_loss: 0.010547534562647343\n",
      "      total_loss: 1367.5443115234375\n",
      "      vf_explained_var: 0.519004225730896\n",
      "      vf_loss: 1367.5338134765625\n",
      "    sample_time_ms: 32410.738\n",
      "    update_time_ms: 10.338\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.148679610556755\n",
      "  time_since_restore: 10406.56123828888\n",
      "  time_this_iter_s: 29.90567398071289\n",
      "  time_total_s: 10406.56123828888\n",
      "  timestamp: 1554818713\n",
      "  timesteps_since_restore: 3800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3800000\n",
      "  training_iteration: 380\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10406 s, 380 iter, 3800000 ts, -92.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-05-44\n",
      "  done: false\n",
      "  episode_len_mean: 93.12962962962963\n",
      "  episode_reward_max: 5.614894388600374\n",
      "  episode_reward_mean: -70.76622884270968\n",
      "  episode_reward_min: -200.0616612077156\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 41008\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6760.124\n",
      "    load_time_ms: 2.018\n",
      "    num_steps_sampled: 3810000\n",
      "    num_steps_trained: 3810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2362045049667358\n",
      "      kl: 0.030025392770767212\n",
      "      policy_loss: 0.013530047610402107\n",
      "      total_loss: 1478.4310302734375\n",
      "      vf_explained_var: 0.449332594871521\n",
      "      vf_loss: 1478.4176025390625\n",
      "    sample_time_ms: 31429.638\n",
      "    update_time_ms: 10.069\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.38311442135484\n",
      "  time_since_restore: 10437.31542301178\n",
      "  time_this_iter_s: 30.75418472290039\n",
      "  time_total_s: 10437.31542301178\n",
      "  timestamp: 1554818744\n",
      "  timesteps_since_restore: 3810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3810000\n",
      "  training_iteration: 381\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10437 s, 381 iter, 3810000 ts, -70.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-06-14\n",
      "  done: false\n",
      "  episode_len_mean: 82.22131147540983\n",
      "  episode_reward_max: 5.571652358708133\n",
      "  episode_reward_mean: -101.886181525164\n",
      "  episode_reward_min: -200.08736179530518\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 41130\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6447.237\n",
      "    load_time_ms: 1.92\n",
      "    num_steps_sampled: 3820000\n",
      "    num_steps_trained: 3820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2571719884872437\n",
      "      kl: 0.03841773048043251\n",
      "      policy_loss: 0.011751338839530945\n",
      "      total_loss: 1364.913818359375\n",
      "      vf_explained_var: 0.5442225337028503\n",
      "      vf_loss: 1364.9022216796875\n",
      "    sample_time_ms: 30285.893\n",
      "    update_time_ms: 9.834\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.943090762582\n",
      "  time_since_restore: 10467.714755296707\n",
      "  time_this_iter_s: 30.399332284927368\n",
      "  time_total_s: 10467.714755296707\n",
      "  timestamp: 1554818774\n",
      "  timesteps_since_restore: 3820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3820000\n",
      "  training_iteration: 382\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10467 s, 382 iter, 3820000 ts, -102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-06-45\n",
      "  done: false\n",
      "  episode_len_mean: 85.3931623931624\n",
      "  episode_reward_max: 5.59514605769529\n",
      "  episode_reward_mean: -92.37964593567948\n",
      "  episode_reward_min: -200.04450069998532\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 41247\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6034.754\n",
      "    load_time_ms: 1.832\n",
      "    num_steps_sampled: 3830000\n",
      "    num_steps_trained: 3830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.249841332435608\n",
      "      kl: 0.03822806477546692\n",
      "      policy_loss: 0.015049634501338005\n",
      "      total_loss: 1400.41748046875\n",
      "      vf_explained_var: 0.5090643167495728\n",
      "      vf_loss: 1400.4024658203125\n",
      "    sample_time_ms: 29131.341\n",
      "    update_time_ms: 9.091\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.18982296783973\n",
      "  time_since_restore: 10498.199777841568\n",
      "  time_this_iter_s: 30.48502254486084\n",
      "  time_total_s: 10498.199777841568\n",
      "  timestamp: 1554818805\n",
      "  timesteps_since_restore: 3830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3830000\n",
      "  training_iteration: 383\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10498 s, 383 iter, 3830000 ts, -92.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-07-15\n",
      "  done: false\n",
      "  episode_len_mean: 85.4957264957265\n",
      "  episode_reward_max: 5.774752534225252\n",
      "  episode_reward_mean: -90.75509664909143\n",
      "  episode_reward_min: -200.07544663929735\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 41364\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5773.156\n",
      "    load_time_ms: 1.706\n",
      "    num_steps_sampled: 3840000\n",
      "    num_steps_trained: 3840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2442415952682495\n",
      "      kl: 0.04159083962440491\n",
      "      policy_loss: 0.02047647535800934\n",
      "      total_loss: 1409.7171630859375\n",
      "      vf_explained_var: 0.5242996215820312\n",
      "      vf_loss: 1409.6966552734375\n",
      "    sample_time_ms: 27327.211\n",
      "    update_time_ms: 8.482\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.377548324545714\n",
      "  time_since_restore: 10528.198328256607\n",
      "  time_this_iter_s: 29.998550415039062\n",
      "  time_total_s: 10528.198328256607\n",
      "  timestamp: 1554818835\n",
      "  timesteps_since_restore: 3840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3840000\n",
      "  training_iteration: 384\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10528 s, 384 iter, 3840000 ts, -90.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-07-45\n",
      "  done: false\n",
      "  episode_len_mean: 86.86842105263158\n",
      "  episode_reward_max: 5.744062986279735\n",
      "  episode_reward_mean: -89.59361151967644\n",
      "  episode_reward_min: -200.071823647338\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 41478\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5532.238\n",
      "    load_time_ms: 1.707\n",
      "    num_steps_sampled: 3850000\n",
      "    num_steps_trained: 3850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2560030221939087\n",
      "      kl: 0.0367167592048645\n",
      "      policy_loss: 0.010527282953262329\n",
      "      total_loss: 1382.265625\n",
      "      vf_explained_var: 0.5059289932250977\n",
      "      vf_loss: 1382.2550048828125\n",
      "    sample_time_ms: 26119.717\n",
      "    update_time_ms: 7.661\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.79680575983822\n",
      "  time_since_restore: 10558.513575077057\n",
      "  time_this_iter_s: 30.31524682044983\n",
      "  time_total_s: 10558.513575077057\n",
      "  timestamp: 1554818865\n",
      "  timesteps_since_restore: 3850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3850000\n",
      "  training_iteration: 385\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10558 s, 385 iter, 3850000 ts, -89.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-08-16\n",
      "  done: false\n",
      "  episode_len_mean: 81.7560975609756\n",
      "  episode_reward_max: 5.850900952110802\n",
      "  episode_reward_mean: -100.79777598691867\n",
      "  episode_reward_min: -200.05318186170066\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 41601\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5329.742\n",
      "    load_time_ms: 1.682\n",
      "    num_steps_sampled: 3860000\n",
      "    num_steps_trained: 3860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2708104848861694\n",
      "      kl: 0.03684542328119278\n",
      "      policy_loss: 0.01764741912484169\n",
      "      total_loss: 1334.9449462890625\n",
      "      vf_explained_var: 0.5526317954063416\n",
      "      vf_loss: 1334.9271240234375\n",
      "    sample_time_ms: 24964.28\n",
      "    update_time_ms: 7.191\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.39888799345933\n",
      "  time_since_restore: 10589.11403298378\n",
      "  time_this_iter_s: 30.600457906723022\n",
      "  time_total_s: 10589.11403298378\n",
      "  timestamp: 1554818896\n",
      "  timesteps_since_restore: 3860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3860000\n",
      "  training_iteration: 386\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10589 s, 386 iter, 3860000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-08-46\n",
      "  done: false\n",
      "  episode_len_mean: 87.48695652173913\n",
      "  episode_reward_max: 5.072537538032615\n",
      "  episode_reward_mean: -85.03531436224824\n",
      "  episode_reward_min: -200.05981873289284\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 41716\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5328.148\n",
      "    load_time_ms: 1.682\n",
      "    num_steps_sampled: 3870000\n",
      "    num_steps_trained: 3870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2701555490493774\n",
      "      kl: 0.04252910986542702\n",
      "      policy_loss: 0.012045457027852535\n",
      "      total_loss: 1424.316162109375\n",
      "      vf_explained_var: 0.4657640755176544\n",
      "      vf_loss: 1424.3038330078125\n",
      "    sample_time_ms: 24921.458\n",
      "    update_time_ms: 7.611\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.51765718112412\n",
      "  time_since_restore: 10619.612602949142\n",
      "  time_this_iter_s: 30.49856996536255\n",
      "  time_total_s: 10619.612602949142\n",
      "  timestamp: 1554818926\n",
      "  timesteps_since_restore: 3870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3870000\n",
      "  training_iteration: 387\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10619 s, 387 iter, 3870000 ts, -85 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-09-17\n",
      "  done: false\n",
      "  episode_len_mean: 82.17355371900827\n",
      "  episode_reward_max: 5.808199087689205\n",
      "  episode_reward_mean: -100.85546983999521\n",
      "  episode_reward_min: -200.05461052144\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 41837\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5330.657\n",
      "    load_time_ms: 1.641\n",
      "    num_steps_sampled: 3880000\n",
      "    num_steps_trained: 3880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2868114709854126\n",
      "      kl: 0.04224276542663574\n",
      "      policy_loss: 0.01500003319233656\n",
      "      total_loss: 1278.6871337890625\n",
      "      vf_explained_var: 0.5455659031867981\n",
      "      vf_loss: 1278.671875\n",
      "    sample_time_ms: 24938.626\n",
      "    update_time_ms: 7.77\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.4277349199976\n",
      "  time_since_restore: 10649.770319461823\n",
      "  time_this_iter_s: 30.157716512680054\n",
      "  time_total_s: 10649.770319461823\n",
      "  timestamp: 1554818957\n",
      "  timesteps_since_restore: 3880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3880000\n",
      "  training_iteration: 388\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10649 s, 388 iter, 3880000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-09-47\n",
      "  done: false\n",
      "  episode_len_mean: 91.03636363636363\n",
      "  episode_reward_max: 5.354030000865174\n",
      "  episode_reward_mean: -76.62383946314144\n",
      "  episode_reward_min: -200.0784920531552\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 41947\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5327.472\n",
      "    load_time_ms: 1.623\n",
      "    num_steps_sampled: 3890000\n",
      "    num_steps_trained: 3890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.264251947402954\n",
      "      kl: 0.03558367118239403\n",
      "      policy_loss: 0.013618679717183113\n",
      "      total_loss: 1501.4154052734375\n",
      "      vf_explained_var: 0.43241316080093384\n",
      "      vf_loss: 1501.40185546875\n",
      "    sample_time_ms: 24966.422\n",
      "    update_time_ms: 7.498\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.31191973157072\n",
      "  time_since_restore: 10679.912400960922\n",
      "  time_this_iter_s: 30.14208149909973\n",
      "  time_total_s: 10679.912400960922\n",
      "  timestamp: 1554818987\n",
      "  timesteps_since_restore: 3890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3890000\n",
      "  training_iteration: 389\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10679 s, 389 iter, 3890000 ts, -76.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-10-17\n",
      "  done: false\n",
      "  episode_len_mean: 90.16216216216216\n",
      "  episode_reward_max: 6.047999415255408\n",
      "  episode_reward_mean: -77.27770916721077\n",
      "  episode_reward_min: -200.0326268920434\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 42058\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5302.642\n",
      "    load_time_ms: 1.582\n",
      "    num_steps_sampled: 3900000\n",
      "    num_steps_trained: 3900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2645961046218872\n",
      "      kl: 0.0347447469830513\n",
      "      policy_loss: 0.010871753096580505\n",
      "      total_loss: 1434.441650390625\n",
      "      vf_explained_var: 0.4520564377307892\n",
      "      vf_loss: 1434.4306640625\n",
      "    sample_time_ms: 25016.715\n",
      "    update_time_ms: 7.362\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.63885458360541\n",
      "  time_since_restore: 10710.068201065063\n",
      "  time_this_iter_s: 30.155800104141235\n",
      "  time_total_s: 10710.068201065063\n",
      "  timestamp: 1554819017\n",
      "  timesteps_since_restore: 3900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3900000\n",
      "  training_iteration: 390\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10710 s, 390 iter, 3900000 ts, -77.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-10-47\n",
      "  done: false\n",
      "  episode_len_mean: 84.5126050420168\n",
      "  episode_reward_max: 5.306416007004508\n",
      "  episode_reward_mean: -93.96338173979737\n",
      "  episode_reward_min: -200.060898208403\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 42177\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5291.032\n",
      "    load_time_ms: 1.584\n",
      "    num_steps_sampled: 3910000\n",
      "    num_steps_trained: 3910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2756767272949219\n",
      "      kl: 0.03190496191382408\n",
      "      policy_loss: 0.014444749802350998\n",
      "      total_loss: 1269.225830078125\n",
      "      vf_explained_var: 0.5591882467269897\n",
      "      vf_loss: 1269.21142578125\n",
      "    sample_time_ms: 24956.268\n",
      "    update_time_ms: 7.178\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.98169086989868\n",
      "  time_since_restore: 10740.097685813904\n",
      "  time_this_iter_s: 30.029484748840332\n",
      "  time_total_s: 10740.097685813904\n",
      "  timestamp: 1554819047\n",
      "  timesteps_since_restore: 3910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3910000\n",
      "  training_iteration: 391\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10740 s, 391 iter, 3910000 ts, -94 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-11-18\n",
      "  done: false\n",
      "  episode_len_mean: 89.9090909090909\n",
      "  episode_reward_max: 5.857841997246565\n",
      "  episode_reward_mean: -79.8265671146789\n",
      "  episode_reward_min: -200.03930959739782\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 42287\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5312.36\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 3920000\n",
      "    num_steps_trained: 3920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2777926921844482\n",
      "      kl: 0.04732618108391762\n",
      "      policy_loss: 0.0214622151106596\n",
      "      total_loss: 1438.2333984375\n",
      "      vf_explained_var: 0.4786844849586487\n",
      "      vf_loss: 1438.2117919921875\n",
      "    sample_time_ms: 24935.72\n",
      "    update_time_ms: 7.239\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.91328355733944\n",
      "  time_since_restore: 10770.506804704666\n",
      "  time_this_iter_s: 30.40911889076233\n",
      "  time_total_s: 10770.506804704666\n",
      "  timestamp: 1554819078\n",
      "  timesteps_since_restore: 3920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3920000\n",
      "  training_iteration: 392\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10770 s, 392 iter, 3920000 ts, -79.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-11-48\n",
      "  done: false\n",
      "  episode_len_mean: 88.49122807017544\n",
      "  episode_reward_max: 5.813750869225986\n",
      "  episode_reward_mean: -84.41990951384854\n",
      "  episode_reward_min: -200.05987307170307\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 42401\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5289.233\n",
      "    load_time_ms: 1.6\n",
      "    num_steps_sampled: 3930000\n",
      "    num_steps_trained: 3930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2749065160751343\n",
      "      kl: 0.0597107820212841\n",
      "      policy_loss: 0.0259990356862545\n",
      "      total_loss: 1380.94189453125\n",
      "      vf_explained_var: 0.49978578090667725\n",
      "      vf_loss: 1380.9158935546875\n",
      "    sample_time_ms: 24946.089\n",
      "    update_time_ms: 7.228\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.209954756924276\n",
      "  time_since_restore: 10800.864953994751\n",
      "  time_this_iter_s: 30.35814929008484\n",
      "  time_total_s: 10800.864953994751\n",
      "  timestamp: 1554819108\n",
      "  timesteps_since_restore: 3930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3930000\n",
      "  training_iteration: 393\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10800 s, 393 iter, 3930000 ts, -84.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-12-18\n",
      "  done: false\n",
      "  episode_len_mean: 87.00884955752213\n",
      "  episode_reward_max: 5.87296997353304\n",
      "  episode_reward_mean: -86.65480391102295\n",
      "  episode_reward_min: -200.03059847385111\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 42514\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5296.08\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 3940000\n",
      "    num_steps_trained: 3940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2789007425308228\n",
      "      kl: 0.041503727436065674\n",
      "      policy_loss: 0.014973631128668785\n",
      "      total_loss: 1407.1978759765625\n",
      "      vf_explained_var: 0.4950787425041199\n",
      "      vf_loss: 1407.182861328125\n",
      "    sample_time_ms: 24927.99\n",
      "    update_time_ms: 7.008\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.327401955511476\n",
      "  time_since_restore: 10830.748237133026\n",
      "  time_this_iter_s: 29.883283138275146\n",
      "  time_total_s: 10830.748237133026\n",
      "  timestamp: 1554819138\n",
      "  timesteps_since_restore: 3940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3940000\n",
      "  training_iteration: 394\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10830 s, 394 iter, 3940000 ts, -86.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-12-48\n",
      "  done: false\n",
      "  episode_len_mean: 92.18348623853211\n",
      "  episode_reward_max: 4.974739074713126\n",
      "  episode_reward_mean: -73.52079991081204\n",
      "  episode_reward_min: -200.04064617104325\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 42623\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5292.995\n",
      "    load_time_ms: 1.55\n",
      "    num_steps_sampled: 3950000\n",
      "    num_steps_trained: 3950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.288061261177063\n",
      "      kl: 0.03317777439951897\n",
      "      policy_loss: 0.010462437756359577\n",
      "      total_loss: 1384.281494140625\n",
      "      vf_explained_var: 0.4793446958065033\n",
      "      vf_loss: 1384.2711181640625\n",
      "    sample_time_ms: 24894.843\n",
      "    update_time_ms: 7.134\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.760399955406015\n",
      "  time_since_restore: 10860.700788497925\n",
      "  time_this_iter_s: 29.95255136489868\n",
      "  time_total_s: 10860.700788497925\n",
      "  timestamp: 1554819168\n",
      "  timesteps_since_restore: 3950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3950000\n",
      "  training_iteration: 395\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10860 s, 395 iter, 3950000 ts, -73.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-13-18\n",
      "  done: false\n",
      "  episode_len_mean: 85.96581196581197\n",
      "  episode_reward_max: 5.764676431299325\n",
      "  episode_reward_mean: -90.79608259629296\n",
      "  episode_reward_min: -200.0673134103523\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 42740\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5314.675\n",
      "    load_time_ms: 1.488\n",
      "    num_steps_sampled: 3960000\n",
      "    num_steps_trained: 3960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2762295007705688\n",
      "      kl: 71.69512176513672\n",
      "      policy_loss: 0.20889639854431152\n",
      "      total_loss: 1375.7203369140625\n",
      "      vf_explained_var: 0.5243789553642273\n",
      "      vf_loss: 1375.511474609375\n",
      "    sample_time_ms: 24860.61\n",
      "    update_time_ms: 7.277\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.398041298146495\n",
      "  time_since_restore: 10891.17295885086\n",
      "  time_this_iter_s: 30.47217035293579\n",
      "  time_total_s: 10891.17295885086\n",
      "  timestamp: 1554819198\n",
      "  timesteps_since_restore: 3960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3960000\n",
      "  training_iteration: 396\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10891 s, 396 iter, 3960000 ts, -90.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-13-48\n",
      "  done: false\n",
      "  episode_len_mean: 89.03571428571429\n",
      "  episode_reward_max: 8.729135291366285\n",
      "  episode_reward_mean: -84.2120415558771\n",
      "  episode_reward_min: -200.07409614729\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 42852\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5304.393\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 3970000\n",
      "    num_steps_trained: 3970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2815641164779663\n",
      "      kl: 0.03621947020292282\n",
      "      policy_loss: 0.01308648381382227\n",
      "      total_loss: 1405.4371337890625\n",
      "      vf_explained_var: 0.5051189661026001\n",
      "      vf_loss: 1405.423828125\n",
      "    sample_time_ms: 24825.722\n",
      "    update_time_ms: 6.9\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.10602077793855\n",
      "  time_since_restore: 10921.221783876419\n",
      "  time_this_iter_s: 30.04882502555847\n",
      "  time_total_s: 10921.221783876419\n",
      "  timestamp: 1554819228\n",
      "  timesteps_since_restore: 3970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3970000\n",
      "  training_iteration: 397\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10921 s, 397 iter, 3970000 ts, -84.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-14-18\n",
      "  done: false\n",
      "  episode_len_mean: 91.54545454545455\n",
      "  episode_reward_max: 5.816248373759805\n",
      "  episode_reward_mean: -76.62366377913693\n",
      "  episode_reward_min: -200.03212522551144\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 42962\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5288.516\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 3980000\n",
      "    num_steps_trained: 3980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2600858211517334\n",
      "      kl: 0.043401431292295456\n",
      "      policy_loss: 0.018559809774160385\n",
      "      total_loss: 1405.21875\n",
      "      vf_explained_var: 0.5007287263870239\n",
      "      vf_loss: 1405.2003173828125\n",
      "    sample_time_ms: 24791.343\n",
      "    update_time_ms: 6.956\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.31183188956847\n",
      "  time_since_restore: 10950.880560159683\n",
      "  time_this_iter_s: 29.65877628326416\n",
      "  time_total_s: 10950.880560159683\n",
      "  timestamp: 1554819258\n",
      "  timesteps_since_restore: 3980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3980000\n",
      "  training_iteration: 398\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10950 s, 398 iter, 3980000 ts, -76.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-14-48\n",
      "  done: false\n",
      "  episode_len_mean: 88.78571428571429\n",
      "  episode_reward_max: 7.258660728050688\n",
      "  episode_reward_mean: -81.73973277851738\n",
      "  episode_reward_min: -200.04595008721705\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 43074\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5288.385\n",
      "    load_time_ms: 1.579\n",
      "    num_steps_sampled: 3990000\n",
      "    num_steps_trained: 3990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2712457180023193\n",
      "      kl: 0.036466218531131744\n",
      "      policy_loss: 0.017848476767539978\n",
      "      total_loss: 1388.4693603515625\n",
      "      vf_explained_var: 0.47895631194114685\n",
      "      vf_loss: 1388.4515380859375\n",
      "    sample_time_ms: 24755.138\n",
      "    update_time_ms: 7.124\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.86986638925868\n",
      "  time_since_restore: 10980.66001200676\n",
      "  time_this_iter_s: 29.779451847076416\n",
      "  time_total_s: 10980.66001200676\n",
      "  timestamp: 1554819288\n",
      "  timesteps_since_restore: 3990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3990000\n",
      "  training_iteration: 399\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 10980 s, 399 iter, 3990000 ts, -81.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-15-19\n",
      "  done: false\n",
      "  episode_len_mean: 80.0952380952381\n",
      "  episode_reward_max: 7.265883802854663\n",
      "  episode_reward_mean: -106.41994824244573\n",
      "  episode_reward_min: -200.11491109269102\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 43200\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5315.501\n",
      "    load_time_ms: 1.649\n",
      "    num_steps_sampled: 4000000\n",
      "    num_steps_trained: 4000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.303104281425476\n",
      "      kl: 0.03384554758667946\n",
      "      policy_loss: 0.013027955777943134\n",
      "      total_loss: 1317.9874267578125\n",
      "      vf_explained_var: 0.5493844747543335\n",
      "      vf_loss: 1317.974365234375\n",
      "    sample_time_ms: 24778.534\n",
      "    update_time_ms: 8.253\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -53.20997412122285\n",
      "  time_since_restore: 11011.331542491913\n",
      "  time_this_iter_s: 30.6715304851532\n",
      "  time_total_s: 11011.331542491913\n",
      "  timestamp: 1554819319\n",
      "  timesteps_since_restore: 4000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4000000\n",
      "  training_iteration: 400\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11011 s, 400 iter, 4000000 ts, -106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-15-49\n",
      "  done: false\n",
      "  episode_len_mean: 87.98230088495575\n",
      "  episode_reward_max: 10.315634305261469\n",
      "  episode_reward_mean: -84.85137591273451\n",
      "  episode_reward_min: -200.1324632604917\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 43313\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5303.207\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 4010000\n",
      "    num_steps_trained: 4010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2762551307678223\n",
      "      kl: 0.033954668790102005\n",
      "      policy_loss: 0.013298360630869865\n",
      "      total_loss: 1418.3814697265625\n",
      "      vf_explained_var: 0.4740851819515228\n",
      "      vf_loss: 1418.3681640625\n",
      "    sample_time_ms: 24846.167\n",
      "    update_time_ms: 8.081\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.425687956367256\n",
      "  time_since_restore: 11041.913624763489\n",
      "  time_this_iter_s: 30.582082271575928\n",
      "  time_total_s: 11041.913624763489\n",
      "  timestamp: 1554819349\n",
      "  timesteps_since_restore: 4010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4010000\n",
      "  training_iteration: 401\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11041 s, 401 iter, 4010000 ts, -84.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-16-19\n",
      "  done: false\n",
      "  episode_len_mean: 88.89380530973452\n",
      "  episode_reward_max: 7.610468793947118\n",
      "  episode_reward_mean: -83.15739943074743\n",
      "  episode_reward_min: -200.12292297614823\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 43426\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5280.308\n",
      "    load_time_ms: 1.617\n",
      "    num_steps_sampled: 4020000\n",
      "    num_steps_trained: 4020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.28105890750885\n",
      "      kl: 0.044131528586149216\n",
      "      policy_loss: 0.019367095082998276\n",
      "      total_loss: 1438.098388671875\n",
      "      vf_explained_var: 0.4792812168598175\n",
      "      vf_loss: 1438.0789794921875\n",
      "    sample_time_ms: 24801.0\n",
      "    update_time_ms: 8.221\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.57869971537372\n",
      "  time_since_restore: 11071.642917633057\n",
      "  time_this_iter_s: 29.72929286956787\n",
      "  time_total_s: 11071.642917633057\n",
      "  timestamp: 1554819379\n",
      "  timesteps_since_restore: 4020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4020000\n",
      "  training_iteration: 402\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11071 s, 402 iter, 4020000 ts, -83.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-16-49\n",
      "  done: false\n",
      "  episode_len_mean: 86.12931034482759\n",
      "  episode_reward_max: 10.957828355358433\n",
      "  episode_reward_mean: -89.14226075602072\n",
      "  episode_reward_min: -200.0744502910427\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 43542\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5308.415\n",
      "    load_time_ms: 1.599\n",
      "    num_steps_sampled: 4030000\n",
      "    num_steps_trained: 4030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.279882550239563\n",
      "      kl: 0.035361163318157196\n",
      "      policy_loss: 0.015417351387441158\n",
      "      total_loss: 1332.2235107421875\n",
      "      vf_explained_var: 0.5345927476882935\n",
      "      vf_loss: 1332.2081298828125\n",
      "    sample_time_ms: 24756.088\n",
      "    update_time_ms: 8.149\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.571130378010345\n",
      "  time_since_restore: 11101.832678318024\n",
      "  time_this_iter_s: 30.18976068496704\n",
      "  time_total_s: 11101.832678318024\n",
      "  timestamp: 1554819409\n",
      "  timesteps_since_restore: 4030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4030000\n",
      "  training_iteration: 403\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11101 s, 403 iter, 4030000 ts, -89.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-17-19\n",
      "  done: false\n",
      "  episode_len_mean: 85.74137931034483\n",
      "  episode_reward_max: 8.127167228759745\n",
      "  episode_reward_mean: -91.6234949604308\n",
      "  episode_reward_min: -200.12993015167723\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 43658\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5292.774\n",
      "    load_time_ms: 1.689\n",
      "    num_steps_sampled: 4040000\n",
      "    num_steps_trained: 4040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.282517671585083\n",
      "      kl: 0.03533605486154556\n",
      "      policy_loss: 0.01219874806702137\n",
      "      total_loss: 1403.099609375\n",
      "      vf_explained_var: 0.4905265271663666\n",
      "      vf_loss: 1403.0872802734375\n",
      "    sample_time_ms: 24774.786\n",
      "    update_time_ms: 8.015\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.8117474802154\n",
      "  time_since_restore: 11131.74285697937\n",
      "  time_this_iter_s: 29.910178661346436\n",
      "  time_total_s: 11131.74285697937\n",
      "  timestamp: 1554819439\n",
      "  timesteps_since_restore: 4040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4040000\n",
      "  training_iteration: 404\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11131 s, 404 iter, 4040000 ts, -91.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 84.05882352941177\n",
      "  episode_reward_max: 8.24102673761998\n",
      "  episode_reward_mean: -96.0317516305555\n",
      "  episode_reward_min: -200.16006871883326\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 43777\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5308.15\n",
      "    load_time_ms: 1.732\n",
      "    num_steps_sampled: 4050000\n",
      "    num_steps_trained: 4050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.29109525680542\n",
      "      kl: 0.03582537919282913\n",
      "      policy_loss: 0.013045461848378181\n",
      "      total_loss: 1370.3353271484375\n",
      "      vf_explained_var: 0.5252580642700195\n",
      "      vf_loss: 1370.322265625\n",
      "    sample_time_ms: 24816.509\n",
      "    update_time_ms: 8.127\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.015875815277745\n",
      "  time_since_restore: 11162.271089315414\n",
      "  time_this_iter_s: 30.52823233604431\n",
      "  time_total_s: 11162.271089315414\n",
      "  timestamp: 1554819470\n",
      "  timesteps_since_restore: 4050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4050000\n",
      "  training_iteration: 405\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11162 s, 405 iter, 4050000 ts, -96 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-18-20\n",
      "  done: false\n",
      "  episode_len_mean: 87.97345132743362\n",
      "  episode_reward_max: 9.225522998854306\n",
      "  episode_reward_mean: -86.69154136621638\n",
      "  episode_reward_min: -200.1120417043297\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 43890\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5295.504\n",
      "    load_time_ms: 1.739\n",
      "    num_steps_sampled: 4060000\n",
      "    num_steps_trained: 4060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2823368310928345\n",
      "      kl: 0.04394970461726189\n",
      "      policy_loss: 0.016868751496076584\n",
      "      total_loss: 1409.306884765625\n",
      "      vf_explained_var: 0.4857940673828125\n",
      "      vf_loss: 1409.2899169921875\n",
      "    sample_time_ms: 24794.836\n",
      "    update_time_ms: 8.339\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.34577068310819\n",
      "  time_since_restore: 11192.404757738113\n",
      "  time_this_iter_s: 30.133668422698975\n",
      "  time_total_s: 11192.404757738113\n",
      "  timestamp: 1554819500\n",
      "  timesteps_since_restore: 4060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4060000\n",
      "  training_iteration: 406\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11192 s, 406 iter, 4060000 ts, -86.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-18-50\n",
      "  done: false\n",
      "  episode_len_mean: 86.11965811965813\n",
      "  episode_reward_max: 10.858882279547675\n",
      "  episode_reward_mean: -90.72180863694092\n",
      "  episode_reward_min: -200.1115108437238\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 44007\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5289.894\n",
      "    load_time_ms: 1.762\n",
      "    num_steps_sampled: 4070000\n",
      "    num_steps_trained: 4070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2857155799865723\n",
      "      kl: 0.0287772286683321\n",
      "      policy_loss: 0.010479869320988655\n",
      "      total_loss: 1367.25927734375\n",
      "      vf_explained_var: 0.5011329650878906\n",
      "      vf_loss: 1367.248779296875\n",
      "    sample_time_ms: 24826.683\n",
      "    update_time_ms: 8.237\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.36090431847047\n",
      "  time_since_restore: 11222.714407205582\n",
      "  time_this_iter_s: 30.30964946746826\n",
      "  time_total_s: 11222.714407205582\n",
      "  timestamp: 1554819530\n",
      "  timesteps_since_restore: 4070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4070000\n",
      "  training_iteration: 407\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11222 s, 407 iter, 4070000 ts, -90.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-19-20\n",
      "  done: false\n",
      "  episode_len_mean: 91.54629629629629\n",
      "  episode_reward_max: 9.007035932303781\n",
      "  episode_reward_mean: -75.76877406037279\n",
      "  episode_reward_min: -200.0499964843857\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 44115\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5303.328\n",
      "    load_time_ms: 1.768\n",
      "    num_steps_sampled: 4080000\n",
      "    num_steps_trained: 4080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.283940076828003\n",
      "      kl: 0.039414264261722565\n",
      "      policy_loss: 0.015046494081616402\n",
      "      total_loss: 1483.36279296875\n",
      "      vf_explained_var: 0.45218443870544434\n",
      "      vf_loss: 1483.3475341796875\n",
      "    sample_time_ms: 24853.909\n",
      "    update_time_ms: 8.163\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.8843870301864\n",
      "  time_since_restore: 11252.777752637863\n",
      "  time_this_iter_s: 30.063345432281494\n",
      "  time_total_s: 11252.777752637863\n",
      "  timestamp: 1554819560\n",
      "  timesteps_since_restore: 4080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4080000\n",
      "  training_iteration: 408\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11252 s, 408 iter, 4080000 ts, -75.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-19-51\n",
      "  done: false\n",
      "  episode_len_mean: 89.57522123893806\n",
      "  episode_reward_max: 7.652755207767479\n",
      "  episode_reward_mean: -79.47962942150276\n",
      "  episode_reward_min: -200.04357936240064\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 44228\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5314.919\n",
      "    load_time_ms: 1.765\n",
      "    num_steps_sampled: 4090000\n",
      "    num_steps_trained: 4090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2808430194854736\n",
      "      kl: 0.03603516146540642\n",
      "      policy_loss: 0.015629781410098076\n",
      "      total_loss: 1417.8975830078125\n",
      "      vf_explained_var: 0.4688890278339386\n",
      "      vf_loss: 1417.8818359375\n",
      "    sample_time_ms: 24916.678\n",
      "    update_time_ms: 8.061\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.73981471075138\n",
      "  time_since_restore: 11283.300641536713\n",
      "  time_this_iter_s: 30.522888898849487\n",
      "  time_total_s: 11283.300641536713\n",
      "  timestamp: 1554819591\n",
      "  timesteps_since_restore: 4090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4090000\n",
      "  training_iteration: 409\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11283 s, 409 iter, 4090000 ts, -79.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-20-21\n",
      "  done: false\n",
      "  episode_len_mean: 83.71666666666667\n",
      "  episode_reward_max: 8.914229950020545\n",
      "  episode_reward_mean: -94.93429855359929\n",
      "  episode_reward_min: -200.01517661147105\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 44348\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5311.124\n",
      "    load_time_ms: 1.764\n",
      "    num_steps_sampled: 4100000\n",
      "    num_steps_trained: 4100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3048756122589111\n",
      "      kl: 0.05116305872797966\n",
      "      policy_loss: 0.020549874752759933\n",
      "      total_loss: 1378.453369140625\n",
      "      vf_explained_var: 0.5151758790016174\n",
      "      vf_loss: 1378.4327392578125\n",
      "    sample_time_ms: 24887.094\n",
      "    update_time_ms: 6.96\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.46714927679964\n",
      "  time_since_restore: 11313.629549741745\n",
      "  time_this_iter_s: 30.32890820503235\n",
      "  time_total_s: 11313.629549741745\n",
      "  timestamp: 1554819621\n",
      "  timesteps_since_restore: 4100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4100000\n",
      "  training_iteration: 410\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11313 s, 410 iter, 4100000 ts, -94.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-20-52\n",
      "  done: false\n",
      "  episode_len_mean: 91.5137614678899\n",
      "  episode_reward_max: 8.595591894790408\n",
      "  episode_reward_mean: -77.01744170504324\n",
      "  episode_reward_min: -200.06761388693334\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 44457\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5313.873\n",
      "    load_time_ms: 1.747\n",
      "    num_steps_sampled: 4110000\n",
      "    num_steps_trained: 4110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.2927314043045044\n",
      "      kl: 0.030687227845191956\n",
      "      policy_loss: 0.01082912739366293\n",
      "      total_loss: 1432.5474853515625\n",
      "      vf_explained_var: 0.4749891757965088\n",
      "      vf_loss: 1432.53662109375\n",
      "    sample_time_ms: 24828.938\n",
      "    update_time_ms: 7.303\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.50872085252162\n",
      "  time_since_restore: 11343.662041425705\n",
      "  time_this_iter_s: 30.03249168395996\n",
      "  time_total_s: 11343.662041425705\n",
      "  timestamp: 1554819652\n",
      "  timesteps_since_restore: 4110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4110000\n",
      "  training_iteration: 411\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11343 s, 411 iter, 4110000 ts, -77 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-21-22\n",
      "  done: false\n",
      "  episode_len_mean: 85.59482758620689\n",
      "  episode_reward_max: 8.723433293060573\n",
      "  episode_reward_mean: -93.06230431883263\n",
      "  episode_reward_min: -200.12205013855427\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 44573\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5338.748\n",
      "    load_time_ms: 1.799\n",
      "    num_steps_sampled: 4120000\n",
      "    num_steps_trained: 4120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.317281723022461\n",
      "      kl: 0.04011419042944908\n",
      "      policy_loss: 0.012942388653755188\n",
      "      total_loss: 1391.4300537109375\n",
      "      vf_explained_var: 0.4982277452945709\n",
      "      vf_loss: 1391.417236328125\n",
      "    sample_time_ms: 24897.043\n",
      "    update_time_ms: 7.185\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.53115215941633\n",
      "  time_since_restore: 11374.321829319\n",
      "  time_this_iter_s: 30.659787893295288\n",
      "  time_total_s: 11374.321829319\n",
      "  timestamp: 1554819682\n",
      "  timesteps_since_restore: 4120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4120000\n",
      "  training_iteration: 412\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11374 s, 412 iter, 4120000 ts, -93.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-21-52\n",
      "  done: false\n",
      "  episode_len_mean: 89.38053097345133\n",
      "  episode_reward_max: 7.394987628793045\n",
      "  episode_reward_mean: -83.1028881684043\n",
      "  episode_reward_min: -200.05423378525512\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 44686\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5318.343\n",
      "    load_time_ms: 1.774\n",
      "    num_steps_sampled: 4130000\n",
      "    num_steps_trained: 4130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3219068050384521\n",
      "      kl: 0.04042207822203636\n",
      "      policy_loss: 0.014946329407393932\n",
      "      total_loss: 1456.032958984375\n",
      "      vf_explained_var: 0.4651367962360382\n",
      "      vf_loss: 1456.01806640625\n",
      "    sample_time_ms: 24884.178\n",
      "    update_time_ms: 7.655\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.55144408420215\n",
      "  time_since_restore: 11404.18132686615\n",
      "  time_this_iter_s: 29.859497547149658\n",
      "  time_total_s: 11404.18132686615\n",
      "  timestamp: 1554819712\n",
      "  timesteps_since_restore: 4130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4130000\n",
      "  training_iteration: 413\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11404 s, 413 iter, 4130000 ts, -83.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-22-23\n",
      "  done: false\n",
      "  episode_len_mean: 89.63963963963964\n",
      "  episode_reward_max: 6.732986246134596\n",
      "  episode_reward_mean: -81.35194237355509\n",
      "  episode_reward_min: -200.12101334543138\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 44797\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5325.108\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 4140000\n",
      "    num_steps_trained: 4140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3110967874526978\n",
      "      kl: 0.03692241758108139\n",
      "      policy_loss: 0.015086495317518711\n",
      "      total_loss: 1470.8690185546875\n",
      "      vf_explained_var: 0.43399953842163086\n",
      "      vf_loss: 1470.85400390625\n",
      "    sample_time_ms: 24934.631\n",
      "    update_time_ms: 7.685\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.67597118677754\n",
      "  time_since_restore: 11434.664510965347\n",
      "  time_this_iter_s: 30.483184099197388\n",
      "  time_total_s: 11434.664510965347\n",
      "  timestamp: 1554819743\n",
      "  timesteps_since_restore: 4140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4140000\n",
      "  training_iteration: 414\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11434 s, 414 iter, 4140000 ts, -81.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-22-53\n",
      "  done: false\n",
      "  episode_len_mean: 85.09322033898304\n",
      "  episode_reward_max: 6.655210515619583\n",
      "  episode_reward_mean: -93.42892261442374\n",
      "  episode_reward_min: -200.10349315755155\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 44915\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5306.777\n",
      "    load_time_ms: 1.66\n",
      "    num_steps_sampled: 4150000\n",
      "    num_steps_trained: 4150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3228188753128052\n",
      "      kl: 0.04010431095957756\n",
      "      policy_loss: 0.015890680253505707\n",
      "      total_loss: 1354.13720703125\n",
      "      vf_explained_var: 0.5345538258552551\n",
      "      vf_loss: 1354.121337890625\n",
      "    sample_time_ms: 24922.757\n",
      "    update_time_ms: 7.451\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.71446130721187\n",
      "  time_since_restore: 11464.885695695877\n",
      "  time_this_iter_s: 30.221184730529785\n",
      "  time_total_s: 11464.885695695877\n",
      "  timestamp: 1554819773\n",
      "  timesteps_since_restore: 4150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4150000\n",
      "  training_iteration: 415\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11464 s, 415 iter, 4150000 ts, -93.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-23-23\n",
      "  done: false\n",
      "  episode_len_mean: 83.63559322033899\n",
      "  episode_reward_max: 7.24821007902475\n",
      "  episode_reward_mean: -98.57558087209901\n",
      "  episode_reward_min: -200.0755629131217\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 45033\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5296.525\n",
      "    load_time_ms: 1.716\n",
      "    num_steps_sampled: 4160000\n",
      "    num_steps_trained: 4160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.337292194366455\n",
      "      kl: 0.041272033005952835\n",
      "      policy_loss: 0.021801160648465157\n",
      "      total_loss: 1384.657470703125\n",
      "      vf_explained_var: 0.5334828495979309\n",
      "      vf_loss: 1384.6356201171875\n",
      "    sample_time_ms: 24929.727\n",
      "    update_time_ms: 7.092\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.287790436049505\n",
      "  time_since_restore: 11494.984031438828\n",
      "  time_this_iter_s: 30.09833574295044\n",
      "  time_total_s: 11494.984031438828\n",
      "  timestamp: 1554819803\n",
      "  timesteps_since_restore: 4160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4160000\n",
      "  training_iteration: 416\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11494 s, 416 iter, 4160000 ts, -98.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-23-53\n",
      "  done: false\n",
      "  episode_len_mean: 91.36936936936937\n",
      "  episode_reward_max: 10.938499568973528\n",
      "  episode_reward_mean: -77.51852266553169\n",
      "  episode_reward_min: -200.11641282486107\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 45144\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5291.847\n",
      "    load_time_ms: 1.686\n",
      "    num_steps_sampled: 4170000\n",
      "    num_steps_trained: 4170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.322643756866455\n",
      "      kl: 0.03632260113954544\n",
      "      policy_loss: 0.013787972740828991\n",
      "      total_loss: 1460.1033935546875\n",
      "      vf_explained_var: 0.47079047560691833\n",
      "      vf_loss: 1460.089599609375\n",
      "    sample_time_ms: 24898.209\n",
      "    update_time_ms: 7.018\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.75926133276585\n",
      "  time_since_restore: 11524.924310445786\n",
      "  time_this_iter_s: 29.940279006958008\n",
      "  time_total_s: 11524.924310445786\n",
      "  timestamp: 1554819833\n",
      "  timesteps_since_restore: 4170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4170000\n",
      "  training_iteration: 417\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11524 s, 417 iter, 4170000 ts, -77.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-24-24\n",
      "  done: false\n",
      "  episode_len_mean: 83.68067226890756\n",
      "  episode_reward_max: 5.269897556616002\n",
      "  episode_reward_mean: -97.56046518330851\n",
      "  episode_reward_min: -200.07607909708082\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 45263\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5291.449\n",
      "    load_time_ms: 1.64\n",
      "    num_steps_sampled: 4180000\n",
      "    num_steps_trained: 4180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3361446857452393\n",
      "      kl: 0.05745358392596245\n",
      "      policy_loss: 0.021698594093322754\n",
      "      total_loss: 1347.30615234375\n",
      "      vf_explained_var: 0.5130467414855957\n",
      "      vf_loss: 1347.284423828125\n",
      "    sample_time_ms: 24958.158\n",
      "    update_time_ms: 7.055\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.78023259165425\n",
      "  time_since_restore: 11555.58081293106\n",
      "  time_this_iter_s: 30.65650248527527\n",
      "  time_total_s: 11555.58081293106\n",
      "  timestamp: 1554819864\n",
      "  timesteps_since_restore: 4180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4180000\n",
      "  training_iteration: 418\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11555 s, 418 iter, 4180000 ts, -97.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-24-54\n",
      "  done: false\n",
      "  episode_len_mean: 83.35833333333333\n",
      "  episode_reward_max: 9.019459866547404\n",
      "  episode_reward_mean: -96.90941307677403\n",
      "  episode_reward_min: -200.07251128793058\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 45383\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5296.059\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 4190000\n",
      "    num_steps_trained: 4190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3361849784851074\n",
      "      kl: 0.040190067142248154\n",
      "      policy_loss: 0.01753983274102211\n",
      "      total_loss: 1334.3177490234375\n",
      "      vf_explained_var: 0.5342628359794617\n",
      "      vf_loss: 1334.300048828125\n",
      "    sample_time_ms: 24930.76\n",
      "    update_time_ms: 7.169\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.454706538387015\n",
      "  time_since_restore: 11585.878033399582\n",
      "  time_this_iter_s: 30.297220468521118\n",
      "  time_total_s: 11585.878033399582\n",
      "  timestamp: 1554819894\n",
      "  timesteps_since_restore: 4190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4190000\n",
      "  training_iteration: 419\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11585 s, 419 iter, 4190000 ts, -96.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-25-24\n",
      "  done: false\n",
      "  episode_len_mean: 83.43697478991596\n",
      "  episode_reward_max: 8.833554139033076\n",
      "  episode_reward_mean: -95.74073802403282\n",
      "  episode_reward_min: -200.0476113406361\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 45502\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5277.122\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 4200000\n",
      "    num_steps_trained: 4200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3363800048828125\n",
      "      kl: 0.04149677976965904\n",
      "      policy_loss: 0.016412748023867607\n",
      "      total_loss: 1361.2552490234375\n",
      "      vf_explained_var: 0.5146970152854919\n",
      "      vf_loss: 1361.2386474609375\n",
      "    sample_time_ms: 24940.733\n",
      "    update_time_ms: 7.194\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.87036901201641\n",
      "  time_since_restore: 11616.116379737854\n",
      "  time_this_iter_s: 30.238346338272095\n",
      "  time_total_s: 11616.116379737854\n",
      "  timestamp: 1554819924\n",
      "  timesteps_since_restore: 4200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4200000\n",
      "  training_iteration: 420\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11616 s, 420 iter, 4200000 ts, -95.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-25-55\n",
      "  done: false\n",
      "  episode_len_mean: 80.528\n",
      "  episode_reward_max: 7.891014655661886\n",
      "  episode_reward_mean: -105.58414110706687\n",
      "  episode_reward_min: -200.06883200261277\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 45627\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5279.262\n",
      "    load_time_ms: 1.646\n",
      "    num_steps_sampled: 4210000\n",
      "    num_steps_trained: 4210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3435360193252563\n",
      "      kl: 0.06622226536273956\n",
      "      policy_loss: 0.026390906423330307\n",
      "      total_loss: 1250.45849609375\n",
      "      vf_explained_var: 0.5665579438209534\n",
      "      vf_loss: 1250.4322509765625\n",
      "    sample_time_ms: 24982.303\n",
      "    update_time_ms: 7.054\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.79207055353343\n",
      "  time_since_restore: 11646.582512378693\n",
      "  time_this_iter_s: 30.466132640838623\n",
      "  time_total_s: 11646.582512378693\n",
      "  timestamp: 1554819955\n",
      "  timesteps_since_restore: 4210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4210000\n",
      "  training_iteration: 421\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11646 s, 421 iter, 4210000 ts, -106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-26-25\n",
      "  done: false\n",
      "  episode_len_mean: 88.73451327433628\n",
      "  episode_reward_max: 5.47435131370712\n",
      "  episode_reward_mean: -83.41164976879558\n",
      "  episode_reward_min: -200.0878647557476\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 45740\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5273.271\n",
      "    load_time_ms: 1.59\n",
      "    num_steps_sampled: 4220000\n",
      "    num_steps_trained: 4220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3304271697998047\n",
      "      kl: 0.037476200610399246\n",
      "      policy_loss: 0.017082849517464638\n",
      "      total_loss: 1401.6837158203125\n",
      "      vf_explained_var: 0.5118093490600586\n",
      "      vf_loss: 1401.6666259765625\n",
      "    sample_time_ms: 24943.77\n",
      "    update_time_ms: 7.051\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.70582488439781\n",
      "  time_since_restore: 11676.793163061142\n",
      "  time_this_iter_s: 30.21065068244934\n",
      "  time_total_s: 11676.793163061142\n",
      "  timestamp: 1554819985\n",
      "  timesteps_since_restore: 4220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4220000\n",
      "  training_iteration: 422\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11676 s, 422 iter, 4220000 ts, -83.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-26-56\n",
      "  done: false\n",
      "  episode_len_mean: 86.1304347826087\n",
      "  episode_reward_max: 9.356770739406757\n",
      "  episode_reward_mean: -90.79613545715466\n",
      "  episode_reward_min: -200.06346164936318\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 45855\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5278.033\n",
      "    load_time_ms: 1.592\n",
      "    num_steps_sampled: 4230000\n",
      "    num_steps_trained: 4230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3376293182373047\n",
      "      kl: 0.051105137914419174\n",
      "      policy_loss: 0.022509494796395302\n",
      "      total_loss: 1378.5692138671875\n",
      "      vf_explained_var: 0.5332450866699219\n",
      "      vf_loss: 1378.546630859375\n",
      "    sample_time_ms: 24998.265\n",
      "    update_time_ms: 6.732\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.398067728577324\n",
      "  time_since_restore: 11707.242551088333\n",
      "  time_this_iter_s: 30.449388027191162\n",
      "  time_total_s: 11707.242551088333\n",
      "  timestamp: 1554820016\n",
      "  timesteps_since_restore: 4230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4230000\n",
      "  training_iteration: 423\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11707 s, 423 iter, 4230000 ts, -90.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-27-26\n",
      "  done: false\n",
      "  episode_len_mean: 84.56302521008404\n",
      "  episode_reward_max: 8.934414168290871\n",
      "  episode_reward_mean: -95.59343925495044\n",
      "  episode_reward_min: -200.03963397099585\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 45974\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5270.296\n",
      "    load_time_ms: 1.586\n",
      "    num_steps_sampled: 4240000\n",
      "    num_steps_trained: 4240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3460403680801392\n",
      "      kl: 0.049638375639915466\n",
      "      policy_loss: 0.020064519718289375\n",
      "      total_loss: 1407.95751953125\n",
      "      vf_explained_var: 0.4869537949562073\n",
      "      vf_loss: 1407.9375\n",
      "    sample_time_ms: 24979.571\n",
      "    update_time_ms: 7.185\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.79671962747522\n",
      "  time_since_restore: 11737.465516805649\n",
      "  time_this_iter_s: 30.222965717315674\n",
      "  time_total_s: 11737.465516805649\n",
      "  timestamp: 1554820046\n",
      "  timesteps_since_restore: 4240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4240000\n",
      "  training_iteration: 424\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11737 s, 424 iter, 4240000 ts, -95.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-27-57\n",
      "  done: false\n",
      "  episode_len_mean: 86.56521739130434\n",
      "  episode_reward_max: 8.995790549037425\n",
      "  episode_reward_mean: -88.50232721144222\n",
      "  episode_reward_min: -200.11988126493515\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 46089\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5282.761\n",
      "    load_time_ms: 1.587\n",
      "    num_steps_sampled: 4250000\n",
      "    num_steps_trained: 4250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3407626152038574\n",
      "      kl: 0.042846377938985825\n",
      "      policy_loss: 0.017463216558098793\n",
      "      total_loss: 1351.2357177734375\n",
      "      vf_explained_var: 0.49545004963874817\n",
      "      vf_loss: 1351.2183837890625\n",
      "    sample_time_ms: 25010.838\n",
      "    update_time_ms: 7.265\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.25116360572111\n",
      "  time_since_restore: 11768.12325668335\n",
      "  time_this_iter_s: 30.657739877700806\n",
      "  time_total_s: 11768.12325668335\n",
      "  timestamp: 1554820077\n",
      "  timesteps_since_restore: 4250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4250000\n",
      "  training_iteration: 425\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11768 s, 425 iter, 4250000 ts, -88.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-28-28\n",
      "  done: false\n",
      "  episode_len_mean: 91.76146788990826\n",
      "  episode_reward_max: 8.304399503535494\n",
      "  episode_reward_mean: -75.55130103512968\n",
      "  episode_reward_min: -200.06181781671899\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 46198\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5461.312\n",
      "    load_time_ms: 1.532\n",
      "    num_steps_sampled: 4260000\n",
      "    num_steps_trained: 4260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3337453603744507\n",
      "      kl: 0.054842375218868256\n",
      "      policy_loss: 0.02258000336587429\n",
      "      total_loss: 1448.9384765625\n",
      "      vf_explained_var: 0.4431474208831787\n",
      "      vf_loss: 1448.9158935546875\n",
      "    sample_time_ms: 24999.904\n",
      "    update_time_ms: 7.21\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.775650517564834\n",
      "  time_since_restore: 11799.89530825615\n",
      "  time_this_iter_s: 31.772051572799683\n",
      "  time_total_s: 11799.89530825615\n",
      "  timestamp: 1554820108\n",
      "  timesteps_since_restore: 4260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4260000\n",
      "  training_iteration: 426\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11799 s, 426 iter, 4260000 ts, -75.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-28-59\n",
      "  done: false\n",
      "  episode_len_mean: 91.88073394495413\n",
      "  episode_reward_max: 6.500963713536094\n",
      "  episode_reward_mean: -75.36679397982422\n",
      "  episode_reward_min: -200.09286277958964\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 46307\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5465.696\n",
      "    load_time_ms: 1.534\n",
      "    num_steps_sampled: 4270000\n",
      "    num_steps_trained: 4270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.334047794342041\n",
      "      kl: 0.0672016590833664\n",
      "      policy_loss: 0.02289356105029583\n",
      "      total_loss: 1452.6116943359375\n",
      "      vf_explained_var: 0.45092615485191345\n",
      "      vf_loss: 1452.5887451171875\n",
      "    sample_time_ms: 25017.363\n",
      "    update_time_ms: 7.845\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.68339698991211\n",
      "  time_since_restore: 11830.0634329319\n",
      "  time_this_iter_s: 30.168124675750732\n",
      "  time_total_s: 11830.0634329319\n",
      "  timestamp: 1554820139\n",
      "  timesteps_since_restore: 4270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4270000\n",
      "  training_iteration: 427\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11830 s, 427 iter, 4270000 ts, -75.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 88.38938053097345\n",
      "  episode_reward_max: 9.121577964451413\n",
      "  episode_reward_mean: -84.97888993590267\n",
      "  episode_reward_min: -200.09797247680808\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 46420\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5464.229\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 4280000\n",
      "    num_steps_trained: 4280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.341137170791626\n",
      "      kl: 0.0859917402267456\n",
      "      policy_loss: 0.03770681098103523\n",
      "      total_loss: 1392.0322265625\n",
      "      vf_explained_var: 0.5084472298622131\n",
      "      vf_loss: 1391.994384765625\n",
      "    sample_time_ms: 24981.01\n",
      "    update_time_ms: 7.703\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.48944496795134\n",
      "  time_since_restore: 11860.34147977829\n",
      "  time_this_iter_s: 30.27804684638977\n",
      "  time_total_s: 11860.34147977829\n",
      "  timestamp: 1554820169\n",
      "  timesteps_since_restore: 4280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4280000\n",
      "  training_iteration: 428\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11860 s, 428 iter, 4280000 ts, -85 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-30-00\n",
      "  done: false\n",
      "  episode_len_mean: 80.448\n",
      "  episode_reward_max: 10.39857612562205\n",
      "  episode_reward_mean: -105.70616639894797\n",
      "  episode_reward_min: -200.10184057038606\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 46545\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5442.188\n",
      "    load_time_ms: 1.542\n",
      "    num_steps_sampled: 4290000\n",
      "    num_steps_trained: 4290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.357651710510254\n",
      "      kl: 0.04368804395198822\n",
      "      policy_loss: 0.019398372620344162\n",
      "      total_loss: 1337.999267578125\n",
      "      vf_explained_var: 0.5513308644294739\n",
      "      vf_loss: 1337.9798583984375\n",
      "    sample_time_ms: 25055.411\n",
      "    update_time_ms: 7.517\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.853083199473986\n",
      "  time_since_restore: 11891.159311771393\n",
      "  time_this_iter_s: 30.817831993103027\n",
      "  time_total_s: 11891.159311771393\n",
      "  timestamp: 1554820200\n",
      "  timesteps_since_restore: 4290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4290000\n",
      "  training_iteration: 429\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11891 s, 429 iter, 4290000 ts, -106 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-30-30\n",
      "  done: false\n",
      "  episode_len_mean: 97.45544554455445\n",
      "  episode_reward_max: 7.687560431095743\n",
      "  episode_reward_mean: -59.69023581632189\n",
      "  episode_reward_min: -200.0810968469022\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 46646\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5451.387\n",
      "    load_time_ms: 1.547\n",
      "    num_steps_sampled: 4300000\n",
      "    num_steps_trained: 4300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3315280675888062\n",
      "      kl: 0.03378800302743912\n",
      "      policy_loss: 0.012287908233702183\n",
      "      total_loss: 1549.904296875\n",
      "      vf_explained_var: 0.38238880038261414\n",
      "      vf_loss: 1549.891845703125\n",
      "    sample_time_ms: 25079.372\n",
      "    update_time_ms: 7.844\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -29.84511790816094\n",
      "  time_since_restore: 11921.732836484909\n",
      "  time_this_iter_s: 30.573524713516235\n",
      "  time_total_s: 11921.732836484909\n",
      "  timestamp: 1554820230\n",
      "  timesteps_since_restore: 4300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4300000\n",
      "  training_iteration: 430\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11921 s, 430 iter, 4300000 ts, -59.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-31-02\n",
      "  done: false\n",
      "  episode_len_mean: 84.0495867768595\n",
      "  episode_reward_max: 7.363866130707011\n",
      "  episode_reward_mean: -95.55210026155564\n",
      "  episode_reward_min: -200.02764273357315\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 46767\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5510.789\n",
      "    load_time_ms: 1.507\n",
      "    num_steps_sampled: 4310000\n",
      "    num_steps_trained: 4310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3647985458374023\n",
      "      kl: 0.05831993371248245\n",
      "      policy_loss: 0.025389933958649635\n",
      "      total_loss: 1300.9112548828125\n",
      "      vf_explained_var: 0.5534489750862122\n",
      "      vf_loss: 1300.8858642578125\n",
      "    sample_time_ms: 25080.149\n",
      "    update_time_ms: 7.781\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.77605013077782\n",
      "  time_since_restore: 11952.799857378006\n",
      "  time_this_iter_s: 31.067020893096924\n",
      "  time_total_s: 11952.799857378006\n",
      "  timestamp: 1554820262\n",
      "  timesteps_since_restore: 4310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4310000\n",
      "  training_iteration: 431\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11952 s, 431 iter, 4310000 ts, -95.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-31-32\n",
      "  done: false\n",
      "  episode_len_mean: 87.93805309734513\n",
      "  episode_reward_max: 7.57304383606664\n",
      "  episode_reward_mean: -86.80877498740716\n",
      "  episode_reward_min: -200.08657809949784\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 46880\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5503.397\n",
      "    load_time_ms: 1.554\n",
      "    num_steps_sampled: 4320000\n",
      "    num_steps_trained: 4320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3604449033737183\n",
      "      kl: 0.05366332828998566\n",
      "      policy_loss: 0.024715973064303398\n",
      "      total_loss: 1393.7503662109375\n",
      "      vf_explained_var: 0.46925032138824463\n",
      "      vf_loss: 1393.7257080078125\n",
      "    sample_time_ms: 25071.809\n",
      "    update_time_ms: 7.68\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.4043874937036\n",
      "  time_since_restore: 11982.85590004921\n",
      "  time_this_iter_s: 30.056042671203613\n",
      "  time_total_s: 11982.85590004921\n",
      "  timestamp: 1554820292\n",
      "  timesteps_since_restore: 4320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4320000\n",
      "  training_iteration: 432\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 11982 s, 432 iter, 4320000 ts, -86.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-32-02\n",
      "  done: false\n",
      "  episode_len_mean: 90.14545454545454\n",
      "  episode_reward_max: 8.971680467613833\n",
      "  episode_reward_mean: -82.01910486931702\n",
      "  episode_reward_min: -200.1094473489989\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 46990\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5517.991\n",
      "    load_time_ms: 1.564\n",
      "    num_steps_sampled: 4330000\n",
      "    num_steps_trained: 4330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3619394302368164\n",
      "      kl: 0.04517078399658203\n",
      "      policy_loss: 0.019391249865293503\n",
      "      total_loss: 1389.6580810546875\n",
      "      vf_explained_var: 0.5038220286369324\n",
      "      vf_loss: 1389.638671875\n",
      "    sample_time_ms: 25046.854\n",
      "    update_time_ms: 7.789\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.00955243465851\n",
      "  time_since_restore: 12013.205397129059\n",
      "  time_this_iter_s: 30.349497079849243\n",
      "  time_total_s: 12013.205397129059\n",
      "  timestamp: 1554820322\n",
      "  timesteps_since_restore: 4330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4330000\n",
      "  training_iteration: 433\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12013 s, 433 iter, 4330000 ts, -82 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-32-33\n",
      "  done: false\n",
      "  episode_len_mean: 90.73214285714286\n",
      "  episode_reward_max: 8.218606133816596\n",
      "  episode_reward_mean: -78.71374619449713\n",
      "  episode_reward_min: -200.0403647759578\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 47102\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5541.626\n",
      "    load_time_ms: 1.572\n",
      "    num_steps_sampled: 4340000\n",
      "    num_steps_trained: 4340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.358964204788208\n",
      "      kl: 0.03718788921833038\n",
      "      policy_loss: 0.018324466422200203\n",
      "      total_loss: 1470.524658203125\n",
      "      vf_explained_var: 0.46299615502357483\n",
      "      vf_loss: 1470.50634765625\n",
      "    sample_time_ms: 25079.376\n",
      "    update_time_ms: 7.507\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.35687309724857\n",
      "  time_since_restore: 12043.985813856125\n",
      "  time_this_iter_s: 30.78041672706604\n",
      "  time_total_s: 12043.985813856125\n",
      "  timestamp: 1554820353\n",
      "  timesteps_since_restore: 4340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4340000\n",
      "  training_iteration: 434\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12043 s, 434 iter, 4340000 ts, -78.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-33-04\n",
      "  done: false\n",
      "  episode_len_mean: 86.6842105263158\n",
      "  episode_reward_max: 6.929937008234376\n",
      "  episode_reward_mean: -87.88340281598839\n",
      "  episode_reward_min: -200.01890683218124\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 47216\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5532.254\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 4350000\n",
      "    num_steps_trained: 4350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3538247346878052\n",
      "      kl: 0.04155030846595764\n",
      "      policy_loss: 0.016919735819101334\n",
      "      total_loss: 1419.30810546875\n",
      "      vf_explained_var: 0.4938885271549225\n",
      "      vf_loss: 1419.291259765625\n",
      "    sample_time_ms: 25097.354\n",
      "    update_time_ms: 7.359\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.941701407994195\n",
      "  time_since_restore: 12074.732372045517\n",
      "  time_this_iter_s: 30.74655818939209\n",
      "  time_total_s: 12074.732372045517\n",
      "  timestamp: 1554820384\n",
      "  timesteps_since_restore: 4350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4350000\n",
      "  training_iteration: 435\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12074 s, 435 iter, 4350000 ts, -87.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-33-35\n",
      "  done: false\n",
      "  episode_len_mean: 90.0625\n",
      "  episode_reward_max: 11.495828123417466\n",
      "  episode_reward_mean: -78.29298567202788\n",
      "  episode_reward_min: -200.0984274674085\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 47328\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5394.497\n",
      "    load_time_ms: 1.589\n",
      "    num_steps_sampled: 4360000\n",
      "    num_steps_trained: 4360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.351982593536377\n",
      "      kl: 0.0356752946972847\n",
      "      policy_loss: 0.014121820218861103\n",
      "      total_loss: 1448.5821533203125\n",
      "      vf_explained_var: 0.45579224824905396\n",
      "      vf_loss: 1448.5679931640625\n",
      "    sample_time_ms: 25190.986\n",
      "    update_time_ms: 7.468\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.146492836013934\n",
      "  time_since_restore: 12106.063279628754\n",
      "  time_this_iter_s: 31.330907583236694\n",
      "  time_total_s: 12106.063279628754\n",
      "  timestamp: 1554820415\n",
      "  timesteps_since_restore: 4360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4360000\n",
      "  training_iteration: 436\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12106 s, 436 iter, 4360000 ts, -78.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-34-06\n",
      "  done: false\n",
      "  episode_len_mean: 89.02702702702703\n",
      "  episode_reward_max: 9.46451010885214\n",
      "  episode_reward_mean: -84.61604327747573\n",
      "  episode_reward_min: -200.11148403112193\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 47439\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5430.511\n",
      "    load_time_ms: 1.642\n",
      "    num_steps_sampled: 4370000\n",
      "    num_steps_trained: 4370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3621554374694824\n",
      "      kl: 0.05235396325588226\n",
      "      policy_loss: 0.021578775718808174\n",
      "      total_loss: 1392.7960205078125\n",
      "      vf_explained_var: 0.4985205829143524\n",
      "      vf_loss: 1392.7744140625\n",
      "    sample_time_ms: 25186.093\n",
      "    update_time_ms: 6.849\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.30802163873786\n",
      "  time_since_restore: 12136.539538860321\n",
      "  time_this_iter_s: 30.476259231567383\n",
      "  time_total_s: 12136.539538860321\n",
      "  timestamp: 1554820446\n",
      "  timesteps_since_restore: 4370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4370000\n",
      "  training_iteration: 437\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12136 s, 437 iter, 4370000 ts, -84.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-34-36\n",
      "  done: false\n",
      "  episode_len_mean: 88.51754385964912\n",
      "  episode_reward_max: 9.428937324454195\n",
      "  episode_reward_mean: -82.6477918011169\n",
      "  episode_reward_min: -200.04853360668784\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 47553\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5448.822\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 4380000\n",
      "    num_steps_trained: 4380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3574714660644531\n",
      "      kl: 0.03726952522993088\n",
      "      policy_loss: 0.015312760137021542\n",
      "      total_loss: 1433.7152099609375\n",
      "      vf_explained_var: 0.48146384954452515\n",
      "      vf_loss: 1433.699951171875\n",
      "    sample_time_ms: 25222.876\n",
      "    update_time_ms: 6.967\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.323895900558426\n",
      "  time_since_restore: 12167.371150493622\n",
      "  time_this_iter_s: 30.83161163330078\n",
      "  time_total_s: 12167.371150493622\n",
      "  timestamp: 1554820476\n",
      "  timesteps_since_restore: 4380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4380000\n",
      "  training_iteration: 438\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12167 s, 438 iter, 4380000 ts, -82.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-35-10\n",
      "  done: false\n",
      "  episode_len_mean: 83.91596638655462\n",
      "  episode_reward_max: 7.868321599511615\n",
      "  episode_reward_mean: -95.47869952069678\n",
      "  episode_reward_min: -200.105589721735\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 47672\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5503.464\n",
      "    load_time_ms: 1.676\n",
      "    num_steps_sampled: 4390000\n",
      "    num_steps_trained: 4390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3628188371658325\n",
      "      kl: 0.04176643490791321\n",
      "      policy_loss: 0.01600191928446293\n",
      "      total_loss: 1340.9293212890625\n",
      "      vf_explained_var: 0.5385191440582275\n",
      "      vf_loss: 1340.913330078125\n",
      "    sample_time_ms: 25446.216\n",
      "    update_time_ms: 6.951\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.73934976034839\n",
      "  time_since_restore: 12200.966935157776\n",
      "  time_this_iter_s: 33.59578466415405\n",
      "  time_total_s: 12200.966935157776\n",
      "  timestamp: 1554820510\n",
      "  timesteps_since_restore: 4390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4390000\n",
      "  training_iteration: 439\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12200 s, 439 iter, 4390000 ts, -95.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-35-51\n",
      "  done: false\n",
      "  episode_len_mean: 89.71428571428571\n",
      "  episode_reward_max: 6.39260718294906\n",
      "  episode_reward_mean: -81.75749127274541\n",
      "  episode_reward_min: -200.071625053641\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 47784\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5557.886\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 4400000\n",
      "    num_steps_trained: 4400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.351855754852295\n",
      "      kl: 0.04193802922964096\n",
      "      policy_loss: 0.01586344465613365\n",
      "      total_loss: 1465.6678466796875\n",
      "      vf_explained_var: 0.4664914906024933\n",
      "      vf_loss: 1465.652099609375\n",
      "    sample_time_ms: 26466.579\n",
      "    update_time_ms: 6.814\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.878745636372706\n",
      "  time_since_restore: 12242.295080184937\n",
      "  time_this_iter_s: 41.328145027160645\n",
      "  time_total_s: 12242.295080184937\n",
      "  timestamp: 1554820551\n",
      "  timesteps_since_restore: 4400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4400000\n",
      "  training_iteration: 440\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12242 s, 440 iter, 4400000 ts, -81.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-36-43\n",
      "  done: false\n",
      "  episode_len_mean: 85.12931034482759\n",
      "  episode_reward_max: 7.0274101547187\n",
      "  episode_reward_mean: -91.33985785357288\n",
      "  episode_reward_min: -200.12244370441596\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 47900\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5981.163\n",
      "    load_time_ms: 1.718\n",
      "    num_steps_sampled: 4410000\n",
      "    num_steps_trained: 4410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.35394287109375\n",
      "      kl: 0.04618007689714432\n",
      "      policy_loss: 0.019335104152560234\n",
      "      total_loss: 1416.207275390625\n",
      "      vf_explained_var: 0.4966525435447693\n",
      "      vf_loss: 1416.18798828125\n",
      "    sample_time_ms: 28062.73\n",
      "    update_time_ms: 7.573\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.66992892678644\n",
      "  time_since_restore: 12293.572986364365\n",
      "  time_this_iter_s: 51.2779061794281\n",
      "  time_total_s: 12293.572986364365\n",
      "  timestamp: 1554820603\n",
      "  timesteps_since_restore: 4410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4410000\n",
      "  training_iteration: 441\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12293 s, 441 iter, 4410000 ts, -91.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-37-37\n",
      "  done: false\n",
      "  episode_len_mean: 90.43243243243244\n",
      "  episode_reward_max: 7.007470658366769\n",
      "  episode_reward_mean: -79.27041277082108\n",
      "  episode_reward_min: -200.1011187617585\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 48011\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6439.619\n",
      "    load_time_ms: 1.868\n",
      "    num_steps_sampled: 4420000\n",
      "    num_steps_trained: 4420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.357269048690796\n",
      "      kl: 0.039662692695856094\n",
      "      policy_loss: 0.01621263287961483\n",
      "      total_loss: 1526.61376953125\n",
      "      vf_explained_var: 0.43994903564453125\n",
      "      vf_loss: 1526.5975341796875\n",
      "    sample_time_ms: 30008.705\n",
      "    update_time_ms: 8.403\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.63520638541054\n",
      "  time_since_restore: 12347.7094912529\n",
      "  time_this_iter_s: 54.136504888534546\n",
      "  time_total_s: 12347.7094912529\n",
      "  timestamp: 1554820657\n",
      "  timesteps_since_restore: 4420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4420000\n",
      "  training_iteration: 442\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12347 s, 442 iter, 4420000 ts, -79.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-38-24\n",
      "  done: false\n",
      "  episode_len_mean: 85.92241379310344\n",
      "  episode_reward_max: 7.763398640475307\n",
      "  episode_reward_mean: -91.26330378923218\n",
      "  episode_reward_min: -200.09652365194557\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 48127\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6761.916\n",
      "    load_time_ms: 1.873\n",
      "    num_steps_sampled: 4430000\n",
      "    num_steps_trained: 4430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3489235639572144\n",
      "      kl: 6.878579139709473\n",
      "      policy_loss: 0.0993327870965004\n",
      "      total_loss: 1283.506591796875\n",
      "      vf_explained_var: 0.5518263578414917\n",
      "      vf_loss: 1283.4072265625\n",
      "    sample_time_ms: 31374.52\n",
      "    update_time_ms: 8.683\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.63165189461609\n",
      "  time_since_restore: 12394.954735040665\n",
      "  time_this_iter_s: 47.2452437877655\n",
      "  time_total_s: 12394.954735040665\n",
      "  timestamp: 1554820704\n",
      "  timesteps_since_restore: 4430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4430000\n",
      "  training_iteration: 443\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12394 s, 443 iter, 4430000 ts, -91.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-39-07\n",
      "  done: false\n",
      "  episode_len_mean: 89.09649122807018\n",
      "  episode_reward_max: 11.401597231283054\n",
      "  episode_reward_mean: -82.58243580339347\n",
      "  episode_reward_min: -200.10614300296072\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 48241\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6795.551\n",
      "    load_time_ms: 1.973\n",
      "    num_steps_sampled: 4440000\n",
      "    num_steps_trained: 4440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.332203984260559\n",
      "      kl: 0.04397345334291458\n",
      "      policy_loss: 0.01608780026435852\n",
      "      total_loss: 1456.192138671875\n",
      "      vf_explained_var: 0.46842193603515625\n",
      "      vf_loss: 1456.176025390625\n",
      "    sample_time_ms: 32538.09\n",
      "    update_time_ms: 8.754\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.29121790169673\n",
      "  time_since_restore: 12437.711434602737\n",
      "  time_this_iter_s: 42.756699562072754\n",
      "  time_total_s: 12437.711434602737\n",
      "  timestamp: 1554820747\n",
      "  timesteps_since_restore: 4440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4440000\n",
      "  training_iteration: 444\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12437 s, 444 iter, 4440000 ts, -82.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-39-38\n",
      "  done: false\n",
      "  episode_len_mean: 89.55855855855856\n",
      "  episode_reward_max: 9.301808733313438\n",
      "  episode_reward_mean: -80.98457933193829\n",
      "  episode_reward_min: -200.02917769530785\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 48352\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6804.037\n",
      "    load_time_ms: 1.924\n",
      "    num_steps_sampled: 4450000\n",
      "    num_steps_trained: 4450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3432689905166626\n",
      "      kl: 0.04977145418524742\n",
      "      policy_loss: 0.020775984972715378\n",
      "      total_loss: 1420.874755859375\n",
      "      vf_explained_var: 0.46345749497413635\n",
      "      vf_loss: 1420.85400390625\n",
      "    sample_time_ms: 32552.904\n",
      "    update_time_ms: 8.933\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.49228966596913\n",
      "  time_since_restore: 12468.690526008606\n",
      "  time_this_iter_s: 30.97909140586853\n",
      "  time_total_s: 12468.690526008606\n",
      "  timestamp: 1554820778\n",
      "  timesteps_since_restore: 4450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4450000\n",
      "  training_iteration: 445\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12468 s, 445 iter, 4450000 ts, -81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-40-09\n",
      "  done: false\n",
      "  episode_len_mean: 87.34782608695652\n",
      "  episode_reward_max: 11.029062762368198\n",
      "  episode_reward_mean: -88.58846454773739\n",
      "  episode_reward_min: -200.05997960375853\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 48467\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6793.848\n",
      "    load_time_ms: 1.918\n",
      "    num_steps_sampled: 4460000\n",
      "    num_steps_trained: 4460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3499642610549927\n",
      "      kl: 0.04724840447306633\n",
      "      policy_loss: 0.01916806772351265\n",
      "      total_loss: 1378.2581787109375\n",
      "      vf_explained_var: 0.49033281207084656\n",
      "      vf_loss: 1378.239013671875\n",
      "    sample_time_ms: 32516.105\n",
      "    update_time_ms: 9.68\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.29423227386869\n",
      "  time_since_restore: 12499.561022281647\n",
      "  time_this_iter_s: 30.87049627304077\n",
      "  time_total_s: 12499.561022281647\n",
      "  timestamp: 1554820809\n",
      "  timesteps_since_restore: 4460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4460000\n",
      "  training_iteration: 446\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12499 s, 446 iter, 4460000 ts, -88.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-40-39\n",
      "  done: false\n",
      "  episode_len_mean: 85.4957264957265\n",
      "  episode_reward_max: 12.657808576174226\n",
      "  episode_reward_mean: -93.79948123617456\n",
      "  episode_reward_min: -200.21572296436875\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 48584\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6763.433\n",
      "    load_time_ms: 1.855\n",
      "    num_steps_sampled: 4470000\n",
      "    num_steps_trained: 4470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3445709943771362\n",
      "      kl: 0.05406634137034416\n",
      "      policy_loss: 0.02151907980442047\n",
      "      total_loss: 1347.009765625\n",
      "      vf_explained_var: 0.5262578129768372\n",
      "      vf_loss: 1346.9884033203125\n",
      "    sample_time_ms: 32528.935\n",
      "    update_time_ms: 9.955\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.899740618087264\n",
      "  time_since_restore: 12529.858678817749\n",
      "  time_this_iter_s: 30.297656536102295\n",
      "  time_total_s: 12529.858678817749\n",
      "  timestamp: 1554820839\n",
      "  timesteps_since_restore: 4470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4470000\n",
      "  training_iteration: 447\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12529 s, 447 iter, 4470000 ts, -93.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-41-10\n",
      "  done: false\n",
      "  episode_len_mean: 80.12096774193549\n",
      "  episode_reward_max: 12.989522936963732\n",
      "  episode_reward_mean: -107.97865381251543\n",
      "  episode_reward_min: -200.11904653761837\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 48708\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6742.492\n",
      "    load_time_ms: 1.813\n",
      "    num_steps_sampled: 4480000\n",
      "    num_steps_trained: 4480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.354430913925171\n",
      "      kl: 0.04757356271147728\n",
      "      policy_loss: 0.014843354001641273\n",
      "      total_loss: 1278.737548828125\n",
      "      vf_explained_var: 0.5710216760635376\n",
      "      vf_loss: 1278.72265625\n",
      "    sample_time_ms: 32498.426\n",
      "    update_time_ms: 9.967\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -53.989326906257716\n",
      "  time_since_restore: 12560.175966262817\n",
      "  time_this_iter_s: 30.31728744506836\n",
      "  time_total_s: 12560.175966262817\n",
      "  timestamp: 1554820870\n",
      "  timesteps_since_restore: 4480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4480000\n",
      "  training_iteration: 448\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12560 s, 448 iter, 4480000 ts, -108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-41-40\n",
      "  done: false\n",
      "  episode_len_mean: 83.72033898305085\n",
      "  episode_reward_max: 10.866825203766059\n",
      "  episode_reward_mean: -98.18414424051785\n",
      "  episode_reward_min: -200.11213475575659\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 48826\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6704.419\n",
      "    load_time_ms: 1.805\n",
      "    num_steps_sampled: 4490000\n",
      "    num_steps_trained: 4490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.34512197971344\n",
      "      kl: 0.04564244672656059\n",
      "      policy_loss: 0.018257470801472664\n",
      "      total_loss: 1420.28662109375\n",
      "      vf_explained_var: 0.4865777790546417\n",
      "      vf_loss: 1420.2684326171875\n",
      "    sample_time_ms: 32198.846\n",
      "    update_time_ms: 10.317\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.092072120258926\n",
      "  time_since_restore: 12590.402644634247\n",
      "  time_this_iter_s: 30.226678371429443\n",
      "  time_total_s: 12590.402644634247\n",
      "  timestamp: 1554820900\n",
      "  timesteps_since_restore: 4490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4490000\n",
      "  training_iteration: 449\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12590 s, 449 iter, 4490000 ts, -98.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-42-10\n",
      "  done: false\n",
      "  episode_len_mean: 87.71304347826087\n",
      "  episode_reward_max: 9.882331215909732\n",
      "  episode_reward_mean: -89.06410598829314\n",
      "  episode_reward_min: -200.13869724180927\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 48941\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6646.494\n",
      "    load_time_ms: 1.85\n",
      "    num_steps_sampled: 4500000\n",
      "    num_steps_trained: 4500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.343013882637024\n",
      "      kl: 0.044549617916345596\n",
      "      policy_loss: 0.01828404888510704\n",
      "      total_loss: 1382.0572509765625\n",
      "      vf_explained_var: 0.5211231708526611\n",
      "      vf_loss: 1382.0389404296875\n",
      "    sample_time_ms: 31122.62\n",
      "    update_time_ms: 10.558\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.53205299414658\n",
      "  time_since_restore: 12620.385115385056\n",
      "  time_this_iter_s: 29.982470750808716\n",
      "  time_total_s: 12620.385115385056\n",
      "  timestamp: 1554820930\n",
      "  timesteps_since_restore: 4500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4500000\n",
      "  training_iteration: 450\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12620 s, 450 iter, 4500000 ts, -89.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-42-40\n",
      "  done: false\n",
      "  episode_len_mean: 87.59130434782608\n",
      "  episode_reward_max: 7.959569746226573\n",
      "  episode_reward_mean: -86.93976221892699\n",
      "  episode_reward_min: -200.08121924743966\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 49056\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6176.367\n",
      "    load_time_ms: 1.766\n",
      "    num_steps_sampled: 4510000\n",
      "    num_steps_trained: 4510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3372682332992554\n",
      "      kl: 0.036075789481401443\n",
      "      policy_loss: 0.01270889863371849\n",
      "      total_loss: 1388.4468994140625\n",
      "      vf_explained_var: 0.4953070282936096\n",
      "      vf_loss: 1388.43408203125\n",
      "    sample_time_ms: 29483.032\n",
      "    update_time_ms: 10.15\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.46988110946349\n",
      "  time_since_restore: 12650.552844762802\n",
      "  time_this_iter_s: 30.167729377746582\n",
      "  time_total_s: 12650.552844762802\n",
      "  timestamp: 1554820960\n",
      "  timesteps_since_restore: 4510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4510000\n",
      "  training_iteration: 451\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12650 s, 451 iter, 4510000 ts, -86.9 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-43-10\n",
      "  done: false\n",
      "  episode_len_mean: 93.12264150943396\n",
      "  episode_reward_max: 10.502741675873454\n",
      "  episode_reward_mean: -71.23796161030815\n",
      "  episode_reward_min: -200.06967686872426\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 49162\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5726.222\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 4520000\n",
      "    num_steps_trained: 4520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3165075778961182\n",
      "      kl: 0.035127829760313034\n",
      "      policy_loss: 0.01266622543334961\n",
      "      total_loss: 1421.7786865234375\n",
      "      vf_explained_var: 0.4406076967716217\n",
      "      vf_loss: 1421.76611328125\n",
      "    sample_time_ms: 27523.075\n",
      "    update_time_ms: 9.391\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.618980805154074\n",
      "  time_since_restore: 12680.551180362701\n",
      "  time_this_iter_s: 29.998335599899292\n",
      "  time_total_s: 12680.551180362701\n",
      "  timestamp: 1554820990\n",
      "  timesteps_since_restore: 4520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4520000\n",
      "  training_iteration: 452\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12680 s, 452 iter, 4520000 ts, -71.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-43-41\n",
      "  done: false\n",
      "  episode_len_mean: 81.04065040650407\n",
      "  episode_reward_max: 7.4597182829431485\n",
      "  episode_reward_mean: -104.41454498315932\n",
      "  episode_reward_min: -200.09067463758504\n",
      "  episodes_this_iter: 123\n",
      "  episodes_total: 49285\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5382.072\n",
      "    load_time_ms: 1.624\n",
      "    num_steps_sampled: 4530000\n",
      "    num_steps_trained: 4530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3435437679290771\n",
      "      kl: 0.047886911779642105\n",
      "      policy_loss: 0.020747581496834755\n",
      "      total_loss: 1345.4534912109375\n",
      "      vf_explained_var: 0.5307936072349548\n",
      "      vf_loss: 1345.432861328125\n",
      "    sample_time_ms: 26152.989\n",
      "    update_time_ms: 8.9\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.20727249157965\n",
      "  time_since_restore: 12710.63495516777\n",
      "  time_this_iter_s: 30.08377480506897\n",
      "  time_total_s: 12710.63495516777\n",
      "  timestamp: 1554821021\n",
      "  timesteps_since_restore: 4530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4530000\n",
      "  training_iteration: 453\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12710 s, 453 iter, 4530000 ts, -104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-44-11\n",
      "  done: false\n",
      "  episode_len_mean: 85.58119658119658\n",
      "  episode_reward_max: 7.715050205643518\n",
      "  episode_reward_mean: -93.90735454093326\n",
      "  episode_reward_min: -200.15352876299505\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 49402\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5336.566\n",
      "    load_time_ms: 1.567\n",
      "    num_steps_sampled: 4540000\n",
      "    num_steps_trained: 4540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3296910524368286\n",
      "      kl: 0.03572343289852142\n",
      "      policy_loss: 0.013140974566340446\n",
      "      total_loss: 1344.51611328125\n",
      "      vf_explained_var: 0.5103845596313477\n",
      "      vf_loss: 1344.5029296875\n",
      "    sample_time_ms: 25013.593\n",
      "    update_time_ms: 8.452\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.95367727046663\n",
      "  time_since_restore: 12741.541860818863\n",
      "  time_this_iter_s: 30.90690565109253\n",
      "  time_total_s: 12741.541860818863\n",
      "  timestamp: 1554821051\n",
      "  timesteps_since_restore: 4540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4540000\n",
      "  training_iteration: 454\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12741 s, 454 iter, 4540000 ts, -93.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-44-42\n",
      "  done: false\n",
      "  episode_len_mean: 84.575\n",
      "  episode_reward_max: 12.40954468488212\n",
      "  episode_reward_mean: -96.65904168910077\n",
      "  episode_reward_min: -200.11357890890866\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 49522\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5332.111\n",
      "    load_time_ms: 1.633\n",
      "    num_steps_sampled: 4550000\n",
      "    num_steps_trained: 4550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.335628628730774\n",
      "      kl: 0.043655019253492355\n",
      "      policy_loss: 0.018675975501537323\n",
      "      total_loss: 1334.9000244140625\n",
      "      vf_explained_var: 0.5397547483444214\n",
      "      vf_loss: 1334.8814697265625\n",
      "    sample_time_ms: 24973.811\n",
      "    update_time_ms: 8.383\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.32952084455039\n",
      "  time_since_restore: 12772.07625412941\n",
      "  time_this_iter_s: 30.534393310546875\n",
      "  time_total_s: 12772.07625412941\n",
      "  timestamp: 1554821082\n",
      "  timesteps_since_restore: 4550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4550000\n",
      "  training_iteration: 455\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12772 s, 455 iter, 4550000 ts, -96.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-45-13\n",
      "  done: false\n",
      "  episode_len_mean: 87.76785714285714\n",
      "  episode_reward_max: 12.132262264699877\n",
      "  episode_reward_mean: -84.9920469004381\n",
      "  episode_reward_min: -200.09461343471875\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 49634\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5311.42\n",
      "    load_time_ms: 1.625\n",
      "    num_steps_sampled: 4560000\n",
      "    num_steps_trained: 4560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.320147156715393\n",
      "      kl: 0.04237356781959534\n",
      "      policy_loss: 0.021262940019369125\n",
      "      total_loss: 1255.9466552734375\n",
      "      vf_explained_var: 0.5332782864570618\n",
      "      vf_loss: 1255.92529296875\n",
      "    sample_time_ms: 24961.801\n",
      "    update_time_ms: 7.733\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.49602345021905\n",
      "  time_since_restore: 12802.615716934204\n",
      "  time_this_iter_s: 30.53946280479431\n",
      "  time_total_s: 12802.615716934204\n",
      "  timestamp: 1554821113\n",
      "  timesteps_since_restore: 4560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4560000\n",
      "  training_iteration: 456\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12802 s, 456 iter, 4560000 ts, -85 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-45-43\n",
      "  done: false\n",
      "  episode_len_mean: 84.49166666666666\n",
      "  episode_reward_max: 12.35196653644749\n",
      "  episode_reward_mean: -95.41351783405186\n",
      "  episode_reward_min: -200.12175011865872\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 49754\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5316.504\n",
      "    load_time_ms: 1.652\n",
      "    num_steps_sampled: 4570000\n",
      "    num_steps_trained: 4570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3316669464111328\n",
      "      kl: 0.038770537823438644\n",
      "      policy_loss: 0.017402449622750282\n",
      "      total_loss: 1399.9852294921875\n",
      "      vf_explained_var: 0.5064999461174011\n",
      "      vf_loss: 1399.9677734375\n",
      "    sample_time_ms: 24951.89\n",
      "    update_time_ms: 7.711\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.70675891702593\n",
      "  time_since_restore: 12832.869250535965\n",
      "  time_this_iter_s: 30.253533601760864\n",
      "  time_total_s: 12832.869250535965\n",
      "  timestamp: 1554821143\n",
      "  timesteps_since_restore: 4570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4570000\n",
      "  training_iteration: 457\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12832 s, 457 iter, 4570000 ts, -95.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-46-13\n",
      "  done: false\n",
      "  episode_len_mean: 79.22222222222223\n",
      "  episode_reward_max: 10.245446032222395\n",
      "  episode_reward_mean: -108.18094052448114\n",
      "  episode_reward_min: -200.14388374570095\n",
      "  episodes_this_iter: 126\n",
      "  episodes_total: 49880\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5322.433\n",
      "    load_time_ms: 1.686\n",
      "    num_steps_sampled: 4580000\n",
      "    num_steps_trained: 4580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3343905210494995\n",
      "      kl: 0.04403642937541008\n",
      "      policy_loss: 0.019630614668130875\n",
      "      total_loss: 1328.982666015625\n",
      "      vf_explained_var: 0.5643230080604553\n",
      "      vf_loss: 1328.963134765625\n",
      "    sample_time_ms: 24923.921\n",
      "    update_time_ms: 7.916\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -54.09047026224058\n",
      "  time_since_restore: 12862.966752529144\n",
      "  time_this_iter_s: 30.09750199317932\n",
      "  time_total_s: 12862.966752529144\n",
      "  timestamp: 1554821173\n",
      "  timesteps_since_restore: 4580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4580000\n",
      "  training_iteration: 458\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12862 s, 458 iter, 4580000 ts, -108 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-46-43\n",
      "  done: false\n",
      "  episode_len_mean: 87.47826086956522\n",
      "  episode_reward_max: 13.262542196129232\n",
      "  episode_reward_mean: -86.97744946102246\n",
      "  episode_reward_min: -200.2547188031256\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 49995\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5314.994\n",
      "    load_time_ms: 1.723\n",
      "    num_steps_sampled: 4590000\n",
      "    num_steps_trained: 4590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3231557607650757\n",
      "      kl: 0.07144436240196228\n",
      "      policy_loss: 0.024551229551434517\n",
      "      total_loss: 1411.9659423828125\n",
      "      vf_explained_var: 0.518480658531189\n",
      "      vf_loss: 1411.9415283203125\n",
      "    sample_time_ms: 24931.57\n",
      "    update_time_ms: 7.625\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.48872473051122\n",
      "  time_since_restore: 12893.18877530098\n",
      "  time_this_iter_s: 30.222022771835327\n",
      "  time_total_s: 12893.18877530098\n",
      "  timestamp: 1554821203\n",
      "  timesteps_since_restore: 4590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4590000\n",
      "  training_iteration: 459\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12893 s, 459 iter, 4590000 ts, -87 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-47-14\n",
      "  done: false\n",
      "  episode_len_mean: 91.26605504587155\n",
      "  episode_reward_max: 11.21699538572056\n",
      "  episode_reward_mean: -76.98658395061018\n",
      "  episode_reward_min: -200.05135599197456\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 50104\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5316.992\n",
      "    load_time_ms: 1.691\n",
      "    num_steps_sampled: 4600000\n",
      "    num_steps_trained: 4600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3137354850769043\n",
      "      kl: 0.03483342379331589\n",
      "      policy_loss: 0.01418463047593832\n",
      "      total_loss: 1449.8914794921875\n",
      "      vf_explained_var: 0.47452500462532043\n",
      "      vf_loss: 1449.877197265625\n",
      "    sample_time_ms: 24961.554\n",
      "    update_time_ms: 7.178\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.4932919753051\n",
      "  time_since_restore: 12923.482724905014\n",
      "  time_this_iter_s: 30.293949604034424\n",
      "  time_total_s: 12923.482724905014\n",
      "  timestamp: 1554821234\n",
      "  timesteps_since_restore: 4600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4600000\n",
      "  training_iteration: 460\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12923 s, 460 iter, 4600000 ts, -77 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-47-44\n",
      "  done: false\n",
      "  episode_len_mean: 87.2\n",
      "  episode_reward_max: 11.27219885622319\n",
      "  episode_reward_mean: -86.99251883284403\n",
      "  episode_reward_min: -200.06547759926787\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 50219\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5302.573\n",
      "    load_time_ms: 1.727\n",
      "    num_steps_sampled: 4610000\n",
      "    num_steps_trained: 4610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.323866844177246\n",
      "      kl: 0.040515583008527756\n",
      "      policy_loss: 0.014483628794550896\n",
      "      total_loss: 1417.9171142578125\n",
      "      vf_explained_var: 0.5044291615486145\n",
      "      vf_loss: 1417.902587890625\n",
      "    sample_time_ms: 24990.46\n",
      "    update_time_ms: 6.927\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.49625941642201\n",
      "  time_since_restore: 12953.798266887665\n",
      "  time_this_iter_s: 30.315541982650757\n",
      "  time_total_s: 12953.798266887665\n",
      "  timestamp: 1554821264\n",
      "  timesteps_since_restore: 4610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4610000\n",
      "  training_iteration: 461\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12953 s, 461 iter, 4610000 ts, -87 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-48-15\n",
      "  done: false\n",
      "  episode_len_mean: 89.39285714285714\n",
      "  episode_reward_max: 12.932239885825123\n",
      "  episode_reward_mean: -81.2907133693378\n",
      "  episode_reward_min: -200.4059041270727\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 50331\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5297.953\n",
      "    load_time_ms: 1.704\n",
      "    num_steps_sampled: 4620000\n",
      "    num_steps_trained: 4620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.312104344367981\n",
      "      kl: 0.047916095703840256\n",
      "      policy_loss: 0.018094900995492935\n",
      "      total_loss: 1348.6719970703125\n",
      "      vf_explained_var: 0.49573686718940735\n",
      "      vf_loss: 1348.65380859375\n",
      "    sample_time_ms: 25047.517\n",
      "    update_time_ms: 6.984\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.6453566846689\n",
      "  time_since_restore: 12984.319066286087\n",
      "  time_this_iter_s: 30.52079939842224\n",
      "  time_total_s: 12984.319066286087\n",
      "  timestamp: 1554821295\n",
      "  timesteps_since_restore: 4620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4620000\n",
      "  training_iteration: 462\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 12984 s, 462 iter, 4620000 ts, -81.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-48-45\n",
      "  done: false\n",
      "  episode_len_mean: 89.44642857142857\n",
      "  episode_reward_max: 11.45942122134213\n",
      "  episode_reward_mean: -84.24518387443757\n",
      "  episode_reward_min: -200.14777206625865\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 50443\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5306.363\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 4630000\n",
      "    num_steps_trained: 4630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.318987488746643\n",
      "      kl: 0.044912029057741165\n",
      "      policy_loss: 0.01704130321741104\n",
      "      total_loss: 1470.9046630859375\n",
      "      vf_explained_var: 0.4586135745048523\n",
      "      vf_loss: 1470.8875732421875\n",
      "    sample_time_ms: 25032.658\n",
      "    update_time_ms: 7.493\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.122591937218786\n",
      "  time_since_restore: 13014.344400644302\n",
      "  time_this_iter_s: 30.025334358215332\n",
      "  time_total_s: 13014.344400644302\n",
      "  timestamp: 1554821325\n",
      "  timesteps_since_restore: 4630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4630000\n",
      "  training_iteration: 463\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13014 s, 463 iter, 4630000 ts, -84.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-49-15\n",
      "  done: false\n",
      "  episode_len_mean: 88.29203539823008\n",
      "  episode_reward_max: 10.872737693607347\n",
      "  episode_reward_mean: -84.70288528452853\n",
      "  episode_reward_min: -200.16033418060016\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 50556\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5298.617\n",
      "    load_time_ms: 1.663\n",
      "    num_steps_sampled: 4640000\n",
      "    num_steps_trained: 4640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3164821863174438\n",
      "      kl: 0.055419616401195526\n",
      "      policy_loss: 0.02907402440905571\n",
      "      total_loss: 1410.0576171875\n",
      "      vf_explained_var: 0.47217079997062683\n",
      "      vf_loss: 1410.0284423828125\n",
      "    sample_time_ms: 24956.638\n",
      "    update_time_ms: 7.621\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.351442642264296\n",
      "  time_since_restore: 13044.409930229187\n",
      "  time_this_iter_s: 30.065529584884644\n",
      "  time_total_s: 13044.409930229187\n",
      "  timestamp: 1554821355\n",
      "  timesteps_since_restore: 4640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4640000\n",
      "  training_iteration: 464\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13044 s, 464 iter, 4640000 ts, -84.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-49-45\n",
      "  done: false\n",
      "  episode_len_mean: 87.59292035398231\n",
      "  episode_reward_max: 10.54771556274967\n",
      "  episode_reward_mean: -85.54992919338373\n",
      "  episode_reward_min: -200.0894362414465\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 50669\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5292.439\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 4650000\n",
      "    num_steps_trained: 4650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3215664625167847\n",
      "      kl: 0.04015808925032616\n",
      "      policy_loss: 0.0214688740670681\n",
      "      total_loss: 1385.14794921875\n",
      "      vf_explained_var: 0.4974150061607361\n",
      "      vf_loss: 1385.1263427734375\n",
      "    sample_time_ms: 24912.419\n",
      "    update_time_ms: 7.636\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.77496459669186\n",
      "  time_since_restore: 13074.440683603287\n",
      "  time_this_iter_s: 30.03075337409973\n",
      "  time_total_s: 13074.440683603287\n",
      "  timestamp: 1554821385\n",
      "  timesteps_since_restore: 4650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4650000\n",
      "  training_iteration: 465\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13074 s, 465 iter, 4650000 ts, -85.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-50-15\n",
      "  done: false\n",
      "  episode_len_mean: 88.74561403508773\n",
      "  episode_reward_max: 10.265545158038172\n",
      "  episode_reward_mean: -82.23279153903383\n",
      "  episode_reward_min: -200.02471339689953\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 50783\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5280.035\n",
      "    load_time_ms: 1.625\n",
      "    num_steps_sampled: 4660000\n",
      "    num_steps_trained: 4660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.324757695198059\n",
      "      kl: 0.041878826916217804\n",
      "      policy_loss: 0.021107779815793037\n",
      "      total_loss: 1370.0322265625\n",
      "      vf_explained_var: 0.49574676156044006\n",
      "      vf_loss: 1370.010986328125\n",
      "    sample_time_ms: 24880.848\n",
      "    update_time_ms: 7.484\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.116395769516906\n",
      "  time_since_restore: 13104.539181947708\n",
      "  time_this_iter_s: 30.098498344421387\n",
      "  time_total_s: 13104.539181947708\n",
      "  timestamp: 1554821415\n",
      "  timesteps_since_restore: 4660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4660000\n",
      "  training_iteration: 466\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13104 s, 466 iter, 4660000 ts, -82.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-50-46\n",
      "  done: false\n",
      "  episode_len_mean: 86.7719298245614\n",
      "  episode_reward_max: 13.177031078950286\n",
      "  episode_reward_mean: -89.03160272724394\n",
      "  episode_reward_min: -200.10443576268983\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 50897\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5279.44\n",
      "    load_time_ms: 1.658\n",
      "    num_steps_sampled: 4670000\n",
      "    num_steps_trained: 4670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3344141244888306\n",
      "      kl: 0.04133780300617218\n",
      "      policy_loss: 0.017728600651025772\n",
      "      total_loss: 1353.6173095703125\n",
      "      vf_explained_var: 0.5072227716445923\n",
      "      vf_loss: 1353.599609375\n",
      "    sample_time_ms: 24924.721\n",
      "    update_time_ms: 7.144\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.51580136362197\n",
      "  time_since_restore: 13135.223433732986\n",
      "  time_this_iter_s: 30.68425178527832\n",
      "  time_total_s: 13135.223433732986\n",
      "  timestamp: 1554821446\n",
      "  timesteps_since_restore: 4670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4670000\n",
      "  training_iteration: 467\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13135 s, 467 iter, 4670000 ts, -89 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-51-16\n",
      "  done: false\n",
      "  episode_len_mean: 90.0625\n",
      "  episode_reward_max: 11.74777372653476\n",
      "  episode_reward_mean: -80.2677929519864\n",
      "  episode_reward_min: -200.10868279706168\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 51009\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5272.215\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 4680000\n",
      "    num_steps_trained: 4680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3116686344146729\n",
      "      kl: 0.04602457210421562\n",
      "      policy_loss: 0.018680833280086517\n",
      "      total_loss: 1417.61572265625\n",
      "      vf_explained_var: 0.4670734405517578\n",
      "      vf_loss: 1417.596923828125\n",
      "    sample_time_ms: 24941.595\n",
      "    update_time_ms: 7.059\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.1338964759932\n",
      "  time_since_restore: 13165.418900728226\n",
      "  time_this_iter_s: 30.195466995239258\n",
      "  time_total_s: 13165.418900728226\n",
      "  timestamp: 1554821476\n",
      "  timesteps_since_restore: 4680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4680000\n",
      "  training_iteration: 468\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13165 s, 468 iter, 4680000 ts, -80.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-51-46\n",
      "  done: false\n",
      "  episode_len_mean: 92.0925925925926\n",
      "  episode_reward_max: 12.216050353996922\n",
      "  episode_reward_mean: -75.63479813281045\n",
      "  episode_reward_min: -200.25351703159117\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 51117\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5283.691\n",
      "    load_time_ms: 1.699\n",
      "    num_steps_sampled: 4690000\n",
      "    num_steps_trained: 4690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3191039562225342\n",
      "      kl: 0.04333561658859253\n",
      "      policy_loss: 0.01745591126382351\n",
      "      total_loss: 1455.794921875\n",
      "      vf_explained_var: 0.4359040856361389\n",
      "      vf_loss: 1455.777587890625\n",
      "    sample_time_ms: 24935.77\n",
      "    update_time_ms: 7.05\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.81739906640522\n",
      "  time_since_restore: 13195.696171760559\n",
      "  time_this_iter_s: 30.277271032333374\n",
      "  time_total_s: 13195.696171760559\n",
      "  timestamp: 1554821506\n",
      "  timesteps_since_restore: 4690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4690000\n",
      "  training_iteration: 469\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13195 s, 469 iter, 4690000 ts, -75.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-52-17\n",
      "  done: false\n",
      "  episode_len_mean: 87.93859649122807\n",
      "  episode_reward_max: 10.381605105481043\n",
      "  episode_reward_mean: -87.97191780683426\n",
      "  episode_reward_min: -200.2319292261137\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 51231\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5283.118\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 4700000\n",
      "    num_steps_trained: 4700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.319284439086914\n",
      "      kl: 0.03901566192507744\n",
      "      policy_loss: 0.012568650767207146\n",
      "      total_loss: 1369.2821044921875\n",
      "      vf_explained_var: 0.5252442359924316\n",
      "      vf_loss: 1369.2694091796875\n",
      "    sample_time_ms: 24990.122\n",
      "    update_time_ms: 7.456\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.98595890341713\n",
      "  time_since_restore: 13226.53140115738\n",
      "  time_this_iter_s: 30.83522939682007\n",
      "  time_total_s: 13226.53140115738\n",
      "  timestamp: 1554821537\n",
      "  timesteps_since_restore: 4700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4700000\n",
      "  training_iteration: 470\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13226 s, 470 iter, 4700000 ts, -88 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-52-47\n",
      "  done: false\n",
      "  episode_len_mean: 82.10655737704919\n",
      "  episode_reward_max: 12.999952327080464\n",
      "  episode_reward_mean: -101.69765767127817\n",
      "  episode_reward_min: -200.0990403228859\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 51353\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5280.296\n",
      "    load_time_ms: 1.67\n",
      "    num_steps_sampled: 4710000\n",
      "    num_steps_trained: 4710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3261815309524536\n",
      "      kl: 0.03465675562620163\n",
      "      policy_loss: 0.014179827645421028\n",
      "      total_loss: 1350.6175537109375\n",
      "      vf_explained_var: 0.5404672622680664\n",
      "      vf_loss: 1350.603515625\n",
      "    sample_time_ms: 24969.392\n",
      "    update_time_ms: 7.65\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.84882883563908\n",
      "  time_since_restore: 13256.608092069626\n",
      "  time_this_iter_s: 30.076690912246704\n",
      "  time_total_s: 13256.608092069626\n",
      "  timestamp: 1554821567\n",
      "  timesteps_since_restore: 4710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4710000\n",
      "  training_iteration: 471\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13256 s, 471 iter, 4710000 ts, -102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-53-17\n",
      "  done: false\n",
      "  episode_len_mean: 84.72649572649573\n",
      "  episode_reward_max: 11.048828761942197\n",
      "  episode_reward_mean: -95.55062479950064\n",
      "  episode_reward_min: -200.090465603574\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 51470\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5265.24\n",
      "    load_time_ms: 1.657\n",
      "    num_steps_sampled: 4720000\n",
      "    num_steps_trained: 4720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.328251600265503\n",
      "      kl: 0.045344382524490356\n",
      "      policy_loss: 0.015164871700108051\n",
      "      total_loss: 1360.734130859375\n",
      "      vf_explained_var: 0.5339981317520142\n",
      "      vf_loss: 1360.718994140625\n",
      "    sample_time_ms: 24927.024\n",
      "    update_time_ms: 7.824\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.77531239975033\n",
      "  time_since_restore: 13286.557555675507\n",
      "  time_this_iter_s: 29.949463605880737\n",
      "  time_total_s: 13286.557555675507\n",
      "  timestamp: 1554821597\n",
      "  timesteps_since_restore: 4720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4720000\n",
      "  training_iteration: 472\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13286 s, 472 iter, 4720000 ts, -95.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-53-48\n",
      "  done: false\n",
      "  episode_len_mean: 89.52212389380531\n",
      "  episode_reward_max: 9.703405087830586\n",
      "  episode_reward_mean: -83.00846568422118\n",
      "  episode_reward_min: -200.08988934985297\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 51583\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5249.485\n",
      "    load_time_ms: 1.674\n",
      "    num_steps_sampled: 4730000\n",
      "    num_steps_trained: 4730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.323843002319336\n",
      "      kl: 0.04029982537031174\n",
      "      policy_loss: 0.015298986807465553\n",
      "      total_loss: 1388.1199951171875\n",
      "      vf_explained_var: 0.5047216415405273\n",
      "      vf_loss: 1388.1046142578125\n",
      "    sample_time_ms: 24970.442\n",
      "    update_time_ms: 7.415\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.50423284211059\n",
      "  time_since_restore: 13316.859290361404\n",
      "  time_this_iter_s: 30.301734685897827\n",
      "  time_total_s: 13316.859290361404\n",
      "  timestamp: 1554821628\n",
      "  timesteps_since_restore: 4730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4730000\n",
      "  training_iteration: 473\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13316 s, 473 iter, 4730000 ts, -83 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-54-18\n",
      "  done: false\n",
      "  episode_len_mean: 90.23423423423424\n",
      "  episode_reward_max: 10.35682079578035\n",
      "  episode_reward_mean: -81.26642872879303\n",
      "  episode_reward_min: -200.1584620345899\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 51694\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5253.715\n",
      "    load_time_ms: 1.734\n",
      "    num_steps_sampled: 4740000\n",
      "    num_steps_trained: 4740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3279377222061157\n",
      "      kl: 0.034788988530635834\n",
      "      policy_loss: 0.01757415011525154\n",
      "      total_loss: 1485.7872314453125\n",
      "      vf_explained_var: 0.4790535867214203\n",
      "      vf_loss: 1485.769775390625\n",
      "    sample_time_ms: 24949.729\n",
      "    update_time_ms: 8.005\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.63321436439651\n",
      "  time_since_restore: 13346.770609378815\n",
      "  time_this_iter_s: 29.91131901741028\n",
      "  time_total_s: 13346.770609378815\n",
      "  timestamp: 1554821658\n",
      "  timesteps_since_restore: 4740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4740000\n",
      "  training_iteration: 474\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13346 s, 474 iter, 4740000 ts, -81.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-54-47\n",
      "  done: false\n",
      "  episode_len_mean: 92.70370370370371\n",
      "  episode_reward_max: 9.696088798725732\n",
      "  episode_reward_mean: -73.89719474120731\n",
      "  episode_reward_min: -200.11561503786518\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 51802\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5240.078\n",
      "    load_time_ms: 1.784\n",
      "    num_steps_sampled: 4750000\n",
      "    num_steps_trained: 4750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3314622640609741\n",
      "      kl: 0.03653222322463989\n",
      "      policy_loss: 0.0158742256462574\n",
      "      total_loss: 1356.2430419921875\n",
      "      vf_explained_var: 0.5409929156303406\n",
      "      vf_loss: 1356.2271728515625\n",
      "    sample_time_ms: 24941.935\n",
      "    update_time_ms: 8.494\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.94859737060365\n",
      "  time_since_restore: 13376.598752498627\n",
      "  time_this_iter_s: 29.82814311981201\n",
      "  time_total_s: 13376.598752498627\n",
      "  timestamp: 1554821687\n",
      "  timesteps_since_restore: 4750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4750000\n",
      "  training_iteration: 475\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13376 s, 475 iter, 4750000 ts, -73.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-55-18\n",
      "  done: false\n",
      "  episode_len_mean: 89.6036036036036\n",
      "  episode_reward_max: 10.662973374820936\n",
      "  episode_reward_mean: -81.09109926741161\n",
      "  episode_reward_min: -200.12772978154624\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 51913\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5262.397\n",
      "    load_time_ms: 1.768\n",
      "    num_steps_sampled: 4760000\n",
      "    num_steps_trained: 4760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.330433964729309\n",
      "      kl: 0.0546843595802784\n",
      "      policy_loss: 0.022691842168569565\n",
      "      total_loss: 1413.774658203125\n",
      "      vf_explained_var: 0.5171296000480652\n",
      "      vf_loss: 1413.751953125\n",
      "    sample_time_ms: 24950.981\n",
      "    update_time_ms: 8.495\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.545549633705804\n",
      "  time_since_restore: 13407.00673866272\n",
      "  time_this_iter_s: 30.407986164093018\n",
      "  time_total_s: 13407.00673866272\n",
      "  timestamp: 1554821718\n",
      "  timesteps_since_restore: 4760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4760000\n",
      "  training_iteration: 476\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13407 s, 476 iter, 4760000 ts, -81.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-55-48\n",
      "  done: false\n",
      "  episode_len_mean: 88.98214285714286\n",
      "  episode_reward_max: 10.156899577446147\n",
      "  episode_reward_mean: -84.1529051136891\n",
      "  episode_reward_min: -200.14508193167188\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 52025\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5237.647\n",
      "    load_time_ms: 1.707\n",
      "    num_steps_sampled: 4770000\n",
      "    num_steps_trained: 4770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3302080631256104\n",
      "      kl: 0.04300336912274361\n",
      "      policy_loss: 0.018086234107613564\n",
      "      total_loss: 1451.172119140625\n",
      "      vf_explained_var: 0.48917388916015625\n",
      "      vf_loss: 1451.154052734375\n",
      "    sample_time_ms: 24925.411\n",
      "    update_time_ms: 8.589\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.07645255684455\n",
      "  time_since_restore: 13437.183633327484\n",
      "  time_this_iter_s: 30.176894664764404\n",
      "  time_total_s: 13437.183633327484\n",
      "  timestamp: 1554821748\n",
      "  timesteps_since_restore: 4770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4770000\n",
      "  training_iteration: 477\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13437 s, 477 iter, 4770000 ts, -84.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-56-19\n",
      "  done: false\n",
      "  episode_len_mean: 89.09734513274336\n",
      "  episode_reward_max: 10.298564053438447\n",
      "  episode_reward_mean: -84.644366262978\n",
      "  episode_reward_min: -200.16250130319543\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 52138\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5254.022\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 4780000\n",
      "    num_steps_trained: 4780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3351333141326904\n",
      "      kl: 0.04468945786356926\n",
      "      policy_loss: 0.01940128207206726\n",
      "      total_loss: 1463.4130859375\n",
      "      vf_explained_var: 0.46383553743362427\n",
      "      vf_loss: 1463.393798828125\n",
      "    sample_time_ms: 24926.586\n",
      "    update_time_ms: 8.479\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.322183131489\n",
      "  time_since_restore: 13467.554134368896\n",
      "  time_this_iter_s: 30.370501041412354\n",
      "  time_total_s: 13467.554134368896\n",
      "  timestamp: 1554821779\n",
      "  timesteps_since_restore: 4780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4780000\n",
      "  training_iteration: 478\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13467 s, 478 iter, 4780000 ts, -84.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-56-49\n",
      "  done: false\n",
      "  episode_len_mean: 86.23478260869565\n",
      "  episode_reward_max: 10.86019240999961\n",
      "  episode_reward_mean: -91.94165201456072\n",
      "  episode_reward_min: -200.18213716017928\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 52253\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5240.894\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 4790000\n",
      "    num_steps_trained: 4790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.340118169784546\n",
      "      kl: 0.03778010606765747\n",
      "      policy_loss: 0.016306327655911446\n",
      "      total_loss: 1333.1654052734375\n",
      "      vf_explained_var: 0.5379194021224976\n",
      "      vf_loss: 1333.1492919921875\n",
      "    sample_time_ms: 24917.763\n",
      "    update_time_ms: 9.205\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.970826007280344\n",
      "  time_since_restore: 13497.619233369827\n",
      "  time_this_iter_s: 30.065099000930786\n",
      "  time_total_s: 13497.619233369827\n",
      "  timestamp: 1554821809\n",
      "  timesteps_since_restore: 4790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4790000\n",
      "  training_iteration: 479\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13497 s, 479 iter, 4790000 ts, -91.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-57-19\n",
      "  done: false\n",
      "  episode_len_mean: 89.39285714285714\n",
      "  episode_reward_max: 11.243130945861601\n",
      "  episode_reward_mean: -82.00414701052323\n",
      "  episode_reward_min: -200.06027631744624\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 52365\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5233.926\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 4800000\n",
      "    num_steps_trained: 4800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3332971334457397\n",
      "      kl: 0.03641747310757637\n",
      "      policy_loss: 0.01634993590414524\n",
      "      total_loss: 1385.254150390625\n",
      "      vf_explained_var: 0.4912162125110626\n",
      "      vf_loss: 1385.2379150390625\n",
      "    sample_time_ms: 24838.255\n",
      "    update_time_ms: 8.801\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.00207350526163\n",
      "  time_since_restore: 13527.584554672241\n",
      "  time_this_iter_s: 29.96532130241394\n",
      "  time_total_s: 13527.584554672241\n",
      "  timestamp: 1554821839\n",
      "  timesteps_since_restore: 4800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4800000\n",
      "  training_iteration: 480\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13527 s, 480 iter, 4800000 ts, -82 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-57-50\n",
      "  done: false\n",
      "  episode_len_mean: 88.94690265486726\n",
      "  episode_reward_max: 8.56551903217488\n",
      "  episode_reward_mean: -85.11771018250114\n",
      "  episode_reward_min: -200.11877950504595\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 52478\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5248.859\n",
      "    load_time_ms: 1.715\n",
      "    num_steps_sampled: 4810000\n",
      "    num_steps_trained: 4810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.334297776222229\n",
      "      kl: 0.048027317970991135\n",
      "      policy_loss: 0.023175286129117012\n",
      "      total_loss: 1449.5498046875\n",
      "      vf_explained_var: 0.4712112545967102\n",
      "      vf_loss: 1449.526611328125\n",
      "    sample_time_ms: 24897.689\n",
      "    update_time_ms: 8.521\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.55885509125057\n",
      "  time_since_restore: 13558.405106782913\n",
      "  time_this_iter_s: 30.820552110671997\n",
      "  time_total_s: 13558.405106782913\n",
      "  timestamp: 1554821870\n",
      "  timesteps_since_restore: 4810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4810000\n",
      "  training_iteration: 481\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13558 s, 481 iter, 4810000 ts, -85.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-58-20\n",
      "  done: false\n",
      "  episode_len_mean: 85.05982905982906\n",
      "  episode_reward_max: 11.880047789287604\n",
      "  episode_reward_mean: -95.88645876451099\n",
      "  episode_reward_min: -200.10926965099713\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 52595\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5258.578\n",
      "    load_time_ms: 1.723\n",
      "    num_steps_sampled: 4820000\n",
      "    num_steps_trained: 4820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.339361548423767\n",
      "      kl: 0.039340827614068985\n",
      "      policy_loss: 0.016699999570846558\n",
      "      total_loss: 1346.3463134765625\n",
      "      vf_explained_var: 0.533003568649292\n",
      "      vf_loss: 1346.3297119140625\n",
      "    sample_time_ms: 24931.736\n",
      "    update_time_ms: 8.163\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.9432293822555\n",
      "  time_since_restore: 13588.789472341537\n",
      "  time_this_iter_s: 30.384365558624268\n",
      "  time_total_s: 13588.789472341537\n",
      "  timestamp: 1554821900\n",
      "  timesteps_since_restore: 4820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4820000\n",
      "  training_iteration: 482\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13588 s, 482 iter, 4820000 ts, -95.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-58-51\n",
      "  done: false\n",
      "  episode_len_mean: 87.78070175438596\n",
      "  episode_reward_max: 8.001597291032974\n",
      "  episode_reward_mean: -87.7969559154988\n",
      "  episode_reward_min: -200.13614972627153\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 52709\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5370.888\n",
      "    load_time_ms: 1.766\n",
      "    num_steps_sampled: 4830000\n",
      "    num_steps_trained: 4830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3447481393814087\n",
      "      kl: 0.03139163926243782\n",
      "      policy_loss: 0.015636377036571503\n",
      "      total_loss: 1407.7955322265625\n",
      "      vf_explained_var: 0.5001551508903503\n",
      "      vf_loss: 1407.7799072265625\n",
      "    sample_time_ms: 24914.758\n",
      "    update_time_ms: 8.229\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.898477957749414\n",
      "  time_since_restore: 13620.04211139679\n",
      "  time_this_iter_s: 31.252639055252075\n",
      "  time_total_s: 13620.04211139679\n",
      "  timestamp: 1554821931\n",
      "  timesteps_since_restore: 4830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4830000\n",
      "  training_iteration: 483\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13620 s, 483 iter, 4830000 ts, -87.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-59-21\n",
      "  done: false\n",
      "  episode_len_mean: 83.42148760330579\n",
      "  episode_reward_max: 11.216635848822406\n",
      "  episode_reward_mean: -97.23469638017603\n",
      "  episode_reward_min: -200.08531673727714\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 52830\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5370.756\n",
      "    load_time_ms: 1.677\n",
      "    num_steps_sampled: 4840000\n",
      "    num_steps_trained: 4840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3561195135116577\n",
      "      kl: 0.04726690053939819\n",
      "      policy_loss: 0.02178027667105198\n",
      "      total_loss: 1332.75\n",
      "      vf_explained_var: 0.5248848795890808\n",
      "      vf_loss: 1332.7281494140625\n",
      "    sample_time_ms: 24928.211\n",
      "    update_time_ms: 8.113\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.61734819008802\n",
      "  time_since_restore: 13650.07837176323\n",
      "  time_this_iter_s: 30.03626036643982\n",
      "  time_total_s: 13650.07837176323\n",
      "  timestamp: 1554821961\n",
      "  timesteps_since_restore: 4840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4840000\n",
      "  training_iteration: 484\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13650 s, 484 iter, 4840000 ts, -97.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_16-59-51\n",
      "  done: false\n",
      "  episode_len_mean: 88.24107142857143\n",
      "  episode_reward_max: 12.197211832262708\n",
      "  episode_reward_mean: -83.66405100285594\n",
      "  episode_reward_min: -200.07351452221758\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 52942\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5391.295\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 4850000\n",
      "    num_steps_trained: 4850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3488643169403076\n",
      "      kl: 0.04189702123403549\n",
      "      policy_loss: 0.01920901983976364\n",
      "      total_loss: 1467.379150390625\n",
      "      vf_explained_var: 0.4539704918861389\n",
      "      vf_loss: 1467.3599853515625\n",
      "    sample_time_ms: 24910.514\n",
      "    update_time_ms: 7.659\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.83202550142797\n",
      "  time_since_restore: 13679.928456306458\n",
      "  time_this_iter_s: 29.85008454322815\n",
      "  time_total_s: 13679.928456306458\n",
      "  timestamp: 1554821991\n",
      "  timesteps_since_restore: 4850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4850000\n",
      "  training_iteration: 485\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13679 s, 485 iter, 4850000 ts, -83.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-00-21\n",
      "  done: false\n",
      "  episode_len_mean: 93.41121495327103\n",
      "  episode_reward_max: 8.862255726910755\n",
      "  episode_reward_mean: -71.48816981547655\n",
      "  episode_reward_min: -200.1108005928819\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 53049\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5371.181\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 4860000\n",
      "    num_steps_trained: 4860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3481130599975586\n",
      "      kl: 0.048767175525426865\n",
      "      policy_loss: 0.02688577212393284\n",
      "      total_loss: 1423.418701171875\n",
      "      vf_explained_var: 0.47169190645217896\n",
      "      vf_loss: 1423.391845703125\n",
      "    sample_time_ms: 24888.756\n",
      "    update_time_ms: 8.381\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.74408490773828\n",
      "  time_since_restore: 13709.923736810684\n",
      "  time_this_iter_s: 29.995280504226685\n",
      "  time_total_s: 13709.923736810684\n",
      "  timestamp: 1554822021\n",
      "  timesteps_since_restore: 4860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4860000\n",
      "  training_iteration: 486\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13709 s, 486 iter, 4860000 ts, -71.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-00-52\n",
      "  done: false\n",
      "  episode_len_mean: 86.96521739130435\n",
      "  episode_reward_max: 11.755508335087288\n",
      "  episode_reward_mean: -88.9933594979588\n",
      "  episode_reward_min: -200.21822629014432\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 53164\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5407.999\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 4870000\n",
      "    num_steps_trained: 4870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3659026622772217\n",
      "      kl: 0.051670778542757034\n",
      "      policy_loss: 0.02550770714879036\n",
      "      total_loss: 1383.5252685546875\n",
      "      vf_explained_var: 0.5092660784721375\n",
      "      vf_loss: 1383.499755859375\n",
      "    sample_time_ms: 24920.534\n",
      "    update_time_ms: 8.493\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.496679748979396\n",
      "  time_since_restore: 13740.795166015625\n",
      "  time_this_iter_s: 30.871429204940796\n",
      "  time_total_s: 13740.795166015625\n",
      "  timestamp: 1554822052\n",
      "  timesteps_since_restore: 4870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4870000\n",
      "  training_iteration: 487\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13740 s, 487 iter, 4870000 ts, -89 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-01-22\n",
      "  done: false\n",
      "  episode_len_mean: 93.86915887850468\n",
      "  episode_reward_max: 6.19708004073904\n",
      "  episode_reward_mean: -69.64448134996451\n",
      "  episode_reward_min: -200.08852598074446\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 53271\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5389.505\n",
      "    load_time_ms: 1.652\n",
      "    num_steps_sampled: 4880000\n",
      "    num_steps_trained: 4880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3559439182281494\n",
      "      kl: 0.045266684144735336\n",
      "      policy_loss: 0.018395600840449333\n",
      "      total_loss: 1469.24853515625\n",
      "      vf_explained_var: 0.42782264947891235\n",
      "      vf_loss: 1469.2301025390625\n",
      "    sample_time_ms: 24866.462\n",
      "    update_time_ms: 8.369\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.822240674982254\n",
      "  time_since_restore: 13770.438174962997\n",
      "  time_this_iter_s: 29.643008947372437\n",
      "  time_total_s: 13770.438174962997\n",
      "  timestamp: 1554822082\n",
      "  timesteps_since_restore: 4880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4880000\n",
      "  training_iteration: 488\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13770 s, 488 iter, 4880000 ts, -69.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-01-52\n",
      "  done: false\n",
      "  episode_len_mean: 92.75925925925925\n",
      "  episode_reward_max: 9.236295493649052\n",
      "  episode_reward_mean: -72.18094345208463\n",
      "  episode_reward_min: -200.0988888532395\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 53379\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5393.614\n",
      "    load_time_ms: 1.682\n",
      "    num_steps_sampled: 4890000\n",
      "    num_steps_trained: 4890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3541940450668335\n",
      "      kl: 0.03505818173289299\n",
      "      policy_loss: 0.01579061895608902\n",
      "      total_loss: 1505.4593505859375\n",
      "      vf_explained_var: 0.42952895164489746\n",
      "      vf_loss: 1505.443359375\n",
      "    sample_time_ms: 24890.321\n",
      "    update_time_ms: 7.967\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.09047172604232\n",
      "  time_since_restore: 13800.781237840652\n",
      "  time_this_iter_s: 30.34306287765503\n",
      "  time_total_s: 13800.781237840652\n",
      "  timestamp: 1554822112\n",
      "  timesteps_since_restore: 4890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4890000\n",
      "  training_iteration: 489\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13800 s, 489 iter, 4890000 ts, -72.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-02-22\n",
      "  done: false\n",
      "  episode_len_mean: 91.1743119266055\n",
      "  episode_reward_max: 6.955361034875853\n",
      "  episode_reward_mean: -79.00471650199275\n",
      "  episode_reward_min: -200.08538584595462\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 53488\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5428.694\n",
      "    load_time_ms: 1.675\n",
      "    num_steps_sampled: 4900000\n",
      "    num_steps_trained: 4900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.360198974609375\n",
      "      kl: 0.03965168446302414\n",
      "      policy_loss: 0.015509872697293758\n",
      "      total_loss: 1405.9637451171875\n",
      "      vf_explained_var: 0.47684547305107117\n",
      "      vf_loss: 1405.9483642578125\n",
      "    sample_time_ms: 24848.781\n",
      "    update_time_ms: 7.874\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.50235825099635\n",
      "  time_since_restore: 13830.682747125626\n",
      "  time_this_iter_s: 29.901509284973145\n",
      "  time_total_s: 13830.682747125626\n",
      "  timestamp: 1554822142\n",
      "  timesteps_since_restore: 4900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4900000\n",
      "  training_iteration: 490\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13830 s, 490 iter, 4900000 ts, -79 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-02-52\n",
      "  done: false\n",
      "  episode_len_mean: 82.67768595041322\n",
      "  episode_reward_max: 12.945063641600537\n",
      "  episode_reward_mean: -100.66074316704332\n",
      "  episode_reward_min: -200.1514942552817\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 53609\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5424.679\n",
      "    load_time_ms: 1.672\n",
      "    num_steps_sampled: 4910000\n",
      "    num_steps_trained: 4910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3678622245788574\n",
      "      kl: 0.03674580529332161\n",
      "      policy_loss: 0.016596464440226555\n",
      "      total_loss: 1303.0350341796875\n",
      "      vf_explained_var: 0.5417089462280273\n",
      "      vf_loss: 1303.018310546875\n",
      "    sample_time_ms: 24783.644\n",
      "    update_time_ms: 7.802\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.33037158352167\n",
      "  time_since_restore: 13860.809974908829\n",
      "  time_this_iter_s: 30.127227783203125\n",
      "  time_total_s: 13860.809974908829\n",
      "  timestamp: 1554822172\n",
      "  timesteps_since_restore: 4910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4910000\n",
      "  training_iteration: 491\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13860 s, 491 iter, 4910000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-03-23\n",
      "  done: false\n",
      "  episode_len_mean: 88.54385964912281\n",
      "  episode_reward_max: 9.90615485374523\n",
      "  episode_reward_mean: -84.72177714261366\n",
      "  episode_reward_min: -200.11288230617419\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 53723\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5428.274\n",
      "    load_time_ms: 1.708\n",
      "    num_steps_sampled: 4920000\n",
      "    num_steps_trained: 4920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.346476674079895\n",
      "      kl: 0.05203885957598686\n",
      "      policy_loss: 0.023631906136870384\n",
      "      total_loss: 1416.320556640625\n",
      "      vf_explained_var: 0.4939211308956146\n",
      "      vf_loss: 1416.296875\n",
      "    sample_time_ms: 24769.699\n",
      "    update_time_ms: 7.873\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.36088857130683\n",
      "  time_since_restore: 13891.097499608994\n",
      "  time_this_iter_s: 30.287524700164795\n",
      "  time_total_s: 13891.097499608994\n",
      "  timestamp: 1554822203\n",
      "  timesteps_since_restore: 4920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4920000\n",
      "  training_iteration: 492\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13891 s, 492 iter, 4920000 ts, -84.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-03-53\n",
      "  done: false\n",
      "  episode_len_mean: 91.5045871559633\n",
      "  episode_reward_max: 9.938763726075468\n",
      "  episode_reward_mean: -76.86344514449867\n",
      "  episode_reward_min: -200.05096884772502\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 53832\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5352.783\n",
      "    load_time_ms: 1.69\n",
      "    num_steps_sampled: 4930000\n",
      "    num_steps_trained: 4930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3513741493225098\n",
      "      kl: 0.0371561199426651\n",
      "      policy_loss: 0.016423247754573822\n",
      "      total_loss: 1373.6561279296875\n",
      "      vf_explained_var: 0.49901625514030457\n",
      "      vf_loss: 1373.6397705078125\n",
      "    sample_time_ms: 24713.052\n",
      "    update_time_ms: 7.958\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.431722572249335\n",
      "  time_since_restore: 13921.029182195663\n",
      "  time_this_iter_s: 29.931682586669922\n",
      "  time_total_s: 13921.029182195663\n",
      "  timestamp: 1554822233\n",
      "  timesteps_since_restore: 4930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4930000\n",
      "  training_iteration: 493\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13921 s, 493 iter, 4930000 ts, -76.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-04-23\n",
      "  done: false\n",
      "  episode_len_mean: 87.65486725663717\n",
      "  episode_reward_max: 11.475940340636889\n",
      "  episode_reward_mean: -88.38197316487178\n",
      "  episode_reward_min: -200.1041131674843\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 53945\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5357.239\n",
      "    load_time_ms: 1.751\n",
      "    num_steps_sampled: 4940000\n",
      "    num_steps_trained: 4940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3673797845840454\n",
      "      kl: 0.03706663101911545\n",
      "      policy_loss: 0.017246106639504433\n",
      "      total_loss: 1358.9661865234375\n",
      "      vf_explained_var: 0.5020071268081665\n",
      "      vf_loss: 1358.948974609375\n",
      "    sample_time_ms: 24759.316\n",
      "    update_time_ms: 7.462\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.1909865824359\n",
      "  time_since_restore: 13951.573379039764\n",
      "  time_this_iter_s: 30.544196844100952\n",
      "  time_total_s: 13951.573379039764\n",
      "  timestamp: 1554822263\n",
      "  timesteps_since_restore: 4940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4940000\n",
      "  training_iteration: 494\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13951 s, 494 iter, 4940000 ts, -88.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-04-54\n",
      "  done: false\n",
      "  episode_len_mean: 91.13513513513513\n",
      "  episode_reward_max: 10.341268720339\n",
      "  episode_reward_mean: -77.3280206864102\n",
      "  episode_reward_min: -200.0875952664524\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 54056\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5369.158\n",
      "    load_time_ms: 1.759\n",
      "    num_steps_sampled: 4950000\n",
      "    num_steps_trained: 4950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.345354676246643\n",
      "      kl: 0.06888175755739212\n",
      "      policy_loss: 0.026133403182029724\n",
      "      total_loss: 1353.1595458984375\n",
      "      vf_explained_var: 0.49841955304145813\n",
      "      vf_loss: 1353.1334228515625\n",
      "    sample_time_ms: 24800.257\n",
      "    update_time_ms: 7.473\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.66401034320509\n",
      "  time_since_restore: 13981.95079779625\n",
      "  time_this_iter_s: 30.377418756484985\n",
      "  time_total_s: 13981.95079779625\n",
      "  timestamp: 1554822294\n",
      "  timesteps_since_restore: 4950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4950000\n",
      "  training_iteration: 495\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 13981 s, 495 iter, 4950000 ts, -77.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-05-24\n",
      "  done: false\n",
      "  episode_len_mean: 88.29464285714286\n",
      "  episode_reward_max: 8.692243238265387\n",
      "  episode_reward_mean: -84.19554961475704\n",
      "  episode_reward_min: -200.04708400911386\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 54168\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5384.571\n",
      "    load_time_ms: 1.821\n",
      "    num_steps_sampled: 4960000\n",
      "    num_steps_trained: 4960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3499953746795654\n",
      "      kl: 0.04932606220245361\n",
      "      policy_loss: 0.020824536681175232\n",
      "      total_loss: 1454.278076171875\n",
      "      vf_explained_var: 0.48871055245399475\n",
      "      vf_loss: 1454.2572021484375\n",
      "    sample_time_ms: 24771.991\n",
      "    update_time_ms: 6.875\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.09777480737853\n",
      "  time_since_restore: 14011.813076734543\n",
      "  time_this_iter_s: 29.862278938293457\n",
      "  time_total_s: 14011.813076734543\n",
      "  timestamp: 1554822324\n",
      "  timesteps_since_restore: 4960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4960000\n",
      "  training_iteration: 496\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14011 s, 496 iter, 4960000 ts, -84.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-05-53\n",
      "  done: false\n",
      "  episode_len_mean: 85.45762711864407\n",
      "  episode_reward_max: 9.115403988747154\n",
      "  episode_reward_mean: -93.47980016829378\n",
      "  episode_reward_min: -200.1092985152835\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 54286\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5360.188\n",
      "    load_time_ms: 1.805\n",
      "    num_steps_sampled: 4970000\n",
      "    num_steps_trained: 4970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3474899530410767\n",
      "      kl: 0.03559330105781555\n",
      "      policy_loss: 0.01473661232739687\n",
      "      total_loss: 1337.9361572265625\n",
      "      vf_explained_var: 0.5470864772796631\n",
      "      vf_loss: 1337.92138671875\n",
      "    sample_time_ms: 24685.452\n",
      "    update_time_ms: 6.751\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.73990008414689\n",
      "  time_since_restore: 14041.56726861\n",
      "  time_this_iter_s: 29.754191875457764\n",
      "  time_total_s: 14041.56726861\n",
      "  timestamp: 1554822353\n",
      "  timesteps_since_restore: 4970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4970000\n",
      "  training_iteration: 497\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14041 s, 497 iter, 4970000 ts, -93.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-06-24\n",
      "  done: false\n",
      "  episode_len_mean: 87.88495575221239\n",
      "  episode_reward_max: 10.5373366224638\n",
      "  episode_reward_mean: -86.55935176714742\n",
      "  episode_reward_min: -200.05161613442993\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 54399\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5378.014\n",
      "    load_time_ms: 1.753\n",
      "    num_steps_sampled: 4980000\n",
      "    num_steps_trained: 4980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.354880452156067\n",
      "      kl: 0.04561043530702591\n",
      "      policy_loss: 0.01748557947576046\n",
      "      total_loss: 1347.1849365234375\n",
      "      vf_explained_var: 0.5121861696243286\n",
      "      vf_loss: 1347.16748046875\n",
      "    sample_time_ms: 24728.698\n",
      "    update_time_ms: 6.768\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.27967588357371\n",
      "  time_since_restore: 14071.821919441223\n",
      "  time_this_iter_s: 30.254650831222534\n",
      "  time_total_s: 14071.821919441223\n",
      "  timestamp: 1554822384\n",
      "  timesteps_since_restore: 4980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4980000\n",
      "  training_iteration: 498\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14071 s, 498 iter, 4980000 ts, -86.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-06-54\n",
      "  done: false\n",
      "  episode_len_mean: 87.64347826086957\n",
      "  episode_reward_max: 12.221322084760846\n",
      "  episode_reward_mean: -86.62939773913294\n",
      "  episode_reward_min: -200.0838786103215\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 54514\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5392.841\n",
      "    load_time_ms: 1.737\n",
      "    num_steps_sampled: 4990000\n",
      "    num_steps_trained: 4990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3575838804244995\n",
      "      kl: 0.03766964003443718\n",
      "      policy_loss: 0.013329342007637024\n",
      "      total_loss: 1409.053466796875\n",
      "      vf_explained_var: 0.47629013657569885\n",
      "      vf_loss: 1409.0400390625\n",
      "    sample_time_ms: 24669.944\n",
      "    update_time_ms: 6.553\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.31469886956647\n",
      "  time_since_restore: 14101.720227479935\n",
      "  time_this_iter_s: 29.898308038711548\n",
      "  time_total_s: 14101.720227479935\n",
      "  timestamp: 1554822414\n",
      "  timesteps_since_restore: 4990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4990000\n",
      "  training_iteration: 499\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14101 s, 499 iter, 4990000 ts, -86.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-07-24\n",
      "  done: false\n",
      "  episode_len_mean: 84.75213675213675\n",
      "  episode_reward_max: 10.483750736802921\n",
      "  episode_reward_mean: -93.75019661533605\n",
      "  episode_reward_min: -200.14996300157003\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 54631\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5375.232\n",
      "    load_time_ms: 1.761\n",
      "    num_steps_sampled: 5000000\n",
      "    num_steps_trained: 5000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3626298904418945\n",
      "      kl: 0.04315771907567978\n",
      "      policy_loss: 0.018017603084445\n",
      "      total_loss: 1318.3218994140625\n",
      "      vf_explained_var: 0.5422856211662292\n",
      "      vf_loss: 1318.303955078125\n",
      "    sample_time_ms: 24729.352\n",
      "    update_time_ms: 6.72\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.87509830766802\n",
      "  time_since_restore: 14132.043880462646\n",
      "  time_this_iter_s: 30.323652982711792\n",
      "  time_total_s: 14132.043880462646\n",
      "  timestamp: 1554822444\n",
      "  timesteps_since_restore: 5000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5000000\n",
      "  training_iteration: 500\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14132 s, 500 iter, 5000000 ts, -93.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-07-54\n",
      "  done: false\n",
      "  episode_len_mean: 87.10344827586206\n",
      "  episode_reward_max: 13.28528870627443\n",
      "  episode_reward_mean: -87.64266347458295\n",
      "  episode_reward_min: -200.0890236683168\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 54747\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5373.932\n",
      "    load_time_ms: 1.772\n",
      "    num_steps_sampled: 5010000\n",
      "    num_steps_trained: 5010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.360152244567871\n",
      "      kl: 0.04758714884519577\n",
      "      policy_loss: 0.017250780016183853\n",
      "      total_loss: 1362.0870361328125\n",
      "      vf_explained_var: 0.5301637053489685\n",
      "      vf_loss: 1362.0699462890625\n",
      "    sample_time_ms: 24714.383\n",
      "    update_time_ms: 6.898\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.82133173729147\n",
      "  time_since_restore: 14162.011094808578\n",
      "  time_this_iter_s: 29.967214345932007\n",
      "  time_total_s: 14162.011094808578\n",
      "  timestamp: 1554822474\n",
      "  timesteps_since_restore: 5010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5010000\n",
      "  training_iteration: 501\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14162 s, 501 iter, 5010000 ts, -87.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-08-24\n",
      "  done: false\n",
      "  episode_len_mean: 84.80508474576271\n",
      "  episode_reward_max: 9.240073488208154\n",
      "  episode_reward_mean: -93.71867190636584\n",
      "  episode_reward_min: -200.12000446934147\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 54865\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5359.996\n",
      "    load_time_ms: 1.696\n",
      "    num_steps_sampled: 5020000\n",
      "    num_steps_trained: 5020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3660703897476196\n",
      "      kl: 0.051878612488508224\n",
      "      policy_loss: 0.019374117255210876\n",
      "      total_loss: 1335.2318115234375\n",
      "      vf_explained_var: 0.5243213176727295\n",
      "      vf_loss: 1335.2125244140625\n",
      "    sample_time_ms: 24669.609\n",
      "    update_time_ms: 7.015\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.85933595318291\n",
      "  time_since_restore: 14191.703175067902\n",
      "  time_this_iter_s: 29.69208025932312\n",
      "  time_total_s: 14191.703175067902\n",
      "  timestamp: 1554822504\n",
      "  timesteps_since_restore: 5020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5020000\n",
      "  training_iteration: 502\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14191 s, 502 iter, 5020000 ts, -93.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-08-54\n",
      "  done: false\n",
      "  episode_len_mean: 90.41284403669725\n",
      "  episode_reward_max: 12.836903274993157\n",
      "  episode_reward_mean: -80.16101584493079\n",
      "  episode_reward_min: -200.20546461926102\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 54974\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5339.881\n",
      "    load_time_ms: 1.654\n",
      "    num_steps_sampled: 5030000\n",
      "    num_steps_trained: 5030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3601590394973755\n",
      "      kl: 0.7467414140701294\n",
      "      policy_loss: 0.0387842170894146\n",
      "      total_loss: 1390.0743408203125\n",
      "      vf_explained_var: 0.4841597080230713\n",
      "      vf_loss: 1390.035400390625\n",
      "    sample_time_ms: 24754.85\n",
      "    update_time_ms: 6.894\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.080507922465394\n",
      "  time_since_restore: 14222.28505897522\n",
      "  time_this_iter_s: 30.581883907318115\n",
      "  time_total_s: 14222.28505897522\n",
      "  timestamp: 1554822534\n",
      "  timesteps_since_restore: 5030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5030000\n",
      "  training_iteration: 503\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14222 s, 503 iter, 5030000 ts, -80.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-09-25\n",
      "  done: false\n",
      "  episode_len_mean: 87.98260869565217\n",
      "  episode_reward_max: 8.254809878109526\n",
      "  episode_reward_mean: -86.98452828281066\n",
      "  episode_reward_min: -200.2110538924333\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 55089\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5326.75\n",
      "    load_time_ms: 1.595\n",
      "    num_steps_sampled: 5040000\n",
      "    num_steps_trained: 5040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3852310180664062\n",
      "      kl: 0.05048598721623421\n",
      "      policy_loss: 0.01719861850142479\n",
      "      total_loss: 1410.312255859375\n",
      "      vf_explained_var: 0.48956918716430664\n",
      "      vf_loss: 1410.295166015625\n",
      "    sample_time_ms: 24738.393\n",
      "    update_time_ms: 6.994\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.49226414140533\n",
      "  time_since_restore: 14252.531748771667\n",
      "  time_this_iter_s: 30.246689796447754\n",
      "  time_total_s: 14252.531748771667\n",
      "  timestamp: 1554822565\n",
      "  timesteps_since_restore: 5040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5040000\n",
      "  training_iteration: 504\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14252 s, 504 iter, 5040000 ts, -87 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-09-55\n",
      "  done: false\n",
      "  episode_len_mean: 85.72173913043478\n",
      "  episode_reward_max: 10.651757128542004\n",
      "  episode_reward_mean: -92.09272441665236\n",
      "  episode_reward_min: -200.1288445664254\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 55204\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5314.47\n",
      "    load_time_ms: 1.615\n",
      "    num_steps_sampled: 5050000\n",
      "    num_steps_trained: 5050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3886085748672485\n",
      "      kl: 0.05144273489713669\n",
      "      policy_loss: 0.021112827584147453\n",
      "      total_loss: 1364.4525146484375\n",
      "      vf_explained_var: 0.5350939631462097\n",
      "      vf_loss: 1364.4312744140625\n",
      "    sample_time_ms: 24698.964\n",
      "    update_time_ms: 6.798\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.04636220832617\n",
      "  time_since_restore: 14282.39037847519\n",
      "  time_this_iter_s: 29.85862970352173\n",
      "  time_total_s: 14282.39037847519\n",
      "  timestamp: 1554822595\n",
      "  timesteps_since_restore: 5050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5050000\n",
      "  training_iteration: 505\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14282 s, 505 iter, 5050000 ts, -92.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-10-25\n",
      "  done: false\n",
      "  episode_len_mean: 89.83185840707965\n",
      "  episode_reward_max: 9.267453572123564\n",
      "  episode_reward_mean: -81.55833309400664\n",
      "  episode_reward_min: -200.1192731583129\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 55317\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5299.756\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 5060000\n",
      "    num_steps_trained: 5060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3769906759262085\n",
      "      kl: 0.03681967034935951\n",
      "      policy_loss: 0.014555211178958416\n",
      "      total_loss: 1386.7374267578125\n",
      "      vf_explained_var: 0.48469194769859314\n",
      "      vf_loss: 1386.722900390625\n",
      "    sample_time_ms: 24748.316\n",
      "    update_time_ms: 6.756\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.77916654700331\n",
      "  time_since_restore: 14312.602100610733\n",
      "  time_this_iter_s: 30.211722135543823\n",
      "  time_total_s: 14312.602100610733\n",
      "  timestamp: 1554822625\n",
      "  timesteps_since_restore: 5060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5060000\n",
      "  training_iteration: 506\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14312 s, 506 iter, 5060000 ts, -81.6 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-10-55\n",
      "  done: false\n",
      "  episode_len_mean: 88.69642857142857\n",
      "  episode_reward_max: 10.173396741403186\n",
      "  episode_reward_mean: -84.34261842109693\n",
      "  episode_reward_min: -200.05764119203914\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 55429\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5294.036\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 5070000\n",
      "    num_steps_trained: 5070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3743082284927368\n",
      "      kl: 0.042640626430511475\n",
      "      policy_loss: 0.01691659353673458\n",
      "      total_loss: 1375.2237548828125\n",
      "      vf_explained_var: 0.5204933285713196\n",
      "      vf_loss: 1375.2069091796875\n",
      "    sample_time_ms: 24749.317\n",
      "    update_time_ms: 6.866\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.17130921054845\n",
      "  time_since_restore: 14342.31414270401\n",
      "  time_this_iter_s: 29.712042093276978\n",
      "  time_total_s: 14342.31414270401\n",
      "  timestamp: 1554822655\n",
      "  timesteps_since_restore: 5070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5070000\n",
      "  training_iteration: 507\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14342 s, 507 iter, 5070000 ts, -84.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-11-24\n",
      "  done: false\n",
      "  episode_len_mean: 82.45901639344262\n",
      "  episode_reward_max: 8.450377561207588\n",
      "  episode_reward_mean: -99.86877722926172\n",
      "  episode_reward_min: -200.15303115650806\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 55551\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5282.49\n",
      "    load_time_ms: 1.622\n",
      "    num_steps_sampled: 5080000\n",
      "    num_steps_trained: 5080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3813064098358154\n",
      "      kl: 0.03870100900530815\n",
      "      policy_loss: 0.014662587083876133\n",
      "      total_loss: 1363.790771484375\n",
      "      vf_explained_var: 0.5164927840232849\n",
      "      vf_loss: 1363.7760009765625\n",
      "    sample_time_ms: 24709.009\n",
      "    update_time_ms: 7.111\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.93438861463086\n",
      "  time_since_restore: 14372.048999071121\n",
      "  time_this_iter_s: 29.734856367111206\n",
      "  time_total_s: 14372.048999071121\n",
      "  timestamp: 1554822684\n",
      "  timesteps_since_restore: 5080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5080000\n",
      "  training_iteration: 508\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14372 s, 508 iter, 5080000 ts, -99.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-11-54\n",
      "  done: false\n",
      "  episode_len_mean: 82.91735537190083\n",
      "  episode_reward_max: 9.45527294917525\n",
      "  episode_reward_mean: -98.950522103556\n",
      "  episode_reward_min: -200.09109139600577\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 55672\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5255.488\n",
      "    load_time_ms: 1.558\n",
      "    num_steps_sampled: 5090000\n",
      "    num_steps_trained: 5090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3924497365951538\n",
      "      kl: 0.03655470162630081\n",
      "      policy_loss: 0.011960671283304691\n",
      "      total_loss: 1406.9654541015625\n",
      "      vf_explained_var: 0.5064467787742615\n",
      "      vf_loss: 1406.953369140625\n",
      "    sample_time_ms: 24699.729\n",
      "    update_time_ms: 7.365\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.475261051778\n",
      "  time_since_restore: 14401.589691400528\n",
      "  time_this_iter_s: 29.54069232940674\n",
      "  time_total_s: 14401.589691400528\n",
      "  timestamp: 1554822714\n",
      "  timesteps_since_restore: 5090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5090000\n",
      "  training_iteration: 509\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14401 s, 509 iter, 5090000 ts, -99 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-12-24\n",
      "  done: false\n",
      "  episode_len_mean: 87.14912280701755\n",
      "  episode_reward_max: 9.583257095275595\n",
      "  episode_reward_mean: -89.46116268386055\n",
      "  episode_reward_min: -200.14299292688645\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 55786\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5240.565\n",
      "    load_time_ms: 1.566\n",
      "    num_steps_sampled: 5100000\n",
      "    num_steps_trained: 5100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3956358432769775\n",
      "      kl: 0.07520247995853424\n",
      "      policy_loss: 0.035649947822093964\n",
      "      total_loss: 1409.7486572265625\n",
      "      vf_explained_var: 0.4857215881347656\n",
      "      vf_loss: 1409.713134765625\n",
      "    sample_time_ms: 24676.712\n",
      "    update_time_ms: 7.548\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.73058134193027\n",
      "  time_since_restore: 14431.53506565094\n",
      "  time_this_iter_s: 29.945374250411987\n",
      "  time_total_s: 14431.53506565094\n",
      "  timestamp: 1554822744\n",
      "  timesteps_since_restore: 5100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5100000\n",
      "  training_iteration: 510\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14431 s, 510 iter, 5100000 ts, -89.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-12-54\n",
      "  done: false\n",
      "  episode_len_mean: 81.20491803278688\n",
      "  episode_reward_max: 9.876716808312528\n",
      "  episode_reward_mean: -105.23107605255306\n",
      "  episode_reward_min: -200.14990835624246\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 55908\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5245.19\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 5110000\n",
      "    num_steps_trained: 5110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.404170274734497\n",
      "      kl: 0.06374455988407135\n",
      "      policy_loss: 0.028572391718626022\n",
      "      total_loss: 1274.1732177734375\n",
      "      vf_explained_var: 0.570336639881134\n",
      "      vf_loss: 1274.1446533203125\n",
      "    sample_time_ms: 24709.268\n",
      "    update_time_ms: 7.246\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.61553802627654\n",
      "  time_since_restore: 14461.869134187698\n",
      "  time_this_iter_s: 30.334068536758423\n",
      "  time_total_s: 14461.869134187698\n",
      "  timestamp: 1554822774\n",
      "  timesteps_since_restore: 5110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5110000\n",
      "  training_iteration: 511\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14461 s, 511 iter, 5110000 ts, -105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-13-24\n",
      "  done: false\n",
      "  episode_len_mean: 90.39285714285714\n",
      "  episode_reward_max: 8.61759061763546\n",
      "  episode_reward_mean: -80.29268960922876\n",
      "  episode_reward_min: -200.13484691687086\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 56020\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5246.94\n",
      "    load_time_ms: 1.611\n",
      "    num_steps_sampled: 5120000\n",
      "    num_steps_trained: 5120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3842822313308716\n",
      "      kl: 0.032532334327697754\n",
      "      policy_loss: 0.012698899023234844\n",
      "      total_loss: 1432.875732421875\n",
      "      vf_explained_var: 0.4684436619281769\n",
      "      vf_loss: 1432.863037109375\n",
      "    sample_time_ms: 24717.305\n",
      "    update_time_ms: 7.146\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.14634480461439\n",
      "  time_since_restore: 14491.659669160843\n",
      "  time_this_iter_s: 29.79053497314453\n",
      "  time_total_s: 14491.659669160843\n",
      "  timestamp: 1554822804\n",
      "  timesteps_since_restore: 5120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5120000\n",
      "  training_iteration: 512\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14491 s, 512 iter, 5120000 ts, -80.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-13-54\n",
      "  done: false\n",
      "  episode_len_mean: 87.76106194690266\n",
      "  episode_reward_max: 8.956140237380975\n",
      "  episode_reward_mean: -86.87037445193823\n",
      "  episode_reward_min: -200.08486455595576\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 56133\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5249.808\n",
      "    load_time_ms: 1.639\n",
      "    num_steps_sampled: 5130000\n",
      "    num_steps_trained: 5130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.389020323753357\n",
      "      kl: 0.0388512946665287\n",
      "      policy_loss: 0.016464946791529655\n",
      "      total_loss: 1462.978515625\n",
      "      vf_explained_var: 0.4701400101184845\n",
      "      vf_loss: 1462.962158203125\n",
      "    sample_time_ms: 24673.231\n",
      "    update_time_ms: 6.974\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.435187225969116\n",
      "  time_since_restore: 14521.826271533966\n",
      "  time_this_iter_s: 30.16660237312317\n",
      "  time_total_s: 14521.826271533966\n",
      "  timestamp: 1554822834\n",
      "  timesteps_since_restore: 5130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5130000\n",
      "  training_iteration: 513\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14521 s, 513 iter, 5130000 ts, -86.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-14-25\n",
      "  done: false\n",
      "  episode_len_mean: 86.24137931034483\n",
      "  episode_reward_max: 10.577396612335578\n",
      "  episode_reward_mean: -91.22563165341394\n",
      "  episode_reward_min: -200.09546464697323\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 56249\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5262.242\n",
      "    load_time_ms: 1.697\n",
      "    num_steps_sampled: 5140000\n",
      "    num_steps_trained: 5140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3816696405410767\n",
      "      kl: 0.04324093833565712\n",
      "      policy_loss: 0.018463782966136932\n",
      "      total_loss: 1431.6982421875\n",
      "      vf_explained_var: 0.49220746755599976\n",
      "      vf_loss: 1431.6796875\n",
      "    sample_time_ms: 24674.057\n",
      "    update_time_ms: 6.964\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.61281582670695\n",
      "  time_since_restore: 14552.204872846603\n",
      "  time_this_iter_s: 30.37860131263733\n",
      "  time_total_s: 14552.204872846603\n",
      "  timestamp: 1554822865\n",
      "  timesteps_since_restore: 5140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5140000\n",
      "  training_iteration: 514\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14552 s, 514 iter, 5140000 ts, -91.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-14-55\n",
      "  done: false\n",
      "  episode_len_mean: 82.92561983471074\n",
      "  episode_reward_max: 7.335226365333325\n",
      "  episode_reward_mean: -99.48569012870304\n",
      "  episode_reward_min: -200.11109675435813\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 56370\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5255.712\n",
      "    load_time_ms: 1.707\n",
      "    num_steps_sampled: 5150000\n",
      "    num_steps_trained: 5150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.39371919631958\n",
      "      kl: 0.041266318410634995\n",
      "      policy_loss: 0.01399934571236372\n",
      "      total_loss: 1323.7568359375\n",
      "      vf_explained_var: 0.5492647886276245\n",
      "      vf_loss: 1323.7427978515625\n",
      "    sample_time_ms: 24716.078\n",
      "    update_time_ms: 7.448\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.74284506435153\n",
      "  time_since_restore: 14582.424553155899\n",
      "  time_this_iter_s: 30.219680309295654\n",
      "  time_total_s: 14582.424553155899\n",
      "  timestamp: 1554822895\n",
      "  timesteps_since_restore: 5150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5150000\n",
      "  training_iteration: 515\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14582 s, 515 iter, 5150000 ts, -99.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-15-25\n",
      "  done: false\n",
      "  episode_len_mean: 94.30188679245283\n",
      "  episode_reward_max: 6.983527963211083\n",
      "  episode_reward_mean: -69.94873292344607\n",
      "  episode_reward_min: -200.0668387887788\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 56476\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5255.828\n",
      "    load_time_ms: 1.733\n",
      "    num_steps_sampled: 5160000\n",
      "    num_steps_trained: 5160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.367090106010437\n",
      "      kl: 0.05103275552392006\n",
      "      policy_loss: 0.027768336236476898\n",
      "      total_loss: 1495.8634033203125\n",
      "      vf_explained_var: 0.4489402770996094\n",
      "      vf_loss: 1495.835693359375\n",
      "    sample_time_ms: 24714.821\n",
      "    update_time_ms: 7.723\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.97436646172303\n",
      "  time_since_restore: 14612.630588531494\n",
      "  time_this_iter_s: 30.206035375595093\n",
      "  time_total_s: 14612.630588531494\n",
      "  timestamp: 1554822925\n",
      "  timesteps_since_restore: 5160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5160000\n",
      "  training_iteration: 516\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14612 s, 516 iter, 5160000 ts, -69.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-15-56\n",
      "  done: false\n",
      "  episode_len_mean: 89.78181818181818\n",
      "  episode_reward_max: 9.008974312421387\n",
      "  episode_reward_mean: -79.95212600014466\n",
      "  episode_reward_min: -200.08771391597767\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 56586\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5253.825\n",
      "    load_time_ms: 1.732\n",
      "    num_steps_sampled: 5170000\n",
      "    num_steps_trained: 5170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3743640184402466\n",
      "      kl: 2.087372303009033\n",
      "      policy_loss: 0.07393497228622437\n",
      "      total_loss: 1335.6141357421875\n",
      "      vf_explained_var: 0.5273022651672363\n",
      "      vf_loss: 1335.5404052734375\n",
      "    sample_time_ms: 24774.17\n",
      "    update_time_ms: 7.887\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.976063000072315\n",
      "  time_since_restore: 14642.91363120079\n",
      "  time_this_iter_s: 30.283042669296265\n",
      "  time_total_s: 14642.91363120079\n",
      "  timestamp: 1554822956\n",
      "  timesteps_since_restore: 5170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5170000\n",
      "  training_iteration: 517\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14642 s, 517 iter, 5170000 ts, -80 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-16-26\n",
      "  done: false\n",
      "  episode_len_mean: 91.99090909090908\n",
      "  episode_reward_max: 10.083146647811883\n",
      "  episode_reward_mean: -74.70978648153668\n",
      "  episode_reward_min: -200.23042426805637\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 56696\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5244.317\n",
      "    load_time_ms: 1.73\n",
      "    num_steps_sampled: 5180000\n",
      "    num_steps_trained: 5180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.368722915649414\n",
      "      kl: 0.04757815599441528\n",
      "      policy_loss: 0.01927950233221054\n",
      "      total_loss: 1493.21630859375\n",
      "      vf_explained_var: 0.44489043951034546\n",
      "      vf_loss: 1493.197265625\n",
      "    sample_time_ms: 24845.724\n",
      "    update_time_ms: 8.142\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.354893240768334\n",
      "  time_since_restore: 14673.272682905197\n",
      "  time_this_iter_s: 30.35905170440674\n",
      "  time_total_s: 14673.272682905197\n",
      "  timestamp: 1554822986\n",
      "  timesteps_since_restore: 5180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5180000\n",
      "  training_iteration: 518\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14673 s, 518 iter, 5180000 ts, -74.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-16-56\n",
      "  done: false\n",
      "  episode_len_mean: 86.64655172413794\n",
      "  episode_reward_max: 9.589161408751039\n",
      "  episode_reward_mean: -89.16970428583934\n",
      "  episode_reward_min: -200.129560228613\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 56812\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5247.909\n",
      "    load_time_ms: 1.715\n",
      "    num_steps_sampled: 5190000\n",
      "    num_steps_trained: 5190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3768041133880615\n",
      "      kl: 0.0477142333984375\n",
      "      policy_loss: 0.025383558124303818\n",
      "      total_loss: 1387.45654296875\n",
      "      vf_explained_var: 0.5033444166183472\n",
      "      vf_loss: 1387.4310302734375\n",
      "    sample_time_ms: 24822.658\n",
      "    update_time_ms: 8.281\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.58485214291967\n",
      "  time_since_restore: 14702.618275403976\n",
      "  time_this_iter_s: 29.345592498779297\n",
      "  time_total_s: 14702.618275403976\n",
      "  timestamp: 1554823016\n",
      "  timesteps_since_restore: 5190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5190000\n",
      "  training_iteration: 519\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14702 s, 519 iter, 5190000 ts, -89.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-17-25\n",
      "  done: false\n",
      "  episode_len_mean: 84.15966386554622\n",
      "  episode_reward_max: 12.664189076393187\n",
      "  episode_reward_mean: -93.75830514045634\n",
      "  episode_reward_min: -200.0921318667901\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 56931\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5229.792\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 5200000\n",
      "    num_steps_trained: 5200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3800075054168701\n",
      "      kl: 0.03619740903377533\n",
      "      policy_loss: 0.015110135078430176\n",
      "      total_loss: 1279.9974365234375\n",
      "      vf_explained_var: 0.5659379959106445\n",
      "      vf_loss: 1279.982421875\n",
      "    sample_time_ms: 24816.851\n",
      "    update_time_ms: 8.384\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.879152570228165\n",
      "  time_since_restore: 14732.325350999832\n",
      "  time_this_iter_s: 29.707075595855713\n",
      "  time_total_s: 14732.325350999832\n",
      "  timestamp: 1554823045\n",
      "  timesteps_since_restore: 5200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5200000\n",
      "  training_iteration: 520\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14732 s, 520 iter, 5200000 ts, -93.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-17-55\n",
      "  done: false\n",
      "  episode_len_mean: 81.22131147540983\n",
      "  episode_reward_max: 10.808890997214453\n",
      "  episode_reward_mean: -105.10446997910361\n",
      "  episode_reward_min: -200.12096387911066\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 57053\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5205.408\n",
      "    load_time_ms: 1.605\n",
      "    num_steps_sampled: 5210000\n",
      "    num_steps_trained: 5210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3945740461349487\n",
      "      kl: 0.042480967938899994\n",
      "      policy_loss: 0.018231932073831558\n",
      "      total_loss: 1313.7908935546875\n",
      "      vf_explained_var: 0.5315200686454773\n",
      "      vf_loss: 1313.772705078125\n",
      "    sample_time_ms: 24789.334\n",
      "    update_time_ms: 8.626\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.5522349895518\n",
      "  time_since_restore: 14762.142765283585\n",
      "  time_this_iter_s: 29.81741428375244\n",
      "  time_total_s: 14762.142765283585\n",
      "  timestamp: 1554823075\n",
      "  timesteps_since_restore: 5210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5210000\n",
      "  training_iteration: 521\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14762 s, 521 iter, 5210000 ts, -105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-18-25\n",
      "  done: false\n",
      "  episode_len_mean: 89.1875\n",
      "  episode_reward_max: 11.067723524921583\n",
      "  episode_reward_mean: -81.88319638903667\n",
      "  episode_reward_min: -200.14486785239484\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 57165\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5211.489\n",
      "    load_time_ms: 1.603\n",
      "    num_steps_sampled: 5220000\n",
      "    num_steps_trained: 5220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3687615394592285\n",
      "      kl: 0.03539512678980827\n",
      "      policy_loss: 0.011028184555470943\n",
      "      total_loss: 1458.802734375\n",
      "      vf_explained_var: 0.46059417724609375\n",
      "      vf_loss: 1458.791748046875\n",
      "    sample_time_ms: 24769.325\n",
      "    update_time_ms: 9.106\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.94159819451834\n",
      "  time_since_restore: 14791.798921585083\n",
      "  time_this_iter_s: 29.656156301498413\n",
      "  time_total_s: 14791.798921585083\n",
      "  timestamp: 1554823105\n",
      "  timesteps_since_restore: 5220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5220000\n",
      "  training_iteration: 522\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14791 s, 522 iter, 5220000 ts, -81.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 83.58677685950413\n",
      "  episode_reward_max: 12.57915919878107\n",
      "  episode_reward_mean: -97.77665753457967\n",
      "  episode_reward_min: -200.07640319735458\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 57286\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5201.594\n",
      "    load_time_ms: 1.633\n",
      "    num_steps_sampled: 5230000\n",
      "    num_steps_trained: 5230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3886055946350098\n",
      "      kl: 0.03878873959183693\n",
      "      policy_loss: 0.014734135009348392\n",
      "      total_loss: 1317.784912109375\n",
      "      vf_explained_var: 0.5302196145057678\n",
      "      vf_loss: 1317.77001953125\n",
      "    sample_time_ms: 24759.811\n",
      "    update_time_ms: 9.522\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.88832876728983\n",
      "  time_since_restore: 14821.776734113693\n",
      "  time_this_iter_s: 29.97781252861023\n",
      "  time_total_s: 14821.776734113693\n",
      "  timestamp: 1554823135\n",
      "  timesteps_since_restore: 5230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5230000\n",
      "  training_iteration: 523\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14821 s, 523 iter, 5230000 ts, -97.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-19-25\n",
      "  done: false\n",
      "  episode_len_mean: 91.49074074074075\n",
      "  episode_reward_max: 9.55666041044094\n",
      "  episode_reward_mean: -76.01216926627365\n",
      "  episode_reward_min: -200.12849349190014\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 57394\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5197.113\n",
      "    load_time_ms: 1.619\n",
      "    num_steps_sampled: 5240000\n",
      "    num_steps_trained: 5240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3837392330169678\n",
      "      kl: 0.044446494430303574\n",
      "      policy_loss: 0.016251925379037857\n",
      "      total_loss: 1546.624755859375\n",
      "      vf_explained_var: 0.39246389269828796\n",
      "      vf_loss: 1546.6085205078125\n",
      "    sample_time_ms: 24718.056\n",
      "    update_time_ms: 9.639\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.00608463313682\n",
      "  time_since_restore: 14851.697876214981\n",
      "  time_this_iter_s: 29.921142101287842\n",
      "  time_total_s: 14851.697876214981\n",
      "  timestamp: 1554823165\n",
      "  timesteps_since_restore: 5240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5240000\n",
      "  training_iteration: 524\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14851 s, 524 iter, 5240000 ts, -76 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-19-55\n",
      "  done: false\n",
      "  episode_len_mean: 85.80341880341881\n",
      "  episode_reward_max: 12.9855388645388\n",
      "  episode_reward_mean: -90.55859295047166\n",
      "  episode_reward_min: -200.0676189646041\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 57511\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5200.539\n",
      "    load_time_ms: 1.598\n",
      "    num_steps_sampled: 5250000\n",
      "    num_steps_trained: 5250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.399632215499878\n",
      "      kl: 0.051299240440130234\n",
      "      policy_loss: 0.01957075484097004\n",
      "      total_loss: 1309.23974609375\n",
      "      vf_explained_var: 0.5400516986846924\n",
      "      vf_loss: 1309.2200927734375\n",
      "    sample_time_ms: 24677.254\n",
      "    update_time_ms: 9.358\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.279296475235824\n",
      "  time_since_restore: 14881.536360025406\n",
      "  time_this_iter_s: 29.838483810424805\n",
      "  time_total_s: 14881.536360025406\n",
      "  timestamp: 1554823195\n",
      "  timesteps_since_restore: 5250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5250000\n",
      "  training_iteration: 525\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14881 s, 525 iter, 5250000 ts, -90.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-20-25\n",
      "  done: false\n",
      "  episode_len_mean: 84.03389830508475\n",
      "  episode_reward_max: 10.000298044515118\n",
      "  episode_reward_mean: -96.97937001605243\n",
      "  episode_reward_min: -200.16460430476297\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 57629\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5193.945\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 5260000\n",
      "    num_steps_trained: 5260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3984911441802979\n",
      "      kl: 0.0658390074968338\n",
      "      policy_loss: 0.025529202073812485\n",
      "      total_loss: 1333.572509765625\n",
      "      vf_explained_var: 0.5141316056251526\n",
      "      vf_loss: 1333.546875\n",
      "    sample_time_ms: 24666.75\n",
      "    update_time_ms: 8.956\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.48968500802621\n",
      "  time_since_restore: 14911.563998222351\n",
      "  time_this_iter_s: 30.02763819694519\n",
      "  time_total_s: 14911.563998222351\n",
      "  timestamp: 1554823225\n",
      "  timesteps_since_restore: 5260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5260000\n",
      "  training_iteration: 526\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14911 s, 526 iter, 5260000 ts, -97 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-20-54\n",
      "  done: false\n",
      "  episode_len_mean: 90.875\n",
      "  episode_reward_max: 8.060266488510509\n",
      "  episode_reward_mean: -80.90662398381687\n",
      "  episode_reward_min: -200.40970909748756\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 57741\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5192.562\n",
      "    load_time_ms: 1.56\n",
      "    num_steps_sampled: 5270000\n",
      "    num_steps_trained: 5270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3978233337402344\n",
      "      kl: 0.04098006710410118\n",
      "      policy_loss: 0.013749180361628532\n",
      "      total_loss: 1423.6949462890625\n",
      "      vf_explained_var: 0.4957841634750366\n",
      "      vf_loss: 1423.6810302734375\n",
      "    sample_time_ms: 24546.238\n",
      "    update_time_ms: 8.742\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.453311991908436\n",
      "  time_since_restore: 14940.628654003143\n",
      "  time_this_iter_s: 29.064655780792236\n",
      "  time_total_s: 14940.628654003143\n",
      "  timestamp: 1554823254\n",
      "  timesteps_since_restore: 5270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5270000\n",
      "  training_iteration: 527\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14940 s, 527 iter, 5270000 ts, -80.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-21-25\n",
      "  done: false\n",
      "  episode_len_mean: 87.64601769911505\n",
      "  episode_reward_max: 13.764272260209834\n",
      "  episode_reward_mean: -88.76985342400663\n",
      "  episode_reward_min: -200.09606916166507\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 57854\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5326.865\n",
      "    load_time_ms: 1.606\n",
      "    num_steps_sampled: 5280000\n",
      "    num_steps_trained: 5280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4097315073013306\n",
      "      kl: 0.04300175979733467\n",
      "      policy_loss: 0.01503073237836361\n",
      "      total_loss: 1342.1767578125\n",
      "      vf_explained_var: 0.5291622877120972\n",
      "      vf_loss: 1342.161865234375\n",
      "    sample_time_ms: 24497.081\n",
      "    update_time_ms: 8.287\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.38492671200333\n",
      "  time_since_restore: 14971.846298456192\n",
      "  time_this_iter_s: 31.217644453048706\n",
      "  time_total_s: 14971.846298456192\n",
      "  timestamp: 1554823285\n",
      "  timesteps_since_restore: 5280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5280000\n",
      "  training_iteration: 528\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 14971 s, 528 iter, 5280000 ts, -88.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-21-56\n",
      "  done: false\n",
      "  episode_len_mean: 86.47826086956522\n",
      "  episode_reward_max: 12.067727200166818\n",
      "  episode_reward_mean: -88.37948761325441\n",
      "  episode_reward_min: -200.0683558611324\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 57969\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5326.881\n",
      "    load_time_ms: 1.651\n",
      "    num_steps_sampled: 5290000\n",
      "    num_steps_trained: 5290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4030368328094482\n",
      "      kl: 0.038546282798051834\n",
      "      policy_loss: 0.016442419961094856\n",
      "      total_loss: 1431.999755859375\n",
      "      vf_explained_var: 0.5094059705734253\n",
      "      vf_loss: 1431.983154296875\n",
      "    sample_time_ms: 24641.437\n",
      "    update_time_ms: 8.168\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.18974380662721\n",
      "  time_since_restore: 15002.63275885582\n",
      "  time_this_iter_s: 30.786460399627686\n",
      "  time_total_s: 15002.63275885582\n",
      "  timestamp: 1554823316\n",
      "  timesteps_since_restore: 5290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5290000\n",
      "  training_iteration: 529\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15002 s, 529 iter, 5290000 ts, -88.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-22-26\n",
      "  done: false\n",
      "  episode_len_mean: 85.5042735042735\n",
      "  episode_reward_max: 12.393579634030072\n",
      "  episode_reward_mean: -92.04146007775469\n",
      "  episode_reward_min: -200.07147077906393\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 58086\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5332.654\n",
      "    load_time_ms: 1.693\n",
      "    num_steps_sampled: 5300000\n",
      "    num_steps_trained: 5300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4001425504684448\n",
      "      kl: 0.043246444314718246\n",
      "      policy_loss: 0.018993543460965157\n",
      "      total_loss: 1386.287841796875\n",
      "      vf_explained_var: 0.5109298825263977\n",
      "      vf_loss: 1386.2689208984375\n",
      "    sample_time_ms: 24625.775\n",
      "    update_time_ms: 7.724\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.02073003887735\n",
      "  time_since_restore: 15032.236296892166\n",
      "  time_this_iter_s: 29.603538036346436\n",
      "  time_total_s: 15032.236296892166\n",
      "  timestamp: 1554823346\n",
      "  timesteps_since_restore: 5300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5300000\n",
      "  training_iteration: 530\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15032 s, 530 iter, 5300000 ts, -92 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-22-55\n",
      "  done: false\n",
      "  episode_len_mean: 84.26050420168067\n",
      "  episode_reward_max: 10.122842552218572\n",
      "  episode_reward_mean: -96.29920859079748\n",
      "  episode_reward_min: -200.1481967013938\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 58205\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5329.264\n",
      "    load_time_ms: 1.694\n",
      "    num_steps_sampled: 5310000\n",
      "    num_steps_trained: 5310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4024258852005005\n",
      "      kl: 0.0637875571846962\n",
      "      policy_loss: 0.026306647807359695\n",
      "      total_loss: 1370.0843505859375\n",
      "      vf_explained_var: 0.5233938694000244\n",
      "      vf_loss: 1370.057861328125\n",
      "    sample_time_ms: 24630.243\n",
      "    update_time_ms: 7.695\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.14960429539876\n",
      "  time_since_restore: 15062.061969995499\n",
      "  time_this_iter_s: 29.82567310333252\n",
      "  time_total_s: 15062.061969995499\n",
      "  timestamp: 1554823375\n",
      "  timesteps_since_restore: 5310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5310000\n",
      "  training_iteration: 531\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15062 s, 531 iter, 5310000 ts, -96.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-23-25\n",
      "  done: false\n",
      "  episode_len_mean: 92.72477064220183\n",
      "  episode_reward_max: 8.243307710994738\n",
      "  episode_reward_mean: -73.93010414687386\n",
      "  episode_reward_min: -200.08431580401964\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 58314\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5315.311\n",
      "    load_time_ms: 1.723\n",
      "    num_steps_sampled: 5320000\n",
      "    num_steps_trained: 5320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3882770538330078\n",
      "      kl: 0.03902706876397133\n",
      "      policy_loss: 0.019177373498678207\n",
      "      total_loss: 1355.630126953125\n",
      "      vf_explained_var: 0.506618082523346\n",
      "      vf_loss: 1355.6109619140625\n",
      "    sample_time_ms: 24636.159\n",
      "    update_time_ms: 7.216\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.96505207343694\n",
      "  time_since_restore: 15091.63439488411\n",
      "  time_this_iter_s: 29.57242488861084\n",
      "  time_total_s: 15091.63439488411\n",
      "  timestamp: 1554823405\n",
      "  timesteps_since_restore: 5320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5320000\n",
      "  training_iteration: 532\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15091 s, 532 iter, 5320000 ts, -73.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-23-55\n",
      "  done: false\n",
      "  episode_len_mean: 81.82644628099173\n",
      "  episode_reward_max: 11.948924999034872\n",
      "  episode_reward_mean: -103.87009911274622\n",
      "  episode_reward_min: -200.13055075717318\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 58435\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5324.678\n",
      "    load_time_ms: 1.678\n",
      "    num_steps_sampled: 5330000\n",
      "    num_steps_trained: 5330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4101122617721558\n",
      "      kl: 0.06497077643871307\n",
      "      policy_loss: 0.02934226021170616\n",
      "      total_loss: 1306.35498046875\n",
      "      vf_explained_var: 0.5399146676063538\n",
      "      vf_loss: 1306.32568359375\n",
      "    sample_time_ms: 24586.314\n",
      "    update_time_ms: 7.073\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.93504955637311\n",
      "  time_since_restore: 15121.204741716385\n",
      "  time_this_iter_s: 29.57034683227539\n",
      "  time_total_s: 15121.204741716385\n",
      "  timestamp: 1554823435\n",
      "  timesteps_since_restore: 5330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5330000\n",
      "  training_iteration: 533\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15121 s, 533 iter, 5330000 ts, -104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-24-24\n",
      "  done: false\n",
      "  episode_len_mean: 91.76146788990826\n",
      "  episode_reward_max: 10.938761791662479\n",
      "  episode_reward_mean: -75.03438733535528\n",
      "  episode_reward_min: -200.09812647987826\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 58544\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5325.471\n",
      "    load_time_ms: 1.637\n",
      "    num_steps_sampled: 5340000\n",
      "    num_steps_trained: 5340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3770095109939575\n",
      "      kl: 0.047962963581085205\n",
      "      policy_loss: 0.02162938006222248\n",
      "      total_loss: 1486.8194580078125\n",
      "      vf_explained_var: 0.44398459792137146\n",
      "      vf_loss: 1486.7978515625\n",
      "    sample_time_ms: 24523.58\n",
      "    update_time_ms: 7.326\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.51719366767763\n",
      "  time_since_restore: 15150.50556731224\n",
      "  time_this_iter_s: 29.300825595855713\n",
      "  time_total_s: 15150.50556731224\n",
      "  timestamp: 1554823464\n",
      "  timesteps_since_restore: 5340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5340000\n",
      "  training_iteration: 534\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15150 s, 534 iter, 5340000 ts, -75 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-24-53\n",
      "  done: false\n",
      "  episode_len_mean: 92.06481481481481\n",
      "  episode_reward_max: 10.125956784947826\n",
      "  episode_reward_mean: -74.30890623361846\n",
      "  episode_reward_min: -200.11955421881288\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 58652\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5299.358\n",
      "    load_time_ms: 1.662\n",
      "    num_steps_sampled: 5350000\n",
      "    num_steps_trained: 5350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3875528573989868\n",
      "      kl: 0.04380902275443077\n",
      "      policy_loss: 0.019392196089029312\n",
      "      total_loss: 1435.9923095703125\n",
      "      vf_explained_var: 0.4517298936843872\n",
      "      vf_loss: 1435.972900390625\n",
      "    sample_time_ms: 24486.966\n",
      "    update_time_ms: 7.161\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.154453116809236\n",
      "  time_since_restore: 15179.713597536087\n",
      "  time_this_iter_s: 29.208030223846436\n",
      "  time_total_s: 15179.713597536087\n",
      "  timestamp: 1554823493\n",
      "  timesteps_since_restore: 5350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5350000\n",
      "  training_iteration: 535\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15179 s, 535 iter, 5350000 ts, -74.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-25-23\n",
      "  done: false\n",
      "  episode_len_mean: 83.95798319327731\n",
      "  episode_reward_max: 10.204198150180039\n",
      "  episode_reward_mean: -98.85471442327156\n",
      "  episode_reward_min: -200.36155468352317\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 58771\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5319.254\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 5360000\n",
      "    num_steps_trained: 5360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.391300082206726\n",
      "      kl: 9.963363647460938\n",
      "      policy_loss: 0.07944180071353912\n",
      "      total_loss: 1295.6002197265625\n",
      "      vf_explained_var: 0.5433879494667053\n",
      "      vf_loss: 1295.520751953125\n",
      "    sample_time_ms: 24444.488\n",
      "    update_time_ms: 7.217\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.42735721163577\n",
      "  time_since_restore: 15209.515174627304\n",
      "  time_this_iter_s: 29.80157709121704\n",
      "  time_total_s: 15209.515174627304\n",
      "  timestamp: 1554823523\n",
      "  timesteps_since_restore: 5360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5360000\n",
      "  training_iteration: 536\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15209 s, 536 iter, 5360000 ts, -98.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-25-53\n",
      "  done: false\n",
      "  episode_len_mean: 86.05982905982906\n",
      "  episode_reward_max: 12.560660932742717\n",
      "  episode_reward_mean: -88.80816666292336\n",
      "  episode_reward_min: -200.10550601092197\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 58888\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5310.526\n",
      "    load_time_ms: 1.621\n",
      "    num_steps_sampled: 5370000\n",
      "    num_steps_trained: 5370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3790467977523804\n",
      "      kl: 0.05327680706977844\n",
      "      policy_loss: 0.022143984213471413\n",
      "      total_loss: 1413.7115478515625\n",
      "      vf_explained_var: 0.4702514708042145\n",
      "      vf_loss: 1413.689453125\n",
      "    sample_time_ms: 24478.619\n",
      "    update_time_ms: 7.364\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.40408333146166\n",
      "  time_since_restore: 15238.83128118515\n",
      "  time_this_iter_s: 29.31610655784607\n",
      "  time_total_s: 15238.83128118515\n",
      "  timestamp: 1554823553\n",
      "  timesteps_since_restore: 5370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5370000\n",
      "  training_iteration: 537\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15238 s, 537 iter, 5370000 ts, -88.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-26-22\n",
      "  done: false\n",
      "  episode_len_mean: 83.40495867768595\n",
      "  episode_reward_max: 13.330264842005771\n",
      "  episode_reward_mean: -98.98218386046051\n",
      "  episode_reward_min: -200.12415132424536\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 59009\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5183.907\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 5380000\n",
      "    num_steps_trained: 5380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.384277105331421\n",
      "      kl: 0.03924240916967392\n",
      "      policy_loss: 0.019117992371320724\n",
      "      total_loss: 1338.2503662109375\n",
      "      vf_explained_var: 0.5356967449188232\n",
      "      vf_loss: 1338.231201171875\n",
      "    sample_time_ms: 24425.435\n",
      "    update_time_ms: 7.36\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.491091930230255\n",
      "  time_since_restore: 15268.240320205688\n",
      "  time_this_iter_s: 29.40903902053833\n",
      "  time_total_s: 15268.240320205688\n",
      "  timestamp: 1554823582\n",
      "  timesteps_since_restore: 5380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5380000\n",
      "  training_iteration: 538\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15268 s, 538 iter, 5380000 ts, -99 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-26-52\n",
      "  done: false\n",
      "  episode_len_mean: 85.11206896551724\n",
      "  episode_reward_max: 12.003182206883748\n",
      "  episode_reward_mean: -94.42594727736854\n",
      "  episode_reward_min: -200.0946382252508\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 59125\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5198.281\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 5390000\n",
      "    num_steps_trained: 5390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.385669469833374\n",
      "      kl: 0.04545144364237785\n",
      "      policy_loss: 0.017511524260044098\n",
      "      total_loss: 1356.10400390625\n",
      "      vf_explained_var: 0.5180909633636475\n",
      "      vf_loss: 1356.08642578125\n",
      "    sample_time_ms: 24310.471\n",
      "    update_time_ms: 7.098\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.21297363868427\n",
      "  time_since_restore: 15298.021589517593\n",
      "  time_this_iter_s: 29.781269311904907\n",
      "  time_total_s: 15298.021589517593\n",
      "  timestamp: 1554823612\n",
      "  timesteps_since_restore: 5390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5390000\n",
      "  training_iteration: 539\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15298 s, 539 iter, 5390000 ts, -94.4 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-27-22\n",
      "  done: false\n",
      "  episode_len_mean: 95.17142857142858\n",
      "  episode_reward_max: 9.46710195555002\n",
      "  episode_reward_mean: -66.96763322590058\n",
      "  episode_reward_min: -200.04071325614396\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 59230\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5217.018\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 5400000\n",
      "    num_steps_trained: 5400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3696329593658447\n",
      "      kl: 0.05082087591290474\n",
      "      policy_loss: 0.022324049845337868\n",
      "      total_loss: 1513.09130859375\n",
      "      vf_explained_var: 0.420133501291275\n",
      "      vf_loss: 1513.0689697265625\n",
      "    sample_time_ms: 24297.388\n",
      "    update_time_ms: 7.309\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.4838166129503\n",
      "  time_since_restore: 15327.682035446167\n",
      "  time_this_iter_s: 29.66044592857361\n",
      "  time_total_s: 15327.682035446167\n",
      "  timestamp: 1554823642\n",
      "  timesteps_since_restore: 5400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5400000\n",
      "  training_iteration: 540\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15327 s, 540 iter, 5400000 ts, -67 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-27-52\n",
      "  done: false\n",
      "  episode_len_mean: 89.85714285714286\n",
      "  episode_reward_max: 13.149765946517892\n",
      "  episode_reward_mean: -82.00015223299111\n",
      "  episode_reward_min: -200.23909921274935\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 59342\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5220.979\n",
      "    load_time_ms: 1.487\n",
      "    num_steps_sampled: 5410000\n",
      "    num_steps_trained: 5410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3802034854888916\n",
      "      kl: 0.04100649058818817\n",
      "      policy_loss: 0.013953854329884052\n",
      "      total_loss: 1497.765869140625\n",
      "      vf_explained_var: 0.4107089042663574\n",
      "      vf_loss: 1497.751953125\n",
      "    sample_time_ms: 24329.962\n",
      "    update_time_ms: 7.441\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.00007611649556\n",
      "  time_since_restore: 15357.87688922882\n",
      "  time_this_iter_s: 30.19485378265381\n",
      "  time_total_s: 15357.87688922882\n",
      "  timestamp: 1554823672\n",
      "  timesteps_since_restore: 5410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5410000\n",
      "  training_iteration: 541\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15357 s, 541 iter, 5410000 ts, -82 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-28-22\n",
      "  done: false\n",
      "  episode_len_mean: 86.14655172413794\n",
      "  episode_reward_max: 10.347899219149436\n",
      "  episode_reward_mean: -89.5055284684447\n",
      "  episode_reward_min: -200.13651372350827\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 59458\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5245.514\n",
      "    load_time_ms: 1.459\n",
      "    num_steps_sampled: 5420000\n",
      "    num_steps_trained: 5420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.382623314857483\n",
      "      kl: 0.04196937754750252\n",
      "      policy_loss: 0.017005516216158867\n",
      "      total_loss: 1357.5064697265625\n",
      "      vf_explained_var: 0.4926055371761322\n",
      "      vf_loss: 1357.4893798828125\n",
      "    sample_time_ms: 24350.805\n",
      "    update_time_ms: 7.378\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.75276423422234\n",
      "  time_since_restore: 15387.902955293655\n",
      "  time_this_iter_s: 30.026066064834595\n",
      "  time_total_s: 15387.902955293655\n",
      "  timestamp: 1554823702\n",
      "  timesteps_since_restore: 5420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5420000\n",
      "  training_iteration: 542\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15387 s, 542 iter, 5420000 ts, -89.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-28-51\n",
      "  done: false\n",
      "  episode_len_mean: 86.83620689655173\n",
      "  episode_reward_max: 13.145545893801597\n",
      "  episode_reward_mean: -91.1327625459795\n",
      "  episode_reward_min: -200.14882795962404\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 59574\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5223.274\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 5430000\n",
      "    num_steps_trained: 5430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3970357179641724\n",
      "      kl: 0.037250764667987823\n",
      "      policy_loss: 0.01295966375619173\n",
      "      total_loss: 1405.7515869140625\n",
      "      vf_explained_var: 0.5043301582336426\n",
      "      vf_loss: 1405.738525390625\n",
      "    sample_time_ms: 24368.311\n",
      "    update_time_ms: 7.199\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.566381272989744\n",
      "  time_since_restore: 15417.42681479454\n",
      "  time_this_iter_s: 29.52385950088501\n",
      "  time_total_s: 15417.42681479454\n",
      "  timestamp: 1554823731\n",
      "  timesteps_since_restore: 5430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5430000\n",
      "  training_iteration: 543\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15417 s, 543 iter, 5430000 ts, -91.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-29-22\n",
      "  done: false\n",
      "  episode_len_mean: 90.0\n",
      "  episode_reward_max: 9.105647743279826\n",
      "  episode_reward_mean: -80.71630948898134\n",
      "  episode_reward_min: -200.10017096906626\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 59684\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5204.583\n",
      "    load_time_ms: 1.678\n",
      "    num_steps_sampled: 5440000\n",
      "    num_steps_trained: 5440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3878434896469116\n",
      "      kl: 0.037279870361089706\n",
      "      policy_loss: 0.013884706422686577\n",
      "      total_loss: 1480.489013671875\n",
      "      vf_explained_var: 0.43621137738227844\n",
      "      vf_loss: 1480.4752197265625\n",
      "    sample_time_ms: 24511.452\n",
      "    update_time_ms: 6.697\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.35815474449067\n",
      "  time_since_restore: 15447.966753959656\n",
      "  time_this_iter_s: 30.539939165115356\n",
      "  time_total_s: 15447.966753959656\n",
      "  timestamp: 1554823762\n",
      "  timesteps_since_restore: 5440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5440000\n",
      "  training_iteration: 544\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15447 s, 544 iter, 5440000 ts, -80.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-29-52\n",
      "  done: false\n",
      "  episode_len_mean: 94.06542056074767\n",
      "  episode_reward_max: 9.733830667607148\n",
      "  episode_reward_mean: -68.96640761663582\n",
      "  episode_reward_min: -200.10186694368457\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 59791\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5239.954\n",
      "    load_time_ms: 1.678\n",
      "    num_steps_sampled: 5450000\n",
      "    num_steps_trained: 5450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.390132188796997\n",
      "      kl: 0.05667254701256752\n",
      "      policy_loss: 0.021026458591222763\n",
      "      total_loss: 1491.2041015625\n",
      "      vf_explained_var: 0.4179282486438751\n",
      "      vf_loss: 1491.18310546875\n",
      "    sample_time_ms: 24560.198\n",
      "    update_time_ms: 7.01\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.48320380831791\n",
      "  time_since_restore: 15478.023273706436\n",
      "  time_this_iter_s: 30.056519746780396\n",
      "  time_total_s: 15478.023273706436\n",
      "  timestamp: 1554823792\n",
      "  timesteps_since_restore: 5450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5450000\n",
      "  training_iteration: 545\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15478 s, 545 iter, 5450000 ts, -69 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-30-22\n",
      "  done: false\n",
      "  episode_len_mean: 86.99130434782609\n",
      "  episode_reward_max: 11.842812534918632\n",
      "  episode_reward_mean: -86.9888226508529\n",
      "  episode_reward_min: -200.12321271543107\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 59906\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5244.696\n",
      "    load_time_ms: 1.699\n",
      "    num_steps_sampled: 5460000\n",
      "    num_steps_trained: 5460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4021670818328857\n",
      "      kl: 0.04380529373884201\n",
      "      policy_loss: 0.01611054502427578\n",
      "      total_loss: 1379.0684814453125\n",
      "      vf_explained_var: 0.5149905681610107\n",
      "      vf_loss: 1379.05224609375\n",
      "    sample_time_ms: 24530.577\n",
      "    update_time_ms: 6.889\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.49441132542645\n",
      "  time_since_restore: 15507.577604293823\n",
      "  time_this_iter_s: 29.554330587387085\n",
      "  time_total_s: 15507.577604293823\n",
      "  timestamp: 1554823822\n",
      "  timesteps_since_restore: 5460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5460000\n",
      "  training_iteration: 546\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15507 s, 546 iter, 5460000 ts, -87 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-30-52\n",
      "  done: false\n",
      "  episode_len_mean: 82.2892561983471\n",
      "  episode_reward_max: 12.904603363447794\n",
      "  episode_reward_mean: -104.26418000356075\n",
      "  episode_reward_min: -200.1043758783867\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 60027\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5257.256\n",
      "    load_time_ms: 1.695\n",
      "    num_steps_sampled: 5470000\n",
      "    num_steps_trained: 5470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4060500860214233\n",
      "      kl: 0.0694664716720581\n",
      "      policy_loss: 0.027747850865125656\n",
      "      total_loss: 1295.2208251953125\n",
      "      vf_explained_var: 0.5434350371360779\n",
      "      vf_loss: 1295.1932373046875\n",
      "    sample_time_ms: 24569.972\n",
      "    update_time_ms: 7.268\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.13209000178039\n",
      "  time_since_restore: 15537.421701908112\n",
      "  time_this_iter_s: 29.84409761428833\n",
      "  time_total_s: 15537.421701908112\n",
      "  timestamp: 1554823852\n",
      "  timesteps_since_restore: 5470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5470000\n",
      "  training_iteration: 547\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15537 s, 547 iter, 5470000 ts, -104 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-31-21\n",
      "  done: false\n",
      "  episode_len_mean: 90.49549549549549\n",
      "  episode_reward_max: 8.760354398629925\n",
      "  episode_reward_mean: -79.37010912069074\n",
      "  episode_reward_min: -200.07997793730271\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 60138\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5237.539\n",
      "    load_time_ms: 1.691\n",
      "    num_steps_sampled: 5480000\n",
      "    num_steps_trained: 5480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3783667087554932\n",
      "      kl: 0.047070641070604324\n",
      "      policy_loss: 0.0159834586083889\n",
      "      total_loss: 1452.121337890625\n",
      "      vf_explained_var: 0.4805554747581482\n",
      "      vf_loss: 1452.1053466796875\n",
      "    sample_time_ms: 24575.83\n",
      "    update_time_ms: 7.233\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.68505456034536\n",
      "  time_since_restore: 15566.688871860504\n",
      "  time_this_iter_s: 29.267169952392578\n",
      "  time_total_s: 15566.688871860504\n",
      "  timestamp: 1554823881\n",
      "  timesteps_since_restore: 5480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5480000\n",
      "  training_iteration: 548\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15566 s, 548 iter, 5480000 ts, -79.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-31-51\n",
      "  done: false\n",
      "  episode_len_mean: 88.74107142857143\n",
      "  episode_reward_max: 11.498652412748221\n",
      "  episode_reward_mean: -84.21011688807802\n",
      "  episode_reward_min: -200.3884352731311\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 60250\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5225.581\n",
      "    load_time_ms: 1.683\n",
      "    num_steps_sampled: 5490000\n",
      "    num_steps_trained: 5490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3725574016571045\n",
      "      kl: 0.04649185389280319\n",
      "      policy_loss: 0.022670572623610497\n",
      "      total_loss: 1456.8585205078125\n",
      "      vf_explained_var: 0.4612951874732971\n",
      "      vf_loss: 1456.8359375\n",
      "    sample_time_ms: 24614.558\n",
      "    update_time_ms: 7.733\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.10505844403901\n",
      "  time_since_restore: 15596.739615678787\n",
      "  time_this_iter_s: 30.05074381828308\n",
      "  time_total_s: 15596.739615678787\n",
      "  timestamp: 1554823911\n",
      "  timesteps_since_restore: 5490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5490000\n",
      "  training_iteration: 549\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15596 s, 549 iter, 5490000 ts, -84.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-32-21\n",
      "  done: false\n",
      "  episode_len_mean: 89.5\n",
      "  episode_reward_max: 12.019898421135679\n",
      "  episode_reward_mean: -83.66635289401874\n",
      "  episode_reward_min: -200.11966526723336\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 60362\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5216.887\n",
      "    load_time_ms: 1.723\n",
      "    num_steps_sampled: 5500000\n",
      "    num_steps_trained: 5500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3896352052688599\n",
      "      kl: 0.05042813718318939\n",
      "      policy_loss: 0.023506231606006622\n",
      "      total_loss: 1406.966796875\n",
      "      vf_explained_var: 0.49056753516197205\n",
      "      vf_loss: 1406.943359375\n",
      "    sample_time_ms: 24651.84\n",
      "    update_time_ms: 7.643\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.83317644700937\n",
      "  time_since_restore: 15626.690474271774\n",
      "  time_this_iter_s: 29.95085859298706\n",
      "  time_total_s: 15626.690474271774\n",
      "  timestamp: 1554823941\n",
      "  timesteps_since_restore: 5500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5500000\n",
      "  training_iteration: 550\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15626 s, 550 iter, 5500000 ts, -83.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-32-51\n",
      "  done: false\n",
      "  episode_len_mean: 84.22033898305085\n",
      "  episode_reward_max: 12.510247549266087\n",
      "  episode_reward_mean: -96.2855005630177\n",
      "  episode_reward_min: -200.0856225927353\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 60480\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5219.067\n",
      "    load_time_ms: 1.728\n",
      "    num_steps_sampled: 5510000\n",
      "    num_steps_trained: 5510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3810880184173584\n",
      "      kl: 0.054907090961933136\n",
      "      policy_loss: 0.01905326545238495\n",
      "      total_loss: 1374.2578125\n",
      "      vf_explained_var: 0.49731093645095825\n",
      "      vf_loss: 1374.23876953125\n",
      "    sample_time_ms: 24634.442\n",
      "    update_time_ms: 7.928\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.142750281508846\n",
      "  time_since_restore: 15656.734706401825\n",
      "  time_this_iter_s: 30.04423213005066\n",
      "  time_total_s: 15656.734706401825\n",
      "  timestamp: 1554823971\n",
      "  timesteps_since_restore: 5510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5510000\n",
      "  training_iteration: 551\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15656 s, 551 iter, 5510000 ts, -96.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-33-21\n",
      "  done: false\n",
      "  episode_len_mean: 89.39285714285714\n",
      "  episode_reward_max: 13.70935796452193\n",
      "  episode_reward_mean: -81.94160737757501\n",
      "  episode_reward_min: -200.10003033437266\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 60592\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5206.764\n",
      "    load_time_ms: 1.744\n",
      "    num_steps_sampled: 5520000\n",
      "    num_steps_trained: 5520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.36627197265625\n",
      "      kl: 0.04174058884382248\n",
      "      policy_loss: 0.014664149843156338\n",
      "      total_loss: 1394.253662109375\n",
      "      vf_explained_var: 0.49440962076187134\n",
      "      vf_loss: 1394.2388916015625\n",
      "    sample_time_ms: 24628.689\n",
      "    update_time_ms: 8.34\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.970803688787505\n",
      "  time_since_restore: 15686.5862698555\n",
      "  time_this_iter_s: 29.851563453674316\n",
      "  time_total_s: 15686.5862698555\n",
      "  timestamp: 1554824001\n",
      "  timesteps_since_restore: 5520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5520000\n",
      "  training_iteration: 552\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15686 s, 552 iter, 5520000 ts, -81.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-33-50\n",
      "  done: false\n",
      "  episode_len_mean: 85.55932203389831\n",
      "  episode_reward_max: 14.091833330592467\n",
      "  episode_reward_mean: -92.81933072104131\n",
      "  episode_reward_min: -200.45062137604475\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 60710\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5213.693\n",
      "    load_time_ms: 1.705\n",
      "    num_steps_sampled: 5530000\n",
      "    num_steps_trained: 5530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3738479614257812\n",
      "      kl: 0.04234077408909798\n",
      "      policy_loss: 0.015811370685696602\n",
      "      total_loss: 1378.548828125\n",
      "      vf_explained_var: 0.4956035017967224\n",
      "      vf_loss: 1378.533203125\n",
      "    sample_time_ms: 24612.624\n",
      "    update_time_ms: 8.463\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.40966536052064\n",
      "  time_since_restore: 15716.017686367035\n",
      "  time_this_iter_s: 29.431416511535645\n",
      "  time_total_s: 15716.017686367035\n",
      "  timestamp: 1554824030\n",
      "  timesteps_since_restore: 5530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5530000\n",
      "  training_iteration: 553\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15716 s, 553 iter, 5530000 ts, -92.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-34-20\n",
      "  done: false\n",
      "  episode_len_mean: 89.5625\n",
      "  episode_reward_max: 9.477059935830916\n",
      "  episode_reward_mean: -80.37427549268504\n",
      "  episode_reward_min: -200.20657631027436\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 60822\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5230.739\n",
      "    load_time_ms: 1.563\n",
      "    num_steps_sampled: 5540000\n",
      "    num_steps_trained: 5540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3499681949615479\n",
      "      kl: 4.620334148406982\n",
      "      policy_loss: 0.15232278406620026\n",
      "      total_loss: 1475.3211669921875\n",
      "      vf_explained_var: 0.45700502395629883\n",
      "      vf_loss: 1475.1688232421875\n",
      "    sample_time_ms: 24501.271\n",
      "    update_time_ms: 8.523\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.187137746342515\n",
      "  time_since_restore: 15745.61747431755\n",
      "  time_this_iter_s: 29.599787950515747\n",
      "  time_total_s: 15745.61747431755\n",
      "  timestamp: 1554824060\n",
      "  timesteps_since_restore: 5540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5540000\n",
      "  training_iteration: 554\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15745 s, 554 iter, 5540000 ts, -80.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-34-50\n",
      "  done: false\n",
      "  episode_len_mean: 93.74528301886792\n",
      "  episode_reward_max: 12.941356894466983\n",
      "  episode_reward_mean: -70.90269937838049\n",
      "  episode_reward_min: -200.20710664982246\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 60928\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5214.052\n",
      "    load_time_ms: 1.515\n",
      "    num_steps_sampled: 5550000\n",
      "    num_steps_trained: 5550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3417925834655762\n",
      "      kl: 0.03213048726320267\n",
      "      policy_loss: 0.014209723100066185\n",
      "      total_loss: 1482.9208984375\n",
      "      vf_explained_var: 0.43097081780433655\n",
      "      vf_loss: 1482.9066162109375\n",
      "    sample_time_ms: 24452.09\n",
      "    update_time_ms: 8.318\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.451349689190245\n",
      "  time_since_restore: 15775.010410308838\n",
      "  time_this_iter_s: 29.39293599128723\n",
      "  time_total_s: 15775.010410308838\n",
      "  timestamp: 1554824090\n",
      "  timesteps_since_restore: 5550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5550000\n",
      "  training_iteration: 555\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15775 s, 555 iter, 5550000 ts, -70.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-35-19\n",
      "  done: false\n",
      "  episode_len_mean: 82.77685950413223\n",
      "  episode_reward_max: 13.544432030833768\n",
      "  episode_reward_mean: -100.66084217979353\n",
      "  episode_reward_min: -200.2387212221565\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 61049\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5185.459\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 5560000\n",
      "    num_steps_trained: 5560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3580515384674072\n",
      "      kl: 0.04686131328344345\n",
      "      policy_loss: 0.016461174935102463\n",
      "      total_loss: 1366.4700927734375\n",
      "      vf_explained_var: 0.529330313205719\n",
      "      vf_loss: 1366.4537353515625\n",
      "    sample_time_ms: 24469.418\n",
      "    update_time_ms: 8.363\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.33042108989677\n",
      "  time_since_restore: 15804.449192762375\n",
      "  time_this_iter_s: 29.438782453536987\n",
      "  time_total_s: 15804.449192762375\n",
      "  timestamp: 1554824119\n",
      "  timesteps_since_restore: 5560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5560000\n",
      "  training_iteration: 556\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15804 s, 556 iter, 5560000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-35-49\n",
      "  done: false\n",
      "  episode_len_mean: 84.42857142857143\n",
      "  episode_reward_max: 12.095251075788406\n",
      "  episode_reward_mean: -93.79564148822115\n",
      "  episode_reward_min: -200.24315242568338\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 61168\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5173.822\n",
      "    load_time_ms: 1.516\n",
      "    num_steps_sampled: 5570000\n",
      "    num_steps_trained: 5570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3426218032836914\n",
      "      kl: 0.04510708898305893\n",
      "      policy_loss: 0.019009487703442574\n",
      "      total_loss: 1395.2581787109375\n",
      "      vf_explained_var: 0.5100430250167847\n",
      "      vf_loss: 1395.2391357421875\n",
      "    sample_time_ms: 24445.377\n",
      "    update_time_ms: 8.477\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.89782074411059\n",
      "  time_since_restore: 15833.938601016998\n",
      "  time_this_iter_s: 29.489408254623413\n",
      "  time_total_s: 15833.938601016998\n",
      "  timestamp: 1554824149\n",
      "  timesteps_since_restore: 5570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5570000\n",
      "  training_iteration: 557\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15833 s, 557 iter, 5570000 ts, -93.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-36-18\n",
      "  done: false\n",
      "  episode_len_mean: 87.83185840707965\n",
      "  episode_reward_max: 13.181796792689601\n",
      "  episode_reward_mean: -86.53722671750953\n",
      "  episode_reward_min: -200.53490422769448\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 61281\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5202.09\n",
      "    load_time_ms: 1.552\n",
      "    num_steps_sampled: 5580000\n",
      "    num_steps_trained: 5580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.344350814819336\n",
      "      kl: 0.03613793104887009\n",
      "      policy_loss: 0.014822605066001415\n",
      "      total_loss: 1441.08837890625\n",
      "      vf_explained_var: 0.47863808274269104\n",
      "      vf_loss: 1441.0736083984375\n",
      "    sample_time_ms: 24436.227\n",
      "    update_time_ms: 8.426\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.26861335875476\n",
      "  time_since_restore: 15863.402519464493\n",
      "  time_this_iter_s: 29.463918447494507\n",
      "  time_total_s: 15863.402519464493\n",
      "  timestamp: 1554824178\n",
      "  timesteps_since_restore: 5580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5580000\n",
      "  training_iteration: 558\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15863 s, 558 iter, 5580000 ts, -86.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-36-48\n",
      "  done: false\n",
      "  episode_len_mean: 80.24193548387096\n",
      "  episode_reward_max: 12.396522044060857\n",
      "  episode_reward_mean: -106.86648975273869\n",
      "  episode_reward_min: -200.20082937939122\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 61405\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5191.872\n",
      "    load_time_ms: 1.561\n",
      "    num_steps_sampled: 5590000\n",
      "    num_steps_trained: 5590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3539801836013794\n",
      "      kl: 0.04655785486102104\n",
      "      policy_loss: 0.01842726580798626\n",
      "      total_loss: 1340.8358154296875\n",
      "      vf_explained_var: 0.5243731141090393\n",
      "      vf_loss: 1340.8175048828125\n",
      "    sample_time_ms: 24425.704\n",
      "    update_time_ms: 7.783\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -53.43324487636934\n",
      "  time_since_restore: 15893.241538763046\n",
      "  time_this_iter_s: 29.839019298553467\n",
      "  time_total_s: 15893.241538763046\n",
      "  timestamp: 1554824208\n",
      "  timesteps_since_restore: 5590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5590000\n",
      "  training_iteration: 559\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15893 s, 559 iter, 5590000 ts, -107 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-37-18\n",
      "  done: false\n",
      "  episode_len_mean: 81.31451612903226\n",
      "  episode_reward_max: 10.363520070833975\n",
      "  episode_reward_mean: -105.31931940042018\n",
      "  episode_reward_min: -200.27997502434033\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 61529\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5193.074\n",
      "    load_time_ms: 1.544\n",
      "    num_steps_sampled: 5600000\n",
      "    num_steps_trained: 5600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3546398878097534\n",
      "      kl: 0.05156809091567993\n",
      "      policy_loss: 0.021376796066761017\n",
      "      total_loss: 1303.8896484375\n",
      "      vf_explained_var: 0.557715892791748\n",
      "      vf_loss: 1303.8681640625\n",
      "    sample_time_ms: 24435.819\n",
      "    update_time_ms: 7.807\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.65965970021008\n",
      "  time_since_restore: 15923.301320791245\n",
      "  time_this_iter_s: 30.059782028198242\n",
      "  time_total_s: 15923.301320791245\n",
      "  timestamp: 1554824238\n",
      "  timesteps_since_restore: 5600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5600000\n",
      "  training_iteration: 560\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15923 s, 560 iter, 5600000 ts, -105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-37-48\n",
      "  done: false\n",
      "  episode_len_mean: 86.93859649122807\n",
      "  episode_reward_max: 13.999765816210441\n",
      "  episode_reward_mean: -87.98234050371919\n",
      "  episode_reward_min: -200.42654264723933\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 61643\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5222.14\n",
      "    load_time_ms: 1.628\n",
      "    num_steps_sampled: 5610000\n",
      "    num_steps_trained: 5610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3406753540039062\n",
      "      kl: 0.7476603388786316\n",
      "      policy_loss: 0.04689444229006767\n",
      "      total_loss: 1400.4984130859375\n",
      "      vf_explained_var: 0.5191563367843628\n",
      "      vf_loss: 1400.4515380859375\n",
      "    sample_time_ms: 24373.563\n",
      "    update_time_ms: 7.348\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.99117025185959\n",
      "  time_since_restore: 15953.01456451416\n",
      "  time_this_iter_s: 29.71324372291565\n",
      "  time_total_s: 15953.01456451416\n",
      "  timestamp: 1554824268\n",
      "  timesteps_since_restore: 5610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5610000\n",
      "  training_iteration: 561\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15953 s, 561 iter, 5610000 ts, -88 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-38-18\n",
      "  done: false\n",
      "  episode_len_mean: 84.23333333333333\n",
      "  episode_reward_max: 13.050650806649152\n",
      "  episode_reward_mean: -94.81216098800981\n",
      "  episode_reward_min: -200.2772280105145\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 61763\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5254.671\n",
      "    load_time_ms: 1.612\n",
      "    num_steps_sampled: 5620000\n",
      "    num_steps_trained: 5620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3479148149490356\n",
      "      kl: 0.035363148897886276\n",
      "      policy_loss: 0.01655852422118187\n",
      "      total_loss: 1361.578125\n",
      "      vf_explained_var: 0.53857421875\n",
      "      vf_loss: 1361.5615234375\n",
      "    sample_time_ms: 24354.168\n",
      "    update_time_ms: 7.135\n",
      "  iterations_since_restore: 562\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.406080494004904\n",
      "  time_since_restore: 15982.991539001465\n",
      "  time_this_iter_s: 29.976974487304688\n",
      "  time_total_s: 15982.991539001465\n",
      "  timestamp: 1554824298\n",
      "  timesteps_since_restore: 5620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5620000\n",
      "  training_iteration: 562\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 15982 s, 562 iter, 5620000 ts, -94.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-38-47\n",
      "  done: false\n",
      "  episode_len_mean: 89.66666666666667\n",
      "  episode_reward_max: 12.449150236020428\n",
      "  episode_reward_mean: -81.37314758934836\n",
      "  episode_reward_min: -200.23230292641546\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 61874\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5273.865\n",
      "    load_time_ms: 1.626\n",
      "    num_steps_sampled: 5630000\n",
      "    num_steps_trained: 5630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3438063859939575\n",
      "      kl: 0.032313939183950424\n",
      "      policy_loss: 0.011664116755127907\n",
      "      total_loss: 1411.7318115234375\n",
      "      vf_explained_var: 0.5063166618347168\n",
      "      vf_loss: 1411.719970703125\n",
      "    sample_time_ms: 24347.501\n",
      "    update_time_ms: 6.867\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.68657379467418\n",
      "  time_since_restore: 16012.545782327652\n",
      "  time_this_iter_s: 29.554243326187134\n",
      "  time_total_s: 16012.545782327652\n",
      "  timestamp: 1554824327\n",
      "  timesteps_since_restore: 5630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5630000\n",
      "  training_iteration: 563\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16012 s, 563 iter, 5630000 ts, -81.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-39-17\n",
      "  done: false\n",
      "  episode_len_mean: 85.05084745762711\n",
      "  episode_reward_max: 12.160970775217816\n",
      "  episode_reward_mean: -94.9997382175226\n",
      "  episode_reward_min: -200.2088433635235\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 61992\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5283.624\n",
      "    load_time_ms: 1.65\n",
      "    num_steps_sampled: 5640000\n",
      "    num_steps_trained: 5640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.359794020652771\n",
      "      kl: 0.04735291004180908\n",
      "      policy_loss: 0.01401609368622303\n",
      "      total_loss: 1421.484619140625\n",
      "      vf_explained_var: 0.5276164412498474\n",
      "      vf_loss: 1421.470703125\n",
      "    sample_time_ms: 24297.06\n",
      "    update_time_ms: 6.921\n",
      "  iterations_since_restore: 564\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.49986910876131\n",
      "  time_since_restore: 16041.735728025436\n",
      "  time_this_iter_s: 29.189945697784424\n",
      "  time_total_s: 16041.735728025436\n",
      "  timestamp: 1554824357\n",
      "  timesteps_since_restore: 5640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5640000\n",
      "  training_iteration: 564\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16041 s, 564 iter, 5640000 ts, -95 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-39-47\n",
      "  done: false\n",
      "  episode_len_mean: 89.35135135135135\n",
      "  episode_reward_max: 14.3732892712896\n",
      "  episode_reward_mean: -82.832690837971\n",
      "  episode_reward_min: -200.12920362436773\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 62103\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5297.882\n",
      "    load_time_ms: 1.677\n",
      "    num_steps_sampled: 5650000\n",
      "    num_steps_trained: 5650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3493658304214478\n",
      "      kl: 0.03583317995071411\n",
      "      policy_loss: 0.012101346626877785\n",
      "      total_loss: 1439.9993896484375\n",
      "      vf_explained_var: 0.49387773871421814\n",
      "      vf_loss: 1439.9874267578125\n",
      "    sample_time_ms: 24328.312\n",
      "    update_time_ms: 6.891\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.41634541898551\n",
      "  time_since_restore: 16071.584961175919\n",
      "  time_this_iter_s: 29.849233150482178\n",
      "  time_total_s: 16071.584961175919\n",
      "  timestamp: 1554824387\n",
      "  timesteps_since_restore: 5650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5650000\n",
      "  training_iteration: 565\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16071 s, 565 iter, 5650000 ts, -82.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-40-17\n",
      "  done: false\n",
      "  episode_len_mean: 88.51754385964912\n",
      "  episode_reward_max: 9.709937395006214\n",
      "  episode_reward_mean: -86.92672133773492\n",
      "  episode_reward_min: -200.08430561771263\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 62217\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5336.776\n",
      "    load_time_ms: 1.678\n",
      "    num_steps_sampled: 5660000\n",
      "    num_steps_trained: 5660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3477272987365723\n",
      "      kl: 0.03185547888278961\n",
      "      policy_loss: 0.012274510227143764\n",
      "      total_loss: 1320.5594482421875\n",
      "      vf_explained_var: 0.542119026184082\n",
      "      vf_loss: 1320.547119140625\n",
      "    sample_time_ms: 24343.924\n",
      "    update_time_ms: 7.004\n",
      "  iterations_since_restore: 566\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.46336066886745\n",
      "  time_since_restore: 16101.568738937378\n",
      "  time_this_iter_s: 29.98377776145935\n",
      "  time_total_s: 16101.568738937378\n",
      "  timestamp: 1554824417\n",
      "  timesteps_since_restore: 5660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5660000\n",
      "  training_iteration: 566\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16101 s, 566 iter, 5660000 ts, -86.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-40-46\n",
      "  done: false\n",
      "  episode_len_mean: 90.17272727272727\n",
      "  episode_reward_max: 12.651232946087788\n",
      "  episode_reward_mean: -78.56921989606427\n",
      "  episode_reward_min: -200.31308210527578\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 62327\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5356.398\n",
      "    load_time_ms: 1.665\n",
      "    num_steps_sampled: 5670000\n",
      "    num_steps_trained: 5670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3475768566131592\n",
      "      kl: 0.04076477140188217\n",
      "      policy_loss: 0.009232680313289165\n",
      "      total_loss: 1405.3897705078125\n",
      "      vf_explained_var: 0.5006073117256165\n",
      "      vf_loss: 1405.380615234375\n",
      "    sample_time_ms: 24339.917\n",
      "    update_time_ms: 6.325\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.28460994803212\n",
      "  time_since_restore: 16131.202043533325\n",
      "  time_this_iter_s: 29.633304595947266\n",
      "  time_total_s: 16131.202043533325\n",
      "  timestamp: 1554824446\n",
      "  timesteps_since_restore: 5670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5670000\n",
      "  training_iteration: 567\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16131 s, 567 iter, 5670000 ts, -78.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-41-16\n",
      "  done: false\n",
      "  episode_len_mean: 88.23008849557522\n",
      "  episode_reward_max: 10.393287760832667\n",
      "  episode_reward_mean: -85.4230422156818\n",
      "  episode_reward_min: -200.35688125213858\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 62440\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5360.491\n",
      "    load_time_ms: 1.63\n",
      "    num_steps_sampled: 5680000\n",
      "    num_steps_trained: 5680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.348288893699646\n",
      "      kl: 0.03511080890893936\n",
      "      policy_loss: 0.013395486399531364\n",
      "      total_loss: 1306.140869140625\n",
      "      vf_explained_var: 0.5248494148254395\n",
      "      vf_loss: 1306.12744140625\n",
      "    sample_time_ms: 24388.489\n",
      "    update_time_ms: 6.57\n",
      "  iterations_since_restore: 568\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.7115211078409\n",
      "  time_since_restore: 16161.189915418625\n",
      "  time_this_iter_s: 29.987871885299683\n",
      "  time_total_s: 16161.189915418625\n",
      "  timestamp: 1554824476\n",
      "  timesteps_since_restore: 5680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5680000\n",
      "  training_iteration: 568\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16161 s, 568 iter, 5680000 ts, -85.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-41-47\n",
      "  done: false\n",
      "  episode_len_mean: 90.35135135135135\n",
      "  episode_reward_max: 10.042079820818845\n",
      "  episode_reward_mean: -79.92415888974615\n",
      "  episode_reward_min: -200.14905690238837\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 62551\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5386.553\n",
      "    load_time_ms: 1.647\n",
      "    num_steps_sampled: 5690000\n",
      "    num_steps_trained: 5690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.355130910873413\n",
      "      kl: 0.035904329270124435\n",
      "      policy_loss: 0.012978969141840935\n",
      "      total_loss: 1374.6558837890625\n",
      "      vf_explained_var: 0.5416743159294128\n",
      "      vf_loss: 1374.6427001953125\n",
      "    sample_time_ms: 24423.716\n",
      "    update_time_ms: 6.535\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.96207944487308\n",
      "  time_since_restore: 16191.641250133514\n",
      "  time_this_iter_s: 30.451334714889526\n",
      "  time_total_s: 16191.641250133514\n",
      "  timestamp: 1554824507\n",
      "  timesteps_since_restore: 5690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5690000\n",
      "  training_iteration: 569\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16191 s, 569 iter, 5690000 ts, -79.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-42-17\n",
      "  done: false\n",
      "  episode_len_mean: 87.00862068965517\n",
      "  episode_reward_max: 13.181808735145935\n",
      "  episode_reward_mean: -88.30415050077696\n",
      "  episode_reward_min: -200.17944230994596\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 62667\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5413.162\n",
      "    load_time_ms: 1.614\n",
      "    num_steps_sampled: 5700000\n",
      "    num_steps_trained: 5700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3583992719650269\n",
      "      kl: 0.05215946212410927\n",
      "      policy_loss: 0.02139795757830143\n",
      "      total_loss: 1309.7442626953125\n",
      "      vf_explained_var: 0.5569157004356384\n",
      "      vf_loss: 1309.722900390625\n",
      "    sample_time_ms: 24453.713\n",
      "    update_time_ms: 6.524\n",
      "  iterations_since_restore: 570\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.152075250388485\n",
      "  time_since_restore: 16222.267513036728\n",
      "  time_this_iter_s: 30.6262629032135\n",
      "  time_total_s: 16222.267513036728\n",
      "  timestamp: 1554824537\n",
      "  timesteps_since_restore: 5700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5700000\n",
      "  training_iteration: 570\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16222 s, 570 iter, 5700000 ts, -88.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-42-47\n",
      "  done: false\n",
      "  episode_len_mean: 85.3931623931624\n",
      "  episode_reward_max: 14.000819386427187\n",
      "  episode_reward_mean: -94.32223391810852\n",
      "  episode_reward_min: -200.5217053254297\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 62784\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5405.718\n",
      "    load_time_ms: 1.779\n",
      "    num_steps_sampled: 5710000\n",
      "    num_steps_trained: 5710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.35990571975708\n",
      "      kl: 0.035920243710279465\n",
      "      policy_loss: 0.011391711421310902\n",
      "      total_loss: 1423.33837890625\n",
      "      vf_explained_var: 0.5321146249771118\n",
      "      vf_loss: 1423.3270263671875\n",
      "    sample_time_ms: 24447.181\n",
      "    update_time_ms: 7.329\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.161116959054276\n",
      "  time_since_restore: 16251.847489118576\n",
      "  time_this_iter_s: 29.579976081848145\n",
      "  time_total_s: 16251.847489118576\n",
      "  timestamp: 1554824567\n",
      "  timesteps_since_restore: 5710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5710000\n",
      "  training_iteration: 571\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16251 s, 571 iter, 5710000 ts, -94.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-43-17\n",
      "  done: false\n",
      "  episode_len_mean: 84.5677966101695\n",
      "  episode_reward_max: 11.2589519863569\n",
      "  episode_reward_mean: -96.53375805371238\n",
      "  episode_reward_min: -200.2262678271532\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 62902\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5380.79\n",
      "    load_time_ms: 1.844\n",
      "    num_steps_sampled: 5720000\n",
      "    num_steps_trained: 5720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.359588623046875\n",
      "      kl: 0.03715299442410469\n",
      "      policy_loss: 0.009089159779250622\n",
      "      total_loss: 1362.6522216796875\n",
      "      vf_explained_var: 0.5474982857704163\n",
      "      vf_loss: 1362.6431884765625\n",
      "    sample_time_ms: 24410.199\n",
      "    update_time_ms: 7.291\n",
      "  iterations_since_restore: 572\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.26687902685619\n",
      "  time_since_restore: 16281.207086086273\n",
      "  time_this_iter_s: 29.359596967697144\n",
      "  time_total_s: 16281.207086086273\n",
      "  timestamp: 1554824597\n",
      "  timesteps_since_restore: 5720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5720000\n",
      "  training_iteration: 572\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16281 s, 572 iter, 5720000 ts, -96.5 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-43-47\n",
      "  done: false\n",
      "  episode_len_mean: 89.48648648648648\n",
      "  episode_reward_max: 11.934569596053604\n",
      "  episode_reward_mean: -80.98061862540615\n",
      "  episode_reward_min: -200.2475320923918\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 63013\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5368.452\n",
      "    load_time_ms: 1.941\n",
      "    num_steps_sampled: 5730000\n",
      "    num_steps_trained: 5730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.347485065460205\n",
      "      kl: 0.04686831310391426\n",
      "      policy_loss: 0.019554298371076584\n",
      "      total_loss: 1513.693359375\n",
      "      vf_explained_var: 0.43563589453697205\n",
      "      vf_loss: 1513.6737060546875\n",
      "    sample_time_ms: 24484.554\n",
      "    update_time_ms: 7.726\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.490309312703076\n",
      "  time_since_restore: 16311.384813308716\n",
      "  time_this_iter_s: 30.177727222442627\n",
      "  time_total_s: 16311.384813308716\n",
      "  timestamp: 1554824627\n",
      "  timesteps_since_restore: 5730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5730000\n",
      "  training_iteration: 573\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16311 s, 573 iter, 5730000 ts, -81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-44-17\n",
      "  done: false\n",
      "  episode_len_mean: 88.28318584070796\n",
      "  episode_reward_max: 13.386268901037973\n",
      "  episode_reward_mean: -85.17348965093366\n",
      "  episode_reward_min: -200.55871246771787\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 63126\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5355.076\n",
      "    load_time_ms: 1.901\n",
      "    num_steps_sampled: 5740000\n",
      "    num_steps_trained: 5740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3570547103881836\n",
      "      kl: 0.036161623895168304\n",
      "      policy_loss: 0.013374977745115757\n",
      "      total_loss: 1445.9483642578125\n",
      "      vf_explained_var: 0.4900061786174774\n",
      "      vf_loss: 1445.9349365234375\n",
      "    sample_time_ms: 24574.692\n",
      "    update_time_ms: 7.685\n",
      "  iterations_since_restore: 574\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.58674482546684\n",
      "  time_since_restore: 16341.345037460327\n",
      "  time_this_iter_s: 29.960224151611328\n",
      "  time_total_s: 16341.345037460327\n",
      "  timestamp: 1554824657\n",
      "  timesteps_since_restore: 5740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5740000\n",
      "  training_iteration: 574\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16341 s, 574 iter, 5740000 ts, -85.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-44-47\n",
      "  done: false\n",
      "  episode_len_mean: 84.94017094017094\n",
      "  episode_reward_max: 14.080460646062239\n",
      "  episode_reward_mean: -95.28025173577174\n",
      "  episode_reward_min: -200.35700620231802\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 63243\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5339.482\n",
      "    load_time_ms: 1.897\n",
      "    num_steps_sampled: 5750000\n",
      "    num_steps_trained: 5750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3689604997634888\n",
      "      kl: 0.0653112381696701\n",
      "      policy_loss: 0.02500501275062561\n",
      "      total_loss: 1386.90869140625\n",
      "      vf_explained_var: 0.5391302108764648\n",
      "      vf_loss: 1386.8836669921875\n",
      "    sample_time_ms: 24599.524\n",
      "    update_time_ms: 7.982\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.640125867885885\n",
      "  time_since_restore: 16371.285928487778\n",
      "  time_this_iter_s: 29.94089102745056\n",
      "  time_total_s: 16371.285928487778\n",
      "  timestamp: 1554824687\n",
      "  timesteps_since_restore: 5750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5750000\n",
      "  training_iteration: 575\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16371 s, 575 iter, 5750000 ts, -95.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-45-16\n",
      "  done: false\n",
      "  episode_len_mean: 87.4695652173913\n",
      "  episode_reward_max: 11.236603861756077\n",
      "  episode_reward_mean: -88.36112858619994\n",
      "  episode_reward_min: -200.1375500144158\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 63358\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5327.385\n",
      "    load_time_ms: 1.932\n",
      "    num_steps_sampled: 5760000\n",
      "    num_steps_trained: 5760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3570760488510132\n",
      "      kl: 0.038861844688653946\n",
      "      policy_loss: 0.016208894550800323\n",
      "      total_loss: 1355.185302734375\n",
      "      vf_explained_var: 0.5185518264770508\n",
      "      vf_loss: 1355.1689453125\n",
      "    sample_time_ms: 24577.912\n",
      "    update_time_ms: 8.018\n",
      "  iterations_since_restore: 576\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.18056429309997\n",
      "  time_since_restore: 16400.933940172195\n",
      "  time_this_iter_s: 29.648011684417725\n",
      "  time_total_s: 16400.933940172195\n",
      "  timestamp: 1554824716\n",
      "  timesteps_since_restore: 5760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5760000\n",
      "  training_iteration: 576\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16400 s, 576 iter, 5760000 ts, -88.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-45-47\n",
      "  done: false\n",
      "  episode_len_mean: 87.6086956521739\n",
      "  episode_reward_max: 14.235570102357391\n",
      "  episode_reward_mean: -86.63337298781292\n",
      "  episode_reward_min: -200.15695565183336\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 63473\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5337.493\n",
      "    load_time_ms: 1.966\n",
      "    num_steps_sampled: 5770000\n",
      "    num_steps_trained: 5770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3590608835220337\n",
      "      kl: 0.040939878672361374\n",
      "      policy_loss: 0.016194934025406837\n",
      "      total_loss: 1386.3055419921875\n",
      "      vf_explained_var: 0.4995873272418976\n",
      "      vf_loss: 1386.289306640625\n",
      "    sample_time_ms: 24623.944\n",
      "    update_time_ms: 7.98\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.31668649390647\n",
      "  time_since_restore: 16431.132261753082\n",
      "  time_this_iter_s: 30.19832158088684\n",
      "  time_total_s: 16431.132261753082\n",
      "  timestamp: 1554824747\n",
      "  timesteps_since_restore: 5770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5770000\n",
      "  training_iteration: 577\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16431 s, 577 iter, 5770000 ts, -86.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-46-17\n",
      "  done: false\n",
      "  episode_len_mean: 84.41176470588235\n",
      "  episode_reward_max: 13.587062742000471\n",
      "  episode_reward_mean: -95.14597777417279\n",
      "  episode_reward_min: -200.1860591520071\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 63592\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5341.302\n",
      "    load_time_ms: 2.007\n",
      "    num_steps_sampled: 5780000\n",
      "    num_steps_trained: 5780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3702257871627808\n",
      "      kl: 0.030989395454525948\n",
      "      policy_loss: 0.008098631165921688\n",
      "      total_loss: 1325.84130859375\n",
      "      vf_explained_var: 0.5625647306442261\n",
      "      vf_loss: 1325.8333740234375\n",
      "    sample_time_ms: 24660.81\n",
      "    update_time_ms: 7.726\n",
      "  iterations_since_restore: 578\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.5729888870864\n",
      "  time_since_restore: 16461.52520251274\n",
      "  time_this_iter_s: 30.392940759658813\n",
      "  time_total_s: 16461.52520251274\n",
      "  timestamp: 1554824777\n",
      "  timesteps_since_restore: 5780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5780000\n",
      "  training_iteration: 578\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16461 s, 578 iter, 5780000 ts, -95.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-46-47\n",
      "  done: false\n",
      "  episode_len_mean: 81.00819672131148\n",
      "  episode_reward_max: 10.76377294281763\n",
      "  episode_reward_mean: -105.23176756421678\n",
      "  episode_reward_min: -200.22882718799463\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 63714\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5326.128\n",
      "    load_time_ms: 2.032\n",
      "    num_steps_sampled: 5790000\n",
      "    num_steps_trained: 5790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3737467527389526\n",
      "      kl: 0.041132718324661255\n",
      "      policy_loss: 0.01670774258673191\n",
      "      total_loss: 1300.9715576171875\n",
      "      vf_explained_var: 0.5644580125808716\n",
      "      vf_loss: 1300.9549560546875\n",
      "    sample_time_ms: 24622.565\n",
      "    update_time_ms: 8.713\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.615883782108384\n",
      "  time_since_restore: 16491.450280427933\n",
      "  time_this_iter_s: 29.92507791519165\n",
      "  time_total_s: 16491.450280427933\n",
      "  timestamp: 1554824807\n",
      "  timesteps_since_restore: 5790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5790000\n",
      "  training_iteration: 579\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16491 s, 579 iter, 5790000 ts, -105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-47-17\n",
      "  done: false\n",
      "  episode_len_mean: 93.50925925925925\n",
      "  episode_reward_max: 14.714486662076922\n",
      "  episode_reward_mean: -70.15301788971455\n",
      "  episode_reward_min: -200.1380322060107\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 63822\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5327.418\n",
      "    load_time_ms: 2.029\n",
      "    num_steps_sampled: 5800000\n",
      "    num_steps_trained: 5800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.357357382774353\n",
      "      kl: 0.05261366069316864\n",
      "      policy_loss: 0.02135363221168518\n",
      "      total_loss: 1354.51611328125\n",
      "      vf_explained_var: 0.4897103011608124\n",
      "      vf_loss: 1354.494873046875\n",
      "    sample_time_ms: 24567.308\n",
      "    update_time_ms: 8.724\n",
      "  iterations_since_restore: 580\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -35.076508944857274\n",
      "  time_since_restore: 16521.535712480545\n",
      "  time_this_iter_s: 30.085432052612305\n",
      "  time_total_s: 16521.535712480545\n",
      "  timestamp: 1554824837\n",
      "  timesteps_since_restore: 5800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5800000\n",
      "  training_iteration: 580\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16521 s, 580 iter, 5800000 ts, -70.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-47-47\n",
      "  done: false\n",
      "  episode_len_mean: 83.57627118644068\n",
      "  episode_reward_max: 11.2511005467365\n",
      "  episode_reward_mean: -98.10400580458816\n",
      "  episode_reward_min: -200.24409960655146\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 63940\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5318.109\n",
      "    load_time_ms: 1.769\n",
      "    num_steps_sampled: 5810000\n",
      "    num_steps_trained: 5810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.369903326034546\n",
      "      kl: 0.03761608153581619\n",
      "      policy_loss: 0.014849567785859108\n",
      "      total_loss: 1361.0321044921875\n",
      "      vf_explained_var: 0.5226872563362122\n",
      "      vf_loss: 1361.01708984375\n",
      "    sample_time_ms: 24542.912\n",
      "    update_time_ms: 8.575\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.05200290229408\n",
      "  time_since_restore: 16550.773171663284\n",
      "  time_this_iter_s: 29.237459182739258\n",
      "  time_total_s: 16550.773171663284\n",
      "  timestamp: 1554824867\n",
      "  timesteps_since_restore: 5810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5810000\n",
      "  training_iteration: 581\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16550 s, 581 iter, 5810000 ts, -98.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-48-17\n",
      "  done: false\n",
      "  episode_len_mean: 86.6923076923077\n",
      "  episode_reward_max: 11.875392327753596\n",
      "  episode_reward_mean: -88.99014163514464\n",
      "  episode_reward_min: -200.2846958833829\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 64057\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5320.313\n",
      "    load_time_ms: 1.688\n",
      "    num_steps_sampled: 5820000\n",
      "    num_steps_trained: 5820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.373234510421753\n",
      "      kl: 0.06884155422449112\n",
      "      policy_loss: 0.027587376534938812\n",
      "      total_loss: 1400.0638427734375\n",
      "      vf_explained_var: 0.5113945007324219\n",
      "      vf_loss: 1400.036376953125\n",
      "    sample_time_ms: 24600.421\n",
      "    update_time_ms: 8.578\n",
      "  iterations_since_restore: 582\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.49507081757233\n",
      "  time_since_restore: 16580.727956533432\n",
      "  time_this_iter_s: 29.954784870147705\n",
      "  time_total_s: 16580.727956533432\n",
      "  timestamp: 1554824897\n",
      "  timesteps_since_restore: 5820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5820000\n",
      "  training_iteration: 582\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16580 s, 582 iter, 5820000 ts, -89 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-48-46\n",
      "  done: false\n",
      "  episode_len_mean: 87.1304347826087\n",
      "  episode_reward_max: 10.925739907464852\n",
      "  episode_reward_mean: -87.2242378245476\n",
      "  episode_reward_min: -200.25438880453686\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 64172\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5323.056\n",
      "    load_time_ms: 1.576\n",
      "    num_steps_sampled: 5830000\n",
      "    num_steps_trained: 5830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3595420122146606\n",
      "      kl: 0.04348673298954964\n",
      "      policy_loss: 0.017727749422192574\n",
      "      total_loss: 1490.4840087890625\n",
      "      vf_explained_var: 0.48775237798690796\n",
      "      vf_loss: 1490.4661865234375\n",
      "    sample_time_ms: 24531.556\n",
      "    update_time_ms: 8.401\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.61211891227381\n",
      "  time_since_restore: 16610.247744083405\n",
      "  time_this_iter_s: 29.519787549972534\n",
      "  time_total_s: 16610.247744083405\n",
      "  timestamp: 1554824926\n",
      "  timesteps_since_restore: 5830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5830000\n",
      "  training_iteration: 583\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16610 s, 583 iter, 5830000 ts, -87.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-49-15\n",
      "  done: false\n",
      "  episode_len_mean: 91.90654205607477\n",
      "  episode_reward_max: 8.510611587450342\n",
      "  episode_reward_mean: -76.60727674058863\n",
      "  episode_reward_min: -200.93157138473003\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 64279\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5337.784\n",
      "    load_time_ms: 1.54\n",
      "    num_steps_sampled: 5840000\n",
      "    num_steps_trained: 5840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3579169511795044\n",
      "      kl: 0.05121944099664688\n",
      "      policy_loss: 0.024601105600595474\n",
      "      total_loss: 1462.21142578125\n",
      "      vf_explained_var: 0.46533453464508057\n",
      "      vf_loss: 1462.186767578125\n",
      "    sample_time_ms: 24450.236\n",
      "    update_time_ms: 8.467\n",
      "  iterations_since_restore: 584\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.303638370294316\n",
      "  time_since_restore: 16639.539023399353\n",
      "  time_this_iter_s: 29.291279315948486\n",
      "  time_total_s: 16639.539023399353\n",
      "  timestamp: 1554824955\n",
      "  timesteps_since_restore: 5840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5840000\n",
      "  training_iteration: 584\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16639 s, 584 iter, 5840000 ts, -76.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-49-45\n",
      "  done: false\n",
      "  episode_len_mean: 85.05084745762711\n",
      "  episode_reward_max: 12.850216255137793\n",
      "  episode_reward_mean: -92.77724077536307\n",
      "  episode_reward_min: -200.33271043702723\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 64397\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5367.353\n",
      "    load_time_ms: 1.541\n",
      "    num_steps_sampled: 5850000\n",
      "    num_steps_trained: 5850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3697729110717773\n",
      "      kl: 0.03462463989853859\n",
      "      policy_loss: 0.016350001096725464\n",
      "      total_loss: 1402.738525390625\n",
      "      vf_explained_var: 0.5187689661979675\n",
      "      vf_loss: 1402.722412109375\n",
      "    sample_time_ms: 24423.913\n",
      "    update_time_ms: 8.175\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.38862038768153\n",
      "  time_since_restore: 16669.513526439667\n",
      "  time_this_iter_s: 29.97450304031372\n",
      "  time_total_s: 16669.513526439667\n",
      "  timestamp: 1554824985\n",
      "  timesteps_since_restore: 5850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5850000\n",
      "  training_iteration: 585\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16669 s, 585 iter, 5850000 ts, -92.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-50-15\n",
      "  done: false\n",
      "  episode_len_mean: 87.70434782608696\n",
      "  episode_reward_max: 14.347903824113176\n",
      "  episode_reward_mean: -84.35938729130967\n",
      "  episode_reward_min: -200.46821431236833\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 64512\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5353.854\n",
      "    load_time_ms: 1.553\n",
      "    num_steps_sampled: 5860000\n",
      "    num_steps_trained: 5860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.359610676765442\n",
      "      kl: 0.04773819074034691\n",
      "      policy_loss: 0.019094746559858322\n",
      "      total_loss: 1396.3555908203125\n",
      "      vf_explained_var: 0.5011353492736816\n",
      "      vf_loss: 1396.33642578125\n",
      "    sample_time_ms: 24452.425\n",
      "    update_time_ms: 8.148\n",
      "  iterations_since_restore: 586\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.17969364565485\n",
      "  time_since_restore: 16699.311156988144\n",
      "  time_this_iter_s: 29.797630548477173\n",
      "  time_total_s: 16699.311156988144\n",
      "  timestamp: 1554825015\n",
      "  timesteps_since_restore: 5860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5860000\n",
      "  training_iteration: 586\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16699 s, 586 iter, 5860000 ts, -84.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-50-45\n",
      "  done: false\n",
      "  episode_len_mean: 91.2\n",
      "  episode_reward_max: 12.871746550306344\n",
      "  episode_reward_mean: -76.31086114065486\n",
      "  episode_reward_min: -200.24197894230736\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 64622\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5361.282\n",
      "    load_time_ms: 1.546\n",
      "    num_steps_sampled: 5870000\n",
      "    num_steps_trained: 5870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3520041704177856\n",
      "      kl: 0.03805876523256302\n",
      "      policy_loss: 0.013736718334257603\n",
      "      total_loss: 1432.952880859375\n",
      "      vf_explained_var: 0.4516882300376892\n",
      "      vf_loss: 1432.9393310546875\n",
      "    sample_time_ms: 24388.255\n",
      "    update_time_ms: 8.2\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.15543057032742\n",
      "  time_since_restore: 16728.941474199295\n",
      "  time_this_iter_s: 29.630317211151123\n",
      "  time_total_s: 16728.941474199295\n",
      "  timestamp: 1554825045\n",
      "  timesteps_since_restore: 5870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5870000\n",
      "  training_iteration: 587\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16728 s, 587 iter, 5870000 ts, -76.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-51-15\n",
      "  done: false\n",
      "  episode_len_mean: 82.0\n",
      "  episode_reward_max: 14.912356311312228\n",
      "  episode_reward_mean: -101.53841499734938\n",
      "  episode_reward_min: -200.5132299713612\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 64743\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5347.559\n",
      "    load_time_ms: 1.509\n",
      "    num_steps_sampled: 5880000\n",
      "    num_steps_trained: 5880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3674604892730713\n",
      "      kl: 0.03966965898871422\n",
      "      policy_loss: 0.020459486171603203\n",
      "      total_loss: 1247.5218505859375\n",
      "      vf_explained_var: 0.5614525675773621\n",
      "      vf_loss: 1247.5013427734375\n",
      "    sample_time_ms: 24328.501\n",
      "    update_time_ms: 8.227\n",
      "  iterations_since_restore: 588\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.769207498674696\n",
      "  time_since_restore: 16758.600898742676\n",
      "  time_this_iter_s: 29.659424543380737\n",
      "  time_total_s: 16758.600898742676\n",
      "  timestamp: 1554825075\n",
      "  timesteps_since_restore: 5880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5880000\n",
      "  training_iteration: 588\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16758 s, 588 iter, 5880000 ts, -102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-51-45\n",
      "  done: false\n",
      "  episode_len_mean: 87.74561403508773\n",
      "  episode_reward_max: 10.135004223655203\n",
      "  episode_reward_mean: -86.00724966113688\n",
      "  episode_reward_min: -200.15982365781758\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 64857\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5366.653\n",
      "    load_time_ms: 1.497\n",
      "    num_steps_sampled: 5890000\n",
      "    num_steps_trained: 5890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3668087720870972\n",
      "      kl: 0.04634023457765579\n",
      "      policy_loss: 0.016608573496341705\n",
      "      total_loss: 1406.6778564453125\n",
      "      vf_explained_var: 0.5181388258934021\n",
      "      vf_loss: 1406.6612548828125\n",
      "    sample_time_ms: 24332.929\n",
      "    update_time_ms: 7.397\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.00362483056844\n",
      "  time_since_restore: 16788.755194425583\n",
      "  time_this_iter_s: 30.154295682907104\n",
      "  time_total_s: 16788.755194425583\n",
      "  timestamp: 1554825105\n",
      "  timesteps_since_restore: 5890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5890000\n",
      "  training_iteration: 589\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16788 s, 589 iter, 5890000 ts, -86 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-52-15\n",
      "  done: false\n",
      "  episode_len_mean: 78.2578125\n",
      "  episode_reward_max: 10.38498621555079\n",
      "  episode_reward_mean: -112.61122714313866\n",
      "  episode_reward_min: -200.17144135141373\n",
      "  episodes_this_iter: 128\n",
      "  episodes_total: 64985\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5340.752\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 5900000\n",
      "    num_steps_trained: 5900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3715704679489136\n",
      "      kl: 0.03291955217719078\n",
      "      policy_loss: 0.009994030930101871\n",
      "      total_loss: 1273.015869140625\n",
      "      vf_explained_var: 0.5723298192024231\n",
      "      vf_loss: 1273.005859375\n",
      "    sample_time_ms: 24349.417\n",
      "    update_time_ms: 7.406\n",
      "  iterations_since_restore: 590\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -56.305613571569324\n",
      "  time_since_restore: 16818.750702142715\n",
      "  time_this_iter_s: 29.99550771713257\n",
      "  time_total_s: 16818.750702142715\n",
      "  timestamp: 1554825135\n",
      "  timesteps_since_restore: 5900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5900000\n",
      "  training_iteration: 590\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16818 s, 590 iter, 5900000 ts, -113 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-52-45\n",
      "  done: false\n",
      "  episode_len_mean: 86.65517241379311\n",
      "  episode_reward_max: 8.470522802615282\n",
      "  episode_reward_mean: -89.79894011373614\n",
      "  episode_reward_min: -200.17542677926878\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 65101\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5356.859\n",
      "    load_time_ms: 1.531\n",
      "    num_steps_sampled: 5910000\n",
      "    num_steps_trained: 5910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3654526472091675\n",
      "      kl: 0.03669175133109093\n",
      "      policy_loss: 0.010849283076822758\n",
      "      total_loss: 1306.8328857421875\n",
      "      vf_explained_var: 0.549452543258667\n",
      "      vf_loss: 1306.8221435546875\n",
      "    sample_time_ms: 24441.159\n",
      "    update_time_ms: 6.818\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.89947005686808\n",
      "  time_since_restore: 16849.060781002045\n",
      "  time_this_iter_s: 30.310078859329224\n",
      "  time_total_s: 16849.060781002045\n",
      "  timestamp: 1554825165\n",
      "  timesteps_since_restore: 5910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5910000\n",
      "  training_iteration: 591\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16849 s, 591 iter, 5910000 ts, -89.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-53-15\n",
      "  done: false\n",
      "  episode_len_mean: 90.6697247706422\n",
      "  episode_reward_max: 13.480435548758042\n",
      "  episode_reward_mean: -76.83426843948232\n",
      "  episode_reward_min: -200.1104546784556\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 65210\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5355.935\n",
      "    load_time_ms: 1.537\n",
      "    num_steps_sampled: 5920000\n",
      "    num_steps_trained: 5920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3562750816345215\n",
      "      kl: 0.03627040982246399\n",
      "      policy_loss: 0.016943885013461113\n",
      "      total_loss: 1452.855224609375\n",
      "      vf_explained_var: 0.45620298385620117\n",
      "      vf_loss: 1452.838134765625\n",
      "    sample_time_ms: 24438.83\n",
      "    update_time_ms: 6.684\n",
      "  iterations_since_restore: 592\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.417134219741165\n",
      "  time_since_restore: 16878.982288360596\n",
      "  time_this_iter_s: 29.921507358551025\n",
      "  time_total_s: 16878.982288360596\n",
      "  timestamp: 1554825195\n",
      "  timesteps_since_restore: 5920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5920000\n",
      "  training_iteration: 592\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16878 s, 592 iter, 5920000 ts, -76.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-53-45\n",
      "  done: false\n",
      "  episode_len_mean: 89.70535714285714\n",
      "  episode_reward_max: 11.005685800180041\n",
      "  episode_reward_mean: -81.64841500126808\n",
      "  episode_reward_min: -200.31743303073364\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 65322\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5366.751\n",
      "    load_time_ms: 1.597\n",
      "    num_steps_sampled: 5930000\n",
      "    num_steps_trained: 5930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3643969297409058\n",
      "      kl: 0.04483785852789879\n",
      "      policy_loss: 0.016878673806786537\n",
      "      total_loss: 1414.6492919921875\n",
      "      vf_explained_var: 0.4490446448326111\n",
      "      vf_loss: 1414.632568359375\n",
      "    sample_time_ms: 24435.07\n",
      "    update_time_ms: 6.714\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.82420750063404\n",
      "  time_since_restore: 16908.569936037064\n",
      "  time_this_iter_s: 29.587647676467896\n",
      "  time_total_s: 16908.569936037064\n",
      "  timestamp: 1554825225\n",
      "  timesteps_since_restore: 5930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5930000\n",
      "  training_iteration: 593\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16908 s, 593 iter, 5930000 ts, -81.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-54-14\n",
      "  done: false\n",
      "  episode_len_mean: 84.15254237288136\n",
      "  episode_reward_max: 10.888054765925213\n",
      "  episode_reward_mean: -98.69863789822703\n",
      "  episode_reward_min: -200.1599729192838\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 65440\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5342.679\n",
      "    load_time_ms: 1.609\n",
      "    num_steps_sampled: 5940000\n",
      "    num_steps_trained: 5940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3850840330123901\n",
      "      kl: 0.03696264326572418\n",
      "      policy_loss: 0.013441258110105991\n",
      "      total_loss: 1426.911865234375\n",
      "      vf_explained_var: 0.49582213163375854\n",
      "      vf_loss: 1426.8984375\n",
      "    sample_time_ms: 24481.563\n",
      "    update_time_ms: 6.623\n",
      "  iterations_since_restore: 594\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.349318949113524\n",
      "  time_since_restore: 16938.087094783783\n",
      "  time_this_iter_s: 29.51715874671936\n",
      "  time_total_s: 16938.087094783783\n",
      "  timestamp: 1554825254\n",
      "  timesteps_since_restore: 5940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5940000\n",
      "  training_iteration: 594\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16938 s, 594 iter, 5940000 ts, -98.7 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-54-45\n",
      "  done: false\n",
      "  episode_len_mean: 85.5546218487395\n",
      "  episode_reward_max: 13.069584337277522\n",
      "  episode_reward_mean: -92.35703105611272\n",
      "  episode_reward_min: -200.1869305459261\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 65559\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5345.358\n",
      "    load_time_ms: 1.593\n",
      "    num_steps_sampled: 5950000\n",
      "    num_steps_trained: 5950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3808519840240479\n",
      "      kl: 0.04443248733878136\n",
      "      policy_loss: 0.017026616260409355\n",
      "      total_loss: 1273.9415283203125\n",
      "      vf_explained_var: 0.5682233572006226\n",
      "      vf_loss: 1273.9246826171875\n",
      "    sample_time_ms: 24489.178\n",
      "    update_time_ms: 6.555\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.178515528056344\n",
      "  time_since_restore: 16968.16397023201\n",
      "  time_this_iter_s: 30.07687544822693\n",
      "  time_total_s: 16968.16397023201\n",
      "  timestamp: 1554825285\n",
      "  timesteps_since_restore: 5950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5950000\n",
      "  training_iteration: 595\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16968 s, 595 iter, 5950000 ts, -92.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-55-14\n",
      "  done: false\n",
      "  episode_len_mean: 89.07207207207207\n",
      "  episode_reward_max: 14.217656477953938\n",
      "  episode_reward_mean: -80.9947243413283\n",
      "  episode_reward_min: -200.0869949392557\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 65670\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5356.471\n",
      "    load_time_ms: 1.555\n",
      "    num_steps_sampled: 5960000\n",
      "    num_steps_trained: 5960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3770575523376465\n",
      "      kl: 0.04301133379340172\n",
      "      policy_loss: 0.015677472576498985\n",
      "      total_loss: 1422.781494140625\n",
      "      vf_explained_var: 0.508374810218811\n",
      "      vf_loss: 1422.765869140625\n",
      "    sample_time_ms: 24456.004\n",
      "    update_time_ms: 6.553\n",
      "  iterations_since_restore: 596\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.49736217066414\n",
      "  time_since_restore: 16997.741544008255\n",
      "  time_this_iter_s: 29.577573776245117\n",
      "  time_total_s: 16997.741544008255\n",
      "  timestamp: 1554825314\n",
      "  timesteps_since_restore: 5960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5960000\n",
      "  training_iteration: 596\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 16997 s, 596 iter, 5960000 ts, -81 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 84.64406779661017\n",
      "  episode_reward_max: 10.47524128243386\n",
      "  episode_reward_mean: -96.86501345874785\n",
      "  episode_reward_min: -200.24564208266077\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 65788\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5361.939\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 5970000\n",
      "    num_steps_trained: 5970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.390170693397522\n",
      "      kl: 0.046431463211774826\n",
      "      policy_loss: 0.016813402995467186\n",
      "      total_loss: 1364.0440673828125\n",
      "      vf_explained_var: 0.528913140296936\n",
      "      vf_loss: 1364.02734375\n",
      "    sample_time_ms: 24478.935\n",
      "    update_time_ms: 6.697\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.43250672937393\n",
      "  time_since_restore: 17027.657711982727\n",
      "  time_this_iter_s: 29.916167974472046\n",
      "  time_total_s: 17027.657711982727\n",
      "  timestamp: 1554825344\n",
      "  timesteps_since_restore: 5970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5970000\n",
      "  training_iteration: 597\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17027 s, 597 iter, 5970000 ts, -96.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-56-14\n",
      "  done: false\n",
      "  episode_len_mean: 95.54807692307692\n",
      "  episode_reward_max: 13.436007920085228\n",
      "  episode_reward_mean: -65.86580828873872\n",
      "  episode_reward_min: -200.3293730192753\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 65892\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5358.982\n",
      "    load_time_ms: 1.535\n",
      "    num_steps_sampled: 5980000\n",
      "    num_steps_trained: 5980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3878766298294067\n",
      "      kl: 0.03344043716788292\n",
      "      policy_loss: 0.014760026708245277\n",
      "      total_loss: 1476.9232177734375\n",
      "      vf_explained_var: 0.44955894351005554\n",
      "      vf_loss: 1476.908447265625\n",
      "    sample_time_ms: 24519.164\n",
      "    update_time_ms: 6.759\n",
      "  iterations_since_restore: 598\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -32.93290414436935\n",
      "  time_since_restore: 17057.68720793724\n",
      "  time_this_iter_s: 30.02949595451355\n",
      "  time_total_s: 17057.68720793724\n",
      "  timestamp: 1554825374\n",
      "  timesteps_since_restore: 5980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5980000\n",
      "  training_iteration: 598\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17057 s, 598 iter, 5980000 ts, -65.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-56-45\n",
      "  done: false\n",
      "  episode_len_mean: 84.57142857142857\n",
      "  episode_reward_max: 14.231448337286785\n",
      "  episode_reward_mean: -96.05428404356518\n",
      "  episode_reward_min: -200.1292940990104\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 66011\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5382.149\n",
      "    load_time_ms: 1.499\n",
      "    num_steps_sampled: 5990000\n",
      "    num_steps_trained: 5990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4194228649139404\n",
      "      kl: 0.0401044636964798\n",
      "      policy_loss: 0.012469165027141571\n",
      "      total_loss: 1315.2430419921875\n",
      "      vf_explained_var: 0.5458694696426392\n",
      "      vf_loss: 1315.2305908203125\n",
      "    sample_time_ms: 24547.049\n",
      "    update_time_ms: 6.573\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.02714202178258\n",
      "  time_since_restore: 17088.35134792328\n",
      "  time_this_iter_s: 30.664139986038208\n",
      "  time_total_s: 17088.35134792328\n",
      "  timestamp: 1554825405\n",
      "  timesteps_since_restore: 5990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5990000\n",
      "  training_iteration: 599\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17088 s, 599 iter, 5990000 ts, -96.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 93.62616822429906\n",
      "  episode_reward_max: 12.647918968924014\n",
      "  episode_reward_mean: -69.44237472993865\n",
      "  episode_reward_min: -200.17770419073105\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 66118\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5389.893\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 6000000\n",
      "    num_steps_trained: 6000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3956341743469238\n",
      "      kl: 0.0357045903801918\n",
      "      policy_loss: 0.013405628502368927\n",
      "      total_loss: 1513.941650390625\n",
      "      vf_explained_var: 0.41051924228668213\n",
      "      vf_loss: 1513.92822265625\n",
      "    sample_time_ms: 24557.122\n",
      "    update_time_ms: 6.517\n",
      "  iterations_since_restore: 600\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.721187364969325\n",
      "  time_since_restore: 17118.522280216217\n",
      "  time_this_iter_s: 30.170932292938232\n",
      "  time_total_s: 17118.522280216217\n",
      "  timestamp: 1554825435\n",
      "  timesteps_since_restore: 6000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6000000\n",
      "  training_iteration: 600\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17118 s, 600 iter, 6000000 ts, -69.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-57-46\n",
      "  done: false\n",
      "  episode_len_mean: 86.49137931034483\n",
      "  episode_reward_max: 11.388417441116134\n",
      "  episode_reward_mean: -88.6894864742923\n",
      "  episode_reward_min: -200.20354102146626\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 66234\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5410.152\n",
      "    load_time_ms: 1.502\n",
      "    num_steps_sampled: 6010000\n",
      "    num_steps_trained: 6010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4156301021575928\n",
      "      kl: 0.03835335373878479\n",
      "      policy_loss: 0.018801387399435043\n",
      "      total_loss: 1382.210693359375\n",
      "      vf_explained_var: 0.506597101688385\n",
      "      vf_loss: 1382.192138671875\n",
      "    sample_time_ms: 24542.448\n",
      "    update_time_ms: 6.545\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.34474323714615\n",
      "  time_since_restore: 17148.88844895363\n",
      "  time_this_iter_s: 30.3661687374115\n",
      "  time_total_s: 17148.88844895363\n",
      "  timestamp: 1554825466\n",
      "  timesteps_since_restore: 6010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6010000\n",
      "  training_iteration: 601\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17148 s, 601 iter, 6010000 ts, -88.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-58-15\n",
      "  done: false\n",
      "  episode_len_mean: 89.8018018018018\n",
      "  episode_reward_max: 10.482177255688521\n",
      "  episode_reward_mean: -81.33914340943885\n",
      "  episode_reward_min: -200.14722059857846\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 66345\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5390.663\n",
      "    load_time_ms: 1.51\n",
      "    num_steps_sampled: 6020000\n",
      "    num_steps_trained: 6020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3919508457183838\n",
      "      kl: 0.05091002210974693\n",
      "      policy_loss: 0.021117618307471275\n",
      "      total_loss: 1426.970458984375\n",
      "      vf_explained_var: 0.47076600790023804\n",
      "      vf_loss: 1426.9493408203125\n",
      "    sample_time_ms: 24517.976\n",
      "    update_time_ms: 7.192\n",
      "  iterations_since_restore: 602\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.66957170471943\n",
      "  time_since_restore: 17178.38038110733\n",
      "  time_this_iter_s: 29.491932153701782\n",
      "  time_total_s: 17178.38038110733\n",
      "  timestamp: 1554825495\n",
      "  timesteps_since_restore: 6020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6020000\n",
      "  training_iteration: 602\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17178 s, 602 iter, 6020000 ts, -81.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-58-46\n",
      "  done: false\n",
      "  episode_len_mean: 84.07563025210084\n",
      "  episode_reward_max: 12.116770894515223\n",
      "  episode_reward_mean: -97.81562443911788\n",
      "  episode_reward_min: -200.26289104742528\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 66464\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5403.739\n",
      "    load_time_ms: 1.458\n",
      "    num_steps_sampled: 6030000\n",
      "    num_steps_trained: 6030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4156574010849\n",
      "      kl: 0.04522067308425903\n",
      "      policy_loss: 0.0163615420460701\n",
      "      total_loss: 1358.6602783203125\n",
      "      vf_explained_var: 0.5290379524230957\n",
      "      vf_loss: 1358.64404296875\n",
      "    sample_time_ms: 24589.419\n",
      "    update_time_ms: 7.122\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.907812219558934\n",
      "  time_since_restore: 17208.811235904694\n",
      "  time_this_iter_s: 30.43085479736328\n",
      "  time_total_s: 17208.811235904694\n",
      "  timestamp: 1554825526\n",
      "  timesteps_since_restore: 6030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6030000\n",
      "  training_iteration: 603\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17208 s, 603 iter, 6030000 ts, -97.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-59-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.9245283018868\n",
      "  episode_reward_max: 12.310685599266092\n",
      "  episode_reward_mean: -66.33403993066067\n",
      "  episode_reward_min: -200.1796519294977\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 66570\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5424.286\n",
      "    load_time_ms: 1.462\n",
      "    num_steps_sampled: 6040000\n",
      "    num_steps_trained: 6040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3864452838897705\n",
      "      kl: 0.05152556672692299\n",
      "      policy_loss: 0.022083235904574394\n",
      "      total_loss: 1359.8253173828125\n",
      "      vf_explained_var: 0.48228827118873596\n",
      "      vf_loss: 1359.8033447265625\n",
      "    sample_time_ms: 24694.025\n",
      "    update_time_ms: 7.175\n",
      "  iterations_since_restore: 604\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.16701996533033\n",
      "  time_since_restore: 17239.57995533943\n",
      "  time_this_iter_s: 30.76871943473816\n",
      "  time_total_s: 17239.57995533943\n",
      "  timestamp: 1554825556\n",
      "  timesteps_since_restore: 6040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6040000\n",
      "  training_iteration: 604\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17239 s, 604 iter, 6040000 ts, -66.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_17-59-50\n",
      "  done: false\n",
      "  episode_len_mean: 82.57142857142857\n",
      "  episode_reward_max: 12.277507812179822\n",
      "  episode_reward_mean: -102.78271267929837\n",
      "  episode_reward_min: -200.34806778669878\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 66689\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5401.311\n",
      "    load_time_ms: 1.467\n",
      "    num_steps_sampled: 6050000\n",
      "    num_steps_trained: 6050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3761011362075806\n",
      "      kl: 30.642505645751953\n",
      "      policy_loss: 0.2089788019657135\n",
      "      total_loss: 1247.1011962890625\n",
      "      vf_explained_var: 0.579267680644989\n",
      "      vf_loss: 1246.8922119140625\n",
      "    sample_time_ms: 25034.762\n",
      "    update_time_ms: 7.291\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.39135633964917\n",
      "  time_since_restore: 17272.83962583542\n",
      "  time_this_iter_s: 33.25967049598694\n",
      "  time_total_s: 17272.83962583542\n",
      "  timestamp: 1554825590\n",
      "  timesteps_since_restore: 6050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6050000\n",
      "  training_iteration: 605\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17272 s, 605 iter, 6050000 ts, -103 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-00-20\n",
      "  done: false\n",
      "  episode_len_mean: 91.83636363636364\n",
      "  episode_reward_max: 12.040704167545485\n",
      "  episode_reward_mean: -74.56999341915764\n",
      "  episode_reward_min: -200.10728894495963\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 66799\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5407.458\n",
      "    load_time_ms: 1.446\n",
      "    num_steps_sampled: 6060000\n",
      "    num_steps_trained: 6060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3659955263137817\n",
      "      kl: 0.03278445452451706\n",
      "      policy_loss: 0.012630950659513474\n",
      "      total_loss: 1503.9014892578125\n",
      "      vf_explained_var: 0.44753342866897583\n",
      "      vf_loss: 1503.8887939453125\n",
      "    sample_time_ms: 25116.233\n",
      "    update_time_ms: 7.222\n",
      "  iterations_since_restore: 606\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.284996709578806\n",
      "  time_since_restore: 17303.2919485569\n",
      "  time_this_iter_s: 30.452322721481323\n",
      "  time_total_s: 17303.2919485569\n",
      "  timestamp: 1554825620\n",
      "  timesteps_since_restore: 6060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6060000\n",
      "  training_iteration: 606\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17303 s, 606 iter, 6060000 ts, -74.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-00-51\n",
      "  done: false\n",
      "  episode_len_mean: 84.27731092436974\n",
      "  episode_reward_max: 7.691412901271712\n",
      "  episode_reward_mean: -94.16128449923339\n",
      "  episode_reward_min: -200.20399279735685\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 66918\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5401.856\n",
      "    load_time_ms: 1.469\n",
      "    num_steps_sampled: 6070000\n",
      "    num_steps_trained: 6070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3868316411972046\n",
      "      kl: 0.0340835265815258\n",
      "      policy_loss: 0.0088052311912179\n",
      "      total_loss: 1377.072265625\n",
      "      vf_explained_var: 0.5070415139198303\n",
      "      vf_loss: 1377.0633544921875\n",
      "    sample_time_ms: 25209.463\n",
      "    update_time_ms: 7.209\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.08064224961669\n",
      "  time_since_restore: 17334.084761619568\n",
      "  time_this_iter_s: 30.792813062667847\n",
      "  time_total_s: 17334.084761619568\n",
      "  timestamp: 1554825651\n",
      "  timesteps_since_restore: 6070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6070000\n",
      "  training_iteration: 607\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17334 s, 607 iter, 6070000 ts, -94.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-01-22\n",
      "  done: false\n",
      "  episode_len_mean: 86.97391304347826\n",
      "  episode_reward_max: 9.422395710600563\n",
      "  episode_reward_mean: -88.24832722212062\n",
      "  episode_reward_min: -200.2717141526041\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 67033\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5428.081\n",
      "    load_time_ms: 1.442\n",
      "    num_steps_sampled: 6080000\n",
      "    num_steps_trained: 6080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.392751693725586\n",
      "      kl: 0.04369010031223297\n",
      "      policy_loss: 0.016294613480567932\n",
      "      total_loss: 1477.3935546875\n",
      "      vf_explained_var: 0.45738527178764343\n",
      "      vf_loss: 1477.377197265625\n",
      "    sample_time_ms: 25253.304\n",
      "    update_time_ms: 7.313\n",
      "  iterations_since_restore: 608\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.12416361106032\n",
      "  time_since_restore: 17364.817443609238\n",
      "  time_this_iter_s: 30.7326819896698\n",
      "  time_total_s: 17364.817443609238\n",
      "  timestamp: 1554825682\n",
      "  timesteps_since_restore: 6080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6080000\n",
      "  training_iteration: 608\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17364 s, 608 iter, 6080000 ts, -88.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-01-52\n",
      "  done: false\n",
      "  episode_len_mean: 85.8103448275862\n",
      "  episode_reward_max: 9.996441403660095\n",
      "  episode_reward_mean: -91.80900748486651\n",
      "  episode_reward_min: -200.44469894042498\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 67149\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5402.258\n",
      "    load_time_ms: 1.448\n",
      "    num_steps_sampled: 6090000\n",
      "    num_steps_trained: 6090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.400046467781067\n",
      "      kl: 0.0390186570584774\n",
      "      policy_loss: 0.015013632364571095\n",
      "      total_loss: 1373.3319091796875\n",
      "      vf_explained_var: 0.51846843957901\n",
      "      vf_loss: 1373.31689453125\n",
      "    sample_time_ms: 25275.537\n",
      "    update_time_ms: 7.409\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.904503742433256\n",
      "  time_since_restore: 17395.44445347786\n",
      "  time_this_iter_s: 30.627009868621826\n",
      "  time_total_s: 17395.44445347786\n",
      "  timestamp: 1554825712\n",
      "  timesteps_since_restore: 6090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6090000\n",
      "  training_iteration: 609\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17395 s, 609 iter, 6090000 ts, -91.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-02-23\n",
      "  done: false\n",
      "  episode_len_mean: 85.82758620689656\n",
      "  episode_reward_max: 7.231201373240872\n",
      "  episode_reward_mean: -93.3227410185125\n",
      "  episode_reward_min: -200.2551800382176\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 67265\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5407.435\n",
      "    load_time_ms: 1.426\n",
      "    num_steps_sampled: 6100000\n",
      "    num_steps_trained: 6100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4176937341690063\n",
      "      kl: 0.04362991452217102\n",
      "      policy_loss: 0.016426589339971542\n",
      "      total_loss: 1332.5733642578125\n",
      "      vf_explained_var: 0.5397421717643738\n",
      "      vf_loss: 1332.5570068359375\n",
      "    sample_time_ms: 25317.629\n",
      "    update_time_ms: 8.071\n",
      "  iterations_since_restore: 610\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.66137050925625\n",
      "  time_since_restore: 17426.096945524216\n",
      "  time_this_iter_s: 30.6524920463562\n",
      "  time_total_s: 17426.096945524216\n",
      "  timestamp: 1554825743\n",
      "  timesteps_since_restore: 6100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6100000\n",
      "  training_iteration: 610\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17426 s, 610 iter, 6100000 ts, -93.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-02-54\n",
      "  done: false\n",
      "  episode_len_mean: 89.76785714285714\n",
      "  episode_reward_max: 10.556888659644933\n",
      "  episode_reward_mean: -80.34352352077947\n",
      "  episode_reward_min: -200.30157426952866\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 67377\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5374.367\n",
      "    load_time_ms: 1.485\n",
      "    num_steps_sampled: 6110000\n",
      "    num_steps_trained: 6110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3977587223052979\n",
      "      kl: 0.04886900633573532\n",
      "      policy_loss: 0.018427180126309395\n",
      "      total_loss: 1466.9359130859375\n",
      "      vf_explained_var: 0.4597373306751251\n",
      "      vf_loss: 1466.91748046875\n",
      "    sample_time_ms: 25352.065\n",
      "    update_time_ms: 7.947\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.171761760389735\n",
      "  time_since_restore: 17456.4792573452\n",
      "  time_this_iter_s: 30.382311820983887\n",
      "  time_total_s: 17456.4792573452\n",
      "  timestamp: 1554825774\n",
      "  timesteps_since_restore: 6110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6110000\n",
      "  training_iteration: 611\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17456 s, 611 iter, 6110000 ts, -80.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-03-25\n",
      "  done: false\n",
      "  episode_len_mean: 88.73214285714286\n",
      "  episode_reward_max: 7.438093997723453\n",
      "  episode_reward_mean: -84.62475694071018\n",
      "  episode_reward_min: -200.12325526494095\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 67489\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5551.19\n",
      "    load_time_ms: 1.53\n",
      "    num_steps_sampled: 6120000\n",
      "    num_steps_trained: 6120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4006426334381104\n",
      "      kl: 0.04135700315237045\n",
      "      policy_loss: 0.018359346315264702\n",
      "      total_loss: 1341.4647216796875\n",
      "      vf_explained_var: 0.5541941523551941\n",
      "      vf_loss: 1341.4464111328125\n",
      "    sample_time_ms: 25397.298\n",
      "    update_time_ms: 7.354\n",
      "  iterations_since_restore: 612\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.31237847035509\n",
      "  time_since_restore: 17488.185326576233\n",
      "  time_this_iter_s: 31.706069231033325\n",
      "  time_total_s: 17488.185326576233\n",
      "  timestamp: 1554825805\n",
      "  timesteps_since_restore: 6120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6120000\n",
      "  training_iteration: 612\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17488 s, 612 iter, 6120000 ts, -84.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-04-05\n",
      "  done: false\n",
      "  episode_len_mean: 89.070796460177\n",
      "  episode_reward_max: 10.883386907917595\n",
      "  episode_reward_mean: -82.9452410538743\n",
      "  episode_reward_min: -200.15540877771508\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 67602\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5548.571\n",
      "    load_time_ms: 1.565\n",
      "    num_steps_sampled: 6130000\n",
      "    num_steps_trained: 6130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.401298464324817e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4060168266296387\n",
      "      kl: 0.058778066188097\n",
      "      policy_loss: 0.021763905882835388\n",
      "      total_loss: 1354.435302734375\n",
      "      vf_explained_var: 0.532450258731842\n",
      "      vf_loss: 1354.41357421875\n",
      "    sample_time_ms: 26292.37\n",
      "    update_time_ms: 7.202\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.47262052693714\n",
      "  time_since_restore: 17527.54316687584\n",
      "  time_this_iter_s: 39.35784029960632\n",
      "  time_total_s: 17527.54316687584\n",
      "  timestamp: 1554825845\n",
      "  timesteps_since_restore: 6130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6130000\n",
      "  training_iteration: 613\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17527 s, 613 iter, 6130000 ts, -82.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-04-40\n",
      "  done: false\n",
      "  episode_len_mean: 91.4090909090909\n",
      "  episode_reward_max: 7.684248943501427\n",
      "  episode_reward_mean: -75.04883047482143\n",
      "  episode_reward_min: -200.1552471670053\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 67712\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5713.462\n",
      "    load_time_ms: 1.585\n",
      "    num_steps_sampled: 6140000\n",
      "    num_steps_trained: 6140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.401298464324817e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.399567723274231\n",
      "      kl: 0.047937992960214615\n",
      "      policy_loss: 0.022000441327691078\n",
      "      total_loss: 1461.0419921875\n",
      "      vf_explained_var: 0.49559226632118225\n",
      "      vf_loss: 1461.0198974609375\n",
      "    sample_time_ms: 26607.65\n",
      "    update_time_ms: 7.295\n",
      "  iterations_since_restore: 614\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.52441523741071\n",
      "  time_since_restore: 17563.13189792633\n",
      "  time_this_iter_s: 35.58873105049133\n",
      "  time_total_s: 17563.13189792633\n",
      "  timestamp: 1554825880\n",
      "  timesteps_since_restore: 6140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6140000\n",
      "  training_iteration: 614\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17563 s, 614 iter, 6140000 ts, -75 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-05-17\n",
      "  done: false\n",
      "  episode_len_mean: 91.6574074074074\n",
      "  episode_reward_max: 9.615724016631631\n",
      "  episode_reward_mean: -74.32210484584344\n",
      "  episode_reward_min: -200.1546334670782\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 67820\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5772.874\n",
      "    load_time_ms: 1.738\n",
      "    num_steps_sampled: 6150000\n",
      "    num_steps_trained: 6150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.401298464324817e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3983651399612427\n",
      "      kl: 0.04666566103696823\n",
      "      policy_loss: 0.015041656792163849\n",
      "      total_loss: 1387.3712158203125\n",
      "      vf_explained_var: 0.5091477632522583\n",
      "      vf_loss: 1387.3560791015625\n",
      "    sample_time_ms: 26839.881\n",
      "    update_time_ms: 8.243\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.16105242292172\n",
      "  time_since_restore: 17599.32291650772\n",
      "  time_this_iter_s: 36.19101858139038\n",
      "  time_total_s: 17599.32291650772\n",
      "  timestamp: 1554825917\n",
      "  timesteps_since_restore: 6150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6150000\n",
      "  training_iteration: 615\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17599 s, 615 iter, 6150000 ts, -74.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-05-50\n",
      "  done: false\n",
      "  episode_len_mean: 91.25454545454545\n",
      "  episode_reward_max: 8.681155343551875\n",
      "  episode_reward_mean: -76.38428980825249\n",
      "  episode_reward_min: -200.15674592626388\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 67930\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5794.142\n",
      "    load_time_ms: 1.746\n",
      "    num_steps_sampled: 6160000\n",
      "    num_steps_trained: 6160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.802596928649634e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3980352878570557\n",
      "      kl: 0.035672757774591446\n",
      "      policy_loss: 0.015513105317950249\n",
      "      total_loss: 1548.3424072265625\n",
      "      vf_explained_var: 0.4432421028614044\n",
      "      vf_loss: 1548.3267822265625\n",
      "    sample_time_ms: 27054.885\n",
      "    update_time_ms: 8.3\n",
      "  iterations_since_restore: 616\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.19214490412626\n",
      "  time_since_restore: 17632.144242286682\n",
      "  time_this_iter_s: 32.82132577896118\n",
      "  time_total_s: 17632.144242286682\n",
      "  timestamp: 1554825950\n",
      "  timesteps_since_restore: 6160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6160000\n",
      "  training_iteration: 616\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17632 s, 616 iter, 6160000 ts, -76.4 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-06-20\n",
      "  done: false\n",
      "  episode_len_mean: 90.92792792792793\n",
      "  episode_reward_max: 11.388271427647034\n",
      "  episode_reward_mean: -75.41445272092845\n",
      "  episode_reward_min: -200.23137798156893\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 68041\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5785.693\n",
      "    load_time_ms: 1.734\n",
      "    num_steps_sampled: 6170000\n",
      "    num_steps_trained: 6170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.802596928649634e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4020501375198364\n",
      "      kl: 6.194957733154297\n",
      "      policy_loss: 0.07821430265903473\n",
      "      total_loss: 1564.566650390625\n",
      "      vf_explained_var: 0.4139963686466217\n",
      "      vf_loss: 1564.4884033203125\n",
      "    sample_time_ms: 27032.156\n",
      "    update_time_ms: 8.24\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -37.70722636046422\n",
      "  time_since_restore: 17662.622421979904\n",
      "  time_this_iter_s: 30.478179693222046\n",
      "  time_total_s: 17662.622421979904\n",
      "  timestamp: 1554825980\n",
      "  timesteps_since_restore: 6170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6170000\n",
      "  training_iteration: 617\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17662 s, 617 iter, 6170000 ts, -75.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-06-51\n",
      "  done: false\n",
      "  episode_len_mean: 83.46666666666667\n",
      "  episode_reward_max: 7.166462698284978\n",
      "  episode_reward_mean: -98.58286425847152\n",
      "  episode_reward_min: -200.1353146072257\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 68161\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5783.74\n",
      "    load_time_ms: 1.858\n",
      "    num_steps_sampled: 6180000\n",
      "    num_steps_trained: 6180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.203895392974451e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4177019596099854\n",
      "      kl: 0.039299581199884415\n",
      "      policy_loss: 0.015924671664834023\n",
      "      total_loss: 1296.138671875\n",
      "      vf_explained_var: 0.5653547048568726\n",
      "      vf_loss: 1296.12255859375\n",
      "    sample_time_ms: 27021.572\n",
      "    update_time_ms: 8.107\n",
      "  iterations_since_restore: 618\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.29143212923576\n",
      "  time_since_restore: 17693.236965417862\n",
      "  time_this_iter_s: 30.614543437957764\n",
      "  time_total_s: 17693.236965417862\n",
      "  timestamp: 1554826011\n",
      "  timesteps_since_restore: 6180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6180000\n",
      "  training_iteration: 618\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17693 s, 618 iter, 6180000 ts, -98.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-07-20\n",
      "  done: false\n",
      "  episode_len_mean: 87.45132743362832\n",
      "  episode_reward_max: 9.325834325109561\n",
      "  episode_reward_mean: -85.2895541569956\n",
      "  episode_reward_min: -200.1609778316867\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 68274\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5769.031\n",
      "    load_time_ms: 1.887\n",
      "    num_steps_sampled: 6190000\n",
      "    num_steps_trained: 6190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.203895392974451e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4131581783294678\n",
      "      kl: 0.04539993405342102\n",
      "      policy_loss: 0.018209710717201233\n",
      "      total_loss: 1436.8453369140625\n",
      "      vf_explained_var: 0.4936048984527588\n",
      "      vf_loss: 1436.8270263671875\n",
      "    sample_time_ms: 26942.984\n",
      "    update_time_ms: 8.614\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.6447770784978\n",
      "  time_since_restore: 17722.93698501587\n",
      "  time_this_iter_s: 29.700019598007202\n",
      "  time_total_s: 17722.93698501587\n",
      "  timestamp: 1554826040\n",
      "  timesteps_since_restore: 6190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6190000\n",
      "  training_iteration: 619\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17722 s, 619 iter, 6190000 ts, -85.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-07-51\n",
      "  done: false\n",
      "  episode_len_mean: 85.94871794871794\n",
      "  episode_reward_max: 6.061107342079387\n",
      "  episode_reward_mean: -90.49367501016002\n",
      "  episode_reward_min: -200.3173975055006\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 68391\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5766.381\n",
      "    load_time_ms: 1.897\n",
      "    num_steps_sampled: 6200000\n",
      "    num_steps_trained: 6200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.006492321624085e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.418190360069275\n",
      "      kl: 0.03605083376169205\n",
      "      policy_loss: 0.01110027078539133\n",
      "      total_loss: 1450.7950439453125\n",
      "      vf_explained_var: 0.49079856276512146\n",
      "      vf_loss: 1450.7840576171875\n",
      "    sample_time_ms: 26925.508\n",
      "    update_time_ms: 7.909\n",
      "  iterations_since_restore: 620\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.24683750508001\n",
      "  time_since_restore: 17753.375591039658\n",
      "  time_this_iter_s: 30.438606023788452\n",
      "  time_total_s: 17753.375591039658\n",
      "  timestamp: 1554826071\n",
      "  timesteps_since_restore: 6200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6200000\n",
      "  training_iteration: 620\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17753 s, 620 iter, 6200000 ts, -90.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-08-22\n",
      "  done: false\n",
      "  episode_len_mean: 83.77310924369748\n",
      "  episode_reward_max: 10.550656035518772\n",
      "  episode_reward_mean: -95.31900688092327\n",
      "  episode_reward_min: -200.20057023779094\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 68510\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5780.57\n",
      "    load_time_ms: 1.874\n",
      "    num_steps_sampled: 6210000\n",
      "    num_steps_trained: 6210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.006492321624085e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4224567413330078\n",
      "      kl: 0.039970215409994125\n",
      "      policy_loss: 0.013657722622156143\n",
      "      total_loss: 1359.8131103515625\n",
      "      vf_explained_var: 0.5175240635871887\n",
      "      vf_loss: 1359.7994384765625\n",
      "    sample_time_ms: 27014.252\n",
      "    update_time_ms: 8.465\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.65950344046164\n",
      "  time_since_restore: 17784.792080163956\n",
      "  time_this_iter_s: 31.416489124298096\n",
      "  time_total_s: 17784.792080163956\n",
      "  timestamp: 1554826102\n",
      "  timesteps_since_restore: 6210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6210000\n",
      "  training_iteration: 621\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17784 s, 621 iter, 6210000 ts, -95.3 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-08-53\n",
      "  done: false\n",
      "  episode_len_mean: 90.31531531531532\n",
      "  episode_reward_max: 5.626586386522288\n",
      "  episode_reward_mean: -79.60477909970679\n",
      "  episode_reward_min: -200.1995964662492\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 68621\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5643.081\n",
      "    load_time_ms: 1.896\n",
      "    num_steps_sampled: 6220000\n",
      "    num_steps_trained: 6220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.006492321624085e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.419724941253662\n",
      "      kl: 0.053411103785037994\n",
      "      policy_loss: 0.020170630887150764\n",
      "      total_loss: 1448.4774169921875\n",
      "      vf_explained_var: 0.46541449427604675\n",
      "      vf_loss: 1448.4571533203125\n",
      "    sample_time_ms: 27000.313\n",
      "    update_time_ms: 8.869\n",
      "  iterations_since_restore: 622\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.8023895498534\n",
      "  time_since_restore: 17814.988839149475\n",
      "  time_this_iter_s: 30.19675898551941\n",
      "  time_total_s: 17814.988839149475\n",
      "  timestamp: 1554826133\n",
      "  timesteps_since_restore: 6220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6220000\n",
      "  training_iteration: 622\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17814 s, 622 iter, 6220000 ts, -79.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-09-29\n",
      "  done: false\n",
      "  episode_len_mean: 88.95575221238938\n",
      "  episode_reward_max: 10.065956462860989\n",
      "  episode_reward_mean: -81.33269220102608\n",
      "  episode_reward_min: -200.1743344396633\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 68734\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5871.17\n",
      "    load_time_ms: 1.858\n",
      "    num_steps_sampled: 6230000\n",
      "    num_steps_trained: 6230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.80908925027372e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4289045333862305\n",
      "      kl: 0.03969399258494377\n",
      "      policy_loss: 0.016012145206332207\n",
      "      total_loss: 1447.6055908203125\n",
      "      vf_explained_var: 0.484994500875473\n",
      "      vf_loss: 1447.589599609375\n",
      "    sample_time_ms: 26433.263\n",
      "    update_time_ms: 9.04\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.66634610051303\n",
      "  time_since_restore: 17850.95706319809\n",
      "  time_this_iter_s: 35.9682240486145\n",
      "  time_total_s: 17850.95706319809\n",
      "  timestamp: 1554826169\n",
      "  timesteps_since_restore: 6230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6230000\n",
      "  training_iteration: 623\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17850 s, 623 iter, 6230000 ts, -81.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-10-05\n",
      "  done: false\n",
      "  episode_len_mean: 78.704\n",
      "  episode_reward_max: 9.459040001431116\n",
      "  episode_reward_mean: -110.26803319601619\n",
      "  episode_reward_min: -200.41650195837155\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 68859\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5804.502\n",
      "    load_time_ms: 1.887\n",
      "    num_steps_sampled: 6240000\n",
      "    num_steps_trained: 6240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.80908925027372e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.442555546760559\n",
      "      kl: 0.12146112322807312\n",
      "      policy_loss: 0.04670921713113785\n",
      "      total_loss: 1268.982177734375\n",
      "      vf_explained_var: 0.5731298923492432\n",
      "      vf_loss: 1268.935546875\n",
      "    sample_time_ms: 26553.92\n",
      "    update_time_ms: 9.04\n",
      "  iterations_since_restore: 624\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -55.1340165980081\n",
      "  time_since_restore: 17887.071505069733\n",
      "  time_this_iter_s: 36.114441871643066\n",
      "  time_total_s: 17887.071505069733\n",
      "  timestamp: 1554826205\n",
      "  timesteps_since_restore: 6240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6240000\n",
      "  training_iteration: 624\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17887 s, 624 iter, 6240000 ts, -110 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-10-45\n",
      "  done: false\n",
      "  episode_len_mean: 90.95535714285714\n",
      "  episode_reward_max: 9.994606815244872\n",
      "  episode_reward_mean: -76.48479084412045\n",
      "  episode_reward_min: -200.18244201160866\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 68971\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5806.47\n",
      "    load_time_ms: 1.77\n",
      "    num_steps_sampled: 6250000\n",
      "    num_steps_trained: 6250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.401298464324817e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4186606407165527\n",
      "      kl: 0.03923118859529495\n",
      "      policy_loss: 0.01514400914311409\n",
      "      total_loss: 1433.3758544921875\n",
      "      vf_explained_var: 0.4737906754016876\n",
      "      vf_loss: 1433.3607177734375\n",
      "    sample_time_ms: 26911.108\n",
      "    update_time_ms: 9.463\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.242395422060234\n",
      "  time_since_restore: 17926.85442328453\n",
      "  time_this_iter_s: 39.782918214797974\n",
      "  time_total_s: 17926.85442328453\n",
      "  timestamp: 1554826245\n",
      "  timesteps_since_restore: 6250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6250000\n",
      "  training_iteration: 625\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17926 s, 625 iter, 6250000 ts, -76.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-11-15\n",
      "  done: false\n",
      "  episode_len_mean: 83.61016949152543\n",
      "  episode_reward_max: 9.918465443207424\n",
      "  episode_reward_mean: -96.46355751132634\n",
      "  episode_reward_min: -200.22694234868106\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 69089\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5774.945\n",
      "    load_time_ms: 1.904\n",
      "    num_steps_sampled: 6260000\n",
      "    num_steps_trained: 6260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.401298464324817e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3990345001220703\n",
      "      kl: 42.25550842285156\n",
      "      policy_loss: 0.31150972843170166\n",
      "      total_loss: 1392.1884765625\n",
      "      vf_explained_var: 0.5194846987724304\n",
      "      vf_loss: 1391.876953125\n",
      "    sample_time_ms: 26723.065\n",
      "    update_time_ms: 9.549\n",
      "  iterations_since_restore: 626\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.23177875566315\n",
      "  time_since_restore: 17957.476789951324\n",
      "  time_this_iter_s: 30.622366666793823\n",
      "  time_total_s: 17957.476789951324\n",
      "  timestamp: 1554826275\n",
      "  timesteps_since_restore: 6260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6260000\n",
      "  training_iteration: 626\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17957 s, 626 iter, 6260000 ts, -96.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-11-46\n",
      "  done: false\n",
      "  episode_len_mean: 88.51327433628319\n",
      "  episode_reward_max: 12.459443333483316\n",
      "  episode_reward_mean: -84.73192522966481\n",
      "  episode_reward_min: -200.32648765922755\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 69202\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5785.16\n",
      "    load_time_ms: 1.956\n",
      "    num_steps_sampled: 6270000\n",
      "    num_steps_trained: 6270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1019476964872256e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3835961818695068\n",
      "      kl: 0.03906853869557381\n",
      "      policy_loss: 0.014045383781194687\n",
      "      total_loss: 1446.0450439453125\n",
      "      vf_explained_var: 0.4902752637863159\n",
      "      vf_loss: 1446.031005859375\n",
      "    sample_time_ms: 26741.99\n",
      "    update_time_ms: 9.566\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.365962614832405\n",
      "  time_since_restore: 17988.248730659485\n",
      "  time_this_iter_s: 30.7719407081604\n",
      "  time_total_s: 17988.248730659485\n",
      "  timestamp: 1554826306\n",
      "  timesteps_since_restore: 6270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6270000\n",
      "  training_iteration: 627\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 17988 s, 627 iter, 6270000 ts, -84.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-12-28\n",
      "  done: false\n",
      "  episode_len_mean: 89.30973451327434\n",
      "  episode_reward_max: 14.651906727243603\n",
      "  episode_reward_mean: -82.8786751084771\n",
      "  episode_reward_min: -200.56083414926402\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 69315\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6081.042\n",
      "    load_time_ms: 1.846\n",
      "    num_steps_sampled: 6280000\n",
      "    num_steps_trained: 6280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1019476964872256e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3746310472488403\n",
      "      kl: 0.0370534248650074\n",
      "      policy_loss: 0.016901930794119835\n",
      "      total_loss: 1363.2393798828125\n",
      "      vf_explained_var: 0.49920767545700073\n",
      "      vf_loss: 1363.2225341796875\n",
      "    sample_time_ms: 27579.535\n",
      "    update_time_ms: 9.412\n",
      "  iterations_since_restore: 628\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.43933755423855\n",
      "  time_since_restore: 18030.190467119217\n",
      "  time_this_iter_s: 41.941736459732056\n",
      "  time_total_s: 18030.190467119217\n",
      "  timestamp: 1554826348\n",
      "  timesteps_since_restore: 6280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6280000\n",
      "  training_iteration: 628\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18030 s, 628 iter, 6280000 ts, -82.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-13-09\n",
      "  done: false\n",
      "  episode_len_mean: 82.00819672131148\n",
      "  episode_reward_max: 14.606416325557957\n",
      "  episode_reward_mean: -103.37941696552521\n",
      "  episode_reward_min: -201.35075483971613\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 69437\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6173.288\n",
      "    load_time_ms: 1.851\n",
      "    num_steps_sampled: 6290000\n",
      "    num_steps_trained: 6290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1019476964872256e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3942067623138428\n",
      "      kl: 0.044395919889211655\n",
      "      policy_loss: 0.016760574653744698\n",
      "      total_loss: 1407.42431640625\n",
      "      vf_explained_var: 0.5229005217552185\n",
      "      vf_loss: 1407.4075927734375\n",
      "    sample_time_ms: 28553.025\n",
      "    update_time_ms: 10.101\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.689708482762605\n",
      "  time_since_restore: 18070.555032491684\n",
      "  time_this_iter_s: 40.36456537246704\n",
      "  time_total_s: 18070.555032491684\n",
      "  timestamp: 1554826389\n",
      "  timesteps_since_restore: 6290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6290000\n",
      "  training_iteration: 629\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18070 s, 629 iter, 6290000 ts, -103 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-13-42\n",
      "  done: false\n",
      "  episode_len_mean: 92.58878504672897\n",
      "  episode_reward_max: 14.459911125990176\n",
      "  episode_reward_mean: -72.75184768284836\n",
      "  episode_reward_min: -200.2184715270996\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 69544\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6219.831\n",
      "    load_time_ms: 1.917\n",
      "    num_steps_sampled: 6300000\n",
      "    num_steps_trained: 6300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.2229864679470793e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3806649446487427\n",
      "      kl: 0.03591889515519142\n",
      "      policy_loss: 0.01289344858378172\n",
      "      total_loss: 1397.3909912109375\n",
      "      vf_explained_var: 0.48741471767425537\n",
      "      vf_loss: 1397.378173828125\n",
      "    sample_time_ms: 28786.19\n",
      "    update_time_ms: 10.22\n",
      "  iterations_since_restore: 630\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.37592384142419\n",
      "  time_since_restore: 18103.796627521515\n",
      "  time_this_iter_s: 33.24159502983093\n",
      "  time_total_s: 18103.796627521515\n",
      "  timestamp: 1554826422\n",
      "  timesteps_since_restore: 6300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6300000\n",
      "  training_iteration: 630\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18103 s, 630 iter, 6300000 ts, -72.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-14-13\n",
      "  done: false\n",
      "  episode_len_mean: 84.98305084745763\n",
      "  episode_reward_max: 15.228776621082826\n",
      "  episode_reward_mean: -94.6445704760845\n",
      "  episode_reward_min: -200.57314086800676\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 69662\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6211.098\n",
      "    load_time_ms: 1.909\n",
      "    num_steps_sampled: 6310000\n",
      "    num_steps_trained: 6310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.2229864679470793e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.399450659751892\n",
      "      kl: 0.04032203555107117\n",
      "      policy_loss: 0.010665735229849815\n",
      "      total_loss: 1380.441162109375\n",
      "      vf_explained_var: 0.48722898960113525\n",
      "      vf_loss: 1380.4305419921875\n",
      "    sample_time_ms: 28715.957\n",
      "    update_time_ms: 9.697\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.32228523804224\n",
      "  time_since_restore: 18134.416567087173\n",
      "  time_this_iter_s: 30.61993956565857\n",
      "  time_total_s: 18134.416567087173\n",
      "  timestamp: 1554826453\n",
      "  timesteps_since_restore: 6310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6310000\n",
      "  training_iteration: 631\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18134 s, 631 iter, 6310000 ts, -94.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-14-43\n",
      "  done: false\n",
      "  episode_len_mean: 88.10526315789474\n",
      "  episode_reward_max: 12.573899501859124\n",
      "  episode_reward_mean: -86.45188665896309\n",
      "  episode_reward_min: -200.30592526265568\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 69776\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6191.91\n",
      "    load_time_ms: 1.896\n",
      "    num_steps_sampled: 6320000\n",
      "    num_steps_trained: 6320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.764414778704378e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3946987390518188\n",
      "      kl: 0.040776245296001434\n",
      "      policy_loss: 0.012464474886655807\n",
      "      total_loss: 1391.6180419921875\n",
      "      vf_explained_var: 0.5033143162727356\n",
      "      vf_loss: 1391.6055908203125\n",
      "    sample_time_ms: 28728.02\n",
      "    update_time_ms: 9.436\n",
      "  iterations_since_restore: 632\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.225943329481545\n",
      "  time_since_restore: 18164.53870487213\n",
      "  time_this_iter_s: 30.122137784957886\n",
      "  time_total_s: 18164.53870487213\n",
      "  timestamp: 1554826483\n",
      "  timesteps_since_restore: 6320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6320000\n",
      "  training_iteration: 632\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18164 s, 632 iter, 6320000 ts, -86.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-15-13\n",
      "  done: false\n",
      "  episode_len_mean: 87.23684210526316\n",
      "  episode_reward_max: 17.24125789014436\n",
      "  episode_reward_mean: -88.06681511440651\n",
      "  episode_reward_min: -201.81577677144105\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 69890\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5940.864\n",
      "    load_time_ms: 1.959\n",
      "    num_steps_sampled: 6330000\n",
      "    num_steps_trained: 6330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.286752014489049e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.385059118270874\n",
      "      kl: 0.04663632810115814\n",
      "      policy_loss: 0.017452536150813103\n",
      "      total_loss: 1439.51953125\n",
      "      vf_explained_var: 0.48506247997283936\n",
      "      vf_loss: 1439.501953125\n",
      "    sample_time_ms: 28385.501\n",
      "    update_time_ms: 9.501\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.03340755720326\n",
      "  time_since_restore: 18194.56899356842\n",
      "  time_this_iter_s: 30.030288696289062\n",
      "  time_total_s: 18194.56899356842\n",
      "  timestamp: 1554826513\n",
      "  timesteps_since_restore: 6330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6330000\n",
      "  training_iteration: 633\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18194 s, 633 iter, 6330000 ts, -88.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-15-43\n",
      "  done: false\n",
      "  episode_len_mean: 83.30833333333334\n",
      "  episode_reward_max: 14.033494312831285\n",
      "  episode_reward_mean: -98.41366522898119\n",
      "  episode_reward_min: -201.08603798166706\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 70010\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5838.621\n",
      "    load_time_ms: 1.967\n",
      "    num_steps_sampled: 6340000\n",
      "    num_steps_trained: 6340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0789998175301091e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3838191032409668\n",
      "      kl: 0.04185551404953003\n",
      "      policy_loss: 0.01727212406694889\n",
      "      total_loss: 1389.5377197265625\n",
      "      vf_explained_var: 0.5101475119590759\n",
      "      vf_loss: 1389.5203857421875\n",
      "    sample_time_ms: 27911.29\n",
      "    update_time_ms: 9.552\n",
      "  iterations_since_restore: 634\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.206832614490594\n",
      "  time_since_restore: 18224.917189121246\n",
      "  time_this_iter_s: 30.348195552825928\n",
      "  time_total_s: 18224.917189121246\n",
      "  timestamp: 1554826543\n",
      "  timesteps_since_restore: 6340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6340000\n",
      "  training_iteration: 634\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18224 s, 634 iter, 6340000 ts, -98.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-16-14\n",
      "  done: false\n",
      "  episode_len_mean: 94.99056603773585\n",
      "  episode_reward_max: 12.464297246613889\n",
      "  episode_reward_mean: -67.90982636154115\n",
      "  episode_reward_min: -200.51244842476146\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 70116\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5797.601\n",
      "    load_time_ms: 1.937\n",
      "    num_steps_sampled: 6350000\n",
      "    num_steps_trained: 6350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6255062186167878e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3707466125488281\n",
      "      kl: 0.041579101234674454\n",
      "      policy_loss: 0.01970645971596241\n",
      "      total_loss: 1506.4051513671875\n",
      "      vf_explained_var: 0.43849653005599976\n",
      "      vf_loss: 1506.3853759765625\n",
      "    sample_time_ms: 27067.906\n",
      "    update_time_ms: 8.138\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.954913180770575\n",
      "  time_since_restore: 18255.835730791092\n",
      "  time_this_iter_s: 30.91854166984558\n",
      "  time_total_s: 18255.835730791092\n",
      "  timestamp: 1554826574\n",
      "  timesteps_since_restore: 6350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6350000\n",
      "  training_iteration: 635\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18255 s, 635 iter, 6350000 ts, -67.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 82.86666666666666\n",
      "  episode_reward_max: 14.194988845820777\n",
      "  episode_reward_mean: -102.03430108959974\n",
      "  episode_reward_min: -200.59605163165008\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 70236\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5809.269\n",
      "    load_time_ms: 1.831\n",
      "    num_steps_sampled: 6360000\n",
      "    num_steps_trained: 6360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4382593279251817e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3866909742355347\n",
      "      kl: 0.036589134484529495\n",
      "      policy_loss: 0.01671481691300869\n",
      "      total_loss: 1328.0650634765625\n",
      "      vf_explained_var: 0.5415565371513367\n",
      "      vf_loss: 1328.0484619140625\n",
      "    sample_time_ms: 27025.846\n",
      "    update_time_ms: 8.674\n",
      "  iterations_since_restore: 636\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.01715054479987\n",
      "  time_since_restore: 18286.158138990402\n",
      "  time_this_iter_s: 30.322408199310303\n",
      "  time_total_s: 18286.158138990402\n",
      "  timestamp: 1554826604\n",
      "  timesteps_since_restore: 6360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6360000\n",
      "  training_iteration: 636\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18286 s, 636 iter, 6360000 ts, -102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-17-15\n",
      "  done: false\n",
      "  episode_len_mean: 82.89166666666667\n",
      "  episode_reward_max: 14.629084941400507\n",
      "  episode_reward_mean: -101.41639841130561\n",
      "  episode_reward_min: -200.54633456673452\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 70356\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5796.237\n",
      "    load_time_ms: 1.807\n",
      "    num_steps_sampled: 6370000\n",
      "    num_steps_trained: 6370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4382593279251817e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3850432634353638\n",
      "      kl: 0.04903544485569\n",
      "      policy_loss: 0.019443413242697716\n",
      "      total_loss: 1362.6534423828125\n",
      "      vf_explained_var: 0.5227795243263245\n",
      "      vf_loss: 1362.634033203125\n",
      "    sample_time_ms: 27049.754\n",
      "    update_time_ms: 8.633\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.7081992056528\n",
      "  time_since_restore: 18317.03787636757\n",
      "  time_this_iter_s: 30.879737377166748\n",
      "  time_total_s: 18317.03787636757\n",
      "  timestamp: 1554826635\n",
      "  timesteps_since_restore: 6370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6370000\n",
      "  training_iteration: 637\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18317 s, 637 iter, 6370000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-17-47\n",
      "  done: false\n",
      "  episode_len_mean: 85.05042016806723\n",
      "  episode_reward_max: 16.45073396864189\n",
      "  episode_reward_mean: -95.68568867307717\n",
      "  episode_reward_min: -200.3783307170867\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 70475\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5522.749\n",
      "    load_time_ms: 1.824\n",
      "    num_steps_sampled: 6380000\n",
      "    num_steps_trained: 6380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6573889918877726e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3765430450439453\n",
      "      kl: 0.05229436978697777\n",
      "      policy_loss: 0.02111089415848255\n",
      "      total_loss: 1377.703369140625\n",
      "      vf_explained_var: 0.5332133173942566\n",
      "      vf_loss: 1377.6822509765625\n",
      "    sample_time_ms: 26285.068\n",
      "    update_time_ms: 9.016\n",
      "  iterations_since_restore: 638\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.84284433653859\n",
      "  time_since_restore: 18348.59721469879\n",
      "  time_this_iter_s: 31.559338331222534\n",
      "  time_total_s: 18348.59721469879\n",
      "  timestamp: 1554826667\n",
      "  timesteps_since_restore: 6380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6380000\n",
      "  training_iteration: 638\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18348 s, 638 iter, 6380000 ts, -95.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-18-18\n",
      "  done: false\n",
      "  episode_len_mean: 86.40869565217392\n",
      "  episode_reward_max: 15.306059337938521\n",
      "  episode_reward_mean: -91.23568446550388\n",
      "  episode_reward_min: -200.66118643991098\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 70590\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5436.791\n",
      "    load_time_ms: 1.84\n",
      "    num_steps_sampled: 6390000\n",
      "    num_steps_trained: 6390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.479076995510035e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3673784732818604\n",
      "      kl: 0.04302788898348808\n",
      "      policy_loss: 0.015407862141728401\n",
      "      total_loss: 1369.4385986328125\n",
      "      vf_explained_var: 0.512605607509613\n",
      "      vf_loss: 1369.423095703125\n",
      "    sample_time_ms: 25423.59\n",
      "    update_time_ms: 7.882\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.61784223275194\n",
      "  time_since_restore: 18379.481696128845\n",
      "  time_this_iter_s: 30.88448143005371\n",
      "  time_total_s: 18379.481696128845\n",
      "  timestamp: 1554826698\n",
      "  timesteps_since_restore: 6390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6390000\n",
      "  training_iteration: 639\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18379 s, 639 iter, 6390000 ts, -91.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-18-48\n",
      "  done: false\n",
      "  episode_len_mean: 88.76991150442478\n",
      "  episode_reward_max: 14.172652607592468\n",
      "  episode_reward_mean: -84.61922727748701\n",
      "  episode_reward_min: -200.93806145015841\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 70703\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5385.143\n",
      "    load_time_ms: 1.797\n",
      "    num_steps_sampled: 6400000\n",
      "    num_steps_trained: 6400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.225621985586676e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3704075813293457\n",
      "      kl: 0.032327327877283096\n",
      "      policy_loss: 0.012234902940690517\n",
      "      total_loss: 1397.10107421875\n",
      "      vf_explained_var: 0.49722740054130554\n",
      "      vf_loss: 1397.0889892578125\n",
      "    sample_time_ms: 25198.451\n",
      "    update_time_ms: 7.807\n",
      "  iterations_since_restore: 640\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.30961363874351\n",
      "  time_since_restore: 18409.95473384857\n",
      "  time_this_iter_s: 30.473037719726562\n",
      "  time_total_s: 18409.95473384857\n",
      "  timestamp: 1554826728\n",
      "  timesteps_since_restore: 6400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6400000\n",
      "  training_iteration: 640\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18409 s, 640 iter, 6400000 ts, -84.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 79.016\n",
      "  episode_reward_max: 13.136656485321787\n",
      "  episode_reward_mean: -110.53918220542262\n",
      "  episode_reward_min: -200.57206203851229\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 70828\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5365.372\n",
      "    load_time_ms: 1.79\n",
      "    num_steps_sampled: 6410000\n",
      "    num_steps_trained: 6410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.225621985586676e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3924039602279663\n",
      "      kl: 0.04073304682970047\n",
      "      policy_loss: 0.012465068139135838\n",
      "      total_loss: 1359.226806640625\n",
      "      vf_explained_var: 0.538053572177887\n",
      "      vf_loss: 1359.21435546875\n",
      "    sample_time_ms: 25208.91\n",
      "    update_time_ms: 7.849\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -55.2695911027113\n",
      "  time_since_restore: 18440.48210453987\n",
      "  time_this_iter_s: 30.52737069129944\n",
      "  time_total_s: 18440.48210453987\n",
      "  timestamp: 1554826759\n",
      "  timesteps_since_restore: 6410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6410000\n",
      "  training_iteration: 641\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18440 s, 641 iter, 6410000 ts, -111 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-19-52\n",
      "  done: false\n",
      "  episode_len_mean: 86.17796610169492\n",
      "  episode_reward_max: 14.394495391891871\n",
      "  episode_reward_mean: -91.57306923969008\n",
      "  episode_reward_min: -200.60532193511003\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 70946\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5509.549\n",
      "    load_time_ms: 1.814\n",
      "    num_steps_sampled: 6420000\n",
      "    num_steps_trained: 6420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.233142648605839e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3909642696380615\n",
      "      kl: 0.044903311878442764\n",
      "      policy_loss: 0.014921345748007298\n",
      "      total_loss: 1374.2205810546875\n",
      "      vf_explained_var: 0.5320641994476318\n",
      "      vf_loss: 1374.2056884765625\n",
      "    sample_time_ms: 25340.261\n",
      "    update_time_ms: 7.856\n",
      "  iterations_since_restore: 642\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.78653461984506\n",
      "  time_since_restore: 18473.371144771576\n",
      "  time_this_iter_s: 32.88904023170471\n",
      "  time_total_s: 18473.371144771576\n",
      "  timestamp: 1554826792\n",
      "  timesteps_since_restore: 6420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6420000\n",
      "  training_iteration: 642\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18473 s, 642 iter, 6420000 ts, -91.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-20-34\n",
      "  done: false\n",
      "  episode_len_mean: 86.28070175438596\n",
      "  episode_reward_max: 10.092601144184368\n",
      "  episode_reward_mean: -91.89724926274938\n",
      "  episode_reward_min: -200.44572617827782\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 71060\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5800.454\n",
      "    load_time_ms: 1.856\n",
      "    num_steps_sampled: 6430000\n",
      "    num_steps_trained: 6430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8497139729087585e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.399385690689087\n",
      "      kl: 0.06769649684429169\n",
      "      policy_loss: 0.025954794138669968\n",
      "      total_loss: 1363.6798095703125\n",
      "      vf_explained_var: 0.5245903134346008\n",
      "      vf_loss: 1363.6536865234375\n",
      "    sample_time_ms: 26202.272\n",
      "    update_time_ms: 8.003\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.94862463137469\n",
      "  time_since_restore: 18514.93522620201\n",
      "  time_this_iter_s: 41.56408143043518\n",
      "  time_total_s: 18514.93522620201\n",
      "  timestamp: 1554826834\n",
      "  timesteps_since_restore: 6430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6430000\n",
      "  training_iteration: 643\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18514 s, 643 iter, 6430000 ts, -91.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-21-21\n",
      "  done: false\n",
      "  episode_len_mean: 84.87394957983193\n",
      "  episode_reward_max: 13.029898398010335\n",
      "  episode_reward_mean: -93.41431249680825\n",
      "  episode_reward_min: -201.9863693895466\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 71179\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6083.902\n",
      "    load_time_ms: 2.001\n",
      "    num_steps_sampled: 6440000\n",
      "    num_steps_trained: 6440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7759722578274626e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.401467204093933\n",
      "      kl: 0.05155360326170921\n",
      "      policy_loss: 0.020957717671990395\n",
      "      total_loss: 1386.7880859375\n",
      "      vf_explained_var: 0.4939744472503662\n",
      "      vf_loss: 1386.7669677734375\n",
      "    sample_time_ms: 27671.135\n",
      "    update_time_ms: 7.922\n",
      "  iterations_since_restore: 644\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.707156248404125\n",
      "  time_since_restore: 18562.818383693695\n",
      "  time_this_iter_s: 47.88315749168396\n",
      "  time_total_s: 18562.818383693695\n",
      "  timestamp: 1554826881\n",
      "  timesteps_since_restore: 6440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6440000\n",
      "  training_iteration: 644\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18562 s, 644 iter, 6440000 ts, -93.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-22-12\n",
      "  done: false\n",
      "  episode_len_mean: 82.43442622950819\n",
      "  episode_reward_max: 15.733078266043185\n",
      "  episode_reward_mean: -101.66478117084858\n",
      "  episode_reward_min: -201.04510180036107\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 71301\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6119.909\n",
      "    load_time_ms: 2.058\n",
      "    num_steps_sampled: 6450000\n",
      "    num_steps_trained: 6450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.1632577375090315e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4099410772323608\n",
      "      kl: 0.04757162928581238\n",
      "      policy_loss: 0.02061382494866848\n",
      "      total_loss: 1379.54736328125\n",
      "      vf_explained_var: 0.5241777300834656\n",
      "      vf_loss: 1379.5267333984375\n",
      "    sample_time_ms: 29553.557\n",
      "    update_time_ms: 8.174\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.83239058542431\n",
      "  time_since_restore: 18612.92737841606\n",
      "  time_this_iter_s: 50.10899472236633\n",
      "  time_total_s: 18612.92737841606\n",
      "  timestamp: 1554826932\n",
      "  timesteps_since_restore: 6450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6450000\n",
      "  training_iteration: 645\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18612 s, 645 iter, 6450000 ts, -102 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-22-44\n",
      "  done: false\n",
      "  episode_len_mean: 89.6036036036036\n",
      "  episode_reward_max: 12.785386694975577\n",
      "  episode_reward_mean: -83.89171199025805\n",
      "  episode_reward_min: -200.29391387409163\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 71412\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6120.723\n",
      "    load_time_ms: 2.011\n",
      "    num_steps_sampled: 6460000\n",
      "    num_steps_trained: 6460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.24558725549571e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4004995822906494\n",
      "      kl: 0.045586202293634415\n",
      "      policy_loss: 0.01665402762591839\n",
      "      total_loss: 1371.5184326171875\n",
      "      vf_explained_var: 0.515070378780365\n",
      "      vf_loss: 1371.501953125\n",
      "    sample_time_ms: 29741.177\n",
      "    update_time_ms: 8.414\n",
      "  iterations_since_restore: 646\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.94585599512902\n",
      "  time_since_restore: 18645.13443660736\n",
      "  time_this_iter_s: 32.20705819129944\n",
      "  time_total_s: 18645.13443660736\n",
      "  timestamp: 1554826964\n",
      "  timesteps_since_restore: 6460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6460000\n",
      "  training_iteration: 646\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18645 s, 646 iter, 6460000 ts, -83.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-23-20\n",
      "  done: false\n",
      "  episode_len_mean: 85.85344827586206\n",
      "  episode_reward_max: 15.920312041285314\n",
      "  episode_reward_mean: -90.7885842220645\n",
      "  episode_reward_min: -200.3922469488424\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 71528\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6317.387\n",
      "    load_time_ms: 2.028\n",
      "    num_steps_sampled: 6470000\n",
      "    num_steps_trained: 6470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.367680234011402e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4063247442245483\n",
      "      kl: 0.04574957862496376\n",
      "      policy_loss: 0.0174671970307827\n",
      "      total_loss: 1476.3424072265625\n",
      "      vf_explained_var: 0.47590479254722595\n",
      "      vf_loss: 1476.324951171875\n",
      "    sample_time_ms: 30098.01\n",
      "    update_time_ms: 8.37\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.39429211103225\n",
      "  time_since_restore: 18681.549474477768\n",
      "  time_this_iter_s: 36.415037870407104\n",
      "  time_total_s: 18681.549474477768\n",
      "  timestamp: 1554827000\n",
      "  timesteps_since_restore: 6470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6470000\n",
      "  training_iteration: 647\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18681 s, 647 iter, 6470000 ts, -90.8 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-23-52\n",
      "  done: false\n",
      "  episode_len_mean: 86.92105263157895\n",
      "  episode_reward_max: 13.254539955977386\n",
      "  episode_reward_mean: -89.6676084481635\n",
      "  episode_reward_min: -201.6543595950752\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 71642\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6335.72\n",
      "    load_time_ms: 2.027\n",
      "    num_steps_sampled: 6480000\n",
      "    num_steps_trained: 6480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.405081970178494e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.41688871383667\n",
      "      kl: 0.02929215505719185\n",
      "      policy_loss: 0.009641454555094242\n",
      "      total_loss: 1392.2491455078125\n",
      "      vf_explained_var: 0.4992873966693878\n",
      "      vf_loss: 1392.2396240234375\n",
      "    sample_time_ms: 30113.598\n",
      "    update_time_ms: 8.349\n",
      "  iterations_since_restore: 648\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.83380422408175\n",
      "  time_since_restore: 18713.45157265663\n",
      "  time_this_iter_s: 31.902098178863525\n",
      "  time_total_s: 18713.45157265663\n",
      "  timestamp: 1554827032\n",
      "  timesteps_since_restore: 6480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6480000\n",
      "  training_iteration: 648\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18713 s, 648 iter, 6480000 ts, -89.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-24-32\n",
      "  done: false\n",
      "  episode_len_mean: 85.32203389830508\n",
      "  episode_reward_max: 16.189723971357424\n",
      "  episode_reward_mean: -94.57179268646688\n",
      "  episode_reward_min: -200.69987678027678\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 71760\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6454.434\n",
      "    load_time_ms: 2.017\n",
      "    num_steps_sampled: 6490000\n",
      "    num_steps_trained: 6490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.405081970178494e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4249835014343262\n",
      "      kl: 0.03662170469760895\n",
      "      policy_loss: 0.01355945784598589\n",
      "      total_loss: 1383.917724609375\n",
      "      vf_explained_var: 0.5040649771690369\n",
      "      vf_loss: 1383.9041748046875\n",
      "    sample_time_ms: 30893.007\n",
      "    update_time_ms: 8.751\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.28589634323344\n",
      "  time_since_restore: 18753.3175573349\n",
      "  time_this_iter_s: 39.86598467826843\n",
      "  time_total_s: 18753.3175573349\n",
      "  timestamp: 1554827072\n",
      "  timesteps_since_restore: 6490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6490000\n",
      "  training_iteration: 649\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18753 s, 649 iter, 6490000 ts, -94.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-25-05\n",
      "  done: false\n",
      "  episode_len_mean: 85.38135593220339\n",
      "  episode_reward_max: 13.724971249238797\n",
      "  episode_reward_mean: -95.15120007875733\n",
      "  episode_reward_min: -200.6704538386171\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 71878\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6485.343\n",
      "    load_time_ms: 2.041\n",
      "    num_steps_sampled: 6500000\n",
      "    num_steps_trained: 6500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.405081970178494e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4308353662490845\n",
      "      kl: 0.04823685437440872\n",
      "      policy_loss: 0.016527479514479637\n",
      "      total_loss: 1348.32177734375\n",
      "      vf_explained_var: 0.5341000556945801\n",
      "      vf_loss: 1348.3052978515625\n",
      "    sample_time_ms: 31076.017\n",
      "    update_time_ms: 8.8\n",
      "  iterations_since_restore: 650\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.57560003937867\n",
      "  time_since_restore: 18785.927694797516\n",
      "  time_this_iter_s: 32.61013746261597\n",
      "  time_total_s: 18785.927694797516\n",
      "  timestamp: 1554827105\n",
      "  timesteps_since_restore: 6500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6500000\n",
      "  training_iteration: 650\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18785 s, 650 iter, 6500000 ts, -95.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-25-41\n",
      "  done: false\n",
      "  episode_len_mean: 86.86842105263158\n",
      "  episode_reward_max: 10.90008470950616\n",
      "  episode_reward_mean: -91.3296630774282\n",
      "  episode_reward_min: -201.628571595049\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 71992\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6602.798\n",
      "    load_time_ms: 2.024\n",
      "    num_steps_sampled: 6510000\n",
      "    num_steps_trained: 6510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1076930201909574e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4185287952423096\n",
      "      kl: 0.04999434947967529\n",
      "      policy_loss: 0.014337635599076748\n",
      "      total_loss: 1353.1915283203125\n",
      "      vf_explained_var: 0.5153172016143799\n",
      "      vf_loss: 1353.17724609375\n",
      "    sample_time_ms: 31493.779\n",
      "    update_time_ms: 8.759\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.66483153871411\n",
      "  time_since_restore: 18821.80531358719\n",
      "  time_this_iter_s: 35.87761878967285\n",
      "  time_total_s: 18821.80531358719\n",
      "  timestamp: 1554827141\n",
      "  timesteps_since_restore: 6510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6510000\n",
      "  training_iteration: 651\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18821 s, 651 iter, 6510000 ts, -91.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-26-19\n",
      "  done: false\n",
      "  episode_len_mean: 95.08571428571429\n",
      "  episode_reward_max: 16.771622780483238\n",
      "  episode_reward_mean: -68.44564307704515\n",
      "  episode_reward_min: -201.73839063028637\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 72097\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6524.555\n",
      "    load_time_ms: 1.977\n",
      "    num_steps_sampled: 6520000\n",
      "    num_steps_trained: 6520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.16146946536322e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4070507287979126\n",
      "      kl: 0.041636306792497635\n",
      "      policy_loss: 0.013776445761322975\n",
      "      total_loss: 1524.339599609375\n",
      "      vf_explained_var: 0.41907331347465515\n",
      "      vf_loss: 1524.325927734375\n",
      "    sample_time_ms: 32079.98\n",
      "    update_time_ms: 8.728\n",
      "  iterations_since_restore: 652\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -34.22282153852258\n",
      "  time_since_restore: 18859.763302087784\n",
      "  time_this_iter_s: 37.95798850059509\n",
      "  time_total_s: 18859.763302087784\n",
      "  timestamp: 1554827179\n",
      "  timesteps_since_restore: 6520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6520000\n",
      "  training_iteration: 652\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18859 s, 652 iter, 6520000 ts, -68.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-26-57\n",
      "  done: false\n",
      "  episode_len_mean: 91.23636363636363\n",
      "  episode_reward_max: 15.003365055092935\n",
      "  episode_reward_mean: -78.391890647155\n",
      "  episode_reward_min: -200.6430987638127\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 72207\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6281.244\n",
      "    load_time_ms: 1.904\n",
      "    num_steps_sampled: 6530000\n",
      "    num_steps_trained: 6530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.742274262968046e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4213446378707886\n",
      "      kl: 0.037928685545921326\n",
      "      policy_loss: 0.015493025071918964\n",
      "      total_loss: 1496.4737548828125\n",
      "      vf_explained_var: 0.4445865750312805\n",
      "      vf_loss: 1496.4583740234375\n",
      "    sample_time_ms: 31951.315\n",
      "    update_time_ms: 9.102\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.195945323577504\n",
      "  time_since_restore: 18897.610040187836\n",
      "  time_this_iter_s: 37.84673810005188\n",
      "  time_total_s: 18897.610040187836\n",
      "  timestamp: 1554827217\n",
      "  timesteps_since_restore: 6530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6530000\n",
      "  training_iteration: 653\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18897 s, 653 iter, 6530000 ts, -78.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-27-34\n",
      "  done: false\n",
      "  episode_len_mean: 83.42148760330579\n",
      "  episode_reward_max: 16.489611878280698\n",
      "  episode_reward_mean: -99.33704916799041\n",
      "  episode_reward_min: -201.0749991807232\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 72328\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6075.814\n",
      "    load_time_ms: 1.788\n",
      "    num_steps_sampled: 6540000\n",
      "    num_steps_trained: 6540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.742274262968046e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4253076314926147\n",
      "      kl: 43.360252380371094\n",
      "      policy_loss: 0.2441602349281311\n",
      "      total_loss: 1390.9202880859375\n",
      "      vf_explained_var: 0.5033029317855835\n",
      "      vf_loss: 1390.676025390625\n",
      "    sample_time_ms: 31111.442\n",
      "    update_time_ms: 9.047\n",
      "  iterations_since_restore: 654\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.66852458399521\n",
      "  time_since_restore: 18935.031284093857\n",
      "  time_this_iter_s: 37.42124390602112\n",
      "  time_total_s: 18935.031284093857\n",
      "  timestamp: 1554827254\n",
      "  timesteps_since_restore: 6540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6540000\n",
      "  training_iteration: 654\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18935 s, 654 iter, 6540000 ts, -99.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-28-09\n",
      "  done: false\n",
      "  episode_len_mean: 85.84482758620689\n",
      "  episode_reward_max: 14.748164249577956\n",
      "  episode_reward_mean: -93.95414164681043\n",
      "  episode_reward_min: -201.18128495558707\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 72444\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6051.39\n",
      "    load_time_ms: 1.762\n",
      "    num_steps_sampled: 6550000\n",
      "    num_steps_trained: 6550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.113271264605636e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4338610172271729\n",
      "      kl: 0.027816995978355408\n",
      "      policy_loss: 0.010069360956549644\n",
      "      total_loss: 1312.4288330078125\n",
      "      vf_explained_var: 0.532343864440918\n",
      "      vf_loss: 1312.4188232421875\n",
      "    sample_time_ms: 29635.462\n",
      "    update_time_ms: 8.857\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.97707082340521\n",
      "  time_since_restore: 18970.134345054626\n",
      "  time_this_iter_s: 35.10306096076965\n",
      "  time_total_s: 18970.134345054626\n",
      "  timestamp: 1554827289\n",
      "  timesteps_since_restore: 6550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6550000\n",
      "  training_iteration: 655\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 18970 s, 655 iter, 6550000 ts, -94 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-28-49\n",
      "  done: false\n",
      "  episode_len_mean: 92.64485981308411\n",
      "  episode_reward_max: 17.311200656791094\n",
      "  episode_reward_mean: -76.20634982633403\n",
      "  episode_reward_min: -200.21592541637736\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 72551\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6128.114\n",
      "    load_time_ms: 1.852\n",
      "    num_steps_sampled: 6560000\n",
      "    num_steps_trained: 6560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.113271264605636e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4383920431137085\n",
      "      kl: 0.03980497270822525\n",
      "      policy_loss: 0.013619847595691681\n",
      "      total_loss: 1469.105712890625\n",
      "      vf_explained_var: 0.46204423904418945\n",
      "      vf_loss: 1469.092041015625\n",
      "    sample_time_ms: 30251.133\n",
      "    update_time_ms: 7.968\n",
      "  iterations_since_restore: 656\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.10317491316702\n",
      "  time_since_restore: 19009.26420044899\n",
      "  time_this_iter_s: 39.1298553943634\n",
      "  time_total_s: 19009.26420044899\n",
      "  timestamp: 1554827329\n",
      "  timesteps_since_restore: 6560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6560000\n",
      "  training_iteration: 656\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19009 s, 656 iter, 6560000 ts, -76.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-29-31\n",
      "  done: false\n",
      "  episode_len_mean: 88.78947368421052\n",
      "  episode_reward_max: 12.743139859241005\n",
      "  episode_reward_mean: -84.4463278876288\n",
      "  episode_reward_min: -200.76733013473762\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 72665\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6059.684\n",
      "    load_time_ms: 1.862\n",
      "    num_steps_sampled: 6570000\n",
      "    num_steps_trained: 6570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.113271264605636e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4464490413665771\n",
      "      kl: 0.043090540915727615\n",
      "      policy_loss: 0.01915934681892395\n",
      "      total_loss: 1385.7564697265625\n",
      "      vf_explained_var: 0.48983490467071533\n",
      "      vf_loss: 1385.7374267578125\n",
      "    sample_time_ms: 30921.427\n",
      "    update_time_ms: 7.959\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.2231639438144\n",
      "  time_since_restore: 19051.698780298233\n",
      "  time_this_iter_s: 42.434579849243164\n",
      "  time_total_s: 19051.698780298233\n",
      "  timestamp: 1554827371\n",
      "  timesteps_since_restore: 6570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6570000\n",
      "  training_iteration: 657\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19051 s, 657 iter, 6570000 ts, -84.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-30-05\n",
      "  done: false\n",
      "  episode_len_mean: 88.2280701754386\n",
      "  episode_reward_max: 14.956654107584965\n",
      "  episode_reward_mean: -87.49268850582463\n",
      "  episode_reward_min: -201.41869311585896\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 72779\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6075.416\n",
      "    load_time_ms: 1.898\n",
      "    num_steps_sampled: 6580000\n",
      "    num_steps_trained: 6580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0670047026754887e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4433666467666626\n",
      "      kl: 0.04373621940612793\n",
      "      policy_loss: 0.021655181422829628\n",
      "      total_loss: 1423.4827880859375\n",
      "      vf_explained_var: 0.5023245215415955\n",
      "      vf_loss: 1423.461181640625\n",
      "    sample_time_ms: 31108.108\n",
      "    update_time_ms: 7.798\n",
      "  iterations_since_restore: 658\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.74634425291233\n",
      "  time_since_restore: 19085.627548217773\n",
      "  time_this_iter_s: 33.928767919540405\n",
      "  time_total_s: 19085.627548217773\n",
      "  timestamp: 1554827405\n",
      "  timesteps_since_restore: 6580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6580000\n",
      "  training_iteration: 658\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19085 s, 658 iter, 6580000 ts, -87.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-30-42\n",
      "  done: false\n",
      "  episode_len_mean: 88.27678571428571\n",
      "  episode_reward_max: 13.466709328854042\n",
      "  episode_reward_mean: -85.5877495828538\n",
      "  episode_reward_min: -200.92216967945308\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 72891\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5992.134\n",
      "    load_time_ms: 1.843\n",
      "    num_steps_sampled: 6590000\n",
      "    num_steps_trained: 6590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6004930410285898e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4376323223114014\n",
      "      kl: 11.878189086914062\n",
      "      policy_loss: 0.08608859777450562\n",
      "      total_loss: 1400.491943359375\n",
      "      vf_explained_var: 0.4996275305747986\n",
      "      vf_loss: 1400.406005859375\n",
      "    sample_time_ms: 30853.289\n",
      "    update_time_ms: 7.542\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.7938747914269\n",
      "  time_since_restore: 19122.10752606392\n",
      "  time_this_iter_s: 36.47997784614563\n",
      "  time_total_s: 19122.10752606392\n",
      "  timestamp: 1554827442\n",
      "  timesteps_since_restore: 6590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6590000\n",
      "  training_iteration: 659\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19122 s, 659 iter, 6590000 ts, -85.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-31-33\n",
      "  done: false\n",
      "  episode_len_mean: 81.20161290322581\n",
      "  episode_reward_max: 17.424450602319027\n",
      "  episode_reward_mean: -106.48868522661297\n",
      "  episode_reward_min: -201.0215470851344\n",
      "  episodes_this_iter: 124\n",
      "  episodes_total: 73015\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6246.214\n",
      "    load_time_ms: 2.274\n",
      "    num_steps_sampled: 6600000\n",
      "    num_steps_trained: 6600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4007465680352064e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4609050750732422\n",
      "      kl: 0.04806064814329147\n",
      "      policy_loss: 0.019656704738736153\n",
      "      total_loss: 1240.3438720703125\n",
      "      vf_explained_var: 0.5884121656417847\n",
      "      vf_loss: 1240.3240966796875\n",
      "    sample_time_ms: 32460.555\n",
      "    update_time_ms: 7.559\n",
      "  iterations_since_restore: 660\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -53.24434261330648\n",
      "  time_since_restore: 19173.351689577103\n",
      "  time_this_iter_s: 51.244163513183594\n",
      "  time_total_s: 19173.351689577103\n",
      "  timestamp: 1554827493\n",
      "  timesteps_since_restore: 6600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6600000\n",
      "  training_iteration: 660\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19173 s, 660 iter, 6600000 ts, -106 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-32-12\n",
      "  done: false\n",
      "  episode_len_mean: 86.20869565217392\n",
      "  episode_reward_max: 13.323427598017627\n",
      "  episode_reward_mean: -92.08955569089794\n",
      "  episode_reward_min: -200.74609283962502\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 73130\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6412.242\n",
      "    load_time_ms: 2.319\n",
      "    num_steps_sampled: 6610000\n",
      "    num_steps_trained: 6610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.601126858545131e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.446053385734558\n",
      "      kl: 0.0407753586769104\n",
      "      policy_loss: 0.017292724922299385\n",
      "      total_loss: 1486.26123046875\n",
      "      vf_explained_var: 0.47459569573402405\n",
      "      vf_loss: 1486.2440185546875\n",
      "    sample_time_ms: 32615.337\n",
      "    update_time_ms: 7.573\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.04477784544897\n",
      "  time_since_restore: 19212.44972038269\n",
      "  time_this_iter_s: 39.09803080558777\n",
      "  time_total_s: 19212.44972038269\n",
      "  timestamp: 1554827532\n",
      "  timesteps_since_restore: 6610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6610000\n",
      "  training_iteration: 661\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19212 s, 661 iter, 6610000 ts, -92.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-32-47\n",
      "  done: false\n",
      "  episode_len_mean: 85.83898305084746\n",
      "  episode_reward_max: 14.587538118339658\n",
      "  episode_reward_mean: -93.69350742923235\n",
      "  episode_reward_min: -201.52266795996223\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 73248\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6409.481\n",
      "    load_time_ms: 2.293\n",
      "    num_steps_sampled: 6620000\n",
      "    num_steps_trained: 6620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.401683281325375e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4494720697402954\n",
      "      kl: 0.04900345578789711\n",
      "      policy_loss: 0.017473097890615463\n",
      "      total_loss: 1415.37158203125\n",
      "      vf_explained_var: 0.5116620063781738\n",
      "      vf_loss: 1415.3541259765625\n",
      "    sample_time_ms: 32319.089\n",
      "    update_time_ms: 7.724\n",
      "  iterations_since_restore: 662\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.84675371461617\n",
      "  time_since_restore: 19247.41917204857\n",
      "  time_this_iter_s: 34.969451665878296\n",
      "  time_total_s: 19247.41917204857\n",
      "  timestamp: 1554827567\n",
      "  timesteps_since_restore: 6620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6620000\n",
      "  training_iteration: 662\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19247 s, 662 iter, 6620000 ts, -93.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-33-19\n",
      "  done: false\n",
      "  episode_len_mean: 86.9298245614035\n",
      "  episode_reward_max: 14.993783656804446\n",
      "  episode_reward_mean: -91.1366415858337\n",
      "  episode_reward_min: -202.00389465545572\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 73362\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6369.123\n",
      "    load_time_ms: 2.272\n",
      "    num_steps_sampled: 6630000\n",
      "    num_steps_trained: 6630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.102517915495741e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4428062438964844\n",
      "      kl: 0.059045400470495224\n",
      "      policy_loss: 0.023906871676445007\n",
      "      total_loss: 1397.269775390625\n",
      "      vf_explained_var: 0.508046567440033\n",
      "      vf_loss: 1397.2459716796875\n",
      "    sample_time_ms: 31748.616\n",
      "    update_time_ms: 7.097\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.568320792916865\n",
      "  time_since_restore: 19279.151523828506\n",
      "  time_this_iter_s: 31.732351779937744\n",
      "  time_total_s: 19279.151523828506\n",
      "  timestamp: 1554827599\n",
      "  timesteps_since_restore: 6630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6630000\n",
      "  training_iteration: 663\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19279 s, 663 iter, 6630000 ts, -91.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-33-50\n",
      "  done: false\n",
      "  episode_len_mean: 88.33333333333333\n",
      "  episode_reward_max: 15.439956400140435\n",
      "  episode_reward_mean: -84.57173279752436\n",
      "  episode_reward_min: -200.740830807701\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 73476\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6328.756\n",
      "    load_time_ms: 2.18\n",
      "    num_steps_sampled: 6640000\n",
      "    num_steps_trained: 6640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2153783879735933e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.432173490524292\n",
      "      kl: 0.04992426559329033\n",
      "      policy_loss: 0.018813205882906914\n",
      "      total_loss: 1424.6536865234375\n",
      "      vf_explained_var: 0.5054745078086853\n",
      "      vf_loss: 1424.635009765625\n",
      "    sample_time_ms: 31162.389\n",
      "    update_time_ms: 7.053\n",
      "  iterations_since_restore: 664\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.28586639876217\n",
      "  time_since_restore: 19310.301772356033\n",
      "  time_this_iter_s: 31.150248527526855\n",
      "  time_total_s: 19310.301772356033\n",
      "  timestamp: 1554827630\n",
      "  timesteps_since_restore: 6640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6640000\n",
      "  training_iteration: 664\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19310 s, 664 iter, 6640000 ts, -84.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-34-23\n",
      "  done: false\n",
      "  episode_len_mean: 88.30088495575221\n",
      "  episode_reward_max: 16.25880994685919\n",
      "  episode_reward_mean: -85.77442201432528\n",
      "  episode_reward_min: -200.83090646460244\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 73589\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6390.297\n",
      "    load_time_ms: 2.255\n",
      "    num_steps_sampled: 6650000\n",
      "    num_steps_trained: 6650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8230668813111578e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4334005117416382\n",
      "      kl: 0.05794147402048111\n",
      "      policy_loss: 0.025594979524612427\n",
      "      total_loss: 1393.6121826171875\n",
      "      vf_explained_var: 0.501915693283081\n",
      "      vf_loss: 1393.5865478515625\n",
      "    sample_time_ms: 30842.957\n",
      "    update_time_ms: 6.868\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.88721100716264\n",
      "  time_since_restore: 19342.82411146164\n",
      "  time_this_iter_s: 32.52233910560608\n",
      "  time_total_s: 19342.82411146164\n",
      "  timestamp: 1554827663\n",
      "  timesteps_since_restore: 6650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6650000\n",
      "  training_iteration: 665\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19342 s, 665 iter, 6650000 ts, -85.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-35-13\n",
      "  done: false\n",
      "  episode_len_mean: 88.33628318584071\n",
      "  episode_reward_max: 16.491996028374476\n",
      "  episode_reward_mean: -83.14074678447088\n",
      "  episode_reward_min: -201.04084065512993\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 73702\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6705.459\n",
      "    load_time_ms: 2.301\n",
      "    num_steps_sampled: 6660000\n",
      "    num_steps_trained: 6660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7346003219667367e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4288703203201294\n",
      "      kl: 0.051180873066186905\n",
      "      policy_loss: 0.02169843204319477\n",
      "      total_loss: 1451.816650390625\n",
      "      vf_explained_var: 0.47608909010887146\n",
      "      vf_loss: 1451.794921875\n",
      "    sample_time_ms: 31644.079\n",
      "    update_time_ms: 7.476\n",
      "  iterations_since_restore: 666\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.57037339223544\n",
      "  time_since_restore: 19393.124594449997\n",
      "  time_this_iter_s: 50.300482988357544\n",
      "  time_total_s: 19393.124594449997\n",
      "  timestamp: 1554827713\n",
      "  timesteps_since_restore: 6660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6660000\n",
      "  training_iteration: 666\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19393 s, 666 iter, 6660000 ts, -83.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-35-59\n",
      "  done: false\n",
      "  episode_len_mean: 87.28318584070796\n",
      "  episode_reward_max: 12.325237650808765\n",
      "  episode_reward_mean: -88.5662852523772\n",
      "  episode_reward_min: -200.67579435597122\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 73815\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6967.475\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 6670000\n",
      "    num_steps_trained: 6670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.1019018842485694e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.435198426246643\n",
      "      kl: 0.046137042343616486\n",
      "      policy_loss: 0.01888824626803398\n",
      "      total_loss: 1354.966796875\n",
      "      vf_explained_var: 0.5163339376449585\n",
      "      vf_loss: 1354.94775390625\n",
      "    sample_time_ms: 31700.52\n",
      "    update_time_ms: 8.098\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.2831426261886\n",
      "  time_since_restore: 19438.766622781754\n",
      "  time_this_iter_s: 45.64202833175659\n",
      "  time_total_s: 19438.766622781754\n",
      "  timestamp: 1554827759\n",
      "  timesteps_since_restore: 6670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6670000\n",
      "  training_iteration: 667\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19438 s, 667 iter, 6670000 ts, -88.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-36-39\n",
      "  done: false\n",
      "  episode_len_mean: 84.29166666666667\n",
      "  episode_reward_max: 8.646445053038331\n",
      "  episode_reward_mean: -100.37655224317285\n",
      "  episode_reward_min: -202.32889099592285\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 73935\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7139.803\n",
      "    load_time_ms: 2.45\n",
      "    num_steps_sampled: 6680000\n",
      "    num_steps_trained: 6680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.152852125723622e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4369055032730103\n",
      "      kl: 0.047136690467596054\n",
      "      policy_loss: 0.01839604787528515\n",
      "      total_loss: 1405.628662109375\n",
      "      vf_explained_var: 0.5137699842453003\n",
      "      vf_loss: 1405.6103515625\n",
      "    sample_time_ms: 32167.667\n",
      "    update_time_ms: 8.697\n",
      "  iterations_since_restore: 668\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.18827612158643\n",
      "  time_since_restore: 19479.10540652275\n",
      "  time_this_iter_s: 40.338783740997314\n",
      "  time_total_s: 19479.10540652275\n",
      "  timestamp: 1554827799\n",
      "  timesteps_since_restore: 6680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6680000\n",
      "  training_iteration: 668\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 10.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19479 s, 668 iter, 6680000 ts, -100 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-37-18\n",
      "  done: false\n",
      "  episode_len_mean: 85.21186440677967\n",
      "  episode_reward_max: 16.59383244637263\n",
      "  episode_reward_mean: -95.28478949665326\n",
      "  episode_reward_min: -200.66651356535647\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 74053\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7225.163\n",
      "    load_time_ms: 2.586\n",
      "    num_steps_sampled: 6690000\n",
      "    num_steps_trained: 6690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.229278188585433e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.406217336654663\n",
      "      kl: 1.1249184608459473\n",
      "      policy_loss: 0.042550962418317795\n",
      "      total_loss: 1367.2724609375\n",
      "      vf_explained_var: 0.5159733891487122\n",
      "      vf_loss: 1367.22998046875\n",
      "    sample_time_ms: 32284.669\n",
      "    update_time_ms: 8.642\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.64239474832662\n",
      "  time_since_restore: 19517.610030174255\n",
      "  time_this_iter_s: 38.50462365150452\n",
      "  time_total_s: 19517.610030174255\n",
      "  timestamp: 1554827838\n",
      "  timesteps_since_restore: 6690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6690000\n",
      "  training_iteration: 669\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19517 s, 669 iter, 6690000 ts, -95.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-37-54\n",
      "  done: false\n",
      "  episode_len_mean: 84.58474576271186\n",
      "  episode_reward_max: 13.547104074222323\n",
      "  episode_reward_mean: -94.26408379582176\n",
      "  episode_reward_min: -201.77891298856363\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 74171\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7016.562\n",
      "    load_time_ms: 2.118\n",
      "    num_steps_sampled: 6700000\n",
      "    num_steps_trained: 6700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3843917983527382e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4145585298538208\n",
      "      kl: 0.049926456063985825\n",
      "      policy_loss: 0.016173943877220154\n",
      "      total_loss: 1366.8428955078125\n",
      "      vf_explained_var: 0.5241103768348694\n",
      "      vf_loss: 1366.8267822265625\n",
      "    sample_time_ms: 31004.843\n",
      "    update_time_ms: 8.739\n",
      "  iterations_since_restore: 670\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.132041897910874\n",
      "  time_since_restore: 19553.953900814056\n",
      "  time_this_iter_s: 36.343870639801025\n",
      "  time_total_s: 19553.953900814056\n",
      "  timestamp: 1554827874\n",
      "  timesteps_since_restore: 6700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6700000\n",
      "  training_iteration: 670\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19553 s, 670 iter, 6700000 ts, -94.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 84.57264957264957\n",
      "  episode_reward_max: 15.515913747956985\n",
      "  episode_reward_mean: -94.97903088884544\n",
      "  episode_reward_min: -201.4801911917275\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 74288\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6806.688\n",
      "    load_time_ms: 2.089\n",
      "    num_steps_sampled: 6710000\n",
      "    num_steps_trained: 6710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0765875573992608e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4138126373291016\n",
      "      kl: 0.03937731683254242\n",
      "      policy_loss: 0.015240399166941643\n",
      "      total_loss: 1327.458740234375\n",
      "      vf_explained_var: 0.5244874954223633\n",
      "      vf_loss: 1327.4434814453125\n",
      "    sample_time_ms: 30846.977\n",
      "    update_time_ms: 8.793\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.48951544442272\n",
      "  time_since_restore: 19589.369641542435\n",
      "  time_this_iter_s: 35.415740728378296\n",
      "  time_total_s: 19589.369641542435\n",
      "  timestamp: 1554827910\n",
      "  timesteps_since_restore: 6710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6710000\n",
      "  training_iteration: 671\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19589 s, 671 iter, 6710000 ts, -95 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-39-07\n",
      "  done: false\n",
      "  episode_len_mean: 88.0701754385965\n",
      "  episode_reward_max: 14.648034103240981\n",
      "  episode_reward_mean: -85.87376540116433\n",
      "  episode_reward_min: -201.07163547580825\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 74402\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6834.025\n",
      "    load_time_ms: 2.08\n",
      "    num_steps_sampled: 6720000\n",
      "    num_steps_trained: 6720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0765875573992608e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4109244346618652\n",
      "      kl: 0.09029625356197357\n",
      "      policy_loss: 0.033915355801582336\n",
      "      total_loss: 1477.945556640625\n",
      "      vf_explained_var: 0.45608100295066833\n",
      "      vf_loss: 1477.91162109375\n",
      "    sample_time_ms: 31036.992\n",
      "    update_time_ms: 9.069\n",
      "  iterations_since_restore: 672\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.93688270058216\n",
      "  time_since_restore: 19626.51298904419\n",
      "  time_this_iter_s: 37.14334750175476\n",
      "  time_total_s: 19626.51298904419\n",
      "  timestamp: 1554827947\n",
      "  timesteps_since_restore: 6720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6720000\n",
      "  training_iteration: 672\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19626 s, 672 iter, 6720000 ts, -85.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-39-44\n",
      "  done: false\n",
      "  episode_len_mean: 84.85470085470085\n",
      "  episode_reward_max: 13.420995827396975\n",
      "  episode_reward_mean: -94.04648352850573\n",
      "  episode_reward_min: -200.93281564665784\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 74519\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7012.288\n",
      "    load_time_ms: 2.136\n",
      "    num_steps_sampled: 6730000\n",
      "    num_steps_trained: 6730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.114881336098891e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4086867570877075\n",
      "      kl: 0.03335663676261902\n",
      "      policy_loss: 0.012739698402583599\n",
      "      total_loss: 1366.8990478515625\n",
      "      vf_explained_var: 0.5286872386932373\n",
      "      vf_loss: 1366.8863525390625\n",
      "    sample_time_ms: 31375.496\n",
      "    update_time_ms: 9.151\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.023241764252845\n",
      "  time_since_restore: 19663.41515636444\n",
      "  time_this_iter_s: 36.902167320251465\n",
      "  time_total_s: 19663.41515636444\n",
      "  timestamp: 1554827984\n",
      "  timesteps_since_restore: 6730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6730000\n",
      "  training_iteration: 673\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19663 s, 673 iter, 6730000 ts, -94 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 94.64150943396227\n",
      "  episode_reward_max: 14.171188922477137\n",
      "  episode_reward_mean: -67.05009807027253\n",
      "  episode_reward_min: -201.12628588550047\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 74625\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6973.533\n",
      "    load_time_ms: 2.184\n",
      "    num_steps_sampled: 6740000\n",
      "    num_steps_trained: 6740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.114881336098891e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.396773338317871\n",
      "      kl: 0.033021312206983566\n",
      "      policy_loss: 0.01084642019122839\n",
      "      total_loss: 1497.6646728515625\n",
      "      vf_explained_var: 0.40320414304733276\n",
      "      vf_loss: 1497.65380859375\n",
      "    sample_time_ms: 31342.092\n",
      "    update_time_ms: 9.135\n",
      "  iterations_since_restore: 674\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -33.525049035136256\n",
      "  time_since_restore: 19693.845494270325\n",
      "  time_this_iter_s: 30.43033790588379\n",
      "  time_total_s: 19693.845494270325\n",
      "  timestamp: 1554828014\n",
      "  timesteps_since_restore: 6740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6740000\n",
      "  training_iteration: 674\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19693 s, 674 iter, 6740000 ts, -67.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-40-54\n",
      "  done: false\n",
      "  episode_len_mean: 92.74074074074075\n",
      "  episode_reward_max: 13.398677870378544\n",
      "  episode_reward_mean: -76.59814889498327\n",
      "  episode_reward_min: -200.570445800066\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 74733\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7066.119\n",
      "    load_time_ms: 2.073\n",
      "    num_steps_sampled: 6750000\n",
      "    num_steps_trained: 6750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.114881336098891e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4169045686721802\n",
      "      kl: 0.04099510982632637\n",
      "      policy_loss: 0.016059163957834244\n",
      "      total_loss: 1446.7864990234375\n",
      "      vf_explained_var: 0.46962714195251465\n",
      "      vf_loss: 1446.770263671875\n",
      "    sample_time_ms: 31998.53\n",
      "    update_time_ms: 9.2\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.299074447491634\n",
      "  time_since_restore: 19733.859148025513\n",
      "  time_this_iter_s: 40.01365375518799\n",
      "  time_total_s: 19733.859148025513\n",
      "  timestamp: 1554828054\n",
      "  timesteps_since_restore: 6750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6750000\n",
      "  training_iteration: 675\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19733 s, 675 iter, 6750000 ts, -76.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-41-45\n",
      "  done: false\n",
      "  episode_len_mean: 86.05128205128206\n",
      "  episode_reward_max: 11.969804082626261\n",
      "  episode_reward_mean: -90.64588824532224\n",
      "  episode_reward_min: -201.6677808551666\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 74850\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6914.864\n",
      "    load_time_ms: 1.951\n",
      "    num_steps_sampled: 6760000\n",
      "    num_steps_trained: 6760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.672321163369258e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4218921661376953\n",
      "      kl: 0.0414077453315258\n",
      "      policy_loss: 0.013737752102315426\n",
      "      total_loss: 1403.5809326171875\n",
      "      vf_explained_var: 0.4897095263004303\n",
      "      vf_loss: 1403.5672607421875\n",
      "    sample_time_ms: 32239.536\n",
      "    update_time_ms: 8.604\n",
      "  iterations_since_restore: 676\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.32294412266113\n",
      "  time_since_restore: 19785.045986175537\n",
      "  time_this_iter_s: 51.186838150024414\n",
      "  time_total_s: 19785.045986175537\n",
      "  timestamp: 1554828105\n",
      "  timesteps_since_restore: 6760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6760000\n",
      "  training_iteration: 676\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19785 s, 676 iter, 6760000 ts, -90.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-42-23\n",
      "  done: false\n",
      "  episode_len_mean: 90.49090909090908\n",
      "  episode_reward_max: 13.63392630082199\n",
      "  episode_reward_mean: -79.71598765611525\n",
      "  episode_reward_min: -200.92085062346808\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 74960\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6565.249\n",
      "    load_time_ms: 1.957\n",
      "    num_steps_sampled: 6770000\n",
      "    num_steps_trained: 6770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.008482725962812e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.421844244003296\n",
      "      kl: 0.04419160261750221\n",
      "      policy_loss: 0.016830291599035263\n",
      "      total_loss: 1469.7508544921875\n",
      "      vf_explained_var: 0.4457467794418335\n",
      "      vf_loss: 1469.7340087890625\n",
      "    sample_time_ms: 31819.132\n",
      "    update_time_ms: 8.03\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.85799382805763\n",
      "  time_since_restore: 19822.96995139122\n",
      "  time_this_iter_s: 37.92396521568298\n",
      "  time_total_s: 19822.96995139122\n",
      "  timestamp: 1554828143\n",
      "  timesteps_since_restore: 6770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6770000\n",
      "  training_iteration: 677\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19822 s, 677 iter, 6770000 ts, -79.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-43-01\n",
      "  done: false\n",
      "  episode_len_mean: 87.74561403508773\n",
      "  episode_reward_max: 11.790025861910852\n",
      "  episode_reward_mean: -86.66975578496921\n",
      "  episode_reward_min: -201.04302858250045\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 75074\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6464.184\n",
      "    load_time_ms: 1.822\n",
      "    num_steps_sampled: 6780000\n",
      "    num_steps_trained: 6780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0512723808684526e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4240524768829346\n",
      "      kl: 0.047926198691129684\n",
      "      policy_loss: 0.01588595286011696\n",
      "      total_loss: 1383.8536376953125\n",
      "      vf_explained_var: 0.5072106719017029\n",
      "      vf_loss: 1383.8377685546875\n",
      "    sample_time_ms: 31660.318\n",
      "    update_time_ms: 7.358\n",
      "  iterations_since_restore: 678\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.33487789248463\n",
      "  time_since_restore: 19860.689126491547\n",
      "  time_this_iter_s: 37.71917510032654\n",
      "  time_total_s: 19860.689126491547\n",
      "  timestamp: 1554828181\n",
      "  timesteps_since_restore: 6780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6780000\n",
      "  training_iteration: 678\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19860 s, 678 iter, 6780000 ts, -86.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-43-35\n",
      "  done: false\n",
      "  episode_len_mean: 85.03361344537815\n",
      "  episode_reward_max: 14.741669453884809\n",
      "  episode_reward_mean: -93.4766548206381\n",
      "  episode_reward_min: -200.97216706056452\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 75193\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6368.983\n",
      "    load_time_ms: 1.701\n",
      "    num_steps_sampled: 6790000\n",
      "    num_steps_trained: 6790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5769084031468631e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4231185913085938\n",
      "      kl: 0.04721282050013542\n",
      "      policy_loss: 0.018715640529990196\n",
      "      total_loss: 1384.6219482421875\n",
      "      vf_explained_var: 0.49352216720581055\n",
      "      vf_loss: 1384.60302734375\n",
      "    sample_time_ms: 31306.626\n",
      "    update_time_ms: 7.615\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.73832741031905\n",
      "  time_since_restore: 19894.707342624664\n",
      "  time_this_iter_s: 34.018216133117676\n",
      "  time_total_s: 19894.707342624664\n",
      "  timestamp: 1554828215\n",
      "  timesteps_since_restore: 6790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6790000\n",
      "  training_iteration: 679\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19894 s, 679 iter, 6790000 ts, -93.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-44-15\n",
      "  done: false\n",
      "  episode_len_mean: 80.54098360655738\n",
      "  episode_reward_max: 13.791216707266717\n",
      "  episode_reward_mean: -107.28942246407401\n",
      "  episode_reward_min: -200.81296224759558\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 75315\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6497.119\n",
      "    load_time_ms: 1.762\n",
      "    num_steps_sampled: 6800000\n",
      "    num_steps_trained: 6800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.365363109187742e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4376342296600342\n",
      "      kl: 0.045112039893865585\n",
      "      policy_loss: 0.015335732139647007\n",
      "      total_loss: 1354.1546630859375\n",
      "      vf_explained_var: 0.5222734212875366\n",
      "      vf_loss: 1354.139404296875\n",
      "    sample_time_ms: 31461.318\n",
      "    update_time_ms: 7.364\n",
      "  iterations_since_restore: 680\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -53.64471123203701\n",
      "  time_since_restore: 19933.894470214844\n",
      "  time_this_iter_s: 39.18712759017944\n",
      "  time_total_s: 19933.894470214844\n",
      "  timestamp: 1554828255\n",
      "  timesteps_since_restore: 6800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6800000\n",
      "  training_iteration: 680\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19933 s, 680 iter, 6800000 ts, -107 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-44-51\n",
      "  done: false\n",
      "  episode_len_mean: 85.83898305084746\n",
      "  episode_reward_max: 13.413690068032299\n",
      "  episode_reward_mean: -93.37384687995666\n",
      "  episode_reward_min: -200.41235858043237\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 75433\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6588.493\n",
      "    load_time_ms: 1.866\n",
      "    num_steps_sampled: 6810000\n",
      "    num_steps_trained: 6810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.548044215366104e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.422990083694458\n",
      "      kl: 0.038601867854595184\n",
      "      policy_loss: 0.012787368148565292\n",
      "      total_loss: 1350.990478515625\n",
      "      vf_explained_var: 0.5246415734291077\n",
      "      vf_loss: 1350.977783203125\n",
      "    sample_time_ms: 31458.577\n",
      "    update_time_ms: 7.342\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.68692343997832\n",
      "  time_since_restore: 19970.19163751602\n",
      "  time_this_iter_s: 36.29716730117798\n",
      "  time_total_s: 19970.19163751602\n",
      "  timestamp: 1554828291\n",
      "  timesteps_since_restore: 6810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6810000\n",
      "  training_iteration: 681\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 19970 s, 681 iter, 6810000 ts, -93.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-45-24\n",
      "  done: false\n",
      "  episode_len_mean: 86.70434782608696\n",
      "  episode_reward_max: 15.54546022666433\n",
      "  episode_reward_mean: -88.60355136576385\n",
      "  episode_reward_min: -200.64596813016925\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 75548\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6662.298\n",
      "    load_time_ms: 1.918\n",
      "    num_steps_sampled: 6820000\n",
      "    num_steps_trained: 6820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.548044215366104e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.419136643409729\n",
      "      kl: 0.05607697367668152\n",
      "      policy_loss: 0.021607428789138794\n",
      "      total_loss: 1447.0855712890625\n",
      "      vf_explained_var: 0.4856223165988922\n",
      "      vf_loss: 1447.0638427734375\n",
      "    sample_time_ms: 31000.774\n",
      "    update_time_ms: 6.839\n",
      "  iterations_since_restore: 682\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.30177568288192\n",
      "  time_since_restore: 20003.5030503273\n",
      "  time_this_iter_s: 33.3114128112793\n",
      "  time_total_s: 20003.5030503273\n",
      "  timestamp: 1554828324\n",
      "  timesteps_since_restore: 6820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6820000\n",
      "  training_iteration: 682\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20003 s, 682 iter, 6820000 ts, -88.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-46-04\n",
      "  done: false\n",
      "  episode_len_mean: 86.89565217391305\n",
      "  episode_reward_max: 12.227859825449055\n",
      "  episode_reward_mean: -90.99737605176071\n",
      "  episode_reward_min: -200.82920112147087\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 75663\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6863.376\n",
      "    load_time_ms: 1.846\n",
      "    num_steps_sampled: 6830000\n",
      "    num_steps_trained: 6830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.322066995672419e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4160300493240356\n",
      "      kl: 0.03442857041954994\n",
      "      policy_loss: 0.013186451978981495\n",
      "      total_loss: 1410.7159423828125\n",
      "      vf_explained_var: 0.48760557174682617\n",
      "      vf_loss: 1410.702880859375\n",
      "    sample_time_ms: 31025.669\n",
      "    update_time_ms: 7.165\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.498688025880355\n",
      "  time_since_restore: 20042.689249753952\n",
      "  time_this_iter_s: 39.186199426651\n",
      "  time_total_s: 20042.689249753952\n",
      "  timestamp: 1554828364\n",
      "  timesteps_since_restore: 6830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6830000\n",
      "  training_iteration: 683\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20042 s, 683 iter, 6830000 ts, -91 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-46-40\n",
      "  done: false\n",
      "  episode_len_mean: 82.86666666666666\n",
      "  episode_reward_max: 14.044327012269115\n",
      "  episode_reward_mean: -100.87955100960835\n",
      "  episode_reward_min: -200.8595386658817\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 75783\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6870.02\n",
      "    load_time_ms: 1.81\n",
      "    num_steps_sampled: 6840000\n",
      "    num_steps_trained: 6840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.322066995672419e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4220125675201416\n",
      "      kl: 0.055245380848646164\n",
      "      policy_loss: 0.017832159996032715\n",
      "      total_loss: 1342.977294921875\n",
      "      vf_explained_var: 0.5471385717391968\n",
      "      vf_loss: 1342.9595947265625\n",
      "    sample_time_ms: 31617.458\n",
      "    update_time_ms: 7.636\n",
      "  iterations_since_restore: 684\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.439775504804174\n",
      "  time_since_restore: 20079.108575820923\n",
      "  time_this_iter_s: 36.419326066970825\n",
      "  time_total_s: 20079.108575820923\n",
      "  timestamp: 1554828400\n",
      "  timesteps_since_restore: 6840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6840000\n",
      "  training_iteration: 684\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20079 s, 684 iter, 6840000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-47-19\n",
      "  done: false\n",
      "  episode_len_mean: 85.22222222222223\n",
      "  episode_reward_max: 14.743685271567086\n",
      "  episode_reward_mean: -94.19402255625056\n",
      "  episode_reward_min: -202.7249555686322\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 75900\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6973.838\n",
      "    load_time_ms: 1.844\n",
      "    num_steps_sampled: 6850000\n",
      "    num_steps_trained: 6850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.983100941924137e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4142742156982422\n",
      "      kl: 0.038762494921684265\n",
      "      policy_loss: 0.013821410946547985\n",
      "      total_loss: 1470.296142578125\n",
      "      vf_explained_var: 0.4894951581954956\n",
      "      vf_loss: 1470.2822265625\n",
      "    sample_time_ms: 31418.872\n",
      "    update_time_ms: 8.376\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.097011278125294\n",
      "  time_since_restore: 20118.1878554821\n",
      "  time_this_iter_s: 39.07927966117859\n",
      "  time_total_s: 20118.1878554821\n",
      "  timestamp: 1554828439\n",
      "  timesteps_since_restore: 6850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6850000\n",
      "  training_iteration: 685\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20118 s, 685 iter, 6850000 ts, -94.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-47-55\n",
      "  done: false\n",
      "  episode_len_mean: 86.7304347826087\n",
      "  episode_reward_max: 14.934084312238875\n",
      "  episode_reward_mean: -89.83837813090508\n",
      "  episode_reward_min: -201.48089921211516\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 76015\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6738.808\n",
      "    load_time_ms: 1.878\n",
      "    num_steps_sampled: 6860000\n",
      "    num_steps_trained: 6860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.983100941924137e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.430098533630371\n",
      "      kl: 0.04285435006022453\n",
      "      policy_loss: 0.016908736899495125\n",
      "      total_loss: 1431.9415283203125\n",
      "      vf_explained_var: 0.5047582983970642\n",
      "      vf_loss: 1431.9246826171875\n",
      "    sample_time_ms: 30083.613\n",
      "    update_time_ms: 9.251\n",
      "  iterations_since_restore: 686\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.919189065452535\n",
      "  time_since_restore: 20153.681842565536\n",
      "  time_this_iter_s: 35.49398708343506\n",
      "  time_total_s: 20153.681842565536\n",
      "  timestamp: 1554828475\n",
      "  timesteps_since_restore: 6860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6860000\n",
      "  training_iteration: 686\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20153 s, 686 iter, 6860000 ts, -89.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-48-33\n",
      "  done: false\n",
      "  episode_len_mean: 84.53781512605042\n",
      "  episode_reward_max: 13.568754156536706\n",
      "  episode_reward_mean: -95.4256655911971\n",
      "  episode_reward_min: -201.70267062351382\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 76134\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6809.745\n",
      "    load_time_ms: 1.899\n",
      "    num_steps_sampled: 6870000\n",
      "    num_steps_trained: 6870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1974650964470697e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.427234411239624\n",
      "      kl: 0.04946719855070114\n",
      "      policy_loss: 0.02272629924118519\n",
      "      total_loss: 1437.6903076171875\n",
      "      vf_explained_var: 0.495200514793396\n",
      "      vf_loss: 1437.667724609375\n",
      "    sample_time_ms: 30017.953\n",
      "    update_time_ms: 10.532\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.712832795598544\n",
      "  time_since_restore: 20191.671845912933\n",
      "  time_this_iter_s: 37.99000334739685\n",
      "  time_total_s: 20191.671845912933\n",
      "  timestamp: 1554828513\n",
      "  timesteps_since_restore: 6870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6870000\n",
      "  training_iteration: 687\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20191 s, 687 iter, 6870000 ts, -95.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-49-13\n",
      "  done: false\n",
      "  episode_len_mean: 91.24770642201835\n",
      "  episode_reward_max: 16.571341548719353\n",
      "  episode_reward_mean: -76.6246854401251\n",
      "  episode_reward_min: -200.69212010968832\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 76243\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6866.552\n",
      "    load_time_ms: 1.944\n",
      "    num_steps_sampled: 6880000\n",
      "    num_steps_trained: 6880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.796197554987503e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4088870286941528\n",
      "      kl: 0.055106133222579956\n",
      "      policy_loss: 0.02051789127290249\n",
      "      total_loss: 1445.3612060546875\n",
      "      vf_explained_var: 0.45362913608551025\n",
      "      vf_loss: 1445.3406982421875\n",
      "    sample_time_ms: 30176.71\n",
      "    update_time_ms: 10.65\n",
      "  iterations_since_restore: 688\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.31234272006255\n",
      "  time_since_restore: 20231.5508518219\n",
      "  time_this_iter_s: 39.879005908966064\n",
      "  time_total_s: 20231.5508518219\n",
      "  timestamp: 1554828553\n",
      "  timesteps_since_restore: 6880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6880000\n",
      "  training_iteration: 688\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20231 s, 688 iter, 6880000 ts, -76.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-50-00\n",
      "  done: false\n",
      "  episode_len_mean: 84.675\n",
      "  episode_reward_max: 14.598191037955328\n",
      "  episode_reward_mean: -96.96798645428424\n",
      "  episode_reward_min: -200.7436497310043\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 76363\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7245.897\n",
      "    load_time_ms: 1.955\n",
      "    num_steps_sampled: 6890000\n",
      "    num_steps_trained: 6890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.6942956150164406e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4309478998184204\n",
      "      kl: 0.04664584994316101\n",
      "      policy_loss: 0.016474081203341484\n",
      "      total_loss: 1386.964599609375\n",
      "      vf_explained_var: 0.5095238089561462\n",
      "      vf_loss: 1386.9481201171875\n",
      "    sample_time_ms: 31079.143\n",
      "    update_time_ms: 10.206\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.48399322714213\n",
      "  time_since_restore: 20278.39326786995\n",
      "  time_this_iter_s: 46.84241604804993\n",
      "  time_total_s: 20278.39326786995\n",
      "  timestamp: 1554828600\n",
      "  timesteps_since_restore: 6890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6890000\n",
      "  training_iteration: 689\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20278 s, 689 iter, 6890000 ts, -97 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-50-41\n",
      "  done: false\n",
      "  episode_len_mean: 91.79629629629629\n",
      "  episode_reward_max: 13.734702251504117\n",
      "  episode_reward_mean: -77.42008360968741\n",
      "  episode_reward_min: -202.31144239619297\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 76471\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7166.484\n",
      "    load_time_ms: 1.868\n",
      "    num_steps_sampled: 6900000\n",
      "    num_steps_trained: 6900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.0414448574542884e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4228219985961914\n",
      "      kl: 0.055586472153663635\n",
      "      policy_loss: 0.022524913772940636\n",
      "      total_loss: 1446.2042236328125\n",
      "      vf_explained_var: 0.46653154492378235\n",
      "      vf_loss: 1446.181640625\n",
      "    sample_time_ms: 31387.914\n",
      "    update_time_ms: 11.093\n",
      "  iterations_since_restore: 690\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.710041804843705\n",
      "  time_since_restore: 20319.860597133636\n",
      "  time_this_iter_s: 41.467329263687134\n",
      "  time_total_s: 20319.860597133636\n",
      "  timestamp: 1554828641\n",
      "  timesteps_since_restore: 6900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6900000\n",
      "  training_iteration: 690\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20319 s, 690 iter, 6900000 ts, -77.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-51-19\n",
      "  done: false\n",
      "  episode_len_mean: 84.98290598290598\n",
      "  episode_reward_max: 17.19878537683114\n",
      "  episode_reward_mean: -93.39369005594358\n",
      "  episode_reward_min: -200.456069113514\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 76588\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7149.708\n",
      "    load_time_ms: 1.782\n",
      "    num_steps_sampled: 6910000\n",
      "    num_steps_trained: 6910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.062165851251805e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4219154119491577\n",
      "      kl: 0.07300644367933273\n",
      "      policy_loss: 0.029559575021266937\n",
      "      total_loss: 1333.9541015625\n",
      "      vf_explained_var: 0.5466503500938416\n",
      "      vf_loss: 1333.924560546875\n",
      "    sample_time_ms: 31579.088\n",
      "    update_time_ms: 10.988\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.69684502797179\n",
      "  time_since_restore: 20357.900881528854\n",
      "  time_this_iter_s: 38.040284395217896\n",
      "  time_total_s: 20357.900881528854\n",
      "  timestamp: 1554828679\n",
      "  timesteps_since_restore: 6910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6910000\n",
      "  training_iteration: 691\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20357 s, 691 iter, 6910000 ts, -93.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-51-52\n",
      "  done: false\n",
      "  episode_len_mean: 90.86486486486487\n",
      "  episode_reward_max: 16.889226602969135\n",
      "  episode_reward_mean: -80.55048455884108\n",
      "  episode_reward_min: -201.78005695404926\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 76699\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 7008.255\n",
      "    load_time_ms: 1.873\n",
      "    num_steps_sampled: 6920000\n",
      "    num_steps_trained: 6920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.093249494342521e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.417328953742981\n",
      "      kl: 0.036310311406850815\n",
      "      policy_loss: 0.014743702486157417\n",
      "      total_loss: 1438.759765625\n",
      "      vf_explained_var: 0.4622921943664551\n",
      "      vf_loss: 1438.7449951171875\n",
      "    sample_time_ms: 31661.809\n",
      "    update_time_ms: 10.973\n",
      "  iterations_since_restore: 692\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -40.27524227942054\n",
      "  time_since_restore: 20390.610780477524\n",
      "  time_this_iter_s: 32.709898948669434\n",
      "  time_total_s: 20390.610780477524\n",
      "  timestamp: 1554828712\n",
      "  timesteps_since_restore: 6920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6920000\n",
      "  training_iteration: 692\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20390 s, 692 iter, 6920000 ts, -80.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-52-28\n",
      "  done: false\n",
      "  episode_len_mean: 81.62809917355372\n",
      "  episode_reward_max: 16.401721835259323\n",
      "  episode_reward_mean: -103.11223876801431\n",
      "  episode_reward_min: -200.73055376347475\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 76820\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6651.614\n",
      "    load_time_ms: 1.937\n",
      "    num_steps_sampled: 6930000\n",
      "    num_steps_trained: 6930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.093249494342521e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4350143671035767\n",
      "      kl: 0.04232991859316826\n",
      "      policy_loss: 0.014906707219779491\n",
      "      total_loss: 1332.214599609375\n",
      "      vf_explained_var: 0.5206185579299927\n",
      "      vf_loss: 1332.1998291015625\n",
      "    sample_time_ms: 31659.101\n",
      "    update_time_ms: 10.567\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -51.556119384007154\n",
      "  time_since_restore: 20426.178478479385\n",
      "  time_this_iter_s: 35.56769800186157\n",
      "  time_total_s: 20426.178478479385\n",
      "  timestamp: 1554828748\n",
      "  timesteps_since_restore: 6930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6930000\n",
      "  training_iteration: 693\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20426 s, 693 iter, 6930000 ts, -103 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-53-03\n",
      "  done: false\n",
      "  episode_len_mean: 91.68468468468468\n",
      "  episode_reward_max: 14.664200612591092\n",
      "  episode_reward_mean: -77.70674096174987\n",
      "  episode_reward_min: -200.67434800457954\n",
      "  episodes_this_iter: 111\n",
      "  episodes_total: 76931\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6724.524\n",
      "    load_time_ms: 1.951\n",
      "    num_steps_sampled: 6940000\n",
      "    num_steps_trained: 6940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3639874241513782e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4222819805145264\n",
      "      kl: 0.04121679067611694\n",
      "      policy_loss: 0.018151313066482544\n",
      "      total_loss: 1407.61376953125\n",
      "      vf_explained_var: 0.48465874791145325\n",
      "      vf_loss: 1407.595703125\n",
      "    sample_time_ms: 31472.486\n",
      "    update_time_ms: 10.577\n",
      "  iterations_since_restore: 694\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.85337048087493\n",
      "  time_since_restore: 20461.45966219902\n",
      "  time_this_iter_s: 35.28118371963501\n",
      "  time_total_s: 20461.45966219902\n",
      "  timestamp: 1554828783\n",
      "  timesteps_since_restore: 6940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6940000\n",
      "  training_iteration: 694\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20461 s, 694 iter, 6940000 ts, -77.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-53-39\n",
      "  done: false\n",
      "  episode_len_mean: 87.43859649122807\n",
      "  episode_reward_max: 17.26794904285917\n",
      "  episode_reward_mean: -88.45136558586363\n",
      "  episode_reward_min: -200.46898245407897\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 77045\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6503.794\n",
      "    load_time_ms: 1.946\n",
      "    num_steps_sampled: 6950000\n",
      "    num_steps_trained: 6950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0459813514665114e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4267297983169556\n",
      "      kl: 0.04791831225156784\n",
      "      policy_loss: 0.016983604058623314\n",
      "      total_loss: 1370.4937744140625\n",
      "      vf_explained_var: 0.5144050717353821\n",
      "      vf_loss: 1370.476806640625\n",
      "    sample_time_ms: 31424.713\n",
      "    update_time_ms: 9.893\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.2256827929318\n",
      "  time_since_restore: 20497.841145515442\n",
      "  time_this_iter_s: 36.38148331642151\n",
      "  time_total_s: 20497.841145515442\n",
      "  timestamp: 1554828819\n",
      "  timesteps_since_restore: 6950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6950000\n",
      "  training_iteration: 695\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20497 s, 695 iter, 6950000 ts, -88.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-54-12\n",
      "  done: false\n",
      "  episode_len_mean: 84.45378151260505\n",
      "  episode_reward_max: 14.20911888880906\n",
      "  episode_reward_mean: -95.42778319288296\n",
      "  episode_reward_min: -201.271367989885\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 77164\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6501.486\n",
      "    load_time_ms: 1.931\n",
      "    num_steps_sampled: 6960000\n",
      "    num_steps_trained: 6960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.068972385932174e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4440133571624756\n",
      "      kl: 0.053254853934049606\n",
      "      policy_loss: 0.018174702301621437\n",
      "      total_loss: 1388.147705078125\n",
      "      vf_explained_var: 0.5151992440223694\n",
      "      vf_loss: 1388.1295166015625\n",
      "    sample_time_ms: 31161.331\n",
      "    update_time_ms: 9.245\n",
      "  iterations_since_restore: 696\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.71389159644148\n",
      "  time_since_restore: 20530.666407108307\n",
      "  time_this_iter_s: 32.82526159286499\n",
      "  time_total_s: 20530.666407108307\n",
      "  timestamp: 1554828852\n",
      "  timesteps_since_restore: 6960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6960000\n",
      "  training_iteration: 696\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20530 s, 696 iter, 6960000 ts, -95.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-54-44\n",
      "  done: false\n",
      "  episode_len_mean: 89.66363636363636\n",
      "  episode_reward_max: 10.172724535118924\n",
      "  episode_reward_mean: -83.91937178792784\n",
      "  episode_reward_min: -201.9898192224067\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 77274\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6417.046\n",
      "    load_time_ms: 1.851\n",
      "    num_steps_sampled: 6970000\n",
      "    num_steps_trained: 6970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.6034577179404845e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4331635236740112\n",
      "      kl: 0.0645085871219635\n",
      "      policy_loss: 0.025374190881848335\n",
      "      total_loss: 1405.756591796875\n",
      "      vf_explained_var: 0.46699005365371704\n",
      "      vf_loss: 1405.7313232421875\n",
      "    sample_time_ms: 30576.715\n",
      "    update_time_ms: 7.868\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.959685893963915\n",
      "  time_since_restore: 20561.941326856613\n",
      "  time_this_iter_s: 31.274919748306274\n",
      "  time_total_s: 20561.941326856613\n",
      "  timestamp: 1554828884\n",
      "  timesteps_since_restore: 6970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6970000\n",
      "  training_iteration: 697\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20561 s, 697 iter, 6970000 ts, -83.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-55-17\n",
      "  done: false\n",
      "  episode_len_mean: 83.88235294117646\n",
      "  episode_reward_max: 11.517540144243197\n",
      "  episode_reward_mean: -98.38151842060888\n",
      "  episode_reward_min: -201.02173860801116\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 77393\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6233.72\n",
      "    load_time_ms: 1.769\n",
      "    num_steps_sampled: 6980000\n",
      "    num_steps_trained: 6980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.905186146431839e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4379996061325073\n",
      "      kl: 0.04611653462052345\n",
      "      policy_loss: 0.01548145804554224\n",
      "      total_loss: 1336.360107421875\n",
      "      vf_explained_var: 0.5230316519737244\n",
      "      vf_loss: 1336.3446044921875\n",
      "    sample_time_ms: 30094.527\n",
      "    update_time_ms: 7.803\n",
      "  iterations_since_restore: 698\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.190759210304435\n",
      "  time_since_restore: 20595.161186933517\n",
      "  time_this_iter_s: 33.2198600769043\n",
      "  time_total_s: 20595.161186933517\n",
      "  timestamp: 1554828917\n",
      "  timesteps_since_restore: 6980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6980000\n",
      "  training_iteration: 698\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20595 s, 698 iter, 6980000 ts, -98.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-55-47\n",
      "  done: false\n",
      "  episode_len_mean: 83.94166666666666\n",
      "  episode_reward_max: 11.966805737352818\n",
      "  episode_reward_mean: -97.00392409937055\n",
      "  episode_reward_min: -201.499038907765\n",
      "  episodes_this_iter: 120\n",
      "  episodes_total: 77513\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5841.329\n",
      "    load_time_ms: 1.742\n",
      "    num_steps_sampled: 6990000\n",
      "    num_steps_trained: 6990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0357780080605534e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4507945775985718\n",
      "      kl: 0.041684798896312714\n",
      "      policy_loss: 0.014024920761585236\n",
      "      total_loss: 1412.1224365234375\n",
      "      vf_explained_var: 0.527114748954773\n",
      "      vf_loss: 1412.1085205078125\n",
      "    sample_time_ms: 28821.082\n",
      "    update_time_ms: 8.166\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.501962049685275\n",
      "  time_since_restore: 20625.33646631241\n",
      "  time_this_iter_s: 30.17527937889099\n",
      "  time_total_s: 20625.33646631241\n",
      "  timestamp: 1554828947\n",
      "  timesteps_since_restore: 6990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6990000\n",
      "  training_iteration: 699\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20625 s, 699 iter, 6990000 ts, -97 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-56-17\n",
      "  done: false\n",
      "  episode_len_mean: 88.95535714285714\n",
      "  episode_reward_max: 16.632710752766293\n",
      "  episode_reward_mean: -83.2514669528725\n",
      "  episode_reward_min: -202.07196168899117\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 77625\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5714.952\n",
      "    load_time_ms: 1.729\n",
      "    num_steps_sampled: 7000000\n",
      "    num_steps_trained: 7000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5536671842823854e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4386670589447021\n",
      "      kl: 0.04479837417602539\n",
      "      policy_loss: 0.015336498618125916\n",
      "      total_loss: 1419.7252197265625\n",
      "      vf_explained_var: 0.4777580797672272\n",
      "      vf_loss: 1419.7099609375\n",
      "    sample_time_ms: 27760.268\n",
      "    update_time_ms: 7.378\n",
      "  iterations_since_restore: 700\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -41.625733476436245\n",
      "  time_since_restore: 20654.9289393425\n",
      "  time_this_iter_s: 29.592473030090332\n",
      "  time_total_s: 20654.9289393425\n",
      "  timestamp: 1554828977\n",
      "  timesteps_since_restore: 7000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7000000\n",
      "  training_iteration: 700\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20654 s, 700 iter, 7000000 ts, -83.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-56-46\n",
      "  done: false\n",
      "  episode_len_mean: 88.6283185840708\n",
      "  episode_reward_max: 14.371665566622056\n",
      "  episode_reward_mean: -84.70727253709595\n",
      "  episode_reward_min: -200.9310365455079\n",
      "  episodes_this_iter: 113\n",
      "  episodes_total: 77738\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5591.917\n",
      "    load_time_ms: 1.744\n",
      "    num_steps_sampled: 7010000\n",
      "    num_steps_trained: 7010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3305004320404676e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.44096839427948\n",
      "      kl: 0.04440871626138687\n",
      "      policy_loss: 0.019342629238963127\n",
      "      total_loss: 1428.0555419921875\n",
      "      vf_explained_var: 0.4785136580467224\n",
      "      vf_loss: 1428.0362548828125\n",
      "    sample_time_ms: 26984.37\n",
      "    update_time_ms: 7.666\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -42.35363626854798\n",
      "  time_since_restore: 20683.98426580429\n",
      "  time_this_iter_s: 29.055326461791992\n",
      "  time_total_s: 20683.98426580429\n",
      "  timestamp: 1554829006\n",
      "  timesteps_since_restore: 7010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7010000\n",
      "  training_iteration: 701\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20683 s, 701 iter, 7010000 ts, -84.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 82.80165289256199\n",
      "  episode_reward_max: 15.23503762098337\n",
      "  episode_reward_mean: -99.16454097794552\n",
      "  episode_reward_min: -200.497007959364\n",
      "  episodes_this_iter: 121\n",
      "  episodes_total: 77859\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5560.519\n",
      "    load_time_ms: 1.645\n",
      "    num_steps_sampled: 7020000\n",
      "    num_steps_trained: 7020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4957507628550716e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4185397624969482\n",
      "      kl: 19.485361099243164\n",
      "      policy_loss: 0.20655930042266846\n",
      "      total_loss: 1367.0753173828125\n",
      "      vf_explained_var: 0.5363192558288574\n",
      "      vf_loss: 1366.8687744140625\n",
      "    sample_time_ms: 26677.572\n",
      "    update_time_ms: 7.68\n",
      "  iterations_since_restore: 702\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.58227048897277\n",
      "  time_since_restore: 20713.312721014023\n",
      "  time_this_iter_s: 29.328455209732056\n",
      "  time_total_s: 20713.312721014023\n",
      "  timestamp: 1554829035\n",
      "  timesteps_since_restore: 7020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7020000\n",
      "  training_iteration: 702\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20713 s, 702 iter, 7020000 ts, -99.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-57-45\n",
      "  done: false\n",
      "  episode_len_mean: 86.63478260869566\n",
      "  episode_reward_max: 13.746433122438248\n",
      "  episode_reward_mean: -91.026595026476\n",
      "  episode_reward_min: -200.81888963077128\n",
      "  episodes_this_iter: 115\n",
      "  episodes_total: 77974\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5528.987\n",
      "    load_time_ms: 1.588\n",
      "    num_steps_sampled: 7030000\n",
      "    num_steps_trained: 7030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.243626373871348e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4173173904418945\n",
      "      kl: 0.03312581777572632\n",
      "      policy_loss: 0.01234913058578968\n",
      "      total_loss: 1368.1162109375\n",
      "      vf_explained_var: 0.5353723168373108\n",
      "      vf_loss: 1368.103759765625\n",
      "    sample_time_ms: 26113.759\n",
      "    update_time_ms: 7.674\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.51329751323801\n",
      "  time_since_restore: 20742.922088623047\n",
      "  time_this_iter_s: 29.609367609024048\n",
      "  time_total_s: 20742.922088623047\n",
      "  timestamp: 1554829065\n",
      "  timesteps_since_restore: 7030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7030000\n",
      "  training_iteration: 703\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20742 s, 703 iter, 7030000 ts, -91 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-58-14\n",
      "  done: false\n",
      "  episode_len_mean: 82.0\n",
      "  episode_reward_max: 15.813648802308862\n",
      "  episode_reward_mean: -100.81820880596023\n",
      "  episode_reward_min: -200.76039289891713\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 78096\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5436.739\n",
      "    load_time_ms: 1.568\n",
      "    num_steps_sampled: 7040000\n",
      "    num_steps_trained: 7040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.243626373871348e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4215832948684692\n",
      "      kl: 0.04540468752384186\n",
      "      policy_loss: 0.017488084733486176\n",
      "      total_loss: 1283.5828857421875\n",
      "      vf_explained_var: 0.5564661026000977\n",
      "      vf_loss: 1283.5654296875\n",
      "    sample_time_ms: 25585.456\n",
      "    update_time_ms: 7.3\n",
      "  iterations_since_restore: 704\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.40910440298011\n",
      "  time_since_restore: 20771.990805864334\n",
      "  time_this_iter_s: 29.06871724128723\n",
      "  time_total_s: 20771.990805864334\n",
      "  timestamp: 1554829094\n",
      "  timesteps_since_restore: 7040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7040000\n",
      "  training_iteration: 704\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20771 s, 704 iter, 7040000 ts, -101 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-58-43\n",
      "  done: false\n",
      "  episode_len_mean: 84.83050847457628\n",
      "  episode_reward_max: 13.037045684299313\n",
      "  episode_reward_mean: -95.30107854934325\n",
      "  episode_reward_min: -200.36525618125805\n",
      "  episodes_this_iter: 118\n",
      "  episodes_total: 78214\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5383.079\n",
      "    load_time_ms: 1.551\n",
      "    num_steps_sampled: 7050000\n",
      "    num_steps_trained: 7050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.865440249573243e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4317291975021362\n",
      "      kl: 0.05905430018901825\n",
      "      policy_loss: 0.020542507991194725\n",
      "      total_loss: 1410.2703857421875\n",
      "      vf_explained_var: 0.5226831436157227\n",
      "      vf_loss: 1410.249755859375\n",
      "    sample_time_ms: 24932.313\n",
      "    update_time_ms: 7.172\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.650539274671615\n",
      "  time_since_restore: 20801.299597263336\n",
      "  time_this_iter_s: 29.308791399002075\n",
      "  time_total_s: 20801.299597263336\n",
      "  timestamp: 1554829123\n",
      "  timesteps_since_restore: 7050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7050000\n",
      "  training_iteration: 705\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20801 s, 705 iter, 7050000 ts, -95.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-59-14\n",
      "  done: false\n",
      "  episode_len_mean: 90.92727272727272\n",
      "  episode_reward_max: 13.447276999866192\n",
      "  episode_reward_mean: -78.13578725636299\n",
      "  episode_reward_min: -201.8993978402542\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 78324\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5398.919\n",
      "    load_time_ms: 1.573\n",
      "    num_steps_sampled: 7060000\n",
      "    num_steps_trained: 7060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.179815761929498e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4180988073349\n",
      "      kl: 0.04278815537691116\n",
      "      policy_loss: 0.017251592129468918\n",
      "      total_loss: 1524.359130859375\n",
      "      vf_explained_var: 0.42664483189582825\n",
      "      vf_loss: 1524.341796875\n",
      "    sample_time_ms: 24686.32\n",
      "    update_time_ms: 7.016\n",
      "  iterations_since_restore: 706\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -39.06789362818149\n",
      "  time_since_restore: 20831.824785232544\n",
      "  time_this_iter_s: 30.525187969207764\n",
      "  time_total_s: 20831.824785232544\n",
      "  timestamp: 1554829154\n",
      "  timesteps_since_restore: 7060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7060000\n",
      "  training_iteration: 706\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20831 s, 706 iter, 7060000 ts, -78.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_18-59-45\n",
      "  done: false\n",
      "  episode_len_mean: 92.75\n",
      "  episode_reward_max: 11.904726743236655\n",
      "  episode_reward_mean: -73.96814315080908\n",
      "  episode_reward_min: -200.93582512515576\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 78432\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5536.041\n",
      "    load_time_ms: 1.527\n",
      "    num_steps_sampled: 7070000\n",
      "    num_steps_trained: 7070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7697238265652392e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4273755550384521\n",
      "      kl: 0.12071670591831207\n",
      "      policy_loss: 0.02711784467101097\n",
      "      total_loss: 1435.223388671875\n",
      "      vf_explained_var: 0.42919111251831055\n",
      "      vf_loss: 1435.1962890625\n",
      "    sample_time_ms: 24539.603\n",
      "    update_time_ms: 7.073\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -36.984071575404556\n",
      "  time_since_restore: 20863.005514144897\n",
      "  time_this_iter_s: 31.180728912353516\n",
      "  time_total_s: 20863.005514144897\n",
      "  timestamp: 1554829185\n",
      "  timesteps_since_restore: 7070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7070000\n",
      "  training_iteration: 707\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20863 s, 707 iter, 7070000 ts, -74 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-00-16\n",
      "  done: false\n",
      "  episode_len_mean: 87.25438596491227\n",
      "  episode_reward_max: 13.452181139011522\n",
      "  episode_reward_mean: -87.31507190233471\n",
      "  episode_reward_min: -201.443253417885\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 78546\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5526.608\n",
      "    load_time_ms: 1.536\n",
      "    num_steps_sampled: 7080000\n",
      "    num_steps_trained: 7080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.6545856480123627e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4431955814361572\n",
      "      kl: 0.0421593077480793\n",
      "      policy_loss: 0.01544160395860672\n",
      "      total_loss: 1407.6051025390625\n",
      "      vf_explained_var: 0.48923102021217346\n",
      "      vf_loss: 1407.589599609375\n",
      "    sample_time_ms: 24309.293\n",
      "    update_time_ms: 7.109\n",
      "  iterations_since_restore: 708\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.65753595116736\n",
      "  time_since_restore: 20893.82823395729\n",
      "  time_this_iter_s: 30.82271981239319\n",
      "  time_total_s: 20893.82823395729\n",
      "  timestamp: 1554829216\n",
      "  timesteps_since_restore: 7080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7080000\n",
      "  training_iteration: 708\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20893 s, 708 iter, 7080000 ts, -87.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-00-53\n",
      "  done: false\n",
      "  episode_len_mean: 84.21848739495799\n",
      "  episode_reward_max: 14.567627296005941\n",
      "  episode_reward_mean: -95.53286484493414\n",
      "  episode_reward_min: -201.27183454439177\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 78665\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5744.334\n",
      "    load_time_ms: 1.627\n",
      "    num_steps_sampled: 7090000\n",
      "    num_steps_trained: 7090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.981878012841063e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.459372878074646\n",
      "      kl: 0.06059017404913902\n",
      "      policy_loss: 0.021716149523854256\n",
      "      total_loss: 1457.4415283203125\n",
      "      vf_explained_var: 0.49373334646224976\n",
      "      vf_loss: 1457.419677734375\n",
      "    sample_time_ms: 24811.588\n",
      "    update_time_ms: 7.185\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -47.766432422467076\n",
      "  time_since_restore: 20931.208876132965\n",
      "  time_this_iter_s: 37.38064217567444\n",
      "  time_total_s: 20931.208876132965\n",
      "  timestamp: 1554829253\n",
      "  timesteps_since_restore: 7090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7090000\n",
      "  training_iteration: 709\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20931 s, 709 iter, 7090000 ts, -95.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-01-43\n",
      "  done: false\n",
      "  episode_len_mean: 83.5126050420168\n",
      "  episode_reward_max: 11.341910359701364\n",
      "  episode_reward_mean: -97.63181220233409\n",
      "  episode_reward_min: -200.96033646640353\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 78784\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6036.743\n",
      "    load_time_ms: 1.763\n",
      "    num_steps_sampled: 7100000\n",
      "    num_steps_trained: 7100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.9728168355906025e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4619085788726807\n",
      "      kl: 0.048209868371486664\n",
      "      policy_loss: 0.02061254158616066\n",
      "      total_loss: 1314.43310546875\n",
      "      vf_explained_var: 0.5570588111877441\n",
      "      vf_loss: 1314.4124755859375\n",
      "    sample_time_ms: 26552.593\n",
      "    update_time_ms: 8.614\n",
      "  iterations_since_restore: 710\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -48.81590610116705\n",
      "  time_since_restore: 20981.156131744385\n",
      "  time_this_iter_s: 49.94725561141968\n",
      "  time_total_s: 20981.156131744385\n",
      "  timestamp: 1554829303\n",
      "  timesteps_since_restore: 7100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7100000\n",
      "  training_iteration: 710\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 20981 s, 710 iter, 7100000 ts, -97.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-02-16\n",
      "  done: false\n",
      "  episode_len_mean: 85.95726495726495\n",
      "  episode_reward_max: 16.432270770713302\n",
      "  episode_reward_mean: -90.71398360989592\n",
      "  episode_reward_min: -200.9804535343543\n",
      "  episodes_this_iter: 117\n",
      "  episodes_total: 78901\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6028.911\n",
      "    load_time_ms: 1.742\n",
      "    num_steps_sampled: 7110000\n",
      "    num_steps_trained: 7110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.959226355411858e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4396337270736694\n",
      "      kl: 0.04547558352351189\n",
      "      policy_loss: 0.019856447353959084\n",
      "      total_loss: 1418.1978759765625\n",
      "      vf_explained_var: 0.5019403100013733\n",
      "      vf_loss: 1418.1781005859375\n",
      "    sample_time_ms: 26867.155\n",
      "    update_time_ms: 8.922\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -45.35699180494795\n",
      "  time_since_restore: 21013.282615184784\n",
      "  time_this_iter_s: 32.12648344039917\n",
      "  time_total_s: 21013.282615184784\n",
      "  timestamp: 1554829336\n",
      "  timesteps_since_restore: 7110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7110000\n",
      "  training_iteration: 711\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 21013 s, 711 iter, 7110000 ts, -90.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-02-45\n",
      "  done: false\n",
      "  episode_len_mean: 82.77049180327869\n",
      "  episode_reward_max: 15.848815720800216\n",
      "  episode_reward_mean: -100.3613704767134\n",
      "  episode_reward_min: -200.93536046825824\n",
      "  episodes_this_iter: 122\n",
      "  episodes_total: 79023\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6032.681\n",
      "    load_time_ms: 1.721\n",
      "    num_steps_sampled: 7120000\n",
      "    num_steps_trained: 7120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3438839165775802e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4554940462112427\n",
      "      kl: 0.05008263513445854\n",
      "      policy_loss: 0.017245259135961533\n",
      "      total_loss: 1418.8853759765625\n",
      "      vf_explained_var: 0.5152093172073364\n",
      "      vf_loss: 1418.8681640625\n",
      "    sample_time_ms: 26814.668\n",
      "    update_time_ms: 8.816\n",
      "  iterations_since_restore: 712\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -50.1806852383567\n",
      "  time_since_restore: 21042.124898910522\n",
      "  time_this_iter_s: 28.842283725738525\n",
      "  time_total_s: 21042.124898910522\n",
      "  timestamp: 1554829365\n",
      "  timesteps_since_restore: 7120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7120000\n",
      "  training_iteration: 712\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 21042 s, 712 iter, 7120000 ts, -100 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-03-14\n",
      "  done: false\n",
      "  episode_len_mean: 86.37931034482759\n",
      "  episode_reward_max: 15.243791889086413\n",
      "  episode_reward_mean: -92.10899873758345\n",
      "  episode_reward_min: -201.86817941427793\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 79139\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6037.76\n",
      "    load_time_ms: 1.765\n",
      "    num_steps_sampled: 7130000\n",
      "    num_steps_trained: 7130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.015826168739958e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4412784576416016\n",
      "      kl: 8.001832962036133\n",
      "      policy_loss: 0.061621468514204025\n",
      "      total_loss: 1320.7381591796875\n",
      "      vf_explained_var: 0.5301965475082397\n",
      "      vf_loss: 1320.676513671875\n",
      "    sample_time_ms: 26805.326\n",
      "    update_time_ms: 9.809\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -46.05449936879172\n",
      "  time_since_restore: 21071.707942008972\n",
      "  time_this_iter_s: 29.583043098449707\n",
      "  time_total_s: 21071.707942008972\n",
      "  timestamp: 1554829394\n",
      "  timesteps_since_restore: 7130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7130000\n",
      "  training_iteration: 713\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 21071 s, 713 iter, 7130000 ts, -92.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-03-44\n",
      "  done: false\n",
      "  episode_len_mean: 87.9375\n",
      "  episode_reward_max: 18.120278824687297\n",
      "  episode_reward_mean: -89.47321447914157\n",
      "  episode_reward_min: -201.0405767598789\n",
      "  episodes_this_iter: 112\n",
      "  episodes_total: 79251\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6053.825\n",
      "    load_time_ms: 1.76\n",
      "    num_steps_sampled: 7140000\n",
      "    num_steps_trained: 7140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.023739106173143e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.405792474746704\n",
      "      kl: 11.528087615966797\n",
      "      policy_loss: 0.17199382185935974\n",
      "      total_loss: 1437.7547607421875\n",
      "      vf_explained_var: 0.5020006895065308\n",
      "      vf_loss: 1437.5828857421875\n",
      "    sample_time_ms: 26837.189\n",
      "    update_time_ms: 9.662\n",
      "  iterations_since_restore: 714\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -44.736607239570795\n",
      "  time_since_restore: 21101.25909972191\n",
      "  time_this_iter_s: 29.5511577129364\n",
      "  time_total_s: 21101.25909972191\n",
      "  timestamp: 1554829424\n",
      "  timesteps_since_restore: 7140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7140000\n",
      "  training_iteration: 714\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 21101 s, 714 iter, 7140000 ts, -89.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-04-13\n",
      "  done: false\n",
      "  episode_len_mean: 88.26315789473684\n",
      "  episode_reward_max: 18.282941441281913\n",
      "  episode_reward_mean: -87.49999425432\n",
      "  episode_reward_min: -208.45660256918484\n",
      "  episodes_this_iter: 114\n",
      "  episodes_total: 79365\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 6034.893\n",
      "    load_time_ms: 1.75\n",
      "    num_steps_sampled: 7150000\n",
      "    num_steps_trained: 7150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.53560733682857e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.409177303314209\n",
      "      kl: 0.045503150671720505\n",
      "      policy_loss: 0.016745461151003838\n",
      "      total_loss: 1418.9986572265625\n",
      "      vf_explained_var: 0.4849661886692047\n",
      "      vf_loss: 1418.98193359375\n",
      "    sample_time_ms: 26885.197\n",
      "    update_time_ms: 9.848\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -43.74999712715999\n",
      "  time_since_restore: 21130.85683989525\n",
      "  time_this_iter_s: 29.597740173339844\n",
      "  time_total_s: 21130.85683989525\n",
      "  timestamp: 1554829453\n",
      "  timesteps_since_restore: 7150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7150000\n",
      "  training_iteration: 715\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 21130 s, 715 iter, 7150000 ts, -87.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-04-43\n",
      "  done: false\n",
      "  episode_len_mean: 92.1651376146789\n",
      "  episode_reward_max: 13.650594275191885\n",
      "  episode_reward_mean: -77.55044480790905\n",
      "  episode_reward_min: -201.58046812756882\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 79474\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5997.851\n",
      "    load_time_ms: 1.725\n",
      "    num_steps_sampled: 7160000\n",
      "    num_steps_trained: 7160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.803413356231557e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.4028985500335693\n",
      "      kl: 0.03501030057668686\n",
      "      policy_loss: 0.010119968093931675\n",
      "      total_loss: 1527.685546875\n",
      "      vf_explained_var: 0.41962364315986633\n",
      "      vf_loss: 1527.675537109375\n",
      "    sample_time_ms: 26811.815\n",
      "    update_time_ms: 9.622\n",
      "  iterations_since_restore: 716\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -38.77522240395454\n",
      "  time_since_restore: 21160.272727251053\n",
      "  time_this_iter_s: 29.415887355804443\n",
      "  time_total_s: 21160.272727251053\n",
      "  timestamp: 1554829483\n",
      "  timesteps_since_restore: 7160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7160000\n",
      "  training_iteration: 716\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 21160 s, 716 iter, 7160000 ts, -77.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-05-11\n",
      "  done: false\n",
      "  episode_len_mean: 83.94117647058823\n",
      "  episode_reward_max: 13.53692398404706\n",
      "  episode_reward_mean: -105.18097059584997\n",
      "  episode_reward_min: -201.51192253853281\n",
      "  episodes_this_iter: 119\n",
      "  episodes_total: 79593\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5828.114\n",
      "    load_time_ms: 1.755\n",
      "    num_steps_sampled: 7170000\n",
      "    num_steps_trained: 7170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.803413356231557e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3948864936828613\n",
      "      kl: 1.270455241203308\n",
      "      policy_loss: 0.05544087663292885\n",
      "      total_loss: 1367.092529296875\n",
      "      vf_explained_var: 0.514208197593689\n",
      "      vf_loss: 1367.037109375\n",
      "    sample_time_ms: 26721.829\n",
      "    update_time_ms: 9.608\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -52.59048529792499\n",
      "  time_since_restore: 21188.85872244835\n",
      "  time_this_iter_s: 28.585995197296143\n",
      "  time_total_s: 21188.85872244835\n",
      "  timestamp: 1554829511\n",
      "  timesteps_since_restore: 7170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7170000\n",
      "  training_iteration: 717\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 21188 s, 717 iter, 7170000 ts, -105 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-05-41\n",
      "  done: false\n",
      "  episode_len_mean: 85.25862068965517\n",
      "  episode_reward_max: 16.281754869516135\n",
      "  episode_reward_mean: -99.06763200822489\n",
      "  episode_reward_min: -206.43465649412633\n",
      "  episodes_this_iter: 116\n",
      "  episodes_total: 79709\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5817.935\n",
      "    load_time_ms: 1.744\n",
      "    num_steps_sampled: 7180000\n",
      "    num_steps_trained: 7180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0205117683358633e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3921377658843994\n",
      "      kl: 0.037141524255275726\n",
      "      policy_loss: 0.012555057182908058\n",
      "      total_loss: 1355.899658203125\n",
      "      vf_explained_var: 0.5156821012496948\n",
      "      vf_loss: 1355.886962890625\n",
      "    sample_time_ms: 26598.445\n",
      "    update_time_ms: 9.6\n",
      "  iterations_since_restore: 718\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -49.533816004112445\n",
      "  time_since_restore: 21218.34708094597\n",
      "  time_this_iter_s: 29.48835849761963\n",
      "  time_total_s: 21218.34708094597\n",
      "  timestamp: 1554829541\n",
      "  timesteps_since_restore: 7180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7180000\n",
      "  training_iteration: 718\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 11.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\tRUNNING [pid=30302], 21218 s, 718 iter, 7180000 ts, -99.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-09_19-06-10\n",
      "  done: false\n",
      "  episode_len_mean: 81.08\n",
      "  episode_reward_max: 12.163313126421663\n",
      "  episode_reward_mean: -110.12676354847491\n",
      "  episode_reward_min: -202.97170702590677\n",
      "  episodes_this_iter: 125\n",
      "  episodes_total: 79834\n",
      "  experiment_id: 22b1cc9446844e61a011e26f0fdde742\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 5582.964\n",
      "    load_time_ms: 1.68\n",
      "    num_steps_sampled: 7190000\n",
      "    num_steps_trained: 7190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0205117683358633e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -1.3945953845977783\n",
      "      kl: 0.039475299417972565\n",
      "      policy_loss: 0.01523870974779129\n",
      "      total_loss: 1331.8331298828125\n",
      "      vf_explained_var: 0.5190800428390503\n",
      "      vf_loss: 1331.81787109375\n",
      "    sample_time_ms: 26033.602\n",
      "    update_time_ms: 9.519\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 30302\n",
      "  policy_reward_mean:\n",
      "    rl_0: -55.06338177423747\n",
      "  time_since_restore: 21247.723551511765\n",
      "  time_this_iter_s: 29.3764705657959\n",
      "  time_total_s: 21247.723551511765\n",
      "  timestamp: 1554829570\n",
      "  timesteps_since_restore: 7190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7190000\n",
      "  training_iteration: 719\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,  # RL algorithm to run\n",
    "        \"env\": gym_name,  # environment name generated earlier\n",
    "        \"config\": {  # configuration params (must match \"run\" value)\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 1,  # number of iterations between checkpoints\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 1000,  # number of iterations to stop after\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flow_2)",
   "language": "python",
   "name": "flow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
