{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING I3W\n",
    "\n",
    "\n",
    "# A) Create Envorinment, Vehicles etc\n",
    "\n",
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scenarios:\n",
      "['Scenario', 'BayBridgeScenario', 'BayBridgeTollScenario', 'BottleneckScenario', 'Figure8Scenario', 'SimpleGridScenario', 'HighwayScenario', 'LoopScenario', 'MergeScenario', 'TwoLoopsOneMergingScenario', 'MultiLoopScenario', 'IntersectionScenarioTW', 'TenaciousDScenario']\n",
      "\n",
      "Available environments:\n",
      "['MultiEnv', 'MultiAgentAccelEnv', 'MultiWaveAttenuationPOEnv', 'MultiAgentIntersectionEnv', 'MultiAgentTeamSpiritIntersectionEnv', 'MultiAgentIntersectionEnv_baseline_1', 'MultiAgentIntersectionEnv_baseline_2', 'MultiAgentIntersectionEnv_baseline_3', 'MultiAgentIntersectionEnv_sharedPolicy_TeamSpirit', 'MultiWaveAttenuationPOEnv_dipl']\n"
     ]
    }
   ],
   "source": [
    "# Define horizon as a variable to ensure consistent use across notebook (length of one rollout)\n",
    "HORIZON= 500                                 #103 max Horizon, wenn es vor verlassen abbrechen soll!, default war 500\n",
    "\n",
    "# name of the experiment\n",
    "experiment_name = \"TenaciousD\"\n",
    "\n",
    "# scenario class\n",
    "import flow.scenarios as scenarios\n",
    "print(\"Available scenarios:\")\n",
    "print(scenarios.__all__)\n",
    "scenario_name = \"TenaciousDScenario\"\n",
    "\n",
    "# environment class\n",
    "import flow.multiagent_envs as flowenvs\n",
    "print(\"\\nAvailable environments:\")\n",
    "print(flowenvs.__all__)\n",
    "env_name = \"MultiWaveAttenuationPOEnv_dipl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import NetParams\n",
    "from flow.scenarios.intersection import ADDITIONAL_NET_PARAMS\n",
    "\n",
    "additionalNetParams={\n",
    "            'length': 230,\n",
    "            'lanes': 1,\n",
    "            'speed_limit': 15,\n",
    "            'resolution': 40,\n",
    "        }\n",
    "\n",
    "net_params = NetParams( no_internal_links=False,                  #default: True   !! damit Kreuzungen nicht Ã¼berspr. werden\n",
    "                        inflows=None,                             #default: None\n",
    "                        osm_path=None,                            #default: None\n",
    "                        netfile=None,                             #default: None\n",
    "                        additional_params=additionalNetParams     #default: None   !!\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitialConfig Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['right_upper', 'right_lower', 'left_upper', 'left_lower']\n"
     ]
    }
   ],
   "source": [
    "from flow.core.params import InitialConfig\n",
    "\n",
    "initialEdges = []\n",
    "initialEdges.append(\"right_upper\")\n",
    "initialEdges.append(\"right_lower\")\n",
    "initialEdges.append(\"left_upper\")\n",
    "initialEdges.append(\"left_lower\")\n",
    "print(initialEdges)\n",
    "\n",
    "initial_config = InitialConfig( shuffle=False,                           #default: False          !!\n",
    "                                spacing=\"custom\",                        #default: \"uniform\"      !!\n",
    "                                min_gap=10,                              #default: 0\n",
    "                                perturbation=0.0,                        #default: 0.0            !!        \n",
    "                                x0=0,                                    #default: 0\n",
    "                                bunching=0,                              #default: 0\n",
    "                                lanes_distribution=float(\"inf\"),         #default: float(\"inf\")\n",
    "                                edges_distribution=initialEdges,         #default: \"all\"          !!\n",
    "                                additional_params=None )                 #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMO Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sumo_params = SumoParams( port = None,                  #default: None\n",
    "                          sim_step=0.1,                 #default: 0.1\n",
    "                          emission_path=None,           #default: None\n",
    "                          lateral_resolution=None,      #default: None\n",
    "                          no_step_log=True,             #default: True\n",
    "                          render=False,                 #default: False !!\n",
    "                          save_render=False,            #default: False\n",
    "                          sight_radius=25,              #default: 25\n",
    "                          show_radius=False,            #default: False\n",
    "                          pxpm=2,                       #default: 2\n",
    "                          overtake_right=False,         #default: False    \n",
    "                          seed=None,                    #default: None\n",
    "                          restart_instance=False,       #default: False\n",
    "                          print_warnings=True,          #default: True\n",
    "                          teleport_time=-1,             #default: -1\n",
    "                          num_clients=1,                #default: 1\n",
    "                          sumo_binary=None )            #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "additionalEnvParams={\n",
    "            'max_accel': 1,\n",
    "            'max_decel': 1,\n",
    "            'ring_length': [230, 230],\n",
    "            'target_velocity': 4\n",
    "        }\n",
    "\n",
    "env_params = EnvParams( additional_params=additionalEnvParams, #default: None    !!\n",
    "                        horizon=HORIZON,                       #default: 500     !!\n",
    "                        warmup_steps=0,                        #default: 0       \n",
    "                        sims_per_step=1,                       #default: 1\n",
    "                        evaluate=False )                       #default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import VehicleParams\n",
    "\n",
    "# import vehicles dynamics models\n",
    "#from flow.controllers import SumoCarFollowingController\n",
    "from flow.controllers import ContinuousRouter\n",
    "from flow.controllers import TenaciousDRouter\n",
    "#from flow.controllers.lane_change_controllers import SumoLaneChangeController\n",
    "from flow.controllers.lane_change_controllers import StaticLaneChanger\n",
    "from flow.controllers import RLController\n",
    "from flow.core.params import SumoLaneChangeParams\n",
    "from flow.core.params import SumoCarFollowingParams\n",
    "from random import *\n",
    "\n",
    "vehicles = VehicleParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add RL-Agent controlled vehicles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car following parameters, default: None\n",
    "cf_parameter = SumoCarFollowingParams(\n",
    "                speed_mode=\"aggressive\")\n",
    "# lane change parameters, default: None\n",
    "lc_parameter =  None\n",
    "\n",
    "vehicles.add( # name of the vehicle\n",
    "                veh_id = \"rl\",\n",
    "              # acceleration controller, default: (SumoCarFollowingController, {})\n",
    "                acceleration_controller=(RLController, {}),\n",
    "              # lane_change_controller, default: (SumoLaneChangeController, {})\n",
    "                lane_change_controller=(StaticLaneChanger,{}),\n",
    "              # routing controller, default: None\n",
    "                routing_controller=(TenaciousDRouter, {}),\n",
    "              # initial speed, default: 0\n",
    "                initial_speed=0,\n",
    "              # number of vehicles, default: 1 \n",
    "                num_vehicles=4,\n",
    "                \n",
    "                car_following_params=cf_parameter\n",
    "              # speed mode, default: \"right_of_way\"\n",
    "                #speed_mode=\"aggressive\",\n",
    "              # lane change mode, default: \"no_lat_collide\"\n",
    "                #lane_change_mode=\"aggressive\", \n",
    "              # car following parameter, default: None\n",
    "                #sumo_car_following_params=cf_parameter,\n",
    "              # lane change parameter, default: None\n",
    "                #sumo_lc_params=lc_parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict( # name of the experiment\n",
    "                      exp_tag=experiment_name,\n",
    "                    # name of the flow environment the experiment is running on\n",
    "                      env_name=env_name,\n",
    "                    # name of the scenario class the experiment uses\n",
    "                      scenario=scenario_name,\n",
    "                    # simulator that is used by the experiment\n",
    "                      simulator='traci',\n",
    "                    # sumo-related parameters (see flow.core.params.SumoParams)\n",
    "                      sim=sumo_params,\n",
    "                    # environment related parameters (see flow.core.params.EnvParams)\n",
    "                      env=env_params,\n",
    "                    # network-related parameters (see flow.core.params.NetParams and\n",
    "                    # the scenario's documentation or ADDITIONAL_NET_PARAMS component)\n",
    "                      net=net_params,\n",
    "                    # vehicles to be placed in the network at the start of a rollout \n",
    "                    # (see flow.core.vehicles.Vehicles)\n",
    "                      veh=vehicles,\n",
    "                   # (optional) parameters affecting the positioning of vehicles upon \n",
    "                   # initialization/reset (see flow.core.params.InitialConfig)\n",
    "                      initial=initial_config\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo.ppo_policy_graph import PPOPolicyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-04-25_00-24-48_25059/logs.\n",
      "Waiting for redis server at 127.0.0.1:49942 to respond...\n",
      "Waiting for redis server at 127.0.0.1:57269 to respond...\n",
      "Starting the Plasma object store with 6.554658406 GB memory using /dev/shm.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=38ab8f51ad05b1868d14a856b9755ac79f088360a817576a\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.16.123.117',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-04-25_00-24-48_25059/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-04-25_00-24-48_25059/sockets/raylet'],\n",
       " 'redis_address': '172.16.123.117:49942',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui.ipynb?token=38ab8f51ad05b1868d14a856b9755ac79f088360a817576a'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "N_CPUS = 2\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 20\n",
    "\n",
    "ray.init(redirect_output=True, num_cpus=N_CPUS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm or model to train. This may refer to \"\n",
    "#      \"the name of a built-on algorithm (e.g. RLLib's DQN \"\n",
    "#      \"or PPO), or a user-defined trainable function or \"\n",
    "#      \"class registered in the tune registry.\")\n",
    "alg_run = \"PPO\"\n",
    "\n",
    "agent_cls = get_agent_class(alg_run)\n",
    "config = agent_cls._default_config.copy()\n",
    "config[\"num_workers\"] = N_CPUS  # number of parallel workers\n",
    "config[\"train_batch_size\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.9  # discount rate default 0.999\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [100, 50, 25]})  # size of hidden layers in network defaule 64 32\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "#config[\"sgd_minibatch_size\"] = min(16 * 1024, config[\"train_batch_size\"])  # stochastic gradient descent\n",
    "#config[\"sample_batch_size\"] = config[\"train_batch_size\"]/config[\"num_workers\"] # 200 default, trotzdem zu hoch?\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "config['env_config']['run'] = alg_run\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, gym_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(gym_name, create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Starting SUMO on port 50521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Teamspirit:\n",
      "0.5317682839881297\n",
      "-0.7361193313770671\n"
     ]
    }
   ],
   "source": [
    "# multi agent policy mapping\n",
    "test_env = create_env()\n",
    "obs_space = test_env.observation_space\n",
    "act_space = test_env.action_space\n",
    "\n",
    "def gen_policy():\n",
    "    return (PPOPolicyGraph, obs_space, act_space, {})\n",
    "\n",
    "# Setup PG with an ensemble of `num_policies` different policy graphs\n",
    "policy_graphs = {'rl_0': gen_policy()}\n",
    "    \n",
    "def policy_mapping_fn(agent_id):\n",
    "    return 'rl_0'\n",
    "\n",
    "config.update({\n",
    "        'multiagent': {\n",
    "            'policy_graphs': policy_graphs,\n",
    "            'policy_mapping_fn': tune.function(policy_mapping_fn),\n",
    "            'policies_to_train': ['rl_0']\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "\n",
      "Created LogSyncer for /home/thorsten/ray_results/TenaciousD/PPO_MultiWaveAttenuationPOEnv_dipl-v0_0_2019-04-25_00-24-51dtqekb01 -> \n",
      "WARNING: Falling back to serializing objects of type <class 'numpy.dtype'> by using pickle. This may be inefficient.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 9.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/TenaciousD\n",
      "RUNNING trials:\n",
      " - PPO_MultiWaveAttenuationPOEnv_dipl-v0_0:\tRUNNING\n",
      "\n",
      "Result for PPO_MultiWaveAttenuationPOEnv_dipl-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-04-25_00-26-38\n",
      "  done: false\n",
      "  episode_len_mean: 473.65\n",
      "  episode_reward_max: 804.0477244703865\n",
      "  episode_reward_mean: 476.27201807663886\n",
      "  episode_reward_min: 202.3023019632859\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 20\n",
      "  experiment_id: e45cccfed7474d7faa27b27462267144\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 10826.265\n",
      "    load_time_ms: 50.704\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20000003278255463\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4269903898239136\n",
      "      kl: 0.033543847501277924\n",
      "      policy_loss: -0.021996358409523964\n",
      "      total_loss: 1.1116037368774414\n",
      "      vf_explained_var: 0.6309910416603088\n",
      "      vf_loss: 1.1268913745880127\n",
      "    sample_time_ms: 41749.21\n",
      "    update_time_ms: 1166.85\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.16.123.117\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 25113\n",
      "  policy_reward_mean:\n",
      "    rl_0: 119.06800451915971\n",
      "  time_since_restore: 53.87343239784241\n",
      "  time_this_iter_s: 53.87343239784241\n",
      "  time_total_s: 53.87343239784241\n",
      "  timestamp: 1556144798\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 1\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,  # RL algorithm to run\n",
    "        \"env\": gym_name,  # environment name generated earlier\n",
    "        \"config\": {  # configuration params (must match \"run\" value)\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 1,  # number of iterations between checkpoints\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 1000,  # number of iterations to stop after\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flow_2)",
   "language": "python",
   "name": "flow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
