{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING I3W\n",
    "\n",
    "\n",
    "# A) Create Envorinment, Vehicles etc\n",
    "\n",
    "### General Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scenarios:\n",
      "['Scenario', 'BayBridgeScenario', 'BayBridgeTollScenario', 'BottleneckScenario', 'Figure8Scenario', 'SimpleGridScenario', 'HighwayScenario', 'LoopScenario', 'MergeScenario', 'TwoLoopsOneMergingScenario', 'MultiLoopScenario', 'IntersectionScenario', 'IntersectionScenarioTW']\n",
      "\n",
      "Available environments:\n",
      "['MultiEnv', 'MultiAgentAccelEnv', 'MultiWaveAttenuationPOEnv', 'MultiAgentIntersectionEnv', 'MultiAgentTeamSpiritIntersectionEnv']\n"
     ]
    }
   ],
   "source": [
    "# Define horizon as a variable to ensure consistent use across notebook (length of one rollout)\n",
    "HORIZON=500\n",
    "\n",
    "# name of the experiment\n",
    "experiment_name = \"IntersectionExample\"\n",
    "\n",
    "# scenario class\n",
    "import flow.scenarios as scenarios\n",
    "print(\"Available scenarios:\")\n",
    "print(scenarios.__all__)\n",
    "scenario_name = \"IntersectionTWScenario\"\n",
    "\n",
    "# environment class\n",
    "import flow.multiagent_envs as flowenvs\n",
    "print(\"\\nAvailable environments:\")\n",
    "print(flowenvs.__all__)\n",
    "env_name = \"MultiAgentTeamSpiritIntersectionEnv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import NetParams\n",
    "from flow.scenarios.intersection import ADDITIONAL_NET_PARAMS\n",
    "\n",
    "additionalNetParams = {\n",
    "            \"edge_length\": 40,\n",
    "            \"lanes\": 1,\n",
    "            \"speed_limit\": 30\n",
    "        }\n",
    "\n",
    "net_params = NetParams( no_internal_links=False,                  #default: True   !! damit Kreuzungen nicht Ã¼berspr. werden\n",
    "                        inflows=None,                             #default: None\n",
    "                        osm_path=None,                            #default: None\n",
    "                        netfile=None,                             #default: None\n",
    "                        additional_params=additionalNetParams     #default: None   !!\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InitialConfig Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import InitialConfig\n",
    "\n",
    "initial_config = InitialConfig( shuffle=True,                            #default: False         !!\n",
    "                                spacing=\"custom\",                        #default: \"uniform\"     !!\n",
    "                                min_gap=10,                              #default: 0\n",
    "                                perturbation=39.99,                      #default: 0.0            !!        \n",
    "                                x0=0,                                    #default: 0\n",
    "                                bunching=0,                              #default: 0\n",
    "                                lanes_distribution=float(\"inf\"),         #default: float(\"inf\")\n",
    "                                edges_distribution=\"all\",                #default: \"all\"\n",
    "                                additional_params=None )                 #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMO Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sumo_params = SumoParams( port = None,                  #default: None\n",
    "                          sim_step=0.1,                 #default: 0.1\n",
    "                          emission_path=None,           #default: None\n",
    "                          lateral_resolution=None,      #default: None\n",
    "                          no_step_log=True,             #default: True\n",
    "                          render=False,                 #default: False\n",
    "                          save_render=False,            #default: False\n",
    "                          sight_radius=25,              #default: 25\n",
    "                          show_radius=False,            #default: False\n",
    "                          pxpm=2,                       #default: 2\n",
    "                          overtake_right=False,         #default: False    \n",
    "                          seed=None,                    #default: None\n",
    "                          restart_instance=False,       #default: False\n",
    "                          print_warnings=True,          #default: True\n",
    "                          teleport_time=-1,             #default: -1\n",
    "                          num_clients=1,                #default: 1\n",
    "                          sumo_binary=None )            #default: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "additionalEnvParams = {\n",
    "        # maximum acceleration of autonomous vehicles\n",
    "        \"max_accel\": 3,\n",
    "        # maximum deceleration of autonomous vehicles\n",
    "        \"max_decel\": 3,\n",
    "        \"target_velocity\": 30\n",
    "    }\n",
    "\n",
    "env_params = EnvParams( additional_params=additionalEnvParams, #default: None    !!\n",
    "                        horizon=HORIZON,                       #default: 500     !!\n",
    "                        warmup_steps=0,                        #default: 0       \n",
    "                        sims_per_step=1,                       #default: 1\n",
    "                        evaluate=False )                       #default: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicles Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow.core.params import VehicleParams\n",
    "\n",
    "# import vehicles dynamics models\n",
    "#from flow.controllers import SumoCarFollowingController\n",
    "from flow.controllers import ContinuousRouter\n",
    "#from flow.controllers.lane_change_controllers import SumoLaneChangeController\n",
    "from flow.controllers.lane_change_controllers import StaticLaneChanger\n",
    "from flow.controllers import RLController\n",
    "from flow.core.params import SumoLaneChangeParams\n",
    "from flow.core.params import SumoCarFollowingParams\n",
    "from random import *\n",
    "\n",
    "vehicles = VehicleParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add RL-Agent controlled vehicles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car following parameters, default: None\n",
    "cf_parameter = SumoCarFollowingParams(\n",
    "                speed_mode=\"aggressive\")\n",
    "# lane change parameters, default: None\n",
    "lc_parameter =  None\n",
    "\n",
    "vehicles.add( # name of the vehicle\n",
    "                veh_id = \"rl\",\n",
    "              # acceleration controller, default: (SumoCarFollowingController, {})\n",
    "                acceleration_controller=(RLController, {}),\n",
    "              # lane_change_controller, default: (SumoLaneChangeController, {})\n",
    "                lane_change_controller=(StaticLaneChanger,{}),\n",
    "              # routing controller, default: None\n",
    "                routing_controller=(ContinuousRouter, {}),\n",
    "              # initial speed, default: 0\n",
    "                initial_speed=0,\n",
    "              # number of vehicles, default: 1 \n",
    "                num_vehicles=2,\n",
    "                \n",
    "                car_following_params=cf_parameter\n",
    "              # speed mode, default: \"right_of_way\"\n",
    "                #speed_mode=\"aggressive\",\n",
    "              # lane change mode, default: \"no_lat_collide\"\n",
    "                #lane_change_mode=\"aggressive\", \n",
    "              # car following parameter, default: None\n",
    "                #sumo_car_following_params=cf_parameter,\n",
    "              # lane change parameter, default: None\n",
    "                #sumo_lc_params=lc_parameter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict( # name of the experiment\n",
    "                      exp_tag=experiment_name,\n",
    "                    # name of the flow environment the experiment is running on\n",
    "                      env_name=env_name,\n",
    "                    # name of the scenario class the experiment uses\n",
    "                      scenario=scenario_name,\n",
    "                    # simulator that is used by the experiment\n",
    "                      simulator='traci',\n",
    "                    # sumo-related parameters (see flow.core.params.SumoParams)\n",
    "                      sim=sumo_params,\n",
    "                    # environment related parameters (see flow.core.params.EnvParams)\n",
    "                      env=env_params,\n",
    "                    # network-related parameters (see flow.core.params.NetParams and\n",
    "                    # the scenario's documentation or ADDITIONAL_NET_PARAMS component)\n",
    "                      net=net_params,\n",
    "                    # vehicles to be placed in the network at the start of a rollout \n",
    "                    # (see flow.core.vehicles.Vehicles)\n",
    "                      veh=vehicles,\n",
    "                   # (optional) parameters affecting the positioning of vehicles upon \n",
    "                   # initialization/reset (see flow.core.params.InitialConfig)\n",
    "                      initial=initial_config\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "try:\n",
    "    from ray.rllib.agents.agent import get_agent_class\n",
    "except ImportError:\n",
    "    from ray.rllib.agents.registry import get_agent_class\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.registry import make_create_env\n",
    "from flow.utils.rllib import FlowParamsEncoder\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo.ppo_policy_graph import PPOPolicyGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-02-23_01-09-09_12703/logs.\n",
      "Waiting for redis server at 127.0.0.1:21994 to respond...\n",
      "Waiting for redis server at 127.0.0.1:49613 to respond...\n",
      "Starting the Plasma object store with 6.554658406 GB memory using /dev/shm.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=e101b9a8d3f9ba6e6f712de31e0b9c203bc003a504a165d1\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.2.102',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-02-23_01-09-09_12703/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-02-23_01-09-09_12703/sockets/raylet'],\n",
       " 'redis_address': '192.168.2.102:21994',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui.ipynb?token=e101b9a8d3f9ba6e6f712de31e0b9c203bc003a504a165d1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "N_CPUS = 2\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 20\n",
    "\n",
    "ray.init(redirect_output=True, num_cpus=N_CPUS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The algorithm or model to train. This may refer to \"\n",
    "#      \"the name of a built-on algorithm (e.g. RLLib's DQN \"\n",
    "#      \"or PPO), or a user-defined trainable function or \"\n",
    "#      \"class registered in the tune registry.\")\n",
    "alg_run = \"PPO\"\n",
    "\n",
    "agent_cls = get_agent_class(alg_run)\n",
    "config = agent_cls._default_config.copy()\n",
    "config[\"num_workers\"] = N_CPUS  # number of parallel workers\n",
    "config[\"train_batch_size\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.999  # discount rate\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [64, 32]})  # size of hidden layers in network\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "#config[\"sgd_minibatch_size\"] = min(16 * 1024, config[\"train_batch_size\"])  # stochastic gradient descent\n",
    "#config[\"sample_batch_size\"] = config[\"train_batch_size\"]/config[\"num_workers\"] # 200 default, trotzdem zu hoch?\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "config['env_config']['run'] = alg_run\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, gym_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(gym_name, create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Starting SUMO on port 48217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6038076979708429\n",
      "11.582291891152966\n"
     ]
    }
   ],
   "source": [
    "# multi agent policy mapping\n",
    "test_env = create_env()\n",
    "obs_space = test_env.observation_space\n",
    "act_space = test_env.action_space\n",
    "\n",
    "def gen_policy():\n",
    "    return (PPOPolicyGraph, obs_space, act_space, {})\n",
    "\n",
    "# Setup PG with an ensemble of `num_policies` different policy graphs\n",
    "policy_graphs = {'rl_0': gen_policy(), 'rl_1': gen_policy()}\n",
    "    \n",
    "def policy_mapping_fn(agent_id):\n",
    "    return agent_id\n",
    "\n",
    "config.update({\n",
    "        'multiagent': {\n",
    "            'policy_graphs': policy_graphs,\n",
    "            'policy_mapping_fn': tune.function(policy_mapping_fn)\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.2/16.4 GB\n",
      "\n",
      "Created LogSyncer for /home/thorsten/ray_results/IntersectionExample/PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0_2019-02-23_01-09-11i4dg0a94 -> \n",
      "WARNING: Falling back to serializing objects of type <class 'numpy.dtype'> by using pickle. This may be inefficient.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-10-07\n",
      "  done: false\n",
      "  episode_len_mean: 400.1666666666667\n",
      "  episode_reward_max: 145.38326111257012\n",
      "  episode_reward_mean: -8.759566947312722\n",
      "  episode_reward_min: -181.94378557141593\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 24\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 4278.545\n",
      "    load_time_ms: 143.977\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 10000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.42253839969635\n",
      "      kl: 0.003931640647351742\n",
      "      policy_loss: -0.003522492479532957\n",
      "      total_loss: 146.45535278320312\n",
      "      vf_explained_var: 0.012962057255208492\n",
      "      vf_loss: 146.45806884765625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.20000000298023224\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4196985960006714\n",
      "      kl: 0.0002657687582541257\n",
      "      policy_loss: -4.512759460340021e-06\n",
      "      total_loss: 144.9232940673828\n",
      "      vf_explained_var: 0.01726820506155491\n",
      "      vf_loss: 144.92323303222656\n",
      "    sample_time_ms: 20380.517\n",
      "    update_time_ms: 1597.448\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: -3.035754634724338\n",
      "    rl_1: -5.723812312588392\n",
      "  time_since_restore: 26.526036977767944\n",
      "  time_this_iter_s: 26.526036977767944\n",
      "  time_total_s: 26.526036977767944\n",
      "  timestamp: 1550880607\n",
      "  timesteps_since_restore: 10000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 26 s, 1 iter, 10000 ts, -8.76 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-10-30\n",
      "  done: false\n",
      "  episode_len_mean: 397.32\n",
      "  episode_reward_max: 167.08105752205313\n",
      "  episode_reward_mean: -2.0330906325266955\n",
      "  episode_reward_min: -181.94378557141593\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 50\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3773.478\n",
      "    load_time_ms: 73.063\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.10000000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4253275394439697\n",
      "      kl: 0.0012997891753911972\n",
      "      policy_loss: -0.001472023199312389\n",
      "      total_loss: 149.55679321289062\n",
      "      vf_explained_var: 0.06792282313108444\n",
      "      vf_loss: 149.55813598632812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.10000000149011612\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4251710176467896\n",
      "      kl: 0.0009956425055861473\n",
      "      policy_loss: -0.0007512602605856955\n",
      "      total_loss: 157.29246520996094\n",
      "      vf_explained_var: 0.04299594461917877\n",
      "      vf_loss: 157.29312133789062\n",
      "    sample_time_ms: 20304.257\n",
      "    update_time_ms: 804.494\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: -1.5257308364607196\n",
      "    rl_1: -0.5073597960659706\n",
      "  time_since_restore: 50.05030941963196\n",
      "  time_this_iter_s: 23.524272441864014\n",
      "  time_total_s: 50.05030941963196\n",
      "  timestamp: 1550880630\n",
      "  timesteps_since_restore: 20000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 50 s, 2 iter, 20000 ts, -2.03 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-10-53\n",
      "  done: false\n",
      "  episode_len_mean: 398.2162162162162\n",
      "  episode_reward_max: 167.08105752205313\n",
      "  episode_reward_mean: 3.5478277278368173\n",
      "  episode_reward_min: -181.94378557141593\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 74\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3599.134\n",
      "    load_time_ms: 49.711\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 30000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.05000000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4274804592132568\n",
      "      kl: 0.0006565166404470801\n",
      "      policy_loss: -0.0015145244542509317\n",
      "      total_loss: 124.09562683105469\n",
      "      vf_explained_var: 0.13426634669303894\n",
      "      vf_loss: 124.09715270996094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.05000000074505806\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4246373176574707\n",
      "      kl: 0.0018917283741757274\n",
      "      policy_loss: -0.003114755032584071\n",
      "      total_loss: 127.42153930664062\n",
      "      vf_explained_var: 0.06048707291483879\n",
      "      vf_loss: 127.42455291748047\n",
      "    sample_time_ms: 20172.565\n",
      "    update_time_ms: 538.805\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 0.22537923971810792\n",
      "    rl_1: 3.32244848811871\n",
      "  time_since_restore: 73.23737335205078\n",
      "  time_this_iter_s: 23.187063932418823\n",
      "  time_total_s: 73.23737335205078\n",
      "  timestamp: 1550880653\n",
      "  timesteps_since_restore: 30000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 3\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 73 s, 3 iter, 30000 ts, 3.55 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-11-17\n",
      "  done: false\n",
      "  episode_len_mean: 405.8061224489796\n",
      "  episode_reward_max: 167.08105752205313\n",
      "  episode_reward_mean: 17.15564948375794\n",
      "  episode_reward_min: -181.94378557141593\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 98\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3520.212\n",
      "    load_time_ms: 37.818\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.02500000037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4267874956130981\n",
      "      kl: 0.0014391817385330796\n",
      "      policy_loss: -0.002263049129396677\n",
      "      total_loss: 81.28706359863281\n",
      "      vf_explained_var: 0.264076292514801\n",
      "      vf_loss: 81.28929138183594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.02500000037252903\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4229904413223267\n",
      "      kl: 0.001037092530168593\n",
      "      policy_loss: -0.0008422179380431771\n",
      "      total_loss: 86.66825866699219\n",
      "      vf_explained_var: 0.07295770943164825\n",
      "      vf_loss: 86.6690673828125\n",
      "    sample_time_ms: 20108.218\n",
      "    update_time_ms: 406.172\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 4.758749854494372\n",
      "    rl_1: 12.39689962926358\n",
      "  time_since_restore: 96.46114730834961\n",
      "  time_this_iter_s: 23.223773956298828\n",
      "  time_total_s: 96.46114730834961\n",
      "  timestamp: 1550880677\n",
      "  timesteps_since_restore: 40000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 4\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 96 s, 4 iter, 40000 ts, 17.2 rew\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-11-41\n",
      "  done: false\n",
      "  episode_len_mean: 398.7\n",
      "  episode_reward_max: 207.50015774012948\n",
      "  episode_reward_mean: 25.34166855334402\n",
      "  episode_reward_min: -176.02688496905031\n",
      "  episodes_this_iter: 26\n",
      "  episodes_total: 124\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3472.252\n",
      "    load_time_ms: 30.896\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 50000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.012500000186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4442048072814941\n",
      "      kl: 0.005586014594882727\n",
      "      policy_loss: -0.00443550618365407\n",
      "      total_loss: 151.82093811035156\n",
      "      vf_explained_var: 0.2782227396965027\n",
      "      vf_loss: 151.82530212402344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.012500000186264515\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.414603352546692\n",
      "      kl: 0.0022687746677547693\n",
      "      policy_loss: -0.0024181895423680544\n",
      "      total_loss: 150.1072235107422\n",
      "      vf_explained_var: 0.1519683450460434\n",
      "      vf_loss: 150.10960388183594\n",
      "    sample_time_ms: 20209.851\n",
      "    update_time_ms: 326.268\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 9.950540536639243\n",
      "    rl_1: 15.391128016704789\n",
      "  time_since_restore: 120.38452363014221\n",
      "  time_this_iter_s: 23.923376321792603\n",
      "  time_total_s: 120.38452363014221\n",
      "  timestamp: 1550880701\n",
      "  timesteps_since_restore: 50000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 5\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 120 s, 5 iter, 50000 ts, 25.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-12-05\n",
      "  done: false\n",
      "  episode_len_mean: 389.07\n",
      "  episode_reward_max: 207.50015774012948\n",
      "  episode_reward_mean: 39.57376138147672\n",
      "  episode_reward_min: -176.02688496905031\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 151\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3437.587\n",
      "    load_time_ms: 26.1\n",
      "    num_steps_sampled: 60000\n",
      "    num_steps_trained: 60000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0062500000931322575\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.460905909538269\n",
      "      kl: 0.0024331570602953434\n",
      "      policy_loss: -0.002532550133764744\n",
      "      total_loss: 132.16281127929688\n",
      "      vf_explained_var: 0.36014318466186523\n",
      "      vf_loss: 132.16529846191406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0062500000931322575\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4278433322906494\n",
      "      kl: 0.0012275830376893282\n",
      "      policy_loss: -0.0007148115546442568\n",
      "      total_loss: 112.28179931640625\n",
      "      vf_explained_var: 0.1565556675195694\n",
      "      vf_loss: 112.28252410888672\n",
      "    sample_time_ms: 20255.113\n",
      "    update_time_ms: 273.221\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 20.68624142425875\n",
      "    rl_1: 18.88751995721798\n",
      "  time_since_restore: 144.1569309234619\n",
      "  time_this_iter_s: 23.772407293319702\n",
      "  time_total_s: 144.1569309234619\n",
      "  timestamp: 1550880725\n",
      "  timesteps_since_restore: 60000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 6\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 144 s, 6 iter, 60000 ts, 39.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-12-28\n",
      "  done: false\n",
      "  episode_len_mean: 376.97\n",
      "  episode_reward_max: 207.50015774012948\n",
      "  episode_reward_mean: 48.87417738090745\n",
      "  episode_reward_min: -176.02688496905031\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 179\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3412.847\n",
      "    load_time_ms: 22.687\n",
      "    num_steps_sampled: 70000\n",
      "    num_steps_trained: 70000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0031250000465661287\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4461482763290405\n",
      "      kl: 0.0021521432790905237\n",
      "      policy_loss: -0.000928421039134264\n",
      "      total_loss: 119.81326293945312\n",
      "      vf_explained_var: 0.42612671852111816\n",
      "      vf_loss: 119.81417846679688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0031250000465661287\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4221374988555908\n",
      "      kl: 0.0034046757500618696\n",
      "      policy_loss: -0.0023443002719432116\n",
      "      total_loss: 107.13660430908203\n",
      "      vf_explained_var: 0.22090043127536774\n",
      "      vf_loss: 107.13894653320312\n",
      "    sample_time_ms: 20213.006\n",
      "    update_time_ms: 235.102\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 28.31638430022555\n",
      "    rl_1: 20.557793080681904\n",
      "  time_since_restore: 167.40590000152588\n",
      "  time_this_iter_s: 23.248969078063965\n",
      "  time_total_s: 167.40590000152588\n",
      "  timestamp: 1550880748\n",
      "  timesteps_since_restore: 70000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 70000\n",
      "  training_iteration: 7\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 167 s, 7 iter, 70000 ts, 48.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-12-51\n",
      "  done: false\n",
      "  episode_len_mean: 361.94\n",
      "  episode_reward_max: 208.21025410316182\n",
      "  episode_reward_mean: 48.61579064385939\n",
      "  episode_reward_min: -169.86439609773745\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 209\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3391.113\n",
      "    load_time_ms: 20.119\n",
      "    num_steps_sampled: 80000\n",
      "    num_steps_trained: 80000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0015625000232830644\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.420195460319519\n",
      "      kl: 0.0023493433836847544\n",
      "      policy_loss: -0.0022800760343670845\n",
      "      total_loss: 159.2084503173828\n",
      "      vf_explained_var: 0.3766709864139557\n",
      "      vf_loss: 159.2107391357422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0015625000232830644\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4364778995513916\n",
      "      kl: 0.0016682352870702744\n",
      "      policy_loss: -0.001954990206286311\n",
      "      total_loss: 166.05389404296875\n",
      "      vf_explained_var: 0.16622720658779144\n",
      "      vf_loss: 166.0558624267578\n",
      "    sample_time_ms: 20201.469\n",
      "    update_time_ms: 206.589\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.026921543202608\n",
      "    rl_1: 21.588869100656783\n",
      "  time_since_restore: 190.79015588760376\n",
      "  time_this_iter_s: 23.38425588607788\n",
      "  time_total_s: 190.79015588760376\n",
      "  timestamp: 1550880771\n",
      "  timesteps_since_restore: 80000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 8\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 190 s, 8 iter, 80000 ts, 48.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-13-15\n",
      "  done: false\n",
      "  episode_len_mean: 358.85\n",
      "  episode_reward_max: 208.21025410316182\n",
      "  episode_reward_mean: 48.679953107361946\n",
      "  episode_reward_min: -166.79983174525807\n",
      "  episodes_this_iter: 27\n",
      "  episodes_total: 236\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3379.363\n",
      "    load_time_ms: 18.118\n",
      "    num_steps_sampled: 90000\n",
      "    num_steps_trained: 90000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0007812500116415322\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4259079694747925\n",
      "      kl: 0.006117867771536112\n",
      "      policy_loss: -0.0036331613082438707\n",
      "      total_loss: 118.7431869506836\n",
      "      vf_explained_var: 0.4278103709220886\n",
      "      vf_loss: 118.74683380126953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0007812500116415322\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4366393089294434\n",
      "      kl: 0.0015761961694806814\n",
      "      policy_loss: -0.0016900751506909728\n",
      "      total_loss: 127.37456512451172\n",
      "      vf_explained_var: 0.2670819163322449\n",
      "      vf_loss: 127.37625122070312\n",
      "    sample_time_ms: 20239.655\n",
      "    update_time_ms: 184.499\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 22.40129459591346\n",
      "    rl_1: 26.278658511448487\n",
      "  time_since_restore: 214.64536046981812\n",
      "  time_this_iter_s: 23.855204582214355\n",
      "  time_total_s: 214.64536046981812\n",
      "  timestamp: 1550880795\n",
      "  timesteps_since_restore: 90000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 90000\n",
      "  training_iteration: 9\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 214 s, 9 iter, 90000 ts, 48.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-13-39\n",
      "  done: false\n",
      "  episode_len_mean: 333.85\n",
      "  episode_reward_max: 208.21025410316182\n",
      "  episode_reward_mean: 38.5822240009209\n",
      "  episode_reward_min: -179.29151748662593\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 269\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3369.236\n",
      "    load_time_ms: 16.579\n",
      "    num_steps_sampled: 100000\n",
      "    num_steps_trained: 100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0003906250058207661\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.439549207687378\n",
      "      kl: 0.004999891854822636\n",
      "      policy_loss: -0.0033731877338141203\n",
      "      total_loss: 185.97064208984375\n",
      "      vf_explained_var: 0.4356483519077301\n",
      "      vf_loss: 185.97401428222656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0003906250058207661\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4252179861068726\n",
      "      kl: 0.0018171020783483982\n",
      "      policy_loss: -0.000895656761713326\n",
      "      total_loss: 177.22349548339844\n",
      "      vf_explained_var: 0.26227548718452454\n",
      "      vf_loss: 177.224365234375\n",
      "    sample_time_ms: 20279.517\n",
      "    update_time_ms: 166.66\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 16.473983737748835\n",
      "    rl_1: 22.10824026317207\n",
      "  time_since_restore: 238.5861475467682\n",
      "  time_this_iter_s: 23.940787076950073\n",
      "  time_total_s: 238.5861475467682\n",
      "  timestamp: 1550880819\n",
      "  timesteps_since_restore: 100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 100000\n",
      "  training_iteration: 10\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 238 s, 10 iter, 100000 ts, 38.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 330.03\n",
      "  episode_reward_max: 200.77907125651248\n",
      "  episode_reward_mean: 30.37677518713946\n",
      "  episode_reward_min: -179.29151748662593\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 299\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3278.082\n",
      "    load_time_ms: 2.475\n",
      "    num_steps_sampled: 110000\n",
      "    num_steps_trained: 110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.00019531250291038305\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4210083484649658\n",
      "      kl: 0.0018974319100379944\n",
      "      policy_loss: -0.0021653056610375643\n",
      "      total_loss: 138.7574920654297\n",
      "      vf_explained_var: 0.42972540855407715\n",
      "      vf_loss: 138.7596435546875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.00019531250291038305\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4298744201660156\n",
      "      kl: 0.0029049357399344444\n",
      "      policy_loss: -0.002019808627665043\n",
      "      total_loss: 148.13999938964844\n",
      "      vf_explained_var: 0.2768627107143402\n",
      "      vf_loss: 148.14199829101562\n",
      "    sample_time_ms: 20280.264\n",
      "    update_time_ms: 7.566\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 12.091963364128567\n",
      "    rl_1: 18.28481182301091\n",
      "  time_since_restore: 262.368860244751\n",
      "  time_this_iter_s: 23.782712697982788\n",
      "  time_total_s: 262.368860244751\n",
      "  timestamp: 1550880843\n",
      "  timesteps_since_restore: 110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 110000\n",
      "  training_iteration: 11\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 262 s, 11 iter, 110000 ts, 30.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-14-27\n",
      "  done: false\n",
      "  episode_len_mean: 310.11\n",
      "  episode_reward_max: 200.77907125651248\n",
      "  episode_reward_mean: 22.621847080468047\n",
      "  episode_reward_min: -180.16472194699503\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 333\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3276.451\n",
      "    load_time_ms: 2.476\n",
      "    num_steps_sampled: 120000\n",
      "    num_steps_trained: 120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.765625145519152e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4089843034744263\n",
      "      kl: 0.002452670130878687\n",
      "      policy_loss: -0.0018428617622703314\n",
      "      total_loss: 174.8946075439453\n",
      "      vf_explained_var: 0.4093974530696869\n",
      "      vf_loss: 174.8964385986328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 9.765625145519152e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4293776750564575\n",
      "      kl: 0.0009990244871005416\n",
      "      policy_loss: -0.0003355728986207396\n",
      "      total_loss: 187.15090942382812\n",
      "      vf_explained_var: 0.26948222517967224\n",
      "      vf_loss: 187.1512451171875\n",
      "    sample_time_ms: 20353.052\n",
      "    update_time_ms: 7.157\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.895139202478452\n",
      "    rl_1: 15.726707877989593\n",
      "  time_since_restore: 286.60412979125977\n",
      "  time_this_iter_s: 24.23526954650879\n",
      "  time_total_s: 286.60412979125977\n",
      "  timestamp: 1550880867\n",
      "  timesteps_since_restore: 120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 120000\n",
      "  training_iteration: 12\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 286 s, 12 iter, 120000 ts, 22.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-14-50\n",
      "  done: false\n",
      "  episode_len_mean: 306.29\n",
      "  episode_reward_max: 197.51946411696582\n",
      "  episode_reward_mean: 12.220920363732468\n",
      "  episode_reward_min: -183.48026746832272\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 368\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3275.057\n",
      "    load_time_ms: 2.404\n",
      "    num_steps_sampled: 130000\n",
      "    num_steps_trained: 130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.882812572759576e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.415986180305481\n",
      "      kl: 0.002975230338051915\n",
      "      policy_loss: -0.0019518064800649881\n",
      "      total_loss: 244.21018981933594\n",
      "      vf_explained_var: 0.3105745017528534\n",
      "      vf_loss: 244.2121124267578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.882812572759576e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4312973022460938\n",
      "      kl: 0.0009441187721677125\n",
      "      policy_loss: -0.0009176906896755099\n",
      "      total_loss: 230.68992614746094\n",
      "      vf_explained_var: 0.32152867317199707\n",
      "      vf_loss: 230.69081115722656\n",
      "    sample_time_ms: 20328.97\n",
      "    update_time_ms: 7.105\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: -0.14858564553599607\n",
      "    rl_1: 12.369506009268461\n",
      "  time_since_restore: 309.5344853401184\n",
      "  time_this_iter_s: 22.930355548858643\n",
      "  time_total_s: 309.5344853401184\n",
      "  timestamp: 1550880890\n",
      "  timesteps_since_restore: 130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 130000\n",
      "  training_iteration: 13\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 309 s, 13 iter, 130000 ts, 12.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-15-14\n",
      "  done: false\n",
      "  episode_len_mean: 285.27\n",
      "  episode_reward_max: 198.02057601373295\n",
      "  episode_reward_mean: 7.811125007299028\n",
      "  episode_reward_min: -183.48026746832272\n",
      "  episodes_this_iter: 35\n",
      "  episodes_total: 403\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3273.681\n",
      "    load_time_ms: 2.47\n",
      "    num_steps_sampled: 140000\n",
      "    num_steps_trained: 140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.441406286379788e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.430029273033142\n",
      "      kl: 0.0020008424762636423\n",
      "      policy_loss: -0.00032299934537149966\n",
      "      total_loss: 203.38438415527344\n",
      "      vf_explained_var: 0.3191138803958893\n",
      "      vf_loss: 203.38470458984375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.441406286379788e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4336812496185303\n",
      "      kl: 0.0026279864832758904\n",
      "      policy_loss: -0.0013810957316309214\n",
      "      total_loss: 190.9893035888672\n",
      "      vf_explained_var: 0.3828997015953064\n",
      "      vf_loss: 190.99066162109375\n",
      "    sample_time_ms: 20388.255\n",
      "    update_time_ms: 7.669\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: -3.2912086248985815\n",
      "    rl_1: 11.1023336321976\n",
      "  time_since_restore: 333.34543895721436\n",
      "  time_this_iter_s: 23.810953617095947\n",
      "  time_total_s: 333.34543895721436\n",
      "  timestamp: 1550880914\n",
      "  timesteps_since_restore: 140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 140000\n",
      "  training_iteration: 14\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 333 s, 14 iter, 140000 ts, 7.81 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-15-38\n",
      "  done: false\n",
      "  episode_len_mean: 305.45\n",
      "  episode_reward_max: 203.06118103919619\n",
      "  episode_reward_mean: 25.038074221456988\n",
      "  episode_reward_min: -183.48026746832272\n",
      "  episodes_this_iter: 28\n",
      "  episodes_total: 431\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3271.985\n",
      "    load_time_ms: 2.419\n",
      "    num_steps_sampled: 150000\n",
      "    num_steps_trained: 150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.220703143189894e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4099640846252441\n",
      "      kl: 0.0023611080832779408\n",
      "      policy_loss: -0.0013746994081884623\n",
      "      total_loss: 75.6988754272461\n",
      "      vf_explained_var: 0.4979251027107239\n",
      "      vf_loss: 75.70024871826172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.220703143189894e-05\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.414857268333435\n",
      "      kl: 0.006976695265620947\n",
      "      policy_loss: -0.002703294390812516\n",
      "      total_loss: 73.40521240234375\n",
      "      vf_explained_var: 0.47943785786628723\n",
      "      vf_loss: 73.4079360961914\n",
      "    sample_time_ms: 20368.154\n",
      "    update_time_ms: 7.568\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 6.407295244881839\n",
      "    rl_1: 18.63077897657514\n",
      "  time_since_restore: 357.04963779449463\n",
      "  time_this_iter_s: 23.704198837280273\n",
      "  time_total_s: 357.04963779449463\n",
      "  timestamp: 1550880938\n",
      "  timesteps_since_restore: 150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 150000\n",
      "  training_iteration: 15\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 357 s, 15 iter, 150000 ts, 25 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-16-01\n",
      "  done: false\n",
      "  episode_len_mean: 320.44\n",
      "  episode_reward_max: 217.24857015238325\n",
      "  episode_reward_mean: 44.47842641088234\n",
      "  episode_reward_min: -175.4350752986692\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 460\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3270.823\n",
      "    load_time_ms: 2.504\n",
      "    num_steps_sampled: 160000\n",
      "    num_steps_trained: 160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.10351571594947e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4191458225250244\n",
      "      kl: 0.0017033347394317389\n",
      "      policy_loss: -0.0013474274892359972\n",
      "      total_loss: 123.70536804199219\n",
      "      vf_explained_var: 0.3827958106994629\n",
      "      vf_loss: 123.70671844482422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 6.10351571594947e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4183813333511353\n",
      "      kl: 0.0035245276521891356\n",
      "      policy_loss: -0.001712303375825286\n",
      "      total_loss: 124.56977081298828\n",
      "      vf_explained_var: 0.42304039001464844\n",
      "      vf_loss: 124.57146453857422\n",
      "    sample_time_ms: 20315.71\n",
      "    update_time_ms: 7.487\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 14.880664666481328\n",
      "    rl_1: 29.597761744401\n",
      "  time_since_restore: 380.28825068473816\n",
      "  time_this_iter_s: 23.23861289024353\n",
      "  time_total_s: 380.28825068473816\n",
      "  timestamp: 1550880961\n",
      "  timesteps_since_restore: 160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 160000\n",
      "  training_iteration: 16\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 380 s, 16 iter, 160000 ts, 44.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-16-25\n",
      "  done: false\n",
      "  episode_len_mean: 319.39\n",
      "  episode_reward_max: 217.24857015238325\n",
      "  episode_reward_mean: 57.97474501845855\n",
      "  episode_reward_min: -172.7416627013285\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 494\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3269.416\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 170000\n",
      "    num_steps_trained: 170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.051757857974735e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4511688947677612\n",
      "      kl: 0.0018074462423101068\n",
      "      policy_loss: -0.0014228649670258164\n",
      "      total_loss: 189.85598754882812\n",
      "      vf_explained_var: 0.3638455867767334\n",
      "      vf_loss: 189.85743713378906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.051757857974735e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4127798080444336\n",
      "      kl: 0.0028161935042589903\n",
      "      policy_loss: -0.001937643508426845\n",
      "      total_loss: 148.46292114257812\n",
      "      vf_explained_var: 0.4008360505104065\n",
      "      vf_loss: 148.46485900878906\n",
      "    sample_time_ms: 20338.718\n",
      "    update_time_ms: 7.58\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 26.605774335703938\n",
      "    rl_1: 31.36897068275461\n",
      "  time_since_restore: 403.7548682689667\n",
      "  time_this_iter_s: 23.466617584228516\n",
      "  time_total_s: 403.7548682689667\n",
      "  timestamp: 1550880985\n",
      "  timesteps_since_restore: 170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 170000\n",
      "  training_iteration: 17\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 403 s, 17 iter, 170000 ts, 58 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-16-48\n",
      "  done: false\n",
      "  episode_len_mean: 318.73\n",
      "  episode_reward_max: 217.24857015238325\n",
      "  episode_reward_mean: 65.83919783001187\n",
      "  episode_reward_min: -171.5632427010571\n",
      "  episodes_this_iter: 31\n",
      "  episodes_total: 525\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3270.814\n",
      "    load_time_ms: 2.502\n",
      "    num_steps_sampled: 180000\n",
      "    num_steps_trained: 180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5258789289873675e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.426047682762146\n",
      "      kl: 0.0032778375316411257\n",
      "      policy_loss: -0.002917103935033083\n",
      "      total_loss: 110.41687774658203\n",
      "      vf_explained_var: 0.38948583602905273\n",
      "      vf_loss: 110.41978454589844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.5258789289873675e-06\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4170812368392944\n",
      "      kl: 0.0059306444600224495\n",
      "      policy_loss: -0.003648050595074892\n",
      "      total_loss: 74.26593017578125\n",
      "      vf_explained_var: 0.4462062120437622\n",
      "      vf_loss: 74.26958465576172\n",
      "    sample_time_ms: 20334.1\n",
      "    update_time_ms: 7.885\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 35.40811826062045\n",
      "    rl_1: 30.4310795693914\n",
      "  time_since_restore: 427.1110649108887\n",
      "  time_this_iter_s: 23.356196641921997\n",
      "  time_total_s: 427.1110649108887\n",
      "  timestamp: 1550881008\n",
      "  timesteps_since_restore: 180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 180000\n",
      "  training_iteration: 18\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 427 s, 18 iter, 180000 ts, 65.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-17-12\n",
      "  done: false\n",
      "  episode_len_mean: 285.92\n",
      "  episode_reward_max: 211.2370153478997\n",
      "  episode_reward_mean: 60.9714620330818\n",
      "  episode_reward_min: -177.89501972044874\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 566\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3266.618\n",
      "    load_time_ms: 2.523\n",
      "    num_steps_sampled: 190000\n",
      "    num_steps_trained: 190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.629394644936838e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4526052474975586\n",
      "      kl: 0.003728206269443035\n",
      "      policy_loss: -0.0019505578093230724\n",
      "      total_loss: 254.97605895996094\n",
      "      vf_explained_var: 0.366969496011734\n",
      "      vf_loss: 254.97796630859375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.629394644936838e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4094504117965698\n",
      "      kl: 0.0012203613296151161\n",
      "      policy_loss: -0.001818854478187859\n",
      "      total_loss: 200.0603790283203\n",
      "      vf_explained_var: 0.39431166648864746\n",
      "      vf_loss: 200.06219482421875\n",
      "    sample_time_ms: 20330.111\n",
      "    update_time_ms: 7.769\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.04024364887114\n",
      "    rl_1: 21.93121838421065\n",
      "  time_since_restore: 450.88416290283203\n",
      "  time_this_iter_s: 23.77309799194336\n",
      "  time_total_s: 450.88416290283203\n",
      "  timestamp: 1550881032\n",
      "  timesteps_since_restore: 190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 190000\n",
      "  training_iteration: 19\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 450 s, 19 iter, 190000 ts, 61 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-17-35\n",
      "  done: false\n",
      "  episode_len_mean: 254.06\n",
      "  episode_reward_max: 211.2370153478997\n",
      "  episode_reward_mean: 49.256519552869385\n",
      "  episode_reward_min: -177.89501972044874\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 608\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3263.241\n",
      "    load_time_ms: 2.497\n",
      "    num_steps_sampled: 200000\n",
      "    num_steps_trained: 200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.814697322468419e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4443562030792236\n",
      "      kl: 0.003174273297190666\n",
      "      policy_loss: -0.0019141527591273189\n",
      "      total_loss: 239.689697265625\n",
      "      vf_explained_var: 0.42292436957359314\n",
      "      vf_loss: 239.691650390625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.814697322468419e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3940138816833496\n",
      "      kl: 0.003392104059457779\n",
      "      policy_loss: -0.0014748258981853724\n",
      "      total_loss: 172.990966796875\n",
      "      vf_explained_var: 0.4437248408794403\n",
      "      vf_loss: 172.99244689941406\n",
      "    sample_time_ms: 20271.526\n",
      "    update_time_ms: 7.752\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 34.761916822498705\n",
      "    rl_1: 14.494602730370675\n",
      "  time_since_restore: 474.20543456077576\n",
      "  time_this_iter_s: 23.321271657943726\n",
      "  time_total_s: 474.20543456077576\n",
      "  timestamp: 1550881055\n",
      "  timesteps_since_restore: 200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 200000\n",
      "  training_iteration: 20\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 474 s, 20 iter, 200000 ts, 49.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-17-59\n",
      "  done: false\n",
      "  episode_len_mean: 262.86\n",
      "  episode_reward_max: 211.2370153478997\n",
      "  episode_reward_mean: 56.87875094357137\n",
      "  episode_reward_min: -177.89501972044874\n",
      "  episodes_this_iter: 33\n",
      "  episodes_total: 641\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3250.57\n",
      "    load_time_ms: 2.428\n",
      "    num_steps_sampled: 210000\n",
      "    num_steps_trained: 210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.9073486612342094e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4418972730636597\n",
      "      kl: 0.004016150254756212\n",
      "      policy_loss: -0.003230200381949544\n",
      "      total_loss: 127.70339965820312\n",
      "      vf_explained_var: 0.56322181224823\n",
      "      vf_loss: 127.70659637451172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.9073486612342094e-07\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4155442714691162\n",
      "      kl: 0.002918271580711007\n",
      "      policy_loss: -0.0020272883120924234\n",
      "      total_loss: 75.86569213867188\n",
      "      vf_explained_var: 0.5644587278366089\n",
      "      vf_loss: 75.86771392822266\n",
      "    sample_time_ms: 20252.026\n",
      "    update_time_ms: 7.72\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 37.062918415647715\n",
      "    rl_1: 19.815832527923643\n",
      "  time_since_restore: 497.66235399246216\n",
      "  time_this_iter_s: 23.4569194316864\n",
      "  time_total_s: 497.66235399246216\n",
      "  timestamp: 1550881079\n",
      "  timesteps_since_restore: 210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 210000\n",
      "  training_iteration: 21\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 497 s, 21 iter, 210000 ts, 56.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-18-22\n",
      "  done: false\n",
      "  episode_len_mean: 255.31\n",
      "  episode_reward_max: 209.20195266554293\n",
      "  episode_reward_mean: 82.29481893666699\n",
      "  episode_reward_min: -172.6431833842239\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 685\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3251.183\n",
      "    load_time_ms: 2.484\n",
      "    num_steps_sampled: 220000\n",
      "    num_steps_trained: 220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.536743306171047e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4509203433990479\n",
      "      kl: 0.001329289167188108\n",
      "      policy_loss: -0.0007530126022174954\n",
      "      total_loss: 202.78456115722656\n",
      "      vf_explained_var: 0.5262331366539001\n",
      "      vf_loss: 202.78530883789062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 9.536743306171047e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4041802883148193\n",
      "      kl: 0.002680379431694746\n",
      "      policy_loss: -0.0011234722333028913\n",
      "      total_loss: 72.86296844482422\n",
      "      vf_explained_var: 0.48538094758987427\n",
      "      vf_loss: 72.86408996582031\n",
      "    sample_time_ms: 20190.242\n",
      "    update_time_ms: 7.709\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.871665531356456\n",
      "    rl_1: 25.423153405310508\n",
      "  time_since_restore: 521.2854039669037\n",
      "  time_this_iter_s: 23.62304997444153\n",
      "  time_total_s: 521.2854039669037\n",
      "  timestamp: 1550881102\n",
      "  timesteps_since_restore: 220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 220000\n",
      "  training_iteration: 22\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 521 s, 22 iter, 220000 ts, 82.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-18-46\n",
      "  done: false\n",
      "  episode_len_mean: 242.72\n",
      "  episode_reward_max: 199.2166230319903\n",
      "  episode_reward_mean: 102.22968121501162\n",
      "  episode_reward_min: -183.140928751687\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 727\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3250.569\n",
      "    load_time_ms: 2.522\n",
      "    num_steps_sampled: 230000\n",
      "    num_steps_trained: 230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.7683716530855236e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.440940022468567\n",
      "      kl: 0.009167343378067017\n",
      "      policy_loss: -0.0038323046173900366\n",
      "      total_loss: 176.2301788330078\n",
      "      vf_explained_var: 0.5883383750915527\n",
      "      vf_loss: 176.23399353027344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.7683716530855236e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4118138551712036\n",
      "      kl: 0.004007021430879831\n",
      "      policy_loss: -0.0018225357634946704\n",
      "      total_loss: 87.63134002685547\n",
      "      vf_explained_var: 0.5061177015304565\n",
      "      vf_loss: 87.6331558227539\n",
      "    sample_time_ms: 20283.155\n",
      "    update_time_ms: 7.698\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.65741177490905\n",
      "    rl_1: 31.572269440102577\n",
      "  time_since_restore: 545.1399328708649\n",
      "  time_this_iter_s: 23.85452890396118\n",
      "  time_total_s: 545.1399328708649\n",
      "  timestamp: 1550881126\n",
      "  timesteps_since_restore: 230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 230000\n",
      "  training_iteration: 23\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 545 s, 23 iter, 230000 ts, 102 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-19-10\n",
      "  done: false\n",
      "  episode_len_mean: 222.59\n",
      "  episode_reward_max: 217.5742707864381\n",
      "  episode_reward_mean: 104.58997064178199\n",
      "  episode_reward_min: -183.140928751687\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 774\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3247.407\n",
      "    load_time_ms: 2.455\n",
      "    num_steps_sampled: 240000\n",
      "    num_steps_trained: 240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3841858265427618e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4543765783309937\n",
      "      kl: 0.002136063762009144\n",
      "      policy_loss: -0.002143696416169405\n",
      "      total_loss: 211.89512634277344\n",
      "      vf_explained_var: 0.6083317399024963\n",
      "      vf_loss: 211.8972930908203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.3841858265427618e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4129050970077515\n",
      "      kl: 0.0019509620033204556\n",
      "      policy_loss: -0.0010783206671476364\n",
      "      total_loss: 87.89437103271484\n",
      "      vf_explained_var: 0.5342251658439636\n",
      "      vf_loss: 87.89544677734375\n",
      "    sample_time_ms: 20293.704\n",
      "    update_time_ms: 6.99\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.60429493694579\n",
      "    rl_1: 28.985675704836225\n",
      "  time_since_restore: 569.0170774459839\n",
      "  time_this_iter_s: 23.87714457511902\n",
      "  time_total_s: 569.0170774459839\n",
      "  timestamp: 1550881150\n",
      "  timesteps_since_restore: 240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 240000\n",
      "  training_iteration: 24\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 569 s, 24 iter, 240000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-19-34\n",
      "  done: false\n",
      "  episode_len_mean: 218.07\n",
      "  episode_reward_max: 217.5742707864381\n",
      "  episode_reward_mean: 122.62047781001533\n",
      "  episode_reward_min: -151.10609299527448\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 821\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3245.769\n",
      "    load_time_ms: 2.489\n",
      "    num_steps_sampled: 250000\n",
      "    num_steps_trained: 250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1920929132713809e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4461814165115356\n",
      "      kl: 0.0037622659001499414\n",
      "      policy_loss: -0.0012750530149787664\n",
      "      total_loss: 172.09487915039062\n",
      "      vf_explained_var: 0.6570449471473694\n",
      "      vf_loss: 172.09616088867188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.1920929132713809e-08\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.377126693725586\n",
      "      kl: 0.008060760796070099\n",
      "      policy_loss: -0.003102715127170086\n",
      "      total_loss: 61.23787307739258\n",
      "      vf_explained_var: 0.5431206226348877\n",
      "      vf_loss: 61.24097442626953\n",
      "    sample_time_ms: 20300.667\n",
      "    update_time_ms: 7.148\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.94190834696545\n",
      "    rl_1: 36.67856946304988\n",
      "  time_since_restore: 592.7769169807434\n",
      "  time_this_iter_s: 23.75983953475952\n",
      "  time_total_s: 592.7769169807434\n",
      "  timestamp: 1550881174\n",
      "  timesteps_since_restore: 250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 250000\n",
      "  training_iteration: 25\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 592 s, 25 iter, 250000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-19-58\n",
      "  done: false\n",
      "  episode_len_mean: 206.28\n",
      "  episode_reward_max: 214.22021984360572\n",
      "  episode_reward_mean: 114.13327872720949\n",
      "  episode_reward_min: -180.01135697062915\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 871\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3246.284\n",
      "    load_time_ms: 2.426\n",
      "    num_steps_sampled: 260000\n",
      "    num_steps_trained: 260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.9604645663569045e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.441886067390442\n",
      "      kl: 0.004866017960011959\n",
      "      policy_loss: -0.0030071884393692017\n",
      "      total_loss: 238.5518798828125\n",
      "      vf_explained_var: 0.567109227180481\n",
      "      vf_loss: 238.5548553466797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.9604645663569045e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.395749807357788\n",
      "      kl: 0.005033912602812052\n",
      "      policy_loss: -0.002254009712487459\n",
      "      total_loss: 128.7373046875\n",
      "      vf_explained_var: 0.5015495419502258\n",
      "      vf_loss: 128.73951721191406\n",
      "    sample_time_ms: 20345.749\n",
      "    update_time_ms: 7.353\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.82114890718702\n",
      "    rl_1: 34.31212982002245\n",
      "  time_since_restore: 616.47127866745\n",
      "  time_this_iter_s: 23.694361686706543\n",
      "  time_total_s: 616.47127866745\n",
      "  timestamp: 1550881198\n",
      "  timesteps_since_restore: 260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 260000\n",
      "  training_iteration: 26\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 616 s, 26 iter, 260000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-20-22\n",
      "  done: false\n",
      "  episode_len_mean: 194.27\n",
      "  episode_reward_max: 208.17120304922915\n",
      "  episode_reward_mean: 92.99157564322985\n",
      "  episode_reward_min: -184.80681948289578\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 924\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3244.618\n",
      "    load_time_ms: 2.426\n",
      "    num_steps_sampled: 270000\n",
      "    num_steps_trained: 270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9802322831784522e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4431002140045166\n",
      "      kl: 0.0012637743493542075\n",
      "      policy_loss: -0.0008745138184167445\n",
      "      total_loss: 257.6013488769531\n",
      "      vf_explained_var: 0.585756242275238\n",
      "      vf_loss: 257.60223388671875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.9802322831784522e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.365500807762146\n",
      "      kl: 0.0059467763639986515\n",
      "      policy_loss: -0.0031998406630009413\n",
      "      total_loss: 140.96334838867188\n",
      "      vf_explained_var: 0.5643507242202759\n",
      "      vf_loss: 140.96658325195312\n",
      "    sample_time_ms: 20389.806\n",
      "    update_time_ms: 7.344\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.3205142284979\n",
      "    rl_1: 26.67106141473195\n",
      "  time_since_restore: 640.3623685836792\n",
      "  time_this_iter_s: 23.891089916229248\n",
      "  time_total_s: 640.3623685836792\n",
      "  timestamp: 1550881222\n",
      "  timesteps_since_restore: 270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 270000\n",
      "  training_iteration: 27\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 640 s, 27 iter, 270000 ts, 93 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-20-46\n",
      "  done: false\n",
      "  episode_len_mean: 196.29\n",
      "  episode_reward_max: 211.55395653818383\n",
      "  episode_reward_mean: 91.8279555142939\n",
      "  episode_reward_min: -184.80681948289578\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 974\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3241.036\n",
      "    load_time_ms: 2.419\n",
      "    num_steps_sampled: 280000\n",
      "    num_steps_trained: 280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4901161415892261e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4505950212478638\n",
      "      kl: 0.001831526169553399\n",
      "      policy_loss: -0.00048023872659541667\n",
      "      total_loss: 216.04319763183594\n",
      "      vf_explained_var: 0.5867494940757751\n",
      "      vf_loss: 216.04367065429688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.4901161415892261e-09\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3932499885559082\n",
      "      kl: 0.003281294833868742\n",
      "      policy_loss: -0.0017801171634346247\n",
      "      total_loss: 106.87721252441406\n",
      "      vf_explained_var: 0.6078530550003052\n",
      "      vf_loss: 106.87899017333984\n",
      "    sample_time_ms: 20437.93\n",
      "    update_time_ms: 7.261\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.2830573157555\n",
      "    rl_1: 27.544898198538394\n",
      "  time_since_restore: 664.1653878688812\n",
      "  time_this_iter_s: 23.803019285202026\n",
      "  time_total_s: 664.1653878688812\n",
      "  timestamp: 1550881246\n",
      "  timesteps_since_restore: 280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 280000\n",
      "  training_iteration: 28\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 664 s, 28 iter, 280000 ts, 91.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-21-10\n",
      "  done: false\n",
      "  episode_len_mean: 204.47\n",
      "  episode_reward_max: 211.55395653818383\n",
      "  episode_reward_mean: 93.23297280433904\n",
      "  episode_reward_min: -180.81216930273956\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 1022\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3238.336\n",
      "    load_time_ms: 2.406\n",
      "    num_steps_sampled: 290000\n",
      "    num_steps_trained: 290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.450580707946131e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4392452239990234\n",
      "      kl: 0.0016547534614801407\n",
      "      policy_loss: -0.0008252125699073076\n",
      "      total_loss: 239.8282928466797\n",
      "      vf_explained_var: 0.5937840938568115\n",
      "      vf_loss: 239.82913208007812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.450580707946131e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4203662872314453\n",
      "      kl: 0.0026008065324276686\n",
      "      policy_loss: -0.0022298276890069246\n",
      "      total_loss: 125.96004486083984\n",
      "      vf_explained_var: 0.6052173972129822\n",
      "      vf_loss: 125.96228790283203\n",
      "    sample_time_ms: 20476.058\n",
      "    update_time_ms: 7.214\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.1776739825556\n",
      "    rl_1: 28.05529882178342\n",
      "  time_since_restore: 688.2963807582855\n",
      "  time_this_iter_s: 24.130992889404297\n",
      "  time_total_s: 688.2963807582855\n",
      "  timestamp: 1550881270\n",
      "  timesteps_since_restore: 290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 290000\n",
      "  training_iteration: 29\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 688 s, 29 iter, 290000 ts, 93.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-21-33\n",
      "  done: false\n",
      "  episode_len_mean: 213.85\n",
      "  episode_reward_max: 211.55395653818383\n",
      "  episode_reward_mean: 97.6093677358442\n",
      "  episode_reward_min: -180.81216930273956\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 1067\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3237.93\n",
      "    load_time_ms: 2.431\n",
      "    num_steps_sampled: 300000\n",
      "    num_steps_trained: 300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.7252903539730653e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4159560203552246\n",
      "      kl: 0.0033431334886699915\n",
      "      policy_loss: -0.001336504239588976\n",
      "      total_loss: 192.185546875\n",
      "      vf_explained_var: 0.6469511985778809\n",
      "      vf_loss: 192.1868896484375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.7252903539730653e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.360599398612976\n",
      "      kl: 0.003346183802932501\n",
      "      policy_loss: -0.0022673949133604765\n",
      "      total_loss: 107.34683227539062\n",
      "      vf_explained_var: 0.6258114576339722\n",
      "      vf_loss: 107.34910583496094\n",
      "    sample_time_ms: 20498.17\n",
      "    update_time_ms: 7.234\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.46688974933733\n",
      "    rl_1: 32.14247798650686\n",
      "  time_since_restore: 711.8377304077148\n",
      "  time_this_iter_s: 23.54134964942932\n",
      "  time_total_s: 711.8377304077148\n",
      "  timestamp: 1550881293\n",
      "  timesteps_since_restore: 300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 300000\n",
      "  training_iteration: 30\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 711 s, 30 iter, 300000 ts, 97.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-21-57\n",
      "  done: false\n",
      "  episode_len_mean: 205.48\n",
      "  episode_reward_max: 205.3879470254575\n",
      "  episode_reward_mean: 116.54916352748731\n",
      "  episode_reward_min: -165.1894730752573\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 1119\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3239.913\n",
      "    load_time_ms: 2.494\n",
      "    num_steps_sampled: 310000\n",
      "    num_steps_trained: 310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8626451769865326e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4240995645523071\n",
      "      kl: 0.01129009760916233\n",
      "      policy_loss: -0.0054342010989785194\n",
      "      total_loss: 257.8995056152344\n",
      "      vf_explained_var: 0.6186007261276245\n",
      "      vf_loss: 257.9049377441406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.8626451769865326e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3723125457763672\n",
      "      kl: 0.0014316791202872992\n",
      "      policy_loss: -0.00197513191960752\n",
      "      total_loss: 126.95230102539062\n",
      "      vf_explained_var: 0.5621786117553711\n",
      "      vf_loss: 126.95425415039062\n",
      "    sample_time_ms: 20525.807\n",
      "    update_time_ms: 7.312\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.52701015929647\n",
      "    rl_1: 40.02215336819083\n",
      "  time_since_restore: 735.5942327976227\n",
      "  time_this_iter_s: 23.756502389907837\n",
      "  time_total_s: 735.5942327976227\n",
      "  timestamp: 1550881317\n",
      "  timesteps_since_restore: 310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 310000\n",
      "  training_iteration: 31\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 735 s, 31 iter, 310000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-22-21\n",
      "  done: false\n",
      "  episode_len_mean: 188.79\n",
      "  episode_reward_max: 205.3879470254575\n",
      "  episode_reward_mean: 109.8672702614798\n",
      "  episode_reward_min: -185.68263754353228\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 1174\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3236.711\n",
      "    load_time_ms: 2.468\n",
      "    num_steps_sampled: 320000\n",
      "    num_steps_trained: 320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8626451769865326e-10\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4114903211593628\n",
      "      kl: 0.0038843429647386074\n",
      "      policy_loss: -0.0015861139399930835\n",
      "      total_loss: 236.52410888671875\n",
      "      vf_explained_var: 0.68110191822052\n",
      "      vf_loss: 236.52569580078125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 9.313225884932663e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.389498233795166\n",
      "      kl: 0.007624025456607342\n",
      "      policy_loss: -0.003233684226870537\n",
      "      total_loss: 121.06293487548828\n",
      "      vf_explained_var: 0.5784212350845337\n",
      "      vf_loss: 121.06616973876953\n",
      "    sample_time_ms: 20557.239\n",
      "    update_time_ms: 7.359\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 73.98096856932202\n",
      "    rl_1: 35.88630169215783\n",
      "  time_since_restore: 759.5009622573853\n",
      "  time_this_iter_s: 23.906729459762573\n",
      "  time_total_s: 759.5009622573853\n",
      "  timestamp: 1550881341\n",
      "  timesteps_since_restore: 320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 320000\n",
      "  training_iteration: 32\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 759 s, 32 iter, 320000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-22-44\n",
      "  done: false\n",
      "  episode_len_mean: 180.99\n",
      "  episode_reward_max: 183.79413430776478\n",
      "  episode_reward_mean: 95.51217157307447\n",
      "  episode_reward_min: -185.68263754353228\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 1229\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3238.528\n",
      "    load_time_ms: 2.421\n",
      "    num_steps_sampled: 330000\n",
      "    num_steps_trained: 330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.313225884932663e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.41600501537323\n",
      "      kl: 0.00430508004501462\n",
      "      policy_loss: -0.002442422090098262\n",
      "      total_loss: 227.3389892578125\n",
      "      vf_explained_var: 0.7272010445594788\n",
      "      vf_loss: 227.34141540527344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.6566129424663316e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4031016826629639\n",
      "      kl: 0.005025018006563187\n",
      "      policy_loss: -0.004088403657078743\n",
      "      total_loss: 99.93433380126953\n",
      "      vf_explained_var: 0.6445149183273315\n",
      "      vf_loss: 99.93841552734375\n",
      "    sample_time_ms: 20498.17\n",
      "    update_time_ms: 8.071\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.09536792257393\n",
      "    rl_1: 28.41680365050056\n",
      "  time_since_restore: 782.7886924743652\n",
      "  time_this_iter_s: 23.28773021697998\n",
      "  time_total_s: 782.7886924743652\n",
      "  timestamp: 1550881364\n",
      "  timesteps_since_restore: 330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 330000\n",
      "  training_iteration: 33\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 782 s, 33 iter, 330000 ts, 95.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-23-08\n",
      "  done: false\n",
      "  episode_len_mean: 186.97\n",
      "  episode_reward_max: 194.55015353671996\n",
      "  episode_reward_mean: 109.93438277465282\n",
      "  episode_reward_min: -181.03022379493814\n",
      "  episodes_this_iter: 52\n",
      "  episodes_total: 1281\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3238.453\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 340000\n",
      "    num_steps_trained: 340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.6566129424663316e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.400782823562622\n",
      "      kl: 0.008475656621158123\n",
      "      policy_loss: -0.0037447642534971237\n",
      "      total_loss: 194.42417907714844\n",
      "      vf_explained_var: 0.7357674837112427\n",
      "      vf_loss: 194.42791748046875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.3283064712331658e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3963792324066162\n",
      "      kl: 0.006146655417978764\n",
      "      policy_loss: -0.0031242782715708017\n",
      "      total_loss: 54.93893814086914\n",
      "      vf_explained_var: 0.6126707196235657\n",
      "      vf_loss: 54.94206237792969\n",
      "    sample_time_ms: 20446.677\n",
      "    update_time_ms: 8.026\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.34864202610515\n",
      "    rl_1: 32.58574074854767\n",
      "  time_since_restore: 806.1484279632568\n",
      "  time_this_iter_s: 23.3597354888916\n",
      "  time_total_s: 806.1484279632568\n",
      "  timestamp: 1550881388\n",
      "  timesteps_since_restore: 340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 340000\n",
      "  training_iteration: 34\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 3.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 806 s, 34 iter, 340000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-23-32\n",
      "  done: false\n",
      "  episode_len_mean: 195.09\n",
      "  episode_reward_max: 194.55015353671996\n",
      "  episode_reward_mean: 109.94031918802045\n",
      "  episode_reward_min: -184.68931254095526\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 1332\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3237.829\n",
      "    load_time_ms: 2.446\n",
      "    num_steps_sampled: 350000\n",
      "    num_steps_trained: 350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3283064712331658e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3986058235168457\n",
      "      kl: 0.00550841772928834\n",
      "      policy_loss: -0.0022649578750133514\n",
      "      total_loss: 222.3424530029297\n",
      "      vf_explained_var: 0.7536980509757996\n",
      "      vf_loss: 222.3447265625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.1641532356165829e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4043701887130737\n",
      "      kl: 0.002303661545738578\n",
      "      policy_loss: -0.001823464990593493\n",
      "      total_loss: 125.22737884521484\n",
      "      vf_explained_var: 0.5611749291419983\n",
      "      vf_loss: 125.22920227050781\n",
      "    sample_time_ms: 20454.85\n",
      "    update_time_ms: 8.058\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.81566140797386\n",
      "    rl_1: 35.12465778004658\n",
      "  time_since_restore: 829.9835391044617\n",
      "  time_this_iter_s: 23.835111141204834\n",
      "  time_total_s: 829.9835391044617\n",
      "  timestamp: 1550881412\n",
      "  timesteps_since_restore: 350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 350000\n",
      "  training_iteration: 35\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 829 s, 35 iter, 350000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-23-56\n",
      "  done: false\n",
      "  episode_len_mean: 182.3\n",
      "  episode_reward_max: 186.15499360208855\n",
      "  episode_reward_mean: 104.73535120545232\n",
      "  episode_reward_min: -184.68931254095526\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1390\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3237.232\n",
      "    load_time_ms: 2.456\n",
      "    num_steps_sampled: 360000\n",
      "    num_steps_trained: 360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1641532356165829e-11\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3909262418746948\n",
      "      kl: 0.00628823833540082\n",
      "      policy_loss: -0.0019191192695870996\n",
      "      total_loss: 223.0769805908203\n",
      "      vf_explained_var: 0.7295913696289062\n",
      "      vf_loss: 223.0789337158203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.8207661780829145e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.387351393699646\n",
      "      kl: 0.001426976639777422\n",
      "      policy_loss: -0.0015797968953847885\n",
      "      total_loss: 89.82168579101562\n",
      "      vf_explained_var: 0.6110589504241943\n",
      "      vf_loss: 89.8232650756836\n",
      "    sample_time_ms: 20468.939\n",
      "    update_time_ms: 7.969\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.326124908323\n",
      "    rl_1: 30.40922629712931\n",
      "  time_since_restore: 853.8138520717621\n",
      "  time_this_iter_s: 23.830312967300415\n",
      "  time_total_s: 853.8138520717621\n",
      "  timestamp: 1550881436\n",
      "  timesteps_since_restore: 360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 360000\n",
      "  training_iteration: 36\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 853 s, 36 iter, 360000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-24-20\n",
      "  done: false\n",
      "  episode_len_mean: 174.28\n",
      "  episode_reward_max: 190.23185003187575\n",
      "  episode_reward_mean: 122.76440407777889\n",
      "  episode_reward_min: -182.4410232140694\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 1446\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3238.823\n",
      "    load_time_ms: 2.467\n",
      "    num_steps_sampled: 370000\n",
      "    num_steps_trained: 370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.8207661780829145e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3955672979354858\n",
      "      kl: 0.006185954436659813\n",
      "      policy_loss: -0.002120411954820156\n",
      "      total_loss: 203.1456756591797\n",
      "      vf_explained_var: 0.7829961180686951\n",
      "      vf_loss: 203.14781188964844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.9103830890414573e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4000824689865112\n",
      "      kl: 0.002526662778109312\n",
      "      policy_loss: -0.0013655155198648572\n",
      "      total_loss: 71.3028793334961\n",
      "      vf_explained_var: 0.6025533676147461\n",
      "      vf_loss: 71.30423736572266\n",
      "    sample_time_ms: 20480.026\n",
      "    update_time_ms: 7.961\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.8951610785794\n",
      "    rl_1: 35.86924299919947\n",
      "  time_since_restore: 877.8324682712555\n",
      "  time_this_iter_s: 24.018616199493408\n",
      "  time_total_s: 877.8324682712555\n",
      "  timestamp: 1550881460\n",
      "  timesteps_since_restore: 370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 370000\n",
      "  training_iteration: 37\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 877 s, 37 iter, 370000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-24-43\n",
      "  done: false\n",
      "  episode_len_mean: 173.95\n",
      "  episode_reward_max: 190.23185003187575\n",
      "  episode_reward_mean: 122.63131866998572\n",
      "  episode_reward_min: -178.94357854630175\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1506\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3240.797\n",
      "    load_time_ms: 2.534\n",
      "    num_steps_sampled: 380000\n",
      "    num_steps_trained: 380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.9103830890414573e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4002431631088257\n",
      "      kl: 0.006244119722396135\n",
      "      policy_loss: -0.0022912879940122366\n",
      "      total_loss: 218.86383056640625\n",
      "      vf_explained_var: 0.7918210029602051\n",
      "      vf_loss: 218.86610412597656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.4551915445207286e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4364808797836304\n",
      "      kl: 0.0022414764389395714\n",
      "      policy_loss: -0.0022457512095570564\n",
      "      total_loss: 81.30221557617188\n",
      "      vf_explained_var: 0.6557698249816895\n",
      "      vf_loss: 81.30445861816406\n",
      "    sample_time_ms: 20465.744\n",
      "    update_time_ms: 7.76\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.4410035961087\n",
      "    rl_1: 36.190315073877066\n",
      "  time_since_restore: 901.5088534355164\n",
      "  time_this_iter_s: 23.676385164260864\n",
      "  time_total_s: 901.5088534355164\n",
      "  timestamp: 1550881483\n",
      "  timesteps_since_restore: 380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 380000\n",
      "  training_iteration: 38\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 901 s, 38 iter, 380000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-25-07\n",
      "  done: false\n",
      "  episode_len_mean: 157.05\n",
      "  episode_reward_max: 181.3901465429585\n",
      "  episode_reward_mean: 119.88203920714919\n",
      "  episode_reward_min: -174.54621595194922\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 1569\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3243.784\n",
      "    load_time_ms: 2.539\n",
      "    num_steps_sampled: 390000\n",
      "    num_steps_trained: 390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4551915445207286e-12\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3803982734680176\n",
      "      kl: 0.007690309546887875\n",
      "      policy_loss: -0.0025089920964092016\n",
      "      total_loss: 207.29103088378906\n",
      "      vf_explained_var: 0.8072265982627869\n",
      "      vf_loss: 207.29356384277344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.275957722603643e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4183357954025269\n",
      "      kl: 0.003026446094736457\n",
      "      policy_loss: -0.0007208117749541998\n",
      "      total_loss: 74.05249786376953\n",
      "      vf_explained_var: 0.6281295418739319\n",
      "      vf_loss: 74.05321502685547\n",
      "    sample_time_ms: 20425.723\n",
      "    update_time_ms: 8.142\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.82421945009922\n",
      "    rl_1: 31.057819757049966\n",
      "  time_since_restore: 925.2708752155304\n",
      "  time_this_iter_s: 23.762021780014038\n",
      "  time_total_s: 925.2708752155304\n",
      "  timestamp: 1550881507\n",
      "  timesteps_since_restore: 390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 390000\n",
      "  training_iteration: 39\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 925 s, 39 iter, 390000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-25-31\n",
      "  done: false\n",
      "  episode_len_mean: 159.98\n",
      "  episode_reward_max: 179.8337410508864\n",
      "  episode_reward_mean: 117.55896690797056\n",
      "  episode_reward_min: -174.54621595194922\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 1632\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3245.286\n",
      "    load_time_ms: 2.518\n",
      "    num_steps_sampled: 400000\n",
      "    num_steps_trained: 400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.275957722603643e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.389387607574463\n",
      "      kl: 0.0025914099533110857\n",
      "      policy_loss: -0.0017558932304382324\n",
      "      total_loss: 230.19729614257812\n",
      "      vf_explained_var: 0.82518070936203\n",
      "      vf_loss: 230.1990509033203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.6379788613018216e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3593722581863403\n",
      "      kl: 0.0010324607137590647\n",
      "      policy_loss: -0.0008225144702009857\n",
      "      total_loss: 98.27320861816406\n",
      "      vf_explained_var: 0.7372733354568481\n",
      "      vf_loss: 98.2740249633789\n",
      "    sample_time_ms: 20489.975\n",
      "    update_time_ms: 8.285\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.38754833740822\n",
      "    rl_1: 30.17141857056231\n",
      "  time_since_restore: 949.4714703559875\n",
      "  time_this_iter_s: 24.200595140457153\n",
      "  time_total_s: 949.4714703559875\n",
      "  timestamp: 1550881531\n",
      "  timesteps_since_restore: 400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 400000\n",
      "  training_iteration: 40\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 949 s, 40 iter, 400000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-25-56\n",
      "  done: false\n",
      "  episode_len_mean: 157.41\n",
      "  episode_reward_max: 179.8337410508864\n",
      "  episode_reward_mean: 113.54006760036992\n",
      "  episode_reward_min: -178.15767451851696\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 1697\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3242.488\n",
      "    load_time_ms: 2.45\n",
      "    num_steps_sampled: 410000\n",
      "    num_steps_trained: 410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6379788613018216e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3979816436767578\n",
      "      kl: 0.00911557488143444\n",
      "      policy_loss: -0.003540587844327092\n",
      "      total_loss: 179.9800262451172\n",
      "      vf_explained_var: 0.864955484867096\n",
      "      vf_loss: 179.9835662841797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.8189894306509108e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4574544429779053\n",
      "      kl: 0.0028710111510008574\n",
      "      policy_loss: -0.002470135921612382\n",
      "      total_loss: 67.78705596923828\n",
      "      vf_explained_var: 0.7568265199661255\n",
      "      vf_loss: 67.78953552246094\n",
      "    sample_time_ms: 20555.482\n",
      "    update_time_ms: 8.311\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.16267053297184\n",
      "    rl_1: 29.37739706739806\n",
      "  time_since_restore: 973.8536629676819\n",
      "  time_this_iter_s: 24.382192611694336\n",
      "  time_total_s: 973.8536629676819\n",
      "  timestamp: 1550881556\n",
      "  timesteps_since_restore: 410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 410000\n",
      "  training_iteration: 41\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 973 s, 41 iter, 410000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-26-20\n",
      "  done: false\n",
      "  episode_len_mean: 149.93\n",
      "  episode_reward_max: 178.3161501746697\n",
      "  episode_reward_mean: 99.69637742584959\n",
      "  episode_reward_min: -178.15767451851696\n",
      "  episodes_this_iter: 67\n",
      "  episodes_total: 1764\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3249.857\n",
      "    load_time_ms: 2.418\n",
      "    num_steps_sampled: 420000\n",
      "    num_steps_trained: 420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8189894306509108e-13\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.373557448387146\n",
      "      kl: 0.005879302974790335\n",
      "      policy_loss: -0.0020972315687686205\n",
      "      total_loss: 286.893310546875\n",
      "      vf_explained_var: 0.7788823246955872\n",
      "      vf_loss: 286.8953552246094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 9.094947153254554e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3754711151123047\n",
      "      kl: 0.0012342995032668114\n",
      "      policy_loss: -0.0016674933722242713\n",
      "      total_loss: 145.42616271972656\n",
      "      vf_explained_var: 0.6932359337806702\n",
      "      vf_loss: 145.42784118652344\n",
      "    sample_time_ms: 20512.693\n",
      "    update_time_ms: 8.178\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.98001302540868\n",
      "    rl_1: 22.716364400440895\n",
      "  time_since_restore: 997.4050209522247\n",
      "  time_this_iter_s: 23.551357984542847\n",
      "  time_total_s: 997.4050209522247\n",
      "  timestamp: 1550881580\n",
      "  timesteps_since_restore: 420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 420000\n",
      "  training_iteration: 42\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 997 s, 42 iter, 420000 ts, 99.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 142.31\n",
      "  episode_reward_max: 182.44113851775455\n",
      "  episode_reward_mean: 102.56330070094269\n",
      "  episode_reward_min: -189.31585511598723\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 1832\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3249.839\n",
      "    load_time_ms: 2.407\n",
      "    num_steps_sampled: 430000\n",
      "    num_steps_trained: 430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.094947153254554e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.397634744644165\n",
      "      kl: 0.006206169258803129\n",
      "      policy_loss: -0.0018125004135072231\n",
      "      total_loss: 262.4436340332031\n",
      "      vf_explained_var: 0.8118297457695007\n",
      "      vf_loss: 262.4454650878906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.547473576627277e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4192874431610107\n",
      "      kl: 0.004439073149114847\n",
      "      policy_loss: -0.003099289955571294\n",
      "      total_loss: 94.7007064819336\n",
      "      vf_explained_var: 0.7493756413459778\n",
      "      vf_loss: 94.70379638671875\n",
      "    sample_time_ms: 20674.588\n",
      "    update_time_ms: 7.41\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.27494922710929\n",
      "    rl_1: 22.288351473833426\n",
      "  time_since_restore: 1022.305438041687\n",
      "  time_this_iter_s: 24.90041708946228\n",
      "  time_total_s: 1022.305438041687\n",
      "  timestamp: 1550881604\n",
      "  timesteps_since_restore: 430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 430000\n",
      "  training_iteration: 43\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1022 s, 43 iter, 430000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-27-08\n",
      "  done: false\n",
      "  episode_len_mean: 150.75\n",
      "  episode_reward_max: 182.44113851775455\n",
      "  episode_reward_mean: 115.08843388266338\n",
      "  episode_reward_min: -189.31585511598723\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 1897\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3251.665\n",
      "    load_time_ms: 2.467\n",
      "    num_steps_sampled: 440000\n",
      "    num_steps_trained: 440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.547473576627277e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3841512203216553\n",
      "      kl: 0.0036682651843875647\n",
      "      policy_loss: -0.002952344948425889\n",
      "      total_loss: 230.43467712402344\n",
      "      vf_explained_var: 0.8535365462303162\n",
      "      vf_loss: 230.43765258789062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4310964345932007\n",
      "      kl: 0.0019364971667528152\n",
      "      policy_loss: -0.0021700134966522455\n",
      "      total_loss: 71.7281723022461\n",
      "      vf_explained_var: 0.7560284733772278\n",
      "      vf_loss: 71.73033142089844\n",
      "    sample_time_ms: 20704.332\n",
      "    update_time_ms: 7.553\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.28881834982414\n",
      "    rl_1: 28.799615532839262\n",
      "  time_since_restore: 1045.9886190891266\n",
      "  time_this_iter_s: 23.683181047439575\n",
      "  time_total_s: 1045.9886190891266\n",
      "  timestamp: 1550881628\n",
      "  timesteps_since_restore: 440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 440000\n",
      "  training_iteration: 44\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1045 s, 44 iter, 440000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-27-32\n",
      "  done: false\n",
      "  episode_len_mean: 155.42\n",
      "  episode_reward_max: 173.55049460435433\n",
      "  episode_reward_mean: 123.19799347863733\n",
      "  episode_reward_min: -187.41309548272062\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 1963\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3252.765\n",
      "    load_time_ms: 2.461\n",
      "    num_steps_sampled: 450000\n",
      "    num_steps_trained: 450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2737367883136385e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3674184083938599\n",
      "      kl: 0.009635932743549347\n",
      "      policy_loss: -0.003882280085235834\n",
      "      total_loss: 195.08572387695312\n",
      "      vf_explained_var: 0.8734028339385986\n",
      "      vf_loss: 195.08961486816406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.1368683941568192e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4406299591064453\n",
      "      kl: 0.0029741134494543076\n",
      "      policy_loss: -0.003034300170838833\n",
      "      total_loss: 71.50431060791016\n",
      "      vf_explained_var: 0.7755376100540161\n",
      "      vf_loss: 71.50733947753906\n",
      "    sample_time_ms: 20721.767\n",
      "    update_time_ms: 7.554\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.49648890113082\n",
      "    rl_1: 32.701504577506526\n",
      "  time_since_restore: 1070.013972043991\n",
      "  time_this_iter_s: 24.025352954864502\n",
      "  time_total_s: 1070.013972043991\n",
      "  timestamp: 1550881652\n",
      "  timesteps_since_restore: 450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 450000\n",
      "  training_iteration: 45\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1070 s, 45 iter, 450000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-27-56\n",
      "  done: false\n",
      "  episode_len_mean: 146.83\n",
      "  episode_reward_max: 182.1448441691749\n",
      "  episode_reward_mean: 121.5094470725843\n",
      "  episode_reward_min: -178.3577016662027\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 2032\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3255.49\n",
      "    load_time_ms: 2.465\n",
      "    num_steps_sampled: 460000\n",
      "    num_steps_trained: 460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1368683941568192e-14\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.371103286743164\n",
      "      kl: 0.0035024385433644056\n",
      "      policy_loss: -0.0017904588021337986\n",
      "      total_loss: 197.04608154296875\n",
      "      vf_explained_var: 0.8491552472114563\n",
      "      vf_loss: 197.04788208007812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.684341970784096e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3766101598739624\n",
      "      kl: 0.004317765589803457\n",
      "      policy_loss: -0.002328794449567795\n",
      "      total_loss: 86.31593322753906\n",
      "      vf_explained_var: 0.7890092134475708\n",
      "      vf_loss: 86.31826782226562\n",
      "    sample_time_ms: 20731.699\n",
      "    update_time_ms: 7.533\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.06729771424847\n",
      "    rl_1: 30.442149358335787\n",
      "  time_since_restore: 1093.9710760116577\n",
      "  time_this_iter_s: 23.957103967666626\n",
      "  time_total_s: 1093.9710760116577\n",
      "  timestamp: 1550881676\n",
      "  timesteps_since_restore: 460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 460000\n",
      "  training_iteration: 46\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1093 s, 46 iter, 460000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-28-20\n",
      "  done: false\n",
      "  episode_len_mean: 143.3\n",
      "  episode_reward_max: 182.1448441691749\n",
      "  episode_reward_mean: 119.3781467708269\n",
      "  episode_reward_min: -174.15428546541864\n",
      "  episodes_this_iter: 71\n",
      "  episodes_total: 2103\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3257.553\n",
      "    load_time_ms: 2.482\n",
      "    num_steps_sampled: 470000\n",
      "    num_steps_trained: 470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.684341970784096e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3659265041351318\n",
      "      kl: 0.007473936304450035\n",
      "      policy_loss: -0.0035647733602672815\n",
      "      total_loss: 216.35231018066406\n",
      "      vf_explained_var: 0.8512834310531616\n",
      "      vf_loss: 216.35586547851562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.842170985392048e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.430828332901001\n",
      "      kl: 0.00570263434201479\n",
      "      policy_loss: -0.0030370180029422045\n",
      "      total_loss: 74.1973648071289\n",
      "      vf_explained_var: 0.7576636075973511\n",
      "      vf_loss: 74.20040130615234\n",
      "    sample_time_ms: 20728.362\n",
      "    update_time_ms: 7.557\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.27126718097921\n",
      "    rl_1: 29.106879589847686\n",
      "  time_since_restore: 1117.9775490760803\n",
      "  time_this_iter_s: 24.006473064422607\n",
      "  time_total_s: 1117.9775490760803\n",
      "  timestamp: 1550881700\n",
      "  timesteps_since_restore: 470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 470000\n",
      "  training_iteration: 47\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1117 s, 47 iter, 470000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-28-44\n",
      "  done: false\n",
      "  episode_len_mean: 130.57\n",
      "  episode_reward_max: 172.69001955105506\n",
      "  episode_reward_mean: 119.10137115661637\n",
      "  episode_reward_min: -163.53136601560408\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 2180\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3258.584\n",
      "    load_time_ms: 2.482\n",
      "    num_steps_sampled: 480000\n",
      "    num_steps_trained: 480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.842170985392048e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3631247282028198\n",
      "      kl: 0.008878118358552456\n",
      "      policy_loss: -0.004923245403915644\n",
      "      total_loss: 252.78811645507812\n",
      "      vf_explained_var: 0.7517428994178772\n",
      "      vf_loss: 252.7930450439453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.421085492696024e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.454816222190857\n",
      "      kl: 0.0027010056655853987\n",
      "      policy_loss: -0.002412245376035571\n",
      "      total_loss: 95.94123840332031\n",
      "      vf_explained_var: 0.705878496170044\n",
      "      vf_loss: 95.94363403320312\n",
      "    sample_time_ms: 20768.314\n",
      "    update_time_ms: 7.665\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.12382525240814\n",
      "    rl_1: 27.977545904208274\n",
      "  time_since_restore: 1142.0672550201416\n",
      "  time_this_iter_s: 24.08970594406128\n",
      "  time_total_s: 1142.0672550201416\n",
      "  timestamp: 1550881724\n",
      "  timesteps_since_restore: 480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 480000\n",
      "  training_iteration: 48\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1142 s, 48 iter, 480000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-29-08\n",
      "  done: false\n",
      "  episode_len_mean: 126.04\n",
      "  episode_reward_max: 177.55170479379973\n",
      "  episode_reward_mean: 116.00047550731014\n",
      "  episode_reward_min: -176.68546961138975\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 2260\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3271.862\n",
      "    load_time_ms: 2.583\n",
      "    num_steps_sampled: 490000\n",
      "    num_steps_trained: 490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.421085492696024e-15\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3461569547653198\n",
      "      kl: 0.008960583247244358\n",
      "      policy_loss: -0.002721089869737625\n",
      "      total_loss: 224.05577087402344\n",
      "      vf_explained_var: 0.7584881782531738\n",
      "      vf_loss: 224.0584716796875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.10542746348012e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4667551517486572\n",
      "      kl: 0.0028406893834471703\n",
      "      policy_loss: -0.0005862244870513678\n",
      "      total_loss: 83.0562515258789\n",
      "      vf_explained_var: 0.746272623538971\n",
      "      vf_loss: 83.05684661865234\n",
      "    sample_time_ms: 20760.064\n",
      "    update_time_ms: 7.476\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.25128714255872\n",
      "    rl_1: 25.749188364751454\n",
      "  time_since_restore: 1165.8798260688782\n",
      "  time_this_iter_s: 23.812571048736572\n",
      "  time_total_s: 1165.8798260688782\n",
      "  timestamp: 1550881748\n",
      "  timesteps_since_restore: 490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 490000\n",
      "  training_iteration: 49\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1165 s, 49 iter, 490000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-29-32\n",
      "  done: false\n",
      "  episode_len_mean: 134.32\n",
      "  episode_reward_max: 181.1152484889443\n",
      "  episode_reward_mean: 122.14974922748746\n",
      "  episode_reward_min: -156.5322551073875\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 2333\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3263.117\n",
      "    load_time_ms: 2.639\n",
      "    num_steps_sampled: 500000\n",
      "    num_steps_trained: 500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.10542746348012e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3622477054595947\n",
      "      kl: 0.010939909145236015\n",
      "      policy_loss: -0.004622458480298519\n",
      "      total_loss: 175.03224182128906\n",
      "      vf_explained_var: 0.8950076699256897\n",
      "      vf_loss: 175.03688049316406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.55271373174006e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4489784240722656\n",
      "      kl: 0.006728724110871553\n",
      "      policy_loss: -0.003301717573776841\n",
      "      total_loss: 63.30752944946289\n",
      "      vf_explained_var: 0.8553706407546997\n",
      "      vf_loss: 63.310829162597656\n",
      "    sample_time_ms: 20676.07\n",
      "    update_time_ms: 7.406\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.19283912431287\n",
      "    rl_1: 28.956910103174593\n",
      "  time_since_restore: 1189.151123046875\n",
      "  time_this_iter_s: 23.271296977996826\n",
      "  time_total_s: 1189.151123046875\n",
      "  timestamp: 1550881772\n",
      "  timesteps_since_restore: 500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 500000\n",
      "  training_iteration: 50\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1189 s, 50 iter, 500000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 141.31\n",
      "  episode_reward_max: 184.25291638951083\n",
      "  episode_reward_mean: 115.97759700544896\n",
      "  episode_reward_min: -169.0367704558612\n",
      "  episodes_this_iter: 73\n",
      "  episodes_total: 2406\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3250.023\n",
      "    load_time_ms: 2.712\n",
      "    num_steps_sampled: 510000\n",
      "    num_steps_trained: 510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.10542746348012e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3120925426483154\n",
      "      kl: 0.01110112201422453\n",
      "      policy_loss: -0.004468295723199844\n",
      "      total_loss: 181.415283203125\n",
      "      vf_explained_var: 0.8812161684036255\n",
      "      vf_loss: 181.41976928710938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.77635686587003e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.405229926109314\n",
      "      kl: 0.0018400513799861073\n",
      "      policy_loss: -0.0017564470181241632\n",
      "      total_loss: 72.93267059326172\n",
      "      vf_explained_var: 0.8203085064888\n",
      "      vf_loss: 72.9344253540039\n",
      "    sample_time_ms: 20621.138\n",
      "    update_time_ms: 7.259\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.2395375146262\n",
      "    rl_1: 26.738059490822756\n",
      "  time_since_restore: 1212.8552758693695\n",
      "  time_this_iter_s: 23.704152822494507\n",
      "  time_total_s: 1212.8552758693695\n",
      "  timestamp: 1550881795\n",
      "  timesteps_since_restore: 510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 510000\n",
      "  training_iteration: 51\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1212 s, 51 iter, 510000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-30-20\n",
      "  done: false\n",
      "  episode_len_mean: 125.5\n",
      "  episode_reward_max: 180.47693112628195\n",
      "  episode_reward_mean: 133.5860251251552\n",
      "  episode_reward_min: -148.51615446009714\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 2486\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3231.67\n",
      "    load_time_ms: 2.711\n",
      "    num_steps_sampled: 520000\n",
      "    num_steps_trained: 520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.10542746348012e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3001654148101807\n",
      "      kl: 0.007150739431381226\n",
      "      policy_loss: -0.003610131796449423\n",
      "      total_loss: 186.6099853515625\n",
      "      vf_explained_var: 0.8384973406791687\n",
      "      vf_loss: 186.6135711669922\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 8.88178432935015e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4267503023147583\n",
      "      kl: 0.0060667721554636955\n",
      "      policy_loss: -0.0031718730460852385\n",
      "      total_loss: 48.75138473510742\n",
      "      vf_explained_var: 0.8247708082199097\n",
      "      vf_loss: 48.75455856323242\n",
      "    sample_time_ms: 20705.365\n",
      "    update_time_ms: 7.349\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 102.51258009376184\n",
      "    rl_1: 31.07344503139336\n",
      "  time_since_restore: 1237.065612077713\n",
      "  time_this_iter_s: 24.210336208343506\n",
      "  time_total_s: 1237.065612077713\n",
      "  timestamp: 1550881820\n",
      "  timesteps_since_restore: 520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 520000\n",
      "  training_iteration: 52\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1237 s, 52 iter, 520000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-30-44\n",
      "  done: false\n",
      "  episode_len_mean: 134.69\n",
      "  episode_reward_max: 202.21201192641675\n",
      "  episode_reward_mean: 130.78034583497438\n",
      "  episode_reward_min: -148.0366495261294\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 2556\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3216.956\n",
      "    load_time_ms: 2.777\n",
      "    num_steps_sampled: 530000\n",
      "    num_steps_trained: 530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.55271373174006e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3241264820098877\n",
      "      kl: 0.0030441295821219683\n",
      "      policy_loss: -0.0014386248076334596\n",
      "      total_loss: 147.06689453125\n",
      "      vf_explained_var: 0.8959761261940002\n",
      "      vf_loss: 147.06832885742188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.440892164675075e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.417834997177124\n",
      "      kl: 0.0034400431904941797\n",
      "      policy_loss: -0.0017430981388315558\n",
      "      total_loss: 64.73541259765625\n",
      "      vf_explained_var: 0.827829897403717\n",
      "      vf_loss: 64.73714447021484\n",
      "    sample_time_ms: 20644.304\n",
      "    update_time_ms: 7.53\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.63582067920714\n",
      "    rl_1: 32.14452515576726\n",
      "  time_since_restore: 1261.2107949256897\n",
      "  time_this_iter_s: 24.145182847976685\n",
      "  time_total_s: 1261.2107949256897\n",
      "  timestamp: 1550881844\n",
      "  timesteps_since_restore: 530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 530000\n",
      "  training_iteration: 53\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1261 s, 53 iter, 530000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-31-08\n",
      "  done: false\n",
      "  episode_len_mean: 138.28\n",
      "  episode_reward_max: 195.0210602073574\n",
      "  episode_reward_mean: 133.43616779448456\n",
      "  episode_reward_min: -130.58950721542698\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 2633\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3216.261\n",
      "    load_time_ms: 2.757\n",
      "    num_steps_sampled: 540000\n",
      "    num_steps_trained: 540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.77635686587003e-16\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3064227104187012\n",
      "      kl: 0.00697989109903574\n",
      "      policy_loss: -0.002599886618554592\n",
      "      total_loss: 162.58837890625\n",
      "      vf_explained_var: 0.8284233212471008\n",
      "      vf_loss: 162.5909881591797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.2204460823375376e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4696877002716064\n",
      "      kl: 0.010564006865024567\n",
      "      policy_loss: -0.00451187789440155\n",
      "      total_loss: 63.21713638305664\n",
      "      vf_explained_var: 0.7119328379631042\n",
      "      vf_loss: 63.221641540527344\n",
      "    sample_time_ms: 20642.95\n",
      "    update_time_ms: 7.539\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.84507306438661\n",
      "    rl_1: 34.591094730097936\n",
      "  time_since_restore: 1284.8718786239624\n",
      "  time_this_iter_s: 23.661083698272705\n",
      "  time_total_s: 1284.8718786239624\n",
      "  timestamp: 1550881868\n",
      "  timesteps_since_restore: 540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 540000\n",
      "  training_iteration: 54\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1284 s, 54 iter, 540000 ts, 133 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-31-31\n",
      "  done: false\n",
      "  episode_len_mean: 147.85\n",
      "  episode_reward_max: 191.44310828612262\n",
      "  episode_reward_mean: 134.43034807142067\n",
      "  episode_reward_min: -144.0544710148374\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 2698\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3201.341\n",
      "    load_time_ms: 2.689\n",
      "    num_steps_sampled: 550000\n",
      "    num_steps_trained: 550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.88178432935015e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3112443685531616\n",
      "      kl: 0.0014718365855515003\n",
      "      policy_loss: -0.0010469222906976938\n",
      "      total_loss: 149.31556701660156\n",
      "      vf_explained_var: 0.8847987055778503\n",
      "      vf_loss: 149.3166046142578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.2204460823375376e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.374002456665039\n",
      "      kl: 0.0037734340876340866\n",
      "      policy_loss: -0.001956404885277152\n",
      "      total_loss: 63.449562072753906\n",
      "      vf_explained_var: 0.8425849676132202\n",
      "      vf_loss: 63.45152282714844\n",
      "    sample_time_ms: 20603.145\n",
      "    update_time_ms: 7.355\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 99.20690071134437\n",
      "    rl_1: 35.223447360076285\n",
      "  time_since_restore: 1308.3430252075195\n",
      "  time_this_iter_s: 23.47114658355713\n",
      "  time_total_s: 1308.3430252075195\n",
      "  timestamp: 1550881891\n",
      "  timesteps_since_restore: 550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 550000\n",
      "  training_iteration: 55\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1308 s, 55 iter, 550000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-31-55\n",
      "  done: false\n",
      "  episode_len_mean: 141.61\n",
      "  episode_reward_max: 189.83802069473845\n",
      "  episode_reward_mean: 130.8463096609755\n",
      "  episode_reward_min: -152.09366628142698\n",
      "  episodes_this_iter: 69\n",
      "  episodes_total: 2767\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3183.668\n",
      "    load_time_ms: 2.697\n",
      "    num_steps_sampled: 560000\n",
      "    num_steps_trained: 560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.440892164675075e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3225747346878052\n",
      "      kl: 0.005239951889961958\n",
      "      policy_loss: -0.002437382470816374\n",
      "      total_loss: 158.44415283203125\n",
      "      vf_explained_var: 0.8518599271774292\n",
      "      vf_loss: 158.4465789794922\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.1102230411687688e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.405103087425232\n",
      "      kl: 0.002148910891264677\n",
      "      policy_loss: -0.0021155215799808502\n",
      "      total_loss: 64.06513977050781\n",
      "      vf_explained_var: 0.7722592949867249\n",
      "      vf_loss: 64.0672607421875\n",
      "    sample_time_ms: 20595.095\n",
      "    update_time_ms: 7.488\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.818221102245\n",
      "    rl_1: 35.02808855873047\n",
      "  time_since_restore: 1332.0423543453217\n",
      "  time_this_iter_s: 23.699329137802124\n",
      "  time_total_s: 1332.0423543453217\n",
      "  timestamp: 1550881915\n",
      "  timesteps_since_restore: 560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 560000\n",
      "  training_iteration: 56\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1332 s, 56 iter, 560000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-32-19\n",
      "  done: false\n",
      "  episode_len_mean: 127.95\n",
      "  episode_reward_max: 189.83802069473845\n",
      "  episode_reward_mean: 129.39549912994036\n",
      "  episode_reward_min: -156.5166746320976\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 2847\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3163.528\n",
      "    load_time_ms: 2.668\n",
      "    num_steps_sampled: 570000\n",
      "    num_steps_trained: 570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2204460823375376e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3109358549118042\n",
      "      kl: 0.006014588754624128\n",
      "      policy_loss: -0.001482726656831801\n",
      "      total_loss: 175.51292419433594\n",
      "      vf_explained_var: 0.809393048286438\n",
      "      vf_loss: 175.514404296875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.551115205843844e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.4447494745254517\n",
      "      kl: 0.003756421385332942\n",
      "      policy_loss: -0.0027465748135000467\n",
      "      total_loss: 68.41065979003906\n",
      "      vf_explained_var: 0.72584468126297\n",
      "      vf_loss: 68.41340637207031\n",
      "    sample_time_ms: 20622.658\n",
      "    update_time_ms: 7.453\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.8577696350055\n",
      "    rl_1: 35.53772949493487\n",
      "  time_since_restore: 1356.121477842331\n",
      "  time_this_iter_s: 24.079123497009277\n",
      "  time_total_s: 1356.121477842331\n",
      "  timestamp: 1550881939\n",
      "  timesteps_since_restore: 570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 570000\n",
      "  training_iteration: 57\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1356 s, 57 iter, 570000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-32-43\n",
      "  done: false\n",
      "  episode_len_mean: 134.55\n",
      "  episode_reward_max: 200.0419584056572\n",
      "  episode_reward_mean: 126.47067069747659\n",
      "  episode_reward_min: -156.5166746320976\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2919\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3145.855\n",
      "    load_time_ms: 2.681\n",
      "    num_steps_sampled: 580000\n",
      "    num_steps_trained: 580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1102230411687688e-17\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.315874695777893\n",
      "      kl: 0.006804862059652805\n",
      "      policy_loss: -0.0030223350040614605\n",
      "      total_loss: 161.52403259277344\n",
      "      vf_explained_var: 0.8565607070922852\n",
      "      vf_loss: 161.5270233154297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.775557602921922e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3488826751708984\n",
      "      kl: 0.002574888290837407\n",
      "      policy_loss: -0.002169928979128599\n",
      "      total_loss: 73.63111877441406\n",
      "      vf_explained_var: 0.8255524039268494\n",
      "      vf_loss: 73.63328552246094\n",
      "    sample_time_ms: 20610.153\n",
      "    update_time_ms: 7.502\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.07826225402302\n",
      "    rl_1: 33.39240844345359\n",
      "  time_since_restore: 1379.9073226451874\n",
      "  time_this_iter_s: 23.785844802856445\n",
      "  time_total_s: 1379.9073226451874\n",
      "  timestamp: 1550881963\n",
      "  timesteps_since_restore: 580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 580000\n",
      "  training_iteration: 58\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1379 s, 58 iter, 580000 ts, 126 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-33-06\n",
      "  done: false\n",
      "  episode_len_mean: 134.69\n",
      "  episode_reward_max: 189.56708086275097\n",
      "  episode_reward_mean: 128.07660624690664\n",
      "  episode_reward_min: -140.68997376660812\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 2995\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3117.577\n",
      "    load_time_ms: 2.578\n",
      "    num_steps_sampled: 590000\n",
      "    num_steps_trained: 590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.551115205843844e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2934890985488892\n",
      "      kl: 0.008227547630667686\n",
      "      policy_loss: -0.003612386528402567\n",
      "      total_loss: 132.6400146484375\n",
      "      vf_explained_var: 0.875669538974762\n",
      "      vf_loss: 132.6436309814453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.387778801460961e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.388835072517395\n",
      "      kl: 0.0068325768224895\n",
      "      policy_loss: -0.0041821785271167755\n",
      "      total_loss: 46.051551818847656\n",
      "      vf_explained_var: 0.8580073714256287\n",
      "      vf_loss: 46.05573654174805\n",
      "    sample_time_ms: 20580.788\n",
      "    update_time_ms: 7.264\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.54229971175963\n",
      "    rl_1: 33.534306535147024\n",
      "  time_since_restore: 1403.1386065483093\n",
      "  time_this_iter_s: 23.23128390312195\n",
      "  time_total_s: 1403.1386065483093\n",
      "  timestamp: 1550881986\n",
      "  timesteps_since_restore: 590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 590000\n",
      "  training_iteration: 59\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1403 s, 59 iter, 590000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-33-30\n",
      "  done: false\n",
      "  episode_len_mean: 131.68\n",
      "  episode_reward_max: 189.4759598350896\n",
      "  episode_reward_mean: 143.47007093884974\n",
      "  episode_reward_min: -136.75809857942883\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 3073\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3107.212\n",
      "    load_time_ms: 2.521\n",
      "    num_steps_sampled: 600000\n",
      "    num_steps_trained: 600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.775557602921922e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2876793146133423\n",
      "      kl: 0.0028764568269252777\n",
      "      policy_loss: -0.0016477463068440557\n",
      "      total_loss: 140.76698303222656\n",
      "      vf_explained_var: 0.8390016555786133\n",
      "      vf_loss: 140.76861572265625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 6.938894007304805e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.391042709350586\n",
      "      kl: 0.003187482478097081\n",
      "      policy_loss: -0.00256925611756742\n",
      "      total_loss: 57.070858001708984\n",
      "      vf_explained_var: 0.745293915271759\n",
      "      vf_loss: 57.07343673706055\n",
      "    sample_time_ms: 20668.809\n",
      "    update_time_ms: 7.439\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 102.44967790896062\n",
      "    rl_1: 41.020393029889135\n",
      "  time_since_restore: 1427.1866974830627\n",
      "  time_this_iter_s: 24.048090934753418\n",
      "  time_total_s: 1427.1866974830627\n",
      "  timestamp: 1550882010\n",
      "  timesteps_since_restore: 600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 600000\n",
      "  training_iteration: 60\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1427 s, 60 iter, 600000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-33-54\n",
      "  done: false\n",
      "  episode_len_mean: 127.59\n",
      "  episode_reward_max: 189.4759598350896\n",
      "  episode_reward_mean: 133.93319163369287\n",
      "  episode_reward_min: -159.98705528104603\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 3150\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3106.81\n",
      "    load_time_ms: 2.484\n",
      "    num_steps_sampled: 610000\n",
      "    num_steps_trained: 610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.387778801460961e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.269737958908081\n",
      "      kl: 0.012042648158967495\n",
      "      policy_loss: -0.003771647810935974\n",
      "      total_loss: 161.79052734375\n",
      "      vf_explained_var: 0.8317233324050903\n",
      "      vf_loss: 161.79429626464844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.4694470036524025e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3770705461502075\n",
      "      kl: 0.003106571501120925\n",
      "      policy_loss: -0.0014535908121615648\n",
      "      total_loss: 73.72566986083984\n",
      "      vf_explained_var: 0.7850362658500671\n",
      "      vf_loss: 73.72712707519531\n",
      "    sample_time_ms: 20692.422\n",
      "    update_time_ms: 7.521\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.04804820577665\n",
      "    rl_1: 37.88514342791622\n",
      "  time_since_restore: 1451.122365951538\n",
      "  time_this_iter_s: 23.935668468475342\n",
      "  time_total_s: 1451.122365951538\n",
      "  timestamp: 1550882034\n",
      "  timesteps_since_restore: 610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 610000\n",
      "  training_iteration: 61\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1451 s, 61 iter, 610000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-34-18\n",
      "  done: false\n",
      "  episode_len_mean: 134.85\n",
      "  episode_reward_max: 196.09732026931258\n",
      "  episode_reward_mean: 138.37529059363308\n",
      "  episode_reward_min: -144.50521875911613\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 3226\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.387\n",
      "    load_time_ms: 2.482\n",
      "    num_steps_sampled: 620000\n",
      "    num_steps_trained: 620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.387778801460961e-18\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.261293888092041\n",
      "      kl: 0.004314610734581947\n",
      "      policy_loss: -0.0027579914312809706\n",
      "      total_loss: 141.90432739257812\n",
      "      vf_explained_var: 0.8471795320510864\n",
      "      vf_loss: 141.90711975097656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.7347235018262012e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.401702880859375\n",
      "      kl: 0.0030813466291874647\n",
      "      policy_loss: -0.0011421316303312778\n",
      "      total_loss: 55.67748260498047\n",
      "      vf_explained_var: 0.7962822318077087\n",
      "      vf_loss: 55.678611755371094\n",
      "    sample_time_ms: 20648.614\n",
      "    update_time_ms: 7.66\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 99.2848680666497\n",
      "    rl_1: 39.09042252698341\n",
      "  time_since_restore: 1474.8494656085968\n",
      "  time_this_iter_s: 23.727099657058716\n",
      "  time_total_s: 1474.8494656085968\n",
      "  timestamp: 1550882058\n",
      "  timesteps_since_restore: 620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 620000\n",
      "  training_iteration: 62\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1474 s, 62 iter, 620000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-34-42\n",
      "  done: false\n",
      "  episode_len_mean: 130.1\n",
      "  episode_reward_max: 190.39519469102535\n",
      "  episode_reward_mean: 147.95403490662923\n",
      "  episode_reward_min: 44.349098704589686\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 3303\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.746\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 630000\n",
      "    num_steps_trained: 630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.938894007304805e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2691465616226196\n",
      "      kl: 0.0021948879584670067\n",
      "      policy_loss: -0.002188808983191848\n",
      "      total_loss: 106.1616439819336\n",
      "      vf_explained_var: 0.8894181847572327\n",
      "      vf_loss: 106.16383361816406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 8.673617509131006e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.39352548122406\n",
      "      kl: 0.005551011301577091\n",
      "      policy_loss: -0.003487661015242338\n",
      "      total_loss: 38.234676361083984\n",
      "      vf_explained_var: 0.8065729737281799\n",
      "      vf_loss: 38.23816680908203\n",
      "    sample_time_ms: 20628.693\n",
      "    update_time_ms: 7.534\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 103.83551361262711\n",
      "    rl_1: 44.118521294002115\n",
      "  time_since_restore: 1498.7761223316193\n",
      "  time_this_iter_s: 23.92665672302246\n",
      "  time_total_s: 1498.7761223316193\n",
      "  timestamp: 1550882082\n",
      "  timesteps_since_restore: 630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 630000\n",
      "  training_iteration: 63\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1498 s, 63 iter, 630000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-35-06\n",
      "  done: false\n",
      "  episode_len_mean: 131.97\n",
      "  episode_reward_max: 196.4420564385812\n",
      "  episode_reward_mean: 139.09548343468862\n",
      "  episode_reward_min: -156.62166510719055\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 3378\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.488\n",
      "    load_time_ms: 2.38\n",
      "    num_steps_sampled: 640000\n",
      "    num_steps_trained: 640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.4694470036524025e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2831974029541016\n",
      "      kl: 0.004403637256473303\n",
      "      policy_loss: -0.003480661427602172\n",
      "      total_loss: 184.48739624023438\n",
      "      vf_explained_var: 0.781140148639679\n",
      "      vf_loss: 184.4908447265625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.336808754565503e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3746191263198853\n",
      "      kl: 0.0018399945693090558\n",
      "      policy_loss: -0.0024532333482056856\n",
      "      total_loss: 97.43804168701172\n",
      "      vf_explained_var: 0.721210241317749\n",
      "      vf_loss: 97.44050598144531\n",
      "    sample_time_ms: 20705.782\n",
      "    update_time_ms: 7.454\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.4411585964542\n",
      "    rl_1: 42.65432483823441\n",
      "  time_since_restore: 1523.0521094799042\n",
      "  time_this_iter_s: 24.275987148284912\n",
      "  time_total_s: 1523.0521094799042\n",
      "  timestamp: 1550882106\n",
      "  timesteps_since_restore: 640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 640000\n",
      "  training_iteration: 64\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1523 s, 64 iter, 640000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-35-30\n",
      "  done: false\n",
      "  episode_len_mean: 118.19\n",
      "  episode_reward_max: 191.822472369337\n",
      "  episode_reward_mean: 143.20073902492052\n",
      "  episode_reward_min: -164.10395937539107\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 3462\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.539\n",
      "    load_time_ms: 2.429\n",
      "    num_steps_sampled: 650000\n",
      "    num_steps_trained: 650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.7347235018262012e-19\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.252562165260315\n",
      "      kl: 0.0034226595889776945\n",
      "      policy_loss: -0.002573461504653096\n",
      "      total_loss: 106.31858825683594\n",
      "      vf_explained_var: 0.8613489866256714\n",
      "      vf_loss: 106.32115173339844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.1684043772827515e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.388240933418274\n",
      "      kl: 0.007918396033346653\n",
      "      policy_loss: -0.0038609278853982687\n",
      "      total_loss: 43.45069885253906\n",
      "      vf_explained_var: 0.7839956283569336\n",
      "      vf_loss: 43.45456314086914\n",
      "    sample_time_ms: 20726.353\n",
      "    update_time_ms: 7.486\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.78473425119606\n",
      "    rl_1: 44.41600477372445\n",
      "  time_since_restore: 1546.7046194076538\n",
      "  time_this_iter_s: 23.652509927749634\n",
      "  time_total_s: 1546.7046194076538\n",
      "  timestamp: 1550882130\n",
      "  timesteps_since_restore: 650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 650000\n",
      "  training_iteration: 65\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1546 s, 65 iter, 650000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-35-54\n",
      "  done: false\n",
      "  episode_len_mean: 125.33\n",
      "  episode_reward_max: 203.9169869343356\n",
      "  episode_reward_mean: 139.95796806999368\n",
      "  episode_reward_min: -164.10395937539107\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 3541\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.034\n",
      "    load_time_ms: 2.454\n",
      "    num_steps_sampled: 660000\n",
      "    num_steps_trained: 660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.673617509131006e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2505146265029907\n",
      "      kl: 0.005611791275441647\n",
      "      policy_loss: -0.002927422057837248\n",
      "      total_loss: 137.81900024414062\n",
      "      vf_explained_var: 0.8582461476325989\n",
      "      vf_loss: 137.8218994140625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.0842021886413758e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3740699291229248\n",
      "      kl: 0.007394038140773773\n",
      "      policy_loss: -0.0028660441748797894\n",
      "      total_loss: 70.37003326416016\n",
      "      vf_explained_var: 0.8012087941169739\n",
      "      vf_loss: 70.37289428710938\n",
      "    sample_time_ms: 20753.534\n",
      "    update_time_ms: 7.212\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.3157035319371\n",
      "    rl_1: 44.64226453805655\n",
      "  time_since_restore: 1570.6503267288208\n",
      "  time_this_iter_s: 23.945707321166992\n",
      "  time_total_s: 1570.6503267288208\n",
      "  timestamp: 1550882154\n",
      "  timesteps_since_restore: 660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 660000\n",
      "  training_iteration: 66\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1570 s, 66 iter, 660000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-36-18\n",
      "  done: false\n",
      "  episode_len_mean: 128.81\n",
      "  episode_reward_max: 207.26360247050508\n",
      "  episode_reward_mean: 152.11980062026743\n",
      "  episode_reward_min: -132.1535621453571\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 3619\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.175\n",
      "    load_time_ms: 2.45\n",
      "    num_steps_sampled: 670000\n",
      "    num_steps_trained: 670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.336808754565503e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.234729290008545\n",
      "      kl: 0.005794145166873932\n",
      "      policy_loss: -0.001862684148363769\n",
      "      total_loss: 82.949951171875\n",
      "      vf_explained_var: 0.8913263082504272\n",
      "      vf_loss: 82.95181274414062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.421010943206879e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3509243726730347\n",
      "      kl: 0.006364599801599979\n",
      "      policy_loss: -0.002985800616443157\n",
      "      total_loss: 33.60654067993164\n",
      "      vf_explained_var: 0.8692721128463745\n",
      "      vf_loss: 33.60953140258789\n",
      "    sample_time_ms: 20735.882\n",
      "    update_time_ms: 7.288\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 101.89387968284431\n",
      "    rl_1: 50.2259209374231\n",
      "  time_since_restore: 1594.603865146637\n",
      "  time_this_iter_s: 23.953538417816162\n",
      "  time_total_s: 1594.603865146637\n",
      "  timestamp: 1550882178\n",
      "  timesteps_since_restore: 670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 670000\n",
      "  training_iteration: 67\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1594 s, 67 iter, 670000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-36-42\n",
      "  done: false\n",
      "  episode_len_mean: 134.81\n",
      "  episode_reward_max: 231.4284690324479\n",
      "  episode_reward_mean: 152.84921584217813\n",
      "  episode_reward_min: -145.0525746945244\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 3695\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.599\n",
      "    load_time_ms: 2.458\n",
      "    num_steps_sampled: 680000\n",
      "    num_steps_trained: 680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.1684043772827515e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2777739763259888\n",
      "      kl: 0.005878800991922617\n",
      "      policy_loss: -0.0045817396603524685\n",
      "      total_loss: 100.61936950683594\n",
      "      vf_explained_var: 0.8642088174819946\n",
      "      vf_loss: 100.62393951416016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.7105054716034394e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3278337717056274\n",
      "      kl: 0.003870317479595542\n",
      "      policy_loss: -0.0020110183395445347\n",
      "      total_loss: 54.04999923706055\n",
      "      vf_explained_var: 0.8608879446983337\n",
      "      vf_loss: 54.05200958251953\n",
      "    sample_time_ms: 20736.565\n",
      "    update_time_ms: 6.999\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 101.20605470948676\n",
      "    rl_1: 51.643161132691404\n",
      "  time_since_restore: 1618.3893239498138\n",
      "  time_this_iter_s: 23.78545880317688\n",
      "  time_total_s: 1618.3893239498138\n",
      "  timestamp: 1550882202\n",
      "  timesteps_since_restore: 680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 680000\n",
      "  training_iteration: 68\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1618 s, 68 iter, 680000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-37-05\n",
      "  done: false\n",
      "  episode_len_mean: 126.88\n",
      "  episode_reward_max: 213.63449313999578\n",
      "  episode_reward_mean: 141.836656272171\n",
      "  episode_reward_min: -158.9596100878773\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 3772\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.721\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 690000\n",
      "    num_steps_trained: 690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0842021886413758e-20\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2875787019729614\n",
      "      kl: 0.006428824737668037\n",
      "      policy_loss: -0.0020744497887790203\n",
      "      total_loss: 166.4184112548828\n",
      "      vf_explained_var: 0.8051267862319946\n",
      "      vf_loss: 166.4204559326172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.3552527358017197e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.333530068397522\n",
      "      kl: 0.00568249961361289\n",
      "      policy_loss: -0.0034090864937752485\n",
      "      total_loss: 100.6957778930664\n",
      "      vf_explained_var: 0.7736759185791016\n",
      "      vf_loss: 100.69918823242188\n",
      "    sample_time_ms: 20752.626\n",
      "    update_time_ms: 7.646\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.56974153954143\n",
      "    rl_1: 48.266914732629594\n",
      "  time_since_restore: 1641.7607657909393\n",
      "  time_this_iter_s: 23.37144184112549\n",
      "  time_total_s: 1641.7607657909393\n",
      "  timestamp: 1550882225\n",
      "  timesteps_since_restore: 690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 690000\n",
      "  training_iteration: 69\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1641 s, 69 iter, 690000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-37-28\n",
      "  done: false\n",
      "  episode_len_mean: 123.84\n",
      "  episode_reward_max: 208.73417199828862\n",
      "  episode_reward_mean: 127.89556796136645\n",
      "  episode_reward_min: -158.9596100878773\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 3854\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.589\n",
      "    load_time_ms: 2.406\n",
      "    num_steps_sampled: 700000\n",
      "    num_steps_trained: 700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.421010943206879e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2577980756759644\n",
      "      kl: 0.006087045185267925\n",
      "      policy_loss: -0.003924958407878876\n",
      "      total_loss: 263.1474609375\n",
      "      vf_explained_var: 0.755247950553894\n",
      "      vf_loss: 263.1513977050781\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 6.776263679008599e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3682727813720703\n",
      "      kl: 0.0038972378242760897\n",
      "      policy_loss: -0.0031836486887186766\n",
      "      total_loss: 182.563720703125\n",
      "      vf_explained_var: 0.6820107102394104\n",
      "      vf_loss: 182.56690979003906\n",
      "    sample_time_ms: 20678.323\n",
      "    update_time_ms: 7.405\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.2060858464113\n",
      "    rl_1: 42.68948211495513\n",
      "  time_since_restore: 1665.1018974781036\n",
      "  time_this_iter_s: 23.341131687164307\n",
      "  time_total_s: 1665.1018974781036\n",
      "  timestamp: 1550882248\n",
      "  timesteps_since_restore: 700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 700000\n",
      "  training_iteration: 70\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1665 s, 70 iter, 700000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-37-52\n",
      "  done: false\n",
      "  episode_len_mean: 124.05\n",
      "  episode_reward_max: 208.73417199828862\n",
      "  episode_reward_mean: 141.40758811689\n",
      "  episode_reward_min: -153.16457783849776\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 3935\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.337\n",
      "    load_time_ms: 2.363\n",
      "    num_steps_sampled: 710000\n",
      "    num_steps_trained: 710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.7105054716034394e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2651097774505615\n",
      "      kl: 0.0058673047460615635\n",
      "      policy_loss: -0.003645651275292039\n",
      "      total_loss: 134.88865661621094\n",
      "      vf_explained_var: 0.8463731408119202\n",
      "      vf_loss: 134.8922882080078\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.3881318395042993e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3486641645431519\n",
      "      kl: 0.005562277976423502\n",
      "      policy_loss: -0.0012134560383856297\n",
      "      total_loss: 92.12933349609375\n",
      "      vf_explained_var: 0.7937723994255066\n",
      "      vf_loss: 92.13053894042969\n",
      "    sample_time_ms: 20664.787\n",
      "    update_time_ms: 7.397\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.68690441570699\n",
      "    rl_1: 47.72068370118299\n",
      "  time_since_restore: 1688.8992099761963\n",
      "  time_this_iter_s: 23.79731249809265\n",
      "  time_total_s: 1688.8992099761963\n",
      "  timestamp: 1550882272\n",
      "  timesteps_since_restore: 710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 710000\n",
      "  training_iteration: 71\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1688 s, 71 iter, 710000 ts, 141 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-38-16\n",
      "  done: false\n",
      "  episode_len_mean: 124.12\n",
      "  episode_reward_max: 208.3986420904277\n",
      "  episode_reward_mean: 145.53158843967128\n",
      "  episode_reward_min: -153.16457783849776\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 4013\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.59\n",
      "    load_time_ms: 2.413\n",
      "    num_steps_sampled: 720000\n",
      "    num_steps_trained: 720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.3552527358017197e-21\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2681636810302734\n",
      "      kl: 0.004645850509405136\n",
      "      policy_loss: -0.0018744757398962975\n",
      "      total_loss: 112.41533660888672\n",
      "      vf_explained_var: 0.8840031027793884\n",
      "      vf_loss: 112.41722869873047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.6940659197521496e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3487275838851929\n",
      "      kl: 0.006987479981034994\n",
      "      policy_loss: -0.002604091539978981\n",
      "      total_loss: 79.2925796508789\n",
      "      vf_explained_var: 0.8458837866783142\n",
      "      vf_loss: 79.2951889038086\n",
      "    sample_time_ms: 20663.721\n",
      "    update_time_ms: 7.514\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.03767487956314\n",
      "    rl_1: 52.49391356010812\n",
      "  time_since_restore: 1712.6731479167938\n",
      "  time_this_iter_s: 23.773937940597534\n",
      "  time_total_s: 1712.6731479167938\n",
      "  timestamp: 1550882296\n",
      "  timesteps_since_restore: 720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 720000\n",
      "  training_iteration: 72\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1712 s, 72 iter, 720000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-38-40\n",
      "  done: false\n",
      "  episode_len_mean: 138.31\n",
      "  episode_reward_max: 221.15606634510453\n",
      "  episode_reward_mean: 144.02551765778213\n",
      "  episode_reward_min: -145.60263332750236\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 4083\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3108.67\n",
      "    load_time_ms: 2.396\n",
      "    num_steps_sampled: 730000\n",
      "    num_steps_trained: 730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.776263679008599e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3136147260665894\n",
      "      kl: 0.009370941668748856\n",
      "      policy_loss: -0.004581269342452288\n",
      "      total_loss: 171.3506317138672\n",
      "      vf_explained_var: 0.8414149880409241\n",
      "      vf_loss: 171.35523986816406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 8.470329598760748e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3091694116592407\n",
      "      kl: 0.001568081323057413\n",
      "      policy_loss: -0.0025935887824743986\n",
      "      total_loss: 121.7188491821289\n",
      "      vf_explained_var: 0.8193578124046326\n",
      "      vf_loss: 121.72142791748047\n",
      "    sample_time_ms: 20608.245\n",
      "    update_time_ms: 7.487\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.71341433534208\n",
      "    rl_1: 52.31210332244004\n",
      "  time_since_restore: 1736.2263386249542\n",
      "  time_this_iter_s: 23.5531907081604\n",
      "  time_total_s: 1736.2263386249542\n",
      "  timestamp: 1550882320\n",
      "  timesteps_since_restore: 730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 730000\n",
      "  training_iteration: 73\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1736 s, 73 iter, 730000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-39-03\n",
      "  done: false\n",
      "  episode_len_mean: 130.4\n",
      "  episode_reward_max: 206.05525676170234\n",
      "  episode_reward_mean: 152.6237088154113\n",
      "  episode_reward_min: -142.08635250894616\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 4163\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3106.432\n",
      "    load_time_ms: 2.377\n",
      "    num_steps_sampled: 740000\n",
      "    num_steps_trained: 740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.3881318395042993e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.243876576423645\n",
      "      kl: 0.0034157373011112213\n",
      "      policy_loss: -0.002098526805639267\n",
      "      total_loss: 93.68995666503906\n",
      "      vf_explained_var: 0.9031820893287659\n",
      "      vf_loss: 93.69207000732422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.235164799380374e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3263452053070068\n",
      "      kl: 0.007309514097869396\n",
      "      policy_loss: -0.00260297954082489\n",
      "      total_loss: 67.56389617919922\n",
      "      vf_explained_var: 0.889372706413269\n",
      "      vf_loss: 67.56649017333984\n",
      "    sample_time_ms: 20507.396\n",
      "    update_time_ms: 7.497\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.02877396691228\n",
      "    rl_1: 57.59493484849896\n",
      "  time_since_restore: 1759.4715013504028\n",
      "  time_this_iter_s: 23.24516272544861\n",
      "  time_total_s: 1759.4715013504028\n",
      "  timestamp: 1550882343\n",
      "  timesteps_since_restore: 740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 740000\n",
      "  training_iteration: 74\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1759 s, 74 iter, 740000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 119.92\n",
      "  episode_reward_max: 217.52069531815314\n",
      "  episode_reward_mean: 134.46815324786587\n",
      "  episode_reward_min: -163.61940762245172\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 4244\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3108.061\n",
      "    load_time_ms: 2.292\n",
      "    num_steps_sampled: 750000\n",
      "    num_steps_trained: 750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6940659197521496e-22\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2373552322387695\n",
      "      kl: 0.0034458530135452747\n",
      "      policy_loss: -0.0015256738988682628\n",
      "      total_loss: 249.7784881591797\n",
      "      vf_explained_var: 0.7614225745201111\n",
      "      vf_loss: 249.780029296875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.117582399690187e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3294932842254639\n",
      "      kl: 0.0067789568565785885\n",
      "      policy_loss: -0.00270267715677619\n",
      "      total_loss: 195.89517211914062\n",
      "      vf_explained_var: 0.727361261844635\n",
      "      vf_loss: 195.8978729248047\n",
      "    sample_time_ms: 20501.015\n",
      "    update_time_ms: 7.997\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.70440906441664\n",
      "    rl_1: 50.76374418344924\n",
      "  time_since_restore: 1783.076501607895\n",
      "  time_this_iter_s: 23.605000257492065\n",
      "  time_total_s: 1783.076501607895\n",
      "  timestamp: 1550882367\n",
      "  timesteps_since_restore: 750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 750000\n",
      "  training_iteration: 75\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1783 s, 75 iter, 750000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-39-50\n",
      "  done: false\n",
      "  episode_len_mean: 120.35\n",
      "  episode_reward_max: 217.52069531815314\n",
      "  episode_reward_mean: 147.3529075614338\n",
      "  episode_reward_min: -146.81067697156956\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 4324\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3105.424\n",
      "    load_time_ms: 2.23\n",
      "    num_steps_sampled: 760000\n",
      "    num_steps_trained: 760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.470329598760748e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2359727621078491\n",
      "      kl: 0.002237423323094845\n",
      "      policy_loss: -0.00044491246808320284\n",
      "      total_loss: 154.97471618652344\n",
      "      vf_explained_var: 0.8389171957969666\n",
      "      vf_loss: 154.9751739501953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3087050914764404\n",
      "      kl: 0.002995152026414871\n",
      "      policy_loss: -0.002139272401109338\n",
      "      total_loss: 129.30487060546875\n",
      "      vf_explained_var: 0.8005847334861755\n",
      "      vf_loss: 129.30703735351562\n",
      "    sample_time_ms: 20457.646\n",
      "    update_time_ms: 8.018\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.72501008666036\n",
      "    rl_1: 56.627897474773434\n",
      "  time_since_restore: 1806.5589456558228\n",
      "  time_this_iter_s: 23.482444047927856\n",
      "  time_total_s: 1806.5589456558228\n",
      "  timestamp: 1550882390\n",
      "  timesteps_since_restore: 760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 760000\n",
      "  training_iteration: 76\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1806 s, 76 iter, 760000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 128.59\n",
      "  episode_reward_max: 226.5466148183755\n",
      "  episode_reward_mean: 154.06659898227517\n",
      "  episode_reward_min: -158.14949596826574\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 4402\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3112.133\n",
      "    load_time_ms: 2.229\n",
      "    num_steps_sampled: 770000\n",
      "    num_steps_trained: 770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.235164799380374e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2463420629501343\n",
      "      kl: 0.010261401534080505\n",
      "      policy_loss: -0.005062208045274019\n",
      "      total_loss: 133.17869567871094\n",
      "      vf_explained_var: 0.8774123787879944\n",
      "      vf_loss: 133.1837615966797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.293955999225468e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3015583753585815\n",
      "      kl: 0.007194791920483112\n",
      "      policy_loss: -0.0018955885898321867\n",
      "      total_loss: 108.54898834228516\n",
      "      vf_explained_var: 0.8374980092048645\n",
      "      vf_loss: 108.5508804321289\n",
      "    sample_time_ms: 20433.945\n",
      "    update_time_ms: 8.108\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.03663354219238\n",
      "    rl_1: 60.029965440082776\n",
      "  time_since_restore: 1830.3441302776337\n",
      "  time_this_iter_s: 23.785184621810913\n",
      "  time_total_s: 1830.3441302776337\n",
      "  timestamp: 1550882414\n",
      "  timesteps_since_restore: 770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 770000\n",
      "  training_iteration: 77\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1830 s, 77 iter, 770000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-40-38\n",
      "  done: false\n",
      "  episode_len_mean: 124.66\n",
      "  episode_reward_max: 220.31810641493257\n",
      "  episode_reward_mean: 162.20181117081844\n",
      "  episode_reward_min: -139.4587169446199\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 4477\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3128.702\n",
      "    load_time_ms: 2.221\n",
      "    num_steps_sampled: 780000\n",
      "    num_steps_trained: 780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.235164799380374e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2520582675933838\n",
      "      kl: 0.008639208041131496\n",
      "      policy_loss: -0.002268481068313122\n",
      "      total_loss: 99.08623504638672\n",
      "      vf_explained_var: 0.8788619637489319\n",
      "      vf_loss: 99.0885009765625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.646977999612734e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3016185760498047\n",
      "      kl: 0.01336357370018959\n",
      "      policy_loss: -0.004679212812334299\n",
      "      total_loss: 92.22220611572266\n",
      "      vf_explained_var: 0.8453382849693298\n",
      "      vf_loss: 92.22689056396484\n",
      "    sample_time_ms: 20403.244\n",
      "    update_time_ms: 8.105\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.79674579888538\n",
      "    rl_1: 65.40506537193302\n",
      "  time_since_restore: 1853.9877903461456\n",
      "  time_this_iter_s: 23.643660068511963\n",
      "  time_total_s: 1853.9877903461456\n",
      "  timestamp: 1550882438\n",
      "  timesteps_since_restore: 780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 780000\n",
      "  training_iteration: 78\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1853 s, 78 iter, 780000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-41-01\n",
      "  done: false\n",
      "  episode_len_mean: 144.23\n",
      "  episode_reward_max: 220.31810641493257\n",
      "  episode_reward_mean: 138.08204380360897\n",
      "  episode_reward_min: -149.16074277280532\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 4543\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3127.747\n",
      "    load_time_ms: 2.217\n",
      "    num_steps_sampled: 790000\n",
      "    num_steps_trained: 790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.117582399690187e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3160436153411865\n",
      "      kl: 0.006348230876028538\n",
      "      policy_loss: -0.002163086086511612\n",
      "      total_loss: 202.06295776367188\n",
      "      vf_explained_var: 0.7996864914894104\n",
      "      vf_loss: 202.06512451171875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.646977999612734e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.288744568824768\n",
      "      kl: 0.002712102374061942\n",
      "      policy_loss: -0.0010844040662050247\n",
      "      total_loss: 159.81056213378906\n",
      "      vf_explained_var: 0.8069407343864441\n",
      "      vf_loss: 159.8116455078125\n",
      "    sample_time_ms: 20392.568\n",
      "    update_time_ms: 7.539\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.41266637993431\n",
      "    rl_1: 54.66937742367465\n",
      "  time_since_restore: 1877.2337539196014\n",
      "  time_this_iter_s: 23.24596357345581\n",
      "  time_total_s: 1877.2337539196014\n",
      "  timestamp: 1550882461\n",
      "  timesteps_since_restore: 790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 790000\n",
      "  training_iteration: 79\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1877 s, 79 iter, 790000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 124.21\n",
      "  episode_reward_max: 224.32505130914427\n",
      "  episode_reward_mean: 129.07016972406242\n",
      "  episode_reward_min: -159.56576211225627\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 4629\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3127.547\n",
      "    load_time_ms: 2.217\n",
      "    num_steps_sampled: 800000\n",
      "    num_steps_trained: 800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0587911998450935e-23\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.179699182510376\n",
      "      kl: 0.0060830083675682545\n",
      "      policy_loss: -0.003096052212640643\n",
      "      total_loss: 229.94886779785156\n",
      "      vf_explained_var: 0.7995643615722656\n",
      "      vf_loss: 229.9520263671875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3246146440505981\n",
      "      kl: 0.0030647343955934048\n",
      "      policy_loss: -0.002137998351827264\n",
      "      total_loss: 194.50924682617188\n",
      "      vf_explained_var: 0.7643473744392395\n",
      "      vf_loss: 194.51136779785156\n",
      "    sample_time_ms: 20369.262\n",
      "    update_time_ms: 7.57\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.02377235836813\n",
      "    rl_1: 52.04639736569427\n",
      "  time_since_restore: 1900.3406031131744\n",
      "  time_this_iter_s: 23.106849193572998\n",
      "  time_total_s: 1900.3406031131744\n",
      "  timestamp: 1550882484\n",
      "  timesteps_since_restore: 800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 800000\n",
      "  training_iteration: 80\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1900 s, 80 iter, 800000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-41-48\n",
      "  done: false\n",
      "  episode_len_mean: 116.7\n",
      "  episode_reward_max: 216.32714134953932\n",
      "  episode_reward_mean: 132.13093048024095\n",
      "  episode_reward_min: -170.51775743741837\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 4713\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3125.774\n",
      "    load_time_ms: 2.213\n",
      "    num_steps_sampled: 810000\n",
      "    num_steps_trained: 810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.293955999225468e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2150111198425293\n",
      "      kl: 0.005470242351293564\n",
      "      policy_loss: -0.0027650631964206696\n",
      "      total_loss: 259.5104064941406\n",
      "      vf_explained_var: 0.77965247631073\n",
      "      vf_loss: 259.5131530761719\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 6.617444999031835e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3341807126998901\n",
      "      kl: 0.004813314415514469\n",
      "      policy_loss: -0.003720993874594569\n",
      "      total_loss: 207.29977416992188\n",
      "      vf_explained_var: 0.7791623473167419\n",
      "      vf_loss: 207.30349731445312\n",
      "    sample_time_ms: 20335.12\n",
      "    update_time_ms: 7.908\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.21986386150432\n",
      "    rl_1: 55.91106661873664\n",
      "  time_since_restore: 1923.781550168991\n",
      "  time_this_iter_s: 23.44094705581665\n",
      "  time_total_s: 1923.781550168991\n",
      "  timestamp: 1550882508\n",
      "  timesteps_since_restore: 810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 810000\n",
      "  training_iteration: 81\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1923 s, 81 iter, 810000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 121.8\n",
      "  episode_reward_max: 219.2384675179006\n",
      "  episode_reward_mean: 154.28972724947226\n",
      "  episode_reward_min: -143.8639647931571\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 4791\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3118.904\n",
      "    load_time_ms: 2.158\n",
      "    num_steps_sampled: 820000\n",
      "    num_steps_trained: 820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.646977999612734e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2412482500076294\n",
      "      kl: 0.004641964100301266\n",
      "      policy_loss: -0.0035948753356933594\n",
      "      total_loss: 84.556396484375\n",
      "      vf_explained_var: 0.9116509556770325\n",
      "      vf_loss: 84.55999755859375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.3087224995159173e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.307334065437317\n",
      "      kl: 0.004335218109190464\n",
      "      policy_loss: -0.0017686696955934167\n",
      "      total_loss: 72.01343536376953\n",
      "      vf_explained_var: 0.9013566374778748\n",
      "      vf_loss: 72.01518249511719\n",
      "    sample_time_ms: 20287.676\n",
      "    update_time_ms: 7.653\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.86365912366682\n",
      "    rl_1: 63.42606812580545\n",
      "  time_since_restore: 1947.0066924095154\n",
      "  time_this_iter_s: 23.225142240524292\n",
      "  time_total_s: 1947.0066924095154\n",
      "  timestamp: 1550882531\n",
      "  timesteps_since_restore: 820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 820000\n",
      "  training_iteration: 82\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1947 s, 82 iter, 820000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-42-34\n",
      "  done: false\n",
      "  episode_len_mean: 136.07\n",
      "  episode_reward_max: 228.9900539665439\n",
      "  episode_reward_mean: 142.49382062222813\n",
      "  episode_reward_min: -175.51230543859472\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 4867\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3101.335\n",
      "    load_time_ms: 2.174\n",
      "    num_steps_sampled: 830000\n",
      "    num_steps_trained: 830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.323488999806367e-24\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2745929956436157\n",
      "      kl: 0.0035322685725986958\n",
      "      policy_loss: -0.0017442498356103897\n",
      "      total_loss: 233.47488403320312\n",
      "      vf_explained_var: 0.7891871929168701\n",
      "      vf_loss: 233.4766082763672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.6543612497579586e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.308825135231018\n",
      "      kl: 0.004351551178842783\n",
      "      policy_loss: -0.0019232500344514847\n",
      "      total_loss: 187.19577026367188\n",
      "      vf_explained_var: 0.7973446846008301\n",
      "      vf_loss: 187.1976776123047\n",
      "    sample_time_ms: 20228.509\n",
      "    update_time_ms: 7.683\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.74200664184407\n",
      "    rl_1: 58.751813980384085\n",
      "  time_since_restore: 1969.7917683124542\n",
      "  time_this_iter_s: 22.785075902938843\n",
      "  time_total_s: 1969.7917683124542\n",
      "  timestamp: 1550882554\n",
      "  timesteps_since_restore: 830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 830000\n",
      "  training_iteration: 83\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1969 s, 83 iter, 830000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-42-57\n",
      "  done: false\n",
      "  episode_len_mean: 123.69\n",
      "  episode_reward_max: 222.61418210158044\n",
      "  episode_reward_mean: 148.77617014355667\n",
      "  episode_reward_min: -147.004754693072\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 4949\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.706\n",
      "    load_time_ms: 2.183\n",
      "    num_steps_sampled: 840000\n",
      "    num_steps_trained: 840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.617444999031835e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2158105373382568\n",
      "      kl: 0.00894695520401001\n",
      "      policy_loss: -0.0033882909920066595\n",
      "      total_loss: 250.3370819091797\n",
      "      vf_explained_var: 0.7629981637001038\n",
      "      vf_loss: 250.3404998779297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 8.271806248789793e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3263643980026245\n",
      "      kl: 0.008198624476790428\n",
      "      policy_loss: -0.008274545893073082\n",
      "      total_loss: 214.5226593017578\n",
      "      vf_explained_var: 0.7470703125\n",
      "      vf_loss: 214.53094482421875\n",
      "    sample_time_ms: 20224.228\n",
      "    update_time_ms: 7.771\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.73088283469222\n",
      "    rl_1: 62.04528730886448\n",
      "  time_since_restore: 1992.990494966507\n",
      "  time_this_iter_s: 23.198726654052734\n",
      "  time_total_s: 1992.990494966507\n",
      "  timestamp: 1550882577\n",
      "  timesteps_since_restore: 840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 840000\n",
      "  training_iteration: 84\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 1992 s, 84 iter, 840000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 138.55\n",
      "  episode_reward_max: 225.68668800325057\n",
      "  episode_reward_mean: 130.31766738361995\n",
      "  episode_reward_min: -152.52569258659145\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 5012\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.275\n",
      "    load_time_ms: 2.214\n",
      "    num_steps_sampled: 850000\n",
      "    num_steps_trained: 850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.3087224995159173e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.337809443473816\n",
      "      kl: 0.0036949904169887304\n",
      "      policy_loss: -0.0035281837917864323\n",
      "      total_loss: 144.68893432617188\n",
      "      vf_explained_var: 0.8591926693916321\n",
      "      vf_loss: 144.69244384765625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.1359031243948966e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3063137531280518\n",
      "      kl: 0.004800039809197187\n",
      "      policy_loss: -0.0024068434722721577\n",
      "      total_loss: 109.267578125\n",
      "      vf_explained_var: 0.8788658380508423\n",
      "      vf_loss: 109.26998138427734\n",
      "    sample_time_ms: 20203.465\n",
      "    update_time_ms: 7.339\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.43022126733504\n",
      "    rl_1: 52.887446116284906\n",
      "  time_since_restore: 2016.3792626857758\n",
      "  time_this_iter_s: 23.3887677192688\n",
      "  time_total_s: 2016.3792626857758\n",
      "  timestamp: 1550882600\n",
      "  timesteps_since_restore: 850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 850000\n",
      "  training_iteration: 85\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2016 s, 85 iter, 850000 ts, 130 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-43-44\n",
      "  done: false\n",
      "  episode_len_mean: 125.24\n",
      "  episode_reward_max: 224.2782014409058\n",
      "  episode_reward_mean: 130.37353274678787\n",
      "  episode_reward_min: -173.46962215750983\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 5093\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.072\n",
      "    load_time_ms: 2.2\n",
      "    num_steps_sampled: 860000\n",
      "    num_steps_trained: 860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6543612497579586e-25\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2636045217514038\n",
      "      kl: 0.004476298578083515\n",
      "      policy_loss: -0.0025826971977949142\n",
      "      total_loss: 188.69253540039062\n",
      "      vf_explained_var: 0.8385618329048157\n",
      "      vf_loss: 188.69512939453125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.0679515621974483e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.3025285005569458\n",
      "      kl: 0.007073161657899618\n",
      "      policy_loss: -0.0031260389368981123\n",
      "      total_loss: 136.2770233154297\n",
      "      vf_explained_var: 0.8573383688926697\n",
      "      vf_loss: 136.28013610839844\n",
      "    sample_time_ms: 20175.732\n",
      "    update_time_ms: 7.986\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.82697334732188\n",
      "    rl_1: 53.54655939946596\n",
      "  time_since_restore: 2039.6070709228516\n",
      "  time_this_iter_s: 23.227808237075806\n",
      "  time_total_s: 2039.6070709228516\n",
      "  timestamp: 1550882624\n",
      "  timesteps_since_restore: 860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 860000\n",
      "  training_iteration: 86\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2039 s, 86 iter, 860000 ts, 130 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-44-07\n",
      "  done: false\n",
      "  episode_len_mean: 112.75\n",
      "  episode_reward_max: 227.87677284658082\n",
      "  episode_reward_mean: 132.15132924858193\n",
      "  episode_reward_min: -173.46962215750983\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 5180\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3116.418\n",
      "    load_time_ms: 2.219\n",
      "    num_steps_sampled: 870000\n",
      "    num_steps_trained: 870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.271806248789793e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2191001176834106\n",
      "      kl: 0.0042527406476438046\n",
      "      policy_loss: -0.0023846514523029327\n",
      "      total_loss: 170.01260375976562\n",
      "      vf_explained_var: 0.8645700216293335\n",
      "      vf_loss: 170.01498413085938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.0339757810987241e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2885915040969849\n",
      "      kl: 0.0038312256801873446\n",
      "      policy_loss: -0.0015834320802241564\n",
      "      total_loss: 145.682373046875\n",
      "      vf_explained_var: 0.8514243960380554\n",
      "      vf_loss: 145.68394470214844\n",
      "    sample_time_ms: 20118.404\n",
      "    update_time_ms: 7.782\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.88084942511131\n",
      "    rl_1: 55.27047982347062\n",
      "  time_since_restore: 2062.961684703827\n",
      "  time_this_iter_s: 23.354613780975342\n",
      "  time_total_s: 2062.961684703827\n",
      "  timestamp: 1550882647\n",
      "  timesteps_since_restore: 870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 870000\n",
      "  training_iteration: 87\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2062 s, 87 iter, 870000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-44-30\n",
      "  done: false\n",
      "  episode_len_mean: 107.04\n",
      "  episode_reward_max: 221.63267132479874\n",
      "  episode_reward_mean: 128.25806829265824\n",
      "  episode_reward_min: -172.95057247236764\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 5274\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.392\n",
      "    load_time_ms: 2.21\n",
      "    num_steps_sampled: 880000\n",
      "    num_steps_trained: 880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.1359031243948966e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.189784049987793\n",
      "      kl: 0.006264924071729183\n",
      "      policy_loss: -0.0020166158210486174\n",
      "      total_loss: 349.3950500488281\n",
      "      vf_explained_var: 0.7770196199417114\n",
      "      vf_loss: 349.3971252441406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.169878905493621e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2914551496505737\n",
      "      kl: 0.004591863602399826\n",
      "      policy_loss: -0.0017511695623397827\n",
      "      total_loss: 269.28912353515625\n",
      "      vf_explained_var: 0.7756455540657043\n",
      "      vf_loss: 269.2908630371094\n",
      "    sample_time_ms: 20051.704\n",
      "    update_time_ms: 8.206\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 73.82828360448961\n",
      "    rl_1: 54.42978468816867\n",
      "  time_since_restore: 2085.783612012863\n",
      "  time_this_iter_s: 22.821927309036255\n",
      "  time_total_s: 2085.783612012863\n",
      "  timestamp: 1550882670\n",
      "  timesteps_since_restore: 880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 880000\n",
      "  training_iteration: 88\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2085 s, 88 iter, 880000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-44-53\n",
      "  done: false\n",
      "  episode_len_mean: 112.99\n",
      "  episode_reward_max: 225.42401336776175\n",
      "  episode_reward_mean: 148.50216040672413\n",
      "  episode_reward_min: -168.8489741517377\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 5362\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.246\n",
      "    load_time_ms: 2.226\n",
      "    num_steps_sampled: 890000\n",
      "    num_steps_trained: 890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0679515621974483e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1969630718231201\n",
      "      kl: 0.008241446688771248\n",
      "      policy_loss: -0.002896299120038748\n",
      "      total_loss: 170.65133666992188\n",
      "      vf_explained_var: 0.8716408014297485\n",
      "      vf_loss: 170.6542205810547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.5849394527468104e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.286259651184082\n",
      "      kl: 0.008573168888688087\n",
      "      policy_loss: -0.004110776819288731\n",
      "      total_loss: 147.70501708984375\n",
      "      vf_explained_var: 0.8598341345787048\n",
      "      vf_loss: 147.70913696289062\n",
      "    sample_time_ms: 20051.479\n",
      "    update_time_ms: 8.196\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.89454956897583\n",
      "    rl_1: 63.60761083774832\n",
      "  time_since_restore: 2109.0469574928284\n",
      "  time_this_iter_s: 23.26334547996521\n",
      "  time_total_s: 2109.0469574928284\n",
      "  timestamp: 1550882693\n",
      "  timesteps_since_restore: 890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 890000\n",
      "  training_iteration: 89\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2109 s, 89 iter, 890000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-45-16\n",
      "  done: false\n",
      "  episode_len_mean: 113.05\n",
      "  episode_reward_max: 222.43331099681157\n",
      "  episode_reward_mean: 127.42525754557718\n",
      "  episode_reward_min: -157.0576347849017\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 5449\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.287\n",
      "    load_time_ms: 2.252\n",
      "    num_steps_sampled: 900000\n",
      "    num_steps_trained: 900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0339757810987241e-26\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2228657007217407\n",
      "      kl: 0.004121205769479275\n",
      "      policy_loss: -0.0024744553957134485\n",
      "      total_loss: 313.74139404296875\n",
      "      vf_explained_var: 0.7639987468719482\n",
      "      vf_loss: 313.743896484375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.2924697263734052e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.292459487915039\n",
      "      kl: 0.006186627317219973\n",
      "      policy_loss: -0.004614412318915129\n",
      "      total_loss: 245.52847290039062\n",
      "      vf_explained_var: 0.8022170662879944\n",
      "      vf_loss: 245.53309631347656\n",
      "    sample_time_ms: 20058.417\n",
      "    update_time_ms: 8.265\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.44257055822938\n",
      "    rl_1: 52.98268698734782\n",
      "  time_since_restore: 2132.175031900406\n",
      "  time_this_iter_s: 23.128074407577515\n",
      "  time_total_s: 2132.175031900406\n",
      "  timestamp: 1550882716\n",
      "  timesteps_since_restore: 900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 900000\n",
      "  training_iteration: 90\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2132 s, 90 iter, 900000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-45-40\n",
      "  done: false\n",
      "  episode_len_mean: 106.66\n",
      "  episode_reward_max: 212.82795252673017\n",
      "  episode_reward_mean: 139.49760275703787\n",
      "  episode_reward_min: -177.47506019295858\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 5543\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3117.847\n",
      "    load_time_ms: 2.254\n",
      "    num_steps_sampled: 910000\n",
      "    num_steps_trained: 910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.169878905493621e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.188462495803833\n",
      "      kl: 0.00401444872841239\n",
      "      policy_loss: -0.001215850468724966\n",
      "      total_loss: 179.33436584472656\n",
      "      vf_explained_var: 0.8637686371803284\n",
      "      vf_loss: 179.33555603027344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 6.462348631867026e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.295680046081543\n",
      "      kl: 0.005015520378947258\n",
      "      policy_loss: -0.0025336332619190216\n",
      "      total_loss: 144.316162109375\n",
      "      vf_explained_var: 0.8620297312736511\n",
      "      vf_loss: 144.3186798095703\n",
      "    sample_time_ms: 20021.078\n",
      "    update_time_ms: 7.981\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.00633461675147\n",
      "    rl_1: 58.4912681402864\n",
      "  time_since_restore: 2155.4441142082214\n",
      "  time_this_iter_s: 23.26908230781555\n",
      "  time_total_s: 2155.4441142082214\n",
      "  timestamp: 1550882740\n",
      "  timesteps_since_restore: 910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 910000\n",
      "  training_iteration: 91\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2155 s, 91 iter, 910000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-46-03\n",
      "  done: false\n",
      "  episode_len_mean: 111.72\n",
      "  episode_reward_max: 221.3380970794555\n",
      "  episode_reward_mean: 139.16080997524037\n",
      "  episode_reward_min: -175.38699166446787\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 5632\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3117.532\n",
      "    load_time_ms: 2.308\n",
      "    num_steps_sampled: 920000\n",
      "    num_steps_trained: 920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.5849394527468104e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2175368070602417\n",
      "      kl: 0.0037608291022479534\n",
      "      policy_loss: -0.0021403739228844643\n",
      "      total_loss: 219.4983673095703\n",
      "      vf_explained_var: 0.8559752106666565\n",
      "      vf_loss: 219.50047302246094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.231174315933513e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2958080768585205\n",
      "      kl: 0.004679689649492502\n",
      "      policy_loss: -0.0030710063874721527\n",
      "      total_loss: 182.41464233398438\n",
      "      vf_explained_var: 0.8588424921035767\n",
      "      vf_loss: 182.41769409179688\n",
      "    sample_time_ms: 20023.923\n",
      "    update_time_ms: 7.923\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.67590307974625\n",
      "    rl_1: 60.48490689549411\n",
      "  time_since_restore: 2178.695729970932\n",
      "  time_this_iter_s: 23.25161576271057\n",
      "  time_total_s: 2178.695729970932\n",
      "  timestamp: 1550882763\n",
      "  timesteps_since_restore: 920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 920000\n",
      "  training_iteration: 92\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2178 s, 92 iter, 920000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-46-26\n",
      "  done: false\n",
      "  episode_len_mean: 123.19\n",
      "  episode_reward_max: 228.5412791836351\n",
      "  episode_reward_mean: 149.23388885824934\n",
      "  episode_reward_min: -152.96588506469845\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 5713\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3115.093\n",
      "    load_time_ms: 2.3\n",
      "    num_steps_sampled: 930000\n",
      "    num_steps_trained: 930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2924697263734052e-27\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2430810928344727\n",
      "      kl: 0.006543973460793495\n",
      "      policy_loss: -0.0018718510400503874\n",
      "      total_loss: 111.0263900756836\n",
      "      vf_explained_var: 0.916610598564148\n",
      "      vf_loss: 111.02826690673828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.6155871579667565e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2947465181350708\n",
      "      kl: 0.00733792781829834\n",
      "      policy_loss: -0.003430198412388563\n",
      "      total_loss: 104.64936065673828\n",
      "      vf_explained_var: 0.8970301747322083\n",
      "      vf_loss: 104.65279388427734\n",
      "    sample_time_ms: 20020.366\n",
      "    update_time_ms: 7.986\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.22830820053763\n",
      "    rl_1: 63.005580657711704\n",
      "  time_since_restore: 2201.42333316803\n",
      "  time_this_iter_s: 22.72760319709778\n",
      "  time_total_s: 2201.42333316803\n",
      "  timestamp: 1550882786\n",
      "  timesteps_since_restore: 930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 930000\n",
      "  training_iteration: 93\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2201 s, 93 iter, 930000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-46-49\n",
      "  done: false\n",
      "  episode_len_mean: 115.34\n",
      "  episode_reward_max: 228.5412791836351\n",
      "  episode_reward_mean: 144.64367493646364\n",
      "  episode_reward_min: -176.18981390587572\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 5803\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3114.658\n",
      "    load_time_ms: 2.323\n",
      "    num_steps_sampled: 940000\n",
      "    num_steps_trained: 940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.462348631867026e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.220112919807434\n",
      "      kl: 0.003356331028044224\n",
      "      policy_loss: -0.0019035509321838617\n",
      "      total_loss: 190.4070281982422\n",
      "      vf_explained_var: 0.8501358032226562\n",
      "      vf_loss: 190.408935546875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 8.077935789833782e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2908087968826294\n",
      "      kl: 0.003662814386188984\n",
      "      policy_loss: -0.001063842442817986\n",
      "      total_loss: 174.30772399902344\n",
      "      vf_explained_var: 0.8404384255409241\n",
      "      vf_loss: 174.30877685546875\n",
      "    sample_time_ms: 20022.928\n",
      "    update_time_ms: 8.575\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.71988590473467\n",
      "    rl_1: 63.92378903172897\n",
      "  time_since_restore: 2224.6492488384247\n",
      "  time_this_iter_s: 23.225915670394897\n",
      "  time_total_s: 2224.6492488384247\n",
      "  timestamp: 1550882809\n",
      "  timesteps_since_restore: 940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 940000\n",
      "  training_iteration: 94\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2224 s, 94 iter, 940000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-47-12\n",
      "  done: false\n",
      "  episode_len_mean: 123.75\n",
      "  episode_reward_max: 223.2915462625158\n",
      "  episode_reward_mean: 120.89213223980916\n",
      "  episode_reward_min: -176.18981390587572\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 5884\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3112.025\n",
      "    load_time_ms: 2.368\n",
      "    num_steps_sampled: 950000\n",
      "    num_steps_trained: 950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.231174315933513e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2397916316986084\n",
      "      kl: 0.003809463232755661\n",
      "      policy_loss: -0.002593162702396512\n",
      "      total_loss: 320.68792724609375\n",
      "      vf_explained_var: 0.8036791682243347\n",
      "      vf_loss: 320.6905212402344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.038967894916891e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2826299667358398\n",
      "      kl: 0.007731015793979168\n",
      "      policy_loss: -0.003832776565104723\n",
      "      total_loss: 258.1731262207031\n",
      "      vf_explained_var: 0.8230096697807312\n",
      "      vf_loss: 258.1769714355469\n",
      "    sample_time_ms: 19951.865\n",
      "    update_time_ms: 8.563\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.46994092422209\n",
      "    rl_1: 53.42219131558708\n",
      "  time_since_restore: 2247.3048181533813\n",
      "  time_this_iter_s: 22.655569314956665\n",
      "  time_total_s: 2247.3048181533813\n",
      "  timestamp: 1550882832\n",
      "  timesteps_since_restore: 950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 950000\n",
      "  training_iteration: 95\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2247 s, 95 iter, 950000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-47-35\n",
      "  done: false\n",
      "  episode_len_mean: 117.26\n",
      "  episode_reward_max: 227.10995728791457\n",
      "  episode_reward_mean: 138.99086795998045\n",
      "  episode_reward_min: -133.45986124122516\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 5972\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3109.961\n",
      "    load_time_ms: 2.374\n",
      "    num_steps_sampled: 960000\n",
      "    num_steps_trained: 960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.6155871579667565e-28\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.208694338798523\n",
      "      kl: 0.005603461526334286\n",
      "      policy_loss: -0.004469421226531267\n",
      "      total_loss: 201.63381958007812\n",
      "      vf_explained_var: 0.8562736511230469\n",
      "      vf_loss: 201.63829040527344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.0194839474584456e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2901673316955566\n",
      "      kl: 0.0009961428586393595\n",
      "      policy_loss: -0.0009145760559476912\n",
      "      total_loss: 170.51536560058594\n",
      "      vf_explained_var: 0.8613120913505554\n",
      "      vf_loss: 170.5162811279297\n",
      "    sample_time_ms: 19930.48\n",
      "    update_time_ms: 7.956\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.81666951222903\n",
      "    rl_1: 62.17419844775143\n",
      "  time_since_restore: 2270.2940850257874\n",
      "  time_this_iter_s: 22.989266872406006\n",
      "  time_total_s: 2270.2940850257874\n",
      "  timestamp: 1550882855\n",
      "  timesteps_since_restore: 960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 960000\n",
      "  training_iteration: 96\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2270 s, 96 iter, 960000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-47-58\n",
      "  done: false\n",
      "  episode_len_mean: 121.71\n",
      "  episode_reward_max: 231.35241759880788\n",
      "  episode_reward_mean: 142.3399378430428\n",
      "  episode_reward_min: -153.94732642995558\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 6052\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.77\n",
      "    load_time_ms: 2.476\n",
      "    num_steps_sampled: 970000\n",
      "    num_steps_trained: 970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.077935789833782e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2271682024002075\n",
      "      kl: 0.0038427377585321665\n",
      "      policy_loss: -0.0024652224965393543\n",
      "      total_loss: 148.7659454345703\n",
      "      vf_explained_var: 0.8872793316841125\n",
      "      vf_loss: 148.76840209960938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.0097419737292228e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.287821888923645\n",
      "      kl: 0.003867881838232279\n",
      "      policy_loss: -0.002312843222171068\n",
      "      total_loss: 137.37083435058594\n",
      "      vf_explained_var: 0.882828950881958\n",
      "      vf_loss: 137.37315368652344\n",
      "    sample_time_ms: 19911.114\n",
      "    update_time_ms: 8.006\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.26238098472551\n",
      "    rl_1: 62.077556858317294\n",
      "  time_since_restore: 2293.1944568157196\n",
      "  time_this_iter_s: 22.90037178993225\n",
      "  time_total_s: 2293.1944568157196\n",
      "  timestamp: 1550882878\n",
      "  timesteps_since_restore: 970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 970000\n",
      "  training_iteration: 97\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2293 s, 97 iter, 970000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-48-21\n",
      "  done: false\n",
      "  episode_len_mean: 117.08\n",
      "  episode_reward_max: 225.64926341326097\n",
      "  episode_reward_mean: 128.28448841860092\n",
      "  episode_reward_min: -177.26112265382676\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 6138\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.529\n",
      "    load_time_ms: 2.407\n",
      "    num_steps_sampled: 980000\n",
      "    num_steps_trained: 980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.038967894916891e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1945675611495972\n",
      "      kl: 0.005727292504161596\n",
      "      policy_loss: -0.0025877191219478846\n",
      "      total_loss: 259.765869140625\n",
      "      vf_explained_var: 0.81344074010849\n",
      "      vf_loss: 259.76849365234375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.048709868646114e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2825028896331787\n",
      "      kl: 0.004922191612422466\n",
      "      policy_loss: -0.004280319437384605\n",
      "      total_loss: 211.8289794921875\n",
      "      vf_explained_var: 0.8377128839492798\n",
      "      vf_loss: 211.83328247070312\n",
      "    sample_time_ms: 19976.229\n",
      "    update_time_ms: 7.704\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.37239178240235\n",
      "    rl_1: 55.912096636198584\n",
      "  time_since_restore: 2316.658551931381\n",
      "  time_this_iter_s: 23.46409511566162\n",
      "  time_total_s: 2316.658551931381\n",
      "  timestamp: 1550882901\n",
      "  timesteps_since_restore: 980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 980000\n",
      "  training_iteration: 98\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2316 s, 98 iter, 980000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-48-45\n",
      "  done: false\n",
      "  episode_len_mean: 110.63\n",
      "  episode_reward_max: 229.48032182458124\n",
      "  episode_reward_mean: 158.45646152418283\n",
      "  episode_reward_min: -161.75918492505622\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 6229\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.287\n",
      "    load_time_ms: 2.469\n",
      "    num_steps_sampled: 990000\n",
      "    num_steps_trained: 990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.0194839474584456e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.201766848564148\n",
      "      kl: 0.0020650874357670546\n",
      "      policy_loss: -0.0011143848532810807\n",
      "      total_loss: 183.7224884033203\n",
      "      vf_explained_var: 0.8519773483276367\n",
      "      vf_loss: 183.7235870361328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.524354934323057e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2766458988189697\n",
      "      kl: 0.005871281959116459\n",
      "      policy_loss: -0.004334254655987024\n",
      "      total_loss: 157.53395080566406\n",
      "      vf_explained_var: 0.8397558927536011\n",
      "      vf_loss: 157.5382537841797\n",
      "    sample_time_ms: 19999.305\n",
      "    update_time_ms: 8.623\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.19332896015214\n",
      "    rl_1: 70.26313256403064\n",
      "  time_since_restore: 2340.119813680649\n",
      "  time_this_iter_s: 23.461261749267578\n",
      "  time_total_s: 2340.119813680649\n",
      "  timestamp: 1550882925\n",
      "  timesteps_since_restore: 990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 990000\n",
      "  training_iteration: 99\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2340 s, 99 iter, 990000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-49-08\n",
      "  done: false\n",
      "  episode_len_mean: 125.31\n",
      "  episode_reward_max: 225.16599318271759\n",
      "  episode_reward_mean: 131.23995421274606\n",
      "  episode_reward_min: -177.70848331484996\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 6305\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.098\n",
      "    load_time_ms: 2.512\n",
      "    num_steps_sampled: 1000000\n",
      "    num_steps_trained: 1000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.0097419737292228e-29\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2767598628997803\n",
      "      kl: 0.0037948954850435257\n",
      "      policy_loss: -0.0027340759988874197\n",
      "      total_loss: 181.63632202148438\n",
      "      vf_explained_var: 0.8829603791236877\n",
      "      vf_loss: 181.63905334472656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.2621774671615285e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2870464324951172\n",
      "      kl: 0.003693987615406513\n",
      "      policy_loss: -0.002052904339507222\n",
      "      total_loss: 143.90896606445312\n",
      "      vf_explained_var: 0.9015229940414429\n",
      "      vf_loss: 143.91102600097656\n",
      "    sample_time_ms: 19978.172\n",
      "    update_time_ms: 8.607\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.2113616506176\n",
      "    rl_1: 56.02859256212843\n",
      "  time_since_restore: 2363.2161300182343\n",
      "  time_this_iter_s: 23.09631633758545\n",
      "  time_total_s: 2363.2161300182343\n",
      "  timestamp: 1550882948\n",
      "  timesteps_since_restore: 1000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1000000\n",
      "  training_iteration: 100\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2363 s, 100 iter, 1000000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-49-31\n",
      "  done: false\n",
      "  episode_len_mean: 119.86\n",
      "  episode_reward_max: 226.87121113196443\n",
      "  episode_reward_mean: 125.8169660632911\n",
      "  episode_reward_min: -177.70848331484996\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 6386\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.468\n",
      "    load_time_ms: 2.534\n",
      "    num_steps_sampled: 1010000\n",
      "    num_steps_trained: 1010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.048709868646114e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2240606546401978\n",
      "      kl: 0.004165951162576675\n",
      "      policy_loss: -0.0034791724756360054\n",
      "      total_loss: 175.05885314941406\n",
      "      vf_explained_var: 0.8883804082870483\n",
      "      vf_loss: 175.0623321533203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 6.3108873358076425e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2666248083114624\n",
      "      kl: 0.00416746037080884\n",
      "      policy_loss: -0.0030228067189455032\n",
      "      total_loss: 141.55572509765625\n",
      "      vf_explained_var: 0.8976613283157349\n",
      "      vf_loss: 141.5587615966797\n",
      "    sample_time_ms: 19964.11\n",
      "    update_time_ms: 8.907\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.71305212688353\n",
      "    rl_1: 54.103913936407565\n",
      "  time_since_restore: 2386.092203140259\n",
      "  time_this_iter_s: 22.876073122024536\n",
      "  time_total_s: 2386.092203140259\n",
      "  timestamp: 1550882971\n",
      "  timesteps_since_restore: 1010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1010000\n",
      "  training_iteration: 101\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2386 s, 101 iter, 1010000 ts, 126 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-49-54\n",
      "  done: false\n",
      "  episode_len_mean: 115.95\n",
      "  episode_reward_max: 220.5575913477235\n",
      "  episode_reward_mean: 129.60858249459798\n",
      "  episode_reward_min: -180.10668812275208\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 6480\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.96\n",
      "    load_time_ms: 2.535\n",
      "    num_steps_sampled: 1020000\n",
      "    num_steps_trained: 1020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.524354934323057e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1597864627838135\n",
      "      kl: 0.003960727714002132\n",
      "      policy_loss: -0.0022484620567411184\n",
      "      total_loss: 226.21429443359375\n",
      "      vf_explained_var: 0.8685263395309448\n",
      "      vf_loss: 226.216552734375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.1554436679038213e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2463195323944092\n",
      "      kl: 0.007032155990600586\n",
      "      policy_loss: -0.0031712432391941547\n",
      "      total_loss: 172.46218872070312\n",
      "      vf_explained_var: 0.8773024082183838\n",
      "      vf_loss: 172.46536254882812\n",
      "    sample_time_ms: 19968.306\n",
      "    update_time_ms: 8.802\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.32434416467873\n",
      "    rl_1: 55.28423832991927\n",
      "  time_since_restore: 2409.3693594932556\n",
      "  time_this_iter_s: 23.277156352996826\n",
      "  time_total_s: 2409.3693594932556\n",
      "  timestamp: 1550882994\n",
      "  timesteps_since_restore: 1020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1020000\n",
      "  training_iteration: 102\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2409 s, 102 iter, 1020000 ts, 130 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-50-18\n",
      "  done: false\n",
      "  episode_len_mean: 100.03\n",
      "  episode_reward_max: 238.96963109225075\n",
      "  episode_reward_mean: 143.0114807097086\n",
      "  episode_reward_min: -176.37674569957335\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 6580\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.701\n",
      "    load_time_ms: 2.663\n",
      "    num_steps_sampled: 1030000\n",
      "    num_steps_trained: 1030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2621774671615285e-30\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1023670434951782\n",
      "      kl: 0.00816644448786974\n",
      "      policy_loss: -0.003677149536088109\n",
      "      total_loss: 211.73092651367188\n",
      "      vf_explained_var: 0.8740479946136475\n",
      "      vf_loss: 211.734619140625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.5777218339519106e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2263673543930054\n",
      "      kl: 0.007713144179433584\n",
      "      policy_loss: -0.0029824129305779934\n",
      "      total_loss: 185.2170867919922\n",
      "      vf_explained_var: 0.8552316427230835\n",
      "      vf_loss: 185.22007751464844\n",
      "    sample_time_ms: 20065.274\n",
      "    update_time_ms: 8.83\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.81108337230692\n",
      "    rl_1: 61.20039733740165\n",
      "  time_since_restore: 2433.0433025360107\n",
      "  time_this_iter_s: 23.673943042755127\n",
      "  time_total_s: 2433.0433025360107\n",
      "  timestamp: 1550883018\n",
      "  timesteps_since_restore: 1030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1030000\n",
      "  training_iteration: 103\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2433 s, 103 iter, 1030000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-50-41\n",
      "  done: false\n",
      "  episode_len_mean: 110.81\n",
      "  episode_reward_max: 236.89928188003597\n",
      "  episode_reward_mean: 144.66962692533667\n",
      "  episode_reward_min: -129.29823275175096\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 6669\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.696\n",
      "    load_time_ms: 2.638\n",
      "    num_steps_sampled: 1040000\n",
      "    num_steps_trained: 1040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.3108873358076425e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1507186889648438\n",
      "      kl: 0.00794743187725544\n",
      "      policy_loss: -0.0033992023672908545\n",
      "      total_loss: 210.69781494140625\n",
      "      vf_explained_var: 0.8426501154899597\n",
      "      vf_loss: 210.70120239257812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.888609169759553e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2367823123931885\n",
      "      kl: 0.006354539655148983\n",
      "      policy_loss: -0.004031652119010687\n",
      "      total_loss: 189.11720275878906\n",
      "      vf_explained_var: 0.8397237062454224\n",
      "      vf_loss: 189.12123107910156\n",
      "    sample_time_ms: 20095.654\n",
      "    update_time_ms: 8.034\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.03934496266702\n",
      "    rl_1: 63.63028196266964\n",
      "  time_since_restore: 2456.544003009796\n",
      "  time_this_iter_s: 23.5007004737854\n",
      "  time_total_s: 2456.544003009796\n",
      "  timestamp: 1550883041\n",
      "  timesteps_since_restore: 1040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1040000\n",
      "  training_iteration: 104\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2456 s, 104 iter, 1040000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-51-05\n",
      "  done: false\n",
      "  episode_len_mean: 121.36\n",
      "  episode_reward_max: 236.89928188003597\n",
      "  episode_reward_mean: 155.42839941394195\n",
      "  episode_reward_min: -158.15846639205154\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 6750\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3063.788\n",
      "    load_time_ms: 2.599\n",
      "    num_steps_sampled: 1050000\n",
      "    num_steps_trained: 1050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.1554436679038213e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.181519627571106\n",
      "      kl: 0.004522817209362984\n",
      "      policy_loss: -0.0028103129006922245\n",
      "      total_loss: 152.5612335205078\n",
      "      vf_explained_var: 0.8796184062957764\n",
      "      vf_loss: 152.5640411376953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.9443045848797766e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2496488094329834\n",
      "      kl: 0.002758676651865244\n",
      "      policy_loss: -0.0009304434061050415\n",
      "      total_loss: 130.17318725585938\n",
      "      vf_explained_var: 0.8798895478248596\n",
      "      vf_loss: 130.1741485595703\n",
      "    sample_time_ms: 20147.554\n",
      "    update_time_ms: 8.301\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.1935396753416\n",
      "    rl_1: 67.23485973860032\n",
      "  time_since_restore: 2479.6982476711273\n",
      "  time_this_iter_s: 23.154244661331177\n",
      "  time_total_s: 2479.6982476711273\n",
      "  timestamp: 1550883065\n",
      "  timesteps_since_restore: 1050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1050000\n",
      "  training_iteration: 105\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2479 s, 105 iter, 1050000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-51-28\n",
      "  done: false\n",
      "  episode_len_mean: 105.21\n",
      "  episode_reward_max: 231.71543867221774\n",
      "  episode_reward_mean: 134.64287193764338\n",
      "  episode_reward_min: -180.3790050538301\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 6848\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.194\n",
      "    load_time_ms: 2.592\n",
      "    num_steps_sampled: 1060000\n",
      "    num_steps_trained: 1060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5777218339519106e-31\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.110789179801941\n",
      "      kl: 0.00638157781213522\n",
      "      policy_loss: -0.0031186288688331842\n",
      "      total_loss: 290.6395263671875\n",
      "      vf_explained_var: 0.8105114698410034\n",
      "      vf_loss: 290.6426086425781\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.9721522924398883e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2079442739486694\n",
      "      kl: 0.007343752309679985\n",
      "      policy_loss: -0.0037081600166857243\n",
      "      total_loss: 237.46788024902344\n",
      "      vf_explained_var: 0.8074259161949158\n",
      "      vf_loss: 237.47157287597656\n",
      "    sample_time_ms: 20185.803\n",
      "    update_time_ms: 8.252\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.89998343642795\n",
      "    rl_1: 57.74288850121545\n",
      "  time_since_restore: 2503.075215578079\n",
      "  time_this_iter_s: 23.376967906951904\n",
      "  time_total_s: 2503.075215578079\n",
      "  timestamp: 1550883088\n",
      "  timesteps_since_restore: 1060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1060000\n",
      "  training_iteration: 106\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2503 s, 106 iter, 1060000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-51-52\n",
      "  done: false\n",
      "  episode_len_mean: 110.49\n",
      "  episode_reward_max: 228.75296945023797\n",
      "  episode_reward_mean: 131.53732147864386\n",
      "  episode_reward_min: -180.3790050538301\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 6935\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.951\n",
      "    load_time_ms: 2.526\n",
      "    num_steps_sampled: 1070000\n",
      "    num_steps_trained: 1070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.888609169759553e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1575859785079956\n",
      "      kl: 0.0063865953125059605\n",
      "      policy_loss: -0.0029829726554453373\n",
      "      total_loss: 150.2247772216797\n",
      "      vf_explained_var: 0.8984667658805847\n",
      "      vf_loss: 150.2277374267578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 9.860761462199441e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2312511205673218\n",
      "      kl: 0.004297592211514711\n",
      "      policy_loss: -0.0030832940246909857\n",
      "      total_loss: 129.82513427734375\n",
      "      vf_explained_var: 0.8820330500602722\n",
      "      vf_loss: 129.8282012939453\n",
      "    sample_time_ms: 20248.256\n",
      "    update_time_ms: 8.582\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.33247661820857\n",
      "    rl_1: 57.20484486043531\n",
      "  time_since_restore: 2526.594497680664\n",
      "  time_this_iter_s: 23.51928210258484\n",
      "  time_total_s: 2526.594497680664\n",
      "  timestamp: 1550883112\n",
      "  timesteps_since_restore: 1070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1070000\n",
      "  training_iteration: 107\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2526 s, 107 iter, 1070000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-52-14\n",
      "  done: false\n",
      "  episode_len_mean: 125.91\n",
      "  episode_reward_max: 234.58267698380314\n",
      "  episode_reward_mean: 151.6140817721215\n",
      "  episode_reward_min: -170.08184056640698\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 7010\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.908\n",
      "    load_time_ms: 2.572\n",
      "    num_steps_sampled: 1080000\n",
      "    num_steps_trained: 1080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.9443045848797766e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2264223098754883\n",
      "      kl: 0.004963750019669533\n",
      "      policy_loss: -0.002489035716280341\n",
      "      total_loss: 114.93568420410156\n",
      "      vf_explained_var: 0.9273675084114075\n",
      "      vf_loss: 114.93817901611328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.930380731099721e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2399108409881592\n",
      "      kl: 0.005970754660665989\n",
      "      policy_loss: -0.0026725041680037975\n",
      "      total_loss: 93.2139892578125\n",
      "      vf_explained_var: 0.9205375909805298\n",
      "      vf_loss: 93.2166748046875\n",
      "    sample_time_ms: 20156.055\n",
      "    update_time_ms: 9.227\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.91765160891056\n",
      "    rl_1: 65.69643016321092\n",
      "  time_since_restore: 2549.234535217285\n",
      "  time_this_iter_s: 22.640037536621094\n",
      "  time_total_s: 2549.234535217285\n",
      "  timestamp: 1550883134\n",
      "  timesteps_since_restore: 1080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1080000\n",
      "  training_iteration: 108\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2549 s, 108 iter, 1080000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-52-37\n",
      "  done: false\n",
      "  episode_len_mean: 138.29\n",
      "  episode_reward_max: 234.58267698380314\n",
      "  episode_reward_mean: 146.47459205264195\n",
      "  episode_reward_min: -174.7450568018487\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 7089\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.725\n",
      "    load_time_ms: 2.533\n",
      "    num_steps_sampled: 1090000\n",
      "    num_steps_trained: 1090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.9721522924398883e-32\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1998413801193237\n",
      "      kl: 0.005998076871037483\n",
      "      policy_loss: -0.0028143743984401226\n",
      "      total_loss: 121.90904235839844\n",
      "      vf_explained_var: 0.9134466648101807\n",
      "      vf_loss: 121.91187286376953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.4651903655498604e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2227685451507568\n",
      "      kl: 0.005202946253120899\n",
      "      policy_loss: -0.003171239048242569\n",
      "      total_loss: 109.84271240234375\n",
      "      vf_explained_var: 0.9092569351196289\n",
      "      vf_loss: 109.84587860107422\n",
      "    sample_time_ms: 20080.217\n",
      "    update_time_ms: 8.282\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.01898725226272\n",
      "    rl_1: 62.45560480037924\n",
      "  time_since_restore: 2572.1474549770355\n",
      "  time_this_iter_s: 22.912919759750366\n",
      "  time_total_s: 2572.1474549770355\n",
      "  timestamp: 1550883157\n",
      "  timesteps_since_restore: 1090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1090000\n",
      "  training_iteration: 109\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2572 s, 109 iter, 1090000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-53-00\n",
      "  done: false\n",
      "  episode_len_mean: 113.74\n",
      "  episode_reward_max: 232.444994820026\n",
      "  episode_reward_mean: 131.03933011309766\n",
      "  episode_reward_min: -177.07182487101448\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 7179\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.668\n",
      "    load_time_ms: 2.465\n",
      "    num_steps_sampled: 1100000\n",
      "    num_steps_trained: 1100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.860761462199441e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1314996480941772\n",
      "      kl: 0.007831055670976639\n",
      "      policy_loss: -0.004103930201381445\n",
      "      total_loss: 158.70057678222656\n",
      "      vf_explained_var: 0.9004577994346619\n",
      "      vf_loss: 158.7046661376953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.2325951827749302e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2159024477005005\n",
      "      kl: 0.006010562181472778\n",
      "      policy_loss: -0.0029957459773868322\n",
      "      total_loss: 129.776611328125\n",
      "      vf_explained_var: 0.9023498296737671\n",
      "      vf_loss: 129.77960205078125\n",
      "    sample_time_ms: 20077.903\n",
      "    update_time_ms: 8.398\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.44161913770718\n",
      "    rl_1: 56.5977109753905\n",
      "  time_since_restore: 2595.0703513622284\n",
      "  time_this_iter_s: 22.92289638519287\n",
      "  time_total_s: 2595.0703513622284\n",
      "  timestamp: 1550883180\n",
      "  timesteps_since_restore: 1100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1100000\n",
      "  training_iteration: 110\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2595 s, 110 iter, 1100000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-53-24\n",
      "  done: false\n",
      "  episode_len_mean: 103.16\n",
      "  episode_reward_max: 229.46155471644363\n",
      "  episode_reward_mean: 139.90524465164856\n",
      "  episode_reward_min: -177.25566785088438\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 7276\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.213\n",
      "    load_time_ms: 2.492\n",
      "    num_steps_sampled: 1110000\n",
      "    num_steps_trained: 1110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.930380731099721e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1136951446533203\n",
      "      kl: 0.006772803142666817\n",
      "      policy_loss: -0.003603540128096938\n",
      "      total_loss: 246.93112182617188\n",
      "      vf_explained_var: 0.8557285666465759\n",
      "      vf_loss: 246.93472290039062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 6.162975913874651e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1754862070083618\n",
      "      kl: 0.006273615173995495\n",
      "      policy_loss: -0.0035439766943454742\n",
      "      total_loss: 199.5802764892578\n",
      "      vf_explained_var: 0.8590598702430725\n",
      "      vf_loss: 199.58383178710938\n",
      "    sample_time_ms: 20141.593\n",
      "    update_time_ms: 7.985\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.27286176503723\n",
      "    rl_1: 62.632382886611325\n",
      "  time_since_restore: 2618.604743242264\n",
      "  time_this_iter_s: 23.5343918800354\n",
      "  time_total_s: 2618.604743242264\n",
      "  timestamp: 1550883204\n",
      "  timesteps_since_restore: 1110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1110000\n",
      "  training_iteration: 111\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2618 s, 111 iter, 1110000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-53-47\n",
      "  done: false\n",
      "  episode_len_mean: 111.04\n",
      "  episode_reward_max: 234.42478164204994\n",
      "  episode_reward_mean: 140.69622957854864\n",
      "  episode_reward_min: -181.63399458040402\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 7365\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.433\n",
      "    load_time_ms: 2.5\n",
      "    num_steps_sampled: 1120000\n",
      "    num_steps_trained: 1120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4651903655498604e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1545394659042358\n",
      "      kl: 0.004109538160264492\n",
      "      policy_loss: -0.001576998271048069\n",
      "      total_loss: 177.63514709472656\n",
      "      vf_explained_var: 0.8893649578094482\n",
      "      vf_loss: 177.63674926757812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.0814879569373254e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1970043182373047\n",
      "      kl: 0.005260707810521126\n",
      "      policy_loss: -0.003712070407345891\n",
      "      total_loss: 147.96588134765625\n",
      "      vf_explained_var: 0.9007667899131775\n",
      "      vf_loss: 147.96961975097656\n",
      "    sample_time_ms: 20099.577\n",
      "    update_time_ms: 8.445\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.58653961610347\n",
      "    rl_1: 63.109689962445174\n",
      "  time_since_restore: 2641.467577457428\n",
      "  time_this_iter_s: 22.862834215164185\n",
      "  time_total_s: 2641.467577457428\n",
      "  timestamp: 1550883227\n",
      "  timesteps_since_restore: 1120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1120000\n",
      "  training_iteration: 112\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2641 s, 112 iter, 1120000 ts, 141 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-54-10\n",
      "  done: false\n",
      "  episode_len_mean: 113.35\n",
      "  episode_reward_max: 231.24404850751165\n",
      "  episode_reward_mean: 143.62527422388283\n",
      "  episode_reward_min: -171.3886516118243\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 7451\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.98\n",
      "    load_time_ms: 2.367\n",
      "    num_steps_sampled: 1130000\n",
      "    num_steps_trained: 1130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2325951827749302e-33\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1731756925582886\n",
      "      kl: 0.005906281061470509\n",
      "      policy_loss: -0.002868556184694171\n",
      "      total_loss: 106.88316345214844\n",
      "      vf_explained_var: 0.9276052713394165\n",
      "      vf_loss: 106.88603973388672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.5407439784686627e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.198476791381836\n",
      "      kl: 0.009156852029263973\n",
      "      policy_loss: -0.003687687683850527\n",
      "      total_loss: 95.419921875\n",
      "      vf_explained_var: 0.9284439086914062\n",
      "      vf_loss: 95.42361450195312\n",
      "    sample_time_ms: 20063.68\n",
      "    update_time_ms: 8.248\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.49793694766028\n",
      "    rl_1: 63.12733727622257\n",
      "  time_since_restore: 2664.807875394821\n",
      "  time_this_iter_s: 23.34029793739319\n",
      "  time_total_s: 2664.807875394821\n",
      "  timestamp: 1550883250\n",
      "  timesteps_since_restore: 1130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1130000\n",
      "  training_iteration: 113\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2664 s, 113 iter, 1130000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-54-34\n",
      "  done: false\n",
      "  episode_len_mean: 109.41\n",
      "  episode_reward_max: 231.30437604292288\n",
      "  episode_reward_mean: 151.62623882733772\n",
      "  episode_reward_min: -165.80087900201727\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 7543\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.595\n",
      "    load_time_ms: 2.363\n",
      "    num_steps_sampled: 1140000\n",
      "    num_steps_trained: 1140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.162975913874651e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1346427202224731\n",
      "      kl: 0.00604605209082365\n",
      "      policy_loss: -0.003328056773170829\n",
      "      total_loss: 231.43174743652344\n",
      "      vf_explained_var: 0.851851224899292\n",
      "      vf_loss: 231.43511962890625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.703719892343314e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1833741664886475\n",
      "      kl: 0.002978520467877388\n",
      "      policy_loss: -0.001700204680673778\n",
      "      total_loss: 191.66603088378906\n",
      "      vf_explained_var: 0.8394612073898315\n",
      "      vf_loss: 191.667724609375\n",
      "    sample_time_ms: 20063.539\n",
      "    update_time_ms: 8.516\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.6995489768829\n",
      "    rl_1: 67.92668985045484\n",
      "  time_since_restore: 2688.3058211803436\n",
      "  time_this_iter_s: 23.49794578552246\n",
      "  time_total_s: 2688.3058211803436\n",
      "  timestamp: 1550883274\n",
      "  timesteps_since_restore: 1140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1140000\n",
      "  training_iteration: 114\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2688 s, 114 iter, 1140000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-54-57\n",
      "  done: false\n",
      "  episode_len_mean: 113.63\n",
      "  episode_reward_max: 223.3397722816799\n",
      "  episode_reward_mean: 155.44709304844105\n",
      "  episode_reward_min: -161.4787808711474\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 7633\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.919\n",
      "    load_time_ms: 2.335\n",
      "    num_steps_sampled: 1150000\n",
      "    num_steps_trained: 1150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.0814879569373254e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0968682765960693\n",
      "      kl: 0.005371363367885351\n",
      "      policy_loss: -0.0009045574115589261\n",
      "      total_loss: 114.30369567871094\n",
      "      vf_explained_var: 0.914166271686554\n",
      "      vf_loss: 114.30462646484375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.851859946171657e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2026368379592896\n",
      "      kl: 0.0018083691829815507\n",
      "      policy_loss: -0.0003265540290158242\n",
      "      total_loss: 94.38227081298828\n",
      "      vf_explained_var: 0.9088348150253296\n",
      "      vf_loss: 94.38261413574219\n",
      "    sample_time_ms: 20096.41\n",
      "    update_time_ms: 8.287\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.08162669967527\n",
      "    rl_1: 67.36546634876575\n",
      "  time_since_restore: 2711.7990906238556\n",
      "  time_this_iter_s: 23.493269443511963\n",
      "  time_total_s: 2711.7990906238556\n",
      "  timestamp: 1550883297\n",
      "  timesteps_since_restore: 1150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1150000\n",
      "  training_iteration: 115\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2711 s, 115 iter, 1150000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-55-20\n",
      "  done: false\n",
      "  episode_len_mean: 103.18\n",
      "  episode_reward_max: 238.83931126226219\n",
      "  episode_reward_mean: 123.61698482372407\n",
      "  episode_reward_min: -180.7112001805342\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 7730\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.54\n",
      "    load_time_ms: 2.355\n",
      "    num_steps_sampled: 1160000\n",
      "    num_steps_trained: 1160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5407439784686627e-34\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.077778935432434\n",
      "      kl: 0.0063208588398993015\n",
      "      policy_loss: -0.002580148633569479\n",
      "      total_loss: 238.5380859375\n",
      "      vf_explained_var: 0.8648462295532227\n",
      "      vf_loss: 238.54066467285156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.9259299730858284e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1771730184555054\n",
      "      kl: 0.00606453837826848\n",
      "      policy_loss: -0.003111870726570487\n",
      "      total_loss: 200.1166229248047\n",
      "      vf_explained_var: 0.8715627789497375\n",
      "      vf_loss: 200.11973571777344\n",
      "    sample_time_ms: 20070.666\n",
      "    update_time_ms: 8.199\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.27034880781551\n",
      "    rl_1: 53.34663601590857\n",
      "  time_since_restore: 2734.8918693065643\n",
      "  time_this_iter_s: 23.09277868270874\n",
      "  time_total_s: 2734.8918693065643\n",
      "  timestamp: 1550883320\n",
      "  timesteps_since_restore: 1160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1160000\n",
      "  training_iteration: 116\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2734 s, 116 iter, 1160000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 111.3\n",
      "  episode_reward_max: 238.83931126226219\n",
      "  episode_reward_mean: 140.49227891350603\n",
      "  episode_reward_min: -178.86768582823746\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 7818\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.505\n",
      "    load_time_ms: 2.316\n",
      "    num_steps_sampled: 1170000\n",
      "    num_steps_trained: 1170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.703719892343314e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0961748361587524\n",
      "      kl: 0.006097760982811451\n",
      "      policy_loss: -0.001861650263890624\n",
      "      total_loss: 184.61904907226562\n",
      "      vf_explained_var: 0.8757319450378418\n",
      "      vf_loss: 184.6208953857422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 9.629649865429142e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1971062421798706\n",
      "      kl: 0.005397409666329622\n",
      "      policy_loss: -0.0028087999671697617\n",
      "      total_loss: 167.91795349121094\n",
      "      vf_explained_var: 0.8704849481582642\n",
      "      vf_loss: 167.92074584960938\n",
      "    sample_time_ms: 20061.134\n",
      "    update_time_ms: 8.086\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.03495518342044\n",
      "    rl_1: 64.45732373008558\n",
      "  time_since_restore: 2758.302335500717\n",
      "  time_this_iter_s: 23.410466194152832\n",
      "  time_total_s: 2758.302335500717\n",
      "  timestamp: 1550883344\n",
      "  timesteps_since_restore: 1170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1170000\n",
      "  training_iteration: 117\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2758 s, 117 iter, 1170000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-56-07\n",
      "  done: false\n",
      "  episode_len_mean: 106.85\n",
      "  episode_reward_max: 222.94707780859596\n",
      "  episode_reward_mean: 125.88444954212062\n",
      "  episode_reward_min: -142.85460584835423\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 7912\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.53\n",
      "    load_time_ms: 2.318\n",
      "    num_steps_sampled: 1180000\n",
      "    num_steps_trained: 1180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.851859946171657e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0436182022094727\n",
      "      kl: 0.010702012106776237\n",
      "      policy_loss: -0.004410350229591131\n",
      "      total_loss: 258.37225341796875\n",
      "      vf_explained_var: 0.8696483969688416\n",
      "      vf_loss: 258.3766784667969\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.814824932714571e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1698174476623535\n",
      "      kl: 0.0052251871675252914\n",
      "      policy_loss: -0.002443103352561593\n",
      "      total_loss: 206.03475952148438\n",
      "      vf_explained_var: 0.8693206906318665\n",
      "      vf_loss: 206.0371856689453\n",
      "    sample_time_ms: 20126.745\n",
      "    update_time_ms: 7.425\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.2763012759084\n",
      "    rl_1: 55.60814826621221\n",
      "  time_since_restore: 2781.6449687480927\n",
      "  time_this_iter_s: 23.34263324737549\n",
      "  time_total_s: 2781.6449687480927\n",
      "  timestamp: 1550883367\n",
      "  timesteps_since_restore: 1180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1180000\n",
      "  training_iteration: 118\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2781 s, 118 iter, 1180000 ts, 126 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-56-31\n",
      "  done: false\n",
      "  episode_len_mean: 108.37\n",
      "  episode_reward_max: 228.2872578744963\n",
      "  episode_reward_mean: 138.51850514682326\n",
      "  episode_reward_min: -163.3610031146608\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 8002\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.961\n",
      "    load_time_ms: 2.327\n",
      "    num_steps_sampled: 1190000\n",
      "    num_steps_trained: 1190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.851859946171657e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0426305532455444\n",
      "      kl: 0.0034825014881789684\n",
      "      policy_loss: -0.0015605229418724775\n",
      "      total_loss: 140.6168670654297\n",
      "      vf_explained_var: 0.9057906866073608\n",
      "      vf_loss: 140.618408203125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.4074124663572855e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1775554418563843\n",
      "      kl: 0.0031867511570453644\n",
      "      policy_loss: -0.0019132263259962201\n",
      "      total_loss: 113.2754135131836\n",
      "      vf_explained_var: 0.9001085162162781\n",
      "      vf_loss: 113.27732849121094\n",
      "    sample_time_ms: 20194.017\n",
      "    update_time_ms: 7.488\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.99304374656565\n",
      "    rl_1: 58.52546140025761\n",
      "  time_since_restore: 2805.0253825187683\n",
      "  time_this_iter_s: 23.38041377067566\n",
      "  time_total_s: 2805.0253825187683\n",
      "  timestamp: 1550883391\n",
      "  timesteps_since_restore: 1190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1190000\n",
      "  training_iteration: 119\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2805 s, 119 iter, 1190000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-56-54\n",
      "  done: false\n",
      "  episode_len_mean: 108.59\n",
      "  episode_reward_max: 225.93123945728286\n",
      "  episode_reward_mean: 142.0891383587442\n",
      "  episode_reward_min: -167.0611426875007\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 8093\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.089\n",
      "    load_time_ms: 2.351\n",
      "    num_steps_sampled: 1200000\n",
      "    num_steps_trained: 1200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.9259299730858284e-35\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0169060230255127\n",
      "      kl: 0.003673017490655184\n",
      "      policy_loss: -0.0011918798554688692\n",
      "      total_loss: 129.70266723632812\n",
      "      vf_explained_var: 0.9193127751350403\n",
      "      vf_loss: 129.70387268066406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.2037062331786428e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.186729073524475\n",
      "      kl: 0.008181288838386536\n",
      "      policy_loss: -0.0037347215693444014\n",
      "      total_loss: 117.39246368408203\n",
      "      vf_explained_var: 0.9057474136352539\n",
      "      vf_loss: 117.39618682861328\n",
      "    sample_time_ms: 20236.628\n",
      "    update_time_ms: 7.474\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.76076210556181\n",
      "    rl_1: 59.328376253182405\n",
      "  time_since_restore: 2828.3556277751923\n",
      "  time_this_iter_s: 23.33024525642395\n",
      "  time_total_s: 2828.3556277751923\n",
      "  timestamp: 1550883414\n",
      "  timesteps_since_restore: 1200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1200000\n",
      "  training_iteration: 120\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2828 s, 120 iter, 1200000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-57-18\n",
      "  done: false\n",
      "  episode_len_mean: 116.0\n",
      "  episode_reward_max: 232.96865222309395\n",
      "  episode_reward_mean: 136.37025705005277\n",
      "  episode_reward_min: -168.4521861402942\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 8182\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3063.926\n",
      "    load_time_ms: 2.331\n",
      "    num_steps_sampled: 1210000\n",
      "    num_steps_trained: 1210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.629649865429142e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.039623498916626\n",
      "      kl: 0.005532647017389536\n",
      "      policy_loss: -0.0023736830335110426\n",
      "      total_loss: 167.75955200195312\n",
      "      vf_explained_var: 0.9066195487976074\n",
      "      vf_loss: 167.76193237304688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 6.018531165893214e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.2035294771194458\n",
      "      kl: 0.0032170366030186415\n",
      "      policy_loss: -0.0019942643120884895\n",
      "      total_loss: 138.58837890625\n",
      "      vf_explained_var: 0.897405743598938\n",
      "      vf_loss: 138.59036254882812\n",
      "    sample_time_ms: 20252.573\n",
      "    update_time_ms: 7.447\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.24652676238371\n",
      "    rl_1: 58.123730287669105\n",
      "  time_since_restore: 2852.0475690364838\n",
      "  time_this_iter_s: 23.691941261291504\n",
      "  time_total_s: 2852.0475690364838\n",
      "  timestamp: 1550883438\n",
      "  timesteps_since_restore: 1210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1210000\n",
      "  training_iteration: 121\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2852 s, 121 iter, 1210000 ts, 136 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-57-41\n",
      "  done: false\n",
      "  episode_len_mean: 104.37\n",
      "  episode_reward_max: 229.4139789619214\n",
      "  episode_reward_mean: 165.0233482180767\n",
      "  episode_reward_min: -163.12645630651426\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 8277\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.982\n",
      "    load_time_ms: 2.301\n",
      "    num_steps_sampled: 1220000\n",
      "    num_steps_trained: 1220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.814824932714571e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9728220701217651\n",
      "      kl: 0.004294137470424175\n",
      "      policy_loss: -0.001448202645406127\n",
      "      total_loss: 127.5150375366211\n",
      "      vf_explained_var: 0.881802499294281\n",
      "      vf_loss: 127.51648712158203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.009265582946607e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1733851432800293\n",
      "      kl: 0.006799606140702963\n",
      "      policy_loss: -0.003606255166232586\n",
      "      total_loss: 115.21287536621094\n",
      "      vf_explained_var: 0.8516708016395569\n",
      "      vf_loss: 115.21648406982422\n",
      "    sample_time_ms: 20292.358\n",
      "    update_time_ms: 7.048\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.1261604298656\n",
      "    rl_1: 73.8971877882111\n",
      "  time_since_restore: 2875.3651914596558\n",
      "  time_this_iter_s: 23.317622423171997\n",
      "  time_total_s: 2875.3651914596558\n",
      "  timestamp: 1550883461\n",
      "  timesteps_since_restore: 1220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1220000\n",
      "  training_iteration: 122\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2875 s, 122 iter, 1220000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-58-04\n",
      "  done: false\n",
      "  episode_len_mean: 112.33\n",
      "  episode_reward_max: 222.8777376261228\n",
      "  episode_reward_mean: 134.66241814849846\n",
      "  episode_reward_min: -179.55034556364274\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 8366\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.384\n",
      "    load_time_ms: 2.309\n",
      "    num_steps_sampled: 1230000\n",
      "    num_steps_trained: 1230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.4074124663572855e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.036875605583191\n",
      "      kl: 0.005116210784763098\n",
      "      policy_loss: -0.0017667422071099281\n",
      "      total_loss: 164.29103088378906\n",
      "      vf_explained_var: 0.9059036374092102\n",
      "      vf_loss: 164.29281616210938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.5046327914733034e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1886249780654907\n",
      "      kl: 0.008550725877285004\n",
      "      policy_loss: -0.0037894309498369694\n",
      "      total_loss: 127.1465835571289\n",
      "      vf_explained_var: 0.9116839170455933\n",
      "      vf_loss: 127.15037536621094\n",
      "    sample_time_ms: 20282.587\n",
      "    update_time_ms: 7.097\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.02639067921048\n",
      "    rl_1: 58.63602746928798\n",
      "  time_since_restore: 2898.5902161598206\n",
      "  time_this_iter_s: 23.225024700164795\n",
      "  time_total_s: 2898.5902161598206\n",
      "  timestamp: 1550883484\n",
      "  timesteps_since_restore: 1230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1230000\n",
      "  training_iteration: 123\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2898 s, 123 iter, 1230000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-58-27\n",
      "  done: false\n",
      "  episode_len_mean: 102.4\n",
      "  episode_reward_max: 226.11219124837777\n",
      "  episode_reward_mean: 147.395539868832\n",
      "  episode_reward_min: -176.90786633352593\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 8462\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.514\n",
      "    load_time_ms: 2.309\n",
      "    num_steps_sampled: 1240000\n",
      "    num_steps_trained: 1240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.2037062331786428e-36\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9621573090553284\n",
      "      kl: 0.005862119607627392\n",
      "      policy_loss: -0.002782030263915658\n",
      "      total_loss: 135.5174102783203\n",
      "      vf_explained_var: 0.9077386856079102\n",
      "      vf_loss: 135.5201873779297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.523163957366517e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1256306171417236\n",
      "      kl: 0.002684819744899869\n",
      "      policy_loss: -0.0014100176049396396\n",
      "      total_loss: 109.24669647216797\n",
      "      vf_explained_var: 0.8961224555969238\n",
      "      vf_loss: 109.24810791015625\n",
      "    sample_time_ms: 20231.377\n",
      "    update_time_ms: 6.949\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.91169707231204\n",
      "    rl_1: 62.483842796519966\n",
      "  time_since_restore: 2921.604596853256\n",
      "  time_this_iter_s: 23.01438069343567\n",
      "  time_total_s: 2921.604596853256\n",
      "  timestamp: 1550883507\n",
      "  timesteps_since_restore: 1240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1240000\n",
      "  training_iteration: 124\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2921 s, 124 iter, 1240000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-58-51\n",
      "  done: false\n",
      "  episode_len_mean: 105.95\n",
      "  episode_reward_max: 236.85043159439456\n",
      "  episode_reward_mean: 156.54841857532077\n",
      "  episode_reward_min: -176.90786633352593\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 8557\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.393\n",
      "    load_time_ms: 2.431\n",
      "    num_steps_sampled: 1250000\n",
      "    num_steps_trained: 1250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 6.018531165893214e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9865960478782654\n",
      "      kl: 0.0055294097401201725\n",
      "      policy_loss: -0.0016883087810128927\n",
      "      total_loss: 200.82640075683594\n",
      "      vf_explained_var: 0.8286296129226685\n",
      "      vf_loss: 200.82809448242188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.7615819786832586e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.123556137084961\n",
      "      kl: 0.006082484032958746\n",
      "      policy_loss: -0.0030789445154368877\n",
      "      total_loss: 157.62896728515625\n",
      "      vf_explained_var: 0.8389979600906372\n",
      "      vf_loss: 157.63204956054688\n",
      "    sample_time_ms: 20254.946\n",
      "    update_time_ms: 6.88\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.72910255039764\n",
      "    rl_1: 70.8193160249231\n",
      "  time_since_restore: 2945.334823846817\n",
      "  time_this_iter_s: 23.73022699356079\n",
      "  time_total_s: 2945.334823846817\n",
      "  timestamp: 1550883531\n",
      "  timesteps_since_restore: 1250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1250000\n",
      "  training_iteration: 125\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2945 s, 125 iter, 1250000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-59-14\n",
      "  done: false\n",
      "  episode_len_mean: 120.57\n",
      "  episode_reward_max: 235.31237810649432\n",
      "  episode_reward_mean: 139.68348413170986\n",
      "  episode_reward_min: -164.46115800597406\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 8636\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.403\n",
      "    load_time_ms: 2.434\n",
      "    num_steps_sampled: 1260000\n",
      "    num_steps_trained: 1260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.009265582946607e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0596001148223877\n",
      "      kl: 0.004362737759947777\n",
      "      policy_loss: -0.0034991931170225143\n",
      "      total_loss: 161.95748901367188\n",
      "      vf_explained_var: 0.875730574131012\n",
      "      vf_loss: 161.9609832763672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.8807909893416293e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1558351516723633\n",
      "      kl: 0.005624806974083185\n",
      "      policy_loss: -0.003028811188414693\n",
      "      total_loss: 139.6385040283203\n",
      "      vf_explained_var: 0.8637937903404236\n",
      "      vf_loss: 139.6415557861328\n",
      "    sample_time_ms: 20252.233\n",
      "    update_time_ms: 6.944\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.90214997015325\n",
      "    rl_1: 60.781334161556636\n",
      "  time_since_restore: 2968.423910856247\n",
      "  time_this_iter_s: 23.08908700942993\n",
      "  time_total_s: 2968.423910856247\n",
      "  timestamp: 1550883554\n",
      "  timesteps_since_restore: 1260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1260000\n",
      "  training_iteration: 126\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2968 s, 126 iter, 1260000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_01-59-38\n",
      "  done: false\n",
      "  episode_len_mean: 116.36\n",
      "  episode_reward_max: 235.31237810649432\n",
      "  episode_reward_mean: 154.23799734813593\n",
      "  episode_reward_min: -174.166296331424\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 8724\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.893\n",
      "    load_time_ms: 2.462\n",
      "    num_steps_sampled: 1270000\n",
      "    num_steps_trained: 1270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.5046327914733034e-37\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.027700424194336\n",
      "      kl: 0.003683920484036207\n",
      "      policy_loss: -0.002082587918266654\n",
      "      total_loss: 141.25230407714844\n",
      "      vf_explained_var: 0.8854182362556458\n",
      "      vf_loss: 141.25436401367188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 9.403954246058914e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.1093425750732422\n",
      "      kl: 0.007491040509194136\n",
      "      policy_loss: -0.004628528840839863\n",
      "      total_loss: 119.44369506835938\n",
      "      vf_explained_var: 0.8782763481140137\n",
      "      vf_loss: 119.44835662841797\n",
      "    sample_time_ms: 20264.551\n",
      "    update_time_ms: 6.614\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.99076501181521\n",
      "    rl_1: 68.24723233632072\n",
      "  time_since_restore: 2992.1382925510406\n",
      "  time_this_iter_s: 23.7143816947937\n",
      "  time_total_s: 2992.1382925510406\n",
      "  timestamp: 1550883578\n",
      "  timesteps_since_restore: 1270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1270000\n",
      "  training_iteration: 127\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 2992 s, 127 iter, 1270000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 105.21\n",
      "  episode_reward_max: 231.98029969116826\n",
      "  episode_reward_mean: 141.6101263426267\n",
      "  episode_reward_min: -184.91826704087646\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 8819\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.138\n",
      "    load_time_ms: 2.508\n",
      "    num_steps_sampled: 1280000\n",
      "    num_steps_trained: 1280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.523163957366517e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9929509162902832\n",
      "      kl: 0.007461074274033308\n",
      "      policy_loss: -0.0035907519049942493\n",
      "      total_loss: 160.8105926513672\n",
      "      vf_explained_var: 0.8940141201019287\n",
      "      vf_loss: 160.8141632080078\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.701977123029457e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0979337692260742\n",
      "      kl: 0.007990348152816296\n",
      "      policy_loss: -0.000905445369426161\n",
      "      total_loss: 124.17625427246094\n",
      "      vf_explained_var: 0.9006092548370361\n",
      "      vf_loss: 124.17718505859375\n",
      "    sample_time_ms: 20292.743\n",
      "    update_time_ms: 6.54\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.12546192170241\n",
      "    rl_1: 61.48466442092431\n",
      "  time_since_restore: 3015.6122097969055\n",
      "  time_this_iter_s: 23.473917245864868\n",
      "  time_total_s: 3015.6122097969055\n",
      "  timestamp: 1550883602\n",
      "  timesteps_since_restore: 1280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1280000\n",
      "  training_iteration: 128\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3015 s, 128 iter, 1280000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-00-25\n",
      "  done: false\n",
      "  episode_len_mean: 105.12\n",
      "  episode_reward_max: 217.49652226494248\n",
      "  episode_reward_mean: 135.793444139558\n",
      "  episode_reward_min: -181.7990988573098\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 8914\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.979\n",
      "    load_time_ms: 2.458\n",
      "    num_steps_sampled: 1290000\n",
      "    num_steps_trained: 1290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.7615819786832586e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9712710380554199\n",
      "      kl: 0.004649959970265627\n",
      "      policy_loss: -0.002111302223056555\n",
      "      total_loss: 156.4165802001953\n",
      "      vf_explained_var: 0.9029844403266907\n",
      "      vf_loss: 156.418701171875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.3509892621639607e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0729718208312988\n",
      "      kl: 0.008398741483688354\n",
      "      policy_loss: -0.0024958092253655195\n",
      "      total_loss: 129.29257202148438\n",
      "      vf_explained_var: 0.908521294593811\n",
      "      vf_loss: 129.29505920410156\n",
      "    sample_time_ms: 20287.827\n",
      "    update_time_ms: 7.075\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.23093831414296\n",
      "    rl_1: 59.562505825415016\n",
      "  time_since_restore: 3038.9557554721832\n",
      "  time_this_iter_s: 23.34354567527771\n",
      "  time_total_s: 3038.9557554721832\n",
      "  timestamp: 1550883625\n",
      "  timesteps_since_restore: 1290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1290000\n",
      "  training_iteration: 129\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3038 s, 129 iter, 1290000 ts, 136 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-00-48\n",
      "  done: false\n",
      "  episode_len_mean: 110.61\n",
      "  episode_reward_max: 228.5704776179612\n",
      "  episode_reward_mean: 157.72890353371656\n",
      "  episode_reward_min: -166.32556663539856\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 9003\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.816\n",
      "    load_time_ms: 2.491\n",
      "    num_steps_sampled: 1300000\n",
      "    num_steps_trained: 1300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8807909893416293e-38\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.996436595916748\n",
      "      kl: 0.0074156830087304115\n",
      "      policy_loss: -0.0038056622724980116\n",
      "      total_loss: 102.11051177978516\n",
      "      vf_explained_var: 0.9237672090530396\n",
      "      vf_loss: 102.11431121826172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.1754946310819804e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0847253799438477\n",
      "      kl: 0.0066306376829743385\n",
      "      policy_loss: -0.003135908395051956\n",
      "      total_loss: 80.11165618896484\n",
      "      vf_explained_var: 0.9204530715942383\n",
      "      vf_loss: 80.11479949951172\n",
      "    sample_time_ms: 20291.771\n",
      "    update_time_ms: 6.909\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.73067383703052\n",
      "    rl_1: 69.99822969668608\n",
      "  time_since_restore: 3062.3208208084106\n",
      "  time_this_iter_s: 23.365065336227417\n",
      "  time_total_s: 3062.3208208084106\n",
      "  timestamp: 1550883648\n",
      "  timesteps_since_restore: 1300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1300000\n",
      "  training_iteration: 130\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3062 s, 130 iter, 1300000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-01-11\n",
      "  done: false\n",
      "  episode_len_mean: 113.07\n",
      "  episode_reward_max: 227.89101315303412\n",
      "  episode_reward_mean: 137.80409652938587\n",
      "  episode_reward_min: -183.93765690189912\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 9095\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.016\n",
      "    load_time_ms: 2.466\n",
      "    num_steps_sampled: 1310000\n",
      "    num_steps_trained: 1310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.403954246058914e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9934088587760925\n",
      "      kl: 0.0048064496368169785\n",
      "      policy_loss: -0.0037547419779002666\n",
      "      total_loss: 149.06105041503906\n",
      "      vf_explained_var: 0.9121591448783875\n",
      "      vf_loss: 149.06478881835938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.87746614891758e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.075726866722107\n",
      "      kl: 0.007198321633040905\n",
      "      policy_loss: -0.0034794302191585302\n",
      "      total_loss: 105.67842102050781\n",
      "      vf_explained_var: 0.9198204278945923\n",
      "      vf_loss: 105.68189239501953\n",
      "    sample_time_ms: 20223.368\n",
      "    update_time_ms: 6.978\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.96233436744171\n",
      "    rl_1: 59.841762161944146\n",
      "  time_since_restore: 3085.331882715225\n",
      "  time_this_iter_s: 23.011061906814575\n",
      "  time_total_s: 3085.331882715225\n",
      "  timestamp: 1550883671\n",
      "  timesteps_since_restore: 1310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1310000\n",
      "  training_iteration: 131\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3085 s, 131 iter, 1310000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-01-35\n",
      "  done: false\n",
      "  episode_len_mean: 108.44\n",
      "  episode_reward_max: 222.1707502757664\n",
      "  episode_reward_mean: 148.86011597551015\n",
      "  episode_reward_min: -183.93765690189912\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 9186\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.092\n",
      "    load_time_ms: 2.432\n",
      "    num_steps_sampled: 1320000\n",
      "    num_steps_trained: 1320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.701977123029457e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9611354470252991\n",
      "      kl: 0.009070276282727718\n",
      "      policy_loss: -0.005414534825831652\n",
      "      total_loss: 148.29400634765625\n",
      "      vf_explained_var: 0.8961898684501648\n",
      "      vf_loss: 148.29940795898438\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.93873307445879e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.059422492980957\n",
      "      kl: 0.008000052534043789\n",
      "      policy_loss: -0.00403941236436367\n",
      "      total_loss: 122.36572265625\n",
      "      vf_explained_var: 0.8962927460670471\n",
      "      vf_loss: 122.36976623535156\n",
      "    sample_time_ms: 20220.007\n",
      "    update_time_ms: 7.029\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.21049930998014\n",
      "    rl_1: 66.64961666553003\n",
      "  time_since_restore: 3108.577824831009\n",
      "  time_this_iter_s: 23.24594211578369\n",
      "  time_total_s: 3108.577824831009\n",
      "  timestamp: 1550883695\n",
      "  timesteps_since_restore: 1320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1320000\n",
      "  training_iteration: 132\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3108 s, 132 iter, 1320000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-01-58\n",
      "  done: false\n",
      "  episode_len_mean: 109.29\n",
      "  episode_reward_max: 229.50298730903205\n",
      "  episode_reward_mean: 158.28382301398162\n",
      "  episode_reward_min: -167.82100385766836\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 9276\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.661\n",
      "    load_time_ms: 2.443\n",
      "    num_steps_sampled: 1330000\n",
      "    num_steps_trained: 1330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.3509892621639607e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.950302243232727\n",
      "      kl: 0.006844400428235531\n",
      "      policy_loss: -0.003115503117442131\n",
      "      total_loss: 111.73941040039062\n",
      "      vf_explained_var: 0.9133198261260986\n",
      "      vf_loss: 111.74252319335938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.4693735437217167e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.063546895980835\n",
      "      kl: 0.003526115557178855\n",
      "      policy_loss: -0.002092895098030567\n",
      "      total_loss: 100.66014099121094\n",
      "      vf_explained_var: 0.8964812159538269\n",
      "      vf_loss: 100.6622314453125\n",
      "    sample_time_ms: 20186.18\n",
      "    update_time_ms: 6.998\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.31518545691071\n",
      "    rl_1: 68.96863755707092\n",
      "  time_since_restore: 3131.4619314670563\n",
      "  time_this_iter_s: 22.884106636047363\n",
      "  time_total_s: 3131.4619314670563\n",
      "  timestamp: 1550883718\n",
      "  timesteps_since_restore: 1330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1330000\n",
      "  training_iteration: 133\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3131 s, 133 iter, 1330000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-02-21\n",
      "  done: false\n",
      "  episode_len_mean: 107.47\n",
      "  episode_reward_max: 222.90408470376317\n",
      "  episode_reward_mean: 139.7192803759581\n",
      "  episode_reward_min: -178.26968891347764\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 9368\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.079\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 1340000\n",
      "    num_steps_trained: 1340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1754946310819804e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9281103610992432\n",
      "      kl: 0.011174105107784271\n",
      "      policy_loss: -0.003849087981507182\n",
      "      total_loss: 95.0487289428711\n",
      "      vf_explained_var: 0.9393685460090637\n",
      "      vf_loss: 95.05256652832031\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.346867718608583e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0246658325195312\n",
      "      kl: 0.009774117730557919\n",
      "      policy_loss: -0.0016201534308493137\n",
      "      total_loss: 71.87247467041016\n",
      "      vf_explained_var: 0.9416853785514832\n",
      "      vf_loss: 71.87409210205078\n",
      "    sample_time_ms: 20226.71\n",
      "    update_time_ms: 6.912\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.17152421819524\n",
      "    rl_1: 59.54775615776285\n",
      "  time_since_restore: 3154.888583421707\n",
      "  time_this_iter_s: 23.42665195465088\n",
      "  time_total_s: 3154.888583421707\n",
      "  timestamp: 1550883741\n",
      "  timesteps_since_restore: 1340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1340000\n",
      "  training_iteration: 134\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3154 s, 134 iter, 1340000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-02-44\n",
      "  done: false\n",
      "  episode_len_mean: 100.25\n",
      "  episode_reward_max: 229.6346492756676\n",
      "  episode_reward_mean: 152.32006027069215\n",
      "  episode_reward_min: -177.90363424014404\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 9468\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.038\n",
      "    load_time_ms: 2.408\n",
      "    num_steps_sampled: 1350000\n",
      "    num_steps_trained: 1350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1754946310819804e-39\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8555963039398193\n",
      "      kl: 0.005210178438574076\n",
      "      policy_loss: -0.001362870098091662\n",
      "      total_loss: 135.0548095703125\n",
      "      vf_explained_var: 0.903104841709137\n",
      "      vf_loss: 135.05618286132812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.6733637943810755e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9798628687858582\n",
      "      kl: 0.004331566393375397\n",
      "      policy_loss: -0.002708949614316225\n",
      "      total_loss: 109.23416137695312\n",
      "      vf_explained_var: 0.8998120427131653\n",
      "      vf_loss: 109.23686981201172\n",
      "    sample_time_ms: 20169.094\n",
      "    update_time_ms: 7.054\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.78338629809275\n",
      "    rl_1: 65.53667397259936\n",
      "  time_since_restore: 3178.060977458954\n",
      "  time_this_iter_s: 23.172394037246704\n",
      "  time_total_s: 3178.060977458954\n",
      "  timestamp: 1550883764\n",
      "  timesteps_since_restore: 1350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1350000\n",
      "  training_iteration: 135\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3178 s, 135 iter, 1350000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-03-07\n",
      "  done: false\n",
      "  episode_len_mean: 103.78\n",
      "  episode_reward_max: 231.6221648960116\n",
      "  episode_reward_mean: 164.0886456127515\n",
      "  episode_reward_min: -176.3459390797969\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 9561\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.376\n",
      "    load_time_ms: 2.395\n",
      "    num_steps_sampled: 1360000\n",
      "    num_steps_trained: 1360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.87746614891758e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8868241906166077\n",
      "      kl: 0.009407317265868187\n",
      "      policy_loss: -0.0036623100750148296\n",
      "      total_loss: 103.16895294189453\n",
      "      vf_explained_var: 0.9267867803573608\n",
      "      vf_loss: 103.17262268066406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.8366818971905377e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.01851224899292\n",
      "      kl: 0.005936117842793465\n",
      "      policy_loss: -0.0026856984477490187\n",
      "      total_loss: 88.85074615478516\n",
      "      vf_explained_var: 0.9203887581825256\n",
      "      vf_loss: 88.85343170166016\n",
      "    sample_time_ms: 20130.78\n",
      "    update_time_ms: 7.069\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.30730846910487\n",
      "    rl_1: 73.78133714364658\n",
      "  time_since_restore: 3201.007103919983\n",
      "  time_this_iter_s: 22.946126461029053\n",
      "  time_total_s: 3201.007103919983\n",
      "  timestamp: 1550883787\n",
      "  timesteps_since_restore: 1360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1360000\n",
      "  training_iteration: 136\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3201 s, 136 iter, 1360000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-03-31\n",
      "  done: false\n",
      "  episode_len_mean: 107.76\n",
      "  episode_reward_max: 225.27490034664532\n",
      "  episode_reward_mean: 145.38308416651478\n",
      "  episode_reward_min: -184.85357185449323\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 9655\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.33\n",
      "    load_time_ms: 2.434\n",
      "    num_steps_sampled: 1370000\n",
      "    num_steps_trained: 1370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.93873307445879e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8805984258651733\n",
      "      kl: 0.004416892770677805\n",
      "      policy_loss: -0.001974312821403146\n",
      "      total_loss: 116.04951477050781\n",
      "      vf_explained_var: 0.931024968624115\n",
      "      vf_loss: 116.05148315429688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 9.184110135184851e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0152344703674316\n",
      "      kl: 0.0075383721850812435\n",
      "      policy_loss: -0.003010005922988057\n",
      "      total_loss: 93.82123565673828\n",
      "      vf_explained_var: 0.9300628900527954\n",
      "      vf_loss: 93.82425689697266\n",
      "    sample_time_ms: 20086.031\n",
      "    update_time_ms: 7.328\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.52802719116542\n",
      "    rl_1: 62.85505697534936\n",
      "  time_since_restore: 3224.0951821804047\n",
      "  time_this_iter_s: 23.088078260421753\n",
      "  time_total_s: 3224.0951821804047\n",
      "  timestamp: 1550883811\n",
      "  timesteps_since_restore: 1370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1370000\n",
      "  training_iteration: 137\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3224 s, 137 iter, 1370000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-03-54\n",
      "  done: false\n",
      "  episode_len_mean: 108.47\n",
      "  episode_reward_max: 231.59132008870245\n",
      "  episode_reward_mean: 137.7855685572509\n",
      "  episode_reward_min: -185.58552510172098\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 9748\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.314\n",
      "    load_time_ms: 2.351\n",
      "    num_steps_sampled: 1380000\n",
      "    num_steps_trained: 1380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4693735437217167e-40\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9011605381965637\n",
      "      kl: 0.006333878729492426\n",
      "      policy_loss: -0.0031826109625399113\n",
      "      total_loss: 162.63250732421875\n",
      "      vf_explained_var: 0.9071923494338989\n",
      "      vf_loss: 162.63568115234375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.5920550675924255e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.0512720346450806\n",
      "      kl: 0.007433412130922079\n",
      "      policy_loss: -0.0034668254666030407\n",
      "      total_loss: 131.57528686523438\n",
      "      vf_explained_var: 0.9036340117454529\n",
      "      vf_loss: 131.5787353515625\n",
      "    sample_time_ms: 20100.741\n",
      "    update_time_ms: 7.391\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.31362506044773\n",
      "    rl_1: 60.47194349680318\n",
      "  time_since_restore: 3247.7257347106934\n",
      "  time_this_iter_s: 23.630552530288696\n",
      "  time_total_s: 3247.7257347106934\n",
      "  timestamp: 1550883834\n",
      "  timesteps_since_restore: 1380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1380000\n",
      "  training_iteration: 138\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3247 s, 138 iter, 1380000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 114.84\n",
      "  episode_reward_max: 230.24779873839614\n",
      "  episode_reward_mean: 158.10161446895364\n",
      "  episode_reward_min: -177.03436744215972\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 9834\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.635\n",
      "    load_time_ms: 2.354\n",
      "    num_steps_sampled: 1390000\n",
      "    num_steps_trained: 1390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.346867718608583e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9212606549263\n",
      "      kl: 0.004793411120772362\n",
      "      policy_loss: -0.0014210202498361468\n",
      "      total_loss: 104.56363677978516\n",
      "      vf_explained_var: 0.9274919033050537\n",
      "      vf_loss: 104.5650405883789\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.2953268845640504e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.052691102027893\n",
      "      kl: 0.007566189859062433\n",
      "      policy_loss: -0.001762873842380941\n",
      "      total_loss: 92.01054382324219\n",
      "      vf_explained_var: 0.9239259362220764\n",
      "      vf_loss: 92.0123062133789\n",
      "    sample_time_ms: 20118.878\n",
      "    update_time_ms: 7.136\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.58580125144904\n",
      "    rl_1: 69.5158132175046\n",
      "  time_since_restore: 3271.249857902527\n",
      "  time_this_iter_s: 23.524123191833496\n",
      "  time_total_s: 3271.249857902527\n",
      "  timestamp: 1550883858\n",
      "  timesteps_since_restore: 1390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1390000\n",
      "  training_iteration: 139\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3271 s, 139 iter, 1390000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-04-41\n",
      "  done: false\n",
      "  episode_len_mean: 121.14\n",
      "  episode_reward_max: 227.43457469010016\n",
      "  episode_reward_mean: 159.00365848592804\n",
      "  episode_reward_min: -181.13053975411174\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 9917\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.544\n",
      "    load_time_ms: 2.39\n",
      "    num_steps_sampled: 1400000\n",
      "    num_steps_trained: 1400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6733637943810755e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9126669764518738\n",
      "      kl: 0.006881444249302149\n",
      "      policy_loss: -0.0011145251337438822\n",
      "      total_loss: 114.22064208984375\n",
      "      vf_explained_var: 0.9380072355270386\n",
      "      vf_loss: 114.2217788696289\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.1476634422820252e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.031881332397461\n",
      "      kl: 0.0059660812839865685\n",
      "      policy_loss: -0.0018168902024626732\n",
      "      total_loss: 92.242431640625\n",
      "      vf_explained_var: 0.9464887976646423\n",
      "      vf_loss: 92.2442626953125\n",
      "    sample_time_ms: 20086.206\n",
      "    update_time_ms: 7.119\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.65115471041307\n",
      "    rl_1: 71.35250377551496\n",
      "  time_since_restore: 3294.2613785266876\n",
      "  time_this_iter_s: 23.011520624160767\n",
      "  time_total_s: 3294.2613785266876\n",
      "  timestamp: 1550883881\n",
      "  timesteps_since_restore: 1400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1400000\n",
      "  training_iteration: 140\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3294 s, 140 iter, 1400000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-05-04\n",
      "  done: false\n",
      "  episode_len_mean: 106.47\n",
      "  episode_reward_max: 226.29228990220452\n",
      "  episode_reward_mean: 147.51048552694294\n",
      "  episode_reward_min: -182.17755379352946\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 10014\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.896\n",
      "    load_time_ms: 2.439\n",
      "    num_steps_sampled: 1410000\n",
      "    num_steps_trained: 1410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8366818971905377e-41\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8313328623771667\n",
      "      kl: 0.006672147195786238\n",
      "      policy_loss: -0.0020274738781154156\n",
      "      total_loss: 140.2939453125\n",
      "      vf_explained_var: 0.912216305732727\n",
      "      vf_loss: 140.2959442138672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 5.74532370373175e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9598669409751892\n",
      "      kl: 0.004669039510190487\n",
      "      policy_loss: -0.0025790345389395952\n",
      "      total_loss: 114.81903839111328\n",
      "      vf_explained_var: 0.908522367477417\n",
      "      vf_loss: 114.82162475585938\n",
      "    sample_time_ms: 20093.9\n",
      "    update_time_ms: 7.245\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.73168733408889\n",
      "    rl_1: 63.77879819285405\n",
      "  time_since_restore: 3317.3575541973114\n",
      "  time_this_iter_s: 23.09617567062378\n",
      "  time_total_s: 3317.3575541973114\n",
      "  timestamp: 1550883904\n",
      "  timesteps_since_restore: 1410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1410000\n",
      "  training_iteration: 141\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3317 s, 141 iter, 1410000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-05-27\n",
      "  done: false\n",
      "  episode_len_mean: 110.01\n",
      "  episode_reward_max: 220.74168312602632\n",
      "  episode_reward_mean: 150.692059532429\n",
      "  episode_reward_min: -182.34290946753669\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 10106\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.082\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 1420000\n",
      "    num_steps_trained: 1420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.184110135184851e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8779529929161072\n",
      "      kl: 0.011808500625193119\n",
      "      policy_loss: -0.0035646550823003054\n",
      "      total_loss: 119.76978302001953\n",
      "      vf_explained_var: 0.9277198910713196\n",
      "      vf_loss: 119.7733383178711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.872661851865875e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9712069630622864\n",
      "      kl: 0.00895033311098814\n",
      "      policy_loss: -0.002896675607189536\n",
      "      total_loss: 100.88274383544922\n",
      "      vf_explained_var: 0.9238048195838928\n",
      "      vf_loss: 100.88562774658203\n",
      "    sample_time_ms: 20096.787\n",
      "    update_time_ms: 7.204\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.55476424768294\n",
      "    rl_1: 66.13729528474605\n",
      "  time_since_restore: 3340.623389005661\n",
      "  time_this_iter_s: 23.26583480834961\n",
      "  time_total_s: 3340.623389005661\n",
      "  timestamp: 1550883927\n",
      "  timesteps_since_restore: 1420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1420000\n",
      "  training_iteration: 142\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3340 s, 142 iter, 1420000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-05-51\n",
      "  done: false\n",
      "  episode_len_mean: 110.36\n",
      "  episode_reward_max: 224.68820279179988\n",
      "  episode_reward_mean: 158.94660789431992\n",
      "  episode_reward_min: -181.44193254901302\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 10195\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.925\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 1430000\n",
      "    num_steps_trained: 1430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.184110135184851e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8621042966842651\n",
      "      kl: 0.010907434858381748\n",
      "      policy_loss: -0.004362801555544138\n",
      "      total_loss: 99.8666763305664\n",
      "      vf_explained_var: 0.9453973770141602\n",
      "      vf_loss: 99.87104034423828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.4293244336113134e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9850447177886963\n",
      "      kl: 0.004499037284404039\n",
      "      policy_loss: -0.0028341615106910467\n",
      "      total_loss: 85.35881042480469\n",
      "      vf_explained_var: 0.9408847093582153\n",
      "      vf_loss: 85.36164855957031\n",
      "    sample_time_ms: 20121.31\n",
      "    update_time_ms: 7.31\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.77602963160903\n",
      "    rl_1: 70.1705782627109\n",
      "  time_since_restore: 3363.742402076721\n",
      "  time_this_iter_s: 23.11901307106018\n",
      "  time_total_s: 3363.742402076721\n",
      "  timestamp: 1550883951\n",
      "  timesteps_since_restore: 1430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1430000\n",
      "  training_iteration: 143\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3363 s, 143 iter, 1430000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-06-14\n",
      "  done: false\n",
      "  episode_len_mean: 111.17\n",
      "  episode_reward_max: 219.43175704020092\n",
      "  episode_reward_mean: 171.61124003145437\n",
      "  episode_reward_min: -160.05111045854994\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 10286\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.913\n",
      "    load_time_ms: 2.449\n",
      "    num_steps_sampled: 1440000\n",
      "    num_steps_trained: 1440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 9.184110135184851e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8062623143196106\n",
      "      kl: 0.00828967522829771\n",
      "      policy_loss: -0.0028726395685225725\n",
      "      total_loss: 74.88848114013672\n",
      "      vf_explained_var: 0.9354684352874756\n",
      "      vf_loss: 74.89136505126953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 7.146622168056567e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9729146957397461\n",
      "      kl: 0.006570821162313223\n",
      "      policy_loss: -0.0035964304115623236\n",
      "      total_loss: 67.5548095703125\n",
      "      vf_explained_var: 0.9294434785842896\n",
      "      vf_loss: 67.55840301513672\n",
      "    sample_time_ms: 20111.438\n",
      "    update_time_ms: 7.745\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.84121596623022\n",
      "    rl_1: 76.77002406522409\n",
      "  time_since_restore: 3387.112315893173\n",
      "  time_this_iter_s: 23.369913816452026\n",
      "  time_total_s: 3387.112315893173\n",
      "  timestamp: 1550883974\n",
      "  timesteps_since_restore: 1440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1440000\n",
      "  training_iteration: 144\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3387 s, 144 iter, 1440000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-06-37\n",
      "  done: false\n",
      "  episode_len_mean: 117.82\n",
      "  episode_reward_max: 219.4969100466332\n",
      "  episode_reward_mean: 161.98792179131934\n",
      "  episode_reward_min: -160.27454807622584\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 10372\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.975\n",
      "    load_time_ms: 2.439\n",
      "    num_steps_sampled: 1450000\n",
      "    num_steps_trained: 1450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.5920550675924255e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8977375626564026\n",
      "      kl: 0.004366109613329172\n",
      "      policy_loss: -0.0011331186397001147\n",
      "      total_loss: 63.47062301635742\n",
      "      vf_explained_var: 0.959126889705658\n",
      "      vf_loss: 63.47175979614258\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 3.6433760072445244e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 1.005351185798645\n",
      "      kl: 0.008739383891224861\n",
      "      policy_loss: -0.004175305366516113\n",
      "      total_loss: 45.60782241821289\n",
      "      vf_explained_var: 0.965101957321167\n",
      "      vf_loss: 45.61199951171875\n",
      "    sample_time_ms: 20085.582\n",
      "    update_time_ms: 7.993\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.0792386070523\n",
      "    rl_1: 72.90868318426705\n",
      "  time_since_restore: 3410.1997039318085\n",
      "  time_this_iter_s: 23.087388038635254\n",
      "  time_total_s: 3410.1997039318085\n",
      "  timestamp: 1550883997\n",
      "  timesteps_since_restore: 1450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1450000\n",
      "  training_iteration: 145\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3410 s, 145 iter, 1450000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-07-00\n",
      "  done: false\n",
      "  episode_len_mean: 103.96\n",
      "  episode_reward_max: 229.95675454629526\n",
      "  episode_reward_mean: 152.90259939200843\n",
      "  episode_reward_min: -179.08872761783306\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 10468\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.938\n",
      "    load_time_ms: 2.53\n",
      "    num_steps_sampled: 1460000\n",
      "    num_steps_trained: 1460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.2953268845640504e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7885317206382751\n",
      "      kl: 0.0037340063136070967\n",
      "      policy_loss: -0.002170037245377898\n",
      "      total_loss: 126.62847900390625\n",
      "      vf_explained_var: 0.9261103868484497\n",
      "      vf_loss: 126.63063049316406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.8216880036222622e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9543725848197937\n",
      "      kl: 0.006048061419278383\n",
      "      policy_loss: -0.001936463639140129\n",
      "      total_loss: 104.85523986816406\n",
      "      vf_explained_var: 0.9202146530151367\n",
      "      vf_loss: 104.85717010498047\n",
      "    sample_time_ms: 20128.166\n",
      "    update_time_ms: 8.142\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.92459625473373\n",
      "    rl_1: 65.97800313727467\n",
      "  time_since_restore: 3433.3548538684845\n",
      "  time_this_iter_s: 23.155149936676025\n",
      "  time_total_s: 3433.3548538684845\n",
      "  timestamp: 1550884020\n",
      "  timesteps_since_restore: 1460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1460000\n",
      "  training_iteration: 146\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3433 s, 146 iter, 1460000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-07-23\n",
      "  done: false\n",
      "  episode_len_mean: 113.41\n",
      "  episode_reward_max: 224.81454639935214\n",
      "  episode_reward_mean: 144.88030553224337\n",
      "  episode_reward_min: -176.74617902829405\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 10555\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.048\n",
      "    load_time_ms: 2.592\n",
      "    num_steps_sampled: 1470000\n",
      "    num_steps_trained: 1470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.1476634422820252e-42\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9220446348190308\n",
      "      kl: 0.007222485728561878\n",
      "      policy_loss: -0.0030003387946635485\n",
      "      total_loss: 183.55247497558594\n",
      "      vf_explained_var: 0.8992088437080383\n",
      "      vf_loss: 183.5554962158203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 8.407790785948902e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9872990250587463\n",
      "      kl: 0.009152626618742943\n",
      "      policy_loss: -0.0037948612589389086\n",
      "      total_loss: 162.78701782226562\n",
      "      vf_explained_var: 0.8722996115684509\n",
      "      vf_loss: 162.7908172607422\n",
      "    sample_time_ms: 20101.716\n",
      "    update_time_ms: 8.041\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.19705055680477\n",
      "    rl_1: 62.68325497543859\n",
      "  time_since_restore: 3456.1970088481903\n",
      "  time_this_iter_s: 22.84215497970581\n",
      "  time_total_s: 3456.1970088481903\n",
      "  timestamp: 1550884043\n",
      "  timesteps_since_restore: 1470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1470000\n",
      "  training_iteration: 147\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3456 s, 147 iter, 1470000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-07-47\n",
      "  done: false\n",
      "  episode_len_mean: 118.66\n",
      "  episode_reward_max: 221.33139259947114\n",
      "  episode_reward_mean: 167.43460050624932\n",
      "  episode_reward_min: -170.65405626221107\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 10636\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.116\n",
      "    load_time_ms: 2.689\n",
      "    num_steps_sampled: 1480000\n",
      "    num_steps_trained: 1480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 5.74532370373175e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8971256613731384\n",
      "      kl: 0.008038492873311043\n",
      "      policy_loss: -0.002849126234650612\n",
      "      total_loss: 37.86272430419922\n",
      "      vf_explained_var: 0.9735938906669617\n",
      "      vf_loss: 37.865562438964844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 4.203895392974451e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9830775856971741\n",
      "      kl: 0.006344378925859928\n",
      "      policy_loss: -0.001135718310251832\n",
      "      total_loss: 29.566068649291992\n",
      "      vf_explained_var: 0.9705671668052673\n",
      "      vf_loss: 29.567197799682617\n",
      "    sample_time_ms: 20096.133\n",
      "    update_time_ms: 7.998\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.64384946820752\n",
      "    rl_1: 71.79075103804182\n",
      "  time_since_restore: 3479.753347635269\n",
      "  time_this_iter_s: 23.556338787078857\n",
      "  time_total_s: 3479.753347635269\n",
      "  timestamp: 1550884067\n",
      "  timesteps_since_restore: 1480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1480000\n",
      "  training_iteration: 148\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3479 s, 148 iter, 1480000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-08-10\n",
      "  done: false\n",
      "  episode_len_mean: 105.39\n",
      "  episode_reward_max: 224.54154496970088\n",
      "  episode_reward_mean: 166.22372607603177\n",
      "  episode_reward_min: -147.83967844355453\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 10731\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.007\n",
      "    load_time_ms: 2.706\n",
      "    num_steps_sampled: 1490000\n",
      "    num_steps_trained: 1490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.872661851865875e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7998914122581482\n",
      "      kl: 0.005511968396604061\n",
      "      policy_loss: -0.0033764441031962633\n",
      "      total_loss: 94.04557037353516\n",
      "      vf_explained_var: 0.9437835812568665\n",
      "      vf_loss: 94.04895782470703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.802596928649634e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9337751865386963\n",
      "      kl: 0.01047765463590622\n",
      "      policy_loss: -0.004417791962623596\n",
      "      total_loss: 88.73265075683594\n",
      "      vf_explained_var: 0.9310067296028137\n",
      "      vf_loss: 88.73707580566406\n",
      "    sample_time_ms: 20012.639\n",
      "    update_time_ms: 7.658\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.05576003665543\n",
      "    rl_1: 72.16796603937637\n",
      "  time_since_restore: 3502.628450870514\n",
      "  time_this_iter_s: 22.87510323524475\n",
      "  time_total_s: 3502.628450870514\n",
      "  timestamp: 1550884090\n",
      "  timesteps_since_restore: 1490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1490000\n",
      "  training_iteration: 149\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3502 s, 149 iter, 1490000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-08-33\n",
      "  done: false\n",
      "  episode_len_mean: 111.52\n",
      "  episode_reward_max: 227.1992927148417\n",
      "  episode_reward_mean: 175.44398714310336\n",
      "  episode_reward_min: 7.791556151704921\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 10819\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.808\n",
      "    load_time_ms: 2.627\n",
      "    num_steps_sampled: 1500000\n",
      "    num_steps_trained: 1500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.4293244336113134e-43\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8554191589355469\n",
      "      kl: 0.0041921259835362434\n",
      "      policy_loss: -5.218386650085449e-05\n",
      "      total_loss: 34.78353500366211\n",
      "      vf_explained_var: 0.9754472374916077\n",
      "      vf_loss: 34.7835807800293\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 2.802596928649634e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9222174286842346\n",
      "      kl: 0.007546545006334782\n",
      "      policy_loss: -0.0022903685458004475\n",
      "      total_loss: 25.782899856567383\n",
      "      vf_explained_var: 0.9708340167999268\n",
      "      vf_loss: 25.785186767578125\n",
      "    sample_time_ms: 20047.087\n",
      "    update_time_ms: 7.738\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.87653280131327\n",
      "    rl_1: 76.56745434179014\n",
      "  time_since_restore: 3526.009064912796\n",
      "  time_this_iter_s: 23.380614042282104\n",
      "  time_total_s: 3526.009064912796\n",
      "  timestamp: 1550884113\n",
      "  timesteps_since_restore: 1500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1500000\n",
      "  training_iteration: 150\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3526 s, 150 iter, 1500000 ts, 175 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-08-56\n",
      "  done: false\n",
      "  episode_len_mean: 115.74\n",
      "  episode_reward_max: 221.49314300264464\n",
      "  episode_reward_mean: 167.2755238897401\n",
      "  episode_reward_min: -164.68801243265622\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 10910\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.503\n",
      "    load_time_ms: 2.617\n",
      "    num_steps_sampled: 1510000\n",
      "    num_steps_trained: 1510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 7.146622168056567e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8023977875709534\n",
      "      kl: 0.00759938033297658\n",
      "      policy_loss: -0.0032459034118801355\n",
      "      total_loss: 45.2974967956543\n",
      "      vf_explained_var: 0.9632736444473267\n",
      "      vf_loss: 45.30073928833008\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 1.401298464324817e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8979256749153137\n",
      "      kl: 0.007038374897092581\n",
      "      policy_loss: -0.0032656837720423937\n",
      "      total_loss: 37.59815979003906\n",
      "      vf_explained_var: 0.9576306343078613\n",
      "      vf_loss: 37.6014289855957\n",
      "    sample_time_ms: 20006.494\n",
      "    update_time_ms: 7.654\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.10136385631304\n",
      "    rl_1: 72.17416003342709\n",
      "  time_since_restore: 3548.6744837760925\n",
      "  time_this_iter_s: 22.66541886329651\n",
      "  time_total_s: 3548.6744837760925\n",
      "  timestamp: 1550884136\n",
      "  timesteps_since_restore: 1510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1510000\n",
      "  training_iteration: 151\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3548 s, 151 iter, 1510000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-09-19\n",
      "  done: false\n",
      "  episode_len_mean: 126.29\n",
      "  episode_reward_max: 221.49314300264464\n",
      "  episode_reward_mean: 159.188976880185\n",
      "  episode_reward_min: -145.95721451978454\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 10988\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3098.227\n",
      "    load_time_ms: 2.687\n",
      "    num_steps_sampled: 1520000\n",
      "    num_steps_trained: 1520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 3.6433760072445244e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8958001732826233\n",
      "      kl: 0.004457453731447458\n",
      "      policy_loss: -0.0012226998805999756\n",
      "      total_loss: 60.0368766784668\n",
      "      vf_explained_var: 0.958154559135437\n",
      "      vf_loss: 60.0380973815918\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9620699882507324\n",
      "      kl: 0.0050849756225943565\n",
      "      policy_loss: -0.0026570926420390606\n",
      "      total_loss: 50.0958251953125\n",
      "      vf_explained_var: 0.951575756072998\n",
      "      vf_loss: 50.098480224609375\n",
      "    sample_time_ms: 19983.949\n",
      "    update_time_ms: 7.745\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.97294378167639\n",
      "    rl_1: 68.21603309850865\n",
      "  time_since_restore: 3571.7261912822723\n",
      "  time_this_iter_s: 23.05170750617981\n",
      "  time_total_s: 3571.7261912822723\n",
      "  timestamp: 1550884159\n",
      "  timesteps_since_restore: 1520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1520000\n",
      "  training_iteration: 152\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3571 s, 152 iter, 1520000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-09-42\n",
      "  done: false\n",
      "  episode_len_mean: 112.18\n",
      "  episode_reward_max: 221.62781694763422\n",
      "  episode_reward_mean: 138.02088017574818\n",
      "  episode_reward_min: -179.38075689912972\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 11076\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3103.832\n",
      "    load_time_ms: 2.739\n",
      "    num_steps_sampled: 1530000\n",
      "    num_steps_trained: 1530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.8216880036222622e-44\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8393864631652832\n",
      "      kl: 0.005271221976727247\n",
      "      policy_loss: -0.001522456994280219\n",
      "      total_loss: 152.4853973388672\n",
      "      vf_explained_var: 0.9138508439064026\n",
      "      vf_loss: 152.48692321777344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9377085566520691\n",
      "      kl: 0.004420361015945673\n",
      "      policy_loss: -0.0029030798468738794\n",
      "      total_loss: 131.5794219970703\n",
      "      vf_explained_var: 0.9132739305496216\n",
      "      vf_loss: 131.58233642578125\n",
      "    sample_time_ms: 19956.639\n",
      "    update_time_ms: 7.976\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.11484708320725\n",
      "    rl_1: 59.90603309254094\n",
      "  time_since_restore: 3594.630584001541\n",
      "  time_this_iter_s: 22.9043927192688\n",
      "  time_total_s: 3594.630584001541\n",
      "  timestamp: 1550884182\n",
      "  timesteps_since_restore: 1530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1530000\n",
      "  training_iteration: 153\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3594 s, 153 iter, 1530000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-10-05\n",
      "  done: false\n",
      "  episode_len_mean: 124.93\n",
      "  episode_reward_max: 223.19953640415997\n",
      "  episode_reward_mean: 155.97862700003142\n",
      "  episode_reward_min: -183.23030372769406\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 11155\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.119\n",
      "    load_time_ms: 2.747\n",
      "    num_steps_sampled: 1540000\n",
      "    num_steps_trained: 1540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 8.407790785948902e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9037482142448425\n",
      "      kl: 0.00894575472921133\n",
      "      policy_loss: -0.003689376637339592\n",
      "      total_loss: 40.508148193359375\n",
      "      vf_explained_var: 0.974773108959198\n",
      "      vf_loss: 40.51183319091797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9648360013961792\n",
      "      kl: 0.009599527344107628\n",
      "      policy_loss: -0.007933031767606735\n",
      "      total_loss: 32.513675689697266\n",
      "      vf_explained_var: 0.9708698987960815\n",
      "      vf_loss: 32.5216064453125\n",
      "    sample_time_ms: 19954.611\n",
      "    update_time_ms: 7.559\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.78190035827993\n",
      "    rl_1: 68.19672664175148\n",
      "  time_since_restore: 3617.907395839691\n",
      "  time_this_iter_s: 23.276811838150024\n",
      "  time_total_s: 3617.907395839691\n",
      "  timestamp: 1550884205\n",
      "  timesteps_since_restore: 1540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1540000\n",
      "  training_iteration: 154\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3617 s, 154 iter, 1540000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-10-29\n",
      "  done: false\n",
      "  episode_len_mean: 107.58\n",
      "  episode_reward_max: 223.19953640415997\n",
      "  episode_reward_mean: 141.90114377105957\n",
      "  episode_reward_min: -183.23030372769406\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 11243\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.523\n",
      "    load_time_ms: 2.76\n",
      "    num_steps_sampled: 1550000\n",
      "    num_steps_trained: 1550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 4.203895392974451e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8091483116149902\n",
      "      kl: 0.004182177130132914\n",
      "      policy_loss: -0.0013916752068325877\n",
      "      total_loss: 94.17634582519531\n",
      "      vf_explained_var: 0.9411987662315369\n",
      "      vf_loss: 94.17772674560547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.894829273223877\n",
      "      kl: 0.0062816510908305645\n",
      "      policy_loss: -0.0024007379543036222\n",
      "      total_loss: 78.56182098388672\n",
      "      vf_explained_var: 0.9377015829086304\n",
      "      vf_loss: 78.56422424316406\n",
      "    sample_time_ms: 20006.659\n",
      "    update_time_ms: 7.143\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.72164998102521\n",
      "    rl_1: 62.179493790034364\n",
      "  time_since_restore: 3641.313581943512\n",
      "  time_this_iter_s: 23.4061861038208\n",
      "  time_total_s: 3641.313581943512\n",
      "  timestamp: 1550884229\n",
      "  timesteps_since_restore: 1550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1550000\n",
      "  training_iteration: 155\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3641 s, 155 iter, 1550000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-10-52\n",
      "  done: false\n",
      "  episode_len_mean: 113.11\n",
      "  episode_reward_max: 227.69249506027813\n",
      "  episode_reward_mean: 169.09153782298955\n",
      "  episode_reward_min: -149.13157764448636\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 11333\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.459\n",
      "    load_time_ms: 2.737\n",
      "    num_steps_sampled: 1560000\n",
      "    num_steps_trained: 1560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 2.802596928649634e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7763301730155945\n",
      "      kl: 0.0032236953265964985\n",
      "      policy_loss: -0.000329203816363588\n",
      "      total_loss: 76.97290802001953\n",
      "      vf_explained_var: 0.9473038911819458\n",
      "      vf_loss: 76.9732437133789\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8792935013771057\n",
      "      kl: 0.00893817376345396\n",
      "      policy_loss: -0.004340318497270346\n",
      "      total_loss: 68.6368408203125\n",
      "      vf_explained_var: 0.9364375472068787\n",
      "      vf_loss: 68.64116668701172\n",
      "    sample_time_ms: 20013.27\n",
      "    update_time_ms: 7.128\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.6348206848031\n",
      "    rl_1: 75.45671713818648\n",
      "  time_since_restore: 3664.4947984218597\n",
      "  time_this_iter_s: 23.18121647834778\n",
      "  time_total_s: 3664.4947984218597\n",
      "  timestamp: 1550884252\n",
      "  timesteps_since_restore: 1560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1560000\n",
      "  training_iteration: 156\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3664 s, 156 iter, 1560000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-11-15\n",
      "  done: false\n",
      "  episode_len_mean: 117.21\n",
      "  episode_reward_max: 229.05308430439572\n",
      "  episode_reward_mean: 157.11567096229285\n",
      "  episode_reward_min: -167.85884721566953\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 11417\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.011\n",
      "    load_time_ms: 2.627\n",
      "    num_steps_sampled: 1570000\n",
      "    num_steps_trained: 1570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 1.401298464324817e-45\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8831030130386353\n",
      "      kl: 0.004091984126716852\n",
      "      policy_loss: -0.003366554854437709\n",
      "      total_loss: 93.95171356201172\n",
      "      vf_explained_var: 0.9429644346237183\n",
      "      vf_loss: 93.95506286621094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9030500650405884\n",
      "      kl: 0.009176983498036861\n",
      "      policy_loss: -0.002773463726043701\n",
      "      total_loss: 79.36162567138672\n",
      "      vf_explained_var: 0.9362382292747498\n",
      "      vf_loss: 79.3644027709961\n",
      "    sample_time_ms: 19996.701\n",
      "    update_time_ms: 7.201\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.5546439874423\n",
      "    rl_1: 68.56102697485055\n",
      "  time_since_restore: 3687.1578481197357\n",
      "  time_this_iter_s: 22.663049697875977\n",
      "  time_total_s: 3687.1578481197357\n",
      "  timestamp: 1550884275\n",
      "  timesteps_since_restore: 1570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1570000\n",
      "  training_iteration: 157\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3687 s, 157 iter, 1570000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-11-38\n",
      "  done: false\n",
      "  episode_len_mean: 104.64\n",
      "  episode_reward_max: 222.7577567837646\n",
      "  episode_reward_mean: 156.24304063952476\n",
      "  episode_reward_min: -170.48105246056488\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 11513\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.031\n",
      "    load_time_ms: 2.515\n",
      "    num_steps_sampled: 1580000\n",
      "    num_steps_trained: 1580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7730923891067505\n",
      "      kl: 0.004221751354634762\n",
      "      policy_loss: -0.0008511057822033763\n",
      "      total_loss: 98.18328094482422\n",
      "      vf_explained_var: 0.9284307956695557\n",
      "      vf_loss: 98.18415069580078\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8466424942016602\n",
      "      kl: 0.003968882840126753\n",
      "      policy_loss: -0.0012933965772390366\n",
      "      total_loss: 77.91292572021484\n",
      "      vf_explained_var: 0.9298068284988403\n",
      "      vf_loss: 77.91421508789062\n",
      "    sample_time_ms: 19955.799\n",
      "    update_time_ms: 7.163\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.49735551521871\n",
      "    rl_1: 68.74568512430602\n",
      "  time_since_restore: 3710.4825258255005\n",
      "  time_this_iter_s: 23.32467770576477\n",
      "  time_total_s: 3710.4825258255005\n",
      "  timestamp: 1550884298\n",
      "  timesteps_since_restore: 1580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1580000\n",
      "  training_iteration: 158\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3710 s, 158 iter, 1580000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-12-01\n",
      "  done: false\n",
      "  episode_len_mean: 102.84\n",
      "  episode_reward_max: 231.7334137812006\n",
      "  episode_reward_mean: 166.59139548369137\n",
      "  episode_reward_min: -166.8862928536373\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 11610\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.105\n",
      "    load_time_ms: 2.489\n",
      "    num_steps_sampled: 1590000\n",
      "    num_steps_trained: 1590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7630739212036133\n",
      "      kl: 0.005612329579889774\n",
      "      policy_loss: -0.001267341198399663\n",
      "      total_loss: 71.33824157714844\n",
      "      vf_explained_var: 0.9350468516349792\n",
      "      vf_loss: 71.33950805664062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8142277002334595\n",
      "      kl: 0.0019928126130253077\n",
      "      policy_loss: -0.0011065489379689097\n",
      "      total_loss: 61.43172836303711\n",
      "      vf_explained_var: 0.9333834648132324\n",
      "      vf_loss: 61.43284225463867\n",
      "    sample_time_ms: 20008.441\n",
      "    update_time_ms: 7.166\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.55981885168268\n",
      "    rl_1: 74.03157663200867\n",
      "  time_since_restore: 3733.7053170204163\n",
      "  time_this_iter_s: 23.22279119491577\n",
      "  time_total_s: 3733.7053170204163\n",
      "  timestamp: 1550884321\n",
      "  timesteps_since_restore: 1590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1590000\n",
      "  training_iteration: 159\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3733 s, 159 iter, 1590000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-12-25\n",
      "  done: false\n",
      "  episode_len_mean: 104.78\n",
      "  episode_reward_max: 227.08115143455672\n",
      "  episode_reward_mean: 153.2063760083013\n",
      "  episode_reward_min: -176.28161168202112\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 11704\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.66\n",
      "    load_time_ms: 2.487\n",
      "    num_steps_sampled: 1600000\n",
      "    num_steps_trained: 1600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7821781635284424\n",
      "      kl: 0.005941102746874094\n",
      "      policy_loss: -0.0008529264014214277\n",
      "      total_loss: 111.98849487304688\n",
      "      vf_explained_var: 0.9182072281837463\n",
      "      vf_loss: 111.98933410644531\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8657121658325195\n",
      "      kl: 0.010101347230374813\n",
      "      policy_loss: -0.003156856866553426\n",
      "      total_loss: 97.91426849365234\n",
      "      vf_explained_var: 0.9131516814231873\n",
      "      vf_loss: 97.91741943359375\n",
      "    sample_time_ms: 20011.179\n",
      "    update_time_ms: 7.101\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.84723194383703\n",
      "    rl_1: 66.3591440644643\n",
      "  time_since_restore: 3757.1003637313843\n",
      "  time_this_iter_s: 23.395046710968018\n",
      "  time_total_s: 3757.1003637313843\n",
      "  timestamp: 1550884345\n",
      "  timesteps_since_restore: 1600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1600000\n",
      "  training_iteration: 160\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3757 s, 160 iter, 1600000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-12-48\n",
      "  done: false\n",
      "  episode_len_mean: 105.72\n",
      "  episode_reward_max: 227.46452692617936\n",
      "  episode_reward_mean: 159.56525260994934\n",
      "  episode_reward_min: -175.38905186343987\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 11798\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.434\n",
      "    load_time_ms: 2.44\n",
      "    num_steps_sampled: 1610000\n",
      "    num_steps_trained: 1610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7836071252822876\n",
      "      kl: 0.004630952142179012\n",
      "      policy_loss: -0.0009025181643664837\n",
      "      total_loss: 71.78313446044922\n",
      "      vf_explained_var: 0.9460253715515137\n",
      "      vf_loss: 71.78402709960938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8584524989128113\n",
      "      kl: 0.007599018979817629\n",
      "      policy_loss: -0.0032478158827871084\n",
      "      total_loss: 59.18586730957031\n",
      "      vf_explained_var: 0.9412503242492676\n",
      "      vf_loss: 59.18911361694336\n",
      "    sample_time_ms: 20093.062\n",
      "    update_time_ms: 7.072\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.33843299862161\n",
      "    rl_1: 68.22681961132773\n",
      "  time_since_restore: 3780.5789318084717\n",
      "  time_this_iter_s: 23.478568077087402\n",
      "  time_total_s: 3780.5789318084717\n",
      "  timestamp: 1550884368\n",
      "  timesteps_since_restore: 1610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1610000\n",
      "  training_iteration: 161\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3780 s, 161 iter, 1610000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-13-12\n",
      "  done: false\n",
      "  episode_len_mean: 111.84\n",
      "  episode_reward_max: 218.59569161402678\n",
      "  episode_reward_mean: 170.07522914623524\n",
      "  episode_reward_min: -142.27403679494728\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 11888\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.078\n",
      "    load_time_ms: 2.443\n",
      "    num_steps_sampled: 1620000\n",
      "    num_steps_trained: 1620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8222382664680481\n",
      "      kl: 0.0034543322399258614\n",
      "      policy_loss: -0.0013702519936487079\n",
      "      total_loss: 40.564449310302734\n",
      "      vf_explained_var: 0.964986264705658\n",
      "      vf_loss: 40.565826416015625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8867143392562866\n",
      "      kl: 0.005813882686197758\n",
      "      policy_loss: -0.0014130889903753996\n",
      "      total_loss: 35.61811065673828\n",
      "      vf_explained_var: 0.9585913419723511\n",
      "      vf_loss: 35.619529724121094\n",
      "    sample_time_ms: 20147.778\n",
      "    update_time_ms: 7.036\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.69668515958875\n",
      "    rl_1: 73.37854398664646\n",
      "  time_since_restore: 3804.1701147556305\n",
      "  time_this_iter_s: 23.591182947158813\n",
      "  time_total_s: 3804.1701147556305\n",
      "  timestamp: 1550884392\n",
      "  timesteps_since_restore: 1620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1620000\n",
      "  training_iteration: 162\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3804 s, 162 iter, 1620000 ts, 170 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-13-35\n",
      "  done: false\n",
      "  episode_len_mean: 104.58\n",
      "  episode_reward_max: 228.7783010353121\n",
      "  episode_reward_mean: 147.79266008607974\n",
      "  episode_reward_min: -163.2992508552323\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 11983\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.033\n",
      "    load_time_ms: 2.324\n",
      "    num_steps_sampled: 1630000\n",
      "    num_steps_trained: 1630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7720162272453308\n",
      "      kl: 0.0075808335095644\n",
      "      policy_loss: -0.0028042341582477093\n",
      "      total_loss: 140.99594116210938\n",
      "      vf_explained_var: 0.8977871537208557\n",
      "      vf_loss: 140.99874877929688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8454716801643372\n",
      "      kl: 0.006424042861908674\n",
      "      policy_loss: -0.0021485798060894012\n",
      "      total_loss: 115.45191955566406\n",
      "      vf_explained_var: 0.9036053419113159\n",
      "      vf_loss: 115.45402526855469\n",
      "    sample_time_ms: 20181.242\n",
      "    update_time_ms: 6.761\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.0341781347353\n",
      "    rl_1: 64.75848195134444\n",
      "  time_since_restore: 3827.3536310195923\n",
      "  time_this_iter_s: 23.183516263961792\n",
      "  time_total_s: 3827.3536310195923\n",
      "  timestamp: 1550884415\n",
      "  timesteps_since_restore: 1630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1630000\n",
      "  training_iteration: 163\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3827 s, 163 iter, 1630000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-13-58\n",
      "  done: false\n",
      "  episode_len_mean: 116.52\n",
      "  episode_reward_max: 227.23339684455954\n",
      "  episode_reward_mean: 153.49987626031995\n",
      "  episode_reward_min: -163.2992508552323\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 12066\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.522\n",
      "    load_time_ms: 2.3\n",
      "    num_steps_sampled: 1640000\n",
      "    num_steps_trained: 1640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8640714883804321\n",
      "      kl: 0.004959548823535442\n",
      "      policy_loss: -0.002187286037951708\n",
      "      total_loss: 75.48715209960938\n",
      "      vf_explained_var: 0.9410653710365295\n",
      "      vf_loss: 75.48934173583984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8752034306526184\n",
      "      kl: 0.007584515493363142\n",
      "      policy_loss: -0.005004094913601875\n",
      "      total_loss: 63.47983169555664\n",
      "      vf_explained_var: 0.9392254948616028\n",
      "      vf_loss: 63.48483657836914\n",
      "    sample_time_ms: 20151.899\n",
      "    update_time_ms: 7.035\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.25113355593965\n",
      "    rl_1: 67.24874270438033\n",
      "  time_since_restore: 3850.3550188541412\n",
      "  time_this_iter_s: 23.00138783454895\n",
      "  time_total_s: 3850.3550188541412\n",
      "  timestamp: 1550884438\n",
      "  timesteps_since_restore: 1640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1640000\n",
      "  training_iteration: 164\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3850 s, 164 iter, 1640000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-14-22\n",
      "  done: false\n",
      "  episode_len_mean: 118.66\n",
      "  episode_reward_max: 224.30346473821547\n",
      "  episode_reward_mean: 154.09536992288628\n",
      "  episode_reward_min: -157.57326757416533\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 12149\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.584\n",
      "    load_time_ms: 2.331\n",
      "    num_steps_sampled: 1650000\n",
      "    num_steps_trained: 1650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8808738589286804\n",
      "      kl: 0.005687179043889046\n",
      "      policy_loss: -0.0020379829220473766\n",
      "      total_loss: 80.85091400146484\n",
      "      vf_explained_var: 0.948368489742279\n",
      "      vf_loss: 80.85294342041016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.9094975590705872\n",
      "      kl: 0.005139645654708147\n",
      "      policy_loss: -0.0018481732113286853\n",
      "      total_loss: 64.45545196533203\n",
      "      vf_explained_var: 0.9528008699417114\n",
      "      vf_loss: 64.45729064941406\n",
      "    sample_time_ms: 20181.161\n",
      "    update_time_ms: 7.016\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.38115678868606\n",
      "    rl_1: 68.7142131342002\n",
      "  time_since_restore: 3874.0653331279755\n",
      "  time_this_iter_s: 23.71031427383423\n",
      "  time_total_s: 3874.0653331279755\n",
      "  timestamp: 1550884462\n",
      "  timesteps_since_restore: 1650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1650000\n",
      "  training_iteration: 165\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3874 s, 165 iter, 1650000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-14-45\n",
      "  done: false\n",
      "  episode_len_mean: 120.18\n",
      "  episode_reward_max: 226.40594918416465\n",
      "  episode_reward_mean: 141.50860309645984\n",
      "  episode_reward_min: -169.84688599037855\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 12235\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.275\n",
      "    load_time_ms: 2.252\n",
      "    num_steps_sampled: 1660000\n",
      "    num_steps_trained: 1660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8129143118858337\n",
      "      kl: 0.004910783842206001\n",
      "      policy_loss: -0.0029199884738773108\n",
      "      total_loss: 109.31490325927734\n",
      "      vf_explained_var: 0.9356206059455872\n",
      "      vf_loss: 109.31783294677734\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8505485653877258\n",
      "      kl: 0.007466057315468788\n",
      "      policy_loss: -0.004508741199970245\n",
      "      total_loss: 94.82845306396484\n",
      "      vf_explained_var: 0.9326677322387695\n",
      "      vf_loss: 94.83295440673828\n",
      "    sample_time_ms: 20176.425\n",
      "    update_time_ms: 6.961\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.75212821552074\n",
      "    rl_1: 60.75647488093909\n",
      "  time_since_restore: 3897.1948466300964\n",
      "  time_this_iter_s: 23.12951350212097\n",
      "  time_total_s: 3897.1948466300964\n",
      "  timestamp: 1550884485\n",
      "  timesteps_since_restore: 1660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1660000\n",
      "  training_iteration: 166\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3897 s, 166 iter, 1660000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-15-08\n",
      "  done: false\n",
      "  episode_len_mean: 107.57\n",
      "  episode_reward_max: 226.89339243416345\n",
      "  episode_reward_mean: 149.97038440373797\n",
      "  episode_reward_min: -160.17258414284157\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 12328\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.452\n",
      "    load_time_ms: 2.232\n",
      "    num_steps_sampled: 1670000\n",
      "    num_steps_trained: 1670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7585813999176025\n",
      "      kl: 0.007793655153363943\n",
      "      policy_loss: -0.0030404229182749987\n",
      "      total_loss: 113.51715087890625\n",
      "      vf_explained_var: 0.9336971640586853\n",
      "      vf_loss: 113.52019500732422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8221516013145447\n",
      "      kl: 0.008216378279030323\n",
      "      policy_loss: -0.0056435842998325825\n",
      "      total_loss: 100.91046905517578\n",
      "      vf_explained_var: 0.9235159158706665\n",
      "      vf_loss: 100.91610717773438\n",
      "    sample_time_ms: 20181.45\n",
      "    update_time_ms: 6.693\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.65502337735903\n",
      "    rl_1: 64.31536102637892\n",
      "  time_since_restore: 3920.0966618061066\n",
      "  time_this_iter_s: 22.901815176010132\n",
      "  time_total_s: 3920.0966618061066\n",
      "  timestamp: 1550884508\n",
      "  timesteps_since_restore: 1670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1670000\n",
      "  training_iteration: 167\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3920 s, 167 iter, 1670000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 118.15\n",
      "  episode_reward_max: 218.92656173460105\n",
      "  episode_reward_mean: 164.2825891859673\n",
      "  episode_reward_min: -172.22024239659072\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 12414\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.336\n",
      "    load_time_ms: 2.247\n",
      "    num_steps_sampled: 1680000\n",
      "    num_steps_trained: 1680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8319592475891113\n",
      "      kl: 0.005364601965993643\n",
      "      policy_loss: -0.0018470115028321743\n",
      "      total_loss: 38.143497467041016\n",
      "      vf_explained_var: 0.9690828323364258\n",
      "      vf_loss: 38.14534378051758\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8405494689941406\n",
      "      kl: 0.010084065608680248\n",
      "      policy_loss: -0.00293519115075469\n",
      "      total_loss: 32.29210662841797\n",
      "      vf_explained_var: 0.9675731062889099\n",
      "      vf_loss: 32.295040130615234\n",
      "    sample_time_ms: 20179.336\n",
      "    update_time_ms: 7.021\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.85880956378405\n",
      "    rl_1: 72.42377962218323\n",
      "  time_since_restore: 3943.243816137314\n",
      "  time_this_iter_s: 23.147154331207275\n",
      "  time_total_s: 3943.243816137314\n",
      "  timestamp: 1550884531\n",
      "  timesteps_since_restore: 1680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1680000\n",
      "  training_iteration: 168\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3943 s, 168 iter, 1680000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-15-55\n",
      "  done: false\n",
      "  episode_len_mean: 111.7\n",
      "  episode_reward_max: 226.70433811853832\n",
      "  episode_reward_mean: 161.4506199938772\n",
      "  episode_reward_min: -180.63304291053703\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 12500\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.547\n",
      "    load_time_ms: 2.301\n",
      "    num_steps_sampled: 1690000\n",
      "    num_steps_trained: 1690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7773693799972534\n",
      "      kl: 0.011691977269947529\n",
      "      policy_loss: -0.0030844153370708227\n",
      "      total_loss: 80.00712585449219\n",
      "      vf_explained_var: 0.9410116672515869\n",
      "      vf_loss: 80.01020050048828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8043488264083862\n",
      "      kl: 0.0032471250742673874\n",
      "      policy_loss: -0.0013523275265470147\n",
      "      total_loss: 72.2789306640625\n",
      "      vf_explained_var: 0.9274553060531616\n",
      "      vf_loss: 72.28028106689453\n",
      "    sample_time_ms: 20198.594\n",
      "    update_time_ms: 6.974\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.07069937668724\n",
      "    rl_1: 70.37992061718997\n",
      "  time_since_restore: 3966.654853820801\n",
      "  time_this_iter_s: 23.41103768348694\n",
      "  time_total_s: 3966.654853820801\n",
      "  timestamp: 1550884555\n",
      "  timesteps_since_restore: 1690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1690000\n",
      "  training_iteration: 169\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3966 s, 169 iter, 1690000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-16-18\n",
      "  done: false\n",
      "  episode_len_mean: 113.82\n",
      "  episode_reward_max: 227.64759219287436\n",
      "  episode_reward_mean: 162.35436439090128\n",
      "  episode_reward_min: -153.12728336640322\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 12590\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.069\n",
      "    load_time_ms: 2.338\n",
      "    num_steps_sampled: 1700000\n",
      "    num_steps_trained: 1700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7351281642913818\n",
      "      kl: 0.006349725183099508\n",
      "      policy_loss: -0.001037177979014814\n",
      "      total_loss: 56.22784423828125\n",
      "      vf_explained_var: 0.9602338075637817\n",
      "      vf_loss: 56.228885650634766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7934799194335938\n",
      "      kl: 0.0015007185284048319\n",
      "      policy_loss: -0.0008013762417249382\n",
      "      total_loss: 44.86100387573242\n",
      "      vf_explained_var: 0.9600334167480469\n",
      "      vf_loss: 44.86181640625\n",
      "    sample_time_ms: 20204.775\n",
      "    update_time_ms: 7.047\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.28449533442895\n",
      "    rl_1: 71.06986905647231\n",
      "  time_since_restore: 3990.1559920310974\n",
      "  time_this_iter_s: 23.50113821029663\n",
      "  time_total_s: 3990.1559920310974\n",
      "  timestamp: 1550884578\n",
      "  timesteps_since_restore: 1700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1700000\n",
      "  training_iteration: 170\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 3990 s, 170 iter, 1700000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-16-42\n",
      "  done: false\n",
      "  episode_len_mean: 108.0\n",
      "  episode_reward_max: 217.07666404249576\n",
      "  episode_reward_mean: 163.136137334132\n",
      "  episode_reward_min: -146.7168153038246\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 12682\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.491\n",
      "    load_time_ms: 2.37\n",
      "    num_steps_sampled: 1710000\n",
      "    num_steps_trained: 1710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7249191403388977\n",
      "      kl: 0.0035799676552414894\n",
      "      policy_loss: -0.0007089270511642098\n",
      "      total_loss: 79.88851165771484\n",
      "      vf_explained_var: 0.9424223303794861\n",
      "      vf_loss: 79.88922119140625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.778314471244812\n",
      "      kl: 0.006051685195416212\n",
      "      policy_loss: -0.0012577215675264597\n",
      "      total_loss: 71.05830383300781\n",
      "      vf_explained_var: 0.9376624822616577\n",
      "      vf_loss: 71.05956268310547\n",
      "    sample_time_ms: 20188.101\n",
      "    update_time_ms: 7.158\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.43324848796577\n",
      "    rl_1: 72.70288884616623\n",
      "  time_since_restore: 4013.5041797161102\n",
      "  time_this_iter_s: 23.348187685012817\n",
      "  time_total_s: 4013.5041797161102\n",
      "  timestamp: 1550884602\n",
      "  timesteps_since_restore: 1710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1710000\n",
      "  training_iteration: 171\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4013 s, 171 iter, 1710000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-17-04\n",
      "  done: false\n",
      "  episode_len_mean: 119.01\n",
      "  episode_reward_max: 227.05077412761509\n",
      "  episode_reward_mean: 155.56052016814286\n",
      "  episode_reward_min: -169.2388481937033\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 12767\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.906\n",
      "    load_time_ms: 2.337\n",
      "    num_steps_sampled: 1720000\n",
      "    num_steps_trained: 1720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7734862565994263\n",
      "      kl: 0.007238705176860094\n",
      "      policy_loss: -0.0019213991472497582\n",
      "      total_loss: 104.03333282470703\n",
      "      vf_explained_var: 0.9275298714637756\n",
      "      vf_loss: 104.03524780273438\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7626053094863892\n",
      "      kl: 0.012082523666322231\n",
      "      policy_loss: -0.005713163875043392\n",
      "      total_loss: 92.25119018554688\n",
      "      vf_explained_var: 0.9207667112350464\n",
      "      vf_loss: 92.25689697265625\n",
      "    sample_time_ms: 20120.602\n",
      "    update_time_ms: 7.097\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.81848768924132\n",
      "    rl_1: 67.7420324789015\n",
      "  time_since_restore: 4036.414370775223\n",
      "  time_this_iter_s: 22.91019105911255\n",
      "  time_total_s: 4036.414370775223\n",
      "  timestamp: 1550884624\n",
      "  timesteps_since_restore: 1720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1720000\n",
      "  training_iteration: 172\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4036 s, 172 iter, 1720000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-17-28\n",
      "  done: false\n",
      "  episode_len_mean: 113.75\n",
      "  episode_reward_max: 225.79362781009624\n",
      "  episode_reward_mean: 156.36641963170817\n",
      "  episode_reward_min: -169.2388481937033\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 12853\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.226\n",
      "    load_time_ms: 2.323\n",
      "    num_steps_sampled: 1730000\n",
      "    num_steps_trained: 1730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7416148781776428\n",
      "      kl: 0.004833273123949766\n",
      "      policy_loss: -0.0028397052083164454\n",
      "      total_loss: 53.37308883666992\n",
      "      vf_explained_var: 0.9580076336860657\n",
      "      vf_loss: 53.37593460083008\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7401939034461975\n",
      "      kl: 0.007081394549459219\n",
      "      policy_loss: -0.001001422991976142\n",
      "      total_loss: 40.9466438293457\n",
      "      vf_explained_var: 0.96250319480896\n",
      "      vf_loss: 40.947635650634766\n",
      "    sample_time_ms: 20124.492\n",
      "    update_time_ms: 7.09\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.78115512956305\n",
      "    rl_1: 68.58526450214512\n",
      "  time_since_restore: 4059.679208755493\n",
      "  time_this_iter_s: 23.264837980270386\n",
      "  time_total_s: 4059.679208755493\n",
      "  timestamp: 1550884648\n",
      "  timesteps_since_restore: 1730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1730000\n",
      "  training_iteration: 173\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4059 s, 173 iter, 1730000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 118.14\n",
      "  episode_reward_max: 230.0018189871617\n",
      "  episode_reward_mean: 167.48176927500376\n",
      "  episode_reward_min: -141.1218262487954\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 12939\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.235\n",
      "    load_time_ms: 2.321\n",
      "    num_steps_sampled: 1740000\n",
      "    num_steps_trained: 1740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7580345273017883\n",
      "      kl: 0.0034792141523212194\n",
      "      policy_loss: -0.0018889113562181592\n",
      "      total_loss: 36.55083465576172\n",
      "      vf_explained_var: 0.9652072191238403\n",
      "      vf_loss: 36.5527229309082\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7658689618110657\n",
      "      kl: 0.0065422095358371735\n",
      "      policy_loss: -0.0030035185627639294\n",
      "      total_loss: 29.15011215209961\n",
      "      vf_explained_var: 0.9672953486442566\n",
      "      vf_loss: 29.153114318847656\n",
      "    sample_time_ms: 20157.859\n",
      "    update_time_ms: 6.768\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.69059031632094\n",
      "    rl_1: 74.79117895868279\n",
      "  time_since_restore: 4083.0124990940094\n",
      "  time_this_iter_s: 23.333290338516235\n",
      "  time_total_s: 4083.0124990940094\n",
      "  timestamp: 1550884671\n",
      "  timesteps_since_restore: 1740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1740000\n",
      "  training_iteration: 174\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4083 s, 174 iter, 1740000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-18-15\n",
      "  done: false\n",
      "  episode_len_mean: 105.66\n",
      "  episode_reward_max: 228.60950939626844\n",
      "  episode_reward_mean: 164.7929736221681\n",
      "  episode_reward_min: -178.17169519025185\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 13033\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.081\n",
      "    load_time_ms: 2.271\n",
      "    num_steps_sampled: 1750000\n",
      "    num_steps_trained: 1750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7096218466758728\n",
      "      kl: 0.007241190876811743\n",
      "      policy_loss: -0.003063447307795286\n",
      "      total_loss: 69.98835754394531\n",
      "      vf_explained_var: 0.9426597356796265\n",
      "      vf_loss: 69.99142456054688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6929519176483154\n",
      "      kl: 0.00807515811175108\n",
      "      policy_loss: -0.0031175047624856234\n",
      "      total_loss: 56.69651412963867\n",
      "      vf_explained_var: 0.9432256817817688\n",
      "      vf_loss: 56.69962692260742\n",
      "    sample_time_ms: 20157.863\n",
      "    update_time_ms: 7.375\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.81727092950376\n",
      "    rl_1: 73.97570269266438\n",
      "  time_since_restore: 4106.808739423752\n",
      "  time_this_iter_s: 23.79624032974243\n",
      "  time_total_s: 4106.808739423752\n",
      "  timestamp: 1550884695\n",
      "  timesteps_since_restore: 1750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1750000\n",
      "  training_iteration: 175\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4106 s, 175 iter, 1750000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-18-38\n",
      "  done: false\n",
      "  episode_len_mean: 116.42\n",
      "  episode_reward_max: 222.71726034497382\n",
      "  episode_reward_mean: 154.71702934235333\n",
      "  episode_reward_min: -158.3400995137372\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 13118\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3108.53\n",
      "    load_time_ms: 2.274\n",
      "    num_steps_sampled: 1760000\n",
      "    num_steps_trained: 1760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8160459995269775\n",
      "      kl: 0.007864998653531075\n",
      "      policy_loss: -0.0011890189489349723\n",
      "      total_loss: 131.72889709472656\n",
      "      vf_explained_var: 0.9211474657058716\n",
      "      vf_loss: 131.73011779785156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7814833521842957\n",
      "      kl: 0.010531709529459476\n",
      "      policy_loss: -0.006191885098814964\n",
      "      total_loss: 108.19546508789062\n",
      "      vf_explained_var: 0.9204071164131165\n",
      "      vf_loss: 108.20166015625\n",
      "    sample_time_ms: 20151.178\n",
      "    update_time_ms: 7.348\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.9946509524684\n",
      "    rl_1: 68.72237838988491\n",
      "  time_since_restore: 4130.064605712891\n",
      "  time_this_iter_s: 23.255866289138794\n",
      "  time_total_s: 4130.064605712891\n",
      "  timestamp: 1550884718\n",
      "  timesteps_since_restore: 1760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1760000\n",
      "  training_iteration: 176\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4130 s, 176 iter, 1760000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-19-01\n",
      "  done: false\n",
      "  episode_len_mean: 107.46\n",
      "  episode_reward_max: 229.5933294078802\n",
      "  episode_reward_mean: 162.5642388388095\n",
      "  episode_reward_min: -165.8575758854487\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 13209\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.504\n",
      "    load_time_ms: 2.346\n",
      "    num_steps_sampled: 1770000\n",
      "    num_steps_trained: 1770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.679792046546936\n",
      "      kl: 0.007872749119997025\n",
      "      policy_loss: -0.001466865767724812\n",
      "      total_loss: 76.57882690429688\n",
      "      vf_explained_var: 0.9452528357505798\n",
      "      vf_loss: 76.58029174804688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6948104500770569\n",
      "      kl: 0.004518277943134308\n",
      "      policy_loss: -0.0021236299071460962\n",
      "      total_loss: 63.60408401489258\n",
      "      vf_explained_var: 0.9439771771430969\n",
      "      vf_loss: 63.60619354248047\n",
      "    sample_time_ms: 20137.19\n",
      "    update_time_ms: 7.458\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.69275780869025\n",
      "    rl_1: 71.87148103011924\n",
      "  time_since_restore: 4152.629565477371\n",
      "  time_this_iter_s: 22.56495976448059\n",
      "  time_total_s: 4152.629565477371\n",
      "  timestamp: 1550884741\n",
      "  timesteps_since_restore: 1770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1770000\n",
      "  training_iteration: 177\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4152 s, 177 iter, 1770000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-19-24\n",
      "  done: false\n",
      "  episode_len_mean: 115.41\n",
      "  episode_reward_max: 222.3301387187187\n",
      "  episode_reward_mean: 164.59236528235323\n",
      "  episode_reward_min: -166.97351590062368\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 13296\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.897\n",
      "    load_time_ms: 2.441\n",
      "    num_steps_sampled: 1780000\n",
      "    num_steps_trained: 1780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.752018392086029\n",
      "      kl: 0.005485182162374258\n",
      "      policy_loss: -0.0026033034082502127\n",
      "      total_loss: 66.91757202148438\n",
      "      vf_explained_var: 0.9447807669639587\n",
      "      vf_loss: 66.920166015625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7599931359291077\n",
      "      kl: 0.01178350392729044\n",
      "      policy_loss: -0.002151217544451356\n",
      "      total_loss: 64.62117004394531\n",
      "      vf_explained_var: 0.9388718008995056\n",
      "      vf_loss: 64.6233139038086\n",
      "    sample_time_ms: 20119.76\n",
      "    update_time_ms: 7.26\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.50386368511653\n",
      "    rl_1: 73.08850159723671\n",
      "  time_since_restore: 4175.5851900577545\n",
      "  time_this_iter_s: 22.9556245803833\n",
      "  time_total_s: 4175.5851900577545\n",
      "  timestamp: 1550884764\n",
      "  timesteps_since_restore: 1780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1780000\n",
      "  training_iteration: 178\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4175 s, 178 iter, 1780000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-19-47\n",
      "  done: false\n",
      "  episode_len_mean: 107.39\n",
      "  episode_reward_max: 226.8363081820427\n",
      "  episode_reward_mean: 164.88222511805714\n",
      "  episode_reward_min: -162.0890212657658\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 13389\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.702\n",
      "    load_time_ms: 2.39\n",
      "    num_steps_sampled: 1790000\n",
      "    num_steps_trained: 1790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6508451104164124\n",
      "      kl: 0.006594065576791763\n",
      "      policy_loss: -0.0002831483434420079\n",
      "      total_loss: 69.82325744628906\n",
      "      vf_explained_var: 0.9436149597167969\n",
      "      vf_loss: 69.82353973388672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6483945846557617\n",
      "      kl: 0.007448774762451649\n",
      "      policy_loss: -0.0022910479456186295\n",
      "      total_loss: 64.17037963867188\n",
      "      vf_explained_var: 0.9293668866157532\n",
      "      vf_loss: 64.17266845703125\n",
      "    sample_time_ms: 20122.963\n",
      "    update_time_ms: 7.469\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.2344508564403\n",
      "    rl_1: 71.64777426161686\n",
      "  time_since_restore: 4199.034976005554\n",
      "  time_this_iter_s: 23.449785947799683\n",
      "  time_total_s: 4199.034976005554\n",
      "  timestamp: 1550884787\n",
      "  timesteps_since_restore: 1790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1790000\n",
      "  training_iteration: 179\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4199 s, 179 iter, 1790000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 107.45\n",
      "  episode_reward_max: 228.36994537485714\n",
      "  episode_reward_mean: 168.96800330738535\n",
      "  episode_reward_min: -171.5136075063936\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 13482\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.367\n",
      "    load_time_ms: 2.414\n",
      "    num_steps_sampled: 1800000\n",
      "    num_steps_trained: 1800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6881727576255798\n",
      "      kl: 0.005061628762632608\n",
      "      policy_loss: -0.0023392944131046534\n",
      "      total_loss: 66.65166473388672\n",
      "      vf_explained_var: 0.9471391439437866\n",
      "      vf_loss: 66.65399932861328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7138150334358215\n",
      "      kl: 0.005528741516172886\n",
      "      policy_loss: -0.002219520043581724\n",
      "      total_loss: 57.232810974121094\n",
      "      vf_explained_var: 0.9295871257781982\n",
      "      vf_loss: 57.23502731323242\n",
      "    sample_time_ms: 20109.4\n",
      "    update_time_ms: 7.4\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.793826556164\n",
      "    rl_1: 73.17417675122137\n",
      "  time_since_restore: 4222.359089374542\n",
      "  time_this_iter_s: 23.324113368988037\n",
      "  time_total_s: 4222.359089374542\n",
      "  timestamp: 1550884811\n",
      "  timesteps_since_restore: 1800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1800000\n",
      "  training_iteration: 180\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4222 s, 180 iter, 1800000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-20-34\n",
      "  done: false\n",
      "  episode_len_mean: 113.16\n",
      "  episode_reward_max: 222.20157377312674\n",
      "  episode_reward_mean: 159.80530202370383\n",
      "  episode_reward_min: -169.95355891151806\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 13567\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.738\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 1810000\n",
      "    num_steps_trained: 1810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.778134822845459\n",
      "      kl: 0.0040051694959402084\n",
      "      policy_loss: -0.0025844089686870575\n",
      "      total_loss: 78.09867858886719\n",
      "      vf_explained_var: 0.9451449513435364\n",
      "      vf_loss: 78.10126495361328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7686948180198669\n",
      "      kl: 0.006796722300350666\n",
      "      policy_loss: -0.0027985216584056616\n",
      "      total_loss: 67.75965881347656\n",
      "      vf_explained_var: 0.9426566958427429\n",
      "      vf_loss: 67.762451171875\n",
      "    sample_time_ms: 20063.436\n",
      "    update_time_ms: 7.841\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.56627309805495\n",
      "    rl_1: 71.23902892564884\n",
      "  time_since_restore: 4245.23677277565\n",
      "  time_this_iter_s: 22.877683401107788\n",
      "  time_total_s: 4245.23677277565\n",
      "  timestamp: 1550884834\n",
      "  timesteps_since_restore: 1810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1810000\n",
      "  training_iteration: 181\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4245 s, 181 iter, 1810000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 119.24\n",
      "  episode_reward_max: 230.01020027423962\n",
      "  episode_reward_mean: 165.07626961285058\n",
      "  episode_reward_min: -161.75708353925006\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 13651\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.752\n",
      "    load_time_ms: 2.5\n",
      "    num_steps_sampled: 1820000\n",
      "    num_steps_trained: 1820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7741511464118958\n",
      "      kl: 0.006132118403911591\n",
      "      policy_loss: -0.0008654883713461459\n",
      "      total_loss: 89.64396667480469\n",
      "      vf_explained_var: 0.9347485303878784\n",
      "      vf_loss: 89.64484405517578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.763076663017273\n",
      "      kl: 0.008651597425341606\n",
      "      policy_loss: -0.0030559636652469635\n",
      "      total_loss: 79.54122924804688\n",
      "      vf_explained_var: 0.9239190816879272\n",
      "      vf_loss: 79.54427337646484\n",
      "    sample_time_ms: 20030.315\n",
      "    update_time_ms: 7.938\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.25013446316397\n",
      "    rl_1: 73.82613514968659\n",
      "  time_since_restore: 4267.820243835449\n",
      "  time_this_iter_s: 22.583471059799194\n",
      "  time_total_s: 4267.820243835449\n",
      "  timestamp: 1550884856\n",
      "  timesteps_since_restore: 1820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1820000\n",
      "  training_iteration: 182\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4267 s, 182 iter, 1820000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-21-20\n",
      "  done: false\n",
      "  episode_len_mean: 117.53\n",
      "  episode_reward_max: 228.28388044925268\n",
      "  episode_reward_mean: 146.9004169387946\n",
      "  episode_reward_min: -172.74220935230846\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 13739\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.521\n",
      "    load_time_ms: 2.582\n",
      "    num_steps_sampled: 1830000\n",
      "    num_steps_trained: 1830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.707695484161377\n",
      "      kl: 0.007842959836125374\n",
      "      policy_loss: -0.0011865817941725254\n",
      "      total_loss: 94.98725128173828\n",
      "      vf_explained_var: 0.9316339492797852\n",
      "      vf_loss: 94.98843383789062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7140587568283081\n",
      "      kl: 0.010247092694044113\n",
      "      policy_loss: -0.0036730782594531775\n",
      "      total_loss: 72.97118377685547\n",
      "      vf_explained_var: 0.9329840540885925\n",
      "      vf_loss: 72.974853515625\n",
      "    sample_time_ms: 20061.644\n",
      "    update_time_ms: 7.891\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.80412304683522\n",
      "    rl_1: 64.09629389195936\n",
      "  time_since_restore: 4291.317985534668\n",
      "  time_this_iter_s: 23.49774169921875\n",
      "  time_total_s: 4291.317985534668\n",
      "  timestamp: 1550884880\n",
      "  timesteps_since_restore: 1830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1830000\n",
      "  training_iteration: 183\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4291 s, 183 iter, 1830000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-21-44\n",
      "  done: false\n",
      "  episode_len_mean: 106.0\n",
      "  episode_reward_max: 228.348600697599\n",
      "  episode_reward_mean: 158.35007705241156\n",
      "  episode_reward_min: -175.69725818263174\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 13832\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.333\n",
      "    load_time_ms: 2.673\n",
      "    num_steps_sampled: 1840000\n",
      "    num_steps_trained: 1840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6043977737426758\n",
      "      kl: 0.006737877149134874\n",
      "      policy_loss: -0.0018540903693065047\n",
      "      total_loss: 105.99894714355469\n",
      "      vf_explained_var: 0.9145854115486145\n",
      "      vf_loss: 106.00080108642578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6554105281829834\n",
      "      kl: 0.006682003382593393\n",
      "      policy_loss: -0.00265869009308517\n",
      "      total_loss: 93.28056335449219\n",
      "      vf_explained_var: 0.9105256199836731\n",
      "      vf_loss: 93.28321838378906\n",
      "    sample_time_ms: 20161.356\n",
      "    update_time_ms: 8.134\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.00913151926035\n",
      "    rl_1: 72.3409455331512\n",
      "  time_since_restore: 4315.630193948746\n",
      "  time_this_iter_s: 24.31220841407776\n",
      "  time_total_s: 4315.630193948746\n",
      "  timestamp: 1550884904\n",
      "  timesteps_since_restore: 1840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1840000\n",
      "  training_iteration: 184\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4315 s, 184 iter, 1840000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-22-08\n",
      "  done: false\n",
      "  episode_len_mean: 110.84\n",
      "  episode_reward_max: 228.99776751621368\n",
      "  episode_reward_mean: 173.58995367505136\n",
      "  episode_reward_min: -139.59837191468736\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 13922\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.91\n",
      "    load_time_ms: 2.746\n",
      "    num_steps_sampled: 1850000\n",
      "    num_steps_trained: 1850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6355474591255188\n",
      "      kl: 0.004769606050103903\n",
      "      policy_loss: -0.0004532778402790427\n",
      "      total_loss: 49.86246109008789\n",
      "      vf_explained_var: 0.9537315368652344\n",
      "      vf_loss: 49.8629150390625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6790524125099182\n",
      "      kl: 0.006112272385507822\n",
      "      policy_loss: -0.001767463400028646\n",
      "      total_loss: 41.885379791259766\n",
      "      vf_explained_var: 0.9545580744743347\n",
      "      vf_loss: 41.88714599609375\n",
      "    sample_time_ms: 20117.127\n",
      "    update_time_ms: 7.696\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.64266596963333\n",
      "    rl_1: 76.94728770541808\n",
      "  time_since_restore: 4339.035119056702\n",
      "  time_this_iter_s: 23.404925107955933\n",
      "  time_total_s: 4339.035119056702\n",
      "  timestamp: 1550884928\n",
      "  timesteps_since_restore: 1850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1850000\n",
      "  training_iteration: 185\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4339 s, 185 iter, 1850000 ts, 174 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-22-31\n",
      "  done: false\n",
      "  episode_len_mean: 122.94\n",
      "  episode_reward_max: 228.74382566531887\n",
      "  episode_reward_mean: 156.7967969401734\n",
      "  episode_reward_min: -171.02318693075563\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 14000\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3060.523\n",
      "    load_time_ms: 2.805\n",
      "    num_steps_sampled: 1860000\n",
      "    num_steps_trained: 1860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7321878671646118\n",
      "      kl: 0.006067986600100994\n",
      "      policy_loss: -0.0023357076570391655\n",
      "      total_loss: 94.2657470703125\n",
      "      vf_explained_var: 0.9338364005088806\n",
      "      vf_loss: 94.26808166503906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7258754372596741\n",
      "      kl: 0.005288069136440754\n",
      "      policy_loss: -0.0008611776283942163\n",
      "      total_loss: 78.38614654541016\n",
      "      vf_explained_var: 0.9355900883674622\n",
      "      vf_loss: 78.38701629638672\n",
      "    sample_time_ms: 20113.48\n",
      "    update_time_ms: 7.647\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.69455627951102\n",
      "    rl_1: 69.1022406606624\n",
      "  time_since_restore: 4362.092552423477\n",
      "  time_this_iter_s: 23.057433366775513\n",
      "  time_total_s: 4362.092552423477\n",
      "  timestamp: 1550884951\n",
      "  timesteps_since_restore: 1860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1860000\n",
      "  training_iteration: 186\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4362 s, 186 iter, 1860000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-22-54\n",
      "  done: false\n",
      "  episode_len_mean: 125.53\n",
      "  episode_reward_max: 231.77920228361634\n",
      "  episode_reward_mean: 157.56077017565215\n",
      "  episode_reward_min: -172.5053656992139\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 14079\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.81\n",
      "    load_time_ms: 2.727\n",
      "    num_steps_sampled: 1870000\n",
      "    num_steps_trained: 1870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7836237549781799\n",
      "      kl: 0.009618384763598442\n",
      "      policy_loss: -0.004637846723198891\n",
      "      total_loss: 108.16492462158203\n",
      "      vf_explained_var: 0.9261075258255005\n",
      "      vf_loss: 108.1695556640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7354421615600586\n",
      "      kl: 0.00984230451285839\n",
      "      policy_loss: -0.002978410106152296\n",
      "      total_loss: 90.08545684814453\n",
      "      vf_explained_var: 0.92747563123703\n",
      "      vf_loss: 90.08844757080078\n",
      "    sample_time_ms: 20130.915\n",
      "    update_time_ms: 7.653\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.06249905600127\n",
      "    rl_1: 68.49827111965084\n",
      "  time_since_restore: 4384.842221736908\n",
      "  time_this_iter_s: 22.749669313430786\n",
      "  time_total_s: 4384.842221736908\n",
      "  timestamp: 1550884974\n",
      "  timesteps_since_restore: 1870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1870000\n",
      "  training_iteration: 187\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4384 s, 187 iter, 1870000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-23-17\n",
      "  done: false\n",
      "  episode_len_mean: 120.64\n",
      "  episode_reward_max: 226.68830104936686\n",
      "  episode_reward_mean: 149.43361958949296\n",
      "  episode_reward_min: -172.5053656992139\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 14166\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.108\n",
      "    load_time_ms: 2.657\n",
      "    num_steps_sampled: 1880000\n",
      "    num_steps_trained: 1880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6863587498664856\n",
      "      kl: 0.006527706049382687\n",
      "      policy_loss: -0.0015568574890494347\n",
      "      total_loss: 107.7339096069336\n",
      "      vf_explained_var: 0.9326179623603821\n",
      "      vf_loss: 107.7354507446289\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6735401749610901\n",
      "      kl: 0.011476041749119759\n",
      "      policy_loss: -0.004262000322341919\n",
      "      total_loss: 85.99524688720703\n",
      "      vf_explained_var: 0.9372591972351074\n",
      "      vf_loss: 85.99950408935547\n",
      "    sample_time_ms: 20145.585\n",
      "    update_time_ms: 7.541\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.60447419538352\n",
      "    rl_1: 65.82914539410943\n",
      "  time_since_restore: 4407.935600280762\n",
      "  time_this_iter_s: 23.09337854385376\n",
      "  time_total_s: 4407.935600280762\n",
      "  timestamp: 1550884997\n",
      "  timesteps_since_restore: 1880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1880000\n",
      "  training_iteration: 188\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4407 s, 188 iter, 1880000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-23-40\n",
      "  done: false\n",
      "  episode_len_mean: 127.63\n",
      "  episode_reward_max: 229.09984871691694\n",
      "  episode_reward_mean: 163.53384805456201\n",
      "  episode_reward_min: -161.42314102178102\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 14242\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.727\n",
      "    load_time_ms: 2.662\n",
      "    num_steps_sampled: 1890000\n",
      "    num_steps_trained: 1890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8015538454055786\n",
      "      kl: 0.0070627592504024506\n",
      "      policy_loss: -0.0007850626716390252\n",
      "      total_loss: 59.1225471496582\n",
      "      vf_explained_var: 0.9556191563606262\n",
      "      vf_loss: 59.12333297729492\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7489900588989258\n",
      "      kl: 0.0028078784234821796\n",
      "      policy_loss: -0.0009753766935318708\n",
      "      total_loss: 46.942405700683594\n",
      "      vf_explained_var: 0.9634774327278137\n",
      "      vf_loss: 46.94337463378906\n",
      "    sample_time_ms: 20062.888\n",
      "    update_time_ms: 7.465\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.82892350294091\n",
      "    rl_1: 73.70492455162108\n",
      "  time_since_restore: 4430.733336687088\n",
      "  time_this_iter_s: 22.797736406326294\n",
      "  time_total_s: 4430.733336687088\n",
      "  timestamp: 1550885020\n",
      "  timesteps_since_restore: 1890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1890000\n",
      "  training_iteration: 189\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4430 s, 189 iter, 1890000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-24-02\n",
      "  done: false\n",
      "  episode_len_mean: 124.4\n",
      "  episode_reward_max: 229.09984871691694\n",
      "  episode_reward_mean: 168.01887294015637\n",
      "  episode_reward_min: -140.14410010206265\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 14324\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.014\n",
      "    load_time_ms: 2.588\n",
      "    num_steps_sampled: 1900000\n",
      "    num_steps_trained: 1900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6849588751792908\n",
      "      kl: 0.0034413153771311045\n",
      "      policy_loss: -0.0003960382891818881\n",
      "      total_loss: 52.12171173095703\n",
      "      vf_explained_var: 0.9625101089477539\n",
      "      vf_loss: 52.12211227416992\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6667596101760864\n",
      "      kl: 0.004618192557245493\n",
      "      policy_loss: -0.0020502768456935883\n",
      "      total_loss: 40.15407943725586\n",
      "      vf_explained_var: 0.9646795392036438\n",
      "      vf_loss: 40.156124114990234\n",
      "    sample_time_ms: 19997.909\n",
      "    update_time_ms: 7.47\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.85264175624283\n",
      "    rl_1: 74.16623118391351\n",
      "  time_since_restore: 4453.416480541229\n",
      "  time_this_iter_s: 22.683143854141235\n",
      "  time_total_s: 4453.416480541229\n",
      "  timestamp: 1550885042\n",
      "  timesteps_since_restore: 1900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1900000\n",
      "  training_iteration: 190\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4453 s, 190 iter, 1900000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-24-25\n",
      "  done: false\n",
      "  episode_len_mean: 122.06\n",
      "  episode_reward_max: 223.68546331299277\n",
      "  episode_reward_mean: 152.57910502658197\n",
      "  episode_reward_min: -168.99757892099797\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 14409\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.847\n",
      "    load_time_ms: 2.565\n",
      "    num_steps_sampled: 1910000\n",
      "    num_steps_trained: 1910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6902056932449341\n",
      "      kl: 0.004419638775289059\n",
      "      policy_loss: -0.002124171704053879\n",
      "      total_loss: 73.52671813964844\n",
      "      vf_explained_var: 0.9519709944725037\n",
      "      vf_loss: 73.52883911132812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6902889013290405\n",
      "      kl: 0.007487905211746693\n",
      "      policy_loss: -0.004395928233861923\n",
      "      total_loss: 62.737911224365234\n",
      "      vf_explained_var: 0.9514102339744568\n",
      "      vf_loss: 62.74230194091797\n",
      "    sample_time_ms: 20013.544\n",
      "    update_time_ms: 6.851\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.09233100640826\n",
      "    rl_1: 66.48677402017374\n",
      "  time_since_restore: 4476.461443424225\n",
      "  time_this_iter_s: 23.044962882995605\n",
      "  time_total_s: 4476.461443424225\n",
      "  timestamp: 1550885065\n",
      "  timesteps_since_restore: 1910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1910000\n",
      "  training_iteration: 191\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4476 s, 191 iter, 1910000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-24-49\n",
      "  done: false\n",
      "  episode_len_mean: 126.15\n",
      "  episode_reward_max: 230.69879629929994\n",
      "  episode_reward_mean: 161.84857929656525\n",
      "  episode_reward_min: -150.4342699408632\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 14488\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.983\n",
      "    load_time_ms: 2.548\n",
      "    num_steps_sampled: 1920000\n",
      "    num_steps_trained: 1920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7742913365364075\n",
      "      kl: 0.004365982953459024\n",
      "      policy_loss: -6.548238889081404e-05\n",
      "      total_loss: 50.53847885131836\n",
      "      vf_explained_var: 0.9597929120063782\n",
      "      vf_loss: 50.53854751586914\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7333734035491943\n",
      "      kl: 0.008557336404919624\n",
      "      policy_loss: -0.003103758906945586\n",
      "      total_loss: 41.5849609375\n",
      "      vf_explained_var: 0.9637400507926941\n",
      "      vf_loss: 41.58805847167969\n",
      "    sample_time_ms: 20065.911\n",
      "    update_time_ms: 6.999\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.60087861958961\n",
      "    rl_1: 71.24770067697567\n",
      "  time_since_restore: 4499.539383888245\n",
      "  time_this_iter_s: 23.077940464019775\n",
      "  time_total_s: 4499.539383888245\n",
      "  timestamp: 1550885089\n",
      "  timesteps_since_restore: 1920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1920000\n",
      "  training_iteration: 192\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4499 s, 192 iter, 1920000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-25-11\n",
      "  done: false\n",
      "  episode_len_mean: 116.24\n",
      "  episode_reward_max: 230.69879629929994\n",
      "  episode_reward_mean: 166.63003879965396\n",
      "  episode_reward_min: -166.51967956673212\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 14569\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.843\n",
      "    load_time_ms: 2.466\n",
      "    num_steps_sampled: 1930000\n",
      "    num_steps_trained: 1930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6881543397903442\n",
      "      kl: 0.01048493105918169\n",
      "      policy_loss: -0.004020391963422298\n",
      "      total_loss: 61.536258697509766\n",
      "      vf_explained_var: 0.9552210569381714\n",
      "      vf_loss: 61.54027557373047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6602796912193298\n",
      "      kl: 0.007040931843221188\n",
      "      policy_loss: -0.0036907512694597244\n",
      "      total_loss: 49.86273956298828\n",
      "      vf_explained_var: 0.9588233828544617\n",
      "      vf_loss: 49.86643600463867\n",
      "    sample_time_ms: 19999.335\n",
      "    update_time_ms: 6.983\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.14025590062701\n",
      "    rl_1: 74.48978289902692\n",
      "  time_since_restore: 4522.426246643066\n",
      "  time_this_iter_s: 22.886862754821777\n",
      "  time_total_s: 4522.426246643066\n",
      "  timestamp: 1550885111\n",
      "  timesteps_since_restore: 1930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1930000\n",
      "  training_iteration: 193\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4522 s, 193 iter, 1930000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-25-34\n",
      "  done: false\n",
      "  episode_len_mean: 125.58\n",
      "  episode_reward_max: 231.17153160879016\n",
      "  episode_reward_mean: 164.60609041692948\n",
      "  episode_reward_min: -166.51967956673212\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 14651\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.332\n",
      "    load_time_ms: 2.393\n",
      "    num_steps_sampled: 1940000\n",
      "    num_steps_trained: 1940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7073665261268616\n",
      "      kl: 0.004283116199076176\n",
      "      policy_loss: -0.0010030897101387382\n",
      "      total_loss: 35.62706756591797\n",
      "      vf_explained_var: 0.9719415307044983\n",
      "      vf_loss: 35.62806701660156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6881535649299622\n",
      "      kl: 0.006192813161760569\n",
      "      policy_loss: -0.002015875419601798\n",
      "      total_loss: 28.206205368041992\n",
      "      vf_explained_var: 0.9722465872764587\n",
      "      vf_loss: 28.208223342895508\n",
      "    sample_time_ms: 19807.858\n",
      "    update_time_ms: 6.815\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.48161101517512\n",
      "    rl_1: 73.12447940175436\n",
      "  time_since_restore: 4544.815727233887\n",
      "  time_this_iter_s: 22.389480590820312\n",
      "  time_total_s: 4544.815727233887\n",
      "  timestamp: 1550885134\n",
      "  timesteps_since_restore: 1940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1940000\n",
      "  training_iteration: 194\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4544 s, 194 iter, 1940000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-25-57\n",
      "  done: false\n",
      "  episode_len_mean: 115.46\n",
      "  episode_reward_max: 234.98740932821593\n",
      "  episode_reward_mean: 165.38747746781533\n",
      "  episode_reward_min: -157.6376053692116\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 14739\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.713\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 1950000\n",
      "    num_steps_trained: 1950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.693749725818634\n",
      "      kl: 0.00607816968113184\n",
      "      policy_loss: -0.0012331173056736588\n",
      "      total_loss: 50.308048248291016\n",
      "      vf_explained_var: 0.9589727520942688\n",
      "      vf_loss: 50.30928039550781\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7002732157707214\n",
      "      kl: 0.005656602792441845\n",
      "      policy_loss: -0.002659096848219633\n",
      "      total_loss: 40.14729309082031\n",
      "      vf_explained_var: 0.9568215608596802\n",
      "      vf_loss: 40.14994812011719\n",
      "    sample_time_ms: 19771.155\n",
      "    update_time_ms: 7.085\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.71884884378842\n",
      "    rl_1: 72.66862862402691\n",
      "  time_since_restore: 4567.728258609772\n",
      "  time_this_iter_s: 22.91253137588501\n",
      "  time_total_s: 4567.728258609772\n",
      "  timestamp: 1550885157\n",
      "  timesteps_since_restore: 1950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1950000\n",
      "  training_iteration: 195\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4567 s, 195 iter, 1950000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-26-20\n",
      "  done: false\n",
      "  episode_len_mean: 125.58\n",
      "  episode_reward_max: 218.98325039079282\n",
      "  episode_reward_mean: 154.65546402377896\n",
      "  episode_reward_min: -174.85631189526765\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 14817\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.619\n",
      "    load_time_ms: 2.288\n",
      "    num_steps_sampled: 1960000\n",
      "    num_steps_trained: 1960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.8276450037956238\n",
      "      kl: 0.006364530883729458\n",
      "      policy_loss: -0.003025224432349205\n",
      "      total_loss: 48.68912124633789\n",
      "      vf_explained_var: 0.9684740900993347\n",
      "      vf_loss: 48.692142486572266\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7621406316757202\n",
      "      kl: 0.006867439951747656\n",
      "      policy_loss: -8.700387115823105e-05\n",
      "      total_loss: 39.4289665222168\n",
      "      vf_explained_var: 0.9656266570091248\n",
      "      vf_loss: 39.429054260253906\n",
      "    sample_time_ms: 19765.139\n",
      "    update_time_ms: 7.091\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.94949132442001\n",
      "    rl_1: 65.70597269935894\n",
      "  time_since_restore: 4590.741575956345\n",
      "  time_this_iter_s: 23.013317346572876\n",
      "  time_total_s: 4590.741575956345\n",
      "  timestamp: 1550885180\n",
      "  timesteps_since_restore: 1960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1960000\n",
      "  training_iteration: 196\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4590 s, 196 iter, 1960000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-26-44\n",
      "  done: false\n",
      "  episode_len_mean: 109.42\n",
      "  episode_reward_max: 217.91011084177987\n",
      "  episode_reward_mean: 147.9170508300248\n",
      "  episode_reward_min: -175.08082099971926\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 14911\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.866\n",
      "    load_time_ms: 2.301\n",
      "    num_steps_sampled: 1970000\n",
      "    num_steps_trained: 1970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6047903299331665\n",
      "      kl: 0.009581191465258598\n",
      "      policy_loss: -0.00043441029265522957\n",
      "      total_loss: 66.543701171875\n",
      "      vf_explained_var: 0.9605411887168884\n",
      "      vf_loss: 66.54413604736328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6348642706871033\n",
      "      kl: 0.005379780195653439\n",
      "      policy_loss: -0.0015268701827153563\n",
      "      total_loss: 56.09885787963867\n",
      "      vf_explained_var: 0.9556776285171509\n",
      "      vf_loss: 56.100372314453125\n",
      "    sample_time_ms: 19903.986\n",
      "    update_time_ms: 7.34\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.64064670179195\n",
      "    rl_1: 63.276404128232855\n",
      "  time_since_restore: 4614.845978021622\n",
      "  time_this_iter_s: 24.1044020652771\n",
      "  time_total_s: 4614.845978021622\n",
      "  timestamp: 1550885204\n",
      "  timesteps_since_restore: 1970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1970000\n",
      "  training_iteration: 197\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4614 s, 197 iter, 1970000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-27-08\n",
      "  done: false\n",
      "  episode_len_mean: 121.63\n",
      "  episode_reward_max: 227.28726885384503\n",
      "  episode_reward_mean: 163.40875687717676\n",
      "  episode_reward_min: -175.85310207669409\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 14994\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.941\n",
      "    load_time_ms: 2.281\n",
      "    num_steps_sampled: 1980000\n",
      "    num_steps_trained: 1980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6985973715782166\n",
      "      kl: 0.006705794017761946\n",
      "      policy_loss: -0.003193907905369997\n",
      "      total_loss: 51.466487884521484\n",
      "      vf_explained_var: 0.9598914980888367\n",
      "      vf_loss: 51.46968078613281\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6993030905723572\n",
      "      kl: 0.006630744785070419\n",
      "      policy_loss: -0.001756673795171082\n",
      "      total_loss: 43.69687271118164\n",
      "      vf_explained_var: 0.9630017280578613\n",
      "      vf_loss: 43.698631286621094\n",
      "    sample_time_ms: 19915.472\n",
      "    update_time_ms: 7.536\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.99259202146258\n",
      "    rl_1: 74.4161648557142\n",
      "  time_since_restore: 4638.2667326927185\n",
      "  time_this_iter_s: 23.4207546710968\n",
      "  time_total_s: 4638.2667326927185\n",
      "  timestamp: 1550885228\n",
      "  timesteps_since_restore: 1980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1980000\n",
      "  training_iteration: 198\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4638 s, 198 iter, 1980000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-27-31\n",
      "  done: false\n",
      "  episode_len_mean: 119.06\n",
      "  episode_reward_max: 233.5275244843148\n",
      "  episode_reward_mean: 168.60856876910017\n",
      "  episode_reward_min: -154.42034511626272\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 15082\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.878\n",
      "    load_time_ms: 2.351\n",
      "    num_steps_sampled: 1990000\n",
      "    num_steps_trained: 1990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5923812389373779\n",
      "      kl: 0.008906316012144089\n",
      "      policy_loss: -0.0010789541993290186\n",
      "      total_loss: 52.94470977783203\n",
      "      vf_explained_var: 0.9580338597297668\n",
      "      vf_loss: 52.9457893371582\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5879278182983398\n",
      "      kl: 0.007243277970701456\n",
      "      policy_loss: -0.0022315902169793844\n",
      "      total_loss: 46.49100875854492\n",
      "      vf_explained_var: 0.949881911277771\n",
      "      vf_loss: 46.49324417114258\n",
      "    sample_time_ms: 19977.466\n",
      "    update_time_ms: 7.472\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.59510828107521\n",
      "    rl_1: 74.01346048802492\n",
      "  time_since_restore: 4661.495455265045\n",
      "  time_this_iter_s: 23.22872257232666\n",
      "  time_total_s: 4661.495455265045\n",
      "  timestamp: 1550885251\n",
      "  timesteps_since_restore: 1990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 1990000\n",
      "  training_iteration: 199\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4661 s, 199 iter, 1990000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-27-54\n",
      "  done: false\n",
      "  episode_len_mean: 124.11\n",
      "  episode_reward_max: 231.61661827129223\n",
      "  episode_reward_mean: 157.3630852020635\n",
      "  episode_reward_min: -160.2300530123373\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 15164\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.988\n",
      "    load_time_ms: 2.359\n",
      "    num_steps_sampled: 2000000\n",
      "    num_steps_trained: 2000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7174768447875977\n",
      "      kl: 0.009942000731825829\n",
      "      policy_loss: -0.003713516751304269\n",
      "      total_loss: 72.12125396728516\n",
      "      vf_explained_var: 0.9499902129173279\n",
      "      vf_loss: 72.12495422363281\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.7124648094177246\n",
      "      kl: 0.004791316110640764\n",
      "      policy_loss: -0.0009489338262937963\n",
      "      total_loss: 57.151885986328125\n",
      "      vf_explained_var: 0.9522150754928589\n",
      "      vf_loss: 57.15283203125\n",
      "    sample_time_ms: 20041.3\n",
      "    update_time_ms: 7.5\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.09480223079109\n",
      "    rl_1: 69.26828297127243\n",
      "  time_since_restore: 4684.809949636459\n",
      "  time_this_iter_s: 23.314494371414185\n",
      "  time_total_s: 4684.809949636459\n",
      "  timestamp: 1550885274\n",
      "  timesteps_since_restore: 2000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2000000\n",
      "  training_iteration: 200\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4684 s, 200 iter, 2000000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-28-18\n",
      "  done: false\n",
      "  episode_len_mean: 121.49\n",
      "  episode_reward_max: 229.81096471537185\n",
      "  episode_reward_mean: 159.52707007527803\n",
      "  episode_reward_min: -166.86245745945686\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 15247\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.739\n",
      "    load_time_ms: 2.278\n",
      "    num_steps_sampled: 2010000\n",
      "    num_steps_trained: 2010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6648977994918823\n",
      "      kl: 0.006626259069889784\n",
      "      policy_loss: -0.001891289371997118\n",
      "      total_loss: 68.87967681884766\n",
      "      vf_explained_var: 0.9484085440635681\n",
      "      vf_loss: 68.88156127929688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6353827714920044\n",
      "      kl: 0.0057771834544837475\n",
      "      policy_loss: -0.0030995409470051527\n",
      "      total_loss: 54.872413635253906\n",
      "      vf_explained_var: 0.9486494660377502\n",
      "      vf_loss: 54.87551498413086\n",
      "    sample_time_ms: 20072.024\n",
      "    update_time_ms: 7.685\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.53455652630663\n",
      "    rl_1: 69.99251354897139\n",
      "  time_since_restore: 4708.142619132996\n",
      "  time_this_iter_s: 23.332669496536255\n",
      "  time_total_s: 4708.142619132996\n",
      "  timestamp: 1550885298\n",
      "  timesteps_since_restore: 2010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2010000\n",
      "  training_iteration: 201\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4708 s, 201 iter, 2010000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-28-41\n",
      "  done: false\n",
      "  episode_len_mean: 105.47\n",
      "  episode_reward_max: 228.52404449745416\n",
      "  episode_reward_mean: 159.4611766410636\n",
      "  episode_reward_min: -172.79005725950657\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 15344\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.759\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 2020000\n",
      "    num_steps_trained: 2020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5017968416213989\n",
      "      kl: 0.00718634994700551\n",
      "      policy_loss: -0.0016039388719946146\n",
      "      total_loss: 105.7324447631836\n",
      "      vf_explained_var: 0.926853597164154\n",
      "      vf_loss: 105.73404693603516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5956800580024719\n",
      "      kl: 0.005138282664120197\n",
      "      policy_loss: -0.0020045002456754446\n",
      "      total_loss: 89.77092742919922\n",
      "      vf_explained_var: 0.9183114767074585\n",
      "      vf_loss: 89.77293395996094\n",
      "    sample_time_ms: 20107.088\n",
      "    update_time_ms: 7.471\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.82926486060724\n",
      "    rl_1: 69.63191178045638\n",
      "  time_since_restore: 4731.598508358002\n",
      "  time_this_iter_s: 23.455889225006104\n",
      "  time_total_s: 4731.598508358002\n",
      "  timestamp: 1550885321\n",
      "  timesteps_since_restore: 2020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2020000\n",
      "  training_iteration: 202\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4731 s, 202 iter, 2020000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-29-04\n",
      "  done: false\n",
      "  episode_len_mean: 108.09\n",
      "  episode_reward_max: 235.13275639048072\n",
      "  episode_reward_mean: 161.6041503693475\n",
      "  episode_reward_min: -172.79005725950657\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 15435\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.456\n",
      "    load_time_ms: 2.394\n",
      "    num_steps_sampled: 2030000\n",
      "    num_steps_trained: 2030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5363234281539917\n",
      "      kl: 0.007803019601851702\n",
      "      policy_loss: -0.002143156947568059\n",
      "      total_loss: 87.05023956298828\n",
      "      vf_explained_var: 0.9295927286148071\n",
      "      vf_loss: 87.0523910522461\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5478622913360596\n",
      "      kl: 0.006561014801263809\n",
      "      policy_loss: -0.002111575333401561\n",
      "      total_loss: 73.65021514892578\n",
      "      vf_explained_var: 0.9233354330062866\n",
      "      vf_loss: 73.6523208618164\n",
      "    sample_time_ms: 20125.604\n",
      "    update_time_ms: 7.565\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.66707616315738\n",
      "    rl_1: 71.93707420619013\n",
      "  time_since_restore: 4754.651206970215\n",
      "  time_this_iter_s: 23.052698612213135\n",
      "  time_total_s: 4754.651206970215\n",
      "  timestamp: 1550885344\n",
      "  timesteps_since_restore: 2030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2030000\n",
      "  training_iteration: 203\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4754 s, 203 iter, 2030000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-29-27\n",
      "  done: false\n",
      "  episode_len_mean: 118.28\n",
      "  episode_reward_max: 231.32296803908346\n",
      "  episode_reward_mean: 150.6608773155038\n",
      "  episode_reward_min: -169.60326691530332\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 15522\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.959\n",
      "    load_time_ms: 2.4\n",
      "    num_steps_sampled: 2040000\n",
      "    num_steps_trained: 2040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5986658334732056\n",
      "      kl: 0.006448998581618071\n",
      "      policy_loss: -0.0012893633684143424\n",
      "      total_loss: 66.9686050415039\n",
      "      vf_explained_var: 0.956371009349823\n",
      "      vf_loss: 66.96989440917969\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6055148243904114\n",
      "      kl: 0.005485318601131439\n",
      "      policy_loss: -0.0018597734160721302\n",
      "      total_loss: 56.300724029541016\n",
      "      vf_explained_var: 0.958314061164856\n",
      "      vf_loss: 56.30258560180664\n",
      "    sample_time_ms: 20210.051\n",
      "    update_time_ms: 7.545\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.40570327106653\n",
      "    rl_1: 65.25517404443728\n",
      "  time_since_restore: 4777.911664009094\n",
      "  time_this_iter_s: 23.260457038879395\n",
      "  time_total_s: 4777.911664009094\n",
      "  timestamp: 1550885367\n",
      "  timesteps_since_restore: 2040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2040000\n",
      "  training_iteration: 204\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4777 s, 204 iter, 2040000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-29-50\n",
      "  done: false\n",
      "  episode_len_mean: 115.03\n",
      "  episode_reward_max: 235.9155893954381\n",
      "  episode_reward_mean: 147.37533629394994\n",
      "  episode_reward_min: -166.32596975121868\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 15608\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.129\n",
      "    load_time_ms: 2.38\n",
      "    num_steps_sampled: 2050000\n",
      "    num_steps_trained: 2050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.612434983253479\n",
      "      kl: 0.008001779206097126\n",
      "      policy_loss: -0.0027051554061472416\n",
      "      total_loss: 73.0187759399414\n",
      "      vf_explained_var: 0.955899178981781\n",
      "      vf_loss: 73.02146911621094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.595280110836029\n",
      "      kl: 0.005103873088955879\n",
      "      policy_loss: -0.0015297486679628491\n",
      "      total_loss: 63.076141357421875\n",
      "      vf_explained_var: 0.9556673765182495\n",
      "      vf_loss: 63.077674865722656\n",
      "    sample_time_ms: 20217.085\n",
      "    update_time_ms: 7.241\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.12201807595784\n",
      "    rl_1: 63.25331821799207\n",
      "  time_since_restore: 4800.863811969757\n",
      "  time_this_iter_s: 22.952147960662842\n",
      "  time_total_s: 4800.863811969757\n",
      "  timestamp: 1550885390\n",
      "  timesteps_since_restore: 2050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2050000\n",
      "  training_iteration: 205\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4800 s, 205 iter, 2050000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-30-13\n",
      "  done: false\n",
      "  episode_len_mean: 114.6\n",
      "  episode_reward_max: 232.68794703504912\n",
      "  episode_reward_mean: 147.38876965189655\n",
      "  episode_reward_min: -170.26783013656927\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 15694\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.443\n",
      "    load_time_ms: 2.365\n",
      "    num_steps_sampled: 2060000\n",
      "    num_steps_trained: 2060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6332676410675049\n",
      "      kl: 0.005393036641180515\n",
      "      policy_loss: -0.0021678078919649124\n",
      "      total_loss: 103.54927062988281\n",
      "      vf_explained_var: 0.9337151646614075\n",
      "      vf_loss: 103.55142974853516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6233642101287842\n",
      "      kl: 0.005271722562611103\n",
      "      policy_loss: -0.0031531555578112602\n",
      "      total_loss: 95.52056121826172\n",
      "      vf_explained_var: 0.9272112846374512\n",
      "      vf_loss: 95.52371215820312\n",
      "    sample_time_ms: 20206.431\n",
      "    update_time_ms: 7.48\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.25832914644096\n",
      "    rl_1: 64.13044050545562\n",
      "  time_since_restore: 4823.796678781509\n",
      "  time_this_iter_s: 22.93286681175232\n",
      "  time_total_s: 4823.796678781509\n",
      "  timestamp: 1550885413\n",
      "  timesteps_since_restore: 2060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2060000\n",
      "  training_iteration: 206\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4823 s, 206 iter, 2060000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 115.01\n",
      "  episode_reward_max: 231.9744778479341\n",
      "  episode_reward_mean: 158.69925256882564\n",
      "  episode_reward_min: -170.056289474332\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 15779\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.377\n",
      "    load_time_ms: 2.35\n",
      "    num_steps_sampled: 2070000\n",
      "    num_steps_trained: 2070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6394368410110474\n",
      "      kl: 0.009357825852930546\n",
      "      policy_loss: -0.00198724796064198\n",
      "      total_loss: 71.29708099365234\n",
      "      vf_explained_var: 0.943343460559845\n",
      "      vf_loss: 71.29905700683594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6168681979179382\n",
      "      kl: 0.0076666963286697865\n",
      "      policy_loss: -0.0036471718922257423\n",
      "      total_loss: 57.50215530395508\n",
      "      vf_explained_var: 0.9491512775421143\n",
      "      vf_loss: 57.50579833984375\n",
      "    sample_time_ms: 20044.036\n",
      "    update_time_ms: 7.222\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.54783360015347\n",
      "    rl_1: 70.15141896867217\n",
      "  time_since_restore: 4846.292856454849\n",
      "  time_this_iter_s: 22.496177673339844\n",
      "  time_total_s: 4846.292856454849\n",
      "  timestamp: 1550885436\n",
      "  timesteps_since_restore: 2070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2070000\n",
      "  training_iteration: 207\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4846 s, 207 iter, 2070000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-30-59\n",
      "  done: false\n",
      "  episode_len_mean: 131.26\n",
      "  episode_reward_max: 229.21662625762872\n",
      "  episode_reward_mean: 160.56338732925863\n",
      "  episode_reward_min: -166.25493915801417\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 15861\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3050.891\n",
      "    load_time_ms: 2.449\n",
      "    num_steps_sampled: 2080000\n",
      "    num_steps_trained: 2080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6153367757797241\n",
      "      kl: 0.009274771437048912\n",
      "      policy_loss: -0.0036907573230564594\n",
      "      total_loss: 60.13043212890625\n",
      "      vf_explained_var: 0.9526901245117188\n",
      "      vf_loss: 60.13412857055664\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5924494862556458\n",
      "      kl: 0.00843833852559328\n",
      "      policy_loss: -0.003981444984674454\n",
      "      total_loss: 45.75469970703125\n",
      "      vf_explained_var: 0.957379937171936\n",
      "      vf_loss: 45.75868225097656\n",
      "    sample_time_ms: 20023.968\n",
      "    update_time_ms: 7.015\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.4894080476141\n",
      "    rl_1: 70.07397928164451\n",
      "  time_since_restore: 4869.287792444229\n",
      "  time_this_iter_s: 22.994935989379883\n",
      "  time_total_s: 4869.287792444229\n",
      "  timestamp: 1550885459\n",
      "  timesteps_since_restore: 2080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2080000\n",
      "  training_iteration: 208\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4869 s, 208 iter, 2080000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-31-22\n",
      "  done: false\n",
      "  episode_len_mean: 116.82\n",
      "  episode_reward_max: 235.20809250498849\n",
      "  episode_reward_mean: 167.00017468776673\n",
      "  episode_reward_min: -166.25493915801417\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 15945\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3050.78\n",
      "    load_time_ms: 2.393\n",
      "    num_steps_sampled: 2090000\n",
      "    num_steps_trained: 2090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6160609126091003\n",
      "      kl: 0.006182328797876835\n",
      "      policy_loss: -0.0007554088369943202\n",
      "      total_loss: 32.29985046386719\n",
      "      vf_explained_var: 0.9728160500526428\n",
      "      vf_loss: 32.30060577392578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.58022540807724\n",
      "      kl: 0.008541935123503208\n",
      "      policy_loss: -0.002568044699728489\n",
      "      total_loss: 28.245899200439453\n",
      "      vf_explained_var: 0.9710673093795776\n",
      "      vf_loss: 28.24846649169922\n",
      "    sample_time_ms: 19955.147\n",
      "    update_time_ms: 7.008\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.11067758217601\n",
      "    rl_1: 72.88949710559072\n",
      "  time_since_restore: 4891.826794624329\n",
      "  time_this_iter_s: 22.539002180099487\n",
      "  time_total_s: 4891.826794624329\n",
      "  timestamp: 1550885482\n",
      "  timesteps_since_restore: 2090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2090000\n",
      "  training_iteration: 209\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4891 s, 209 iter, 2090000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-31-45\n",
      "  done: false\n",
      "  episode_len_mean: 102.99\n",
      "  episode_reward_max: 228.77344269513773\n",
      "  episode_reward_mean: 161.12545014244742\n",
      "  episode_reward_min: -177.00657951579103\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 16042\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3052.768\n",
      "    load_time_ms: 2.378\n",
      "    num_steps_sampled: 2100000\n",
      "    num_steps_trained: 2100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.48471757769584656\n",
      "      kl: 0.008586045354604721\n",
      "      policy_loss: -0.0020141522400081158\n",
      "      total_loss: 75.97772979736328\n",
      "      vf_explained_var: 0.9429721236228943\n",
      "      vf_loss: 75.97974395751953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5354443788528442\n",
      "      kl: 0.01320151798427105\n",
      "      policy_loss: -0.0020601144060492516\n",
      "      total_loss: 65.71702575683594\n",
      "      vf_explained_var: 0.9399229884147644\n",
      "      vf_loss: 65.71908569335938\n",
      "    sample_time_ms: 19947.733\n",
      "    update_time_ms: 7.09\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.06635293181165\n",
      "    rl_1: 71.05909721063578\n",
      "  time_since_restore: 4915.086478471756\n",
      "  time_this_iter_s: 23.259683847427368\n",
      "  time_total_s: 4915.086478471756\n",
      "  timestamp: 1550885505\n",
      "  timesteps_since_restore: 2100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2100000\n",
      "  training_iteration: 210\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4915 s, 210 iter, 2100000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-32-08\n",
      "  done: false\n",
      "  episode_len_mean: 109.73\n",
      "  episode_reward_max: 230.6278724982734\n",
      "  episode_reward_mean: 164.79599306947395\n",
      "  episode_reward_min: -168.85576843214983\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 16133\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.026\n",
      "    load_time_ms: 2.408\n",
      "    num_steps_sampled: 2110000\n",
      "    num_steps_trained: 2110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5301624536514282\n",
      "      kl: 0.006712115835398436\n",
      "      policy_loss: -0.0009837490506470203\n",
      "      total_loss: 80.76583862304688\n",
      "      vf_explained_var: 0.9406396746635437\n",
      "      vf_loss: 80.7668228149414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5574578046798706\n",
      "      kl: 0.00582341430708766\n",
      "      policy_loss: -0.002439721254631877\n",
      "      total_loss: 71.97010040283203\n",
      "      vf_explained_var: 0.9436692595481873\n",
      "      vf_loss: 71.9725341796875\n",
      "    sample_time_ms: 19909.787\n",
      "    update_time_ms: 6.987\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.44646059026914\n",
      "    rl_1: 75.34953247920484\n",
      "  time_since_restore: 4938.23028254509\n",
      "  time_this_iter_s: 23.14380407333374\n",
      "  time_total_s: 4938.23028254509\n",
      "  timestamp: 1550885528\n",
      "  timesteps_since_restore: 2110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2110000\n",
      "  training_iteration: 211\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4938 s, 211 iter, 2110000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-32-31\n",
      "  done: false\n",
      "  episode_len_mean: 114.42\n",
      "  episode_reward_max: 230.6642867878833\n",
      "  episode_reward_mean: 153.94949023701668\n",
      "  episode_reward_min: -173.37710154421666\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 16219\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.484\n",
      "    load_time_ms: 2.346\n",
      "    num_steps_sampled: 2120000\n",
      "    num_steps_trained: 2120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.635317862033844\n",
      "      kl: 0.008440705947577953\n",
      "      policy_loss: -0.0031144048552960157\n",
      "      total_loss: 118.33885192871094\n",
      "      vf_explained_var: 0.9204281568527222\n",
      "      vf_loss: 118.34198760986328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5685932040214539\n",
      "      kl: 0.007105047348886728\n",
      "      policy_loss: -0.002974729984998703\n",
      "      total_loss: 98.65997314453125\n",
      "      vf_explained_var: 0.9227351546287537\n",
      "      vf_loss: 98.6629638671875\n",
      "    sample_time_ms: 19860.403\n",
      "    update_time_ms: 6.987\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.6875001477313\n",
      "    rl_1: 69.26199008928535\n",
      "  time_since_restore: 4961.18923664093\n",
      "  time_this_iter_s: 22.958954095840454\n",
      "  time_total_s: 4961.18923664093\n",
      "  timestamp: 1550885551\n",
      "  timesteps_since_restore: 2120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2120000\n",
      "  training_iteration: 212\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4961 s, 212 iter, 2120000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-32-55\n",
      "  done: false\n",
      "  episode_len_mean: 115.27\n",
      "  episode_reward_max: 222.05110081373033\n",
      "  episode_reward_mean: 168.77556358271696\n",
      "  episode_reward_min: -173.37710154421666\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 16308\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.119\n",
      "    load_time_ms: 2.283\n",
      "    num_steps_sampled: 2130000\n",
      "    num_steps_trained: 2130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5256335139274597\n",
      "      kl: 0.0058981492184102535\n",
      "      policy_loss: -0.0024774386547505856\n",
      "      total_loss: 37.77309799194336\n",
      "      vf_explained_var: 0.9629231095314026\n",
      "      vf_loss: 37.77557373046875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5124185681343079\n",
      "      kl: 0.010857690125703812\n",
      "      policy_loss: -0.0029409800190478563\n",
      "      total_loss: 33.19593048095703\n",
      "      vf_explained_var: 0.9633148312568665\n",
      "      vf_loss: 33.198875427246094\n",
      "    sample_time_ms: 19889.409\n",
      "    update_time_ms: 6.992\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.71854954678807\n",
      "    rl_1: 76.05701403592893\n",
      "  time_since_restore: 4984.568102121353\n",
      "  time_this_iter_s: 23.378865480422974\n",
      "  time_total_s: 4984.568102121353\n",
      "  timestamp: 1550885575\n",
      "  timesteps_since_restore: 2130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2130000\n",
      "  training_iteration: 213\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 4984 s, 213 iter, 2130000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-33-18\n",
      "  done: false\n",
      "  episode_len_mean: 119.1\n",
      "  episode_reward_max: 236.38078526972276\n",
      "  episode_reward_mean: 168.80287248964393\n",
      "  episode_reward_min: -135.05366839356782\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 16386\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.127\n",
      "    load_time_ms: 2.276\n",
      "    num_steps_sampled: 2140000\n",
      "    num_steps_trained: 2140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.639742374420166\n",
      "      kl: 0.009281774051487446\n",
      "      policy_loss: -0.0024666727986186743\n",
      "      total_loss: 63.91082763671875\n",
      "      vf_explained_var: 0.9513106942176819\n",
      "      vf_loss: 63.91328811645508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.590309202671051\n",
      "      kl: 0.007233195006847382\n",
      "      policy_loss: -0.0030419877730309963\n",
      "      total_loss: 55.50162124633789\n",
      "      vf_explained_var: 0.9517115950584412\n",
      "      vf_loss: 55.504676818847656\n",
      "    sample_time_ms: 19916.853\n",
      "    update_time_ms: 7.123\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.31449279967438\n",
      "    rl_1: 75.48837968996956\n",
      "  time_since_restore: 5008.101857662201\n",
      "  time_this_iter_s: 23.53375554084778\n",
      "  time_total_s: 5008.101857662201\n",
      "  timestamp: 1550885598\n",
      "  timesteps_since_restore: 2140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2140000\n",
      "  training_iteration: 214\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5008 s, 214 iter, 2140000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-33-42\n",
      "  done: false\n",
      "  episode_len_mean: 121.34\n",
      "  episode_reward_max: 236.38078526972276\n",
      "  episode_reward_mean: 154.73098345226916\n",
      "  episode_reward_min: -174.70288157032581\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 16467\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.965\n",
      "    load_time_ms: 2.343\n",
      "    num_steps_sampled: 2150000\n",
      "    num_steps_trained: 2150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6257174015045166\n",
      "      kl: 0.007375848013907671\n",
      "      policy_loss: -0.0023161827120929956\n",
      "      total_loss: 63.818058013916016\n",
      "      vf_explained_var: 0.9563873410224915\n",
      "      vf_loss: 63.820369720458984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5622095465660095\n",
      "      kl: 0.004510251339524984\n",
      "      policy_loss: -0.0013089108979329467\n",
      "      total_loss: 49.708290100097656\n",
      "      vf_explained_var: 0.9627966284751892\n",
      "      vf_loss: 49.70960235595703\n",
      "    sample_time_ms: 19953.638\n",
      "    update_time_ms: 7.007\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.67092936084478\n",
      "    rl_1: 69.06005409142436\n",
      "  time_since_restore: 5031.4695456027985\n",
      "  time_this_iter_s: 23.367687940597534\n",
      "  time_total_s: 5031.4695456027985\n",
      "  timestamp: 1550885622\n",
      "  timesteps_since_restore: 2150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2150000\n",
      "  training_iteration: 215\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5031 s, 215 iter, 2150000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-34-05\n",
      "  done: false\n",
      "  episode_len_mean: 129.55\n",
      "  episode_reward_max: 233.64567778556747\n",
      "  episode_reward_mean: 152.38557423864805\n",
      "  episode_reward_min: -157.76184999146093\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 16544\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.094\n",
      "    load_time_ms: 2.44\n",
      "    num_steps_sampled: 2160000\n",
      "    num_steps_trained: 2160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6511059999465942\n",
      "      kl: 0.008310607634484768\n",
      "      policy_loss: -0.002113897819072008\n",
      "      total_loss: 68.51776123046875\n",
      "      vf_explained_var: 0.956906259059906\n",
      "      vf_loss: 68.51986694335938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5615597367286682\n",
      "      kl: 0.005707097705453634\n",
      "      policy_loss: -0.0027769298758357763\n",
      "      total_loss: 60.68324279785156\n",
      "      vf_explained_var: 0.9548120498657227\n",
      "      vf_loss: 60.686004638671875\n",
      "    sample_time_ms: 19963.775\n",
      "    update_time_ms: 6.692\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.52453139379539\n",
      "    rl_1: 65.86104284485263\n",
      "  time_since_restore: 5054.464693307877\n",
      "  time_this_iter_s: 22.995147705078125\n",
      "  time_total_s: 5054.464693307877\n",
      "  timestamp: 1550885645\n",
      "  timesteps_since_restore: 2160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2160000\n",
      "  training_iteration: 216\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5054 s, 216 iter, 2160000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-34-27\n",
      "  done: false\n",
      "  episode_len_mean: 119.46\n",
      "  episode_reward_max: 232.7968178461688\n",
      "  episode_reward_mean: 147.48795955329297\n",
      "  episode_reward_min: -159.3024974485548\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 16626\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.066\n",
      "    load_time_ms: 2.466\n",
      "    num_steps_sampled: 2170000\n",
      "    num_steps_trained: 2170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6441348791122437\n",
      "      kl: 0.011862531304359436\n",
      "      policy_loss: -0.0024514514952898026\n",
      "      total_loss: 109.47880554199219\n",
      "      vf_explained_var: 0.9329800009727478\n",
      "      vf_loss: 109.48126983642578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5472241640090942\n",
      "      kl: 0.006900428794324398\n",
      "      policy_loss: -0.0017207521013915539\n",
      "      total_loss: 89.37310028076172\n",
      "      vf_explained_var: 0.9398891925811768\n",
      "      vf_loss: 89.37481689453125\n",
      "    sample_time_ms: 19994.786\n",
      "    update_time_ms: 6.719\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.79359753399092\n",
      "    rl_1: 65.69436201930205\n",
      "  time_since_restore: 5077.291679143906\n",
      "  time_this_iter_s: 22.826985836029053\n",
      "  time_total_s: 5077.291679143906\n",
      "  timestamp: 1550885667\n",
      "  timesteps_since_restore: 2170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2170000\n",
      "  training_iteration: 217\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5077 s, 217 iter, 2170000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-34-50\n",
      "  done: false\n",
      "  episode_len_mean: 117.14\n",
      "  episode_reward_max: 232.00866628766414\n",
      "  episode_reward_mean: 153.0622929833726\n",
      "  episode_reward_min: -175.01948453376113\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 16716\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.591\n",
      "    load_time_ms: 2.374\n",
      "    num_steps_sampled: 2180000\n",
      "    num_steps_trained: 2180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5049347281455994\n",
      "      kl: 0.011194727383553982\n",
      "      policy_loss: -0.0004517860652413219\n",
      "      total_loss: 88.64962005615234\n",
      "      vf_explained_var: 0.9365612864494324\n",
      "      vf_loss: 88.65006256103516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49440130591392517\n",
      "      kl: 0.005905720870941877\n",
      "      policy_loss: -0.0041656517423689365\n",
      "      total_loss: 83.72037506103516\n",
      "      vf_explained_var: 0.9315370321273804\n",
      "      vf_loss: 83.72454071044922\n",
      "    sample_time_ms: 19991.387\n",
      "    update_time_ms: 7.112\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.87191658604479\n",
      "    rl_1: 68.19037639732781\n",
      "  time_since_restore: 5100.273567676544\n",
      "  time_this_iter_s: 22.98188853263855\n",
      "  time_total_s: 5100.273567676544\n",
      "  timestamp: 1550885690\n",
      "  timesteps_since_restore: 2180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2180000\n",
      "  training_iteration: 218\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5100 s, 218 iter, 2180000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-35-14\n",
      "  done: false\n",
      "  episode_len_mean: 111.41\n",
      "  episode_reward_max: 229.70712951811004\n",
      "  episode_reward_mean: 167.2034960643489\n",
      "  episode_reward_min: -165.32250637959558\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 16806\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.817\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 2190000\n",
      "    num_steps_trained: 2190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4915103018283844\n",
      "      kl: 0.00717988470569253\n",
      "      policy_loss: -0.0017020419472828507\n",
      "      total_loss: 44.06842041015625\n",
      "      vf_explained_var: 0.9672863483428955\n",
      "      vf_loss: 44.07011413574219\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5499166250228882\n",
      "      kl: 0.005314631387591362\n",
      "      policy_loss: -0.0023772227577865124\n",
      "      total_loss: 38.46072769165039\n",
      "      vf_explained_var: 0.9658041596412659\n",
      "      vf_loss: 38.463111877441406\n",
      "    sample_time_ms: 20053.796\n",
      "    update_time_ms: 7.633\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.5175372755559\n",
      "    rl_1: 74.68595878879299\n",
      "  time_since_restore: 5123.452353239059\n",
      "  time_this_iter_s: 23.17878556251526\n",
      "  time_total_s: 5123.452353239059\n",
      "  timestamp: 1550885714\n",
      "  timesteps_since_restore: 2190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2190000\n",
      "  training_iteration: 219\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5123 s, 219 iter, 2190000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-35-37\n",
      "  done: false\n",
      "  episode_len_mean: 118.54\n",
      "  episode_reward_max: 229.71576709623355\n",
      "  episode_reward_mean: 148.78569893088127\n",
      "  episode_reward_min: -169.4957335604069\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 16888\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.016\n",
      "    load_time_ms: 2.39\n",
      "    num_steps_sampled: 2200000\n",
      "    num_steps_trained: 2200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4903582036495209\n",
      "      kl: 0.006501093972474337\n",
      "      policy_loss: -0.0019121429650112987\n",
      "      total_loss: 87.69567108154297\n",
      "      vf_explained_var: 0.9401783347129822\n",
      "      vf_loss: 87.69758605957031\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.46283966302871704\n",
      "      kl: 0.00767933577299118\n",
      "      policy_loss: -0.0011517229722812772\n",
      "      total_loss: 63.65343475341797\n",
      "      vf_explained_var: 0.9494961500167847\n",
      "      vf_loss: 63.65458297729492\n",
      "    sample_time_ms: 20018.482\n",
      "    update_time_ms: 7.557\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.16245057942861\n",
      "    rl_1: 64.62324835145269\n",
      "  time_since_restore: 5146.434175491333\n",
      "  time_this_iter_s: 22.98182225227356\n",
      "  time_total_s: 5146.434175491333\n",
      "  timestamp: 1550885737\n",
      "  timesteps_since_restore: 2200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2200000\n",
      "  training_iteration: 220\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5146 s, 220 iter, 2200000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-35-59\n",
      "  done: false\n",
      "  episode_len_mean: 132.37\n",
      "  episode_reward_max: 230.97238395551113\n",
      "  episode_reward_mean: 155.53893997921193\n",
      "  episode_reward_min: -167.32121660972848\n",
      "  episodes_this_iter: 76\n",
      "  episodes_total: 16964\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.699\n",
      "    load_time_ms: 2.382\n",
      "    num_steps_sampled: 2210000\n",
      "    num_steps_trained: 2210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.667532205581665\n",
      "      kl: 0.0069556343369185925\n",
      "      policy_loss: -0.0014614349929615855\n",
      "      total_loss: 65.8859634399414\n",
      "      vf_explained_var: 0.9583227634429932\n",
      "      vf_loss: 65.8874282836914\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5988779067993164\n",
      "      kl: 0.007263839244842529\n",
      "      policy_loss: -0.0019769298378378153\n",
      "      total_loss: 58.84581756591797\n",
      "      vf_explained_var: 0.9560663104057312\n",
      "      vf_loss: 58.847801208496094\n",
      "    sample_time_ms: 19953.301\n",
      "    update_time_ms: 7.744\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.50692990540756\n",
      "    rl_1: 67.03201007380433\n",
      "  time_since_restore: 5168.735332965851\n",
      "  time_this_iter_s: 22.301157474517822\n",
      "  time_total_s: 5168.735332965851\n",
      "  timestamp: 1550885759\n",
      "  timesteps_since_restore: 2210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2210000\n",
      "  training_iteration: 221\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5168 s, 221 iter, 2210000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-36-22\n",
      "  done: false\n",
      "  episode_len_mean: 119.12\n",
      "  episode_reward_max: 225.30284613925974\n",
      "  episode_reward_mean: 167.1807088910014\n",
      "  episode_reward_min: -167.32121660972848\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 17050\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.593\n",
      "    load_time_ms: 2.357\n",
      "    num_steps_sampled: 2220000\n",
      "    num_steps_trained: 2220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5245552659034729\n",
      "      kl: 0.005665665492415428\n",
      "      policy_loss: -0.0020697142463177443\n",
      "      total_loss: 34.88679122924805\n",
      "      vf_explained_var: 0.9724995493888855\n",
      "      vf_loss: 34.888858795166016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.47708946466445923\n",
      "      kl: 0.00553862052038312\n",
      "      policy_loss: -0.0006077590514905751\n",
      "      total_loss: 29.653047561645508\n",
      "      vf_explained_var: 0.9722523093223572\n",
      "      vf_loss: 29.653656005859375\n",
      "    sample_time_ms: 19997.013\n",
      "    update_time_ms: 7.719\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.4749806736511\n",
      "    rl_1: 74.70572821735028\n",
      "  time_since_restore: 5192.138538360596\n",
      "  time_this_iter_s: 23.403205394744873\n",
      "  time_total_s: 5192.138538360596\n",
      "  timestamp: 1550885782\n",
      "  timesteps_since_restore: 2220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2220000\n",
      "  training_iteration: 222\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5192 s, 222 iter, 2220000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-36-45\n",
      "  done: false\n",
      "  episode_len_mean: 118.68\n",
      "  episode_reward_max: 232.51967388603904\n",
      "  episode_reward_mean: 158.7258004687667\n",
      "  episode_reward_min: -154.36237685912454\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 17136\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.448\n",
      "    load_time_ms: 2.435\n",
      "    num_steps_sampled: 2230000\n",
      "    num_steps_trained: 2230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5415462851524353\n",
      "      kl: 0.008693373762071133\n",
      "      policy_loss: -0.0032089424785226583\n",
      "      total_loss: 75.93727111816406\n",
      "      vf_explained_var: 0.948836624622345\n",
      "      vf_loss: 75.94048309326172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5012558698654175\n",
      "      kl: 0.006727820727974176\n",
      "      policy_loss: -0.001570897176861763\n",
      "      total_loss: 67.88780975341797\n",
      "      vf_explained_var: 0.9465449452400208\n",
      "      vf_loss: 67.88939666748047\n",
      "    sample_time_ms: 19953.948\n",
      "    update_time_ms: 7.94\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.74189079258286\n",
      "    rl_1: 69.98390967618384\n",
      "  time_since_restore: 5215.038148641586\n",
      "  time_this_iter_s: 22.8996102809906\n",
      "  time_total_s: 5215.038148641586\n",
      "  timestamp: 1550885805\n",
      "  timesteps_since_restore: 2230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2230000\n",
      "  training_iteration: 223\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5215 s, 223 iter, 2230000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-37-09\n",
      "  done: false\n",
      "  episode_len_mean: 113.94\n",
      "  episode_reward_max: 235.76511773640814\n",
      "  episode_reward_mean: 161.08059852120084\n",
      "  episode_reward_min: -159.09016131029793\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 17226\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.984\n",
      "    load_time_ms: 2.477\n",
      "    num_steps_sampled: 2240000\n",
      "    num_steps_trained: 2240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.43684861063957214\n",
      "      kl: 0.0038051088340580463\n",
      "      policy_loss: 0.0011353808222338557\n",
      "      total_loss: 99.49179077148438\n",
      "      vf_explained_var: 0.934951663017273\n",
      "      vf_loss: 99.49066925048828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4390835464000702\n",
      "      kl: 0.01027825940400362\n",
      "      policy_loss: -0.0029763495549559593\n",
      "      total_loss: 87.54618072509766\n",
      "      vf_explained_var: 0.9361436367034912\n",
      "      vf_loss: 87.54915618896484\n",
      "    sample_time_ms: 19898.024\n",
      "    update_time_ms: 7.736\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.91210305105709\n",
      "    rl_1: 72.16849547014374\n",
      "  time_since_restore: 5238.1383736133575\n",
      "  time_this_iter_s: 23.10022497177124\n",
      "  time_total_s: 5238.1383736133575\n",
      "  timestamp: 1550885829\n",
      "  timesteps_since_restore: 2240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2240000\n",
      "  training_iteration: 224\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5238 s, 224 iter, 2240000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-37-32\n",
      "  done: false\n",
      "  episode_len_mean: 111.77\n",
      "  episode_reward_max: 229.43323592330242\n",
      "  episode_reward_mean: 173.42845174600458\n",
      "  episode_reward_min: -140.64790303611676\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 17318\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.956\n",
      "    load_time_ms: 2.55\n",
      "    num_steps_sampled: 2250000\n",
      "    num_steps_trained: 2250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4424573481082916\n",
      "      kl: 0.005191334057599306\n",
      "      policy_loss: 0.0003187592956237495\n",
      "      total_loss: 38.8154182434082\n",
      "      vf_explained_var: 0.9644607305526733\n",
      "      vf_loss: 38.81509780883789\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4280870258808136\n",
      "      kl: 0.008527804166078568\n",
      "      policy_loss: 6.080580988054862e-06\n",
      "      total_loss: 33.726802825927734\n",
      "      vf_explained_var: 0.9596644639968872\n",
      "      vf_loss: 33.72679138183594\n",
      "    sample_time_ms: 19907.762\n",
      "    update_time_ms: 7.819\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.67532857385785\n",
      "    rl_1: 76.75312317214676\n",
      "  time_since_restore: 5261.574964284897\n",
      "  time_this_iter_s: 23.436590671539307\n",
      "  time_total_s: 5261.574964284897\n",
      "  timestamp: 1550885852\n",
      "  timesteps_since_restore: 2250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2250000\n",
      "  training_iteration: 225\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5261 s, 225 iter, 2250000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 113.98\n",
      "  episode_reward_max: 228.27230441508024\n",
      "  episode_reward_mean: 158.5330164803046\n",
      "  episode_reward_min: -162.18184045158625\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 17404\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.299\n",
      "    load_time_ms: 2.458\n",
      "    num_steps_sampled: 2260000\n",
      "    num_steps_trained: 2260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5025038719177246\n",
      "      kl: 0.008391140028834343\n",
      "      policy_loss: -0.0031933679711073637\n",
      "      total_loss: 77.49269104003906\n",
      "      vf_explained_var: 0.9422799944877625\n",
      "      vf_loss: 77.49589538574219\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49397987127304077\n",
      "      kl: 0.008529510349035263\n",
      "      policy_loss: -0.0020847180858254433\n",
      "      total_loss: 57.56370162963867\n",
      "      vf_explained_var: 0.9504154920578003\n",
      "      vf_loss: 57.565792083740234\n",
      "    sample_time_ms: 19940.278\n",
      "    update_time_ms: 7.956\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.60353643166356\n",
      "    rl_1: 69.92948004864107\n",
      "  time_since_restore: 5284.868057489395\n",
      "  time_this_iter_s: 23.29309320449829\n",
      "  time_total_s: 5284.868057489395\n",
      "  timestamp: 1550885875\n",
      "  timesteps_since_restore: 2260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2260000\n",
      "  training_iteration: 226\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5284 s, 226 iter, 2260000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-38-19\n",
      "  done: false\n",
      "  episode_len_mean: 117.06\n",
      "  episode_reward_max: 230.8056189389936\n",
      "  episode_reward_mean: 157.21968417626323\n",
      "  episode_reward_min: -158.46986399003316\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 17491\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.99\n",
      "    load_time_ms: 2.443\n",
      "    num_steps_sampled: 2270000\n",
      "    num_steps_trained: 2270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4622359573841095\n",
      "      kl: 0.007597117684781551\n",
      "      policy_loss: 0.0006108215311542153\n",
      "      total_loss: 83.35997009277344\n",
      "      vf_explained_var: 0.9396690726280212\n",
      "      vf_loss: 83.35935974121094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4690110683441162\n",
      "      kl: 0.005555172450840473\n",
      "      policy_loss: -0.0012941876193508506\n",
      "      total_loss: 64.48534393310547\n",
      "      vf_explained_var: 0.9487893581390381\n",
      "      vf_loss: 64.48664093017578\n",
      "    sample_time_ms: 19995.092\n",
      "    update_time_ms: 8.207\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.21970559281617\n",
      "    rl_1: 70.99997858344703\n",
      "  time_since_restore: 5308.263475894928\n",
      "  time_this_iter_s: 23.395418405532837\n",
      "  time_total_s: 5308.263475894928\n",
      "  timestamp: 1550885899\n",
      "  timesteps_since_restore: 2270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2270000\n",
      "  training_iteration: 227\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5308 s, 227 iter, 2270000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-38-42\n",
      "  done: false\n",
      "  episode_len_mean: 114.91\n",
      "  episode_reward_max: 230.67124736052259\n",
      "  episode_reward_mean: 164.10658875209592\n",
      "  episode_reward_min: -167.74201877343967\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 17577\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.717\n",
      "    load_time_ms: 2.482\n",
      "    num_steps_sampled: 2280000\n",
      "    num_steps_trained: 2280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4819803833961487\n",
      "      kl: 0.0073467278853058815\n",
      "      policy_loss: -0.00047287403140217066\n",
      "      total_loss: 77.08936309814453\n",
      "      vf_explained_var: 0.9429853558540344\n",
      "      vf_loss: 77.08982849121094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4381667971611023\n",
      "      kl: 0.010075843892991543\n",
      "      policy_loss: -0.003367644501850009\n",
      "      total_loss: 70.9620361328125\n",
      "      vf_explained_var: 0.9397144913673401\n",
      "      vf_loss: 70.96540832519531\n",
      "    sample_time_ms: 20014.406\n",
      "    update_time_ms: 7.976\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.6512522380842\n",
      "    rl_1: 72.45533651401172\n",
      "  time_since_restore: 5331.452092409134\n",
      "  time_this_iter_s: 23.188616514205933\n",
      "  time_total_s: 5331.452092409134\n",
      "  timestamp: 1550885922\n",
      "  timesteps_since_restore: 2280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2280000\n",
      "  training_iteration: 228\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5331 s, 228 iter, 2280000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-39-05\n",
      "  done: false\n",
      "  episode_len_mean: 127.62\n",
      "  episode_reward_max: 230.67124736052259\n",
      "  episode_reward_mean: 137.51965232298124\n",
      "  episode_reward_min: -173.4790407947432\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 17654\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.491\n",
      "    load_time_ms: 2.486\n",
      "    num_steps_sampled: 2290000\n",
      "    num_steps_trained: 2290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.627566397190094\n",
      "      kl: 0.0052596647292375565\n",
      "      policy_loss: -0.0020597069524228573\n",
      "      total_loss: 83.00486755371094\n",
      "      vf_explained_var: 0.9471081495285034\n",
      "      vf_loss: 83.00691986083984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.47386398911476135\n",
      "      kl: 0.006122733931988478\n",
      "      policy_loss: -0.0010227402672171593\n",
      "      total_loss: 65.11691284179688\n",
      "      vf_explained_var: 0.950776994228363\n",
      "      vf_loss: 65.1179428100586\n",
      "    sample_time_ms: 20001.416\n",
      "    update_time_ms: 7.633\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.21638375397146\n",
      "    rl_1: 58.30326856900979\n",
      "  time_since_restore: 5354.486376285553\n",
      "  time_this_iter_s: 23.034283876419067\n",
      "  time_total_s: 5354.486376285553\n",
      "  timestamp: 1550885945\n",
      "  timesteps_since_restore: 2290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2290000\n",
      "  training_iteration: 229\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5354 s, 229 iter, 2290000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-39-28\n",
      "  done: false\n",
      "  episode_len_mean: 113.04\n",
      "  episode_reward_max: 233.08694316047988\n",
      "  episode_reward_mean: 166.51454674835267\n",
      "  episode_reward_min: -171.8235336922509\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 17739\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.769\n",
      "    load_time_ms: 2.48\n",
      "    num_steps_sampled: 2300000\n",
      "    num_steps_trained: 2300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5202969312667847\n",
      "      kl: 0.008920727297663689\n",
      "      policy_loss: -0.001041543553583324\n",
      "      total_loss: 55.745391845703125\n",
      "      vf_explained_var: 0.9538540244102478\n",
      "      vf_loss: 55.74642562866211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.46775925159454346\n",
      "      kl: 0.005648820661008358\n",
      "      policy_loss: -0.001824672450311482\n",
      "      total_loss: 46.05552673339844\n",
      "      vf_explained_var: 0.9558706283569336\n",
      "      vf_loss: 46.05734634399414\n",
      "    sample_time_ms: 20001.452\n",
      "    update_time_ms: 7.572\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.17056989618524\n",
      "    rl_1: 74.3439768521674\n",
      "  time_since_restore: 5377.389953136444\n",
      "  time_this_iter_s: 22.903576850891113\n",
      "  time_total_s: 5377.389953136444\n",
      "  timestamp: 1550885968\n",
      "  timesteps_since_restore: 2300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2300000\n",
      "  training_iteration: 230\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5377 s, 230 iter, 2300000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-39-51\n",
      "  done: false\n",
      "  episode_len_mean: 110.99\n",
      "  episode_reward_max: 227.4883110310606\n",
      "  episode_reward_mean: 157.04328469013612\n",
      "  episode_reward_min: -167.46166476499008\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 17832\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.7\n",
      "    load_time_ms: 2.526\n",
      "    num_steps_sampled: 2310000\n",
      "    num_steps_trained: 2310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4059337079524994\n",
      "      kl: 0.012653601355850697\n",
      "      policy_loss: -0.0033014488872140646\n",
      "      total_loss: 98.02147674560547\n",
      "      vf_explained_var: 0.9315493702888489\n",
      "      vf_loss: 98.0247802734375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3375190794467926\n",
      "      kl: 0.013523523695766926\n",
      "      policy_loss: -0.0032927249558269978\n",
      "      total_loss: 91.09822845458984\n",
      "      vf_explained_var: 0.9239320158958435\n",
      "      vf_loss: 91.10150909423828\n",
      "    sample_time_ms: 20104.954\n",
      "    update_time_ms: 7.511\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.23336503664613\n",
      "    rl_1: 69.80991965348998\n",
      "  time_since_restore: 5400.725108623505\n",
      "  time_this_iter_s: 23.335155487060547\n",
      "  time_total_s: 5400.725108623505\n",
      "  timestamp: 1550885991\n",
      "  timesteps_since_restore: 2310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2310000\n",
      "  training_iteration: 231\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5400 s, 231 iter, 2310000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-40-15\n",
      "  done: false\n",
      "  episode_len_mean: 128.4\n",
      "  episode_reward_max: 225.28747339958713\n",
      "  episode_reward_mean: 159.71037364149402\n",
      "  episode_reward_min: -167.32746191696955\n",
      "  episodes_this_iter: 75\n",
      "  episodes_total: 17907\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.377\n",
      "    load_time_ms: 2.561\n",
      "    num_steps_sampled: 2320000\n",
      "    num_steps_trained: 2320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.6328440308570862\n",
      "      kl: 0.00822414830327034\n",
      "      policy_loss: -0.0011228026123717427\n",
      "      total_loss: 41.85049819946289\n",
      "      vf_explained_var: 0.9660908579826355\n",
      "      vf_loss: 41.85162353515625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49106255173683167\n",
      "      kl: 0.007779018022119999\n",
      "      policy_loss: -0.0018452545627951622\n",
      "      total_loss: 34.113040924072266\n",
      "      vf_explained_var: 0.9682801365852356\n",
      "      vf_loss: 34.11488723754883\n",
      "    sample_time_ms: 20095.932\n",
      "    update_time_ms: 7.632\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.34398540923581\n",
      "    rl_1: 70.3663882322582\n",
      "  time_since_restore: 5424.133802175522\n",
      "  time_this_iter_s: 23.408693552017212\n",
      "  time_total_s: 5424.133802175522\n",
      "  timestamp: 1550886015\n",
      "  timesteps_since_restore: 2320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2320000\n",
      "  training_iteration: 232\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5424 s, 232 iter, 2320000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-40-38\n",
      "  done: false\n",
      "  episode_len_mean: 114.19\n",
      "  episode_reward_max: 233.1748206504398\n",
      "  episode_reward_mean: 159.19066659073277\n",
      "  episode_reward_min: -157.8839349576636\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 17994\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3098.328\n",
      "    load_time_ms: 2.572\n",
      "    num_steps_sampled: 2330000\n",
      "    num_steps_trained: 2330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4783974289894104\n",
      "      kl: 0.009197443723678589\n",
      "      policy_loss: -0.0016341963782906532\n",
      "      total_loss: 93.48831939697266\n",
      "      vf_explained_var: 0.9372485280036926\n",
      "      vf_loss: 93.48995971679688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.44735580682754517\n",
      "      kl: 0.006008352153003216\n",
      "      policy_loss: -0.0007169375894591212\n",
      "      total_loss: 79.27424621582031\n",
      "      vf_explained_var: 0.943261444568634\n",
      "      vf_loss: 79.27494812011719\n",
      "    sample_time_ms: 20110.94\n",
      "    update_time_ms: 7.501\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.66717769451309\n",
      "    rl_1: 72.52348889621972\n",
      "  time_since_restore: 5447.411083459854\n",
      "  time_this_iter_s: 23.277281284332275\n",
      "  time_total_s: 5447.411083459854\n",
      "  timestamp: 1550886038\n",
      "  timesteps_since_restore: 2330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2330000\n",
      "  training_iteration: 233\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5447 s, 233 iter, 2330000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-41-01\n",
      "  done: false\n",
      "  episode_len_mean: 117.1\n",
      "  episode_reward_max: 233.1748206504398\n",
      "  episode_reward_mean: 152.49301762072827\n",
      "  episode_reward_min: -171.03064120179462\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 18076\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.441\n",
      "    load_time_ms: 2.511\n",
      "    num_steps_sampled: 2340000\n",
      "    num_steps_trained: 2340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.521215558052063\n",
      "      kl: 0.006595886778086424\n",
      "      policy_loss: -0.0011349961860105395\n",
      "      total_loss: 81.99937438964844\n",
      "      vf_explained_var: 0.9527331590652466\n",
      "      vf_loss: 82.00049591064453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4883885085582733\n",
      "      kl: 0.007398094050586224\n",
      "      policy_loss: -0.002930724760517478\n",
      "      total_loss: 76.19184875488281\n",
      "      vf_explained_var: 0.9521273374557495\n",
      "      vf_loss: 76.19478607177734\n",
      "    sample_time_ms: 20065.537\n",
      "    update_time_ms: 7.527\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.44453972109258\n",
      "    rl_1: 68.0484778996357\n",
      "  time_since_restore: 5469.938438415527\n",
      "  time_this_iter_s: 22.527354955673218\n",
      "  time_total_s: 5469.938438415527\n",
      "  timestamp: 1550886061\n",
      "  timesteps_since_restore: 2340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2340000\n",
      "  training_iteration: 234\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5469 s, 234 iter, 2340000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 109.48\n",
      "  episode_reward_max: 226.22500665649312\n",
      "  episode_reward_mean: 152.83938941774983\n",
      "  episode_reward_min: -157.19888296272603\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 18168\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.76\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 2350000\n",
      "    num_steps_trained: 2350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3590467572212219\n",
      "      kl: 0.008252626284956932\n",
      "      policy_loss: -0.0014883601106703281\n",
      "      total_loss: 70.8660888671875\n",
      "      vf_explained_var: 0.950937807559967\n",
      "      vf_loss: 70.8675765991211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3191753029823303\n",
      "      kl: 0.008979415521025658\n",
      "      policy_loss: -0.0011183733586221933\n",
      "      total_loss: 65.77780151367188\n",
      "      vf_explained_var: 0.9480124115943909\n",
      "      vf_loss: 65.7789077758789\n",
      "    sample_time_ms: 20018.438\n",
      "    update_time_ms: 7.525\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.96119579128795\n",
      "    rl_1: 68.87819362646188\n",
      "  time_since_restore: 5492.906927347183\n",
      "  time_this_iter_s: 22.968488931655884\n",
      "  time_total_s: 5492.906927347183\n",
      "  timestamp: 1550886084\n",
      "  timesteps_since_restore: 2350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2350000\n",
      "  training_iteration: 235\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5492 s, 235 iter, 2350000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-41-47\n",
      "  done: false\n",
      "  episode_len_mean: 107.2\n",
      "  episode_reward_max: 230.68954199018987\n",
      "  episode_reward_mean: 156.63276417915188\n",
      "  episode_reward_min: -161.25007488092206\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 18259\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.824\n",
      "    load_time_ms: 2.523\n",
      "    num_steps_sampled: 2360000\n",
      "    num_steps_trained: 2360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.43224355578422546\n",
      "      kl: 0.009621704928576946\n",
      "      policy_loss: -0.0017322244821116328\n",
      "      total_loss: 91.84321594238281\n",
      "      vf_explained_var: 0.9387507438659668\n",
      "      vf_loss: 91.84496307373047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.385039359331131\n",
      "      kl: 0.008443715050816536\n",
      "      policy_loss: -0.002761698793619871\n",
      "      total_loss: 82.83411407470703\n",
      "      vf_explained_var: 0.9355557560920715\n",
      "      vf_loss: 82.83687591552734\n",
      "    sample_time_ms: 20038.326\n",
      "    update_time_ms: 7.787\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.96818790674452\n",
      "    rl_1: 69.66457627240737\n",
      "  time_since_restore: 5516.415230512619\n",
      "  time_this_iter_s: 23.50830316543579\n",
      "  time_total_s: 5516.415230512619\n",
      "  timestamp: 1550886107\n",
      "  timesteps_since_restore: 2360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2360000\n",
      "  training_iteration: 236\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5516 s, 236 iter, 2360000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-42-10\n",
      "  done: false\n",
      "  episode_len_mean: 114.2\n",
      "  episode_reward_max: 225.30186010520995\n",
      "  episode_reward_mean: 152.51129180971498\n",
      "  episode_reward_min: -147.97168675500353\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 18347\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.6\n",
      "    load_time_ms: 2.663\n",
      "    num_steps_sampled: 2370000\n",
      "    num_steps_trained: 2370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.45859429240226746\n",
      "      kl: 0.00952715240418911\n",
      "      policy_loss: -0.0017111446941271424\n",
      "      total_loss: 61.518310546875\n",
      "      vf_explained_var: 0.9597267508506775\n",
      "      vf_loss: 61.52002716064453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4135482907295227\n",
      "      kl: 0.012951500713825226\n",
      "      policy_loss: -0.005824021063745022\n",
      "      total_loss: 53.75334930419922\n",
      "      vf_explained_var: 0.9567294120788574\n",
      "      vf_loss: 53.759178161621094\n",
      "    sample_time_ms: 19997.954\n",
      "    update_time_ms: 7.404\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.45042538933299\n",
      "    rl_1: 67.06086642038196\n",
      "  time_since_restore: 5539.37237739563\n",
      "  time_this_iter_s: 22.957146883010864\n",
      "  time_total_s: 5539.37237739563\n",
      "  timestamp: 1550886130\n",
      "  timesteps_since_restore: 2370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2370000\n",
      "  training_iteration: 237\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5539 s, 237 iter, 2370000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-42-34\n",
      "  done: false\n",
      "  episode_len_mean: 105.16\n",
      "  episode_reward_max: 229.83848821378803\n",
      "  episode_reward_mean: 163.64427444115233\n",
      "  episode_reward_min: -144.66538939436907\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 18442\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.313\n",
      "    load_time_ms: 2.603\n",
      "    num_steps_sampled: 2380000\n",
      "    num_steps_trained: 2380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.31657686829566956\n",
      "      kl: 0.004158693831413984\n",
      "      policy_loss: -0.00045713683357462287\n",
      "      total_loss: 84.02481079101562\n",
      "      vf_explained_var: 0.9372429251670837\n",
      "      vf_loss: 84.02527618408203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2364276796579361\n",
      "      kl: 0.01098395511507988\n",
      "      policy_loss: -0.00024635784211568534\n",
      "      total_loss: 72.88992309570312\n",
      "      vf_explained_var: 0.9327889680862427\n",
      "      vf_loss: 72.89018249511719\n",
      "    sample_time_ms: 19992.882\n",
      "    update_time_ms: 7.314\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.06484075803122\n",
      "    rl_1: 72.57943368312111\n",
      "  time_since_restore: 5562.513454437256\n",
      "  time_this_iter_s: 23.141077041625977\n",
      "  time_total_s: 5562.513454437256\n",
      "  timestamp: 1550886154\n",
      "  timesteps_since_restore: 2380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2380000\n",
      "  training_iteration: 238\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5562 s, 238 iter, 2380000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 106.6\n",
      "  episode_reward_max: 230.12315442150899\n",
      "  episode_reward_mean: 151.3025127955453\n",
      "  episode_reward_min: -178.0834178546044\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 18536\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.324\n",
      "    load_time_ms: 2.589\n",
      "    num_steps_sampled: 2390000\n",
      "    num_steps_trained: 2390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3689537048339844\n",
      "      kl: 0.011781997047364712\n",
      "      policy_loss: -0.0013231458142399788\n",
      "      total_loss: 92.52135467529297\n",
      "      vf_explained_var: 0.9497463703155518\n",
      "      vf_loss: 92.5226821899414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.340242862701416\n",
      "      kl: 0.007506437599658966\n",
      "      policy_loss: -0.0015097642317414284\n",
      "      total_loss: 79.77872467041016\n",
      "      vf_explained_var: 0.9495292901992798\n",
      "      vf_loss: 79.78022766113281\n",
      "    sample_time_ms: 19967.132\n",
      "    update_time_ms: 7.141\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.55801803117154\n",
      "    rl_1: 66.74449476437375\n",
      "  time_since_restore: 5585.277596950531\n",
      "  time_this_iter_s: 22.764142513275146\n",
      "  time_total_s: 5585.277596950531\n",
      "  timestamp: 1550886176\n",
      "  timesteps_since_restore: 2390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2390000\n",
      "  training_iteration: 239\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5585 s, 239 iter, 2390000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 108.22\n",
      "  episode_reward_max: 229.6616162631921\n",
      "  episode_reward_mean: 155.5620385984992\n",
      "  episode_reward_min: -171.3495702804011\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 18629\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.955\n",
      "    load_time_ms: 2.664\n",
      "    num_steps_sampled: 2400000\n",
      "    num_steps_trained: 2400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.36375415325164795\n",
      "      kl: 0.011417745612561703\n",
      "      policy_loss: -0.001511441427282989\n",
      "      total_loss: 91.67070770263672\n",
      "      vf_explained_var: 0.939085066318512\n",
      "      vf_loss: 91.67220306396484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3022032380104065\n",
      "      kl: 0.0067224991507828236\n",
      "      policy_loss: -0.0017899490194395185\n",
      "      total_loss: 81.07331085205078\n",
      "      vf_explained_var: 0.937540590763092\n",
      "      vf_loss: 81.07511138916016\n",
      "    sample_time_ms: 20006.57\n",
      "    update_time_ms: 7.308\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.36782947239217\n",
      "    rl_1: 68.19420912610698\n",
      "  time_since_restore: 5608.582289218903\n",
      "  time_this_iter_s: 23.304692268371582\n",
      "  time_total_s: 5608.582289218903\n",
      "  timestamp: 1550886200\n",
      "  timesteps_since_restore: 2400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2400000\n",
      "  training_iteration: 240\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5608 s, 240 iter, 2400000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-43-43\n",
      "  done: false\n",
      "  episode_len_mean: 121.72\n",
      "  episode_reward_max: 232.34551737098383\n",
      "  episode_reward_mean: 144.47528936522212\n",
      "  episode_reward_min: -172.03473511249902\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 18707\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.772\n",
      "    load_time_ms: 2.607\n",
      "    num_steps_sampled: 2410000\n",
      "    num_steps_trained: 2410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5508217215538025\n",
      "      kl: 0.010366258211433887\n",
      "      policy_loss: -3.140906846965663e-05\n",
      "      total_loss: 66.00947570800781\n",
      "      vf_explained_var: 0.9571864604949951\n",
      "      vf_loss: 66.009521484375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.45409080386161804\n",
      "      kl: 0.00635500205680728\n",
      "      policy_loss: -0.0008187854546122253\n",
      "      total_loss: 58.43207931518555\n",
      "      vf_explained_var: 0.9590133428573608\n",
      "      vf_loss: 58.432899475097656\n",
      "    sample_time_ms: 19999.877\n",
      "    update_time_ms: 7.235\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.92538801148592\n",
      "    rl_1: 63.549901353736225\n",
      "  time_since_restore: 5631.858747720718\n",
      "  time_this_iter_s: 23.276458501815796\n",
      "  time_total_s: 5631.858747720718\n",
      "  timestamp: 1550886223\n",
      "  timesteps_since_restore: 2410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2410000\n",
      "  training_iteration: 241\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5631 s, 241 iter, 2410000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-44-06\n",
      "  done: false\n",
      "  episode_len_mean: 112.98\n",
      "  episode_reward_max: 236.4062786026969\n",
      "  episode_reward_mean: 149.91618846894883\n",
      "  episode_reward_min: -170.76414453496423\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 18799\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.178\n",
      "    load_time_ms: 2.579\n",
      "    num_steps_sampled: 2420000\n",
      "    num_steps_trained: 2420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2866661250591278\n",
      "      kl: 0.006347909104079008\n",
      "      policy_loss: -0.0003048815415240824\n",
      "      total_loss: 82.01799011230469\n",
      "      vf_explained_var: 0.9491710066795349\n",
      "      vf_loss: 82.01830291748047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.25514882802963257\n",
      "      kl: 0.0071550835855305195\n",
      "      policy_loss: -0.0007414412102662027\n",
      "      total_loss: 67.28730010986328\n",
      "      vf_explained_var: 0.9549688696861267\n",
      "      vf_loss: 67.28804016113281\n",
      "    sample_time_ms: 19946.962\n",
      "    update_time_ms: 7.189\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.4243069425972\n",
      "    rl_1: 65.49188152635165\n",
      "  time_since_restore: 5654.644780635834\n",
      "  time_this_iter_s: 22.786032915115356\n",
      "  time_total_s: 5654.644780635834\n",
      "  timestamp: 1550886246\n",
      "  timesteps_since_restore: 2420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2420000\n",
      "  training_iteration: 242\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5654 s, 242 iter, 2420000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-44-29\n",
      "  done: false\n",
      "  episode_len_mean: 121.52\n",
      "  episode_reward_max: 234.76333602351363\n",
      "  episode_reward_mean: 150.27843751510707\n",
      "  episode_reward_min: -170.76414453496423\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 18878\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3057.194\n",
      "    load_time_ms: 2.557\n",
      "    num_steps_sampled: 2430000\n",
      "    num_steps_trained: 2430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4645805358886719\n",
      "      kl: 0.009800172410905361\n",
      "      policy_loss: 0.0003393101505935192\n",
      "      total_loss: 71.85918426513672\n",
      "      vf_explained_var: 0.95985347032547\n",
      "      vf_loss: 71.85884094238281\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3682959973812103\n",
      "      kl: 0.006335440557450056\n",
      "      policy_loss: -0.0020289074163883924\n",
      "      total_loss: 65.79009246826172\n",
      "      vf_explained_var: 0.9564526677131653\n",
      "      vf_loss: 65.7921142578125\n",
      "    sample_time_ms: 19982.94\n",
      "    update_time_ms: 7.103\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.50519717271347\n",
      "    rl_1: 64.7732403423936\n",
      "  time_since_restore: 5678.092638731003\n",
      "  time_this_iter_s: 23.447858095169067\n",
      "  time_total_s: 5678.092638731003\n",
      "  timestamp: 1550886269\n",
      "  timesteps_since_restore: 2430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2430000\n",
      "  training_iteration: 243\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5678 s, 243 iter, 2430000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-44-52\n",
      "  done: false\n",
      "  episode_len_mean: 133.19\n",
      "  episode_reward_max: 233.0924793345326\n",
      "  episode_reward_mean: 151.75985858501025\n",
      "  episode_reward_min: -163.35176435389272\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 18957\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3056.088\n",
      "    load_time_ms: 2.551\n",
      "    num_steps_sampled: 2440000\n",
      "    num_steps_trained: 2440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.49404627084732056\n",
      "      kl: 0.007203054614365101\n",
      "      policy_loss: -0.0024793006014078856\n",
      "      total_loss: 54.471046447753906\n",
      "      vf_explained_var: 0.9624607563018799\n",
      "      vf_loss: 54.473514556884766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.434803307056427\n",
      "      kl: 0.01186523586511612\n",
      "      policy_loss: -0.0006816380191594362\n",
      "      total_loss: 49.408409118652344\n",
      "      vf_explained_var: 0.9623023867607117\n",
      "      vf_loss: 49.409095764160156\n",
      "    sample_time_ms: 19980.825\n",
      "    update_time_ms: 7.151\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.89081910693639\n",
      "    rl_1: 65.86903947807382\n",
      "  time_since_restore: 5700.584383249283\n",
      "  time_this_iter_s: 22.49174451828003\n",
      "  time_total_s: 5700.584383249283\n",
      "  timestamp: 1550886292\n",
      "  timesteps_since_restore: 2440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2440000\n",
      "  training_iteration: 244\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5700 s, 244 iter, 2440000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-45-15\n",
      "  done: false\n",
      "  episode_len_mean: 107.01\n",
      "  episode_reward_max: 234.1337557052357\n",
      "  episode_reward_mean: 162.85347042003133\n",
      "  episode_reward_min: -162.58280965401315\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 19051\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3056.59\n",
      "    load_time_ms: 2.547\n",
      "    num_steps_sampled: 2450000\n",
      "    num_steps_trained: 2450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2749499976634979\n",
      "      kl: 0.011253505013883114\n",
      "      policy_loss: 0.0024569241795688868\n",
      "      total_loss: 62.007362365722656\n",
      "      vf_explained_var: 0.9585291743278503\n",
      "      vf_loss: 62.0048942565918\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.29534265398979187\n",
      "      kl: 0.011195016093552113\n",
      "      policy_loss: 0.00022092220024205744\n",
      "      total_loss: 52.91949462890625\n",
      "      vf_explained_var: 0.9572850465774536\n",
      "      vf_loss: 52.91926956176758\n",
      "    sample_time_ms: 19944.338\n",
      "    update_time_ms: 7.003\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.41118116361822\n",
      "    rl_1: 72.44228925641312\n",
      "  time_since_restore: 5723.1904582977295\n",
      "  time_this_iter_s: 22.606075048446655\n",
      "  time_total_s: 5723.1904582977295\n",
      "  timestamp: 1550886315\n",
      "  timesteps_since_restore: 2450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2450000\n",
      "  training_iteration: 245\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5723 s, 245 iter, 2450000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-45-38\n",
      "  done: false\n",
      "  episode_len_mean: 119.88\n",
      "  episode_reward_max: 219.68189885462516\n",
      "  episode_reward_mean: 145.60742296027146\n",
      "  episode_reward_min: -168.45325020409805\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 19131\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.111\n",
      "    load_time_ms: 2.484\n",
      "    num_steps_sampled: 2460000\n",
      "    num_steps_trained: 2460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5050289630889893\n",
      "      kl: 0.006070068571716547\n",
      "      policy_loss: -0.0027919511776417494\n",
      "      total_loss: 56.35390853881836\n",
      "      vf_explained_var: 0.965958297252655\n",
      "      vf_loss: 56.3567008972168\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.43648236989974976\n",
      "      kl: 0.007577556185424328\n",
      "      policy_loss: -0.002377226483076811\n",
      "      total_loss: 53.10115051269531\n",
      "      vf_explained_var: 0.9650866389274597\n",
      "      vf_loss: 53.1035270690918\n",
      "    sample_time_ms: 19904.737\n",
      "    update_time_ms: 6.621\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.43441026171128\n",
      "    rl_1: 63.173012698560235\n",
      "  time_since_restore: 5746.470685958862\n",
      "  time_this_iter_s: 23.280227661132812\n",
      "  time_total_s: 5746.470685958862\n",
      "  timestamp: 1550886338\n",
      "  timesteps_since_restore: 2460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2460000\n",
      "  training_iteration: 246\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5746 s, 246 iter, 2460000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-46-01\n",
      "  done: false\n",
      "  episode_len_mean: 119.36\n",
      "  episode_reward_max: 234.83204872366727\n",
      "  episode_reward_mean: 151.192320455778\n",
      "  episode_reward_min: -169.96410030958828\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 19220\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.536\n",
      "    load_time_ms: 2.34\n",
      "    num_steps_sampled: 2470000\n",
      "    num_steps_trained: 2470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.30646610260009766\n",
      "      kl: 0.010489776730537415\n",
      "      policy_loss: -0.0007744746981188655\n",
      "      total_loss: 72.65926361083984\n",
      "      vf_explained_var: 0.9564862251281738\n",
      "      vf_loss: 72.66001892089844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3013249337673187\n",
      "      kl: 0.006602608133107424\n",
      "      policy_loss: -0.0009267671266570687\n",
      "      total_loss: 61.4658088684082\n",
      "      vf_explained_var: 0.9576050043106079\n",
      "      vf_loss: 61.46672821044922\n",
      "    sample_time_ms: 19891.528\n",
      "    update_time_ms: 6.688\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.18346957417116\n",
      "    rl_1: 66.00885088160689\n",
      "  time_since_restore: 5769.290550231934\n",
      "  time_this_iter_s: 22.81986427307129\n",
      "  time_total_s: 5769.290550231934\n",
      "  timestamp: 1550886361\n",
      "  timesteps_since_restore: 2470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2470000\n",
      "  training_iteration: 247\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5769 s, 247 iter, 2470000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-46-24\n",
      "  done: false\n",
      "  episode_len_mean: 117.75\n",
      "  episode_reward_max: 234.83204872366727\n",
      "  episode_reward_mean: 159.70457212678915\n",
      "  episode_reward_min: -163.33441191905013\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 19306\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.35\n",
      "    load_time_ms: 2.362\n",
      "    num_steps_sampled: 2480000\n",
      "    num_steps_trained: 2480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.39914751052856445\n",
      "      kl: 0.007207345683127642\n",
      "      policy_loss: -0.0029062475077807903\n",
      "      total_loss: 60.25388717651367\n",
      "      vf_explained_var: 0.9571753144264221\n",
      "      vf_loss: 60.256797790527344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3185557425022125\n",
      "      kl: 0.0066951266489923\n",
      "      policy_loss: -1.4256399083478755e-07\n",
      "      total_loss: 49.0720329284668\n",
      "      vf_explained_var: 0.9592320322990417\n",
      "      vf_loss: 49.0720329284668\n",
      "    sample_time_ms: 19939.506\n",
      "    update_time_ms: 7.187\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.850418226135\n",
      "    rl_1: 70.85415390065413\n",
      "  time_since_restore: 5792.896057605743\n",
      "  time_this_iter_s: 23.605507373809814\n",
      "  time_total_s: 5792.896057605743\n",
      "  timestamp: 1550886384\n",
      "  timesteps_since_restore: 2480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2480000\n",
      "  training_iteration: 248\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5792 s, 248 iter, 2480000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-46-48\n",
      "  done: false\n",
      "  episode_len_mean: 110.64\n",
      "  episode_reward_max: 231.6136627543465\n",
      "  episode_reward_mean: 153.59819768463328\n",
      "  episode_reward_min: -164.55523471274287\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 19394\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.249\n",
      "    load_time_ms: 2.425\n",
      "    num_steps_sampled: 2490000\n",
      "    num_steps_trained: 2490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.37135961651802063\n",
      "      kl: 0.007751286029815674\n",
      "      policy_loss: -0.001743172761052847\n",
      "      total_loss: 94.39923858642578\n",
      "      vf_explained_var: 0.9416755437850952\n",
      "      vf_loss: 94.40099334716797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.35906699299812317\n",
      "      kl: 0.006480488460510969\n",
      "      policy_loss: 0.000601784500759095\n",
      "      total_loss: 89.57643127441406\n",
      "      vf_explained_var: 0.9347581267356873\n",
      "      vf_loss: 89.57584381103516\n",
      "    sample_time_ms: 19981.102\n",
      "    update_time_ms: 8.011\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.37757057969506\n",
      "    rl_1: 68.22062710493825\n",
      "  time_since_restore: 5816.095998048782\n",
      "  time_this_iter_s: 23.19994044303894\n",
      "  time_total_s: 5816.095998048782\n",
      "  timestamp: 1550886408\n",
      "  timesteps_since_restore: 2490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2490000\n",
      "  training_iteration: 249\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5816 s, 249 iter, 2490000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-47-11\n",
      "  done: false\n",
      "  episode_len_mean: 108.88\n",
      "  episode_reward_max: 232.62208010201587\n",
      "  episode_reward_mean: 149.42837481397046\n",
      "  episode_reward_min: -154.2662974257722\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 19487\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.847\n",
      "    load_time_ms: 2.366\n",
      "    num_steps_sampled: 2500000\n",
      "    num_steps_trained: 2500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.302489697933197\n",
      "      kl: 0.006307567935436964\n",
      "      policy_loss: 0.0005947670433670282\n",
      "      total_loss: 97.4115982055664\n",
      "      vf_explained_var: 0.9510374069213867\n",
      "      vf_loss: 97.4110107421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2899518609046936\n",
      "      kl: 0.008567518554627895\n",
      "      policy_loss: -0.0033163027837872505\n",
      "      total_loss: 82.63275909423828\n",
      "      vf_explained_var: 0.9529175162315369\n",
      "      vf_loss: 82.63607025146484\n",
      "    sample_time_ms: 19963.57\n",
      "    update_time_ms: 8.297\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.97797047641569\n",
      "    rl_1: 66.45040433755479\n",
      "  time_since_restore: 5839.211758375168\n",
      "  time_this_iter_s: 23.115760326385498\n",
      "  time_total_s: 5839.211758375168\n",
      "  timestamp: 1550886431\n",
      "  timesteps_since_restore: 2500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2500000\n",
      "  training_iteration: 250\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5839 s, 250 iter, 2500000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 113.49\n",
      "  episode_reward_max: 236.57589608430462\n",
      "  episode_reward_mean: 159.67561623454867\n",
      "  episode_reward_min: -154.31960276737996\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 19574\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.055\n",
      "    load_time_ms: 2.417\n",
      "    num_steps_sampled: 2510000\n",
      "    num_steps_trained: 2510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3704814910888672\n",
      "      kl: 0.006119700614362955\n",
      "      policy_loss: -0.0003194455639459193\n",
      "      total_loss: 63.592430114746094\n",
      "      vf_explained_var: 0.9533994793891907\n",
      "      vf_loss: 63.592742919921875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4138721525669098\n",
      "      kl: 0.006789682898670435\n",
      "      policy_loss: -0.001850200816988945\n",
      "      total_loss: 53.597354888916016\n",
      "      vf_explained_var: 0.9572671055793762\n",
      "      vf_loss: 53.59920120239258\n",
      "    sample_time_ms: 19938.337\n",
      "    update_time_ms: 8.178\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.0360820202785\n",
      "    rl_1: 71.63953421427021\n",
      "  time_since_restore: 5862.236593723297\n",
      "  time_this_iter_s: 23.024835348129272\n",
      "  time_total_s: 5862.236593723297\n",
      "  timestamp: 1550886454\n",
      "  timesteps_since_restore: 2510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2510000\n",
      "  training_iteration: 251\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5862 s, 251 iter, 2510000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-47-57\n",
      "  done: false\n",
      "  episode_len_mean: 104.82\n",
      "  episode_reward_max: 232.97255050114148\n",
      "  episode_reward_mean: 145.08171873672273\n",
      "  episode_reward_min: -159.10187918096722\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 19669\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.212\n",
      "    load_time_ms: 2.412\n",
      "    num_steps_sampled: 2520000\n",
      "    num_steps_trained: 2520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.28947922587394714\n",
      "      kl: 0.012864949181675911\n",
      "      policy_loss: 0.0018949860241264105\n",
      "      total_loss: 98.63687896728516\n",
      "      vf_explained_var: 0.9493719935417175\n",
      "      vf_loss: 98.63497924804688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.23200924694538116\n",
      "      kl: 0.00975288450717926\n",
      "      policy_loss: -0.0001587309961905703\n",
      "      total_loss: 85.0519790649414\n",
      "      vf_explained_var: 0.9514033794403076\n",
      "      vf_loss: 85.05213928222656\n",
      "    sample_time_ms: 19978.814\n",
      "    update_time_ms: 8.082\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.94814678711725\n",
      "    rl_1: 64.13357194960551\n",
      "  time_since_restore: 5885.405705213547\n",
      "  time_this_iter_s: 23.169111490249634\n",
      "  time_total_s: 5885.405705213547\n",
      "  timestamp: 1550886477\n",
      "  timesteps_since_restore: 2520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2520000\n",
      "  training_iteration: 252\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5885 s, 252 iter, 2520000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-48-21\n",
      "  done: false\n",
      "  episode_len_mean: 119.16\n",
      "  episode_reward_max: 234.61712910399396\n",
      "  episode_reward_mean: 156.21695049773697\n",
      "  episode_reward_min: -159.10187918096722\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 19750\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.667\n",
      "    load_time_ms: 2.456\n",
      "    num_steps_sampled: 2530000\n",
      "    num_steps_trained: 2530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4592735171318054\n",
      "      kl: 0.008563540875911713\n",
      "      policy_loss: -0.0008267746889032423\n",
      "      total_loss: 53.989601135253906\n",
      "      vf_explained_var: 0.9599786400794983\n",
      "      vf_loss: 53.99042892456055\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3289031386375427\n",
      "      kl: 0.012266255915164948\n",
      "      policy_loss: -0.0034110569395124912\n",
      "      total_loss: 44.33633041381836\n",
      "      vf_explained_var: 0.964549720287323\n",
      "      vf_loss: 44.339744567871094\n",
      "    sample_time_ms: 19981.258\n",
      "    update_time_ms: 8.166\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.93552868108384\n",
      "    rl_1: 68.28142181665315\n",
      "  time_since_restore: 5908.860683679581\n",
      "  time_this_iter_s: 23.454978466033936\n",
      "  time_total_s: 5908.860683679581\n",
      "  timestamp: 1550886501\n",
      "  timesteps_since_restore: 2530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2530000\n",
      "  training_iteration: 253\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5908 s, 253 iter, 2530000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-48-44\n",
      "  done: false\n",
      "  episode_len_mean: 128.3\n",
      "  episode_reward_max: 231.37247571158213\n",
      "  episode_reward_mean: 150.2094933680077\n",
      "  episode_reward_min: -156.58365977286928\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 19831\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.845\n",
      "    load_time_ms: 2.442\n",
      "    num_steps_sampled: 2540000\n",
      "    num_steps_trained: 2540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.5230134725570679\n",
      "      kl: 0.007599168922752142\n",
      "      policy_loss: -0.0030813126359134912\n",
      "      total_loss: 43.37936782836914\n",
      "      vf_explained_var: 0.9707627892494202\n",
      "      vf_loss: 43.382450103759766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3698893189430237\n",
      "      kl: 0.00715838884934783\n",
      "      policy_loss: -0.0012260957155376673\n",
      "      total_loss: 35.712039947509766\n",
      "      vf_explained_var: 0.9712495803833008\n",
      "      vf_loss: 35.71326446533203\n",
      "    sample_time_ms: 20077.546\n",
      "    update_time_ms: 8.35\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.82567033792631\n",
      "    rl_1: 63.383823030081345\n",
      "  time_since_restore: 5932.299261331558\n",
      "  time_this_iter_s: 23.43857765197754\n",
      "  time_total_s: 5932.299261331558\n",
      "  timestamp: 1550886524\n",
      "  timesteps_since_restore: 2540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2540000\n",
      "  training_iteration: 254\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5932 s, 254 iter, 2540000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-49-07\n",
      "  done: false\n",
      "  episode_len_mean: 107.47\n",
      "  episode_reward_max: 231.9458673127874\n",
      "  episode_reward_mean: 165.92976083606584\n",
      "  episode_reward_min: -174.79251239560475\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 19925\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.314\n",
      "    load_time_ms: 2.436\n",
      "    num_steps_sampled: 2550000\n",
      "    num_steps_trained: 2550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.23599612712860107\n",
      "      kl: 0.013768617995083332\n",
      "      policy_loss: -0.000376858573872596\n",
      "      total_loss: 65.4534912109375\n",
      "      vf_explained_var: 0.9519773721694946\n",
      "      vf_loss: 65.453857421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1636597365140915\n",
      "      kl: 0.010518449358642101\n",
      "      policy_loss: 0.00014692105469293892\n",
      "      total_loss: 61.02386474609375\n",
      "      vf_explained_var: 0.9460409879684448\n",
      "      vf_loss: 61.02372360229492\n",
      "    sample_time_ms: 20081.196\n",
      "    update_time_ms: 8.434\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.74261130258955\n",
      "    rl_1: 71.18714953347627\n",
      "  time_since_restore: 5955.103529691696\n",
      "  time_this_iter_s: 22.80426836013794\n",
      "  time_total_s: 5955.103529691696\n",
      "  timestamp: 1550886547\n",
      "  timesteps_since_restore: 2550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2550000\n",
      "  training_iteration: 255\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5955 s, 255 iter, 2550000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-49-30\n",
      "  done: false\n",
      "  episode_len_mean: 120.6\n",
      "  episode_reward_max: 232.39984735876567\n",
      "  episode_reward_mean: 165.1615685458442\n",
      "  episode_reward_min: -172.62618561509777\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 20007\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.936\n",
      "    load_time_ms: 2.369\n",
      "    num_steps_sampled: 2560000\n",
      "    num_steps_trained: 2560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.40743955969810486\n",
      "      kl: 0.017357859760522842\n",
      "      policy_loss: -0.0014950811164453626\n",
      "      total_loss: 48.7603759765625\n",
      "      vf_explained_var: 0.9613462686538696\n",
      "      vf_loss: 48.76186752319336\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.30277013778686523\n",
      "      kl: 0.006148973945528269\n",
      "      policy_loss: -0.0003224083047825843\n",
      "      total_loss: 40.74393844604492\n",
      "      vf_explained_var: 0.9665980339050293\n",
      "      vf_loss: 40.744266510009766\n",
      "    sample_time_ms: 20048.931\n",
      "    update_time_ms: 8.383\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.76692559101106\n",
      "    rl_1: 72.39464295483316\n",
      "  time_since_restore: 5977.8949406147\n",
      "  time_this_iter_s: 22.79141092300415\n",
      "  time_total_s: 5977.8949406147\n",
      "  timestamp: 1550886570\n",
      "  timesteps_since_restore: 2560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2560000\n",
      "  training_iteration: 256\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 5977 s, 256 iter, 2560000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-49-53\n",
      "  done: false\n",
      "  episode_len_mean: 122.89\n",
      "  episode_reward_max: 235.97018675318253\n",
      "  episode_reward_mean: 142.36561810200993\n",
      "  episode_reward_min: -168.85662490958924\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 20089\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.832\n",
      "    load_time_ms: 2.411\n",
      "    num_steps_sampled: 2570000\n",
      "    num_steps_trained: 2570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.45258209109306335\n",
      "      kl: 0.008731511421501637\n",
      "      policy_loss: 0.0021732596214860678\n",
      "      total_loss: 62.30100631713867\n",
      "      vf_explained_var: 0.9657967686653137\n",
      "      vf_loss: 62.29883575439453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3286224901676178\n",
      "      kl: 0.007066243793815374\n",
      "      policy_loss: -0.0012205984676256776\n",
      "      total_loss: 56.61507034301758\n",
      "      vf_explained_var: 0.9658715724945068\n",
      "      vf_loss: 56.61628723144531\n",
      "    sample_time_ms: 20074.002\n",
      "    update_time_ms: 8.392\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.9626140178251\n",
      "    rl_1: 61.40300408418485\n",
      "  time_since_restore: 6000.972631931305\n",
      "  time_this_iter_s: 23.077691316604614\n",
      "  time_total_s: 6000.972631931305\n",
      "  timestamp: 1550886593\n",
      "  timesteps_since_restore: 2570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2570000\n",
      "  training_iteration: 257\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6000 s, 257 iter, 2570000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-50-16\n",
      "  done: false\n",
      "  episode_len_mean: 108.58\n",
      "  episode_reward_max: 229.61401907009616\n",
      "  episode_reward_mean: 160.98728665971726\n",
      "  episode_reward_min: -167.09656589428238\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 20181\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.667\n",
      "    load_time_ms: 2.446\n",
      "    num_steps_sampled: 2580000\n",
      "    num_steps_trained: 2580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2770434617996216\n",
      "      kl: 0.009140229783952236\n",
      "      policy_loss: 0.00013043501530773938\n",
      "      total_loss: 73.51790618896484\n",
      "      vf_explained_var: 0.9525231719017029\n",
      "      vf_loss: 73.51777648925781\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.16280107200145721\n",
      "      kl: 0.01538964081555605\n",
      "      policy_loss: -0.003698538988828659\n",
      "      total_loss: 71.47347259521484\n",
      "      vf_explained_var: 0.9467886686325073\n",
      "      vf_loss: 71.47715759277344\n",
      "    sample_time_ms: 20049.941\n",
      "    update_time_ms: 7.841\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.87982973984985\n",
      "    rl_1: 69.1074569198674\n",
      "  time_since_restore: 6024.351671695709\n",
      "  time_this_iter_s: 23.379039764404297\n",
      "  time_total_s: 6024.351671695709\n",
      "  timestamp: 1550886616\n",
      "  timesteps_since_restore: 2580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2580000\n",
      "  training_iteration: 258\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6024 s, 258 iter, 2580000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-50-40\n",
      "  done: false\n",
      "  episode_len_mean: 119.13\n",
      "  episode_reward_max: 229.24305309811805\n",
      "  episode_reward_mean: 164.47312259901287\n",
      "  episode_reward_min: -156.4119406244957\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 20266\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.458\n",
      "    load_time_ms: 2.363\n",
      "    num_steps_sampled: 2590000\n",
      "    num_steps_trained: 2590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.4297012984752655\n",
      "      kl: 0.00657771248370409\n",
      "      policy_loss: -0.0014317661989480257\n",
      "      total_loss: 32.933597564697266\n",
      "      vf_explained_var: 0.9694029688835144\n",
      "      vf_loss: 32.93503189086914\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.29173940420150757\n",
      "      kl: 0.008592052385210991\n",
      "      policy_loss: -0.0005698832683265209\n",
      "      total_loss: 29.413881301879883\n",
      "      vf_explained_var: 0.9678678512573242\n",
      "      vf_loss: 29.414447784423828\n",
      "    sample_time_ms: 20052.109\n",
      "    update_time_ms: 7.036\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.49359312141496\n",
      "    rl_1: 70.97952947759792\n",
      "  time_since_restore: 6047.74053478241\n",
      "  time_this_iter_s: 23.38886308670044\n",
      "  time_total_s: 6047.74053478241\n",
      "  timestamp: 1550886640\n",
      "  timesteps_since_restore: 2590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2590000\n",
      "  training_iteration: 259\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6047 s, 259 iter, 2590000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-51-02\n",
      "  done: false\n",
      "  episode_len_mean: 103.28\n",
      "  episode_reward_max: 226.1086526841128\n",
      "  episode_reward_mean: 162.52084492224182\n",
      "  episode_reward_min: -174.19980701099743\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 20362\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.733\n",
      "    load_time_ms: 2.371\n",
      "    num_steps_sampled: 2600000\n",
      "    num_steps_trained: 2600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.20435741543769836\n",
      "      kl: 0.010281910188496113\n",
      "      policy_loss: -0.003557579591870308\n",
      "      total_loss: 67.56419372558594\n",
      "      vf_explained_var: 0.9520524740219116\n",
      "      vf_loss: 67.56776428222656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12960706651210785\n",
      "      kl: 0.01358683593571186\n",
      "      policy_loss: -0.0019721740391105413\n",
      "      total_loss: 67.78627014160156\n",
      "      vf_explained_var: 0.9412136673927307\n",
      "      vf_loss: 67.78824615478516\n",
      "    sample_time_ms: 20007.208\n",
      "    update_time_ms: 6.543\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.81817839820867\n",
      "    rl_1: 71.70266652403313\n",
      "  time_since_restore: 6070.387051582336\n",
      "  time_this_iter_s: 22.646516799926758\n",
      "  time_total_s: 6070.387051582336\n",
      "  timestamp: 1550886662\n",
      "  timesteps_since_restore: 2600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2600000\n",
      "  training_iteration: 260\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6070 s, 260 iter, 2600000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-51-26\n",
      "  done: false\n",
      "  episode_len_mean: 112.9\n",
      "  episode_reward_max: 234.20649429847458\n",
      "  episode_reward_mean: 164.83620443294203\n",
      "  episode_reward_min: -153.12469248870394\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 20451\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.158\n",
      "    load_time_ms: 2.31\n",
      "    num_steps_sampled: 2610000\n",
      "    num_steps_trained: 2610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3056975305080414\n",
      "      kl: 0.009183842688798904\n",
      "      policy_loss: -0.00048699049511924386\n",
      "      total_loss: 87.24369812011719\n",
      "      vf_explained_var: 0.9389247298240662\n",
      "      vf_loss: 87.24417877197266\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.20518772304058075\n",
      "      kl: 0.012181852012872696\n",
      "      policy_loss: -0.0002971893409267068\n",
      "      total_loss: 72.78605651855469\n",
      "      vf_explained_var: 0.9416331052780151\n",
      "      vf_loss: 72.78636169433594\n",
      "    sample_time_ms: 20054.809\n",
      "    update_time_ms: 6.515\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.72735107930139\n",
      "    rl_1: 72.10885335364065\n",
      "  time_since_restore: 6093.888247251511\n",
      "  time_this_iter_s: 23.501195669174194\n",
      "  time_total_s: 6093.888247251511\n",
      "  timestamp: 1550886686\n",
      "  timesteps_since_restore: 2610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2610000\n",
      "  training_iteration: 261\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6093 s, 261 iter, 2610000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-51-49\n",
      "  done: false\n",
      "  episode_len_mean: 111.16\n",
      "  episode_reward_max: 234.41047329882372\n",
      "  episode_reward_mean: 159.08037770344475\n",
      "  episode_reward_min: -167.20282738277265\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 20540\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.617\n",
      "    load_time_ms: 2.313\n",
      "    num_steps_sampled: 2620000\n",
      "    num_steps_trained: 2620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.33645734190940857\n",
      "      kl: 0.011293654330074787\n",
      "      policy_loss: -0.0018287721322849393\n",
      "      total_loss: 83.9681625366211\n",
      "      vf_explained_var: 0.9479487538337708\n",
      "      vf_loss: 83.96998596191406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.213461771607399\n",
      "      kl: 0.007095755077898502\n",
      "      policy_loss: -0.0018577692098915577\n",
      "      total_loss: 71.22834014892578\n",
      "      vf_explained_var: 0.9500992894172668\n",
      "      vf_loss: 71.2302017211914\n",
      "    sample_time_ms: 20048.74\n",
      "    update_time_ms: 6.61\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.41416185207514\n",
      "    rl_1: 69.66621585136959\n",
      "  time_since_restore: 6117.011302232742\n",
      "  time_this_iter_s: 23.12305498123169\n",
      "  time_total_s: 6117.011302232742\n",
      "  timestamp: 1550886709\n",
      "  timesteps_since_restore: 2620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2620000\n",
      "  training_iteration: 262\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6117 s, 262 iter, 2620000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-52-13\n",
      "  done: false\n",
      "  episode_len_mean: 111.36\n",
      "  episode_reward_max: 231.65448664318416\n",
      "  episode_reward_mean: 154.46948261191798\n",
      "  episode_reward_min: -179.43005735918558\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 20628\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.521\n",
      "    load_time_ms: 2.294\n",
      "    num_steps_sampled: 2630000\n",
      "    num_steps_trained: 2630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.34592023491859436\n",
      "      kl: 0.00951594952493906\n",
      "      policy_loss: -0.005175285506993532\n",
      "      total_loss: 69.14934539794922\n",
      "      vf_explained_var: 0.954972505569458\n",
      "      vf_loss: 69.1545181274414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.20616459846496582\n",
      "      kl: 0.008557173423469067\n",
      "      policy_loss: -0.0019856186117976904\n",
      "      total_loss: 61.96806716918945\n",
      "      vf_explained_var: 0.9478182792663574\n",
      "      vf_loss: 61.97005844116211\n",
      "    sample_time_ms: 20021.164\n",
      "    update_time_ms: 6.674\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.79737259211225\n",
      "    rl_1: 66.67211001980577\n",
      "  time_since_restore: 6140.311373233795\n",
      "  time_this_iter_s: 23.300071001052856\n",
      "  time_total_s: 6140.311373233795\n",
      "  timestamp: 1550886733\n",
      "  timesteps_since_restore: 2630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2630000\n",
      "  training_iteration: 263\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6140 s, 263 iter, 2630000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-52-36\n",
      "  done: false\n",
      "  episode_len_mean: 114.79\n",
      "  episode_reward_max: 231.65448664318416\n",
      "  episode_reward_mean: 147.33304803211442\n",
      "  episode_reward_min: -169.83401725119023\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 20714\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3098.083\n",
      "    load_time_ms: 2.393\n",
      "    num_steps_sampled: 2640000\n",
      "    num_steps_trained: 2640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3953559398651123\n",
      "      kl: 0.008448982611298561\n",
      "      policy_loss: 0.00027970990049652755\n",
      "      total_loss: 85.94003295898438\n",
      "      vf_explained_var: 0.9449849128723145\n",
      "      vf_loss: 85.93976593017578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2461162507534027\n",
      "      kl: 0.00990455225110054\n",
      "      policy_loss: -0.0013328276108950377\n",
      "      total_loss: 65.33699035644531\n",
      "      vf_explained_var: 0.9531955122947693\n",
      "      vf_loss: 65.33830261230469\n",
      "    sample_time_ms: 19972.02\n",
      "    update_time_ms: 6.397\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.97621795741269\n",
      "    rl_1: 63.35683007470177\n",
      "  time_since_restore: 6163.263763427734\n",
      "  time_this_iter_s: 22.95239019393921\n",
      "  time_total_s: 6163.263763427734\n",
      "  timestamp: 1550886756\n",
      "  timesteps_since_restore: 2640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2640000\n",
      "  training_iteration: 264\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6163 s, 264 iter, 2640000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 110.79\n",
      "  episode_reward_max: 230.73812458500186\n",
      "  episode_reward_mean: 174.78063977159\n",
      "  episode_reward_min: -156.49392860839052\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 20803\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.866\n",
      "    load_time_ms: 2.416\n",
      "    num_steps_sampled: 2650000\n",
      "    num_steps_trained: 2650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2017238736152649\n",
      "      kl: 0.012346266768872738\n",
      "      policy_loss: -0.00203256425447762\n",
      "      total_loss: 34.37936782836914\n",
      "      vf_explained_var: 0.9638835191726685\n",
      "      vf_loss: 34.381404876708984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.13994254171848297\n",
      "      kl: 0.008741931989789009\n",
      "      policy_loss: 0.00033416340011171997\n",
      "      total_loss: 22.54727554321289\n",
      "      vf_explained_var: 0.9736964106559753\n",
      "      vf_loss: 22.546939849853516\n",
      "    sample_time_ms: 20017.639\n",
      "    update_time_ms: 6.426\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.06741734912819\n",
      "    rl_1: 78.7132224224618\n",
      "  time_since_restore: 6186.326536178589\n",
      "  time_this_iter_s: 23.062772750854492\n",
      "  time_total_s: 6186.326536178589\n",
      "  timestamp: 1550886779\n",
      "  timesteps_since_restore: 2650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2650000\n",
      "  training_iteration: 265\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6186 s, 265 iter, 2650000 ts, 175 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 120.29\n",
      "  episode_reward_max: 227.09470557475325\n",
      "  episode_reward_mean: 165.01847677706743\n",
      "  episode_reward_min: -156.38871808137029\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 20885\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.499\n",
      "    load_time_ms: 2.408\n",
      "    num_steps_sampled: 2660000\n",
      "    num_steps_trained: 2660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.33122551441192627\n",
      "      kl: 0.009348591789603233\n",
      "      policy_loss: -0.0009843847947195172\n",
      "      total_loss: 43.649986267089844\n",
      "      vf_explained_var: 0.9617326259613037\n",
      "      vf_loss: 43.65097427368164\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2562333345413208\n",
      "      kl: 0.016112960875034332\n",
      "      policy_loss: -0.00011432915925979614\n",
      "      total_loss: 33.05960464477539\n",
      "      vf_explained_var: 0.9664192199707031\n",
      "      vf_loss: 33.05971908569336\n",
      "    sample_time_ms: 20068.498\n",
      "    update_time_ms: 6.593\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.08514512608022\n",
      "    rl_1: 71.93333165098714\n",
      "  time_since_restore: 6209.61829662323\n",
      "  time_this_iter_s: 23.291760444641113\n",
      "  time_total_s: 6209.61829662323\n",
      "  timestamp: 1550886802\n",
      "  timesteps_since_restore: 2660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2660000\n",
      "  training_iteration: 266\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6209 s, 266 iter, 2660000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-53-45\n",
      "  done: false\n",
      "  episode_len_mean: 107.38\n",
      "  episode_reward_max: 231.23624973643805\n",
      "  episode_reward_mean: 160.92423996551358\n",
      "  episode_reward_min: -175.06464480534697\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 20977\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.123\n",
      "    load_time_ms: 2.38\n",
      "    num_steps_sampled: 2670000\n",
      "    num_steps_trained: 2670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.17876935005187988\n",
      "      kl: 0.01314710546284914\n",
      "      policy_loss: 0.0039051289204508066\n",
      "      total_loss: 78.35271453857422\n",
      "      vf_explained_var: 0.9449430704116821\n",
      "      vf_loss: 78.34879302978516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09934211522340775\n",
      "      kl: 0.008502588607370853\n",
      "      policy_loss: -0.0011876923963427544\n",
      "      total_loss: 65.41178131103516\n",
      "      vf_explained_var: 0.9432887434959412\n",
      "      vf_loss: 65.41297149658203\n",
      "    sample_time_ms: 20052.657\n",
      "    update_time_ms: 6.738\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.40739199936968\n",
      "    rl_1: 70.51684796614386\n",
      "  time_since_restore: 6232.546328306198\n",
      "  time_this_iter_s: 22.92803168296814\n",
      "  time_total_s: 6232.546328306198\n",
      "  timestamp: 1550886825\n",
      "  timesteps_since_restore: 2670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2670000\n",
      "  training_iteration: 267\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6232 s, 267 iter, 2670000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-54-08\n",
      "  done: false\n",
      "  episode_len_mean: 103.38\n",
      "  episode_reward_max: 226.37799063208087\n",
      "  episode_reward_mean: 160.269542699136\n",
      "  episode_reward_min: -176.1194326688269\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 21074\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3096.947\n",
      "    load_time_ms: 2.318\n",
      "    num_steps_sampled: 2680000\n",
      "    num_steps_trained: 2680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14871345460414886\n",
      "      kl: 0.008821590803563595\n",
      "      policy_loss: -0.0016286212485283613\n",
      "      total_loss: 48.48321533203125\n",
      "      vf_explained_var: 0.9665243625640869\n",
      "      vf_loss: 48.48484420776367\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.10127317905426025\n",
      "      kl: 0.016438186168670654\n",
      "      policy_loss: 0.002965546678751707\n",
      "      total_loss: 40.380985260009766\n",
      "      vf_explained_var: 0.9659804105758667\n",
      "      vf_loss: 40.378021240234375\n",
      "    sample_time_ms: 20004.251\n",
      "    update_time_ms: 6.818\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.02877349094707\n",
      "    rl_1: 70.24076920818894\n",
      "  time_since_restore: 6255.628268957138\n",
      "  time_this_iter_s: 23.08194065093994\n",
      "  time_total_s: 6255.628268957138\n",
      "  timestamp: 1550886848\n",
      "  timesteps_since_restore: 2680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2680000\n",
      "  training_iteration: 268\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6255 s, 268 iter, 2680000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-54-31\n",
      "  done: false\n",
      "  episode_len_mean: 112.77\n",
      "  episode_reward_max: 232.89578081797205\n",
      "  episode_reward_mean: 158.66379652748964\n",
      "  episode_reward_min: -165.65849906829936\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 21161\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.053\n",
      "    load_time_ms: 2.416\n",
      "    num_steps_sampled: 2690000\n",
      "    num_steps_trained: 2690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.29130443930625916\n",
      "      kl: 0.007413287181407213\n",
      "      policy_loss: -0.0031832472886890173\n",
      "      total_loss: 81.1370620727539\n",
      "      vf_explained_var: 0.9392088055610657\n",
      "      vf_loss: 81.1402587890625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.20108161866664886\n",
      "      kl: 0.008795863017439842\n",
      "      policy_loss: -0.002450653351843357\n",
      "      total_loss: 75.36450958251953\n",
      "      vf_explained_var: 0.9307217001914978\n",
      "      vf_loss: 75.36695098876953\n",
      "    sample_time_ms: 19995.275\n",
      "    update_time_ms: 6.78\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.82722326728859\n",
      "    rl_1: 68.83657326020105\n",
      "  time_since_restore: 6278.779579162598\n",
      "  time_this_iter_s: 23.151310205459595\n",
      "  time_total_s: 6278.779579162598\n",
      "  timestamp: 1550886871\n",
      "  timesteps_since_restore: 2690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2690000\n",
      "  training_iteration: 269\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6278 s, 269 iter, 2690000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-54-54\n",
      "  done: false\n",
      "  episode_len_mean: 119.43\n",
      "  episode_reward_max: 224.15195040036974\n",
      "  episode_reward_mean: 157.1805645915207\n",
      "  episode_reward_min: -150.91526537520758\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 21243\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.386\n",
      "    load_time_ms: 2.405\n",
      "    num_steps_sampled: 2700000\n",
      "    num_steps_trained: 2700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3586026132106781\n",
      "      kl: 0.008330504409968853\n",
      "      policy_loss: -0.00040508806705474854\n",
      "      total_loss: 31.06234359741211\n",
      "      vf_explained_var: 0.9736918210983276\n",
      "      vf_loss: 31.062747955322266\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.19355645775794983\n",
      "      kl: 0.009204654954373837\n",
      "      policy_loss: 0.0007298147538676858\n",
      "      total_loss: 25.020915985107422\n",
      "      vf_explained_var: 0.97442227602005\n",
      "      vf_loss: 25.020183563232422\n",
      "    sample_time_ms: 20040.78\n",
      "    update_time_ms: 6.936\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.97995382415618\n",
      "    rl_1: 66.20061076736454\n",
      "  time_since_restore: 6301.904584646225\n",
      "  time_this_iter_s: 23.12500548362732\n",
      "  time_total_s: 6301.904584646225\n",
      "  timestamp: 1550886894\n",
      "  timesteps_since_restore: 2700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2700000\n",
      "  training_iteration: 270\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6301 s, 270 iter, 2700000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-55-18\n",
      "  done: false\n",
      "  episode_len_mean: 120.09\n",
      "  episode_reward_max: 233.92355167016672\n",
      "  episode_reward_mean: 135.9661323010936\n",
      "  episode_reward_min: -174.1215548595071\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 21332\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.274\n",
      "    load_time_ms: 2.456\n",
      "    num_steps_sampled: 2710000\n",
      "    num_steps_trained: 2710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.26047268509864807\n",
      "      kl: 0.01412374060600996\n",
      "      policy_loss: 0.00282511068508029\n",
      "      total_loss: 64.30714416503906\n",
      "      vf_explained_var: 0.9656879901885986\n",
      "      vf_loss: 64.3043212890625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14378714561462402\n",
      "      kl: 0.01025487296283245\n",
      "      policy_loss: 0.0013695696834474802\n",
      "      total_loss: 55.9926872253418\n",
      "      vf_explained_var: 0.9621202349662781\n",
      "      vf_loss: 55.99130630493164\n",
      "    sample_time_ms: 20029.871\n",
      "    update_time_ms: 7.277\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.59333509200705\n",
      "    rl_1: 55.372797209086556\n",
      "  time_since_restore: 6325.302274465561\n",
      "  time_this_iter_s: 23.397689819335938\n",
      "  time_total_s: 6325.302274465561\n",
      "  timestamp: 1550886918\n",
      "  timesteps_since_restore: 2710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2710000\n",
      "  training_iteration: 271\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6325 s, 271 iter, 2710000 ts, 136 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-55-41\n",
      "  done: false\n",
      "  episode_len_mean: 116.0\n",
      "  episode_reward_max: 225.12085714325096\n",
      "  episode_reward_mean: 170.80099044052088\n",
      "  episode_reward_min: -157.21069276393854\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 21422\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.379\n",
      "    load_time_ms: 2.466\n",
      "    num_steps_sampled: 2720000\n",
      "    num_steps_trained: 2720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2531343698501587\n",
      "      kl: 0.012372242286801338\n",
      "      policy_loss: -0.0026531945914030075\n",
      "      total_loss: 43.58109664916992\n",
      "      vf_explained_var: 0.9643008708953857\n",
      "      vf_loss: 43.58374786376953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.16196264326572418\n",
      "      kl: 0.015453659929335117\n",
      "      policy_loss: -0.0025181567762047052\n",
      "      total_loss: 35.81172561645508\n",
      "      vf_explained_var: 0.9648401141166687\n",
      "      vf_loss: 35.81424331665039\n",
      "    sample_time_ms: 20061.542\n",
      "    update_time_ms: 7.21\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.08839482756602\n",
      "    rl_1: 74.71259561295486\n",
      "  time_since_restore: 6348.735554456711\n",
      "  time_this_iter_s: 23.433279991149902\n",
      "  time_total_s: 6348.735554456711\n",
      "  timestamp: 1550886941\n",
      "  timesteps_since_restore: 2720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2720000\n",
      "  training_iteration: 272\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6348 s, 272 iter, 2720000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-56-04\n",
      "  done: false\n",
      "  episode_len_mean: 111.59\n",
      "  episode_reward_max: 222.32075353771864\n",
      "  episode_reward_mean: 162.85268959678126\n",
      "  episode_reward_min: -160.7590963240118\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 21510\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.328\n",
      "    load_time_ms: 2.543\n",
      "    num_steps_sampled: 2730000\n",
      "    num_steps_trained: 2730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2548538148403168\n",
      "      kl: 0.012779103592038155\n",
      "      policy_loss: -0.0035005861427634954\n",
      "      total_loss: 62.58809280395508\n",
      "      vf_explained_var: 0.9495562314987183\n",
      "      vf_loss: 62.591583251953125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12272652238607407\n",
      "      kl: 0.013372297398746014\n",
      "      policy_loss: -0.0034624498803168535\n",
      "      total_loss: 49.031944274902344\n",
      "      vf_explained_var: 0.9497827291488647\n",
      "      vf_loss: 49.03540802001953\n",
      "    sample_time_ms: 20036.183\n",
      "    update_time_ms: 6.97\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.31074441208764\n",
      "    rl_1: 70.54194518469363\n",
      "  time_since_restore: 6371.672688245773\n",
      "  time_this_iter_s: 22.9371337890625\n",
      "  time_total_s: 6371.672688245773\n",
      "  timestamp: 1550886964\n",
      "  timesteps_since_restore: 2730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2730000\n",
      "  training_iteration: 273\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6371 s, 273 iter, 2730000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 116.15\n",
      "  episode_reward_max: 227.60862645291107\n",
      "  episode_reward_mean: 164.02035942588893\n",
      "  episode_reward_min: -160.7590963240118\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 21595\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.193\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 2740000\n",
      "    num_steps_trained: 2740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.24005576968193054\n",
      "      kl: 0.020778784528374672\n",
      "      policy_loss: -0.0014743858482688665\n",
      "      total_loss: 60.35869216918945\n",
      "      vf_explained_var: 0.9453462362289429\n",
      "      vf_loss: 60.360164642333984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12189503014087677\n",
      "      kl: 0.013783211819827557\n",
      "      policy_loss: 0.002542109927162528\n",
      "      total_loss: 53.874298095703125\n",
      "      vf_explained_var: 0.9420846104621887\n",
      "      vf_loss: 53.87174987792969\n",
      "    sample_time_ms: 20106.982\n",
      "    update_time_ms: 7.15\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.72010538940667\n",
      "    rl_1: 71.30025403648222\n",
      "  time_since_restore: 6395.343526363373\n",
      "  time_this_iter_s: 23.670838117599487\n",
      "  time_total_s: 6395.343526363373\n",
      "  timestamp: 1550886988\n",
      "  timesteps_since_restore: 2740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2740000\n",
      "  training_iteration: 274\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6395 s, 274 iter, 2740000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-56-51\n",
      "  done: false\n",
      "  episode_len_mean: 125.64\n",
      "  episode_reward_max: 227.10876550801927\n",
      "  episode_reward_mean: 153.3560107422728\n",
      "  episode_reward_min: -159.71162734204108\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 21679\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.532\n",
      "    load_time_ms: 2.514\n",
      "    num_steps_sampled: 2750000\n",
      "    num_steps_trained: 2750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2696608901023865\n",
      "      kl: 0.013555040583014488\n",
      "      policy_loss: 0.004768196493387222\n",
      "      total_loss: 46.96969223022461\n",
      "      vf_explained_var: 0.9701858758926392\n",
      "      vf_loss: 46.96492385864258\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.15016241371631622\n",
      "      kl: 0.008128492161631584\n",
      "      policy_loss: -0.0012376612285152078\n",
      "      total_loss: 37.41667556762695\n",
      "      vf_explained_var: 0.9746921062469482\n",
      "      vf_loss: 37.41790771484375\n",
      "    sample_time_ms: 20077.737\n",
      "    update_time_ms: 7.127\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.05046471915563\n",
      "    rl_1: 66.30554602311716\n",
      "  time_since_restore: 6418.189219713211\n",
      "  time_this_iter_s: 22.845693349838257\n",
      "  time_total_s: 6418.189219713211\n",
      "  timestamp: 1550887011\n",
      "  timesteps_since_restore: 2750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2750000\n",
      "  training_iteration: 275\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6418 s, 275 iter, 2750000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-57-14\n",
      "  done: false\n",
      "  episode_len_mean: 117.15\n",
      "  episode_reward_max: 219.88925559781583\n",
      "  episode_reward_mean: 153.39719291361752\n",
      "  episode_reward_min: -165.58253813702447\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 21764\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.832\n",
      "    load_time_ms: 2.56\n",
      "    num_steps_sampled: 2760000\n",
      "    num_steps_trained: 2760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.17121365666389465\n",
      "      kl: 0.007776516489684582\n",
      "      policy_loss: 0.00038475258043035865\n",
      "      total_loss: 35.13559341430664\n",
      "      vf_explained_var: 0.9712867736816406\n",
      "      vf_loss: 35.13520431518555\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.05349375680088997\n",
      "      kl: 0.010386049747467041\n",
      "      policy_loss: 0.0006026853225193918\n",
      "      total_loss: 29.2069149017334\n",
      "      vf_explained_var: 0.9715462923049927\n",
      "      vf_loss: 29.206314086914062\n",
      "    sample_time_ms: 20074.523\n",
      "    update_time_ms: 7.226\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.00680631939369\n",
      "    rl_1: 65.39038659422377\n",
      "  time_since_restore: 6441.450660228729\n",
      "  time_this_iter_s: 23.26144051551819\n",
      "  time_total_s: 6441.450660228729\n",
      "  timestamp: 1550887034\n",
      "  timesteps_since_restore: 2760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2760000\n",
      "  training_iteration: 276\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6441 s, 276 iter, 2760000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-57-37\n",
      "  done: false\n",
      "  episode_len_mean: 105.95\n",
      "  episode_reward_max: 232.82684149697496\n",
      "  episode_reward_mean: 159.96333335053237\n",
      "  episode_reward_min: -168.94202441556794\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 21858\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.899\n",
      "    load_time_ms: 2.595\n",
      "    num_steps_sampled: 2770000\n",
      "    num_steps_trained: 2770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08274541050195694\n",
      "      kl: 0.014069190248847008\n",
      "      policy_loss: -0.00163844577036798\n",
      "      total_loss: 82.46199798583984\n",
      "      vf_explained_var: 0.9471975564956665\n",
      "      vf_loss: 82.46363067626953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.017068300396203995\n",
      "      kl: 0.01180057879537344\n",
      "      policy_loss: -0.000749019265640527\n",
      "      total_loss: 68.92304229736328\n",
      "      vf_explained_var: 0.9495996236801147\n",
      "      vf_loss: 68.9238052368164\n",
      "    sample_time_ms: 20044.715\n",
      "    update_time_ms: 7.28\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.43981210371497\n",
      "    rl_1: 71.5235212468174\n",
      "  time_since_restore: 6464.27130317688\n",
      "  time_this_iter_s: 22.820642948150635\n",
      "  time_total_s: 6464.27130317688\n",
      "  timestamp: 1550887057\n",
      "  timesteps_since_restore: 2770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2770000\n",
      "  training_iteration: 277\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6464 s, 277 iter, 2770000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-58-01\n",
      "  done: false\n",
      "  episode_len_mean: 114.96\n",
      "  episode_reward_max: 227.70627644336557\n",
      "  episode_reward_mean: 153.93386353597592\n",
      "  episode_reward_min: -165.80458633269387\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 21945\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.423\n",
      "    load_time_ms: 2.591\n",
      "    num_steps_sampled: 2780000\n",
      "    num_steps_trained: 2780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3046421706676483\n",
      "      kl: 0.012030038982629776\n",
      "      policy_loss: 0.002025628462433815\n",
      "      total_loss: 66.5902328491211\n",
      "      vf_explained_var: 0.9560645818710327\n",
      "      vf_loss: 66.58818817138672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.18314583599567413\n",
      "      kl: 0.01075149979442358\n",
      "      policy_loss: 0.0005565168685279787\n",
      "      total_loss: 56.744972229003906\n",
      "      vf_explained_var: 0.956507682800293\n",
      "      vf_loss: 56.74442672729492\n",
      "    sample_time_ms: 20096.015\n",
      "    update_time_ms: 7.25\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.44702503314944\n",
      "    rl_1: 67.48683850282647\n",
      "  time_since_restore: 6487.690150976181\n",
      "  time_this_iter_s: 23.418847799301147\n",
      "  time_total_s: 6487.690150976181\n",
      "  timestamp: 1550887081\n",
      "  timesteps_since_restore: 2780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2780000\n",
      "  training_iteration: 278\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6487 s, 278 iter, 2780000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-58-24\n",
      "  done: false\n",
      "  episode_len_mean: 119.66\n",
      "  episode_reward_max: 227.86828756161722\n",
      "  episode_reward_mean: 163.1590261301115\n",
      "  episode_reward_min: -158.46066176780138\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 22032\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.648\n",
      "    load_time_ms: 2.507\n",
      "    num_steps_sampled: 2790000\n",
      "    num_steps_trained: 2790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.21820209920406342\n",
      "      kl: 0.010688995942473412\n",
      "      policy_loss: 0.0015885415486991405\n",
      "      total_loss: 46.612457275390625\n",
      "      vf_explained_var: 0.9649003744125366\n",
      "      vf_loss: 46.610870361328125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09232175350189209\n",
      "      kl: 0.01822328381240368\n",
      "      policy_loss: 0.0013097660848870873\n",
      "      total_loss: 37.50016403198242\n",
      "      vf_explained_var: 0.968629002571106\n",
      "      vf_loss: 37.49885940551758\n",
      "    sample_time_ms: 20134.62\n",
      "    update_time_ms: 7.37\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.79956227655177\n",
      "    rl_1: 71.35946385355973\n",
      "  time_since_restore: 6511.220380067825\n",
      "  time_this_iter_s: 23.530229091644287\n",
      "  time_total_s: 6511.220380067825\n",
      "  timestamp: 1550887104\n",
      "  timesteps_since_restore: 2790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2790000\n",
      "  training_iteration: 279\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6511 s, 279 iter, 2790000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-58-48\n",
      "  done: false\n",
      "  episode_len_mean: 110.49\n",
      "  episode_reward_max: 225.9263386255663\n",
      "  episode_reward_mean: 170.50776807496638\n",
      "  episode_reward_min: -148.78940676696035\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 22123\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.459\n",
      "    load_time_ms: 2.518\n",
      "    num_steps_sampled: 2800000\n",
      "    num_steps_trained: 2800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.11398468166589737\n",
      "      kl: 0.011386080645024776\n",
      "      policy_loss: -0.00023358392354566604\n",
      "      total_loss: 35.47371292114258\n",
      "      vf_explained_var: 0.9658692479133606\n",
      "      vf_loss: 35.47394943237305\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06653746217489243\n",
      "      kl: 0.007275083102285862\n",
      "      policy_loss: -0.0005969377234578133\n",
      "      total_loss: 31.124086380004883\n",
      "      vf_explained_var: 0.9650741219520569\n",
      "      vf_loss: 31.124683380126953\n",
      "    sample_time_ms: 20182.49\n",
      "    update_time_ms: 7.787\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.16824171838309\n",
      "    rl_1: 74.33952635658325\n",
      "  time_since_restore: 6534.836750745773\n",
      "  time_this_iter_s: 23.616370677947998\n",
      "  time_total_s: 6534.836750745773\n",
      "  timestamp: 1550887128\n",
      "  timesteps_since_restore: 2800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2800000\n",
      "  training_iteration: 280\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6534 s, 280 iter, 2800000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-59-11\n",
      "  done: false\n",
      "  episode_len_mean: 118.9\n",
      "  episode_reward_max: 229.85981864921874\n",
      "  episode_reward_mean: 161.78235217384292\n",
      "  episode_reward_min: -170.7633342817553\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 22208\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.817\n",
      "    load_time_ms: 2.474\n",
      "    num_steps_sampled: 2810000\n",
      "    num_steps_trained: 2810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.22128088772296906\n",
      "      kl: 0.02841857075691223\n",
      "      policy_loss: 0.011781805194914341\n",
      "      total_loss: 48.21155548095703\n",
      "      vf_explained_var: 0.9658131003379822\n",
      "      vf_loss: 48.199771881103516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.15516382455825806\n",
      "      kl: 0.010486483573913574\n",
      "      policy_loss: 0.0017521027475595474\n",
      "      total_loss: 40.44569778442383\n",
      "      vf_explained_var: 0.9677964448928833\n",
      "      vf_loss: 40.443946838378906\n",
      "    sample_time_ms: 20130.83\n",
      "    update_time_ms: 7.713\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.29517689012788\n",
      "    rl_1: 70.48717528371506\n",
      "  time_since_restore: 6557.707692623138\n",
      "  time_this_iter_s: 22.870941877365112\n",
      "  time_total_s: 6557.707692623138\n",
      "  timestamp: 1550887151\n",
      "  timesteps_since_restore: 2810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2810000\n",
      "  training_iteration: 281\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6557 s, 281 iter, 2810000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-59-33\n",
      "  done: false\n",
      "  episode_len_mean: 126.27\n",
      "  episode_reward_max: 229.85981864921874\n",
      "  episode_reward_mean: 152.71008039235795\n",
      "  episode_reward_min: -170.7633342817553\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 22289\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.72\n",
      "    load_time_ms: 2.482\n",
      "    num_steps_sampled: 2820000\n",
      "    num_steps_trained: 2820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.3348188102245331\n",
      "      kl: 0.00922960415482521\n",
      "      policy_loss: 0.0007322046440094709\n",
      "      total_loss: 64.59255981445312\n",
      "      vf_explained_var: 0.9522700309753418\n",
      "      vf_loss: 64.5918197631836\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.21163207292556763\n",
      "      kl: 0.011015224270522594\n",
      "      policy_loss: -0.004594725556671619\n",
      "      total_loss: 52.74501037597656\n",
      "      vf_explained_var: 0.9580901861190796\n",
      "      vf_loss: 52.74960708618164\n",
      "    sample_time_ms: 20032.428\n",
      "    update_time_ms: 7.863\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.15013728009056\n",
      "    rl_1: 65.55994311226738\n",
      "  time_since_restore: 6580.158365488052\n",
      "  time_this_iter_s: 22.45067286491394\n",
      "  time_total_s: 6580.158365488052\n",
      "  timestamp: 1550887173\n",
      "  timesteps_since_restore: 2820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2820000\n",
      "  training_iteration: 282\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6580 s, 282 iter, 2820000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_02-59-56\n",
      "  done: false\n",
      "  episode_len_mean: 110.09\n",
      "  episode_reward_max: 221.13895702979863\n",
      "  episode_reward_mean: 152.824538882754\n",
      "  episode_reward_min: -171.7239989255494\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 22384\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.723\n",
      "    load_time_ms: 2.359\n",
      "    num_steps_sampled: 2830000\n",
      "    num_steps_trained: 2830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1262284815311432\n",
      "      kl: 0.016295505687594414\n",
      "      policy_loss: -0.0034317506942898035\n",
      "      total_loss: 65.06847381591797\n",
      "      vf_explained_var: 0.9610865712165833\n",
      "      vf_loss: 65.0718994140625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14227677881717682\n",
      "      kl: 0.026303619146347046\n",
      "      policy_loss: -0.002749863313511014\n",
      "      total_loss: 54.19676971435547\n",
      "      vf_explained_var: 0.9614301919937134\n",
      "      vf_loss: 54.19953155517578\n",
      "    sample_time_ms: 20016.359\n",
      "    update_time_ms: 8.109\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.82696070150855\n",
      "    rl_1: 65.99757818124544\n",
      "  time_since_restore: 6602.9340035915375\n",
      "  time_this_iter_s: 22.775638103485107\n",
      "  time_total_s: 6602.9340035915375\n",
      "  timestamp: 1550887196\n",
      "  timesteps_since_restore: 2830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2830000\n",
      "  training_iteration: 283\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6602 s, 283 iter, 2830000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-00-19\n",
      "  done: false\n",
      "  episode_len_mean: 117.71\n",
      "  episode_reward_max: 227.94016660567559\n",
      "  episode_reward_mean: 169.87939099243988\n",
      "  episode_reward_min: -171.7239989255494\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 22469\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.883\n",
      "    load_time_ms: 2.477\n",
      "    num_steps_sampled: 2840000\n",
      "    num_steps_trained: 2840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1677720844745636\n",
      "      kl: 0.015194634906947613\n",
      "      policy_loss: -0.0010369903175160289\n",
      "      total_loss: 38.758140563964844\n",
      "      vf_explained_var: 0.967494547367096\n",
      "      vf_loss: 38.759178161621094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09993156045675278\n",
      "      kl: 0.015535524114966393\n",
      "      policy_loss: -0.0012575307628139853\n",
      "      total_loss: 30.960777282714844\n",
      "      vf_explained_var: 0.9670782685279846\n",
      "      vf_loss: 30.9620304107666\n",
      "    sample_time_ms: 19983.414\n",
      "    update_time_ms: 7.975\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.71176297442797\n",
      "    rl_1: 73.16762801801187\n",
      "  time_since_restore: 6626.277166128159\n",
      "  time_this_iter_s: 23.343162536621094\n",
      "  time_total_s: 6626.277166128159\n",
      "  timestamp: 1550887219\n",
      "  timesteps_since_restore: 2840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2840000\n",
      "  training_iteration: 284\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6626 s, 284 iter, 2840000 ts, 170 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-00-42\n",
      "  done: false\n",
      "  episode_len_mean: 111.1\n",
      "  episode_reward_max: 229.44754949215172\n",
      "  episode_reward_mean: 172.0477096712288\n",
      "  episode_reward_min: -180.1455398953716\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 22559\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.85\n",
      "    load_time_ms: 2.405\n",
      "    num_steps_sampled: 2850000\n",
      "    num_steps_trained: 2850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.03398991376161575\n",
      "      kl: 0.013903767801821232\n",
      "      policy_loss: 0.0002156073896912858\n",
      "      total_loss: 52.21005630493164\n",
      "      vf_explained_var: 0.961024284362793\n",
      "      vf_loss: 52.2098388671875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.016480248421430588\n",
      "      kl: 0.007351697888225317\n",
      "      policy_loss: -0.000497504195664078\n",
      "      total_loss: 41.18413543701172\n",
      "      vf_explained_var: 0.9614224433898926\n",
      "      vf_loss: 41.18463134765625\n",
      "    sample_time_ms: 19958.69\n",
      "    update_time_ms: 7.947\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.9444069892001\n",
      "    rl_1: 75.10330268202871\n",
      "  time_since_restore: 6648.833023548126\n",
      "  time_this_iter_s: 22.55585741996765\n",
      "  time_total_s: 6648.833023548126\n",
      "  timestamp: 1550887242\n",
      "  timesteps_since_restore: 2850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2850000\n",
      "  training_iteration: 285\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6648 s, 285 iter, 2850000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-01-05\n",
      "  done: false\n",
      "  episode_len_mean: 117.06\n",
      "  episode_reward_max: 226.53755786731978\n",
      "  episode_reward_mean: 163.67440089258432\n",
      "  episode_reward_min: -174.0720998886869\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 22647\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.254\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 2860000\n",
      "    num_steps_trained: 2860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.19433769583702087\n",
      "      kl: 0.01609787903726101\n",
      "      policy_loss: 0.00011857302888529375\n",
      "      total_loss: 48.51230239868164\n",
      "      vf_explained_var: 0.9607464671134949\n",
      "      vf_loss: 48.51218032836914\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.10652867704629898\n",
      "      kl: 0.019662752747535706\n",
      "      policy_loss: 0.001687208074145019\n",
      "      total_loss: 42.204872131347656\n",
      "      vf_explained_var: 0.9618279933929443\n",
      "      vf_loss: 42.203182220458984\n",
      "    sample_time_ms: 19910.594\n",
      "    update_time_ms: 7.779\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.02436807377221\n",
      "    rl_1: 71.6500328188121\n",
      "  time_since_restore: 6671.6470901966095\n",
      "  time_this_iter_s: 22.814066648483276\n",
      "  time_total_s: 6671.6470901966095\n",
      "  timestamp: 1550887265\n",
      "  timesteps_since_restore: 2860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2860000\n",
      "  training_iteration: 286\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6671 s, 286 iter, 2860000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-01-28\n",
      "  done: false\n",
      "  episode_len_mean: 115.7\n",
      "  episode_reward_max: 227.69137981803416\n",
      "  episode_reward_mean: 152.09768918619267\n",
      "  episode_reward_min: -172.54781364403505\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 22736\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.787\n",
      "    load_time_ms: 2.385\n",
      "    num_steps_sampled: 2870000\n",
      "    num_steps_trained: 2870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.146762415766716\n",
      "      kl: 0.018750309944152832\n",
      "      policy_loss: 0.0012224058154970407\n",
      "      total_loss: 86.79944610595703\n",
      "      vf_explained_var: 0.9456692934036255\n",
      "      vf_loss: 86.79823303222656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.10202931612730026\n",
      "      kl: 0.019037941470742226\n",
      "      policy_loss: -0.002909991191700101\n",
      "      total_loss: 78.4566421508789\n",
      "      vf_explained_var: 0.9429379105567932\n",
      "      vf_loss: 78.45954132080078\n",
      "    sample_time_ms: 19912.05\n",
      "    update_time_ms: 7.611\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.21357280612574\n",
      "    rl_1: 65.88411638006687\n",
      "  time_since_restore: 6694.2857122421265\n",
      "  time_this_iter_s: 22.638622045516968\n",
      "  time_total_s: 6694.2857122421265\n",
      "  timestamp: 1550887288\n",
      "  timesteps_since_restore: 2870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2870000\n",
      "  training_iteration: 287\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6694 s, 287 iter, 2870000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-01-50\n",
      "  done: false\n",
      "  episode_len_mean: 108.94\n",
      "  episode_reward_max: 230.16808114377199\n",
      "  episode_reward_mean: 164.48532245100506\n",
      "  episode_reward_min: -147.661034725364\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 22826\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3055.437\n",
      "    load_time_ms: 2.452\n",
      "    num_steps_sampled: 2880000\n",
      "    num_steps_trained: 2880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.07300937920808792\n",
      "      kl: 0.00933592114597559\n",
      "      policy_loss: -0.001100321183912456\n",
      "      total_loss: 35.257869720458984\n",
      "      vf_explained_var: 0.972011148929596\n",
      "      vf_loss: 35.25896453857422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.005366648081690073\n",
      "      kl: 0.011332239024341106\n",
      "      policy_loss: 0.00258105737157166\n",
      "      total_loss: 30.319551467895508\n",
      "      vf_explained_var: 0.9706578254699707\n",
      "      vf_loss: 30.31696319580078\n",
      "    sample_time_ms: 19837.502\n",
      "    update_time_ms: 7.507\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.79739898899825\n",
      "    rl_1: 71.68792346200684\n",
      "  time_since_restore: 6716.898087501526\n",
      "  time_this_iter_s: 22.612375259399414\n",
      "  time_total_s: 6716.898087501526\n",
      "  timestamp: 1550887310\n",
      "  timesteps_since_restore: 2880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2880000\n",
      "  training_iteration: 288\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 4.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6716 s, 288 iter, 2880000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-02-13\n",
      "  done: false\n",
      "  episode_len_mean: 111.84\n",
      "  episode_reward_max: 235.95862052874838\n",
      "  episode_reward_mean: 173.0499925884428\n",
      "  episode_reward_min: -153.43629497606167\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 22915\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3059.408\n",
      "    load_time_ms: 2.461\n",
      "    num_steps_sampled: 2890000\n",
      "    num_steps_trained: 2890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08113037049770355\n",
      "      kl: 0.015161707065999508\n",
      "      policy_loss: 0.0007892849971540272\n",
      "      total_loss: 46.243141174316406\n",
      "      vf_explained_var: 0.9638888835906982\n",
      "      vf_loss: 46.24235534667969\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06676369160413742\n",
      "      kl: 0.00770956976339221\n",
      "      policy_loss: -0.0018365519354119897\n",
      "      total_loss: 40.958404541015625\n",
      "      vf_explained_var: 0.964455246925354\n",
      "      vf_loss: 40.96024703979492\n",
      "    sample_time_ms: 19769.471\n",
      "    update_time_ms: 7.894\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.17741613727904\n",
      "    rl_1: 77.8725764511637\n",
      "  time_since_restore: 6739.791221141815\n",
      "  time_this_iter_s: 22.893133640289307\n",
      "  time_total_s: 6739.791221141815\n",
      "  timestamp: 1550887333\n",
      "  timesteps_since_restore: 2890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2890000\n",
      "  training_iteration: 289\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6739 s, 289 iter, 2890000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-02-36\n",
      "  done: false\n",
      "  episode_len_mean: 114.54\n",
      "  episode_reward_max: 235.95862052874838\n",
      "  episode_reward_mean: 153.25602031066515\n",
      "  episode_reward_min: -146.38606588354236\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 23003\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3058.164\n",
      "    load_time_ms: 2.468\n",
      "    num_steps_sampled: 2900000\n",
      "    num_steps_trained: 2900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1659010797739029\n",
      "      kl: 0.019958706572651863\n",
      "      policy_loss: -0.000927191402297467\n",
      "      total_loss: 57.828819274902344\n",
      "      vf_explained_var: 0.9632019400596619\n",
      "      vf_loss: 57.82975387573242\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1263771653175354\n",
      "      kl: 0.011819655075669289\n",
      "      policy_loss: 0.001418908592313528\n",
      "      total_loss: 53.79393768310547\n",
      "      vf_explained_var: 0.9601271152496338\n",
      "      vf_loss: 53.792518615722656\n",
      "    sample_time_ms: 19721.189\n",
      "    update_time_ms: 7.432\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.4038793671127\n",
      "    rl_1: 65.85214094355246\n",
      "  time_since_restore: 6762.908960580826\n",
      "  time_this_iter_s: 23.11773943901062\n",
      "  time_total_s: 6762.908960580826\n",
      "  timestamp: 1550887356\n",
      "  timesteps_since_restore: 2900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2900000\n",
      "  training_iteration: 290\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6762 s, 290 iter, 2900000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-03-00\n",
      "  done: false\n",
      "  episode_len_mean: 120.3\n",
      "  episode_reward_max: 232.0242532606151\n",
      "  episode_reward_mean: 164.7097027529512\n",
      "  episode_reward_min: -171.73010720933723\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 23082\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.273\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 2910000\n",
      "    num_steps_trained: 2910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.28708407282829285\n",
      "      kl: 0.008797633461654186\n",
      "      policy_loss: -8.509231520292815e-06\n",
      "      total_loss: 20.015487670898438\n",
      "      vf_explained_var: 0.9840742945671082\n",
      "      vf_loss: 20.01549530029297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.19934506714344025\n",
      "      kl: 0.01149578858166933\n",
      "      policy_loss: -0.00037979395710863173\n",
      "      total_loss: 16.850038528442383\n",
      "      vf_explained_var: 0.9855990409851074\n",
      "      vf_loss: 16.850418090820312\n",
      "    sample_time_ms: 19759.762\n",
      "    update_time_ms: 7.301\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.31183114234011\n",
      "    rl_1: 71.39787161061109\n",
      "  time_since_restore: 6786.2398364543915\n",
      "  time_this_iter_s: 23.330875873565674\n",
      "  time_total_s: 6786.2398364543915\n",
      "  timestamp: 1550887380\n",
      "  timesteps_since_restore: 2910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2910000\n",
      "  training_iteration: 291\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6786 s, 291 iter, 2910000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-03-23\n",
      "  done: false\n",
      "  episode_len_mean: 123.14\n",
      "  episode_reward_max: 236.32954708311004\n",
      "  episode_reward_mean: 171.84481127752403\n",
      "  episode_reward_min: -176.6283677083647\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 23168\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.533\n",
      "    load_time_ms: 2.547\n",
      "    num_steps_sampled: 2920000\n",
      "    num_steps_trained: 2920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.15275156497955322\n",
      "      kl: 0.01373322308063507\n",
      "      policy_loss: 0.0018094273982569575\n",
      "      total_loss: 21.968746185302734\n",
      "      vf_explained_var: 0.9798385500907898\n",
      "      vf_loss: 21.966938018798828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.07707642763853073\n",
      "      kl: 0.013970253057777882\n",
      "      policy_loss: 0.001943802461028099\n",
      "      total_loss: 18.321020126342773\n",
      "      vf_explained_var: 0.981126070022583\n",
      "      vf_loss: 18.319074630737305\n",
      "    sample_time_ms: 19794.2\n",
      "    update_time_ms: 7.113\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.16649976688464\n",
      "    rl_1: 73.67831151063936\n",
      "  time_since_restore: 6809.044775485992\n",
      "  time_this_iter_s: 22.804939031600952\n",
      "  time_total_s: 6809.044775485992\n",
      "  timestamp: 1550887403\n",
      "  timesteps_since_restore: 2920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2920000\n",
      "  training_iteration: 292\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6809 s, 292 iter, 2920000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-03-46\n",
      "  done: false\n",
      "  episode_len_mean: 117.89\n",
      "  episode_reward_max: 233.16449179592118\n",
      "  episode_reward_mean: 163.43371869570146\n",
      "  episode_reward_min: -154.29930177411487\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 23255\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.91\n",
      "    load_time_ms: 2.608\n",
      "    num_steps_sampled: 2930000\n",
      "    num_steps_trained: 2930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.19968973100185394\n",
      "      kl: 0.023453272879123688\n",
      "      policy_loss: 0.002783681731671095\n",
      "      total_loss: 56.21579360961914\n",
      "      vf_explained_var: 0.9620103240013123\n",
      "      vf_loss: 56.213016510009766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1997314989566803\n",
      "      kl: 0.006469232961535454\n",
      "      policy_loss: -3.264959013904445e-05\n",
      "      total_loss: 47.06438064575195\n",
      "      vf_explained_var: 0.9666656851768494\n",
      "      vf_loss: 47.06441116333008\n",
      "    sample_time_ms: 19830.423\n",
      "    update_time_ms: 7.677\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.77335214491781\n",
      "    rl_1: 71.66036655078368\n",
      "  time_since_restore: 6832.1736607551575\n",
      "  time_this_iter_s: 23.12888526916504\n",
      "  time_total_s: 6832.1736607551575\n",
      "  timestamp: 1550887426\n",
      "  timesteps_since_restore: 2930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2930000\n",
      "  training_iteration: 293\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6832 s, 293 iter, 2930000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-04-09\n",
      "  done: false\n",
      "  episode_len_mean: 117.48\n",
      "  episode_reward_max: 232.81226836421305\n",
      "  episode_reward_mean: 160.24257193113013\n",
      "  episode_reward_min: -180.3038029839238\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 23338\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.171\n",
      "    load_time_ms: 2.524\n",
      "    num_steps_sampled: 2940000\n",
      "    num_steps_trained: 2940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.22409187257289886\n",
      "      kl: 0.00797495897859335\n",
      "      policy_loss: -0.0014001947129145265\n",
      "      total_loss: 59.88933563232422\n",
      "      vf_explained_var: 0.9585330486297607\n",
      "      vf_loss: 59.890724182128906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1537439078092575\n",
      "      kl: 0.014182288199663162\n",
      "      policy_loss: -0.0021565468050539494\n",
      "      total_loss: 43.5679931640625\n",
      "      vf_explained_var: 0.9662023782730103\n",
      "      vf_loss: 43.57014846801758\n",
      "    sample_time_ms: 19822.776\n",
      "    update_time_ms: 7.66\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.23048224171166\n",
      "    rl_1: 68.01208968941849\n",
      "  time_since_restore: 6855.642676115036\n",
      "  time_this_iter_s: 23.46901535987854\n",
      "  time_total_s: 6855.642676115036\n",
      "  timestamp: 1550887449\n",
      "  timesteps_since_restore: 2940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2940000\n",
      "  training_iteration: 294\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6855 s, 294 iter, 2940000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-04-32\n",
      "  done: false\n",
      "  episode_len_mean: 114.77\n",
      "  episode_reward_max: 233.73918128023735\n",
      "  episode_reward_mean: 174.11907997767932\n",
      "  episode_reward_min: -129.29137027130292\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 23424\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.627\n",
      "    load_time_ms: 2.507\n",
      "    num_steps_sampled: 2950000\n",
      "    num_steps_trained: 2950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12192881107330322\n",
      "      kl: 0.00905864778906107\n",
      "      policy_loss: 0.00047898359480313957\n",
      "      total_loss: 31.52617073059082\n",
      "      vf_explained_var: 0.972407877445221\n",
      "      vf_loss: 31.525697708129883\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09389117360115051\n",
      "      kl: 0.014304573647677898\n",
      "      policy_loss: 0.0010646170703694224\n",
      "      total_loss: 27.775819778442383\n",
      "      vf_explained_var: 0.9736228585243225\n",
      "      vf_loss: 27.774749755859375\n",
      "    sample_time_ms: 19856.448\n",
      "    update_time_ms: 8.032\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.37205434270672\n",
      "    rl_1: 76.74702563497256\n",
      "  time_since_restore: 6878.524427890778\n",
      "  time_this_iter_s: 22.881751775741577\n",
      "  time_total_s: 6878.524427890778\n",
      "  timestamp: 1550887472\n",
      "  timesteps_since_restore: 2950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2950000\n",
      "  training_iteration: 295\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6878 s, 295 iter, 2950000 ts, 174 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-04-55\n",
      "  done: false\n",
      "  episode_len_mean: 107.68\n",
      "  episode_reward_max: 229.7977206977259\n",
      "  episode_reward_mean: 162.84696826945995\n",
      "  episode_reward_min: -150.10110968058606\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 23518\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.765\n",
      "    load_time_ms: 2.57\n",
      "    num_steps_sampled: 2960000\n",
      "    num_steps_trained: 2960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12802769243717194\n",
      "      kl: 0.010609091259539127\n",
      "      policy_loss: 0.0023380108177661896\n",
      "      total_loss: 57.199989318847656\n",
      "      vf_explained_var: 0.9565556645393372\n",
      "      vf_loss: 57.197654724121094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.05929058790206909\n",
      "      kl: 0.027227668091654778\n",
      "      policy_loss: 0.004614018369466066\n",
      "      total_loss: 51.032073974609375\n",
      "      vf_explained_var: 0.9514227509498596\n",
      "      vf_loss: 51.02745819091797\n",
      "    sample_time_ms: 19874.94\n",
      "    update_time_ms: 8.012\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.64549832491832\n",
      "    rl_1: 71.20146994454166\n",
      "  time_since_restore: 6901.476869344711\n",
      "  time_this_iter_s: 22.952441453933716\n",
      "  time_total_s: 6901.476869344711\n",
      "  timestamp: 1550887495\n",
      "  timesteps_since_restore: 2960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2960000\n",
      "  training_iteration: 296\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6901 s, 296 iter, 2960000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-05-19\n",
      "  done: false\n",
      "  episode_len_mean: 119.78\n",
      "  episode_reward_max: 228.12160187822622\n",
      "  episode_reward_mean: 160.05895279209787\n",
      "  episode_reward_min: -164.14741755350667\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 23600\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.046\n",
      "    load_time_ms: 2.582\n",
      "    num_steps_sampled: 2970000\n",
      "    num_steps_trained: 2970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2746768295764923\n",
      "      kl: 0.02299189381301403\n",
      "      policy_loss: 0.002948529552668333\n",
      "      total_loss: 35.199493408203125\n",
      "      vf_explained_var: 0.9752979874610901\n",
      "      vf_loss: 35.19654083251953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.23670117557048798\n",
      "      kl: 0.01089111901819706\n",
      "      policy_loss: -0.0009428556077182293\n",
      "      total_loss: 25.944000244140625\n",
      "      vf_explained_var: 0.9803289771080017\n",
      "      vf_loss: 25.944944381713867\n",
      "    sample_time_ms: 19945.928\n",
      "    update_time_ms: 8.207\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.37157765479176\n",
      "    rl_1: 68.6873751373061\n",
      "  time_since_restore: 6924.82998919487\n",
      "  time_this_iter_s: 23.35311985015869\n",
      "  time_total_s: 6924.82998919487\n",
      "  timestamp: 1550887519\n",
      "  timesteps_since_restore: 2970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2970000\n",
      "  training_iteration: 297\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6924 s, 297 iter, 2970000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-05-42\n",
      "  done: false\n",
      "  episode_len_mean: 114.77\n",
      "  episode_reward_max: 226.35506690920124\n",
      "  episode_reward_mean: 176.39571680043161\n",
      "  episode_reward_min: -164.26621969320195\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 23687\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.685\n",
      "    load_time_ms: 2.508\n",
      "    num_steps_sampled: 2980000\n",
      "    num_steps_trained: 2980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14837472140789032\n",
      "      kl: 0.01126748975366354\n",
      "      policy_loss: -0.0029134571086615324\n",
      "      total_loss: 23.381996154785156\n",
      "      vf_explained_var: 0.9778321981430054\n",
      "      vf_loss: 23.38490867614746\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.13306745886802673\n",
      "      kl: 0.01048438809812069\n",
      "      policy_loss: -0.00030816392973065376\n",
      "      total_loss: 20.349212646484375\n",
      "      vf_explained_var: 0.9777429103851318\n",
      "      vf_loss: 20.349523544311523\n",
      "    sample_time_ms: 19981.491\n",
      "    update_time_ms: 8.307\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 100.13913736331398\n",
      "    rl_1: 76.25657943711764\n",
      "  time_since_restore: 6947.89158987999\n",
      "  time_this_iter_s: 23.06160068511963\n",
      "  time_total_s: 6947.89158987999\n",
      "  timestamp: 1550887542\n",
      "  timesteps_since_restore: 2980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2980000\n",
      "  training_iteration: 298\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6947 s, 298 iter, 2980000 ts, 176 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-06-04\n",
      "  done: false\n",
      "  episode_len_mean: 105.23\n",
      "  episode_reward_max: 233.75599691360944\n",
      "  episode_reward_mean: 168.86110178860744\n",
      "  episode_reward_min: -155.68534686662917\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 23781\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.672\n",
      "    load_time_ms: 2.495\n",
      "    num_steps_sampled: 2990000\n",
      "    num_steps_trained: 2990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10540293157100677\n",
      "      kl: 0.01726449280977249\n",
      "      policy_loss: 0.003963180352002382\n",
      "      total_loss: 30.161903381347656\n",
      "      vf_explained_var: 0.9779431223869324\n",
      "      vf_loss: 30.157943725585938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.034518565982580185\n",
      "      kl: 0.010070257820189\n",
      "      policy_loss: 0.0011805284302681684\n",
      "      total_loss: 27.821407318115234\n",
      "      vf_explained_var: 0.9765907526016235\n",
      "      vf_loss: 27.82023048400879\n",
      "    sample_time_ms: 19964.492\n",
      "    update_time_ms: 7.914\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.868728311914\n",
      "    rl_1: 73.99237347669346\n",
      "  time_since_restore: 6970.549467086792\n",
      "  time_this_iter_s: 22.657877206802368\n",
      "  time_total_s: 6970.549467086792\n",
      "  timestamp: 1550887564\n",
      "  timesteps_since_restore: 2990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 2990000\n",
      "  training_iteration: 299\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6970 s, 299 iter, 2990000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-06-28\n",
      "  done: false\n",
      "  episode_len_mean: 103.5\n",
      "  episode_reward_max: 229.2233664600054\n",
      "  episode_reward_mean: 147.43828781608784\n",
      "  episode_reward_min: -169.3172626505655\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 23879\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.826\n",
      "    load_time_ms: 2.479\n",
      "    num_steps_sampled: 3000000\n",
      "    num_steps_trained: 3000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12684021890163422\n",
      "      kl: 0.03426942601799965\n",
      "      policy_loss: 0.00797396618872881\n",
      "      total_loss: 63.735538482666016\n",
      "      vf_explained_var: 0.9662156701087952\n",
      "      vf_loss: 63.7275505065918\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.042251236736774445\n",
      "      kl: 0.014763702638447285\n",
      "      policy_loss: -0.0017112883506342769\n",
      "      total_loss: 55.99386978149414\n",
      "      vf_explained_var: 0.963374674320221\n",
      "      vf_loss: 55.99557876586914\n",
      "    sample_time_ms: 20005.91\n",
      "    update_time_ms: 7.827\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.31936386409754\n",
      "    rl_1: 63.1189239519903\n",
      "  time_since_restore: 6994.091328620911\n",
      "  time_this_iter_s: 23.541861534118652\n",
      "  time_total_s: 6994.091328620911\n",
      "  timestamp: 1550887588\n",
      "  timesteps_since_restore: 3000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3000000\n",
      "  training_iteration: 300\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 6994 s, 300 iter, 3000000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-06-51\n",
      "  done: false\n",
      "  episode_len_mean: 107.43\n",
      "  episode_reward_max: 230.6480483220927\n",
      "  episode_reward_mean: 155.01550985446312\n",
      "  episode_reward_min: -175.4588841296848\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 23971\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.035\n",
      "    load_time_ms: 2.426\n",
      "    num_steps_sampled: 3010000\n",
      "    num_steps_trained: 3010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0479922890663147\n",
      "      kl: 0.019743554294109344\n",
      "      policy_loss: 0.011765413917601109\n",
      "      total_loss: 61.91652297973633\n",
      "      vf_explained_var: 0.9570639133453369\n",
      "      vf_loss: 61.904754638671875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0022209761664271355\n",
      "      kl: 0.010129808448255062\n",
      "      policy_loss: 0.00039670916157774627\n",
      "      total_loss: 46.671016693115234\n",
      "      vf_explained_var: 0.9618179202079773\n",
      "      vf_loss: 46.670623779296875\n",
      "    sample_time_ms: 19974.373\n",
      "    update_time_ms: 7.885\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.24674029046453\n",
      "    rl_1: 65.76876956399863\n",
      "  time_since_restore: 7017.018235206604\n",
      "  time_this_iter_s: 22.92690658569336\n",
      "  time_total_s: 7017.018235206604\n",
      "  timestamp: 1550887611\n",
      "  timesteps_since_restore: 3010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3010000\n",
      "  training_iteration: 301\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7017 s, 301 iter, 3010000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-07-15\n",
      "  done: false\n",
      "  episode_len_mean: 109.58\n",
      "  episode_reward_max: 230.6480483220927\n",
      "  episode_reward_mean: 155.99407046337208\n",
      "  episode_reward_min: -166.6624777680792\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 24062\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.171\n",
      "    load_time_ms: 2.398\n",
      "    num_steps_sampled: 3020000\n",
      "    num_steps_trained: 3020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.026627369225025177\n",
      "      kl: 0.012826123274862766\n",
      "      policy_loss: 0.0010956890182569623\n",
      "      total_loss: 38.72890853881836\n",
      "      vf_explained_var: 0.970605731010437\n",
      "      vf_loss: 38.727813720703125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.05790344998240471\n",
      "      kl: 0.014709994196891785\n",
      "      policy_loss: 3.68530563719105e-05\n",
      "      total_loss: 34.317466735839844\n",
      "      vf_explained_var: 0.9670007228851318\n",
      "      vf_loss: 34.31742477416992\n",
      "    sample_time_ms: 20060.411\n",
      "    update_time_ms: 7.857\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.44323797684456\n",
      "    rl_1: 66.55083248652754\n",
      "  time_since_restore: 7040.633937835693\n",
      "  time_this_iter_s: 23.615702629089355\n",
      "  time_total_s: 7040.633937835693\n",
      "  timestamp: 1550887635\n",
      "  timesteps_since_restore: 3020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3020000\n",
      "  training_iteration: 302\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7040 s, 302 iter, 3020000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-07-38\n",
      "  done: false\n",
      "  episode_len_mean: 108.31\n",
      "  episode_reward_max: 229.35922296722117\n",
      "  episode_reward_mean: 164.76667451816982\n",
      "  episode_reward_min: -155.52854652967008\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 24153\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.787\n",
      "    load_time_ms: 2.321\n",
      "    num_steps_sampled: 3030000\n",
      "    num_steps_trained: 3030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.04905002564191818\n",
      "      kl: 0.012752383016049862\n",
      "      policy_loss: -0.0015771881444379687\n",
      "      total_loss: 41.24763488769531\n",
      "      vf_explained_var: 0.9679282903671265\n",
      "      vf_loss: 41.249210357666016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.07286448031663895\n",
      "      kl: 0.012498806230723858\n",
      "      policy_loss: -0.0009921645978465676\n",
      "      total_loss: 34.230770111083984\n",
      "      vf_explained_var: 0.9698728919029236\n",
      "      vf_loss: 34.23176193237305\n",
      "    sample_time_ms: 20056.137\n",
      "    update_time_ms: 7.023\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.7174432713649\n",
      "    rl_1: 72.04923124680491\n",
      "  time_since_restore: 7063.885372400284\n",
      "  time_this_iter_s: 23.251434564590454\n",
      "  time_total_s: 7063.885372400284\n",
      "  timestamp: 1550887658\n",
      "  timesteps_since_restore: 3030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3030000\n",
      "  training_iteration: 303\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7063 s, 303 iter, 3030000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-08-01\n",
      "  done: false\n",
      "  episode_len_mean: 112.34\n",
      "  episode_reward_max: 231.5076020800158\n",
      "  episode_reward_mean: 159.84319368310696\n",
      "  episode_reward_min: -155.8709902832265\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 24242\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.825\n",
      "    load_time_ms: 2.34\n",
      "    num_steps_sampled: 3040000\n",
      "    num_steps_trained: 3040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0704377219080925\n",
      "      kl: 0.010349195450544357\n",
      "      policy_loss: 0.0008857567445375025\n",
      "      total_loss: 98.31497955322266\n",
      "      vf_explained_var: 0.9200700521469116\n",
      "      vf_loss: 98.31409454345703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14494922757148743\n",
      "      kl: 0.009324740618467331\n",
      "      policy_loss: -0.0003748185408767313\n",
      "      total_loss: 89.91580963134766\n",
      "      vf_explained_var: 0.9174447655677795\n",
      "      vf_loss: 89.91619110107422\n",
      "    sample_time_ms: 20006.152\n",
      "    update_time_ms: 7.206\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.21059164842933\n",
      "    rl_1: 69.63260203467757\n",
      "  time_since_restore: 7086.65797328949\n",
      "  time_this_iter_s: 22.772600889205933\n",
      "  time_total_s: 7086.65797328949\n",
      "  timestamp: 1550887681\n",
      "  timesteps_since_restore: 3040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3040000\n",
      "  training_iteration: 304\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7086 s, 304 iter, 3040000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-08-24\n",
      "  done: false\n",
      "  episode_len_mean: 123.85\n",
      "  episode_reward_max: 231.5076020800158\n",
      "  episode_reward_mean: 146.98788343122408\n",
      "  episode_reward_min: -170.90960658520106\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 24321\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.0\n",
      "    load_time_ms: 2.36\n",
      "    num_steps_sampled: 3050000\n",
      "    num_steps_trained: 3050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.31754377484321594\n",
      "      kl: 0.024864496663212776\n",
      "      policy_loss: 0.0030907681211829185\n",
      "      total_loss: 75.52256774902344\n",
      "      vf_explained_var: 0.9490150809288025\n",
      "      vf_loss: 75.51946258544922\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.21387383341789246\n",
      "      kl: 0.029574347659945488\n",
      "      policy_loss: 0.004599045496433973\n",
      "      total_loss: 63.27741241455078\n",
      "      vf_explained_var: 0.9547103643417358\n",
      "      vf_loss: 63.27281951904297\n",
      "    sample_time_ms: 20000.544\n",
      "    update_time_ms: 6.907\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.63914717146773\n",
      "    rl_1: 62.34873625975636\n",
      "  time_since_restore: 7109.51970410347\n",
      "  time_this_iter_s: 22.861730813980103\n",
      "  time_total_s: 7109.51970410347\n",
      "  timestamp: 1550887704\n",
      "  timesteps_since_restore: 3050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3050000\n",
      "  training_iteration: 305\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7109 s, 305 iter, 3050000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-08-47\n",
      "  done: false\n",
      "  episode_len_mean: 116.79\n",
      "  episode_reward_max: 231.68858413318483\n",
      "  episode_reward_mean: 167.4935631654584\n",
      "  episode_reward_min: -153.62114474672995\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 24407\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.796\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 3060000\n",
      "    num_steps_trained: 3060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0950305312871933\n",
      "      kl: 0.014041779562830925\n",
      "      policy_loss: -0.0021905647590756416\n",
      "      total_loss: 42.10845947265625\n",
      "      vf_explained_var: 0.967160165309906\n",
      "      vf_loss: 42.110652923583984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0857420414686203\n",
      "      kl: 0.01368215773254633\n",
      "      policy_loss: 0.0011838959762826562\n",
      "      total_loss: 37.712833404541016\n",
      "      vf_explained_var: 0.9647976756095886\n",
      "      vf_loss: 37.71165084838867\n",
      "    sample_time_ms: 20032.143\n",
      "    update_time_ms: 7.086\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.79132844515588\n",
      "    rl_1: 71.70223472030249\n",
      "  time_since_restore: 7132.796785116196\n",
      "  time_this_iter_s: 23.27708101272583\n",
      "  time_total_s: 7132.796785116196\n",
      "  timestamp: 1550887727\n",
      "  timesteps_since_restore: 3060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3060000\n",
      "  training_iteration: 306\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7132 s, 306 iter, 3060000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-09-10\n",
      "  done: false\n",
      "  episode_len_mean: 108.58\n",
      "  episode_reward_max: 231.68858413318483\n",
      "  episode_reward_mean: 164.75696219859114\n",
      "  episode_reward_min: -157.1144495452731\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 24502\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3096.361\n",
      "    load_time_ms: 2.336\n",
      "    num_steps_sampled: 3070000\n",
      "    num_steps_trained: 3070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11703058332204819\n",
      "      kl: 0.013568034395575523\n",
      "      policy_loss: 0.004132448695600033\n",
      "      total_loss: 55.1816520690918\n",
      "      vf_explained_var: 0.9586015343666077\n",
      "      vf_loss: 55.17751693725586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.015353350900113583\n",
      "      kl: 0.010865934193134308\n",
      "      policy_loss: -0.0006056400015950203\n",
      "      total_loss: 42.04736328125\n",
      "      vf_explained_var: 0.9607940912246704\n",
      "      vf_loss: 42.04796600341797\n",
      "    sample_time_ms: 19945.663\n",
      "    update_time_ms: 6.924\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.48711522403899\n",
      "    rl_1: 72.26984697455215\n",
      "  time_since_restore: 7155.519317626953\n",
      "  time_this_iter_s: 22.722532510757446\n",
      "  time_total_s: 7155.519317626953\n",
      "  timestamp: 1550887750\n",
      "  timesteps_since_restore: 3070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3070000\n",
      "  training_iteration: 307\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7155 s, 307 iter, 3070000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-09-33\n",
      "  done: false\n",
      "  episode_len_mean: 111.56\n",
      "  episode_reward_max: 228.8863540643289\n",
      "  episode_reward_mean: 173.30075398144777\n",
      "  episode_reward_min: -148.0588586173925\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 24592\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.759\n",
      "    load_time_ms: 2.39\n",
      "    num_steps_sampled: 3080000\n",
      "    num_steps_trained: 3080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.05512296408414841\n",
      "      kl: 0.011314377188682556\n",
      "      policy_loss: -0.000624517910182476\n",
      "      total_loss: 32.85027313232422\n",
      "      vf_explained_var: 0.9698623418807983\n",
      "      vf_loss: 32.85090255737305\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06458260118961334\n",
      "      kl: 0.015254257246851921\n",
      "      policy_loss: 0.0019076126627624035\n",
      "      total_loss: 27.341962814331055\n",
      "      vf_explained_var: 0.9715203642845154\n",
      "      vf_loss: 27.340059280395508\n",
      "    sample_time_ms: 19957.234\n",
      "    update_time_ms: 7.045\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.22670584106646\n",
      "    rl_1: 76.07404814038135\n",
      "  time_since_restore: 7178.625426530838\n",
      "  time_this_iter_s: 23.106108903884888\n",
      "  time_total_s: 7178.625426530838\n",
      "  timestamp: 1550887773\n",
      "  timesteps_since_restore: 3080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3080000\n",
      "  training_iteration: 308\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7178 s, 308 iter, 3080000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-09-56\n",
      "  done: false\n",
      "  episode_len_mean: 113.41\n",
      "  episode_reward_max: 225.44108869391556\n",
      "  episode_reward_mean: 160.7160862095708\n",
      "  episode_reward_min: -153.1699895199178\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 24678\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.877\n",
      "    load_time_ms: 2.454\n",
      "    num_steps_sampled: 3090000\n",
      "    num_steps_trained: 3090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09306811541318893\n",
      "      kl: 0.0178847499191761\n",
      "      policy_loss: 0.002925235079601407\n",
      "      total_loss: 45.3531494140625\n",
      "      vf_explained_var: 0.9664785861968994\n",
      "      vf_loss: 45.35022735595703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.11514528840780258\n",
      "      kl: 0.013411535881459713\n",
      "      policy_loss: -1.4163434570946265e-05\n",
      "      total_loss: 38.000152587890625\n",
      "      vf_explained_var: 0.968496561050415\n",
      "      vf_loss: 38.00016403198242\n",
      "    sample_time_ms: 19977.784\n",
      "    update_time_ms: 6.952\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.34640633251787\n",
      "    rl_1: 69.36967987705289\n",
      "  time_since_restore: 7201.494391441345\n",
      "  time_this_iter_s: 22.868964910507202\n",
      "  time_total_s: 7201.494391441345\n",
      "  timestamp: 1550887796\n",
      "  timesteps_since_restore: 3090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3090000\n",
      "  training_iteration: 309\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7201 s, 309 iter, 3090000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-10-19\n",
      "  done: false\n",
      "  episode_len_mean: 106.88\n",
      "  episode_reward_max: 231.05007383850244\n",
      "  episode_reward_mean: 154.403032802713\n",
      "  episode_reward_min: -160.5225018111231\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 24771\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.804\n",
      "    load_time_ms: 2.466\n",
      "    num_steps_sampled: 3100000\n",
      "    num_steps_trained: 3100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.02276615984737873\n",
      "      kl: 0.00949100311845541\n",
      "      policy_loss: 0.0006539073656313121\n",
      "      total_loss: 35.845333099365234\n",
      "      vf_explained_var: 0.9753531217575073\n",
      "      vf_loss: 35.84467315673828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12498799711465836\n",
      "      kl: 0.008260016329586506\n",
      "      policy_loss: 0.0013250124175101519\n",
      "      total_loss: 32.788124084472656\n",
      "      vf_explained_var: 0.972324788570404\n",
      "      vf_loss: 32.78679656982422\n",
      "    sample_time_ms: 19942.731\n",
      "    update_time_ms: 7.619\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.87977828839466\n",
      "    rl_1: 66.52325451431835\n",
      "  time_since_restore: 7224.6692435741425\n",
      "  time_this_iter_s: 23.17485213279724\n",
      "  time_total_s: 7224.6692435741425\n",
      "  timestamp: 1550887819\n",
      "  timesteps_since_restore: 3100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3100000\n",
      "  training_iteration: 310\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7224 s, 310 iter, 3100000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-10-42\n",
      "  done: false\n",
      "  episode_len_mean: 115.11\n",
      "  episode_reward_max: 228.73052682774664\n",
      "  episode_reward_mean: 161.60236350982154\n",
      "  episode_reward_min: -158.9223899879908\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 24859\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.006\n",
      "    load_time_ms: 2.508\n",
      "    num_steps_sampled: 3110000\n",
      "    num_steps_trained: 3110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0375448577105999\n",
      "      kl: 0.014037959277629852\n",
      "      policy_loss: 0.0012506339699029922\n",
      "      total_loss: 46.270877838134766\n",
      "      vf_explained_var: 0.9653394818305969\n",
      "      vf_loss: 46.269622802734375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08720728009939194\n",
      "      kl: 0.007503177039325237\n",
      "      policy_loss: 0.00033584696939215064\n",
      "      total_loss: 37.473453521728516\n",
      "      vf_explained_var: 0.9671391248703003\n",
      "      vf_loss: 37.47311782836914\n",
      "    sample_time_ms: 19979.06\n",
      "    update_time_ms: 7.724\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.08907654071228\n",
      "    rl_1: 68.51328696910925\n",
      "  time_since_restore: 7247.99036359787\n",
      "  time_this_iter_s: 23.321120023727417\n",
      "  time_total_s: 7247.99036359787\n",
      "  timestamp: 1550887842\n",
      "  timesteps_since_restore: 3110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3110000\n",
      "  training_iteration: 311\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7247 s, 311 iter, 3110000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-11-05\n",
      "  done: false\n",
      "  episode_len_mean: 119.1\n",
      "  episode_reward_max: 227.43739388941884\n",
      "  episode_reward_mean: 161.0576963980076\n",
      "  episode_reward_min: -168.100713560783\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 24942\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.276\n",
      "    load_time_ms: 2.498\n",
      "    num_steps_sampled: 3120000\n",
      "    num_steps_trained: 3120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.11459161341190338\n",
      "      kl: 0.014938059262931347\n",
      "      policy_loss: -0.0006636121543124318\n",
      "      total_loss: 39.22596740722656\n",
      "      vf_explained_var: 0.968080461025238\n",
      "      vf_loss: 39.226627349853516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.16806693375110626\n",
      "      kl: 0.012651735916733742\n",
      "      policy_loss: -0.002008097479119897\n",
      "      total_loss: 32.5018196105957\n",
      "      vf_explained_var: 0.9717034697532654\n",
      "      vf_loss: 32.50382614135742\n",
      "    sample_time_ms: 19884.057\n",
      "    update_time_ms: 7.835\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.16078001472926\n",
      "    rl_1: 68.89691638327832\n",
      "  time_since_restore: 7270.708540916443\n",
      "  time_this_iter_s: 22.718177318572998\n",
      "  time_total_s: 7270.708540916443\n",
      "  timestamp: 1550887865\n",
      "  timesteps_since_restore: 3120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3120000\n",
      "  training_iteration: 312\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7270 s, 312 iter, 3120000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-11-28\n",
      "  done: false\n",
      "  episode_len_mean: 113.63\n",
      "  episode_reward_max: 227.7630186569319\n",
      "  episode_reward_mean: 166.84905520457107\n",
      "  episode_reward_min: -169.28968231049\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 25029\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.967\n",
      "    load_time_ms: 2.526\n",
      "    num_steps_sampled: 3130000\n",
      "    num_steps_trained: 3130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.04831608757376671\n",
      "      kl: 0.015106537379324436\n",
      "      policy_loss: 0.0005267055239528418\n",
      "      total_loss: 44.10570526123047\n",
      "      vf_explained_var: 0.9660281538963318\n",
      "      vf_loss: 44.10518264770508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12291787564754486\n",
      "      kl: 0.01011630054563284\n",
      "      policy_loss: -0.0023971896152943373\n",
      "      total_loss: 39.360591888427734\n",
      "      vf_explained_var: 0.965679943561554\n",
      "      vf_loss: 39.36299133300781\n",
      "    sample_time_ms: 19826.908\n",
      "    update_time_ms: 7.911\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.50999716381737\n",
      "    rl_1: 72.3390580407537\n",
      "  time_since_restore: 7293.23735165596\n",
      "  time_this_iter_s: 22.528810739517212\n",
      "  time_total_s: 7293.23735165596\n",
      "  timestamp: 1550887888\n",
      "  timesteps_since_restore: 3130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3130000\n",
      "  training_iteration: 313\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7293 s, 313 iter, 3130000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-11-51\n",
      "  done: false\n",
      "  episode_len_mean: 112.15\n",
      "  episode_reward_max: 222.54524461288506\n",
      "  episode_reward_mean: 158.713727064354\n",
      "  episode_reward_min: -163.53066822068428\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 25118\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.961\n",
      "    load_time_ms: 2.48\n",
      "    num_steps_sampled: 3140000\n",
      "    num_steps_trained: 3140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.009034291841089725\n",
      "      kl: 0.0663086324930191\n",
      "      policy_loss: 0.01298949308693409\n",
      "      total_loss: 76.3240737915039\n",
      "      vf_explained_var: 0.9448766708374023\n",
      "      vf_loss: 76.31108093261719\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06811563670635223\n",
      "      kl: 0.01991180330514908\n",
      "      policy_loss: -0.0055882432498037815\n",
      "      total_loss: 67.39410400390625\n",
      "      vf_explained_var: 0.943602442741394\n",
      "      vf_loss: 67.39970397949219\n",
      "    sample_time_ms: 19869.022\n",
      "    update_time_ms: 7.835\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.45439146632523\n",
      "    rl_1: 67.25933559802878\n",
      "  time_since_restore: 7316.396855354309\n",
      "  time_this_iter_s: 23.159503698349\n",
      "  time_total_s: 7316.396855354309\n",
      "  timestamp: 1550887911\n",
      "  timesteps_since_restore: 3140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3140000\n",
      "  training_iteration: 314\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7316 s, 314 iter, 3140000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-12-14\n",
      "  done: false\n",
      "  episode_len_mean: 115.81\n",
      "  episode_reward_max: 229.73851288710551\n",
      "  episode_reward_mean: 152.1340922571445\n",
      "  episode_reward_min: -164.861141860234\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 25206\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.215\n",
      "    load_time_ms: 2.476\n",
      "    num_steps_sampled: 3150000\n",
      "    num_steps_trained: 3150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.046557072550058365\n",
      "      kl: 0.016954582184553146\n",
      "      policy_loss: 0.003231598297134042\n",
      "      total_loss: 51.62412643432617\n",
      "      vf_explained_var: 0.9573472738265991\n",
      "      vf_loss: 51.62089538574219\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.13086122274398804\n",
      "      kl: 0.022060176357626915\n",
      "      policy_loss: -0.0020165725145488977\n",
      "      total_loss: 40.7500114440918\n",
      "      vf_explained_var: 0.9596729874610901\n",
      "      vf_loss: 40.75202941894531\n",
      "    sample_time_ms: 19878.193\n",
      "    update_time_ms: 7.794\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.29318900029519\n",
      "    rl_1: 62.84090325684931\n",
      "  time_since_restore: 7339.413300514221\n",
      "  time_this_iter_s: 23.01644515991211\n",
      "  time_total_s: 7339.413300514221\n",
      "  timestamp: 1550887934\n",
      "  timesteps_since_restore: 3150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3150000\n",
      "  training_iteration: 315\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7339 s, 315 iter, 3150000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-12-37\n",
      "  done: false\n",
      "  episode_len_mean: 115.95\n",
      "  episode_reward_max: 231.38093122987948\n",
      "  episode_reward_mean: 164.86876455661795\n",
      "  episode_reward_min: -156.85068586591166\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 25294\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.158\n",
      "    load_time_ms: 2.354\n",
      "    num_steps_sampled: 3160000\n",
      "    num_steps_trained: 3160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.04135177284479141\n",
      "      kl: 0.0537327378988266\n",
      "      policy_loss: 0.0030493021477013826\n",
      "      total_loss: 37.04784393310547\n",
      "      vf_explained_var: 0.9690189957618713\n",
      "      vf_loss: 37.04479217529297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.07862107455730438\n",
      "      kl: 0.009976116009056568\n",
      "      policy_loss: 0.001844407874159515\n",
      "      total_loss: 31.808406829833984\n",
      "      vf_explained_var: 0.9691323637962341\n",
      "      vf_loss: 31.80655860900879\n",
      "    sample_time_ms: 19819.678\n",
      "    update_time_ms: 7.73\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.08317711102231\n",
      "    rl_1: 70.78558744559565\n",
      "  time_since_restore: 7362.246649980545\n",
      "  time_this_iter_s: 22.833349466323853\n",
      "  time_total_s: 7362.246649980545\n",
      "  timestamp: 1550887957\n",
      "  timesteps_since_restore: 3160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3160000\n",
      "  training_iteration: 316\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7362 s, 316 iter, 3160000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-13-00\n",
      "  done: false\n",
      "  episode_len_mean: 116.39\n",
      "  episode_reward_max: 228.80492623834934\n",
      "  episode_reward_mean: 162.1153953631456\n",
      "  episode_reward_min: -148.4542709437198\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 25380\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.907\n",
      "    load_time_ms: 2.421\n",
      "    num_steps_sampled: 3170000\n",
      "    num_steps_trained: 3170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08338088542222977\n",
      "      kl: 0.015046526677906513\n",
      "      policy_loss: 0.0012662861263379455\n",
      "      total_loss: 63.689491271972656\n",
      "      vf_explained_var: 0.9469376802444458\n",
      "      vf_loss: 63.688232421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.10060703754425049\n",
      "      kl: 0.018194327130913734\n",
      "      policy_loss: 0.004455476067960262\n",
      "      total_loss: 54.149871826171875\n",
      "      vf_explained_var: 0.9500085711479187\n",
      "      vf_loss: 54.145408630371094\n",
      "    sample_time_ms: 19907.36\n",
      "    update_time_ms: 8.072\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.98659369886809\n",
      "    rl_1: 70.1288016642775\n",
      "  time_since_restore: 7385.618682861328\n",
      "  time_this_iter_s: 23.37203288078308\n",
      "  time_total_s: 7385.618682861328\n",
      "  timestamp: 1550887980\n",
      "  timesteps_since_restore: 3170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3170000\n",
      "  training_iteration: 317\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7385 s, 317 iter, 3170000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-13-24\n",
      "  done: false\n",
      "  episode_len_mean: 111.45\n",
      "  episode_reward_max: 227.00661488900852\n",
      "  episode_reward_mean: 151.8964879972194\n",
      "  episode_reward_min: -163.5430061342225\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 25468\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.279\n",
      "    load_time_ms: 2.404\n",
      "    num_steps_sampled: 3180000\n",
      "    num_steps_trained: 3180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.020746925845742226\n",
      "      kl: 0.018733076751232147\n",
      "      policy_loss: -0.000885230430867523\n",
      "      total_loss: 50.18881607055664\n",
      "      vf_explained_var: 0.968267560005188\n",
      "      vf_loss: 50.189697265625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1236642450094223\n",
      "      kl: 0.010393877513706684\n",
      "      policy_loss: 3.323966666357592e-05\n",
      "      total_loss: 42.56947708129883\n",
      "      vf_explained_var: 0.9706481695175171\n",
      "      vf_loss: 42.5694465637207\n",
      "    sample_time_ms: 19957.065\n",
      "    update_time_ms: 7.928\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.7502821120629\n",
      "    rl_1: 65.1462058851565\n",
      "  time_since_restore: 7409.232711553574\n",
      "  time_this_iter_s: 23.614028692245483\n",
      "  time_total_s: 7409.232711553574\n",
      "  timestamp: 1550888004\n",
      "  timesteps_since_restore: 3180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3180000\n",
      "  training_iteration: 318\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7409 s, 318 iter, 3180000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-13-47\n",
      "  done: false\n",
      "  episode_len_mean: 103.75\n",
      "  episode_reward_max: 229.5926488364272\n",
      "  episode_reward_mean: 153.17430045698742\n",
      "  episode_reward_min: -153.97986101481814\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 25565\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.776\n",
      "    load_time_ms: 2.359\n",
      "    num_steps_sampled: 3190000\n",
      "    num_steps_trained: 3190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17718620598316193\n",
      "      kl: 0.009947949089109898\n",
      "      policy_loss: 0.0007220115512609482\n",
      "      total_loss: 76.87933349609375\n",
      "      vf_explained_var: 0.9613507390022278\n",
      "      vf_loss: 76.87861633300781\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.026649264618754387\n",
      "      kl: 0.014107045717537403\n",
      "      policy_loss: 0.001532860449515283\n",
      "      total_loss: 66.36478424072266\n",
      "      vf_explained_var: 0.9589767456054688\n",
      "      vf_loss: 66.36325073242188\n",
      "    sample_time_ms: 19975.983\n",
      "    update_time_ms: 7.878\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.14873616937945\n",
      "    rl_1: 66.02556428760799\n",
      "  time_since_restore: 7432.271550893784\n",
      "  time_this_iter_s: 23.03883934020996\n",
      "  time_total_s: 7432.271550893784\n",
      "  timestamp: 1550888027\n",
      "  timesteps_since_restore: 3190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3190000\n",
      "  training_iteration: 319\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7432 s, 319 iter, 3190000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-14-10\n",
      "  done: false\n",
      "  episode_len_mean: 118.38\n",
      "  episode_reward_max: 229.94406244998655\n",
      "  episode_reward_mean: 159.65347088648195\n",
      "  episode_reward_min: -137.13375631744182\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 25648\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.526\n",
      "    load_time_ms: 2.388\n",
      "    num_steps_sampled: 3200000\n",
      "    num_steps_trained: 3200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1145700067281723\n",
      "      kl: 0.009413211606442928\n",
      "      policy_loss: 0.0006006956100463867\n",
      "      total_loss: 58.240196228027344\n",
      "      vf_explained_var: 0.9549407958984375\n",
      "      vf_loss: 58.23959732055664\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.07012669742107391\n",
      "      kl: 0.010229806415736675\n",
      "      policy_loss: 0.00012358334788586944\n",
      "      total_loss: 47.59473419189453\n",
      "      vf_explained_var: 0.9600433111190796\n",
      "      vf_loss: 47.59461212158203\n",
      "    sample_time_ms: 19999.439\n",
      "    update_time_ms: 7.391\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.52830816311668\n",
      "    rl_1: 68.1251627233653\n",
      "  time_since_restore: 7455.677805900574\n",
      "  time_this_iter_s: 23.40625500679016\n",
      "  time_total_s: 7455.677805900574\n",
      "  timestamp: 1550888050\n",
      "  timesteps_since_restore: 3200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3200000\n",
      "  training_iteration: 320\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7455 s, 320 iter, 3200000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-14-34\n",
      "  done: false\n",
      "  episode_len_mean: 110.18\n",
      "  episode_reward_max: 230.11233407323073\n",
      "  episode_reward_mean: 152.66462446776498\n",
      "  episode_reward_min: -156.43772412459987\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 25738\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.735\n",
      "    load_time_ms: 2.435\n",
      "    num_steps_sampled: 3210000\n",
      "    num_steps_trained: 3210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.056000128388404846\n",
      "      kl: 3.9844963550567627\n",
      "      policy_loss: 0.06661902368068695\n",
      "      total_loss: 52.961631774902344\n",
      "      vf_explained_var: 0.9640477299690247\n",
      "      vf_loss: 52.8950080871582\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.11723770201206207\n",
      "      kl: 0.00753813749179244\n",
      "      policy_loss: 4.51754494861234e-05\n",
      "      total_loss: 42.82164001464844\n",
      "      vf_explained_var: 0.9679708480834961\n",
      "      vf_loss: 42.82159423828125\n",
      "    sample_time_ms: 20001.297\n",
      "    update_time_ms: 7.269\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.23104065007547\n",
      "    rl_1: 66.43358381768951\n",
      "  time_since_restore: 7478.979489564896\n",
      "  time_this_iter_s: 23.3016836643219\n",
      "  time_total_s: 7478.979489564896\n",
      "  timestamp: 1550888074\n",
      "  timesteps_since_restore: 3210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3210000\n",
      "  training_iteration: 321\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7478 s, 321 iter, 3210000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-14-57\n",
      "  done: false\n",
      "  episode_len_mean: 108.68\n",
      "  episode_reward_max: 225.9440907938028\n",
      "  episode_reward_mean: 166.93525065071023\n",
      "  episode_reward_min: -174.0600727496973\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 25830\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.007\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 3220000\n",
      "    num_steps_trained: 3220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0629563182592392\n",
      "      kl: 0.00978141836822033\n",
      "      policy_loss: -0.0019013052806258202\n",
      "      total_loss: 83.5464096069336\n",
      "      vf_explained_var: 0.9315486550331116\n",
      "      vf_loss: 83.54832458496094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.03795580938458443\n",
      "      kl: 0.01768994890153408\n",
      "      policy_loss: -0.0006110802642069757\n",
      "      total_loss: 63.42224884033203\n",
      "      vf_explained_var: 0.9412978887557983\n",
      "      vf_loss: 63.42285919189453\n",
      "    sample_time_ms: 20032.277\n",
      "    update_time_ms: 7.198\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.99060644092722\n",
      "    rl_1: 73.94464420978302\n",
      "  time_since_restore: 7501.979436159134\n",
      "  time_this_iter_s: 22.99994659423828\n",
      "  time_total_s: 7501.979436159134\n",
      "  timestamp: 1550888097\n",
      "  timesteps_since_restore: 3220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3220000\n",
      "  training_iteration: 322\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7501 s, 322 iter, 3220000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-15-20\n",
      "  done: false\n",
      "  episode_len_mean: 127.14\n",
      "  episode_reward_max: 228.24212342307652\n",
      "  episode_reward_mean: 166.8998910236419\n",
      "  episode_reward_min: -155.63523846028997\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 25908\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.497\n",
      "    load_time_ms: 2.404\n",
      "    num_steps_sampled: 3230000\n",
      "    num_steps_trained: 3230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.28886520862579346\n",
      "      kl: 0.005835627671331167\n",
      "      policy_loss: 0.0001081449881894514\n",
      "      total_loss: 39.8208122253418\n",
      "      vf_explained_var: 0.9690481424331665\n",
      "      vf_loss: 39.82070541381836\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.21754780411720276\n",
      "      kl: 0.009186659008264542\n",
      "      policy_loss: 0.0007216045050881803\n",
      "      total_loss: 29.931903839111328\n",
      "      vf_explained_var: 0.9756656289100647\n",
      "      vf_loss: 29.931182861328125\n",
      "    sample_time_ms: 20096.045\n",
      "    update_time_ms: 7.284\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.59534870301184\n",
      "    rl_1: 72.30454232063008\n",
      "  time_since_restore: 7525.143858194351\n",
      "  time_this_iter_s: 23.164422035217285\n",
      "  time_total_s: 7525.143858194351\n",
      "  timestamp: 1550888120\n",
      "  timesteps_since_restore: 3230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3230000\n",
      "  training_iteration: 323\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7525 s, 323 iter, 3230000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-15-43\n",
      "  done: false\n",
      "  episode_len_mean: 118.71\n",
      "  episode_reward_max: 229.81028789391172\n",
      "  episode_reward_mean: 145.66455761139457\n",
      "  episode_reward_min: -168.0323871323223\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 25994\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.784\n",
      "    load_time_ms: 2.399\n",
      "    num_steps_sampled: 3240000\n",
      "    num_steps_trained: 3240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.07237647473812103\n",
      "      kl: 0.008753434754908085\n",
      "      policy_loss: -0.0010563108371570706\n",
      "      total_loss: 86.79470825195312\n",
      "      vf_explained_var: 0.9525242447853088\n",
      "      vf_loss: 86.79576873779297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.050818607211112976\n",
      "      kl: 0.011464233510196209\n",
      "      policy_loss: 0.0019066184759140015\n",
      "      total_loss: 70.26302337646484\n",
      "      vf_explained_var: 0.9537835717201233\n",
      "      vf_loss: 70.2611083984375\n",
      "    sample_time_ms: 20057.22\n",
      "    update_time_ms: 7.601\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.03280286998914\n",
      "    rl_1: 59.63175474140539\n",
      "  time_since_restore: 7547.941071987152\n",
      "  time_this_iter_s: 22.797213792800903\n",
      "  time_total_s: 7547.941071987152\n",
      "  timestamp: 1550888143\n",
      "  timesteps_since_restore: 3240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3240000\n",
      "  training_iteration: 324\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7547 s, 324 iter, 3240000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-16-06\n",
      "  done: false\n",
      "  episode_len_mean: 110.62\n",
      "  episode_reward_max: 234.05130259052484\n",
      "  episode_reward_mean: 151.77843474071398\n",
      "  episode_reward_min: -168.0323871323223\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 26085\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3057.055\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 3250000\n",
      "    num_steps_trained: 3250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.00014308496611192822\n",
      "      kl: 0.012229465879499912\n",
      "      policy_loss: -0.0029130978509783745\n",
      "      total_loss: 79.25535583496094\n",
      "      vf_explained_var: 0.9441153407096863\n",
      "      vf_loss: 79.25827026367188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09591002762317657\n",
      "      kl: 0.014429912902414799\n",
      "      policy_loss: 0.0013299364363774657\n",
      "      total_loss: 65.9824447631836\n",
      "      vf_explained_var: 0.9419122338294983\n",
      "      vf_loss: 65.98111724853516\n",
      "    sample_time_ms: 20094.834\n",
      "    update_time_ms: 7.96\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.40083690691117\n",
      "    rl_1: 63.37759783380278\n",
      "  time_since_restore: 7571.223718166351\n",
      "  time_this_iter_s: 23.28264617919922\n",
      "  time_total_s: 7571.223718166351\n",
      "  timestamp: 1550888166\n",
      "  timesteps_since_restore: 3250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3250000\n",
      "  training_iteration: 325\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7571 s, 325 iter, 3250000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-16-29\n",
      "  done: false\n",
      "  episode_len_mean: 114.89\n",
      "  episode_reward_max: 234.05130259052484\n",
      "  episode_reward_mean: 144.85851206154612\n",
      "  episode_reward_min: -164.3066869233566\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 26168\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3043.283\n",
      "    load_time_ms: 2.46\n",
      "    num_steps_sampled: 3260000\n",
      "    num_steps_trained: 3260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14901813864707947\n",
      "      kl: 0.009950811974704266\n",
      "      policy_loss: 0.0014425585977733135\n",
      "      total_loss: 57.97479248046875\n",
      "      vf_explained_var: 0.962773859500885\n",
      "      vf_loss: 57.97334671020508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.17641864717006683\n",
      "      kl: 0.008593331091105938\n",
      "      policy_loss: -0.0014965033624321222\n",
      "      total_loss: 49.77604675292969\n",
      "      vf_explained_var: 0.9617142081260681\n",
      "      vf_loss: 49.77753448486328\n",
      "    sample_time_ms: 20065.346\n",
      "    update_time_ms: 7.763\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.8215089594871\n",
      "    rl_1: 59.03700310205902\n",
      "  time_since_restore: 7593.618043661118\n",
      "  time_this_iter_s: 22.394325494766235\n",
      "  time_total_s: 7593.618043661118\n",
      "  timestamp: 1550888189\n",
      "  timesteps_since_restore: 3260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3260000\n",
      "  training_iteration: 326\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7593 s, 326 iter, 3260000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-16-52\n",
      "  done: false\n",
      "  episode_len_mean: 112.79\n",
      "  episode_reward_max: 229.50027778885666\n",
      "  episode_reward_mean: 164.02622251054487\n",
      "  episode_reward_min: -151.5946370274475\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 26260\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3042.908\n",
      "    load_time_ms: 2.412\n",
      "    num_steps_sampled: 3270000\n",
      "    num_steps_trained: 3270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17843841016292572\n",
      "      kl: 0.03314467519521713\n",
      "      policy_loss: 0.001911323401145637\n",
      "      total_loss: 50.134063720703125\n",
      "      vf_explained_var: 0.9599195718765259\n",
      "      vf_loss: 50.13216018676758\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.04444693773984909\n",
      "      kl: 0.013704778626561165\n",
      "      policy_loss: -0.0017114778747782111\n",
      "      total_loss: 44.242164611816406\n",
      "      vf_explained_var: 0.9557762145996094\n",
      "      vf_loss: 44.243873596191406\n",
      "    sample_time_ms: 20030.976\n",
      "    update_time_ms: 7.369\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.3449066093927\n",
      "    rl_1: 69.68131590115216\n",
      "  time_since_restore: 7616.6367354393005\n",
      "  time_this_iter_s: 23.018691778182983\n",
      "  time_total_s: 7616.6367354393005\n",
      "  timestamp: 1550888212\n",
      "  timesteps_since_restore: 3270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3270000\n",
      "  training_iteration: 327\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7616 s, 327 iter, 3270000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-17-15\n",
      "  done: false\n",
      "  episode_len_mean: 108.4\n",
      "  episode_reward_max: 230.5513262143449\n",
      "  episode_reward_mean: 158.47525805552957\n",
      "  episode_reward_min: -149.2690600644532\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 26351\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3043.973\n",
      "    load_time_ms: 2.389\n",
      "    num_steps_sampled: 3280000\n",
      "    num_steps_trained: 3280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.14564402401447296\n",
      "      kl: 0.016431931406259537\n",
      "      policy_loss: 0.0007668458274565637\n",
      "      total_loss: 99.94190979003906\n",
      "      vf_explained_var: 0.9291208982467651\n",
      "      vf_loss: 99.94114685058594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.01981188729405403\n",
      "      kl: 0.008522487245500088\n",
      "      policy_loss: -0.001980437198653817\n",
      "      total_loss: 83.94718170166016\n",
      "      vf_explained_var: 0.9223101735115051\n",
      "      vf_loss: 83.94916534423828\n",
      "    sample_time_ms: 19948.362\n",
      "    update_time_ms: 7.555\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.30712012885252\n",
      "    rl_1: 67.16813792667705\n",
      "  time_since_restore: 7639.436039447784\n",
      "  time_this_iter_s: 22.799304008483887\n",
      "  time_total_s: 7639.436039447784\n",
      "  timestamp: 1550888235\n",
      "  timesteps_since_restore: 3280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3280000\n",
      "  training_iteration: 328\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7639 s, 328 iter, 3280000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-17-38\n",
      "  done: false\n",
      "  episode_len_mean: 123.12\n",
      "  episode_reward_max: 225.41876854187004\n",
      "  episode_reward_mean: 157.71531744286406\n",
      "  episode_reward_min: -170.27089006024258\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 26432\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.983\n",
      "    load_time_ms: 2.381\n",
      "    num_steps_sampled: 3290000\n",
      "    num_steps_trained: 3290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2273796945810318\n",
      "      kl: 0.01796673983335495\n",
      "      policy_loss: 0.0014610221842303872\n",
      "      total_loss: 61.87690353393555\n",
      "      vf_explained_var: 0.950810432434082\n",
      "      vf_loss: 61.87544631958008\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.22810691595077515\n",
      "      kl: 0.015321576967835426\n",
      "      policy_loss: -0.0008490763721056283\n",
      "      total_loss: 47.44826126098633\n",
      "      vf_explained_var: 0.9574334621429443\n",
      "      vf_loss: 47.4491081237793\n",
      "    sample_time_ms: 19965.868\n",
      "    update_time_ms: 7.728\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.02462799787273\n",
      "    rl_1: 66.69068944499134\n",
      "  time_since_restore: 7662.843186378479\n",
      "  time_this_iter_s: 23.40714693069458\n",
      "  time_total_s: 7662.843186378479\n",
      "  timestamp: 1550888258\n",
      "  timesteps_since_restore: 3290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3290000\n",
      "  training_iteration: 329\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7662 s, 329 iter, 3290000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-18-01\n",
      "  done: false\n",
      "  episode_len_mean: 127.44\n",
      "  episode_reward_max: 225.41876854187004\n",
      "  episode_reward_mean: 167.61278720636955\n",
      "  episode_reward_min: -163.41627314131864\n",
      "  episodes_this_iter: 78\n",
      "  episodes_total: 26510\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.101\n",
      "    load_time_ms: 2.412\n",
      "    num_steps_sampled: 3300000\n",
      "    num_steps_trained: 3300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.29116931557655334\n",
      "      kl: 0.024764621630311012\n",
      "      policy_loss: 0.003887081751599908\n",
      "      total_loss: 21.81974983215332\n",
      "      vf_explained_var: 0.9788277745246887\n",
      "      vf_loss: 21.81586265563965\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2940916419029236\n",
      "      kl: 0.01283828541636467\n",
      "      policy_loss: -0.0005812612362205982\n",
      "      total_loss: 15.983010292053223\n",
      "      vf_explained_var: 0.9838681221008301\n",
      "      vf_loss: 15.983589172363281\n",
      "    sample_time_ms: 19935.456\n",
      "    update_time_ms: 7.537\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.51259640822938\n",
      "    rl_1: 73.10019079814013\n",
      "  time_since_restore: 7685.973762512207\n",
      "  time_this_iter_s: 23.130576133728027\n",
      "  time_total_s: 7685.973762512207\n",
      "  timestamp: 1550888281\n",
      "  timesteps_since_restore: 3300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3300000\n",
      "  training_iteration: 330\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7685 s, 330 iter, 3300000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-18-24\n",
      "  done: false\n",
      "  episode_len_mean: 111.31\n",
      "  episode_reward_max: 228.42377225341386\n",
      "  episode_reward_mean: 173.67631254252035\n",
      "  episode_reward_min: -126.08239769161932\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 26595\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.589\n",
      "    load_time_ms: 2.319\n",
      "    num_steps_sampled: 3310000\n",
      "    num_steps_trained: 3310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.020872002467513084\n",
      "      kl: 0.055502984672784805\n",
      "      policy_loss: 0.021861279383301735\n",
      "      total_loss: 15.56350040435791\n",
      "      vf_explained_var: 0.9842106699943542\n",
      "      vf_loss: 15.54163646697998\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08595772832632065\n",
      "      kl: 0.010089918039739132\n",
      "      policy_loss: -0.00033807524596340954\n",
      "      total_loss: 13.392290115356445\n",
      "      vf_explained_var: 0.9840220212936401\n",
      "      vf_loss: 13.39262866973877\n",
      "    sample_time_ms: 19902.338\n",
      "    update_time_ms: 7.433\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.79334580057375\n",
      "    rl_1: 74.88296674194655\n",
      "  time_since_restore: 7708.960340261459\n",
      "  time_this_iter_s: 22.98657774925232\n",
      "  time_total_s: 7708.960340261459\n",
      "  timestamp: 1550888304\n",
      "  timesteps_since_restore: 3310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3310000\n",
      "  training_iteration: 331\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7708 s, 331 iter, 3310000 ts, 174 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-18-47\n",
      "  done: false\n",
      "  episode_len_mean: 126.16\n",
      "  episode_reward_max: 228.42377225341386\n",
      "  episode_reward_mean: 168.92928126608638\n",
      "  episode_reward_min: -162.69510515735573\n",
      "  episodes_this_iter: 79\n",
      "  episodes_total: 26674\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.731\n",
      "    load_time_ms: 2.34\n",
      "    num_steps_sampled: 3320000\n",
      "    num_steps_trained: 3320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.210103377699852\n",
      "      kl: 0.009382159449160099\n",
      "      policy_loss: -0.003228546818718314\n",
      "      total_loss: 18.98106575012207\n",
      "      vf_explained_var: 0.98153156042099\n",
      "      vf_loss: 18.98429298400879\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.18439655005931854\n",
      "      kl: 0.014221878722310066\n",
      "      policy_loss: -0.0012763409176841378\n",
      "      total_loss: 12.780817031860352\n",
      "      vf_explained_var: 0.9862202405929565\n",
      "      vf_loss: 12.78209400177002\n",
      "    sample_time_ms: 19863.421\n",
      "    update_time_ms: 7.515\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.11525158028824\n",
      "    rl_1: 71.81402968579813\n",
      "  time_since_restore: 7731.59703707695\n",
      "  time_this_iter_s: 22.636696815490723\n",
      "  time_total_s: 7731.59703707695\n",
      "  timestamp: 1550888327\n",
      "  timesteps_since_restore: 3320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3320000\n",
      "  training_iteration: 332\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7731 s, 332 iter, 3320000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-19-10\n",
      "  done: false\n",
      "  episode_len_mean: 108.43\n",
      "  episode_reward_max: 232.29651329890913\n",
      "  episode_reward_mean: 160.34709162231349\n",
      "  episode_reward_min: -173.3673155754425\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 26766\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.445\n",
      "    load_time_ms: 2.388\n",
      "    num_steps_sampled: 3330000\n",
      "    num_steps_trained: 3330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12104462087154388\n",
      "      kl: 0.03936313837766647\n",
      "      policy_loss: 0.006436766590923071\n",
      "      total_loss: 89.5379638671875\n",
      "      vf_explained_var: 0.9403451681137085\n",
      "      vf_loss: 89.53153228759766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.02044924721121788\n",
      "      kl: 0.01565100997686386\n",
      "      policy_loss: -0.0019247715827077627\n",
      "      total_loss: 75.6619873046875\n",
      "      vf_explained_var: 0.9395397901535034\n",
      "      vf_loss: 75.66390228271484\n",
      "    sample_time_ms: 19867.497\n",
      "    update_time_ms: 7.43\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.09551704249526\n",
      "    rl_1: 70.25157457981821\n",
      "  time_since_restore: 7754.81654548645\n",
      "  time_this_iter_s: 23.219508409500122\n",
      "  time_total_s: 7754.81654548645\n",
      "  timestamp: 1550888350\n",
      "  timesteps_since_restore: 3330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3330000\n",
      "  training_iteration: 333\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7754 s, 333 iter, 3330000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-19-33\n",
      "  done: false\n",
      "  episode_len_mean: 102.59\n",
      "  episode_reward_max: 225.37651199538968\n",
      "  episode_reward_mean: 167.00050902293412\n",
      "  episode_reward_min: -178.2891287223664\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 26865\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.925\n",
      "    load_time_ms: 2.377\n",
      "    num_steps_sampled: 3340000\n",
      "    num_steps_trained: 3340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.26674264669418335\n",
      "      kl: 0.017580263316631317\n",
      "      policy_loss: 0.0012505644699558616\n",
      "      total_loss: 34.862098693847656\n",
      "      vf_explained_var: 0.9754626750946045\n",
      "      vf_loss: 34.86084747314453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.026281772181391716\n",
      "      kl: 0.00674719363451004\n",
      "      policy_loss: -0.0018201894126832485\n",
      "      total_loss: 30.765884399414062\n",
      "      vf_explained_var: 0.9730252027511597\n",
      "      vf_loss: 30.7677059173584\n",
      "    sample_time_ms: 19894.61\n",
      "    update_time_ms: 7.157\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.36225664125318\n",
      "    rl_1: 72.6382523816809\n",
      "  time_since_restore: 7777.867488145828\n",
      "  time_this_iter_s: 23.05094265937805\n",
      "  time_total_s: 7777.867488145828\n",
      "  timestamp: 1550888373\n",
      "  timesteps_since_restore: 3340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3340000\n",
      "  training_iteration: 334\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7777 s, 334 iter, 3340000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-19-56\n",
      "  done: false\n",
      "  episode_len_mean: 116.76\n",
      "  episode_reward_max: 226.51590122159908\n",
      "  episode_reward_mean: 159.7803158649139\n",
      "  episode_reward_min: -158.53005437234805\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 26948\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.465\n",
      "    load_time_ms: 2.4\n",
      "    num_steps_sampled: 3350000\n",
      "    num_steps_trained: 3350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.13162362575531006\n",
      "      kl: 0.04606804624199867\n",
      "      policy_loss: 0.006964384112507105\n",
      "      total_loss: 33.80597686767578\n",
      "      vf_explained_var: 0.9742010831832886\n",
      "      vf_loss: 33.79901885986328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.18598774075508118\n",
      "      kl: 0.019958781078457832\n",
      "      policy_loss: 0.0007152205798774958\n",
      "      total_loss: 26.750240325927734\n",
      "      vf_explained_var: 0.9760717749595642\n",
      "      vf_loss: 26.74952507019043\n",
      "    sample_time_ms: 19873.016\n",
      "    update_time_ms: 6.852\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.37653799422864\n",
      "    rl_1: 68.40377787068527\n",
      "  time_since_restore: 7800.944279193878\n",
      "  time_this_iter_s: 23.076791048049927\n",
      "  time_total_s: 7800.944279193878\n",
      "  timestamp: 1550888396\n",
      "  timesteps_since_restore: 3350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3350000\n",
      "  training_iteration: 335\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7800 s, 335 iter, 3350000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-20-19\n",
      "  done: false\n",
      "  episode_len_mean: 104.36\n",
      "  episode_reward_max: 233.71796206245554\n",
      "  episode_reward_mean: 157.46865778804403\n",
      "  episode_reward_min: -176.00954306921753\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 27044\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.778\n",
      "    load_time_ms: 2.429\n",
      "    num_steps_sampled: 3360000\n",
      "    num_steps_trained: 3360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.13355092704296112\n",
      "      kl: 0.04615895450115204\n",
      "      policy_loss: 0.013317191042006016\n",
      "      total_loss: 38.85566711425781\n",
      "      vf_explained_var: 0.9729393124580383\n",
      "      vf_loss: 38.84234619140625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.05301491916179657\n",
      "      kl: 0.00787512119859457\n",
      "      policy_loss: -0.0006877154228277504\n",
      "      total_loss: 34.59600830078125\n",
      "      vf_explained_var: 0.972180187702179\n",
      "      vf_loss: 34.5966911315918\n",
      "    sample_time_ms: 19890.718\n",
      "    update_time_ms: 6.92\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.20200716518679\n",
      "    rl_1: 68.26665062285726\n",
      "  time_since_restore: 7823.53293967247\n",
      "  time_this_iter_s: 22.58866047859192\n",
      "  time_total_s: 7823.53293967247\n",
      "  timestamp: 1550888419\n",
      "  timesteps_since_restore: 3360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3360000\n",
      "  training_iteration: 336\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7823 s, 336 iter, 3360000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-20-42\n",
      "  done: false\n",
      "  episode_len_mean: 106.06\n",
      "  episode_reward_max: 229.93073484228623\n",
      "  episode_reward_mean: 157.79303169357144\n",
      "  episode_reward_min: -167.07937546263537\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 27138\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.268\n",
      "    load_time_ms: 2.488\n",
      "    num_steps_sampled: 3370000\n",
      "    num_steps_trained: 3370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.20391356945037842\n",
      "      kl: 0.024683121591806412\n",
      "      policy_loss: 0.002936269622296095\n",
      "      total_loss: 50.45558166503906\n",
      "      vf_explained_var: 0.9650520086288452\n",
      "      vf_loss: 50.4526481628418\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.03387739881873131\n",
      "      kl: 0.014224071055650711\n",
      "      policy_loss: -0.0018708992283791304\n",
      "      total_loss: 44.379173278808594\n",
      "      vf_explained_var: 0.9614914059638977\n",
      "      vf_loss: 44.38104248046875\n",
      "    sample_time_ms: 19865.164\n",
      "    update_time_ms: 7.114\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.45772894905797\n",
      "    rl_1: 66.33530274451347\n",
      "  time_since_restore: 7846.33812212944\n",
      "  time_this_iter_s: 22.805182456970215\n",
      "  time_total_s: 7846.33812212944\n",
      "  timestamp: 1550888442\n",
      "  timesteps_since_restore: 3370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3370000\n",
      "  training_iteration: 337\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7846 s, 337 iter, 3370000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-21-05\n",
      "  done: false\n",
      "  episode_len_mean: 105.24\n",
      "  episode_reward_max: 227.22593225081678\n",
      "  episode_reward_mean: 169.28933458913158\n",
      "  episode_reward_min: -182.27386481444165\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 27234\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.584\n",
      "    load_time_ms: 2.484\n",
      "    num_steps_sampled: 3380000\n",
      "    num_steps_trained: 3380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2648952007293701\n",
      "      kl: 0.020231138914823532\n",
      "      policy_loss: 0.00718667870387435\n",
      "      total_loss: 40.54718780517578\n",
      "      vf_explained_var: 0.9689602255821228\n",
      "      vf_loss: 40.540000915527344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.042010825127363205\n",
      "      kl: 0.009168670512735844\n",
      "      policy_loss: 0.00200858898460865\n",
      "      total_loss: 31.214248657226562\n",
      "      vf_explained_var: 0.971484363079071\n",
      "      vf_loss: 31.21224594116211\n",
      "    sample_time_ms: 19866.633\n",
      "    update_time_ms: 7.023\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.92735661798268\n",
      "    rl_1: 74.36197797114887\n",
      "  time_since_restore: 7869.1459584236145\n",
      "  time_this_iter_s: 22.807836294174194\n",
      "  time_total_s: 7869.1459584236145\n",
      "  timestamp: 1550888465\n",
      "  timesteps_since_restore: 3380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3380000\n",
      "  training_iteration: 338\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7869 s, 338 iter, 3380000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-21-28\n",
      "  done: false\n",
      "  episode_len_mean: 105.29\n",
      "  episode_reward_max: 226.72654712460812\n",
      "  episode_reward_mean: 149.92782086927596\n",
      "  episode_reward_min: -167.79479136786927\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 27328\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3059.987\n",
      "    load_time_ms: 2.533\n",
      "    num_steps_sampled: 3390000\n",
      "    num_steps_trained: 3390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11135771125555038\n",
      "      kl: 0.018536457791924477\n",
      "      policy_loss: -0.0023829254787415266\n",
      "      total_loss: 52.39657974243164\n",
      "      vf_explained_var: 0.9705381989479065\n",
      "      vf_loss: 52.398963928222656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09632205963134766\n",
      "      kl: 0.01835976354777813\n",
      "      policy_loss: 0.003288791049271822\n",
      "      total_loss: 47.4139518737793\n",
      "      vf_explained_var: 0.9676626920700073\n",
      "      vf_loss: 47.41066360473633\n",
      "    sample_time_ms: 19874.252\n",
      "    update_time_ms: 6.933\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.96186116926252\n",
      "    rl_1: 63.96595970001342\n",
      "  time_since_restore: 7892.473390579224\n",
      "  time_this_iter_s: 23.32743215560913\n",
      "  time_total_s: 7892.473390579224\n",
      "  timestamp: 1550888488\n",
      "  timesteps_since_restore: 3390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3390000\n",
      "  training_iteration: 339\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7892 s, 339 iter, 3390000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-21-51\n",
      "  done: false\n",
      "  episode_len_mean: 107.25\n",
      "  episode_reward_max: 224.40708975152913\n",
      "  episode_reward_mean: 162.35173790827363\n",
      "  episode_reward_min: -165.35825702685347\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 27418\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3058.441\n",
      "    load_time_ms: 2.524\n",
      "    num_steps_sampled: 3400000\n",
      "    num_steps_trained: 3400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.004967924207448959\n",
      "      kl: 0.012197884730994701\n",
      "      policy_loss: 0.000715395319275558\n",
      "      total_loss: 54.361717224121094\n",
      "      vf_explained_var: 0.9545180201530457\n",
      "      vf_loss: 54.36100769042969\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.14889952540397644\n",
      "      kl: 0.010204593650996685\n",
      "      policy_loss: -0.0005354902241379023\n",
      "      total_loss: 47.16893005371094\n",
      "      vf_explained_var: 0.9508447647094727\n",
      "      vf_loss: 47.169464111328125\n",
      "    sample_time_ms: 19858.112\n",
      "    update_time_ms: 7.008\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.50182998652808\n",
      "    rl_1: 69.84990792174553\n",
      "  time_since_restore: 7915.427375078201\n",
      "  time_this_iter_s: 22.95398449897766\n",
      "  time_total_s: 7915.427375078201\n",
      "  timestamp: 1550888511\n",
      "  timesteps_since_restore: 3400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3400000\n",
      "  training_iteration: 340\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7915 s, 340 iter, 3400000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-22-14\n",
      "  done: false\n",
      "  episode_len_mean: 126.18\n",
      "  episode_reward_max: 229.35889316757726\n",
      "  episode_reward_mean: 149.9764080845837\n",
      "  episode_reward_min: -165.35825702685347\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 27500\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.453\n",
      "    load_time_ms: 2.51\n",
      "    num_steps_sampled: 3410000\n",
      "    num_steps_trained: 3410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.2073848396539688\n",
      "      kl: 0.03003515675663948\n",
      "      policy_loss: 0.00553879514336586\n",
      "      total_loss: 59.26084899902344\n",
      "      vf_explained_var: 0.963976263999939\n",
      "      vf_loss: 59.25530242919922\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.17845270037651062\n",
      "      kl: 0.013094470836222172\n",
      "      policy_loss: 0.0005220198654569685\n",
      "      total_loss: 37.647239685058594\n",
      "      vf_explained_var: 0.971668541431427\n",
      "      vf_loss: 37.6467170715332\n",
      "    sample_time_ms: 19821.946\n",
      "    update_time_ms: 7.029\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.04151687257907\n",
      "    rl_1: 60.934891212004665\n",
      "  time_since_restore: 7938.119438648224\n",
      "  time_this_iter_s: 22.692063570022583\n",
      "  time_total_s: 7938.119438648224\n",
      "  timestamp: 1550888534\n",
      "  timesteps_since_restore: 3410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3410000\n",
      "  training_iteration: 341\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7938 s, 341 iter, 3410000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-22-37\n",
      "  done: false\n",
      "  episode_len_mean: 105.08\n",
      "  episode_reward_max: 226.76166142107795\n",
      "  episode_reward_mean: 173.3713818365879\n",
      "  episode_reward_min: -158.4028383634585\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 27596\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.578\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 3420000\n",
      "    num_steps_trained: 3420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19591805338859558\n",
      "      kl: 0.013571779243648052\n",
      "      policy_loss: 0.0009256471530534327\n",
      "      total_loss: 34.628448486328125\n",
      "      vf_explained_var: 0.971472442150116\n",
      "      vf_loss: 34.62752151489258\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.01172628067433834\n",
      "      kl: 0.010632366873323917\n",
      "      policy_loss: -0.0023198635317385197\n",
      "      total_loss: 29.37162971496582\n",
      "      vf_explained_var: 0.9685368537902832\n",
      "      vf_loss: 29.373950958251953\n",
      "    sample_time_ms: 19882.428\n",
      "    update_time_ms: 6.931\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.00337824011616\n",
      "    rl_1: 76.36800359647174\n",
      "  time_since_restore: 7961.528096914291\n",
      "  time_this_iter_s: 23.408658266067505\n",
      "  time_total_s: 7961.528096914291\n",
      "  timestamp: 1550888557\n",
      "  timesteps_since_restore: 3420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3420000\n",
      "  training_iteration: 342\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7961 s, 342 iter, 3420000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-23-00\n",
      "  done: false\n",
      "  episode_len_mean: 106.88\n",
      "  episode_reward_max: 229.01893293656602\n",
      "  episode_reward_mean: 161.35594890098528\n",
      "  episode_reward_min: -138.8912119570191\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 27689\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.522\n",
      "    load_time_ms: 2.511\n",
      "    num_steps_sampled: 3430000\n",
      "    num_steps_trained: 3430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08283691108226776\n",
      "      kl: 0.03933946415781975\n",
      "      policy_loss: 0.00659645302221179\n",
      "      total_loss: 51.41946792602539\n",
      "      vf_explained_var: 0.9643605351448059\n",
      "      vf_loss: 51.41286849975586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.04839400202035904\n",
      "      kl: 0.014197208918631077\n",
      "      policy_loss: 0.002470707055181265\n",
      "      total_loss: 41.204383850097656\n",
      "      vf_explained_var: 0.9619619846343994\n",
      "      vf_loss: 41.20191192626953\n",
      "    sample_time_ms: 19821.141\n",
      "    update_time_ms: 7.651\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.82127140744328\n",
      "    rl_1: 69.53467749354202\n",
      "  time_since_restore: 7984.130142450333\n",
      "  time_this_iter_s: 22.60204553604126\n",
      "  time_total_s: 7984.130142450333\n",
      "  timestamp: 1550888580\n",
      "  timesteps_since_restore: 3430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3430000\n",
      "  training_iteration: 343\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 7984 s, 343 iter, 3430000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-23-23\n",
      "  done: false\n",
      "  episode_len_mean: 111.41\n",
      "  episode_reward_max: 229.17339055485598\n",
      "  episode_reward_mean: 153.78049203164036\n",
      "  episode_reward_min: -150.4825335509259\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 27779\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.651\n",
      "    load_time_ms: 2.523\n",
      "    num_steps_sampled: 3440000\n",
      "    num_steps_trained: 3440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.017411936074495316\n",
      "      kl: 0.019330743700265884\n",
      "      policy_loss: 0.005821153987199068\n",
      "      total_loss: 43.15164566040039\n",
      "      vf_explained_var: 0.9700791835784912\n",
      "      vf_loss: 43.14582061767578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.015044140629470348\n",
      "      kl: 0.01670979894697666\n",
      "      policy_loss: 0.0009001468424685299\n",
      "      total_loss: 36.18968963623047\n",
      "      vf_explained_var: 0.9691081643104553\n",
      "      vf_loss: 36.188785552978516\n",
      "    sample_time_ms: 19793.535\n",
      "    update_time_ms: 7.522\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.79356475718635\n",
      "    rl_1: 64.98692727445399\n",
      "  time_since_restore: 8006.915004968643\n",
      "  time_this_iter_s: 22.784862518310547\n",
      "  time_total_s: 8006.915004968643\n",
      "  timestamp: 1550888603\n",
      "  timesteps_since_restore: 3440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3440000\n",
      "  training_iteration: 344\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8006 s, 344 iter, 3440000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-23-46\n",
      "  done: false\n",
      "  episode_len_mean: 113.54\n",
      "  episode_reward_max: 226.78111448181082\n",
      "  episode_reward_mean: 152.13071142910354\n",
      "  episode_reward_min: -167.48421174513896\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 27867\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.014\n",
      "    load_time_ms: 2.454\n",
      "    num_steps_sampled: 3450000\n",
      "    num_steps_trained: 3450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.028514891862869263\n",
      "      kl: 0.011781105771660805\n",
      "      policy_loss: -0.0011349283158779144\n",
      "      total_loss: 67.76011657714844\n",
      "      vf_explained_var: 0.9530202150344849\n",
      "      vf_loss: 67.7612533569336\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.04807787016034126\n",
      "      kl: 0.01652011089026928\n",
      "      policy_loss: 0.00259554386138916\n",
      "      total_loss: 52.76245880126953\n",
      "      vf_explained_var: 0.9546312093734741\n",
      "      vf_loss: 52.75986099243164\n",
      "    sample_time_ms: 19816.383\n",
      "    update_time_ms: 7.787\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.46472232541444\n",
      "    rl_1: 64.66598910368909\n",
      "  time_since_restore: 8030.22842168808\n",
      "  time_this_iter_s: 23.313416719436646\n",
      "  time_total_s: 8030.22842168808\n",
      "  timestamp: 1550888626\n",
      "  timesteps_since_restore: 3450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3450000\n",
      "  training_iteration: 345\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8030 s, 345 iter, 3450000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-24-09\n",
      "  done: false\n",
      "  episode_len_mean: 103.99\n",
      "  episode_reward_max: 226.6750052922944\n",
      "  episode_reward_mean: 155.8560729423135\n",
      "  episode_reward_min: -171.59086989293596\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 27963\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.797\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 3460000\n",
      "    num_steps_trained: 3460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.14434973895549774\n",
      "      kl: 0.033151719719171524\n",
      "      policy_loss: 0.005841184873133898\n",
      "      total_loss: 64.76204681396484\n",
      "      vf_explained_var: 0.9614192247390747\n",
      "      vf_loss: 64.75619506835938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.001150506897829473\n",
      "      kl: 0.0129844443872571\n",
      "      policy_loss: -0.0013802602188661695\n",
      "      total_loss: 55.583683013916016\n",
      "      vf_explained_var: 0.9608639478683472\n",
      "      vf_loss: 55.585060119628906\n",
      "    sample_time_ms: 19843.796\n",
      "    update_time_ms: 7.971\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.77959532116455\n",
      "    rl_1: 68.07647762114894\n",
      "  time_since_restore: 8053.266652584076\n",
      "  time_this_iter_s: 23.038230895996094\n",
      "  time_total_s: 8053.266652584076\n",
      "  timestamp: 1550888649\n",
      "  timesteps_since_restore: 3460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3460000\n",
      "  training_iteration: 346\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8053 s, 346 iter, 3460000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-24-33\n",
      "  done: false\n",
      "  episode_len_mean: 105.42\n",
      "  episode_reward_max: 232.9773657855864\n",
      "  episode_reward_mean: 158.21534693558417\n",
      "  episode_reward_min: -174.03790974266332\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 28058\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.352\n",
      "    load_time_ms: 2.44\n",
      "    num_steps_sampled: 3470000\n",
      "    num_steps_trained: 3470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17337001860141754\n",
      "      kl: 0.015425718389451504\n",
      "      policy_loss: -0.003019212745130062\n",
      "      total_loss: 70.88678741455078\n",
      "      vf_explained_var: 0.9530587792396545\n",
      "      vf_loss: 70.88980865478516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0971674695611\n",
      "      kl: 0.01360087376087904\n",
      "      policy_loss: -0.000964309845585376\n",
      "      total_loss: 60.98548889160156\n",
      "      vf_explained_var: 0.9475793838500977\n",
      "      vf_loss: 60.98646545410156\n",
      "    sample_time_ms: 19897.758\n",
      "    update_time_ms: 7.954\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.51863526038981\n",
      "    rl_1: 66.69671167519432\n",
      "  time_since_restore: 8076.553536891937\n",
      "  time_this_iter_s: 23.286884307861328\n",
      "  time_total_s: 8076.553536891937\n",
      "  timestamp: 1550888673\n",
      "  timesteps_since_restore: 3470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3470000\n",
      "  training_iteration: 347\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8076 s, 347 iter, 3470000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-24-55\n",
      "  done: false\n",
      "  episode_len_mean: 116.65\n",
      "  episode_reward_max: 224.1509146935119\n",
      "  episode_reward_mean: 164.84902181260324\n",
      "  episode_reward_min: -155.37795814828903\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 28142\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.449\n",
      "    load_time_ms: 2.442\n",
      "    num_steps_sampled: 3480000\n",
      "    num_steps_trained: 3480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.19995322823524475\n",
      "      kl: 0.01119974721223116\n",
      "      policy_loss: 0.0017699026502668858\n",
      "      total_loss: 49.76512908935547\n",
      "      vf_explained_var: 0.9603913426399231\n",
      "      vf_loss: 49.763362884521484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.13655854761600494\n",
      "      kl: 0.011935929767787457\n",
      "      policy_loss: -2.6791929485625587e-05\n",
      "      total_loss: 36.505760192871094\n",
      "      vf_explained_var: 0.9657136797904968\n",
      "      vf_loss: 36.50577926635742\n",
      "    sample_time_ms: 19901.38\n",
      "    update_time_ms: 7.907\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.19078387606615\n",
      "    rl_1: 71.65823793653708\n",
      "  time_since_restore: 8099.396726608276\n",
      "  time_this_iter_s: 22.84318971633911\n",
      "  time_total_s: 8099.396726608276\n",
      "  timestamp: 1550888695\n",
      "  timesteps_since_restore: 3480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3480000\n",
      "  training_iteration: 348\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8099 s, 348 iter, 3480000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-25-19\n",
      "  done: false\n",
      "  episode_len_mean: 103.45\n",
      "  episode_reward_max: 227.57167850347795\n",
      "  episode_reward_mean: 161.62192627140385\n",
      "  episode_reward_min: -166.78921539053687\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 28240\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3092.293\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 3490000\n",
      "    num_steps_trained: 3490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1760357767343521\n",
      "      kl: 23.342920303344727\n",
      "      policy_loss: 0.09344156831502914\n",
      "      total_loss: 62.71912384033203\n",
      "      vf_explained_var: 0.9575335383415222\n",
      "      vf_loss: 62.62568283081055\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.007826275192201138\n",
      "      kl: 0.010903428308665752\n",
      "      policy_loss: -0.002020998625084758\n",
      "      total_loss: 51.23546600341797\n",
      "      vf_explained_var: 0.9577040076255798\n",
      "      vf_loss: 51.23748779296875\n",
      "    sample_time_ms: 19936.481\n",
      "    update_time_ms: 7.87\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.49088981384392\n",
      "    rl_1: 72.13103645755994\n",
      "  time_since_restore: 8123.0411331653595\n",
      "  time_this_iter_s: 23.64440655708313\n",
      "  time_total_s: 8123.0411331653595\n",
      "  timestamp: 1550888719\n",
      "  timesteps_since_restore: 3490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3490000\n",
      "  training_iteration: 349\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8123 s, 349 iter, 3490000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-25-42\n",
      "  done: false\n",
      "  episode_len_mean: 102.71\n",
      "  episode_reward_max: 226.0637469935358\n",
      "  episode_reward_mean: 170.0180491805494\n",
      "  episode_reward_min: -169.22684213078767\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 28337\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3094.125\n",
      "    load_time_ms: 2.375\n",
      "    num_steps_sampled: 3500000\n",
      "    num_steps_trained: 3500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1993454247713089\n",
      "      kl: 0.022578727453947067\n",
      "      policy_loss: 0.007571580354124308\n",
      "      total_loss: 55.998077392578125\n",
      "      vf_explained_var: 0.9609202146530151\n",
      "      vf_loss: 55.99050521850586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08283467590808868\n",
      "      kl: 0.010524696670472622\n",
      "      policy_loss: 2.512030187062919e-05\n",
      "      total_loss: 51.416133880615234\n",
      "      vf_explained_var: 0.9495744109153748\n",
      "      vf_loss: 51.41611099243164\n",
      "    sample_time_ms: 19958.499\n",
      "    update_time_ms: 8.11\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.84011398343723\n",
      "    rl_1: 72.17793519711219\n",
      "  time_since_restore: 8146.236793518066\n",
      "  time_this_iter_s: 23.19566035270691\n",
      "  time_total_s: 8146.236793518066\n",
      "  timestamp: 1550888742\n",
      "  timesteps_since_restore: 3500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3500000\n",
      "  training_iteration: 350\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8146 s, 350 iter, 3500000 ts, 170 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-26-06\n",
      "  done: false\n",
      "  episode_len_mean: 114.99\n",
      "  episode_reward_max: 226.0637469935358\n",
      "  episode_reward_mean: 166.18455423877364\n",
      "  episode_reward_min: -119.47504992192701\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 28423\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.793\n",
      "    load_time_ms: 2.428\n",
      "    num_steps_sampled: 3510000\n",
      "    num_steps_trained: 3510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08260064572095871\n",
      "      kl: 0.014677579514682293\n",
      "      policy_loss: 0.00019156512280460447\n",
      "      total_loss: 25.540836334228516\n",
      "      vf_explained_var: 0.9765892028808594\n",
      "      vf_loss: 25.540645599365234\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.050276461988687515\n",
      "      kl: 0.011555214412510395\n",
      "      policy_loss: 0.001164808520115912\n",
      "      total_loss: 23.866764068603516\n",
      "      vf_explained_var: 0.9731506109237671\n",
      "      vf_loss: 23.865598678588867\n",
      "    sample_time_ms: 20028.451\n",
      "    update_time_ms: 8.069\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.90503511351174\n",
      "    rl_1: 69.27951912526188\n",
      "  time_since_restore: 8169.576972961426\n",
      "  time_this_iter_s: 23.340179443359375\n",
      "  time_total_s: 8169.576972961426\n",
      "  timestamp: 1550888766\n",
      "  timesteps_since_restore: 3510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3510000\n",
      "  training_iteration: 351\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8169 s, 351 iter, 3510000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-26-29\n",
      "  done: false\n",
      "  episode_len_mean: 104.55\n",
      "  episode_reward_max: 221.4044915652547\n",
      "  episode_reward_mean: 156.57885909770133\n",
      "  episode_reward_min: -165.9831966713175\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 28519\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.212\n",
      "    load_time_ms: 2.401\n",
      "    num_steps_sampled: 3520000\n",
      "    num_steps_trained: 3520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0879654660820961\n",
      "      kl: 0.014726215042173862\n",
      "      policy_loss: 0.0016898438334465027\n",
      "      total_loss: 38.98688507080078\n",
      "      vf_explained_var: 0.9743490815162659\n",
      "      vf_loss: 38.985198974609375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.02379032038152218\n",
      "      kl: 0.01266110222786665\n",
      "      policy_loss: 0.00461456086486578\n",
      "      total_loss: 31.911561965942383\n",
      "      vf_explained_var: 0.9772810339927673\n",
      "      vf_loss: 31.90694808959961\n",
      "    sample_time_ms: 20010.039\n",
      "    update_time_ms: 8.108\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.82537056069752\n",
      "    rl_1: 67.75348853700383\n",
      "  time_since_restore: 8192.635170936584\n",
      "  time_this_iter_s: 23.05819797515869\n",
      "  time_total_s: 8192.635170936584\n",
      "  timestamp: 1550888789\n",
      "  timesteps_since_restore: 3520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3520000\n",
      "  training_iteration: 352\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8192 s, 352 iter, 3520000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-26-52\n",
      "  done: false\n",
      "  episode_len_mean: 107.73\n",
      "  episode_reward_max: 226.94499560296387\n",
      "  episode_reward_mean: 155.70043882000732\n",
      "  episode_reward_min: -160.04662776611445\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 28611\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.836\n",
      "    load_time_ms: 2.363\n",
      "    num_steps_sampled: 3530000\n",
      "    num_steps_trained: 3530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.047110553830862045\n",
      "      kl: 0.014476699754595757\n",
      "      policy_loss: 0.00015726331912446767\n",
      "      total_loss: 83.79036712646484\n",
      "      vf_explained_var: 0.9434790015220642\n",
      "      vf_loss: 83.79019927978516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.024208152666687965\n",
      "      kl: 0.01467907428741455\n",
      "      policy_loss: -0.0013210836332291365\n",
      "      total_loss: 74.72576904296875\n",
      "      vf_explained_var: 0.9332725405693054\n",
      "      vf_loss: 74.72708892822266\n",
      "    sample_time_ms: 20092.052\n",
      "    update_time_ms: 7.508\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.04585037525823\n",
      "    rl_1: 64.65458844474911\n",
      "  time_since_restore: 8216.048423051834\n",
      "  time_this_iter_s: 23.413252115249634\n",
      "  time_total_s: 8216.048423051834\n",
      "  timestamp: 1550888812\n",
      "  timesteps_since_restore: 3530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3530000\n",
      "  training_iteration: 353\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8216 s, 353 iter, 3530000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-27-15\n",
      "  done: false\n",
      "  episode_len_mean: 103.94\n",
      "  episode_reward_max: 227.84661194783564\n",
      "  episode_reward_mean: 156.91150821073575\n",
      "  episode_reward_min: -162.2163285226381\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 28707\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.185\n",
      "    load_time_ms: 2.382\n",
      "    num_steps_sampled: 3540000\n",
      "    num_steps_trained: 3540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1583367884159088\n",
      "      kl: 0.03299278765916824\n",
      "      policy_loss: 0.005291535519063473\n",
      "      total_loss: 60.93937683105469\n",
      "      vf_explained_var: 0.9626666307449341\n",
      "      vf_loss: 60.93410110473633\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.06366615742444992\n",
      "      kl: 0.01701260916888714\n",
      "      policy_loss: 0.0009633896988816559\n",
      "      total_loss: 46.58077621459961\n",
      "      vf_explained_var: 0.9626405239105225\n",
      "      vf_loss: 46.57980728149414\n",
      "    sample_time_ms: 20101.808\n",
      "    update_time_ms: 7.637\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.13843372535555\n",
      "    rl_1: 65.7730744853802\n",
      "  time_since_restore: 8238.965135097504\n",
      "  time_this_iter_s: 22.916712045669556\n",
      "  time_total_s: 8238.965135097504\n",
      "  timestamp: 1550888835\n",
      "  timesteps_since_restore: 3540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3540000\n",
      "  training_iteration: 354\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8238 s, 354 iter, 3540000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-27-38\n",
      "  done: false\n",
      "  episode_len_mean: 106.58\n",
      "  episode_reward_max: 224.0554662352818\n",
      "  episode_reward_mean: 174.4300194849589\n",
      "  episode_reward_min: -131.89567032619817\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 28799\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.529\n",
      "    load_time_ms: 2.439\n",
      "    num_steps_sampled: 3550000\n",
      "    num_steps_trained: 3550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18101242184638977\n",
      "      kl: 0.018540898337960243\n",
      "      policy_loss: 0.0010983593529090285\n",
      "      total_loss: 36.082054138183594\n",
      "      vf_explained_var: 0.9677960276603699\n",
      "      vf_loss: 36.08095169067383\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10837447643280029\n",
      "      kl: 0.017898155376315117\n",
      "      policy_loss: 0.0035099219530820847\n",
      "      total_loss: 31.082550048828125\n",
      "      vf_explained_var: 0.9644249081611633\n",
      "      vf_loss: 31.079038619995117\n",
      "    sample_time_ms: 20066.022\n",
      "    update_time_ms: 7.806\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 100.73084016276587\n",
      "    rl_1: 73.69917932219296\n",
      "  time_since_restore: 8262.125122308731\n",
      "  time_this_iter_s: 23.159987211227417\n",
      "  time_total_s: 8262.125122308731\n",
      "  timestamp: 1550888858\n",
      "  timesteps_since_restore: 3550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3550000\n",
      "  training_iteration: 355\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8262 s, 355 iter, 3550000 ts, 174 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-28-01\n",
      "  done: false\n",
      "  episode_len_mean: 106.3\n",
      "  episode_reward_max: 227.97736681316863\n",
      "  episode_reward_mean: 164.87431787544082\n",
      "  episode_reward_min: -175.6057581063513\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 28894\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.781\n",
      "    load_time_ms: 2.44\n",
      "    num_steps_sampled: 3560000\n",
      "    num_steps_trained: 3560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1650674045085907\n",
      "      kl: 0.010605084709823132\n",
      "      policy_loss: -0.0004914123564958572\n",
      "      total_loss: 40.27488708496094\n",
      "      vf_explained_var: 0.9698713421821594\n",
      "      vf_loss: 40.27538299560547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08808308094739914\n",
      "      kl: 0.025963257998228073\n",
      "      policy_loss: 0.0020775150042027235\n",
      "      total_loss: 35.879295349121094\n",
      "      vf_explained_var: 0.9671136140823364\n",
      "      vf_loss: 35.87721633911133\n",
      "    sample_time_ms: 20054.928\n",
      "    update_time_ms: 7.578\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.0855383265982\n",
      "    rl_1: 68.78877954884258\n",
      "  time_since_restore: 8284.852629899979\n",
      "  time_this_iter_s: 22.72750759124756\n",
      "  time_total_s: 8284.852629899979\n",
      "  timestamp: 1550888881\n",
      "  timesteps_since_restore: 3560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3560000\n",
      "  training_iteration: 356\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8284 s, 356 iter, 3560000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-28-25\n",
      "  done: false\n",
      "  episode_len_mean: 107.72\n",
      "  episode_reward_max: 225.67078191110528\n",
      "  episode_reward_mean: 169.3923187650844\n",
      "  episode_reward_min: -175.6057581063513\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 28988\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.953\n",
      "    load_time_ms: 2.399\n",
      "    num_steps_sampled: 3570000\n",
      "    num_steps_trained: 3570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0781605914235115\n",
      "      kl: 0.01802273653447628\n",
      "      policy_loss: 0.00287393806502223\n",
      "      total_loss: 18.856342315673828\n",
      "      vf_explained_var: 0.981267511844635\n",
      "      vf_loss: 18.85346794128418\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.004204393830150366\n",
      "      kl: 0.01963483914732933\n",
      "      policy_loss: 0.0023389265406876802\n",
      "      total_loss: 14.083300590515137\n",
      "      vf_explained_var: 0.9818135499954224\n",
      "      vf_loss: 14.080964088439941\n",
      "    sample_time_ms: 20062.193\n",
      "    update_time_ms: 7.367\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.57018988843274\n",
      "    rl_1: 72.82212887665169\n",
      "  time_since_restore: 8308.230128526688\n",
      "  time_this_iter_s: 23.377498626708984\n",
      "  time_total_s: 8308.230128526688\n",
      "  timestamp: 1550888905\n",
      "  timesteps_since_restore: 3570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3570000\n",
      "  training_iteration: 357\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8308 s, 357 iter, 3570000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-28-48\n",
      "  done: false\n",
      "  episode_len_mean: 107.12\n",
      "  episode_reward_max: 220.51488339709076\n",
      "  episode_reward_mean: 155.9820442055598\n",
      "  episode_reward_min: -162.9901615780507\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 29081\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.92\n",
      "    load_time_ms: 2.403\n",
      "    num_steps_sampled: 3580000\n",
      "    num_steps_trained: 3580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.01116093248128891\n",
      "      kl: 0.01616864837706089\n",
      "      policy_loss: 0.003744042944163084\n",
      "      total_loss: 53.714813232421875\n",
      "      vf_explained_var: 0.9604375958442688\n",
      "      vf_loss: 53.71106719970703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0335485115647316\n",
      "      kl: 0.03699810057878494\n",
      "      policy_loss: 0.0023963209241628647\n",
      "      total_loss: 42.894935607910156\n",
      "      vf_explained_var: 0.964385986328125\n",
      "      vf_loss: 42.892539978027344\n",
      "    sample_time_ms: 20099.554\n",
      "    update_time_ms: 7.438\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.1688598126964\n",
      "    rl_1: 66.8131843928634\n",
      "  time_since_restore: 8331.437282562256\n",
      "  time_this_iter_s: 23.207154035568237\n",
      "  time_total_s: 8331.437282562256\n",
      "  timestamp: 1550888928\n",
      "  timesteps_since_restore: 3580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3580000\n",
      "  training_iteration: 358\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8331 s, 358 iter, 3580000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-29-11\n",
      "  done: false\n",
      "  episode_len_mean: 101.23\n",
      "  episode_reward_max: 227.47467066228583\n",
      "  episode_reward_mean: 150.258309044632\n",
      "  episode_reward_min: -165.77364446460462\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 29179\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.232\n",
      "    load_time_ms: 2.362\n",
      "    num_steps_sampled: 3590000\n",
      "    num_steps_trained: 3590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1550847440958023\n",
      "      kl: 0.034378450363874435\n",
      "      policy_loss: -0.0001553628535475582\n",
      "      total_loss: 84.4264907836914\n",
      "      vf_explained_var: 0.9453849792480469\n",
      "      vf_loss: 84.42664337158203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.047663331031799316\n",
      "      kl: 0.012359989807009697\n",
      "      policy_loss: -0.003003988415002823\n",
      "      total_loss: 71.63125610351562\n",
      "      vf_explained_var: 0.9349039793014526\n",
      "      vf_loss: 71.63426208496094\n",
      "    sample_time_ms: 20059.013\n",
      "    update_time_ms: 7.494\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.85262917925643\n",
      "    rl_1: 62.40567986537559\n",
      "  time_since_restore: 8354.708966970444\n",
      "  time_this_iter_s: 23.271684408187866\n",
      "  time_total_s: 8354.708966970444\n",
      "  timestamp: 1550888951\n",
      "  timesteps_since_restore: 3590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3590000\n",
      "  training_iteration: 359\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8354 s, 359 iter, 3590000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-29-34\n",
      "  done: false\n",
      "  episode_len_mean: 104.9\n",
      "  episode_reward_max: 227.11033468800466\n",
      "  episode_reward_mean: 155.10770844666126\n",
      "  episode_reward_min: -177.97285017944444\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 29276\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.135\n",
      "    load_time_ms: 2.338\n",
      "    num_steps_sampled: 3600000\n",
      "    num_steps_trained: 3600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2062491625547409\n",
      "      kl: 0.03380803391337395\n",
      "      policy_loss: -0.0038078518118709326\n",
      "      total_loss: 77.13506317138672\n",
      "      vf_explained_var: 0.9493210911750793\n",
      "      vf_loss: 77.13887786865234\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.088592030107975\n",
      "      kl: 0.014042315073311329\n",
      "      policy_loss: 0.00013857286830898374\n",
      "      total_loss: 63.882843017578125\n",
      "      vf_explained_var: 0.9486503601074219\n",
      "      vf_loss: 63.88269805908203\n",
      "    sample_time_ms: 20047.225\n",
      "    update_time_ms: 7.229\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.12996740191093\n",
      "    rl_1: 64.97774104475029\n",
      "  time_since_restore: 8377.750386238098\n",
      "  time_this_iter_s: 23.04141926765442\n",
      "  time_total_s: 8377.750386238098\n",
      "  timestamp: 1550888974\n",
      "  timesteps_since_restore: 3600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3600000\n",
      "  training_iteration: 360\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8377 s, 360 iter, 3600000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-29-58\n",
      "  done: false\n",
      "  episode_len_mean: 101.74\n",
      "  episode_reward_max: 224.6033972191904\n",
      "  episode_reward_mean: 155.99338073035742\n",
      "  episode_reward_min: -169.80628999951836\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 29371\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.482\n",
      "    load_time_ms: 2.297\n",
      "    num_steps_sampled: 3610000\n",
      "    num_steps_trained: 3610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21287773549556732\n",
      "      kl: 0.023395158350467682\n",
      "      policy_loss: 0.002337780548259616\n",
      "      total_loss: 65.14008331298828\n",
      "      vf_explained_var: 0.9609916806221008\n",
      "      vf_loss: 65.13774871826172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07871094346046448\n",
      "      kl: 0.01115182414650917\n",
      "      policy_loss: -0.0013988246209919453\n",
      "      total_loss: 54.248905181884766\n",
      "      vf_explained_var: 0.957737922668457\n",
      "      vf_loss: 54.250301361083984\n",
      "    sample_time_ms: 20030.018\n",
      "    update_time_ms: 7.31\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.89529605036428\n",
      "    rl_1: 65.09808467999314\n",
      "  time_since_restore: 8400.921479463577\n",
      "  time_this_iter_s: 23.171093225479126\n",
      "  time_total_s: 8400.921479463577\n",
      "  timestamp: 1550888998\n",
      "  timesteps_since_restore: 3610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3610000\n",
      "  training_iteration: 361\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8400 s, 361 iter, 3610000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-30-21\n",
      "  done: false\n",
      "  episode_len_mean: 112.35\n",
      "  episode_reward_max: 225.77184281322437\n",
      "  episode_reward_mean: 164.4689208557425\n",
      "  episode_reward_min: -170.24080978591223\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 29463\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.927\n",
      "    load_time_ms: 2.299\n",
      "    num_steps_sampled: 3620000\n",
      "    num_steps_trained: 3620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.06685861945152283\n",
      "      kl: 5.3412251472473145\n",
      "      policy_loss: 0.16773773729801178\n",
      "      total_loss: 52.966766357421875\n",
      "      vf_explained_var: 0.9623991250991821\n",
      "      vf_loss: 52.79903030395508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0010098961647599936\n",
      "      kl: 0.01290335226804018\n",
      "      policy_loss: 0.004482497461140156\n",
      "      total_loss: 43.40174102783203\n",
      "      vf_explained_var: 0.9629983305931091\n",
      "      vf_loss: 43.39725875854492\n",
      "    sample_time_ms: 20065.102\n",
      "    update_time_ms: 7.427\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.70282957979232\n",
      "    rl_1: 70.76609127595019\n",
      "  time_since_restore: 8424.32723069191\n",
      "  time_this_iter_s: 23.40575122833252\n",
      "  time_total_s: 8424.32723069191\n",
      "  timestamp: 1550889021\n",
      "  timesteps_since_restore: 3620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3620000\n",
      "  training_iteration: 362\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8424 s, 362 iter, 3620000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-30-44\n",
      "  done: false\n",
      "  episode_len_mean: 104.64\n",
      "  episode_reward_max: 224.57382737717066\n",
      "  episode_reward_mean: 172.46737465104334\n",
      "  episode_reward_min: -146.45637509786653\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 29559\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.738\n",
      "    load_time_ms: 2.358\n",
      "    num_steps_sampled: 3630000\n",
      "    num_steps_trained: 3630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19758260250091553\n",
      "      kl: 0.025707583874464035\n",
      "      policy_loss: 0.008345073089003563\n",
      "      total_loss: 23.11163902282715\n",
      "      vf_explained_var: 0.9788028001785278\n",
      "      vf_loss: 23.10329246520996\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11095794290304184\n",
      "      kl: 0.01656649075448513\n",
      "      policy_loss: -0.0008453394402749836\n",
      "      total_loss: 19.694660186767578\n",
      "      vf_explained_var: 0.9749634861946106\n",
      "      vf_loss: 19.695505142211914\n",
      "    sample_time_ms: 20029.898\n",
      "    update_time_ms: 7.498\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 99.93442184644034\n",
      "    rl_1: 72.53295280460298\n",
      "  time_since_restore: 8447.36666226387\n",
      "  time_this_iter_s: 23.03943157196045\n",
      "  time_total_s: 8447.36666226387\n",
      "  timestamp: 1550889044\n",
      "  timesteps_since_restore: 3630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3630000\n",
      "  training_iteration: 363\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8447 s, 363 iter, 3630000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-31-07\n",
      "  done: false\n",
      "  episode_len_mean: 105.31\n",
      "  episode_reward_max: 222.51587517235188\n",
      "  episode_reward_mean: 152.84758769035452\n",
      "  episode_reward_min: -145.16875089968983\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 29653\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.819\n",
      "    load_time_ms: 2.367\n",
      "    num_steps_sampled: 3640000\n",
      "    num_steps_trained: 3640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08671741187572479\n",
      "      kl: 0.019483352079987526\n",
      "      policy_loss: 0.00405380642041564\n",
      "      total_loss: 46.402008056640625\n",
      "      vf_explained_var: 0.9716461300849915\n",
      "      vf_loss: 46.39795684814453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.01774110272526741\n",
      "      kl: 0.011434285901486874\n",
      "      policy_loss: -0.001488309819251299\n",
      "      total_loss: 38.50469970703125\n",
      "      vf_explained_var: 0.9701675176620483\n",
      "      vf_loss: 38.50619125366211\n",
      "    sample_time_ms: 20002.909\n",
      "    update_time_ms: 7.375\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.56696748867802\n",
      "    rl_1: 63.28062020167646\n",
      "  time_since_restore: 8470.116033554077\n",
      "  time_this_iter_s: 22.74937129020691\n",
      "  time_total_s: 8470.116033554077\n",
      "  timestamp: 1550889067\n",
      "  timesteps_since_restore: 3640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3640000\n",
      "  training_iteration: 364\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8470 s, 364 iter, 3640000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-31-30\n",
      "  done: false\n",
      "  episode_len_mean: 103.57\n",
      "  episode_reward_max: 227.33186820841934\n",
      "  episode_reward_mean: 151.79603974573465\n",
      "  episode_reward_min: -156.73327748048106\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 29749\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.008\n",
      "    load_time_ms: 2.287\n",
      "    num_steps_sampled: 3650000\n",
      "    num_steps_trained: 3650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.06692029535770416\n",
      "      kl: 0.018660198897123337\n",
      "      policy_loss: 0.0015315631171688437\n",
      "      total_loss: 67.05662536621094\n",
      "      vf_explained_var: 0.963201105594635\n",
      "      vf_loss: 67.05509948730469\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.00929916650056839\n",
      "      kl: 0.011262387037277222\n",
      "      policy_loss: 0.0008555804379284382\n",
      "      total_loss: 54.058956146240234\n",
      "      vf_explained_var: 0.9637746810913086\n",
      "      vf_loss: 54.05810546875\n",
      "    sample_time_ms: 19962.725\n",
      "    update_time_ms: 7.292\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.06988231752023\n",
      "    rl_1: 64.72615742821445\n",
      "  time_since_restore: 8492.68516588211\n",
      "  time_this_iter_s: 22.569132328033447\n",
      "  time_total_s: 8492.68516588211\n",
      "  timestamp: 1550889090\n",
      "  timesteps_since_restore: 3650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3650000\n",
      "  training_iteration: 365\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8492 s, 365 iter, 3650000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-31-53\n",
      "  done: false\n",
      "  episode_len_mean: 112.21\n",
      "  episode_reward_max: 222.41822755815838\n",
      "  episode_reward_mean: 151.21511961666974\n",
      "  episode_reward_min: -156.6533131798754\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 29840\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.338\n",
      "    load_time_ms: 2.29\n",
      "    num_steps_sampled: 3660000\n",
      "    num_steps_trained: 3660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.03532494604587555\n",
      "      kl: 0.016505343839526176\n",
      "      policy_loss: 0.006237569730728865\n",
      "      total_loss: 17.55046272277832\n",
      "      vf_explained_var: 0.9883941411972046\n",
      "      vf_loss: 17.544225692749023\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.022686416283249855\n",
      "      kl: 0.02337625063955784\n",
      "      policy_loss: 0.00255502387881279\n",
      "      total_loss: 16.142066955566406\n",
      "      vf_explained_var: 0.9859259128570557\n",
      "      vf_loss: 16.139511108398438\n",
      "    sample_time_ms: 20018.677\n",
      "    update_time_ms: 7.399\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.89385969238157\n",
      "    rl_1: 61.321259924288185\n",
      "  time_since_restore: 8515.9872777462\n",
      "  time_this_iter_s: 23.302111864089966\n",
      "  time_total_s: 8515.9872777462\n",
      "  timestamp: 1550889113\n",
      "  timesteps_since_restore: 3660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3660000\n",
      "  training_iteration: 366\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8515 s, 366 iter, 3660000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-32-16\n",
      "  done: false\n",
      "  episode_len_mean: 106.28\n",
      "  episode_reward_max: 223.10039563651787\n",
      "  episode_reward_mean: 151.4020445697939\n",
      "  episode_reward_min: -169.30780319193346\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 29933\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.148\n",
      "    load_time_ms: 2.302\n",
      "    num_steps_sampled: 3670000\n",
      "    num_steps_trained: 3670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10071282833814621\n",
      "      kl: 0.015417616814374924\n",
      "      policy_loss: 0.0016374815022572875\n",
      "      total_loss: 54.97176742553711\n",
      "      vf_explained_var: 0.9652142524719238\n",
      "      vf_loss: 54.97012710571289\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.06908772140741348\n",
      "      kl: 0.018756026402115822\n",
      "      policy_loss: 0.0035512130707502365\n",
      "      total_loss: 47.86177444458008\n",
      "      vf_explained_var: 0.9614762663841248\n",
      "      vf_loss: 47.85822296142578\n",
      "    sample_time_ms: 19990.11\n",
      "    update_time_ms: 7.633\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.04274117245022\n",
      "    rl_1: 62.35930339734367\n",
      "  time_since_restore: 8539.131839990616\n",
      "  time_this_iter_s: 23.144562244415283\n",
      "  time_total_s: 8539.131839990616\n",
      "  timestamp: 1550889136\n",
      "  timesteps_since_restore: 3670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3670000\n",
      "  training_iteration: 367\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8539 s, 367 iter, 3670000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-32-39\n",
      "  done: false\n",
      "  episode_len_mean: 102.6\n",
      "  episode_reward_max: 229.58723248920575\n",
      "  episode_reward_mean: 167.51987777611146\n",
      "  episode_reward_min: -163.12569522311566\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 30032\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.492\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 3680000\n",
      "    num_steps_trained: 3680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22160466015338898\n",
      "      kl: 0.024105442687869072\n",
      "      policy_loss: 0.0056456574238836765\n",
      "      total_loss: 24.140052795410156\n",
      "      vf_explained_var: 0.9798045754432678\n",
      "      vf_loss: 24.134408950805664\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12350033223628998\n",
      "      kl: 0.011441783048212528\n",
      "      policy_loss: -0.0009214808233082294\n",
      "      total_loss: 18.042037963867188\n",
      "      vf_explained_var: 0.9805148243904114\n",
      "      vf_loss: 18.042959213256836\n",
      "    sample_time_ms: 19964.748\n",
      "    update_time_ms: 7.486\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.36035073117435\n",
      "    rl_1: 72.15952704493714\n",
      "  time_since_restore: 8562.260032653809\n",
      "  time_this_iter_s: 23.12819266319275\n",
      "  time_total_s: 8562.260032653809\n",
      "  timestamp: 1550889159\n",
      "  timesteps_since_restore: 3680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3680000\n",
      "  training_iteration: 368\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8562 s, 368 iter, 3680000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-33-02\n",
      "  done: false\n",
      "  episode_len_mean: 104.23\n",
      "  episode_reward_max: 225.88871001679547\n",
      "  episode_reward_mean: 147.28385236516843\n",
      "  episode_reward_min: -180.23736886507726\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 30128\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.853\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 3690000\n",
      "    num_steps_trained: 3690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08120016753673553\n",
      "      kl: 0.01730629988014698\n",
      "      policy_loss: -0.0013135269982740283\n",
      "      total_loss: 67.78529357910156\n",
      "      vf_explained_var: 0.9599170088768005\n",
      "      vf_loss: 67.78660583496094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.05472260341048241\n",
      "      kl: 0.016786785796284676\n",
      "      policy_loss: -0.000978789641521871\n",
      "      total_loss: 58.79833984375\n",
      "      vf_explained_var: 0.9555692672729492\n",
      "      vf_loss: 58.79932403564453\n",
      "    sample_time_ms: 19927.733\n",
      "    update_time_ms: 7.411\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.36812052370018\n",
      "    rl_1: 60.915731841468244\n",
      "  time_since_restore: 8585.173426628113\n",
      "  time_this_iter_s: 22.9133939743042\n",
      "  time_total_s: 8585.173426628113\n",
      "  timestamp: 1550889182\n",
      "  timesteps_since_restore: 3690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3690000\n",
      "  training_iteration: 369\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8585 s, 369 iter, 3690000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 103.48\n",
      "  episode_reward_max: 229.04724377161696\n",
      "  episode_reward_mean: 163.89616392962154\n",
      "  episode_reward_min: -174.56728873235357\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 30225\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3092.247\n",
      "    load_time_ms: 2.38\n",
      "    num_steps_sampled: 3700000\n",
      "    num_steps_trained: 3700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19993628561496735\n",
      "      kl: 0.020395932719111443\n",
      "      policy_loss: 0.0034737323876470327\n",
      "      total_loss: 45.60742950439453\n",
      "      vf_explained_var: 0.968497633934021\n",
      "      vf_loss: 45.60395812988281\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.13187500834465027\n",
      "      kl: 0.01768573373556137\n",
      "      policy_loss: 0.004249169025570154\n",
      "      total_loss: 34.31892395019531\n",
      "      vf_explained_var: 0.968987762928009\n",
      "      vf_loss: 34.314674377441406\n",
      "    sample_time_ms: 19923.08\n",
      "    update_time_ms: 7.537\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.11981943861639\n",
      "    rl_1: 68.77634449100515\n",
      "  time_since_restore: 8608.185740709305\n",
      "  time_this_iter_s: 23.012314081192017\n",
      "  time_total_s: 8608.185740709305\n",
      "  timestamp: 1550889205\n",
      "  timesteps_since_restore: 3700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3700000\n",
      "  training_iteration: 370\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8608 s, 370 iter, 3700000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-33-49\n",
      "  done: false\n",
      "  episode_len_mean: 108.18\n",
      "  episode_reward_max: 224.39691450960694\n",
      "  episode_reward_mean: 147.46628298996043\n",
      "  episode_reward_min: -176.80487053184703\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 30317\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3092.727\n",
      "    load_time_ms: 2.363\n",
      "    num_steps_sampled: 3710000\n",
      "    num_steps_trained: 3710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0001420963235432282\n",
      "      kl: 0.04982761666178703\n",
      "      policy_loss: 0.00986882857978344\n",
      "      total_loss: 57.01968002319336\n",
      "      vf_explained_var: 0.9643118381500244\n",
      "      vf_loss: 57.00980758666992\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.006713663227856159\n",
      "      kl: 0.015317010693252087\n",
      "      policy_loss: -0.0005381803493946791\n",
      "      total_loss: 48.29245376586914\n",
      "      vf_explained_var: 0.9615792632102966\n",
      "      vf_loss: 48.29298782348633\n",
      "    sample_time_ms: 19931.306\n",
      "    update_time_ms: 8.012\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.83790211646205\n",
      "    rl_1: 60.62838087349843\n",
      "  time_since_restore: 8631.44811630249\n",
      "  time_this_iter_s: 23.262375593185425\n",
      "  time_total_s: 8631.44811630249\n",
      "  timestamp: 1550889229\n",
      "  timesteps_since_restore: 3710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3710000\n",
      "  training_iteration: 371\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8631 s, 371 iter, 3710000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-34-12\n",
      "  done: false\n",
      "  episode_len_mean: 101.08\n",
      "  episode_reward_max: 220.97523208367232\n",
      "  episode_reward_mean: 163.16684788243282\n",
      "  episode_reward_min: -143.78414663926768\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 30416\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.469\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 3720000\n",
      "    num_steps_trained: 3720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24991172552108765\n",
      "      kl: 0.09052686393260956\n",
      "      policy_loss: 0.028567276895046234\n",
      "      total_loss: 38.4775505065918\n",
      "      vf_explained_var: 0.9733798503875732\n",
      "      vf_loss: 38.44899368286133\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1814715415239334\n",
      "      kl: 0.015034685842692852\n",
      "      policy_loss: 0.0016694405348971486\n",
      "      total_loss: 33.8220329284668\n",
      "      vf_explained_var: 0.9696558713912964\n",
      "      vf_loss: 33.82036209106445\n",
      "    sample_time_ms: 19941.207\n",
      "    update_time_ms: 7.975\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.24764135187326\n",
      "    rl_1: 68.91920653055958\n",
      "  time_since_restore: 8655.02336192131\n",
      "  time_this_iter_s: 23.57524561882019\n",
      "  time_total_s: 8655.02336192131\n",
      "  timestamp: 1550889252\n",
      "  timesteps_since_restore: 3720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3720000\n",
      "  training_iteration: 372\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8655 s, 372 iter, 3720000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-34-35\n",
      "  done: false\n",
      "  episode_len_mean: 101.3\n",
      "  episode_reward_max: 226.02287972282642\n",
      "  episode_reward_mean: 151.6755701080295\n",
      "  episode_reward_min: -158.8904114343226\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 30515\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.326\n",
      "    load_time_ms: 2.395\n",
      "    num_steps_sampled: 3730000\n",
      "    num_steps_trained: 3730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2099897712469101\n",
      "      kl: 0.01406191848218441\n",
      "      policy_loss: 0.002462472766637802\n",
      "      total_loss: 59.94488525390625\n",
      "      vf_explained_var: 0.9699122309684753\n",
      "      vf_loss: 59.942413330078125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17196086049079895\n",
      "      kl: 0.013477085158228874\n",
      "      policy_loss: 0.001835563569329679\n",
      "      total_loss: 48.624298095703125\n",
      "      vf_explained_var: 0.9687066674232483\n",
      "      vf_loss: 48.622459411621094\n",
      "    sample_time_ms: 19934.975\n",
      "    update_time_ms: 7.923\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.6890424433745\n",
      "    rl_1: 63.986527664654986\n",
      "  time_since_restore: 8678.006861925125\n",
      "  time_this_iter_s: 22.983500003814697\n",
      "  time_total_s: 8678.006861925125\n",
      "  timestamp: 1550889275\n",
      "  timesteps_since_restore: 3730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3730000\n",
      "  training_iteration: 373\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8678 s, 373 iter, 3730000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-34-59\n",
      "  done: false\n",
      "  episode_len_mean: 101.35\n",
      "  episode_reward_max: 229.2015957543723\n",
      "  episode_reward_mean: 158.73178264900977\n",
      "  episode_reward_min: -168.96540803904884\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 30614\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.167\n",
      "    load_time_ms: 2.369\n",
      "    num_steps_sampled: 3740000\n",
      "    num_steps_trained: 3740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22434166073799133\n",
      "      kl: 0.020066915079951286\n",
      "      policy_loss: 0.0023888591676950455\n",
      "      total_loss: 67.7367935180664\n",
      "      vf_explained_var: 0.9499025344848633\n",
      "      vf_loss: 67.73439025878906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17360550165176392\n",
      "      kl: 0.017517006024718285\n",
      "      policy_loss: 0.0007787181530147791\n",
      "      total_loss: 57.839298248291016\n",
      "      vf_explained_var: 0.9422299265861511\n",
      "      vf_loss: 57.83851623535156\n",
      "    sample_time_ms: 20025.144\n",
      "    update_time_ms: 7.921\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.43124036869337\n",
      "    rl_1: 67.30054228031642\n",
      "  time_since_restore: 8701.525021314621\n",
      "  time_this_iter_s: 23.51815938949585\n",
      "  time_total_s: 8701.525021314621\n",
      "  timestamp: 1550889299\n",
      "  timesteps_since_restore: 3740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3740000\n",
      "  training_iteration: 374\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8701 s, 374 iter, 3740000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-35-22\n",
      "  done: false\n",
      "  episode_len_mean: 109.01\n",
      "  episode_reward_max: 227.2243258120593\n",
      "  episode_reward_mean: 152.78026414454214\n",
      "  episode_reward_min: -161.81073444928035\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 30705\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.742\n",
      "    load_time_ms: 2.391\n",
      "    num_steps_sampled: 3750000\n",
      "    num_steps_trained: 3750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.040287189185619354\n",
      "      kl: 0.024845348671078682\n",
      "      policy_loss: 0.003512629307806492\n",
      "      total_loss: 58.73682403564453\n",
      "      vf_explained_var: 0.9587483406066895\n",
      "      vf_loss: 58.73331832885742\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0771263912320137\n",
      "      kl: 0.015118884854018688\n",
      "      policy_loss: -0.0011951705673709512\n",
      "      total_loss: 38.87255859375\n",
      "      vf_explained_var: 0.9652772545814514\n",
      "      vf_loss: 38.87375259399414\n",
      "    sample_time_ms: 20098.371\n",
      "    update_time_ms: 7.679\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.39016307889018\n",
      "    rl_1: 62.39010106565197\n",
      "  time_since_restore: 8724.798755407333\n",
      "  time_this_iter_s: 23.273734092712402\n",
      "  time_total_s: 8724.798755407333\n",
      "  timestamp: 1550889322\n",
      "  timesteps_since_restore: 3750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3750000\n",
      "  training_iteration: 375\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8724 s, 375 iter, 3750000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-35-45\n",
      "  done: false\n",
      "  episode_len_mean: 111.54\n",
      "  episode_reward_max: 224.36530381091583\n",
      "  episode_reward_mean: 164.57322472936926\n",
      "  episode_reward_min: -161.81073444928035\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 30793\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.357\n",
      "    load_time_ms: 2.457\n",
      "    num_steps_sampled: 3760000\n",
      "    num_steps_trained: 3760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.030761467292904854\n",
      "      kl: 0.02295839600265026\n",
      "      policy_loss: 0.006256864406168461\n",
      "      total_loss: 17.684823989868164\n",
      "      vf_explained_var: 0.9834652543067932\n",
      "      vf_loss: 17.67856788635254\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.005269686691462994\n",
      "      kl: 0.01565992459654808\n",
      "      policy_loss: 0.0014885150594636798\n",
      "      total_loss: 17.671751022338867\n",
      "      vf_explained_var: 0.9797338843345642\n",
      "      vf_loss: 17.670265197753906\n",
      "    sample_time_ms: 20078.22\n",
      "    update_time_ms: 7.658\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.41003600213402\n",
      "    rl_1: 68.16318872723522\n",
      "  time_since_restore: 8747.917947292328\n",
      "  time_this_iter_s: 23.119191884994507\n",
      "  time_total_s: 8747.917947292328\n",
      "  timestamp: 1550889345\n",
      "  timesteps_since_restore: 3760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3760000\n",
      "  training_iteration: 376\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8747 s, 376 iter, 3760000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-36-09\n",
      "  done: false\n",
      "  episode_len_mean: 102.64\n",
      "  episode_reward_max: 220.71615899167426\n",
      "  episode_reward_mean: 150.08838974477257\n",
      "  episode_reward_min: -167.0310736922478\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 30892\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.427\n",
      "    load_time_ms: 2.445\n",
      "    num_steps_sampled: 3770000\n",
      "    num_steps_trained: 3770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24128848314285278\n",
      "      kl: 0.024111252278089523\n",
      "      policy_loss: 0.005303471814841032\n",
      "      total_loss: 66.25904846191406\n",
      "      vf_explained_var: 0.9640562534332275\n",
      "      vf_loss: 66.25373077392578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.23418156802654266\n",
      "      kl: 17.23819923400879\n",
      "      policy_loss: 0.08527986705303192\n",
      "      total_loss: 51.436405181884766\n",
      "      vf_explained_var: 0.9634296894073486\n",
      "      vf_loss: 51.35112380981445\n",
      "    sample_time_ms: 20079.111\n",
      "    update_time_ms: 7.73\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.25529148851291\n",
      "    rl_1: 62.83309825625969\n",
      "  time_since_restore: 8771.20964550972\n",
      "  time_this_iter_s: 23.291698217391968\n",
      "  time_total_s: 8771.20964550972\n",
      "  timestamp: 1550889369\n",
      "  timesteps_since_restore: 3770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3770000\n",
      "  training_iteration: 377\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8771 s, 377 iter, 3770000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-36-33\n",
      "  done: false\n",
      "  episode_len_mean: 101.67\n",
      "  episode_reward_max: 226.43769162448524\n",
      "  episode_reward_mean: 170.69534286697112\n",
      "  episode_reward_min: -140.9575615576656\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 30991\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.398\n",
      "    load_time_ms: 2.411\n",
      "    num_steps_sampled: 3780000\n",
      "    num_steps_trained: 3780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1458536833524704\n",
      "      kl: 1.26884126663208\n",
      "      policy_loss: 0.03453933447599411\n",
      "      total_loss: 29.657997131347656\n",
      "      vf_explained_var: 0.9769423007965088\n",
      "      vf_loss: 29.62346076965332\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.14918798208236694\n",
      "      kl: 0.0075751664116978645\n",
      "      policy_loss: -0.0038304696790874004\n",
      "      total_loss: 27.14652442932129\n",
      "      vf_explained_var: 0.9722166061401367\n",
      "      vf_loss: 27.15035629272461\n",
      "    sample_time_ms: 20176.729\n",
      "    update_time_ms: 7.743\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.0363349446649\n",
      "    rl_1: 75.65900792230623\n",
      "  time_since_restore: 8795.141958713531\n",
      "  time_this_iter_s: 23.932313203811646\n",
      "  time_total_s: 8795.141958713531\n",
      "  timestamp: 1550889393\n",
      "  timesteps_since_restore: 3780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3780000\n",
      "  training_iteration: 378\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8795 s, 378 iter, 3780000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-36-56\n",
      "  done: false\n",
      "  episode_len_mean: 105.68\n",
      "  episode_reward_max: 230.35404173574227\n",
      "  episode_reward_mean: 158.20260905005983\n",
      "  episode_reward_min: -171.64607932220403\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 31085\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.953\n",
      "    load_time_ms: 2.453\n",
      "    num_steps_sampled: 3790000\n",
      "    num_steps_trained: 3790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.059661559760570526\n",
      "      kl: 0.024576706811785698\n",
      "      policy_loss: 0.006870399694889784\n",
      "      total_loss: 47.67366409301758\n",
      "      vf_explained_var: 0.9684827923774719\n",
      "      vf_loss: 47.66679382324219\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10451775044202805\n",
      "      kl: 0.008391913957893848\n",
      "      policy_loss: -0.0014675036072731018\n",
      "      total_loss: 37.2652587890625\n",
      "      vf_explained_var: 0.9717358350753784\n",
      "      vf_loss: 37.2667236328125\n",
      "    sample_time_ms: 20253.943\n",
      "    update_time_ms: 8.347\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.49420926149449\n",
      "    rl_1: 67.70839978856537\n",
      "  time_since_restore: 8818.821885585785\n",
      "  time_this_iter_s: 23.679926872253418\n",
      "  time_total_s: 8818.821885585785\n",
      "  timestamp: 1550889416\n",
      "  timesteps_since_restore: 3790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3790000\n",
      "  training_iteration: 379\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8818 s, 379 iter, 3790000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-37-20\n",
      "  done: false\n",
      "  episode_len_mean: 101.74\n",
      "  episode_reward_max: 226.9298434792756\n",
      "  episode_reward_mean: 176.4280763848468\n",
      "  episode_reward_min: -146.23234810431794\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 31184\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.745\n",
      "    load_time_ms: 2.542\n",
      "    num_steps_sampled: 3800000\n",
      "    num_steps_trained: 3800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15873506665229797\n",
      "      kl: 0.014595357701182365\n",
      "      policy_loss: 0.0029477004427462816\n",
      "      total_loss: 23.27334976196289\n",
      "      vf_explained_var: 0.9790197610855103\n",
      "      vf_loss: 23.270401000976562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22632241249084473\n",
      "      kl: 0.008405723609030247\n",
      "      policy_loss: -0.0033357213251292706\n",
      "      total_loss: 15.790359497070312\n",
      "      vf_explained_var: 0.980107307434082\n",
      "      vf_loss: 15.793694496154785\n",
      "    sample_time_ms: 20294.013\n",
      "    update_time_ms: 8.261\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.69098295717502\n",
      "    rl_1: 77.7370934276718\n",
      "  time_since_restore: 8842.243365049362\n",
      "  time_this_iter_s: 23.42147946357727\n",
      "  time_total_s: 8842.243365049362\n",
      "  timestamp: 1550889440\n",
      "  timesteps_since_restore: 3800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3800000\n",
      "  training_iteration: 380\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8842 s, 380 iter, 3800000 ts, 176 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-37-43\n",
      "  done: false\n",
      "  episode_len_mean: 108.87\n",
      "  episode_reward_max: 230.85840576890195\n",
      "  episode_reward_mean: 166.48733859880355\n",
      "  episode_reward_min: -162.80332354886212\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 31275\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.064\n",
      "    load_time_ms: 2.537\n",
      "    num_steps_sampled: 3810000\n",
      "    num_steps_trained: 3810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.058232687413692474\n",
      "      kl: 0.010217893868684769\n",
      "      policy_loss: -0.0006685586413368583\n",
      "      total_loss: 23.1223201751709\n",
      "      vf_explained_var: 0.9809430241584778\n",
      "      vf_loss: 23.122987747192383\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09258710592985153\n",
      "      kl: 0.009691081941127777\n",
      "      policy_loss: 0.00029608135810121894\n",
      "      total_loss: 18.743391036987305\n",
      "      vf_explained_var: 0.980381429195404\n",
      "      vf_loss: 18.74309730529785\n",
      "    sample_time_ms: 20308.114\n",
      "    update_time_ms: 7.887\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.37049688957575\n",
      "    rl_1: 71.11684170922783\n",
      "  time_since_restore: 8865.616192817688\n",
      "  time_this_iter_s: 23.372827768325806\n",
      "  time_total_s: 8865.616192817688\n",
      "  timestamp: 1550889463\n",
      "  timesteps_since_restore: 3810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3810000\n",
      "  training_iteration: 381\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8865 s, 381 iter, 3810000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-38-07\n",
      "  done: false\n",
      "  episode_len_mean: 103.59\n",
      "  episode_reward_max: 234.67100449657912\n",
      "  episode_reward_mean: 150.80907776181235\n",
      "  episode_reward_min: -151.35284856399443\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 31371\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.972\n",
      "    load_time_ms: 2.478\n",
      "    num_steps_sampled: 3820000\n",
      "    num_steps_trained: 3820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0752461850643158\n",
      "      kl: 0.012874326668679714\n",
      "      policy_loss: -0.002309128176420927\n",
      "      total_loss: 38.614479064941406\n",
      "      vf_explained_var: 0.9754803776741028\n",
      "      vf_loss: 38.61677932739258\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21624523401260376\n",
      "      kl: 0.010577338747680187\n",
      "      policy_loss: 0.00011995410750387236\n",
      "      total_loss: 33.695823669433594\n",
      "      vf_explained_var: 0.9722004532814026\n",
      "      vf_loss: 33.69570541381836\n",
      "    sample_time_ms: 20335.074\n",
      "    update_time_ms: 7.841\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.79817923945144\n",
      "    rl_1: 63.01089852236091\n",
      "  time_since_restore: 8889.635518789291\n",
      "  time_this_iter_s: 24.019325971603394\n",
      "  time_total_s: 8889.635518789291\n",
      "  timestamp: 1550889487\n",
      "  timesteps_since_restore: 3820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3820000\n",
      "  training_iteration: 382\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8889 s, 382 iter, 3820000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 102.65\n",
      "  episode_reward_max: 230.99672923329842\n",
      "  episode_reward_mean: 162.26077860382884\n",
      "  episode_reward_min: -159.01606304231902\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 31469\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.012\n",
      "    load_time_ms: 2.468\n",
      "    num_steps_sampled: 3830000\n",
      "    num_steps_trained: 3830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09344227612018585\n",
      "      kl: 0.020113864913582802\n",
      "      policy_loss: -0.0004676156386267394\n",
      "      total_loss: 48.71331024169922\n",
      "      vf_explained_var: 0.962559163570404\n",
      "      vf_loss: 48.713775634765625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21633458137512207\n",
      "      kl: 0.01387784257531166\n",
      "      policy_loss: -0.0017335257725790143\n",
      "      total_loss: 38.20706558227539\n",
      "      vf_explained_var: 0.9629090428352356\n",
      "      vf_loss: 38.208805084228516\n",
      "    sample_time_ms: 20342.559\n",
      "    update_time_ms: 7.73\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.34647773799178\n",
      "    rl_1: 70.91430086583709\n",
      "  time_since_restore: 8912.70643234253\n",
      "  time_this_iter_s: 23.070913553237915\n",
      "  time_total_s: 8912.70643234253\n",
      "  timestamp: 1550889510\n",
      "  timesteps_since_restore: 3830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3830000\n",
      "  training_iteration: 383\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8912 s, 383 iter, 3830000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-38-54\n",
      "  done: false\n",
      "  episode_len_mean: 108.71\n",
      "  episode_reward_max: 228.14230404997426\n",
      "  episode_reward_mean: 141.21856160925455\n",
      "  episode_reward_min: -165.67603149479208\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 31562\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.587\n",
      "    load_time_ms: 2.542\n",
      "    num_steps_sampled: 3840000\n",
      "    num_steps_trained: 3840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.062002670019865036\n",
      "      kl: 2.7045016288757324\n",
      "      policy_loss: 0.04376178979873657\n",
      "      total_loss: 93.35033416748047\n",
      "      vf_explained_var: 0.9509977698326111\n",
      "      vf_loss: 93.30657958984375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12929211556911469\n",
      "      kl: 0.014129755087196827\n",
      "      policy_loss: -0.0013753456296399236\n",
      "      total_loss: 74.0479736328125\n",
      "      vf_explained_var: 0.9546804428100586\n",
      "      vf_loss: 74.04935455322266\n",
      "    sample_time_ms: 20320.673\n",
      "    update_time_ms: 7.782\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.18962672446715\n",
      "    rl_1: 59.028934884787404\n",
      "  time_since_restore: 8936.012395143509\n",
      "  time_this_iter_s: 23.305962800979614\n",
      "  time_total_s: 8936.012395143509\n",
      "  timestamp: 1550889534\n",
      "  timesteps_since_restore: 3840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3840000\n",
      "  training_iteration: 384\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8936 s, 384 iter, 3840000 ts, 141 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-39-17\n",
      "  done: false\n",
      "  episode_len_mean: 107.48\n",
      "  episode_reward_max: 223.88911872193026\n",
      "  episode_reward_mean: 160.2015079081882\n",
      "  episode_reward_min: -167.3784356643535\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 31656\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3101.163\n",
      "    load_time_ms: 2.562\n",
      "    num_steps_sampled: 3850000\n",
      "    num_steps_trained: 3850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.00926315225660801\n",
      "      kl: 0.02689841389656067\n",
      "      policy_loss: 0.002705354243516922\n",
      "      total_loss: 67.39266967773438\n",
      "      vf_explained_var: 0.9540701508522034\n",
      "      vf_loss: 67.38995361328125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.14982716739177704\n",
      "      kl: 0.01183665357530117\n",
      "      policy_loss: -0.0004717073461506516\n",
      "      total_loss: 55.001365661621094\n",
      "      vf_explained_var: 0.9537907838821411\n",
      "      vf_loss: 55.00183868408203\n",
      "    sample_time_ms: 20313.331\n",
      "    update_time_ms: 7.637\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.9263859738257\n",
      "    rl_1: 68.27512193436247\n",
      "  time_since_restore: 8959.228026628494\n",
      "  time_this_iter_s: 23.21563148498535\n",
      "  time_total_s: 8959.228026628494\n",
      "  timestamp: 1550889557\n",
      "  timesteps_since_restore: 3850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3850000\n",
      "  training_iteration: 385\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8959 s, 385 iter, 3850000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-39-40\n",
      "  done: false\n",
      "  episode_len_mean: 113.18\n",
      "  episode_reward_max: 223.88911872193026\n",
      "  episode_reward_mean: 165.4759030880317\n",
      "  episode_reward_min: -140.64059048395234\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 31745\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.767\n",
      "    load_time_ms: 2.472\n",
      "    num_steps_sampled: 3860000\n",
      "    num_steps_trained: 3860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.12332717329263687\n",
      "      kl: 0.049540482461452484\n",
      "      policy_loss: 0.015080011449754238\n",
      "      total_loss: 37.95240020751953\n",
      "      vf_explained_var: 0.970664381980896\n",
      "      vf_loss: 37.937320709228516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.02940754033625126\n",
      "      kl: 0.014991922304034233\n",
      "      policy_loss: 0.00173291377723217\n",
      "      total_loss: 31.9074764251709\n",
      "      vf_explained_var: 0.9708752036094666\n",
      "      vf_loss: 31.905742645263672\n",
      "    sample_time_ms: 20336.846\n",
      "    update_time_ms: 7.638\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.94181467615446\n",
      "    rl_1: 70.53408841187726\n",
      "  time_since_restore: 8982.598571062088\n",
      "  time_this_iter_s: 23.37054443359375\n",
      "  time_total_s: 8982.598571062088\n",
      "  timestamp: 1550889580\n",
      "  timesteps_since_restore: 3860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3860000\n",
      "  training_iteration: 386\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 8982 s, 386 iter, 3860000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 101.79\n",
      "  episode_reward_max: 220.2138886228461\n",
      "  episode_reward_mean: 163.24535220921445\n",
      "  episode_reward_min: -162.43101937149328\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 31843\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.943\n",
      "    load_time_ms: 2.471\n",
      "    num_steps_sampled: 3870000\n",
      "    num_steps_trained: 3870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10348594933748245\n",
      "      kl: 0.00902608223259449\n",
      "      policy_loss: 0.0010020125191658735\n",
      "      total_loss: 57.02421951293945\n",
      "      vf_explained_var: 0.9608798027038574\n",
      "      vf_loss: 57.02321243286133\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1856040060520172\n",
      "      kl: 0.010922310873866081\n",
      "      policy_loss: -0.001047241617925465\n",
      "      total_loss: 46.76809310913086\n",
      "      vf_explained_var: 0.9617050290107727\n",
      "      vf_loss: 46.76913833618164\n",
      "    sample_time_ms: 20400.87\n",
      "    update_time_ms: 7.449\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.73940547812245\n",
      "    rl_1: 71.50594673109201\n",
      "  time_since_restore: 9006.351789474487\n",
      "  time_this_iter_s: 23.753218412399292\n",
      "  time_total_s: 9006.351789474487\n",
      "  timestamp: 1550889604\n",
      "  timesteps_since_restore: 3870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3870000\n",
      "  training_iteration: 387\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9006 s, 387 iter, 3870000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-40-28\n",
      "  done: false\n",
      "  episode_len_mean: 96.47572815533981\n",
      "  episode_reward_max: 227.9313573562465\n",
      "  episode_reward_mean: 140.0985343660576\n",
      "  episode_reward_min: -178.2601014288174\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 31946\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.266\n",
      "    load_time_ms: 2.407\n",
      "    num_steps_sampled: 3880000\n",
      "    num_steps_trained: 3880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.16104193031787872\n",
      "      kl: 0.02413852885365486\n",
      "      policy_loss: 0.004147970583289862\n",
      "      total_loss: 78.05118560791016\n",
      "      vf_explained_var: 0.9648535251617432\n",
      "      vf_loss: 78.04705047607422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2442978322505951\n",
      "      kl: 0.014525847509503365\n",
      "      policy_loss: -0.00012171989510534331\n",
      "      total_loss: 61.64271545410156\n",
      "      vf_explained_var: 0.9684059023857117\n",
      "      vf_loss: 61.64284896850586\n",
      "    sample_time_ms: 20369.327\n",
      "    update_time_ms: 7.514\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.0500364095013\n",
      "    rl_1: 62.04849795655628\n",
      "  time_since_restore: 9029.970018148422\n",
      "  time_this_iter_s: 23.618228673934937\n",
      "  time_total_s: 9029.970018148422\n",
      "  timestamp: 1550889628\n",
      "  timesteps_since_restore: 3880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3880000\n",
      "  training_iteration: 388\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9029 s, 388 iter, 3880000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-40-51\n",
      "  done: false\n",
      "  episode_len_mean: 103.58\n",
      "  episode_reward_max: 234.10368239221813\n",
      "  episode_reward_mean: 173.6584096588526\n",
      "  episode_reward_min: -147.29694327446552\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 32043\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.356\n",
      "    load_time_ms: 2.377\n",
      "    num_steps_sampled: 3890000\n",
      "    num_steps_trained: 3890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09507933259010315\n",
      "      kl: 0.02020190842449665\n",
      "      policy_loss: 0.0026835878379642963\n",
      "      total_loss: 27.457958221435547\n",
      "      vf_explained_var: 0.9764986038208008\n",
      "      vf_loss: 27.455272674560547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19508197903633118\n",
      "      kl: 0.015105926431715488\n",
      "      policy_loss: 0.003699110122397542\n",
      "      total_loss: 28.096466064453125\n",
      "      vf_explained_var: 0.970229983329773\n",
      "      vf_loss: 28.0927677154541\n",
      "    sample_time_ms: 20307.658\n",
      "    update_time_ms: 6.904\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.04765332025131\n",
      "    rl_1: 75.6107563386013\n",
      "  time_since_restore: 9053.004912137985\n",
      "  time_this_iter_s: 23.03489398956299\n",
      "  time_total_s: 9053.004912137985\n",
      "  timestamp: 1550889651\n",
      "  timesteps_since_restore: 3890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3890000\n",
      "  training_iteration: 389\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9053 s, 389 iter, 3890000 ts, 174 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-41-14\n",
      "  done: false\n",
      "  episode_len_mean: 107.95\n",
      "  episode_reward_max: 227.79192102502586\n",
      "  episode_reward_mean: 160.2075794765736\n",
      "  episode_reward_min: -167.7297304677841\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 32135\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.428\n",
      "    load_time_ms: 2.289\n",
      "    num_steps_sampled: 3900000\n",
      "    num_steps_trained: 3900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.021905366331338882\n",
      "      kl: 0.01448651123791933\n",
      "      policy_loss: 0.0019924186635762453\n",
      "      total_loss: 52.85721969604492\n",
      "      vf_explained_var: 0.9661123752593994\n",
      "      vf_loss: 52.85523223876953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08682975172996521\n",
      "      kl: 0.025088369846343994\n",
      "      policy_loss: 0.0017011360032483935\n",
      "      total_loss: 39.26925277709961\n",
      "      vf_explained_var: 0.9700666666030884\n",
      "      vf_loss: 39.267547607421875\n",
      "    sample_time_ms: 20251.574\n",
      "    update_time_ms: 7.115\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.25637921579205\n",
      "    rl_1: 68.95120026078156\n",
      "  time_since_restore: 9075.803786039352\n",
      "  time_this_iter_s: 22.798873901367188\n",
      "  time_total_s: 9075.803786039352\n",
      "  timestamp: 1550889674\n",
      "  timesteps_since_restore: 3900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3900000\n",
      "  training_iteration: 390\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9075 s, 390 iter, 3900000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-41-37\n",
      "  done: false\n",
      "  episode_len_mean: 105.09\n",
      "  episode_reward_max: 232.65157392166807\n",
      "  episode_reward_mean: 161.43474898461545\n",
      "  episode_reward_min: -172.2118493399824\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 32230\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3094.62\n",
      "    load_time_ms: 2.293\n",
      "    num_steps_sampled: 3910000\n",
      "    num_steps_trained: 3910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08006071299314499\n",
      "      kl: 0.029417945072054863\n",
      "      policy_loss: 0.011395012028515339\n",
      "      total_loss: 36.87614440917969\n",
      "      vf_explained_var: 0.9744985699653625\n",
      "      vf_loss: 36.864742279052734\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2133253961801529\n",
      "      kl: 0.012594743631780148\n",
      "      policy_loss: -0.001189034665003419\n",
      "      total_loss: 33.679908752441406\n",
      "      vf_explained_var: 0.9698858261108398\n",
      "      vf_loss: 33.68110275268555\n",
      "    sample_time_ms: 20242.605\n",
      "    update_time_ms: 6.883\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.59259868842017\n",
      "    rl_1: 68.84215029619527\n",
      "  time_since_restore: 9099.255232095718\n",
      "  time_this_iter_s: 23.451446056365967\n",
      "  time_total_s: 9099.255232095718\n",
      "  timestamp: 1550889697\n",
      "  timesteps_since_restore: 3910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3910000\n",
      "  training_iteration: 391\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9099 s, 391 iter, 3910000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-42-01\n",
      "  done: false\n",
      "  episode_len_mean: 106.59\n",
      "  episode_reward_max: 226.52832159639675\n",
      "  episode_reward_mean: 156.10826291663415\n",
      "  episode_reward_min: -172.2118493399824\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 32324\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.087\n",
      "    load_time_ms: 2.287\n",
      "    num_steps_sampled: 3920000\n",
      "    num_steps_trained: 3920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.04273626208305359\n",
      "      kl: 0.023239905014634132\n",
      "      policy_loss: 0.0006919314037077129\n",
      "      total_loss: 40.091209411621094\n",
      "      vf_explained_var: 0.9722814559936523\n",
      "      vf_loss: 40.090518951416016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09441031515598297\n",
      "      kl: 0.009625913575291634\n",
      "      policy_loss: 0.0022833908442407846\n",
      "      total_loss: 32.35146713256836\n",
      "      vf_explained_var: 0.9733657836914062\n",
      "      vf_loss: 32.34919357299805\n",
      "    sample_time_ms: 20215.218\n",
      "    update_time_ms: 6.771\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.16133109217097\n",
      "    rl_1: 66.94693182446318\n",
      "  time_since_restore: 9122.777155399323\n",
      "  time_this_iter_s: 23.521923303604126\n",
      "  time_total_s: 9122.777155399323\n",
      "  timestamp: 1550889721\n",
      "  timesteps_since_restore: 3920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3920000\n",
      "  training_iteration: 392\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9122 s, 392 iter, 3920000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-42-24\n",
      "  done: false\n",
      "  episode_len_mean: 102.55\n",
      "  episode_reward_max: 229.26533924094053\n",
      "  episode_reward_mean: 162.19249607271908\n",
      "  episode_reward_min: -171.165267654605\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 32421\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.465\n",
      "    load_time_ms: 2.3\n",
      "    num_steps_sampled: 3930000\n",
      "    num_steps_trained: 3930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12688620388507843\n",
      "      kl: 0.014842553064227104\n",
      "      policy_loss: -0.002382454229518771\n",
      "      total_loss: 66.13417053222656\n",
      "      vf_explained_var: 0.9533706903457642\n",
      "      vf_loss: 66.13655853271484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2377007007598877\n",
      "      kl: 0.01674753427505493\n",
      "      policy_loss: -7.535239274147898e-05\n",
      "      total_loss: 51.43759536743164\n",
      "      vf_explained_var: 0.9524931311607361\n",
      "      vf_loss: 51.437679290771484\n",
      "    sample_time_ms: 20240.842\n",
      "    update_time_ms: 6.697\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.37731121629557\n",
      "    rl_1: 69.81518485642351\n",
      "  time_since_restore: 9146.106693983078\n",
      "  time_this_iter_s: 23.329538583755493\n",
      "  time_total_s: 9146.106693983078\n",
      "  timestamp: 1550889744\n",
      "  timesteps_since_restore: 3930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3930000\n",
      "  training_iteration: 393\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9146 s, 393 iter, 3930000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-42-47\n",
      "  done: false\n",
      "  episode_len_mean: 108.39\n",
      "  episode_reward_max: 227.13641897038406\n",
      "  episode_reward_mean: 162.49877854888263\n",
      "  episode_reward_min: -169.3560418945437\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 32513\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.413\n",
      "    load_time_ms: 2.22\n",
      "    num_steps_sampled: 3940000\n",
      "    num_steps_trained: 3940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.0872664526104927\n",
      "      kl: 0.012604176998138428\n",
      "      policy_loss: 0.0011858795769512653\n",
      "      total_loss: 56.24444580078125\n",
      "      vf_explained_var: 0.9581192135810852\n",
      "      vf_loss: 56.24325942993164\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07313451170921326\n",
      "      kl: 0.014138670638203621\n",
      "      policy_loss: -0.001653107930906117\n",
      "      total_loss: 41.59095001220703\n",
      "      vf_explained_var: 0.9649108648300171\n",
      "      vf_loss: 41.59260177612305\n",
      "    sample_time_ms: 20223.291\n",
      "    update_time_ms: 6.994\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.3458841820256\n",
      "    rl_1: 71.15289436685703\n",
      "  time_since_restore: 9169.226763248444\n",
      "  time_this_iter_s: 23.1200692653656\n",
      "  time_total_s: 9169.226763248444\n",
      "  timestamp: 1550889767\n",
      "  timesteps_since_restore: 3940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3940000\n",
      "  training_iteration: 394\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9169 s, 394 iter, 3940000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-43-11\n",
      "  done: false\n",
      "  episode_len_mean: 101.28\n",
      "  episode_reward_max: 231.37688984935596\n",
      "  episode_reward_mean: 158.49651864218526\n",
      "  episode_reward_min: -170.8171500478234\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 32612\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.621\n",
      "    load_time_ms: 2.266\n",
      "    num_steps_sampled: 3950000\n",
      "    num_steps_trained: 3950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10204244405031204\n",
      "      kl: 0.012269273400306702\n",
      "      policy_loss: -0.0003662974922917783\n",
      "      total_loss: 43.4372673034668\n",
      "      vf_explained_var: 0.9700936675071716\n",
      "      vf_loss: 43.4376335144043\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.23669074475765228\n",
      "      kl: 0.012810749001801014\n",
      "      policy_loss: -0.002092452486976981\n",
      "      total_loss: 42.4340705871582\n",
      "      vf_explained_var: 0.9628487825393677\n",
      "      vf_loss: 42.4361572265625\n",
      "    sample_time_ms: 20226.523\n",
      "    update_time_ms: 6.979\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.44309477608468\n",
      "    rl_1: 68.0534238661006\n",
      "  time_since_restore: 9192.466164112091\n",
      "  time_this_iter_s: 23.23940086364746\n",
      "  time_total_s: 9192.466164112091\n",
      "  timestamp: 1550889791\n",
      "  timesteps_since_restore: 3950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3950000\n",
      "  training_iteration: 395\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9192 s, 395 iter, 3950000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-43-34\n",
      "  done: false\n",
      "  episode_len_mean: 105.43\n",
      "  episode_reward_max: 227.84590446261058\n",
      "  episode_reward_mean: 155.5167752803912\n",
      "  episode_reward_min: -169.96995748242875\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 32706\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.726\n",
      "    load_time_ms: 2.384\n",
      "    num_steps_sampled: 3960000\n",
      "    num_steps_trained: 3960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06339626759290695\n",
      "      kl: 0.011813472025096416\n",
      "      policy_loss: 0.0003158049948979169\n",
      "      total_loss: 63.174285888671875\n",
      "      vf_explained_var: 0.9601229429244995\n",
      "      vf_loss: 63.17396545410156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0897146612405777\n",
      "      kl: 0.01925733871757984\n",
      "      policy_loss: 0.0020603693556040525\n",
      "      total_loss: 55.398719787597656\n",
      "      vf_explained_var: 0.9576659798622131\n",
      "      vf_loss: 55.39666748046875\n",
      "    sample_time_ms: 20202.632\n",
      "    update_time_ms: 6.972\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.2921160887292\n",
      "    rl_1: 67.22465919166198\n",
      "  time_since_restore: 9215.567557096481\n",
      "  time_this_iter_s: 23.10139298439026\n",
      "  time_total_s: 9215.567557096481\n",
      "  timestamp: 1550889814\n",
      "  timesteps_since_restore: 3960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3960000\n",
      "  training_iteration: 396\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9215 s, 396 iter, 3960000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-43-57\n",
      "  done: false\n",
      "  episode_len_mean: 111.71\n",
      "  episode_reward_max: 228.15876544431367\n",
      "  episode_reward_mean: 164.2303425048194\n",
      "  episode_reward_min: -163.70429497696125\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 32795\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.933\n",
      "    load_time_ms: 2.347\n",
      "    num_steps_sampled: 3970000\n",
      "    num_steps_trained: 3970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.1516772359609604\n",
      "      kl: 0.01893518678843975\n",
      "      policy_loss: 0.0029185176827013493\n",
      "      total_loss: 63.93546676635742\n",
      "      vf_explained_var: 0.9519482851028442\n",
      "      vf_loss: 63.93252944946289\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.04070856422185898\n",
      "      kl: 0.01689339429140091\n",
      "      policy_loss: 0.003206077963113785\n",
      "      total_loss: 47.18024444580078\n",
      "      vf_explained_var: 0.9572863578796387\n",
      "      vf_loss: 47.17703628540039\n",
      "    sample_time_ms: 20165.937\n",
      "    update_time_ms: 6.83\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.54677495186513\n",
      "    rl_1: 69.68356755295424\n",
      "  time_since_restore: 9238.922432661057\n",
      "  time_this_iter_s: 23.354875564575195\n",
      "  time_total_s: 9238.922432661057\n",
      "  timestamp: 1550889837\n",
      "  timesteps_since_restore: 3970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3970000\n",
      "  training_iteration: 397\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9238 s, 397 iter, 3970000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-44-21\n",
      "  done: false\n",
      "  episode_len_mean: 100.41\n",
      "  episode_reward_max: 230.61681026500818\n",
      "  episode_reward_mean: 154.47715151861618\n",
      "  episode_reward_min: -173.90725989775638\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 32895\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.674\n",
      "    load_time_ms: 2.345\n",
      "    num_steps_sampled: 3980000\n",
      "    num_steps_trained: 3980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11466989666223526\n",
      "      kl: 0.028913263231515884\n",
      "      policy_loss: 0.007102932780981064\n",
      "      total_loss: 76.05027770996094\n",
      "      vf_explained_var: 0.9580252170562744\n",
      "      vf_loss: 76.04315948486328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2255535125732422\n",
      "      kl: 0.015724075958132744\n",
      "      policy_loss: -0.0006679351208731532\n",
      "      total_loss: 60.51613235473633\n",
      "      vf_explained_var: 0.9572194218635559\n",
      "      vf_loss: 60.516788482666016\n",
      "    sample_time_ms: 20164.958\n",
      "    update_time_ms: 6.679\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.93871551326751\n",
      "    rl_1: 66.53843600534871\n",
      "  time_since_restore: 9262.526857614517\n",
      "  time_this_iter_s: 23.604424953460693\n",
      "  time_total_s: 9262.526857614517\n",
      "  timestamp: 1550889861\n",
      "  timesteps_since_restore: 3980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3980000\n",
      "  training_iteration: 398\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9262 s, 398 iter, 3980000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-44-44\n",
      "  done: false\n",
      "  episode_len_mean: 104.1\n",
      "  episode_reward_max: 225.69846780471738\n",
      "  episode_reward_mean: 167.5456515989065\n",
      "  episode_reward_min: -174.51071123389426\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 32991\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.791\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 3990000\n",
      "    num_steps_trained: 3990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.03142287954688072\n",
      "      kl: 0.016690082848072052\n",
      "      policy_loss: 0.00017996228416450322\n",
      "      total_loss: 54.23341751098633\n",
      "      vf_explained_var: 0.9627128839492798\n",
      "      vf_loss: 54.23323440551758\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1908475011587143\n",
      "      kl: 0.017235001549124718\n",
      "      policy_loss: -0.0005171642987988889\n",
      "      total_loss: 48.23046875\n",
      "      vf_explained_var: 0.956340491771698\n",
      "      vf_loss: 48.23098373413086\n",
      "    sample_time_ms: 20202.313\n",
      "    update_time_ms: 6.829\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.2589165391974\n",
      "    rl_1: 72.28673505970912\n",
      "  time_since_restore: 9285.922521591187\n",
      "  time_this_iter_s: 23.39566397666931\n",
      "  time_total_s: 9285.922521591187\n",
      "  timestamp: 1550889884\n",
      "  timesteps_since_restore: 3990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 3990000\n",
      "  training_iteration: 399\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9285 s, 399 iter, 3990000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-45-08\n",
      "  done: false\n",
      "  episode_len_mean: 103.21\n",
      "  episode_reward_max: 231.44534259600994\n",
      "  episode_reward_mean: 149.71599234764534\n",
      "  episode_reward_min: -174.51071123389426\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 33087\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.231\n",
      "    load_time_ms: 2.354\n",
      "    num_steps_sampled: 4000000\n",
      "    num_steps_trained: 4000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.01360798068344593\n",
      "      kl: 0.021491946652531624\n",
      "      policy_loss: 0.003945641219615936\n",
      "      total_loss: 50.79473114013672\n",
      "      vf_explained_var: 0.9696559309959412\n",
      "      vf_loss: 50.7907829284668\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1719561517238617\n",
      "      kl: 0.019854364916682243\n",
      "      policy_loss: 0.002760819159448147\n",
      "      total_loss: 44.8259162902832\n",
      "      vf_explained_var: 0.967763364315033\n",
      "      vf_loss: 44.82314682006836\n",
      "    sample_time_ms: 20312.645\n",
      "    update_time_ms: 6.563\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.64939240002288\n",
      "    rl_1: 63.06659994762245\n",
      "  time_since_restore: 9310.07883310318\n",
      "  time_this_iter_s: 24.156311511993408\n",
      "  time_total_s: 9310.07883310318\n",
      "  timestamp: 1550889908\n",
      "  timesteps_since_restore: 4000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4000000\n",
      "  training_iteration: 400\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9310 s, 400 iter, 4000000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-45-32\n",
      "  done: false\n",
      "  episode_len_mean: 101.42\n",
      "  episode_reward_max: 225.14582131914548\n",
      "  episode_reward_mean: 153.8095098120691\n",
      "  episode_reward_min: -165.754069841622\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 33186\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.547\n",
      "    load_time_ms: 2.408\n",
      "    num_steps_sampled: 4010000\n",
      "    num_steps_trained: 4010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09298983216285706\n",
      "      kl: 0.014572741463780403\n",
      "      policy_loss: 0.0006341657135635614\n",
      "      total_loss: 61.655303955078125\n",
      "      vf_explained_var: 0.9628387689590454\n",
      "      vf_loss: 61.65465545654297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21803736686706543\n",
      "      kl: 0.012152120471000671\n",
      "      policy_loss: 0.0005850984016433358\n",
      "      total_loss: 50.164794921875\n",
      "      vf_explained_var: 0.961973249912262\n",
      "      vf_loss: 50.16421127319336\n",
      "    sample_time_ms: 20335.774\n",
      "    update_time_ms: 6.653\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.30146465877966\n",
      "    rl_1: 66.50804515328949\n",
      "  time_since_restore: 9333.598995685577\n",
      "  time_this_iter_s: 23.52016258239746\n",
      "  time_total_s: 9333.598995685577\n",
      "  timestamp: 1550889932\n",
      "  timesteps_since_restore: 4010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4010000\n",
      "  training_iteration: 401\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9333 s, 401 iter, 4010000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-45-55\n",
      "  done: false\n",
      "  episode_len_mean: 109.13\n",
      "  episode_reward_max: 225.31879958460692\n",
      "  episode_reward_mean: 155.07864092146963\n",
      "  episode_reward_min: -149.10501991297465\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 33276\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.555\n",
      "    load_time_ms: 2.38\n",
      "    num_steps_sampled: 4020000\n",
      "    num_steps_trained: 4020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09030615538358688\n",
      "      kl: 0.03161066025495529\n",
      "      policy_loss: 0.007849828340113163\n",
      "      total_loss: 64.54192352294922\n",
      "      vf_explained_var: 0.9556570053100586\n",
      "      vf_loss: 64.5340805053711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12767332792282104\n",
      "      kl: 0.014502553269267082\n",
      "      policy_loss: 0.00296899420209229\n",
      "      total_loss: 49.17560958862305\n",
      "      vf_explained_var: 0.9619339108467102\n",
      "      vf_loss: 49.17264175415039\n",
      "    sample_time_ms: 20312.813\n",
      "    update_time_ms: 6.916\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.99431899434273\n",
      "    rl_1: 67.08432192712691\n",
      "  time_since_restore: 9356.8716776371\n",
      "  time_this_iter_s: 23.272681951522827\n",
      "  time_total_s: 9356.8716776371\n",
      "  timestamp: 1550889955\n",
      "  timesteps_since_restore: 4020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4020000\n",
      "  training_iteration: 402\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9356 s, 402 iter, 4020000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-46-18\n",
      "  done: false\n",
      "  episode_len_mean: 100.39\n",
      "  episode_reward_max: 234.72483884494565\n",
      "  episode_reward_mean: 165.3984683926967\n",
      "  episode_reward_min: -178.02607458407152\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 33376\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.588\n",
      "    load_time_ms: 2.434\n",
      "    num_steps_sampled: 4030000\n",
      "    num_steps_trained: 4030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07235581427812576\n",
      "      kl: 0.022906959056854248\n",
      "      policy_loss: 0.003792698960751295\n",
      "      total_loss: 55.980751037597656\n",
      "      vf_explained_var: 0.9606622457504272\n",
      "      vf_loss: 55.97696304321289\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2521454989910126\n",
      "      kl: 0.016099849715828896\n",
      "      policy_loss: 0.0002815578191075474\n",
      "      total_loss: 44.05754089355469\n",
      "      vf_explained_var: 0.9625133872032166\n",
      "      vf_loss: 44.057254791259766\n",
      "    sample_time_ms: 20280.706\n",
      "    update_time_ms: 7.241\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.07753467572842\n",
      "    rl_1: 72.32093371696826\n",
      "  time_since_restore: 9379.884774923325\n",
      "  time_this_iter_s: 23.013097286224365\n",
      "  time_total_s: 9379.884774923325\n",
      "  timestamp: 1550889978\n",
      "  timesteps_since_restore: 4030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4030000\n",
      "  training_iteration: 403\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9379 s, 403 iter, 4030000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-46-41\n",
      "  done: false\n",
      "  episode_len_mean: 103.22\n",
      "  episode_reward_max: 214.92877157348295\n",
      "  episode_reward_mean: 160.80802418936705\n",
      "  episode_reward_min: -135.46958623319938\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 33473\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.211\n",
      "    load_time_ms: 2.545\n",
      "    num_steps_sampled: 4040000\n",
      "    num_steps_trained: 4040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.05476653203368187\n",
      "      kl: 0.021568039432168007\n",
      "      policy_loss: 0.002991077257320285\n",
      "      total_loss: 31.614013671875\n",
      "      vf_explained_var: 0.9741735458374023\n",
      "      vf_loss: 31.611019134521484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2463938593864441\n",
      "      kl: 0.02636462263762951\n",
      "      policy_loss: 0.005907681304961443\n",
      "      total_loss: 26.58900260925293\n",
      "      vf_explained_var: 0.9714394807815552\n",
      "      vf_loss: 26.583091735839844\n",
      "    sample_time_ms: 20208.841\n",
      "    update_time_ms: 6.86\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.6189515874041\n",
      "    rl_1: 68.18907260196295\n",
      "  time_since_restore: 9402.314225673676\n",
      "  time_this_iter_s: 22.429450750350952\n",
      "  time_total_s: 9402.314225673676\n",
      "  timestamp: 1550890001\n",
      "  timesteps_since_restore: 4040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4040000\n",
      "  training_iteration: 404\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9402 s, 404 iter, 4040000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-47-04\n",
      "  done: false\n",
      "  episode_len_mean: 100.58\n",
      "  episode_reward_max: 230.18819150583948\n",
      "  episode_reward_mean: 163.04312018864442\n",
      "  episode_reward_min: -166.75752076971483\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 33572\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.367\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 4050000\n",
      "    num_steps_trained: 4050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1060997024178505\n",
      "      kl: 0.04746558889746666\n",
      "      policy_loss: 0.00839760061353445\n",
      "      total_loss: 50.960933685302734\n",
      "      vf_explained_var: 0.9665234088897705\n",
      "      vf_loss: 50.95254135131836\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.26231008768081665\n",
      "      kl: 0.016337184235453606\n",
      "      policy_loss: -0.00037371425423771143\n",
      "      total_loss: 36.67800521850586\n",
      "      vf_explained_var: 0.9704423546791077\n",
      "      vf_loss: 36.678375244140625\n",
      "    sample_time_ms: 20178.149\n",
      "    update_time_ms: 6.889\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.66340370391009\n",
      "    rl_1: 71.37971648473432\n",
      "  time_since_restore: 9425.23714351654\n",
      "  time_this_iter_s: 22.92291784286499\n",
      "  time_total_s: 9425.23714351654\n",
      "  timestamp: 1550890024\n",
      "  timesteps_since_restore: 4050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4050000\n",
      "  training_iteration: 405\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9425 s, 405 iter, 4050000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-47-27\n",
      "  done: false\n",
      "  episode_len_mean: 103.55\n",
      "  episode_reward_max: 232.49654676934702\n",
      "  episode_reward_mean: 148.20658669364656\n",
      "  episode_reward_min: -157.08927366864327\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 33669\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.665\n",
      "    load_time_ms: 2.391\n",
      "    num_steps_sampled: 4060000\n",
      "    num_steps_trained: 4060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.011148158460855484\n",
      "      kl: 0.01300089806318283\n",
      "      policy_loss: -0.001608666148968041\n",
      "      total_loss: 74.1291275024414\n",
      "      vf_explained_var: 0.9574658274650574\n",
      "      vf_loss: 74.1307373046875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17093491554260254\n",
      "      kl: 0.01613098755478859\n",
      "      policy_loss: 0.003808255773037672\n",
      "      total_loss: 60.45003128051758\n",
      "      vf_explained_var: 0.9600967764854431\n",
      "      vf_loss: 60.446231842041016\n",
      "    sample_time_ms: 20173.674\n",
      "    update_time_ms: 7.014\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.0785149017358\n",
      "    rl_1: 64.12807179191076\n",
      "  time_since_restore: 9448.28732419014\n",
      "  time_this_iter_s: 23.050180673599243\n",
      "  time_total_s: 9448.28732419014\n",
      "  timestamp: 1550890047\n",
      "  timesteps_since_restore: 4060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4060000\n",
      "  training_iteration: 406\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9448 s, 406 iter, 4060000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-47-50\n",
      "  done: false\n",
      "  episode_len_mean: 106.08\n",
      "  episode_reward_max: 226.26459941308877\n",
      "  episode_reward_mean: 157.64393566884326\n",
      "  episode_reward_min: -161.00592556148365\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 33763\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.845\n",
      "    load_time_ms: 2.47\n",
      "    num_steps_sampled: 4070000\n",
      "    num_steps_trained: 4070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.05929538607597351\n",
      "      kl: 0.032324571162462234\n",
      "      policy_loss: 0.006399556063115597\n",
      "      total_loss: 42.00574493408203\n",
      "      vf_explained_var: 0.9702913165092468\n",
      "      vf_loss: 41.999351501464844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2476089894771576\n",
      "      kl: 0.030645594000816345\n",
      "      policy_loss: 0.0020090092439204454\n",
      "      total_loss: 34.54234313964844\n",
      "      vf_explained_var: 0.9689103364944458\n",
      "      vf_loss: 34.54032897949219\n",
      "    sample_time_ms: 20175.145\n",
      "    update_time_ms: 7.047\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.50476073456808\n",
      "    rl_1: 66.13917493427518\n",
      "  time_since_restore: 9471.67149591446\n",
      "  time_this_iter_s: 23.384171724319458\n",
      "  time_total_s: 9471.67149591446\n",
      "  timestamp: 1550890070\n",
      "  timesteps_since_restore: 4070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4070000\n",
      "  training_iteration: 407\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9471 s, 407 iter, 4070000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-48-14\n",
      "  done: false\n",
      "  episode_len_mean: 102.25\n",
      "  episode_reward_max: 223.0422323459286\n",
      "  episode_reward_mean: 164.870124443213\n",
      "  episode_reward_min: -138.16755574444792\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 33861\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.687\n",
      "    load_time_ms: 2.487\n",
      "    num_steps_sampled: 4080000\n",
      "    num_steps_trained: 4080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0023297120351344347\n",
      "      kl: 0.010077678598463535\n",
      "      policy_loss: 0.0013972470769658685\n",
      "      total_loss: 32.65168762207031\n",
      "      vf_explained_var: 0.9732998609542847\n",
      "      vf_loss: 32.650291442871094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15214864909648895\n",
      "      kl: 0.01910160481929779\n",
      "      policy_loss: 1.982542198675219e-05\n",
      "      total_loss: 32.112911224365234\n",
      "      vf_explained_var: 0.9667173624038696\n",
      "      vf_loss: 32.11288833618164\n",
      "    sample_time_ms: 20164.599\n",
      "    update_time_ms: 7.385\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.64814726618616\n",
      "    rl_1: 72.22197717702682\n",
      "  time_since_restore: 9495.225796699524\n",
      "  time_this_iter_s: 23.554300785064697\n",
      "  time_total_s: 9495.225796699524\n",
      "  timestamp: 1550890094\n",
      "  timesteps_since_restore: 4080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4080000\n",
      "  training_iteration: 408\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9495 s, 408 iter, 4080000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-48-37\n",
      "  done: false\n",
      "  episode_len_mean: 102.09\n",
      "  episode_reward_max: 221.42372955399233\n",
      "  episode_reward_mean: 154.9330583608499\n",
      "  episode_reward_min: -175.62067290799868\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 33959\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.843\n",
      "    load_time_ms: 2.559\n",
      "    num_steps_sampled: 4090000\n",
      "    num_steps_trained: 4090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11563802510499954\n",
      "      kl: 0.022661976516246796\n",
      "      policy_loss: 0.003820352489128709\n",
      "      total_loss: 75.31112670898438\n",
      "      vf_explained_var: 0.9527777433395386\n",
      "      vf_loss: 75.30731201171875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2519432306289673\n",
      "      kl: 0.013446514494717121\n",
      "      policy_loss: 0.004528149031102657\n",
      "      total_loss: 62.223350524902344\n",
      "      vf_explained_var: 0.9516404271125793\n",
      "      vf_loss: 62.21883010864258\n",
      "    sample_time_ms: 20089.613\n",
      "    update_time_ms: 7.392\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.33764371852666\n",
      "    rl_1: 66.59541464232323\n",
      "  time_since_restore: 9517.958418130875\n",
      "  time_this_iter_s: 22.732621431350708\n",
      "  time_total_s: 9517.958418130875\n",
      "  timestamp: 1550890117\n",
      "  timesteps_since_restore: 4090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4090000\n",
      "  training_iteration: 409\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9517 s, 409 iter, 4090000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-49-00\n",
      "  done: false\n",
      "  episode_len_mean: 108.66\n",
      "  episode_reward_max: 228.77488205076216\n",
      "  episode_reward_mean: 151.1727746049699\n",
      "  episode_reward_min: -162.79674456354434\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 34052\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.969\n",
      "    load_time_ms: 2.547\n",
      "    num_steps_sampled: 4100000\n",
      "    num_steps_trained: 4100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.035754550248384476\n",
      "      kl: 0.013288099318742752\n",
      "      policy_loss: -0.000485369615489617\n",
      "      total_loss: 38.79843521118164\n",
      "      vf_explained_var: 0.97611004114151\n",
      "      vf_loss: 38.798919677734375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1958431899547577\n",
      "      kl: 0.01390919927507639\n",
      "      policy_loss: 0.0067479610443115234\n",
      "      total_loss: 30.243438720703125\n",
      "      vf_explained_var: 0.977964460849762\n",
      "      vf_loss: 30.2366943359375\n",
      "    sample_time_ms: 20023.168\n",
      "    update_time_ms: 7.455\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.71426251643663\n",
      "    rl_1: 63.45851208853332\n",
      "  time_since_restore: 9541.220664978027\n",
      "  time_this_iter_s: 23.26224684715271\n",
      "  time_total_s: 9541.220664978027\n",
      "  timestamp: 1550890140\n",
      "  timesteps_since_restore: 4100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4100000\n",
      "  training_iteration: 410\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9541 s, 410 iter, 4100000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-49-23\n",
      "  done: false\n",
      "  episode_len_mean: 105.76\n",
      "  episode_reward_max: 229.42946156965624\n",
      "  episode_reward_mean: 150.44055912921488\n",
      "  episode_reward_min: -168.52824822216658\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 34146\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.41\n",
      "    load_time_ms: 2.542\n",
      "    num_steps_sampled: 4110000\n",
      "    num_steps_trained: 4110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.003919572569429874\n",
      "      kl: 0.009118500165641308\n",
      "      policy_loss: 0.0011778023326769471\n",
      "      total_loss: 89.83267974853516\n",
      "      vf_explained_var: 0.9475522041320801\n",
      "      vf_loss: 89.83149719238281\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12784358859062195\n",
      "      kl: 0.014370916411280632\n",
      "      policy_loss: 0.0015273857861757278\n",
      "      total_loss: 63.340633392333984\n",
      "      vf_explained_var: 0.9553811550140381\n",
      "      vf_loss: 63.33909225463867\n",
      "    sample_time_ms: 19923.12\n",
      "    update_time_ms: 7.498\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.31265341105221\n",
      "    rl_1: 64.12790571816264\n",
      "  time_since_restore: 9563.743832349777\n",
      "  time_this_iter_s: 22.523167371749878\n",
      "  time_total_s: 9563.743832349777\n",
      "  timestamp: 1550890163\n",
      "  timesteps_since_restore: 4110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4110000\n",
      "  training_iteration: 411\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9563 s, 411 iter, 4110000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-49-46\n",
      "  done: false\n",
      "  episode_len_mean: 102.29\n",
      "  episode_reward_max: 229.35128293346597\n",
      "  episode_reward_mean: 158.03461971577215\n",
      "  episode_reward_min: -163.88210216839178\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 34243\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3060.107\n",
      "    load_time_ms: 2.592\n",
      "    num_steps_sampled: 4120000\n",
      "    num_steps_trained: 4120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1353427618741989\n",
      "      kl: 0.010349994525313377\n",
      "      policy_loss: 0.0004021697386633605\n",
      "      total_loss: 43.2571907043457\n",
      "      vf_explained_var: 0.9688454866409302\n",
      "      vf_loss: 43.25678253173828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.25550711154937744\n",
      "      kl: 0.016696754842996597\n",
      "      policy_loss: 0.00018448832270223647\n",
      "      total_loss: 39.26388931274414\n",
      "      vf_explained_var: 0.9635939002037048\n",
      "      vf_loss: 39.26369857788086\n",
      "    sample_time_ms: 19937.219\n",
      "    update_time_ms: 7.283\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.69540097262137\n",
      "    rl_1: 67.33921874315078\n",
      "  time_since_restore: 9587.1324198246\n",
      "  time_this_iter_s: 23.388587474822998\n",
      "  time_total_s: 9587.1324198246\n",
      "  timestamp: 1550890186\n",
      "  timesteps_since_restore: 4120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4120000\n",
      "  training_iteration: 412\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9587 s, 412 iter, 4120000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-50-09\n",
      "  done: false\n",
      "  episode_len_mean: 103.57\n",
      "  episode_reward_max: 220.02495144479843\n",
      "  episode_reward_mean: 171.02673941715045\n",
      "  episode_reward_min: -146.11912301882185\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 34340\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.722\n",
      "    load_time_ms: 2.526\n",
      "    num_steps_sampled: 4130000\n",
      "    num_steps_trained: 4130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1172165721654892\n",
      "      kl: 0.015945181250572205\n",
      "      policy_loss: 0.0021056735422462225\n",
      "      total_loss: 48.747100830078125\n",
      "      vf_explained_var: 0.9607824683189392\n",
      "      vf_loss: 48.744998931884766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24026702344417572\n",
      "      kl: 0.015131872147321701\n",
      "      policy_loss: -7.976706547196954e-05\n",
      "      total_loss: 45.53167724609375\n",
      "      vf_explained_var: 0.9490769505500793\n",
      "      vf_loss: 45.53176498413086\n",
      "    sample_time_ms: 19884.537\n",
      "    update_time_ms: 6.995\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.84081913438132\n",
      "    rl_1: 73.1859202827692\n",
      "  time_since_restore: 9609.808503389359\n",
      "  time_this_iter_s: 22.6760835647583\n",
      "  time_total_s: 9609.808503389359\n",
      "  timestamp: 1550890209\n",
      "  timesteps_since_restore: 4130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4130000\n",
      "  training_iteration: 413\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9609 s, 413 iter, 4130000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-50-31\n",
      "  done: false\n",
      "  episode_len_mean: 104.0\n",
      "  episode_reward_max: 228.20256887746385\n",
      "  episode_reward_mean: 161.08051666738635\n",
      "  episode_reward_min: -157.38744786788018\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 34437\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.149\n",
      "    load_time_ms: 2.528\n",
      "    num_steps_sampled: 4140000\n",
      "    num_steps_trained: 4140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.021182378754019737\n",
      "      kl: 0.043899308890104294\n",
      "      policy_loss: 0.01028038002550602\n",
      "      total_loss: 60.2024040222168\n",
      "      vf_explained_var: 0.9603408575057983\n",
      "      vf_loss: 60.19211959838867\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15416958928108215\n",
      "      kl: 0.009119687601923943\n",
      "      policy_loss: 0.001708979019895196\n",
      "      total_loss: 50.3925666809082\n",
      "      vf_explained_var: 0.9570003151893616\n",
      "      vf_loss: 50.39086151123047\n",
      "    sample_time_ms: 19905.137\n",
      "    update_time_ms: 7.019\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.51844604151619\n",
      "    rl_1: 68.56207062587012\n",
      "  time_since_restore: 9632.415130138397\n",
      "  time_this_iter_s: 22.606626749038696\n",
      "  time_total_s: 9632.415130138397\n",
      "  timestamp: 1550890231\n",
      "  timesteps_since_restore: 4140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4140000\n",
      "  training_iteration: 414\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9632 s, 414 iter, 4140000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 107.98\n",
      "  episode_reward_max: 229.6346326990391\n",
      "  episode_reward_mean: 156.47911835898807\n",
      "  episode_reward_min: -161.55202881965585\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 34528\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.711\n",
      "    load_time_ms: 2.514\n",
      "    num_steps_sampled: 4150000\n",
      "    num_steps_trained: 4150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.06753761321306229\n",
      "      kl: 0.011326272040605545\n",
      "      policy_loss: 0.0010197876254096627\n",
      "      total_loss: 50.510501861572266\n",
      "      vf_explained_var: 0.9675022959709167\n",
      "      vf_loss: 50.509483337402344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.136362686753273\n",
      "      kl: 0.02575512044131756\n",
      "      policy_loss: 0.006480793002992868\n",
      "      total_loss: 41.45904541015625\n",
      "      vf_explained_var: 0.9672772288322449\n",
      "      vf_loss: 41.45256423950195\n",
      "    sample_time_ms: 19875.765\n",
      "    update_time_ms: 6.98\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.5256242618109\n",
      "    rl_1: 65.95349409717714\n",
      "  time_since_restore: 9655.06907081604\n",
      "  time_this_iter_s: 22.653940677642822\n",
      "  time_total_s: 9655.06907081604\n",
      "  timestamp: 1550890254\n",
      "  timesteps_since_restore: 4150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4150000\n",
      "  training_iteration: 415\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9655 s, 415 iter, 4150000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-51-17\n",
      "  done: false\n",
      "  episode_len_mean: 103.17\n",
      "  episode_reward_max: 224.91962729649896\n",
      "  episode_reward_mean: 170.77001301782676\n",
      "  episode_reward_min: -151.2463408251444\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 34625\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.57\n",
      "    load_time_ms: 2.469\n",
      "    num_steps_sampled: 4160000\n",
      "    num_steps_trained: 4160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11355303227901459\n",
      "      kl: 0.021872855722904205\n",
      "      policy_loss: 0.0019074681913480163\n",
      "      total_loss: 37.590728759765625\n",
      "      vf_explained_var: 0.9719047546386719\n",
      "      vf_loss: 37.58882522583008\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2719596028327942\n",
      "      kl: 0.017049137502908707\n",
      "      policy_loss: -6.406637112377211e-05\n",
      "      total_loss: 30.373672485351562\n",
      "      vf_explained_var: 0.9705601930618286\n",
      "      vf_loss: 30.37373161315918\n",
      "    sample_time_ms: 19862.165\n",
      "    update_time_ms: 7.223\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.22747061075037\n",
      "    rl_1: 73.5425424070764\n",
      "  time_since_restore: 9677.991226434708\n",
      "  time_this_iter_s: 22.922155618667603\n",
      "  time_total_s: 9677.991226434708\n",
      "  timestamp: 1550890277\n",
      "  timesteps_since_restore: 4160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4160000\n",
      "  training_iteration: 416\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9677 s, 416 iter, 4160000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-51-40\n",
      "  done: false\n",
      "  episode_len_mean: 108.41\n",
      "  episode_reward_max: 226.89386513581908\n",
      "  episode_reward_mean: 163.09874955648843\n",
      "  episode_reward_min: -145.27450656478058\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 34716\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.536\n",
      "    load_time_ms: 2.493\n",
      "    num_steps_sampled: 4170000\n",
      "    num_steps_trained: 4170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08536428958177567\n",
      "      kl: 0.01375702116638422\n",
      "      policy_loss: 0.001181087107397616\n",
      "      total_loss: 39.58644104003906\n",
      "      vf_explained_var: 0.9712475538253784\n",
      "      vf_loss: 39.585262298583984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12995432317256927\n",
      "      kl: 0.017114490270614624\n",
      "      policy_loss: 0.004853674676269293\n",
      "      total_loss: 31.278226852416992\n",
      "      vf_explained_var: 0.9710937738418579\n",
      "      vf_loss: 31.273372650146484\n",
      "    sample_time_ms: 19849.591\n",
      "    update_time_ms: 7.199\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.30208885870927\n",
      "    rl_1: 69.79666069777919\n",
      "  time_since_restore: 9701.24111700058\n",
      "  time_this_iter_s: 23.249890565872192\n",
      "  time_total_s: 9701.24111700058\n",
      "  timestamp: 1550890300\n",
      "  timesteps_since_restore: 4170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4170000\n",
      "  training_iteration: 417\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9701 s, 417 iter, 4170000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-52-03\n",
      "  done: false\n",
      "  episode_len_mean: 101.4\n",
      "  episode_reward_max: 229.91617302514814\n",
      "  episode_reward_mean: 156.32882153736944\n",
      "  episode_reward_min: -159.40827282416765\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 34816\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.748\n",
      "    load_time_ms: 2.486\n",
      "    num_steps_sampled: 4180000\n",
      "    num_steps_trained: 4180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0041641974821686745\n",
      "      kl: 0.016373969614505768\n",
      "      policy_loss: 0.0007154113263823092\n",
      "      total_loss: 65.51554107666016\n",
      "      vf_explained_var: 0.9575977921485901\n",
      "      vf_loss: 65.51483917236328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12318980693817139\n",
      "      kl: 0.027453945949673653\n",
      "      policy_loss: -0.0002794241881929338\n",
      "      total_loss: 46.8503303527832\n",
      "      vf_explained_var: 0.9569575190544128\n",
      "      vf_loss: 46.85061264038086\n",
      "    sample_time_ms: 19783.141\n",
      "    update_time_ms: 6.947\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.73200386397797\n",
      "    rl_1: 66.59681767339143\n",
      "  time_since_restore: 9724.076877355576\n",
      "  time_this_iter_s: 22.835760354995728\n",
      "  time_total_s: 9724.076877355576\n",
      "  timestamp: 1550890323\n",
      "  timesteps_since_restore: 4180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4180000\n",
      "  training_iteration: 418\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9724 s, 418 iter, 4180000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-52-27\n",
      "  done: false\n",
      "  episode_len_mean: 102.47\n",
      "  episode_reward_max: 231.49204510046968\n",
      "  episode_reward_mean: 165.64396544876217\n",
      "  episode_reward_min: -166.58696895900846\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 34913\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.489\n",
      "    load_time_ms: 2.484\n",
      "    num_steps_sampled: 4190000\n",
      "    num_steps_trained: 4190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.05631009861826897\n",
      "      kl: 0.022206049412488937\n",
      "      policy_loss: 0.0015378134557977319\n",
      "      total_loss: 76.39070892333984\n",
      "      vf_explained_var: 0.9434370398521423\n",
      "      vf_loss: 76.38917541503906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19617190957069397\n",
      "      kl: 0.01696108467876911\n",
      "      policy_loss: 0.0011474993079900742\n",
      "      total_loss: 58.65625\n",
      "      vf_explained_var: 0.9463998675346375\n",
      "      vf_loss: 58.65510559082031\n",
      "    sample_time_ms: 19851.549\n",
      "    update_time_ms: 6.915\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.48127258600054\n",
      "    rl_1: 73.16269286276165\n",
      "  time_since_restore: 9747.424104690552\n",
      "  time_this_iter_s: 23.347227334976196\n",
      "  time_total_s: 9747.424104690552\n",
      "  timestamp: 1550890347\n",
      "  timesteps_since_restore: 4190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4190000\n",
      "  training_iteration: 419\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9747 s, 419 iter, 4190000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-52-50\n",
      "  done: false\n",
      "  episode_len_mean: 102.79\n",
      "  episode_reward_max: 222.6770308900435\n",
      "  episode_reward_mean: 147.4679668983391\n",
      "  episode_reward_min: -177.0248548126028\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 35010\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.38\n",
      "    load_time_ms: 2.475\n",
      "    num_steps_sampled: 4200000\n",
      "    num_steps_trained: 4200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.02643340639770031\n",
      "      kl: 0.018159084022045135\n",
      "      policy_loss: 0.0026386012323200703\n",
      "      total_loss: 59.132080078125\n",
      "      vf_explained_var: 0.9673463106155396\n",
      "      vf_loss: 59.129425048828125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15756376087665558\n",
      "      kl: 0.0205952487885952\n",
      "      policy_loss: 0.0019316845573484898\n",
      "      total_loss: 49.27374267578125\n",
      "      vf_explained_var: 0.966425359249115\n",
      "      vf_loss: 49.27181625366211\n",
      "    sample_time_ms: 19842.454\n",
      "    update_time_ms: 6.793\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.1845333829824\n",
      "    rl_1: 62.28343351535673\n",
      "  time_since_restore: 9770.59555888176\n",
      "  time_this_iter_s: 23.171454191207886\n",
      "  time_total_s: 9770.59555888176\n",
      "  timestamp: 1550890370\n",
      "  timesteps_since_restore: 4200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4200000\n",
      "  training_iteration: 420\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9770 s, 420 iter, 4200000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-53-13\n",
      "  done: false\n",
      "  episode_len_mean: 108.03\n",
      "  episode_reward_max: 229.39338936763494\n",
      "  episode_reward_mean: 151.88992879548465\n",
      "  episode_reward_min: -179.10628258959665\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 35103\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.818\n",
      "    load_time_ms: 2.431\n",
      "    num_steps_sampled: 4210000\n",
      "    num_steps_trained: 4210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.005032890010625124\n",
      "      kl: 0.0172028336673975\n",
      "      policy_loss: -0.002345283515751362\n",
      "      total_loss: 63.00789260864258\n",
      "      vf_explained_var: 0.9662368893623352\n",
      "      vf_loss: 63.01024627685547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.16967837512493134\n",
      "      kl: 0.01894702948629856\n",
      "      policy_loss: 0.0024010855704545975\n",
      "      total_loss: 55.837947845458984\n",
      "      vf_explained_var: 0.9624635577201843\n",
      "      vf_loss: 55.83554458618164\n",
      "    sample_time_ms: 19939.632\n",
      "    update_time_ms: 6.701\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.00716180323667\n",
      "    rl_1: 63.88276699224801\n",
      "  time_since_restore: 9794.083763837814\n",
      "  time_this_iter_s: 23.488204956054688\n",
      "  time_total_s: 9794.083763837814\n",
      "  timestamp: 1550890393\n",
      "  timesteps_since_restore: 4210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4210000\n",
      "  training_iteration: 421\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9794 s, 421 iter, 4210000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-53-37\n",
      "  done: false\n",
      "  episode_len_mean: 101.79\n",
      "  episode_reward_max: 230.05373604932353\n",
      "  episode_reward_mean: 155.91114454004324\n",
      "  episode_reward_min: -157.61516462070944\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 35201\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.283\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 4220000\n",
      "    num_steps_trained: 4220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11322527378797531\n",
      "      kl: 0.04424111917614937\n",
      "      policy_loss: 0.018448926508426666\n",
      "      total_loss: 86.4327392578125\n",
      "      vf_explained_var: 0.9447973966598511\n",
      "      vf_loss: 86.41429901123047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2094751000404358\n",
      "      kl: 0.01810705102980137\n",
      "      policy_loss: 0.0007091410807333887\n",
      "      total_loss: 76.24835968017578\n",
      "      vf_explained_var: 0.9399856925010681\n",
      "      vf_loss: 76.24764251708984\n",
      "    sample_time_ms: 19910.667\n",
      "    update_time_ms: 6.822\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.04445512656108\n",
      "    rl_1: 68.86668941348213\n",
      "  time_since_restore: 9817.291199445724\n",
      "  time_this_iter_s: 23.207435607910156\n",
      "  time_total_s: 9817.291199445724\n",
      "  timestamp: 1550890417\n",
      "  timesteps_since_restore: 4220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4220000\n",
      "  training_iteration: 422\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9817 s, 422 iter, 4220000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-53-59\n",
      "  done: false\n",
      "  episode_len_mean: 105.24\n",
      "  episode_reward_max: 227.968266509749\n",
      "  episode_reward_mean: 157.01303881426776\n",
      "  episode_reward_min: -155.1768640680212\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 35296\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3057.181\n",
      "    load_time_ms: 2.489\n",
      "    num_steps_sampled: 4230000\n",
      "    num_steps_trained: 4230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.025541851297020912\n",
      "      kl: 7.478530406951904\n",
      "      policy_loss: 0.05018502473831177\n",
      "      total_loss: 70.46883392333984\n",
      "      vf_explained_var: 0.9548664689064026\n",
      "      vf_loss: 70.41864776611328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.16109299659729004\n",
      "      kl: 0.015903254970908165\n",
      "      policy_loss: -0.0021126382052898407\n",
      "      total_loss: 63.29548645019531\n",
      "      vf_explained_var: 0.9521844387054443\n",
      "      vf_loss: 63.29759979248047\n",
      "    sample_time_ms: 19938.304\n",
      "    update_time_ms: 6.874\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.33647048077799\n",
      "    rl_1: 67.67656833348973\n",
      "  time_since_restore: 9840.033314466476\n",
      "  time_this_iter_s: 22.742115020751953\n",
      "  time_total_s: 9840.033314466476\n",
      "  timestamp: 1550890439\n",
      "  timesteps_since_restore: 4230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4230000\n",
      "  training_iteration: 423\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9840 s, 423 iter, 4230000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-54-22\n",
      "  done: false\n",
      "  episode_len_mean: 109.04\n",
      "  episode_reward_max: 235.35431029031048\n",
      "  episode_reward_mean: 159.50603091297904\n",
      "  episode_reward_min: -171.28440396814528\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 35391\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3056.315\n",
      "    load_time_ms: 2.361\n",
      "    num_steps_sampled: 4240000\n",
      "    num_steps_trained: 4240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09774903208017349\n",
      "      kl: 0.013296034187078476\n",
      "      policy_loss: 0.0012728520669043064\n",
      "      total_loss: 61.787803649902344\n",
      "      vf_explained_var: 0.9536598324775696\n",
      "      vf_loss: 61.78654479980469\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22536930441856384\n",
      "      kl: 0.020801739767193794\n",
      "      policy_loss: -0.0008739603799767792\n",
      "      total_loss: 54.779151916503906\n",
      "      vf_explained_var: 0.9507311582565308\n",
      "      vf_loss: 54.780029296875\n",
      "    sample_time_ms: 19971.776\n",
      "    update_time_ms: 7.058\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.45465459426883\n",
      "    rl_1: 69.05137631871024\n",
      "  time_since_restore: 9862.965795516968\n",
      "  time_this_iter_s: 22.932481050491333\n",
      "  time_total_s: 9862.965795516968\n",
      "  timestamp: 1550890462\n",
      "  timesteps_since_restore: 4240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4240000\n",
      "  training_iteration: 424\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9862 s, 424 iter, 4240000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 112.42\n",
      "  episode_reward_max: 228.88836386499347\n",
      "  episode_reward_mean: 160.3895686585506\n",
      "  episode_reward_min: -175.3318334606679\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 35481\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3053.85\n",
      "    load_time_ms: 2.414\n",
      "    num_steps_sampled: 4250000\n",
      "    num_steps_trained: 4250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.044243618845939636\n",
      "      kl: 0.019383667036890984\n",
      "      policy_loss: 0.003014196874573827\n",
      "      total_loss: 59.578426361083984\n",
      "      vf_explained_var: 0.9584229588508606\n",
      "      vf_loss: 59.57541275024414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2052861750125885\n",
      "      kl: 0.017307821661233902\n",
      "      policy_loss: 0.0002826908021233976\n",
      "      total_loss: 49.79801559448242\n",
      "      vf_explained_var: 0.957526683807373\n",
      "      vf_loss: 49.79773712158203\n",
      "    sample_time_ms: 20038.209\n",
      "    update_time_ms: 7.063\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.02398752214464\n",
      "    rl_1: 67.36558113640598\n",
      "  time_since_restore: 9886.25887131691\n",
      "  time_this_iter_s: 23.293075799942017\n",
      "  time_total_s: 9886.25887131691\n",
      "  timestamp: 1550890486\n",
      "  timesteps_since_restore: 4250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4250000\n",
      "  training_iteration: 425\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9886 s, 425 iter, 4250000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-55-09\n",
      "  done: false\n",
      "  episode_len_mean: 105.08\n",
      "  episode_reward_max: 223.84486786103687\n",
      "  episode_reward_mean: 165.11609178478582\n",
      "  episode_reward_min: -169.94911774641702\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 35577\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.715\n",
      "    load_time_ms: 2.416\n",
      "    num_steps_sampled: 4260000\n",
      "    num_steps_trained: 4260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10902170091867447\n",
      "      kl: 0.019480207934975624\n",
      "      policy_loss: 0.0023378925397992134\n",
      "      total_loss: 57.616512298583984\n",
      "      vf_explained_var: 0.9530954360961914\n",
      "      vf_loss: 57.61417007446289\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24767765402793884\n",
      "      kl: 0.014583026990294456\n",
      "      policy_loss: -0.0028600634541362524\n",
      "      total_loss: 45.31556701660156\n",
      "      vf_explained_var: 0.9506996273994446\n",
      "      vf_loss: 45.318424224853516\n",
      "    sample_time_ms: 20039.725\n",
      "    update_time_ms: 6.653\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.00894202264995\n",
      "    rl_1: 71.10714976213585\n",
      "  time_since_restore: 9909.413411855698\n",
      "  time_this_iter_s: 23.154540538787842\n",
      "  time_total_s: 9909.413411855698\n",
      "  timestamp: 1550890509\n",
      "  timesteps_since_restore: 4260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4260000\n",
      "  training_iteration: 426\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9909 s, 426 iter, 4260000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-55-32\n",
      "  done: false\n",
      "  episode_len_mean: 101.3\n",
      "  episode_reward_max: 231.89838284383583\n",
      "  episode_reward_mean: 153.87024698374128\n",
      "  episode_reward_min: -160.81360242008736\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 35675\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.244\n",
      "    load_time_ms: 2.32\n",
      "    num_steps_sampled: 4270000\n",
      "    num_steps_trained: 4270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.16925601661205292\n",
      "      kl: 0.02613564394414425\n",
      "      policy_loss: 0.010163215920329094\n",
      "      total_loss: 41.6409912109375\n",
      "      vf_explained_var: 0.977087676525116\n",
      "      vf_loss: 41.63083267211914\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2544174790382385\n",
      "      kl: 0.5329530239105225\n",
      "      policy_loss: 0.024460986256599426\n",
      "      total_loss: 36.27547073364258\n",
      "      vf_explained_var: 0.9736638069152832\n",
      "      vf_loss: 36.251014709472656\n",
      "    sample_time_ms: 20015.525\n",
      "    update_time_ms: 6.929\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.71284455693731\n",
      "    rl_1: 65.15740242680397\n",
      "  time_since_restore: 9932.426570177078\n",
      "  time_this_iter_s: 23.013158321380615\n",
      "  time_total_s: 9932.426570177078\n",
      "  timestamp: 1550890532\n",
      "  timesteps_since_restore: 4270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4270000\n",
      "  training_iteration: 427\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9932 s, 427 iter, 4270000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-55-55\n",
      "  done: false\n",
      "  episode_len_mean: 102.38\n",
      "  episode_reward_max: 223.820703019732\n",
      "  episode_reward_mean: 146.5560795456171\n",
      "  episode_reward_min: -161.47036455876338\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 35773\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.286\n",
      "    load_time_ms: 2.407\n",
      "    num_steps_sampled: 4280000\n",
      "    num_steps_trained: 4280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.08478233218193054\n",
      "      kl: 0.010068025439977646\n",
      "      policy_loss: 0.0009974800050258636\n",
      "      total_loss: 89.66029357910156\n",
      "      vf_explained_var: 0.956544816493988\n",
      "      vf_loss: 89.6593017578125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1898525357246399\n",
      "      kl: 0.020141329616308212\n",
      "      policy_loss: 0.0016209938330575824\n",
      "      total_loss: 72.94084167480469\n",
      "      vf_explained_var: 0.9560645818710327\n",
      "      vf_loss: 72.93923950195312\n",
      "    sample_time_ms: 20043.201\n",
      "    update_time_ms: 7.222\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.70417352187455\n",
      "    rl_1: 62.85190602374259\n",
      "  time_since_restore: 9955.574748754501\n",
      "  time_this_iter_s: 23.148178577423096\n",
      "  time_total_s: 9955.574748754501\n",
      "  timestamp: 1550890555\n",
      "  timesteps_since_restore: 4280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4280000\n",
      "  training_iteration: 428\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9955 s, 428 iter, 4280000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-56-19\n",
      "  done: false\n",
      "  episode_len_mean: 99.64356435643565\n",
      "  episode_reward_max: 227.143010706676\n",
      "  episode_reward_mean: 143.61183250991346\n",
      "  episode_reward_min: -181.24511852152\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 35874\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.517\n",
      "    load_time_ms: 2.351\n",
      "    num_steps_sampled: 4290000\n",
      "    num_steps_trained: 4290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18199118971824646\n",
      "      kl: 0.018772972747683525\n",
      "      policy_loss: 0.0018959564622491598\n",
      "      total_loss: 49.838096618652344\n",
      "      vf_explained_var: 0.9766669869422913\n",
      "      vf_loss: 49.8361930847168\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.26197338104248047\n",
      "      kl: 0.0159369595348835\n",
      "      policy_loss: -0.00026961887488141656\n",
      "      total_loss: 39.0063591003418\n",
      "      vf_explained_var: 0.9772108197212219\n",
      "      vf_loss: 39.00663757324219\n",
      "    sample_time_ms: 20064.314\n",
      "    update_time_ms: 7.284\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.9489248652242\n",
      "    rl_1: 61.66290764468923\n",
      "  time_since_restore: 9979.164608478546\n",
      "  time_this_iter_s: 23.5898597240448\n",
      "  time_total_s: 9979.164608478546\n",
      "  timestamp: 1550890579\n",
      "  timesteps_since_restore: 4290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4290000\n",
      "  training_iteration: 429\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 9979 s, 429 iter, 4290000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-56-42\n",
      "  done: false\n",
      "  episode_len_mean: 106.15\n",
      "  episode_reward_max: 223.45884475221777\n",
      "  episode_reward_mean: 163.82491670665235\n",
      "  episode_reward_min: -140.91615520449398\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 35967\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.523\n",
      "    load_time_ms: 2.436\n",
      "    num_steps_sampled: 4300000\n",
      "    num_steps_trained: 4300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09671155363321304\n",
      "      kl: 0.012485865503549576\n",
      "      policy_loss: -1.2632554899028037e-05\n",
      "      total_loss: 53.17809295654297\n",
      "      vf_explained_var: 0.9570803642272949\n",
      "      vf_loss: 53.178104400634766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22168278694152832\n",
      "      kl: 0.02022688277065754\n",
      "      policy_loss: 0.0004110712034162134\n",
      "      total_loss: 41.96661376953125\n",
      "      vf_explained_var: 0.9581506252288818\n",
      "      vf_loss: 41.96620559692383\n",
      "    sample_time_ms: 20091.979\n",
      "    update_time_ms: 7.339\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.95209921692978\n",
      "    rl_1: 70.87281748972255\n",
      "  time_since_restore: 10002.654377222061\n",
      "  time_this_iter_s: 23.489768743515015\n",
      "  time_total_s: 10002.654377222061\n",
      "  timestamp: 1550890602\n",
      "  timesteps_since_restore: 4300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4300000\n",
      "  training_iteration: 430\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10002 s, 430 iter, 4300000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-57-05\n",
      "  done: false\n",
      "  episode_len_mean: 105.59\n",
      "  episode_reward_max: 231.2082631036619\n",
      "  episode_reward_mean: 163.32788716267171\n",
      "  episode_reward_min: -168.42548681235473\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 36062\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.415\n",
      "    load_time_ms: 2.489\n",
      "    num_steps_sampled: 4310000\n",
      "    num_steps_trained: 4310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07755839824676514\n",
      "      kl: 0.01969352923333645\n",
      "      policy_loss: 0.004806989338248968\n",
      "      total_loss: 59.44622039794922\n",
      "      vf_explained_var: 0.9598373770713806\n",
      "      vf_loss: 59.4414176940918\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1962338238954544\n",
      "      kl: 0.022277100011706352\n",
      "      policy_loss: 0.004143205936998129\n",
      "      total_loss: 47.908447265625\n",
      "      vf_explained_var: 0.9613302946090698\n",
      "      vf_loss: 47.904300689697266\n",
      "    sample_time_ms: 20023.926\n",
      "    update_time_ms: 7.551\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.60610656127308\n",
      "    rl_1: 71.7217806013986\n",
      "  time_since_restore: 10025.471619606018\n",
      "  time_this_iter_s: 22.81724238395691\n",
      "  time_total_s: 10025.471619606018\n",
      "  timestamp: 1550890625\n",
      "  timesteps_since_restore: 4310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4310000\n",
      "  training_iteration: 431\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10025 s, 431 iter, 4310000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-57-28\n",
      "  done: false\n",
      "  episode_len_mean: 104.98\n",
      "  episode_reward_max: 228.48760169049768\n",
      "  episode_reward_mean: 163.0789710746587\n",
      "  episode_reward_min: -140.88920044657556\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 36156\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.8\n",
      "    load_time_ms: 2.543\n",
      "    num_steps_sampled: 4320000\n",
      "    num_steps_trained: 4320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10096584260463715\n",
      "      kl: 0.012462696060538292\n",
      "      policy_loss: 0.0012424445012584329\n",
      "      total_loss: 42.336727142333984\n",
      "      vf_explained_var: 0.9688427448272705\n",
      "      vf_loss: 42.335487365722656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19687147438526154\n",
      "      kl: 0.013513252139091492\n",
      "      policy_loss: -0.002009668154641986\n",
      "      total_loss: 37.839656829833984\n",
      "      vf_explained_var: 0.9640923738479614\n",
      "      vf_loss: 37.84166717529297\n",
      "    sample_time_ms: 19999.801\n",
      "    update_time_ms: 7.435\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.51269526793418\n",
      "    rl_1: 70.56627580672455\n",
      "  time_since_restore: 10048.391157388687\n",
      "  time_this_iter_s: 22.919537782669067\n",
      "  time_total_s: 10048.391157388687\n",
      "  timestamp: 1550890648\n",
      "  timesteps_since_restore: 4320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4320000\n",
      "  training_iteration: 432\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10048 s, 432 iter, 4320000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-57-51\n",
      "  done: false\n",
      "  episode_len_mean: 106.78\n",
      "  episode_reward_max: 233.12843616104598\n",
      "  episode_reward_mean: 164.0466131785903\n",
      "  episode_reward_min: -173.2107919566438\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 36252\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.971\n",
      "    load_time_ms: 2.489\n",
      "    num_steps_sampled: 4330000\n",
      "    num_steps_trained: 4330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10162440687417984\n",
      "      kl: 0.012265635654330254\n",
      "      policy_loss: 0.0008162145386449993\n",
      "      total_loss: 33.555564880371094\n",
      "      vf_explained_var: 0.9731440544128418\n",
      "      vf_loss: 33.55474853515625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1933363825082779\n",
      "      kl: 0.01576780527830124\n",
      "      policy_loss: 0.0046038259752094746\n",
      "      total_loss: 28.707441329956055\n",
      "      vf_explained_var: 0.9743717908859253\n",
      "      vf_loss: 28.70284080505371\n",
      "    sample_time_ms: 20032.293\n",
      "    update_time_ms: 7.639\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.1469727350025\n",
      "    rl_1: 71.89964044358781\n",
      "  time_since_restore: 10071.48412489891\n",
      "  time_this_iter_s: 23.09296751022339\n",
      "  time_total_s: 10071.48412489891\n",
      "  timestamp: 1550890671\n",
      "  timesteps_since_restore: 4330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4330000\n",
      "  training_iteration: 433\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10071 s, 433 iter, 4330000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-58-15\n",
      "  done: false\n",
      "  episode_len_mean: 105.4\n",
      "  episode_reward_max: 235.70587789260338\n",
      "  episode_reward_mean: 178.2652308685461\n",
      "  episode_reward_min: -150.03934900288573\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 36344\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.377\n",
      "    load_time_ms: 2.609\n",
      "    num_steps_sampled: 4340000\n",
      "    num_steps_trained: 4340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10911142826080322\n",
      "      kl: 0.0217018760740757\n",
      "      policy_loss: 0.005685986019670963\n",
      "      total_loss: 26.966571807861328\n",
      "      vf_explained_var: 0.9766846895217896\n",
      "      vf_loss: 26.96088409423828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18031276762485504\n",
      "      kl: 0.021319067105650902\n",
      "      policy_loss: 0.007059129420667887\n",
      "      total_loss: 24.971092224121094\n",
      "      vf_explained_var: 0.974043607711792\n",
      "      vf_loss: 24.964033126831055\n",
      "    sample_time_ms: 20087.158\n",
      "    update_time_ms: 7.657\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 100.76489723747669\n",
      "    rl_1: 77.50033363106944\n",
      "  time_since_restore: 10095.073330879211\n",
      "  time_this_iter_s: 23.589205980300903\n",
      "  time_total_s: 10095.073330879211\n",
      "  timestamp: 1550890695\n",
      "  timesteps_since_restore: 4340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4340000\n",
      "  training_iteration: 434\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10095 s, 434 iter, 4340000 ts, 178 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-58-38\n",
      "  done: false\n",
      "  episode_len_mean: 103.31\n",
      "  episode_reward_max: 229.52593687071737\n",
      "  episode_reward_mean: 159.6417990765418\n",
      "  episode_reward_min: -178.95124258744448\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 36444\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3117.939\n",
      "    load_time_ms: 2.683\n",
      "    num_steps_sampled: 4350000\n",
      "    num_steps_trained: 4350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19637012481689453\n",
      "      kl: 0.01203113328665495\n",
      "      policy_loss: 0.0006693722098134458\n",
      "      total_loss: 65.0290298461914\n",
      "      vf_explained_var: 0.9608443975448608\n",
      "      vf_loss: 65.02836608886719\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19469203054904938\n",
      "      kl: 0.013727081008255482\n",
      "      policy_loss: 0.0014095180667936802\n",
      "      total_loss: 56.31641387939453\n",
      "      vf_explained_var: 0.9552499651908875\n",
      "      vf_loss: 56.31500244140625\n",
      "    sample_time_ms: 20056.784\n",
      "    update_time_ms: 7.648\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.74915564903566\n",
      "    rl_1: 68.89264342750614\n",
      "  time_since_restore: 10118.291868448257\n",
      "  time_this_iter_s: 23.21853756904602\n",
      "  time_total_s: 10118.291868448257\n",
      "  timestamp: 1550890718\n",
      "  timesteps_since_restore: 4350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4350000\n",
      "  training_iteration: 435\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10118 s, 435 iter, 4350000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-59-01\n",
      "  done: false\n",
      "  episode_len_mean: 109.3\n",
      "  episode_reward_max: 228.49723025876466\n",
      "  episode_reward_mean: 149.7913652598902\n",
      "  episode_reward_min: -178.95124258744448\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 36533\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.89\n",
      "    load_time_ms: 2.667\n",
      "    num_steps_sampled: 4360000\n",
      "    num_steps_trained: 4360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.04308614507317543\n",
      "      kl: 0.01402581948786974\n",
      "      policy_loss: 0.0035983233246952295\n",
      "      total_loss: 41.09220886230469\n",
      "      vf_explained_var: 0.9701708555221558\n",
      "      vf_loss: 41.08861541748047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1039423942565918\n",
      "      kl: 0.016827860847115517\n",
      "      policy_loss: 0.002814982086420059\n",
      "      total_loss: 28.432933807373047\n",
      "      vf_explained_var: 0.9728335738182068\n",
      "      vf_loss: 28.430116653442383\n",
      "    sample_time_ms: 20014.909\n",
      "    update_time_ms: 7.7\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.10496400024144\n",
      "    rl_1: 62.68640125964878\n",
      "  time_since_restore: 10140.827434778214\n",
      "  time_this_iter_s: 22.535566329956055\n",
      "  time_total_s: 10140.827434778214\n",
      "  timestamp: 1550890741\n",
      "  timesteps_since_restore: 4360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4360000\n",
      "  training_iteration: 436\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10140 s, 436 iter, 4360000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-59-24\n",
      "  done: false\n",
      "  episode_len_mean: 106.35\n",
      "  episode_reward_max: 228.49723025876466\n",
      "  episode_reward_mean: 164.96669903603836\n",
      "  episode_reward_min: -143.91214512957754\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 36628\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3098.383\n",
      "    load_time_ms: 2.662\n",
      "    num_steps_sampled: 4370000\n",
      "    num_steps_trained: 4370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.16302385926246643\n",
      "      kl: 0.016603661701083183\n",
      "      policy_loss: 0.000338399171596393\n",
      "      total_loss: 23.695941925048828\n",
      "      vf_explained_var: 0.9812691807746887\n",
      "      vf_loss: 23.695602416992188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24203865230083466\n",
      "      kl: 0.015119431540369987\n",
      "      policy_loss: 0.005185004789382219\n",
      "      total_loss: 21.315317153930664\n",
      "      vf_explained_var: 0.9782509207725525\n",
      "      vf_loss: 21.310131072998047\n",
      "    sample_time_ms: 20022.601\n",
      "    update_time_ms: 7.585\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.8700933539934\n",
      "    rl_1: 70.09660568204495\n",
      "  time_since_restore: 10163.921256780624\n",
      "  time_this_iter_s: 23.09382200241089\n",
      "  time_total_s: 10163.921256780624\n",
      "  timestamp: 1550890764\n",
      "  timesteps_since_restore: 4370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4370000\n",
      "  training_iteration: 437\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10163 s, 437 iter, 4370000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_03-59-47\n",
      "  done: false\n",
      "  episode_len_mean: 106.36\n",
      "  episode_reward_max: 226.69194897091563\n",
      "  episode_reward_mean: 171.41600947424232\n",
      "  episode_reward_min: -143.91214512957754\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 36722\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3094.896\n",
      "    load_time_ms: 2.584\n",
      "    num_steps_sampled: 4380000\n",
      "    num_steps_trained: 4380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07765945047140121\n",
      "      kl: 0.010939485393464565\n",
      "      policy_loss: 0.0032667587511241436\n",
      "      total_loss: 19.429380416870117\n",
      "      vf_explained_var: 0.9806755185127258\n",
      "      vf_loss: 19.426116943359375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.14485815167427063\n",
      "      kl: 0.02044195868074894\n",
      "      policy_loss: 0.00704731373116374\n",
      "      total_loss: 15.418220520019531\n",
      "      vf_explained_var: 0.9791699051856995\n",
      "      vf_loss: 15.411173820495605\n",
      "    sample_time_ms: 20007.932\n",
      "    update_time_ms: 7.377\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.07052875811381\n",
      "    rl_1: 73.3454807161285\n",
      "  time_since_restore: 10186.884521722794\n",
      "  time_this_iter_s: 22.96326494216919\n",
      "  time_total_s: 10186.884521722794\n",
      "  timestamp: 1550890787\n",
      "  timesteps_since_restore: 4380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4380000\n",
      "  training_iteration: 438\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10186 s, 438 iter, 4380000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-00-10\n",
      "  done: false\n",
      "  episode_len_mean: 104.83\n",
      "  episode_reward_max: 227.43572594214328\n",
      "  episode_reward_mean: 156.65627767759747\n",
      "  episode_reward_min: -159.3113231914337\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 36818\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.529\n",
      "    load_time_ms: 2.614\n",
      "    num_steps_sampled: 4390000\n",
      "    num_steps_trained: 4390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09751004725694656\n",
      "      kl: 0.02014823816716671\n",
      "      policy_loss: 0.004532704595476389\n",
      "      total_loss: 47.99576187133789\n",
      "      vf_explained_var: 0.9684997797012329\n",
      "      vf_loss: 47.99122619628906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17041605710983276\n",
      "      kl: 0.01282371487468481\n",
      "      policy_loss: -0.00049611582653597\n",
      "      total_loss: 41.6161994934082\n",
      "      vf_explained_var: 0.9668524265289307\n",
      "      vf_loss: 41.6166877746582\n",
      "    sample_time_ms: 19937.803\n",
      "    update_time_ms: 7.167\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.39915933522303\n",
      "    rl_1: 67.25711834237448\n",
      "  time_since_restore: 10209.776619672775\n",
      "  time_this_iter_s: 22.89209794998169\n",
      "  time_total_s: 10209.776619672775\n",
      "  timestamp: 1550890810\n",
      "  timesteps_since_restore: 4390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4390000\n",
      "  training_iteration: 439\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10209 s, 439 iter, 4390000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-00-33\n",
      "  done: false\n",
      "  episode_len_mean: 102.46\n",
      "  episode_reward_max: 223.632955202946\n",
      "  episode_reward_mean: 159.56283763825542\n",
      "  episode_reward_min: -152.18796210383908\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 36915\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.032\n",
      "    load_time_ms: 2.552\n",
      "    num_steps_sampled: 4400000\n",
      "    num_steps_trained: 4400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11237693578004837\n",
      "      kl: 0.018518120050430298\n",
      "      policy_loss: 0.005468409508466721\n",
      "      total_loss: 57.83182907104492\n",
      "      vf_explained_var: 0.9606553912162781\n",
      "      vf_loss: 57.82637405395508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18758635222911835\n",
      "      kl: 0.013130719773471355\n",
      "      policy_loss: 0.0011404466349631548\n",
      "      total_loss: 51.39134979248047\n",
      "      vf_explained_var: 0.955504298210144\n",
      "      vf_loss: 51.39021301269531\n",
      "    sample_time_ms: 19869.792\n",
      "    update_time_ms: 7.219\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.72545933826446\n",
      "    rl_1: 69.83737829999092\n",
      "  time_since_restore: 10232.600795269012\n",
      "  time_this_iter_s: 22.824175596237183\n",
      "  time_total_s: 10232.600795269012\n",
      "  timestamp: 1550890833\n",
      "  timesteps_since_restore: 4400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4400000\n",
      "  training_iteration: 440\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10232 s, 440 iter, 4400000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-00-56\n",
      "  done: false\n",
      "  episode_len_mean: 102.76\n",
      "  episode_reward_max: 233.126606173891\n",
      "  episode_reward_mean: 169.2665500860662\n",
      "  episode_reward_min: -143.1180465886347\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 37013\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.028\n",
      "    load_time_ms: 2.506\n",
      "    num_steps_sampled: 4410000\n",
      "    num_steps_trained: 4410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17724162340164185\n",
      "      kl: 0.025713959708809853\n",
      "      policy_loss: 0.003871625056490302\n",
      "      total_loss: 64.9251937866211\n",
      "      vf_explained_var: 0.9498133659362793\n",
      "      vf_loss: 64.92131805419922\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22592349350452423\n",
      "      kl: 0.03896892070770264\n",
      "      policy_loss: 0.0018502199091017246\n",
      "      total_loss: 58.803653717041016\n",
      "      vf_explained_var: 0.9400622844696045\n",
      "      vf_loss: 58.80181884765625\n",
      "    sample_time_ms: 19870.005\n",
      "    update_time_ms: 6.993\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.92720118471125\n",
      "    rl_1: 74.33934890135492\n",
      "  time_since_restore: 10255.41715168953\n",
      "  time_this_iter_s: 22.816356420516968\n",
      "  time_total_s: 10255.41715168953\n",
      "  timestamp: 1550890856\n",
      "  timesteps_since_restore: 4410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4410000\n",
      "  training_iteration: 441\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10255 s, 441 iter, 4410000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-01-19\n",
      "  done: false\n",
      "  episode_len_mean: 107.26\n",
      "  episode_reward_max: 230.8472546899688\n",
      "  episode_reward_mean: 171.07864548131587\n",
      "  episode_reward_min: -172.05714481835867\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 37106\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.948\n",
      "    load_time_ms: 2.39\n",
      "    num_steps_sampled: 4420000\n",
      "    num_steps_trained: 4420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.16978254914283752\n",
      "      kl: 0.03505421057343483\n",
      "      policy_loss: 0.006099051330238581\n",
      "      total_loss: 25.662221908569336\n",
      "      vf_explained_var: 0.9768460392951965\n",
      "      vf_loss: 25.6561222076416\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.28118911385536194\n",
      "      kl: 0.010555903427302837\n",
      "      policy_loss: -0.00046848872443661094\n",
      "      total_loss: 23.36164093017578\n",
      "      vf_explained_var: 0.9727766513824463\n",
      "      vf_loss: 23.362112045288086\n",
      "    sample_time_ms: 19872.731\n",
      "    update_time_ms: 6.943\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.52060257462739\n",
      "    rl_1: 72.55804290668847\n",
      "  time_since_restore: 10278.329442739487\n",
      "  time_this_iter_s: 22.912291049957275\n",
      "  time_total_s: 10278.329442739487\n",
      "  timestamp: 1550890879\n",
      "  timesteps_since_restore: 4420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4420000\n",
      "  training_iteration: 442\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10278 s, 442 iter, 4420000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-01-42\n",
      "  done: false\n",
      "  episode_len_mean: 105.98\n",
      "  episode_reward_max: 223.69616112475572\n",
      "  episode_reward_mean: 162.5260722786875\n",
      "  episode_reward_min: -169.13228069627155\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 37200\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3094.761\n",
      "    load_time_ms: 2.405\n",
      "    num_steps_sampled: 4430000\n",
      "    num_steps_trained: 4430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11651726067066193\n",
      "      kl: 0.013839807361364365\n",
      "      policy_loss: -0.0002878303930629045\n",
      "      total_loss: 50.38655471801758\n",
      "      vf_explained_var: 0.9658103585243225\n",
      "      vf_loss: 50.38684844970703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18621918559074402\n",
      "      kl: 0.013609187677502632\n",
      "      policy_loss: 0.0006926409550942481\n",
      "      total_loss: 43.56985092163086\n",
      "      vf_explained_var: 0.9636883735656738\n",
      "      vf_loss: 43.569149017333984\n",
      "    sample_time_ms: 19872.994\n",
      "    update_time_ms: 6.7\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.63013284167528\n",
      "    rl_1: 69.89593943701225\n",
      "  time_since_restore: 10301.42903637886\n",
      "  time_this_iter_s: 23.09959363937378\n",
      "  time_total_s: 10301.42903637886\n",
      "  timestamp: 1550890902\n",
      "  timesteps_since_restore: 4430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4430000\n",
      "  training_iteration: 443\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10301 s, 443 iter, 4430000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-02-05\n",
      "  done: false\n",
      "  episode_len_mean: 104.97\n",
      "  episode_reward_max: 226.7034664935643\n",
      "  episode_reward_mean: 167.8394123649323\n",
      "  episode_reward_min: -139.65012632629896\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 37294\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.061\n",
      "    load_time_ms: 2.364\n",
      "    num_steps_sampled: 4440000\n",
      "    num_steps_trained: 4440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12985117733478546\n",
      "      kl: 10.372819900512695\n",
      "      policy_loss: 0.1135856956243515\n",
      "      total_loss: 28.624618530273438\n",
      "      vf_explained_var: 0.9787299036979675\n",
      "      vf_loss: 28.51103401184082\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21943527460098267\n",
      "      kl: 0.024390587583184242\n",
      "      policy_loss: 0.010326897725462914\n",
      "      total_loss: 23.555192947387695\n",
      "      vf_explained_var: 0.9777714610099792\n",
      "      vf_loss: 23.544864654541016\n",
      "    sample_time_ms: 19869.11\n",
      "    update_time_ms: 6.512\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.60789079126586\n",
      "    rl_1: 72.23152157366647\n",
      "  time_since_restore: 10324.908118724823\n",
      "  time_this_iter_s: 23.479082345962524\n",
      "  time_total_s: 10324.908118724823\n",
      "  timestamp: 1550890925\n",
      "  timesteps_since_restore: 4440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4440000\n",
      "  training_iteration: 444\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10324 s, 444 iter, 4440000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-02-28\n",
      "  done: false\n",
      "  episode_len_mean: 105.47\n",
      "  episode_reward_max: 226.74270912095872\n",
      "  episode_reward_mean: 129.68452184233556\n",
      "  episode_reward_min: -177.9157604015956\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 37390\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.616\n",
      "    load_time_ms: 2.303\n",
      "    num_steps_sampled: 4450000\n",
      "    num_steps_trained: 4450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.13653095066547394\n",
      "      kl: 0.011672616004943848\n",
      "      policy_loss: -0.0006729281158186495\n",
      "      total_loss: 145.4711151123047\n",
      "      vf_explained_var: 0.9346661567687988\n",
      "      vf_loss: 145.47177124023438\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.28215116262435913\n",
      "      kl: 0.01385515183210373\n",
      "      policy_loss: -0.0015151301631703973\n",
      "      total_loss: 132.6812744140625\n",
      "      vf_explained_var: 0.9244215488433838\n",
      "      vf_loss: 132.6827850341797\n",
      "    sample_time_ms: 19880.461\n",
      "    update_time_ms: 6.569\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.16192505017506\n",
      "    rl_1: 53.52259679216046\n",
      "  time_since_restore: 10348.015689373016\n",
      "  time_this_iter_s: 23.10757064819336\n",
      "  time_total_s: 10348.015689373016\n",
      "  timestamp: 1550890948\n",
      "  timesteps_since_restore: 4450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4450000\n",
      "  training_iteration: 445\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10348 s, 445 iter, 4450000 ts, 130 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-02-51\n",
      "  done: false\n",
      "  episode_len_mean: 104.77\n",
      "  episode_reward_max: 227.86503107195304\n",
      "  episode_reward_mean: 175.01533618306033\n",
      "  episode_reward_min: -139.25077875470257\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 37484\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.537\n",
      "    load_time_ms: 2.307\n",
      "    num_steps_sampled: 4460000\n",
      "    num_steps_trained: 4460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21397076547145844\n",
      "      kl: 0.017074964940547943\n",
      "      policy_loss: 0.0001711364893708378\n",
      "      total_loss: 30.004623413085938\n",
      "      vf_explained_var: 0.9724506735801697\n",
      "      vf_loss: 30.004459381103516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3070695996284485\n",
      "      kl: 0.036457937210798264\n",
      "      policy_loss: 0.0036970595829188824\n",
      "      total_loss: 26.28778839111328\n",
      "      vf_explained_var: 0.9676199555397034\n",
      "      vf_loss: 26.28409194946289\n",
      "    sample_time_ms: 19915.54\n",
      "    update_time_ms: 6.767\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.1461184822233\n",
      "    rl_1: 76.86921770083697\n",
      "  time_since_restore: 10370.892418384552\n",
      "  time_this_iter_s: 22.876729011535645\n",
      "  time_total_s: 10370.892418384552\n",
      "  timestamp: 1550890971\n",
      "  timesteps_since_restore: 4460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4460000\n",
      "  training_iteration: 446\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10370 s, 446 iter, 4460000 ts, 175 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-03-14\n",
      "  done: false\n",
      "  episode_len_mean: 107.02\n",
      "  episode_reward_max: 230.22216686301783\n",
      "  episode_reward_mean: 169.8530239970301\n",
      "  episode_reward_min: -169.73430628831738\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 37579\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.663\n",
      "    load_time_ms: 2.302\n",
      "    num_steps_sampled: 4470000\n",
      "    num_steps_trained: 4470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11762554198503494\n",
      "      kl: 0.02788427285850048\n",
      "      policy_loss: 0.00432401429861784\n",
      "      total_loss: 38.307125091552734\n",
      "      vf_explained_var: 0.9704447984695435\n",
      "      vf_loss: 38.30280303955078\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24046970903873444\n",
      "      kl: 0.014112353324890137\n",
      "      policy_loss: -0.00127736188005656\n",
      "      total_loss: 32.249881744384766\n",
      "      vf_explained_var: 0.9703813195228577\n",
      "      vf_loss: 32.25115966796875\n",
      "    sample_time_ms: 19892.566\n",
      "    update_time_ms: 6.849\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.4990918977858\n",
      "    rl_1: 74.35393209924432\n",
      "  time_since_restore: 10393.78362083435\n",
      "  time_this_iter_s: 22.891202449798584\n",
      "  time_total_s: 10393.78362083435\n",
      "  timestamp: 1550890994\n",
      "  timesteps_since_restore: 4470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4470000\n",
      "  training_iteration: 447\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10393 s, 447 iter, 4470000 ts, 170 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-03-38\n",
      "  done: false\n",
      "  episode_len_mean: 104.77\n",
      "  episode_reward_max: 230.39275316174326\n",
      "  episode_reward_mean: 148.4865677496075\n",
      "  episode_reward_min: -169.74641842569105\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 37675\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.295\n",
      "    load_time_ms: 2.314\n",
      "    num_steps_sampled: 4480000\n",
      "    num_steps_trained: 4480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1272987425327301\n",
      "      kl: 0.01695164293050766\n",
      "      policy_loss: 0.005962945520877838\n",
      "      total_loss: 59.59618377685547\n",
      "      vf_explained_var: 0.9694573879241943\n",
      "      vf_loss: 59.59021759033203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2361578792333603\n",
      "      kl: 0.01458788849413395\n",
      "      policy_loss: -0.000492592342197895\n",
      "      total_loss: 47.828773498535156\n",
      "      vf_explained_var: 0.9707969427108765\n",
      "      vf_loss: 47.82926940917969\n",
      "    sample_time_ms: 19926.015\n",
      "    update_time_ms: 6.731\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.67451655841322\n",
      "    rl_1: 64.81205119119431\n",
      "  time_since_restore: 10417.238782644272\n",
      "  time_this_iter_s: 23.455161809921265\n",
      "  time_total_s: 10417.238782644272\n",
      "  timestamp: 1550891018\n",
      "  timesteps_since_restore: 4480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4480000\n",
      "  training_iteration: 448\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10417 s, 448 iter, 4480000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-04-01\n",
      "  done: false\n",
      "  episode_len_mean: 105.61\n",
      "  episode_reward_max: 226.36358496276355\n",
      "  episode_reward_mean: 134.63390986998337\n",
      "  episode_reward_min: -170.78739978515847\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 37770\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.048\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 4490000\n",
      "    num_steps_trained: 4490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.033529527485370636\n",
      "      kl: 0.015304145403206348\n",
      "      policy_loss: -4.200866533210501e-05\n",
      "      total_loss: 100.19648742675781\n",
      "      vf_explained_var: 0.9522190690040588\n",
      "      vf_loss: 100.19654083251953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2331111580133438\n",
      "      kl: 0.02522181160748005\n",
      "      policy_loss: 0.003164375200867653\n",
      "      total_loss: 83.68939208984375\n",
      "      vf_explained_var: 0.9550097584724426\n",
      "      vf_loss: 83.68623352050781\n",
      "    sample_time_ms: 19970.185\n",
      "    update_time_ms: 6.703\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.11477139385093\n",
      "    rl_1: 58.51913847613241\n",
      "  time_since_restore: 10440.55453157425\n",
      "  time_this_iter_s: 23.315748929977417\n",
      "  time_total_s: 10440.55453157425\n",
      "  timestamp: 1550891041\n",
      "  timesteps_since_restore: 4490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4490000\n",
      "  training_iteration: 449\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10440 s, 449 iter, 4490000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-04-25\n",
      "  done: false\n",
      "  episode_len_mean: 105.9\n",
      "  episode_reward_max: 230.57354525974034\n",
      "  episode_reward_mean: 174.91246382005767\n",
      "  episode_reward_min: -143.3618176300403\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 37864\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.699\n",
      "    load_time_ms: 2.376\n",
      "    num_steps_sampled: 4500000\n",
      "    num_steps_trained: 4500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2550087571144104\n",
      "      kl: 0.020882098004221916\n",
      "      policy_loss: 0.0009259572252631187\n",
      "      total_loss: 43.61913299560547\n",
      "      vf_explained_var: 0.9683801531791687\n",
      "      vf_loss: 43.61820602416992\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4111296832561493\n",
      "      kl: 0.023009251803159714\n",
      "      policy_loss: 0.0013673047069460154\n",
      "      total_loss: 35.2551383972168\n",
      "      vf_explained_var: 0.9672209024429321\n",
      "      vf_loss: 35.25377655029297\n",
      "    sample_time_ms: 20033.341\n",
      "    update_time_ms: 6.704\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.89893036727771\n",
      "    rl_1: 77.01353345277998\n",
      "  time_since_restore: 10463.976908445358\n",
      "  time_this_iter_s: 23.42237687110901\n",
      "  time_total_s: 10463.976908445358\n",
      "  timestamp: 1550891065\n",
      "  timesteps_since_restore: 4500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4500000\n",
      "  training_iteration: 450\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10463 s, 450 iter, 4500000 ts, 175 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-04-48\n",
      "  done: false\n",
      "  episode_len_mean: 107.11\n",
      "  episode_reward_max: 222.86013843919451\n",
      "  episode_reward_mean: 150.3311801228427\n",
      "  episode_reward_min: -168.794372960384\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 37958\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.286\n",
      "    load_time_ms: 2.384\n",
      "    num_steps_sampled: 4510000\n",
      "    num_steps_trained: 4510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.05248129740357399\n",
      "      kl: 0.01894647628068924\n",
      "      policy_loss: 0.00392176816239953\n",
      "      total_loss: 65.6429214477539\n",
      "      vf_explained_var: 0.9649022221565247\n",
      "      vf_loss: 65.63899993896484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22885407507419586\n",
      "      kl: 0.06051071360707283\n",
      "      policy_loss: 0.014349722303450108\n",
      "      total_loss: 55.54605484008789\n",
      "      vf_explained_var: 0.9650512337684631\n",
      "      vf_loss: 55.531707763671875\n",
      "    sample_time_ms: 20062.51\n",
      "    update_time_ms: 6.922\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.16989185459443\n",
      "    rl_1: 65.16128826824827\n",
      "  time_since_restore: 10487.083477258682\n",
      "  time_this_iter_s: 23.106568813323975\n",
      "  time_total_s: 10487.083477258682\n",
      "  timestamp: 1550891088\n",
      "  timesteps_since_restore: 4510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4510000\n",
      "  training_iteration: 451\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10487 s, 451 iter, 4510000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-05-11\n",
      "  done: false\n",
      "  episode_len_mean: 103.59\n",
      "  episode_reward_max: 235.58436789483008\n",
      "  episode_reward_mean: 152.18326555466496\n",
      "  episode_reward_min: -173.10645134721727\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 38054\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.424\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 4520000\n",
      "    num_steps_trained: 4520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19630610942840576\n",
      "      kl: 0.021781405434012413\n",
      "      policy_loss: -0.00040188958519138396\n",
      "      total_loss: 52.002410888671875\n",
      "      vf_explained_var: 0.9698457717895508\n",
      "      vf_loss: 52.00281524658203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3417840003967285\n",
      "      kl: 0.009477289393544197\n",
      "      policy_loss: -9.338863310404122e-05\n",
      "      total_loss: 40.87763214111328\n",
      "      vf_explained_var: 0.9719615578651428\n",
      "      vf_loss: 40.877723693847656\n",
      "    sample_time_ms: 20063.993\n",
      "    update_time_ms: 7.02\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.35902924005997\n",
      "    rl_1: 66.82423631460496\n",
      "  time_since_restore: 10510.01605963707\n",
      "  time_this_iter_s: 22.93258237838745\n",
      "  time_total_s: 10510.01605963707\n",
      "  timestamp: 1550891111\n",
      "  timesteps_since_restore: 4520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4520000\n",
      "  training_iteration: 452\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10510 s, 452 iter, 4520000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-05-33\n",
      "  done: false\n",
      "  episode_len_mean: 112.61\n",
      "  episode_reward_max: 228.6331556916734\n",
      "  episode_reward_mean: 158.96472172545552\n",
      "  episode_reward_min: -162.58681961060606\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 38142\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.058\n",
      "    load_time_ms: 2.435\n",
      "    num_steps_sampled: 4530000\n",
      "    num_steps_trained: 4530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.00957526359707117\n",
      "      kl: 0.031345125287771225\n",
      "      policy_loss: 0.003423854010179639\n",
      "      total_loss: 74.0955810546875\n",
      "      vf_explained_var: 0.950922429561615\n",
      "      vf_loss: 74.09214782714844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2230713963508606\n",
      "      kl: 0.015281683765351772\n",
      "      policy_loss: 0.0029176499228924513\n",
      "      total_loss: 55.50668716430664\n",
      "      vf_explained_var: 0.9586005806922913\n",
      "      vf_loss: 55.50376892089844\n",
      "    sample_time_ms: 19978.225\n",
      "    update_time_ms: 7.132\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.94260882109111\n",
      "    rl_1: 71.0221129043644\n",
      "  time_since_restore: 10532.216753959656\n",
      "  time_this_iter_s: 22.20069432258606\n",
      "  time_total_s: 10532.216753959656\n",
      "  timestamp: 1550891133\n",
      "  timesteps_since_restore: 4530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4530000\n",
      "  training_iteration: 453\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10532 s, 453 iter, 4530000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-05-56\n",
      "  done: false\n",
      "  episode_len_mean: 121.97\n",
      "  episode_reward_max: 230.04081325172365\n",
      "  episode_reward_mean: 165.10268208087305\n",
      "  episode_reward_min: -158.2303818944684\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 38227\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.094\n",
      "    load_time_ms: 2.408\n",
      "    num_steps_sampled: 4540000\n",
      "    num_steps_trained: 4540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.036951497197151184\n",
      "      kl: 0.024886880069971085\n",
      "      policy_loss: 0.0015428864862769842\n",
      "      total_loss: 70.09661102294922\n",
      "      vf_explained_var: 0.9450639486312866\n",
      "      vf_loss: 70.0950698852539\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18227852880954742\n",
      "      kl: 0.13711273670196533\n",
      "      policy_loss: -0.012493937276303768\n",
      "      total_loss: 59.044776916503906\n",
      "      vf_explained_var: 0.949647843837738\n",
      "      vf_loss: 59.05728530883789\n",
      "    sample_time_ms: 19927.549\n",
      "    update_time_ms: 7.62\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.19422380255764\n",
      "    rl_1: 71.90845827831544\n",
      "  time_since_restore: 10555.191994667053\n",
      "  time_this_iter_s: 22.97524070739746\n",
      "  time_total_s: 10555.191994667053\n",
      "  timestamp: 1550891156\n",
      "  timesteps_since_restore: 4540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4540000\n",
      "  training_iteration: 454\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10555 s, 454 iter, 4540000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-06-20\n",
      "  done: false\n",
      "  episode_len_mean: 106.24\n",
      "  episode_reward_max: 232.95649909189999\n",
      "  episode_reward_mean: 165.45743046771378\n",
      "  episode_reward_min: -144.19517752213318\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 38322\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.396\n",
      "    load_time_ms: 2.421\n",
      "    num_steps_sampled: 4550000\n",
      "    num_steps_trained: 4550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2328217625617981\n",
      "      kl: 0.05961109325289726\n",
      "      policy_loss: 0.014378736726939678\n",
      "      total_loss: 62.158546447753906\n",
      "      vf_explained_var: 0.9544601440429688\n",
      "      vf_loss: 62.14418029785156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42770928144454956\n",
      "      kl: 0.02840852364897728\n",
      "      policy_loss: 0.006803246680647135\n",
      "      total_loss: 53.24538803100586\n",
      "      vf_explained_var: 0.9518040418624878\n",
      "      vf_loss: 53.23858642578125\n",
      "    sample_time_ms: 19987.497\n",
      "    update_time_ms: 7.668\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.85274772627903\n",
      "    rl_1: 73.60468274143477\n",
      "  time_since_restore: 10578.923278331757\n",
      "  time_this_iter_s: 23.73128366470337\n",
      "  time_total_s: 10578.923278331757\n",
      "  timestamp: 1550891180\n",
      "  timesteps_since_restore: 4550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4550000\n",
      "  training_iteration: 455\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10578 s, 455 iter, 4550000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-06-43\n",
      "  done: false\n",
      "  episode_len_mean: 113.28\n",
      "  episode_reward_max: 232.95649909189999\n",
      "  episode_reward_mean: 166.79245315991375\n",
      "  episode_reward_min: -154.63802176388992\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 38409\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.476\n",
      "    load_time_ms: 2.443\n",
      "    num_steps_sampled: 4560000\n",
      "    num_steps_trained: 4560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.06016184762120247\n",
      "      kl: 0.02737434022128582\n",
      "      policy_loss: 0.00435831630602479\n",
      "      total_loss: 46.132850646972656\n",
      "      vf_explained_var: 0.9629459977149963\n",
      "      vf_loss: 46.12849807739258\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.26728636026382446\n",
      "      kl: 0.02059529908001423\n",
      "      policy_loss: 0.0022526562679558992\n",
      "      total_loss: 38.936946868896484\n",
      "      vf_explained_var: 0.9617558121681213\n",
      "      vf_loss: 38.934696197509766\n",
      "    sample_time_ms: 20038.824\n",
      "    update_time_ms: 7.391\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.83274086626547\n",
      "    rl_1: 71.95971229364831\n",
      "  time_since_restore: 10602.330431461334\n",
      "  time_this_iter_s: 23.407153129577637\n",
      "  time_total_s: 10602.330431461334\n",
      "  timestamp: 1550891203\n",
      "  timesteps_since_restore: 4560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4560000\n",
      "  training_iteration: 456\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10602 s, 456 iter, 4560000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-07-06\n",
      "  done: false\n",
      "  episode_len_mean: 111.79\n",
      "  episode_reward_max: 228.84156465254833\n",
      "  episode_reward_mean: 160.16954381252856\n",
      "  episode_reward_min: -155.64786327973724\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 38498\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.51\n",
      "    load_time_ms: 2.467\n",
      "    num_steps_sampled: 4570000\n",
      "    num_steps_trained: 4570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11254666745662689\n",
      "      kl: 0.01473675761371851\n",
      "      policy_loss: -0.0019221139373257756\n",
      "      total_loss: 55.78516387939453\n",
      "      vf_explained_var: 0.9614576697349548\n",
      "      vf_loss: 55.787078857421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.32767415046691895\n",
      "      kl: 0.01929399184882641\n",
      "      policy_loss: -0.0014777728356420994\n",
      "      total_loss: 51.581787109375\n",
      "      vf_explained_var: 0.957838773727417\n",
      "      vf_loss: 51.5832633972168\n",
      "    sample_time_ms: 20025.434\n",
      "    update_time_ms: 7.105\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.98214174621253\n",
      "    rl_1: 69.18740206631604\n",
      "  time_since_restore: 10625.060378074646\n",
      "  time_this_iter_s: 22.729946613311768\n",
      "  time_total_s: 10625.060378074646\n",
      "  timestamp: 1550891226\n",
      "  timesteps_since_restore: 4570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4570000\n",
      "  training_iteration: 457\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10625 s, 457 iter, 4570000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-07-29\n",
      "  done: false\n",
      "  episode_len_mean: 102.25\n",
      "  episode_reward_max: 227.28910297441107\n",
      "  episode_reward_mean: 153.97129770533732\n",
      "  episode_reward_min: -161.61262684401865\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 38596\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.3\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 4580000\n",
      "    num_steps_trained: 4580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.25156593322753906\n",
      "      kl: 0.029608311131596565\n",
      "      policy_loss: 0.005376288201659918\n",
      "      total_loss: 62.42840576171875\n",
      "      vf_explained_var: 0.9616101384162903\n",
      "      vf_loss: 62.42302703857422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4167691171169281\n",
      "      kl: 0.018174635246396065\n",
      "      policy_loss: 0.001747274654917419\n",
      "      total_loss: 48.563289642333984\n",
      "      vf_explained_var: 0.9665144085884094\n",
      "      vf_loss: 48.56154251098633\n",
      "    sample_time_ms: 20011.755\n",
      "    update_time_ms: 7.206\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.6694656607108\n",
      "    rl_1: 68.3018320446265\n",
      "  time_since_restore: 10648.276136636734\n",
      "  time_this_iter_s: 23.215758562088013\n",
      "  time_total_s: 10648.276136636734\n",
      "  timestamp: 1550891249\n",
      "  timesteps_since_restore: 4580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4580000\n",
      "  training_iteration: 458\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10648 s, 458 iter, 4580000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-07-52\n",
      "  done: false\n",
      "  episode_len_mean: 107.11\n",
      "  episode_reward_max: 225.1090861807609\n",
      "  episode_reward_mean: 163.3276759037734\n",
      "  episode_reward_min: -166.37814975220905\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 38690\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.126\n",
      "    load_time_ms: 2.374\n",
      "    num_steps_sampled: 4590000\n",
      "    num_steps_trained: 4590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18071463704109192\n",
      "      kl: 0.01380578801035881\n",
      "      policy_loss: 0.0013045486994087696\n",
      "      total_loss: 44.67417907714844\n",
      "      vf_explained_var: 0.9652769565582275\n",
      "      vf_loss: 44.672874450683594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3709581196308136\n",
      "      kl: 0.01816122978925705\n",
      "      policy_loss: -0.0027136264834553003\n",
      "      total_loss: 43.0889778137207\n",
      "      vf_explained_var: 0.9568557739257812\n",
      "      vf_loss: 43.09169387817383\n",
      "    sample_time_ms: 19950.698\n",
      "    update_time_ms: 7.312\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.35989615856359\n",
      "    rl_1: 69.96777974520982\n",
      "  time_since_restore: 10670.95555639267\n",
      "  time_this_iter_s: 22.67941975593567\n",
      "  time_total_s: 10670.95555639267\n",
      "  timestamp: 1550891272\n",
      "  timesteps_since_restore: 4590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4590000\n",
      "  training_iteration: 459\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10670 s, 459 iter, 4590000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-08-16\n",
      "  done: false\n",
      "  episode_len_mean: 108.68\n",
      "  episode_reward_max: 227.45962802226072\n",
      "  episode_reward_mean: 155.24972262184468\n",
      "  episode_reward_min: -168.5481160667927\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 38781\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.908\n",
      "    load_time_ms: 2.395\n",
      "    num_steps_sampled: 4600000\n",
      "    num_steps_trained: 4600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2143830806016922\n",
      "      kl: 0.022589804604649544\n",
      "      policy_loss: 0.0048968917690217495\n",
      "      total_loss: 39.12180709838867\n",
      "      vf_explained_var: 0.9716424345970154\n",
      "      vf_loss: 39.116905212402344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.41720184683799744\n",
      "      kl: 0.01852046325802803\n",
      "      policy_loss: 0.006565901916474104\n",
      "      total_loss: 30.467300415039062\n",
      "      vf_explained_var: 0.972282886505127\n",
      "      vf_loss: 30.460737228393555\n",
      "    sample_time_ms: 19959.699\n",
      "    update_time_ms: 7.744\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.94932040643101\n",
      "    rl_1: 65.30040221541367\n",
      "  time_since_restore: 10694.507830619812\n",
      "  time_this_iter_s: 23.552274227142334\n",
      "  time_total_s: 10694.507830619812\n",
      "  timestamp: 1550891296\n",
      "  timesteps_since_restore: 4600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4600000\n",
      "  training_iteration: 460\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10694 s, 460 iter, 4600000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-08-39\n",
      "  done: false\n",
      "  episode_len_mean: 104.75\n",
      "  episode_reward_max: 231.29744207434445\n",
      "  episode_reward_mean: 171.60158823087772\n",
      "  episode_reward_min: -170.85834223962968\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 38876\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.179\n",
      "    load_time_ms: 2.429\n",
      "    num_steps_sampled: 4610000\n",
      "    num_steps_trained: 4610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2315012663602829\n",
      "      kl: 0.009964642114937305\n",
      "      policy_loss: 0.00023621716536581516\n",
      "      total_loss: 40.62316131591797\n",
      "      vf_explained_var: 0.9695395231246948\n",
      "      vf_loss: 40.622920989990234\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3909910023212433\n",
      "      kl: 0.018244914710521698\n",
      "      policy_loss: -0.000450375082436949\n",
      "      total_loss: 38.33922576904297\n",
      "      vf_explained_var: 0.9641839265823364\n",
      "      vf_loss: 38.33967590332031\n",
      "    sample_time_ms: 19979.445\n",
      "    update_time_ms: 7.663\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.60487416650558\n",
      "    rl_1: 75.9967140643721\n",
      "  time_since_restore: 10718.045177459717\n",
      "  time_this_iter_s: 23.537346839904785\n",
      "  time_total_s: 10718.045177459717\n",
      "  timestamp: 1550891319\n",
      "  timesteps_since_restore: 4610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4610000\n",
      "  training_iteration: 461\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10718 s, 461 iter, 4610000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-09-02\n",
      "  done: false\n",
      "  episode_len_mean: 108.11\n",
      "  episode_reward_max: 230.24129981234918\n",
      "  episode_reward_mean: 163.33691142326177\n",
      "  episode_reward_min: -171.21990100043317\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 38969\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.237\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 4620000\n",
      "    num_steps_trained: 4620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18074512481689453\n",
      "      kl: 0.02036566287279129\n",
      "      policy_loss: 0.0016612408217042685\n",
      "      total_loss: 58.04094696044922\n",
      "      vf_explained_var: 0.9595993161201477\n",
      "      vf_loss: 58.03927993774414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.384122759103775\n",
      "      kl: 0.020744260400533676\n",
      "      policy_loss: -0.0018865668680518866\n",
      "      total_loss: 46.558204650878906\n",
      "      vf_explained_var: 0.9629771113395691\n",
      "      vf_loss: 46.560096740722656\n",
      "    sample_time_ms: 19982.498\n",
      "    update_time_ms: 7.924\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.32357677086421\n",
      "    rl_1: 72.0133346523976\n",
      "  time_since_restore: 10741.000367641449\n",
      "  time_this_iter_s: 22.955190181732178\n",
      "  time_total_s: 10741.000367641449\n",
      "  timestamp: 1550891342\n",
      "  timesteps_since_restore: 4620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4620000\n",
      "  training_iteration: 462\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10741 s, 462 iter, 4620000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-09-25\n",
      "  done: false\n",
      "  episode_len_mean: 106.08\n",
      "  episode_reward_max: 223.01685917637025\n",
      "  episode_reward_mean: 162.96136810734012\n",
      "  episode_reward_min: -161.05469103500565\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 39062\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.516\n",
      "    load_time_ms: 2.415\n",
      "    num_steps_sampled: 4630000\n",
      "    num_steps_trained: 4630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.14901821315288544\n",
      "      kl: 0.03097722865641117\n",
      "      policy_loss: 0.0026985397562384605\n",
      "      total_loss: 41.65337371826172\n",
      "      vf_explained_var: 0.967410147190094\n",
      "      vf_loss: 41.65067672729492\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.34218713641166687\n",
      "      kl: 0.022877736017107964\n",
      "      policy_loss: 0.0014676213031634688\n",
      "      total_loss: 33.57575225830078\n",
      "      vf_explained_var: 0.9701391458511353\n",
      "      vf_loss: 33.57428741455078\n",
      "    sample_time_ms: 20073.038\n",
      "    update_time_ms: 7.856\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.68520764329556\n",
      "    rl_1: 73.27616046404455\n",
      "  time_since_restore: 10764.128051996231\n",
      "  time_this_iter_s: 23.127684354782104\n",
      "  time_total_s: 10764.128051996231\n",
      "  timestamp: 1550891365\n",
      "  timesteps_since_restore: 4630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4630000\n",
      "  training_iteration: 463\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10764 s, 463 iter, 4630000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-09-49\n",
      "  done: false\n",
      "  episode_len_mean: 104.55\n",
      "  episode_reward_max: 223.98426667181258\n",
      "  episode_reward_mean: 170.06448322158295\n",
      "  episode_reward_min: -160.12206697119268\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 39158\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.714\n",
      "    load_time_ms: 2.449\n",
      "    num_steps_sampled: 4640000\n",
      "    num_steps_trained: 4640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.23747113347053528\n",
      "      kl: 0.023397723212838173\n",
      "      policy_loss: 0.003396496642380953\n",
      "      total_loss: 42.71697998046875\n",
      "      vf_explained_var: 0.9660278558731079\n",
      "      vf_loss: 42.713584899902344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.37013959884643555\n",
      "      kl: 0.0201998483389616\n",
      "      policy_loss: 0.001125248265452683\n",
      "      total_loss: 36.668758392333984\n",
      "      vf_explained_var: 0.962009608745575\n",
      "      vf_loss: 36.667633056640625\n",
      "    sample_time_ms: 20111.714\n",
      "    update_time_ms: 7.427\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.76988940904583\n",
      "    rl_1: 74.29459381253712\n",
      "  time_since_restore: 10787.48059797287\n",
      "  time_this_iter_s: 23.352545976638794\n",
      "  time_total_s: 10787.48059797287\n",
      "  timestamp: 1550891389\n",
      "  timesteps_since_restore: 4640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4640000\n",
      "  training_iteration: 464\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10787 s, 464 iter, 4640000 ts, 170 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-10-12\n",
      "  done: false\n",
      "  episode_len_mean: 106.06\n",
      "  episode_reward_max: 227.47844628494934\n",
      "  episode_reward_mean: 156.67109204269067\n",
      "  episode_reward_min: -145.77183867347733\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 39251\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.745\n",
      "    load_time_ms: 2.402\n",
      "    num_steps_sampled: 4650000\n",
      "    num_steps_trained: 4650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19045723974704742\n",
      "      kl: 0.0331038162112236\n",
      "      policy_loss: 0.005382821895182133\n",
      "      total_loss: 56.49723815917969\n",
      "      vf_explained_var: 0.9617001414299011\n",
      "      vf_loss: 56.49185562133789\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3783107399940491\n",
      "      kl: 0.02916424348950386\n",
      "      policy_loss: 0.0038509946316480637\n",
      "      total_loss: 49.91069030761719\n",
      "      vf_explained_var: 0.9603349566459656\n",
      "      vf_loss: 49.90684127807617\n",
      "    sample_time_ms: 20036.154\n",
      "    update_time_ms: 7.381\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.76976405819065\n",
      "    rl_1: 68.90132798450004\n",
      "  time_since_restore: 10810.453580141068\n",
      "  time_this_iter_s: 22.972982168197632\n",
      "  time_total_s: 10810.453580141068\n",
      "  timestamp: 1550891412\n",
      "  timesteps_since_restore: 4650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4650000\n",
      "  training_iteration: 465\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10810 s, 465 iter, 4650000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-10-35\n",
      "  done: false\n",
      "  episode_len_mean: 110.15\n",
      "  episode_reward_max: 231.42848896684282\n",
      "  episode_reward_mean: 156.78919848724217\n",
      "  episode_reward_min: -141.83685667523636\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 39342\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.926\n",
      "    load_time_ms: 2.402\n",
      "    num_steps_sampled: 4660000\n",
      "    num_steps_trained: 4660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.11541801691055298\n",
      "      kl: 0.01707940176129341\n",
      "      policy_loss: 0.004395066760480404\n",
      "      total_loss: 46.9304084777832\n",
      "      vf_explained_var: 0.9705036878585815\n",
      "      vf_loss: 46.92601776123047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3039867579936981\n",
      "      kl: 0.024913286790251732\n",
      "      policy_loss: 0.003340058494359255\n",
      "      total_loss: 34.59718322753906\n",
      "      vf_explained_var: 0.975681483745575\n",
      "      vf_loss: 34.59384536743164\n",
      "    sample_time_ms: 19992.779\n",
      "    update_time_ms: 7.706\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.48202389175454\n",
      "    rl_1: 68.30717459548761\n",
      "  time_since_restore: 10833.40370965004\n",
      "  time_this_iter_s: 22.950129508972168\n",
      "  time_total_s: 10833.40370965004\n",
      "  timestamp: 1550891435\n",
      "  timesteps_since_restore: 4660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4660000\n",
      "  training_iteration: 466\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10833 s, 466 iter, 4660000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-10-58\n",
      "  done: false\n",
      "  episode_len_mean: 108.11\n",
      "  episode_reward_max: 227.12268097132778\n",
      "  episode_reward_mean: 168.66389034333045\n",
      "  episode_reward_min: -155.66929670154212\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 39434\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.596\n",
      "    load_time_ms: 2.443\n",
      "    num_steps_sampled: 4670000\n",
      "    num_steps_trained: 4670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19028714299201965\n",
      "      kl: 0.04271124303340912\n",
      "      policy_loss: 0.00859855581074953\n",
      "      total_loss: 51.089046478271484\n",
      "      vf_explained_var: 0.9551106095314026\n",
      "      vf_loss: 51.08045196533203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3592458963394165\n",
      "      kl: 0.014256492257118225\n",
      "      policy_loss: 0.001193084754049778\n",
      "      total_loss: 42.069183349609375\n",
      "      vf_explained_var: 0.9538256525993347\n",
      "      vf_loss: 42.06798553466797\n",
      "    sample_time_ms: 20003.506\n",
      "    update_time_ms: 7.829\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.32366515101094\n",
      "    rl_1: 72.34022519231948\n",
      "  time_since_restore: 10856.240302085876\n",
      "  time_this_iter_s: 22.836592435836792\n",
      "  time_total_s: 10856.240302085876\n",
      "  timestamp: 1550891458\n",
      "  timesteps_since_restore: 4670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4670000\n",
      "  training_iteration: 467\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10856 s, 467 iter, 4670000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-11-21\n",
      "  done: false\n",
      "  episode_len_mean: 105.18\n",
      "  episode_reward_max: 232.36112200476998\n",
      "  episode_reward_mean: 160.63847499220321\n",
      "  episode_reward_min: -157.25663410302798\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 39529\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.798\n",
      "    load_time_ms: 2.433\n",
      "    num_steps_sampled: 4680000\n",
      "    num_steps_trained: 4680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24950841069221497\n",
      "      kl: 0.024502109736204147\n",
      "      policy_loss: 0.00518344109877944\n",
      "      total_loss: 39.86832046508789\n",
      "      vf_explained_var: 0.9715954661369324\n",
      "      vf_loss: 39.86313247680664\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43996939063072205\n",
      "      kl: 0.012591998092830181\n",
      "      policy_loss: -0.0004076083714608103\n",
      "      total_loss: 37.48033142089844\n",
      "      vf_explained_var: 0.966871976852417\n",
      "      vf_loss: 37.48073959350586\n",
      "    sample_time_ms: 19997.881\n",
      "    update_time_ms: 7.713\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.64279811925961\n",
      "    rl_1: 68.99567687294363\n",
      "  time_since_restore: 10879.340721845627\n",
      "  time_this_iter_s: 23.100419759750366\n",
      "  time_total_s: 10879.340721845627\n",
      "  timestamp: 1550891481\n",
      "  timesteps_since_restore: 4680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4680000\n",
      "  training_iteration: 468\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10879 s, 468 iter, 4680000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-11-44\n",
      "  done: false\n",
      "  episode_len_mean: 112.59\n",
      "  episode_reward_max: 229.97209195761783\n",
      "  episode_reward_mean: 155.24172703252597\n",
      "  episode_reward_min: -179.88567118307202\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 39616\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.431\n",
      "    load_time_ms: 2.468\n",
      "    num_steps_sampled: 4690000\n",
      "    num_steps_trained: 4690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.01956590823829174\n",
      "      kl: 0.011692190542817116\n",
      "      policy_loss: 0.0013361620949581265\n",
      "      total_loss: 48.66645050048828\n",
      "      vf_explained_var: 0.9625770449638367\n",
      "      vf_loss: 48.66511154174805\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2925931513309479\n",
      "      kl: 0.01440028939396143\n",
      "      policy_loss: 0.0012270284350961447\n",
      "      total_loss: 38.966773986816406\n",
      "      vf_explained_var: 0.967758297920227\n",
      "      vf_loss: 38.96554946899414\n",
      "    sample_time_ms: 20035.339\n",
      "    update_time_ms: 7.851\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.41325479542225\n",
      "    rl_1: 66.82847223710374\n",
      "  time_since_restore: 10902.383837223053\n",
      "  time_this_iter_s: 23.043115377426147\n",
      "  time_total_s: 10902.383837223053\n",
      "  timestamp: 1550891504\n",
      "  timesteps_since_restore: 4690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4690000\n",
      "  training_iteration: 469\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10902 s, 469 iter, 4690000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-12-07\n",
      "  done: false\n",
      "  episode_len_mean: 109.71\n",
      "  episode_reward_max: 233.86485462815355\n",
      "  episode_reward_mean: 157.4531558087169\n",
      "  episode_reward_min: -148.09858743245886\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 39710\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.32\n",
      "    load_time_ms: 2.393\n",
      "    num_steps_sampled: 4700000\n",
      "    num_steps_trained: 4700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1760568916797638\n",
      "      kl: 0.04090459644794464\n",
      "      policy_loss: 0.017738567665219307\n",
      "      total_loss: 39.64729690551758\n",
      "      vf_explained_var: 0.9763070344924927\n",
      "      vf_loss: 39.62955856323242\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38030943274497986\n",
      "      kl: 0.03919503837823868\n",
      "      policy_loss: 0.010425477288663387\n",
      "      total_loss: 34.74836730957031\n",
      "      vf_explained_var: 0.9748144149780273\n",
      "      vf_loss: 34.73794937133789\n",
      "    sample_time_ms: 20001.407\n",
      "    update_time_ms: 7.531\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.39903385321055\n",
      "    rl_1: 67.05412195550635\n",
      "  time_since_restore: 10925.713401794434\n",
      "  time_this_iter_s: 23.329564571380615\n",
      "  time_total_s: 10925.713401794434\n",
      "  timestamp: 1550891527\n",
      "  timesteps_since_restore: 4700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4700000\n",
      "  training_iteration: 470\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10925 s, 470 iter, 4700000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-12-30\n",
      "  done: false\n",
      "  episode_len_mean: 114.86\n",
      "  episode_reward_max: 218.84347197054714\n",
      "  episode_reward_mean: 156.8920448016936\n",
      "  episode_reward_min: -165.3848797950196\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 39796\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.955\n",
      "    load_time_ms: 2.328\n",
      "    num_steps_sampled: 4710000\n",
      "    num_steps_trained: 4710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.061911363154649734\n",
      "      kl: 0.012218396179378033\n",
      "      policy_loss: -0.0011461713584139943\n",
      "      total_loss: 40.46518325805664\n",
      "      vf_explained_var: 0.9701789617538452\n",
      "      vf_loss: 40.4663200378418\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21796107292175293\n",
      "      kl: 0.022835001349449158\n",
      "      policy_loss: 0.0015835004160180688\n",
      "      total_loss: 35.972190856933594\n",
      "      vf_explained_var: 0.9690166115760803\n",
      "      vf_loss: 35.970603942871094\n",
      "    sample_time_ms: 19966.087\n",
      "    update_time_ms: 7.467\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.49042124983325\n",
      "    rl_1: 67.4016235518604\n",
      "  time_since_restore: 10948.68021774292\n",
      "  time_this_iter_s: 22.966815948486328\n",
      "  time_total_s: 10948.68021774292\n",
      "  timestamp: 1550891550\n",
      "  timesteps_since_restore: 4710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4710000\n",
      "  training_iteration: 471\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10948 s, 471 iter, 4710000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-12-53\n",
      "  done: false\n",
      "  episode_len_mean: 106.04\n",
      "  episode_reward_max: 225.65410096242059\n",
      "  episode_reward_mean: 172.5333042526785\n",
      "  episode_reward_min: -156.80362593210637\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 39890\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.118\n",
      "    load_time_ms: 2.271\n",
      "    num_steps_sampled: 4720000\n",
      "    num_steps_trained: 4720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1253175437450409\n",
      "      kl: 0.012895929627120495\n",
      "      policy_loss: -0.000695444003213197\n",
      "      total_loss: 34.137203216552734\n",
      "      vf_explained_var: 0.9714874625205994\n",
      "      vf_loss: 34.13789749145508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.34353363513946533\n",
      "      kl: 0.012909837067127228\n",
      "      policy_loss: 0.0010959773790091276\n",
      "      total_loss: 28.636728286743164\n",
      "      vf_explained_var: 0.97267746925354\n",
      "      vf_loss: 28.635629653930664\n",
      "    sample_time_ms: 19985.925\n",
      "    update_time_ms: 7.22\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.19407393729549\n",
      "    rl_1: 78.339230315383\n",
      "  time_since_restore: 10971.82868051529\n",
      "  time_this_iter_s: 23.148462772369385\n",
      "  time_total_s: 10971.82868051529\n",
      "  timestamp: 1550891573\n",
      "  timesteps_since_restore: 4720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4720000\n",
      "  training_iteration: 472\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10971 s, 472 iter, 4720000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-13-16\n",
      "  done: false\n",
      "  episode_len_mean: 104.67\n",
      "  episode_reward_max: 228.00159459060978\n",
      "  episode_reward_mean: 162.3694245369016\n",
      "  episode_reward_min: -170.86584941555554\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 39985\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.29\n",
      "    load_time_ms: 2.286\n",
      "    num_steps_sampled: 4730000\n",
      "    num_steps_trained: 4730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19241823256015778\n",
      "      kl: 0.01868099719285965\n",
      "      policy_loss: -0.0025924118235707283\n",
      "      total_loss: 47.10209274291992\n",
      "      vf_explained_var: 0.964777946472168\n",
      "      vf_loss: 47.10469055175781\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39106783270835876\n",
      "      kl: 0.025765875354409218\n",
      "      policy_loss: -0.00010638469393597916\n",
      "      total_loss: 40.3252067565918\n",
      "      vf_explained_var: 0.9641126990318298\n",
      "      vf_loss: 40.32530975341797\n",
      "    sample_time_ms: 19957.648\n",
      "    update_time_ms: 7.221\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.97532359347476\n",
      "    rl_1: 71.39410094342682\n",
      "  time_since_restore: 10994.708330869675\n",
      "  time_this_iter_s: 22.879650354385376\n",
      "  time_total_s: 10994.708330869675\n",
      "  timestamp: 1550891596\n",
      "  timesteps_since_restore: 4730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4730000\n",
      "  training_iteration: 473\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 10994 s, 473 iter, 4730000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-13-40\n",
      "  done: false\n",
      "  episode_len_mean: 108.55\n",
      "  episode_reward_max: 229.89241470955128\n",
      "  episode_reward_mean: 160.33580102775974\n",
      "  episode_reward_min: -170.86584941555554\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 40076\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.746\n",
      "    load_time_ms: 2.226\n",
      "    num_steps_sampled: 4740000\n",
      "    num_steps_trained: 4740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1700807511806488\n",
      "      kl: 0.017241328954696655\n",
      "      policy_loss: 0.0007639030809514225\n",
      "      total_loss: 46.3434944152832\n",
      "      vf_explained_var: 0.9682954549789429\n",
      "      vf_loss: 46.34273147583008\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3387441635131836\n",
      "      kl: 0.028028186410665512\n",
      "      policy_loss: -0.002152272965759039\n",
      "      total_loss: 38.68400192260742\n",
      "      vf_explained_var: 0.9710856676101685\n",
      "      vf_loss: 38.686161041259766\n",
      "    sample_time_ms: 19926.591\n",
      "    update_time_ms: 7.202\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.83170826980064\n",
      "    rl_1: 71.50409275795909\n",
      "  time_since_restore: 11017.931764602661\n",
      "  time_this_iter_s: 23.22343373298645\n",
      "  time_total_s: 11017.931764602661\n",
      "  timestamp: 1550891620\n",
      "  timesteps_since_restore: 4740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4740000\n",
      "  training_iteration: 474\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11017 s, 474 iter, 4740000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 114.12\n",
      "  episode_reward_max: 230.2738769275731\n",
      "  episode_reward_mean: 152.4378266298252\n",
      "  episode_reward_min: -170.65935641101711\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 40164\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.388\n",
      "    load_time_ms: 2.216\n",
      "    num_steps_sampled: 4750000\n",
      "    num_steps_trained: 4750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.029792724177241325\n",
      "      kl: 0.012114601209759712\n",
      "      policy_loss: 0.0023821284994482994\n",
      "      total_loss: 58.04070281982422\n",
      "      vf_explained_var: 0.9648930430412292\n",
      "      vf_loss: 58.0383186340332\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2411685585975647\n",
      "      kl: 0.016921235248446465\n",
      "      policy_loss: -0.0013695547822862864\n",
      "      total_loss: 49.78771209716797\n",
      "      vf_explained_var: 0.968635082244873\n",
      "      vf_loss: 49.789085388183594\n",
      "    sample_time_ms: 19920.63\n",
      "    update_time_ms: 7.252\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.24634390663584\n",
      "    rl_1: 67.19148272318932\n",
      "  time_since_restore: 11040.833914518356\n",
      "  time_this_iter_s: 22.90214991569519\n",
      "  time_total_s: 11040.833914518356\n",
      "  timestamp: 1550891643\n",
      "  timesteps_since_restore: 4750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4750000\n",
      "  training_iteration: 475\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11040 s, 475 iter, 4750000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-14-26\n",
      "  done: false\n",
      "  episode_len_mean: 108.46\n",
      "  episode_reward_max: 229.63187791932958\n",
      "  episode_reward_mean: 165.0580046697694\n",
      "  episode_reward_min: -179.02924594817364\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 40257\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.255\n",
      "    load_time_ms: 2.212\n",
      "    num_steps_sampled: 4760000\n",
      "    num_steps_trained: 4760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.20677143335342407\n",
      "      kl: 0.017804142087697983\n",
      "      policy_loss: -0.001305596437305212\n",
      "      total_loss: 64.51907348632812\n",
      "      vf_explained_var: 0.9526572823524475\n",
      "      vf_loss: 64.52037811279297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35642102360725403\n",
      "      kl: 0.05158955603837967\n",
      "      policy_loss: -0.0028061731718480587\n",
      "      total_loss: 47.39921569824219\n",
      "      vf_explained_var: 0.957818329334259\n",
      "      vf_loss: 47.40202713012695\n",
      "    sample_time_ms: 19930.615\n",
      "    update_time_ms: 6.98\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.40622021075127\n",
      "    rl_1: 72.65178445901806\n",
      "  time_since_restore: 11063.859676361084\n",
      "  time_this_iter_s: 23.02576184272766\n",
      "  time_total_s: 11063.859676361084\n",
      "  timestamp: 1550891666\n",
      "  timesteps_since_restore: 4760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4760000\n",
      "  training_iteration: 476\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11063 s, 476 iter, 4760000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-14-49\n",
      "  done: false\n",
      "  episode_len_mean: 108.74\n",
      "  episode_reward_max: 229.69598242239033\n",
      "  episode_reward_mean: 158.65122426903326\n",
      "  episode_reward_min: -179.02924594817364\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 40348\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.329\n",
      "    load_time_ms: 2.162\n",
      "    num_steps_sampled: 4770000\n",
      "    num_steps_trained: 4770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24946773052215576\n",
      "      kl: 0.023817282170057297\n",
      "      policy_loss: 0.003299843519926071\n",
      "      total_loss: 46.39888381958008\n",
      "      vf_explained_var: 0.9693111777305603\n",
      "      vf_loss: 46.395572662353516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3657054901123047\n",
      "      kl: 0.020708005875349045\n",
      "      policy_loss: 0.0015276928897947073\n",
      "      total_loss: 40.18965530395508\n",
      "      vf_explained_var: 0.9678875803947449\n",
      "      vf_loss: 40.1881217956543\n",
      "    sample_time_ms: 19927.368\n",
      "    update_time_ms: 7.159\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.20936739190002\n",
      "    rl_1: 67.44185687713325\n",
      "  time_since_restore: 11086.69259095192\n",
      "  time_this_iter_s: 22.83291459083557\n",
      "  time_total_s: 11086.69259095192\n",
      "  timestamp: 1550891689\n",
      "  timesteps_since_restore: 4770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4770000\n",
      "  training_iteration: 477\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11086 s, 477 iter, 4770000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-15-12\n",
      "  done: false\n",
      "  episode_len_mean: 105.25\n",
      "  episode_reward_max: 228.90047245412632\n",
      "  episode_reward_mean: 168.8574185231616\n",
      "  episode_reward_min: -148.85433947782727\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 40443\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3094.635\n",
      "    load_time_ms: 2.182\n",
      "    num_steps_sampled: 4780000\n",
      "    num_steps_trained: 4780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.29024839401245117\n",
      "      kl: 0.037849608808755875\n",
      "      policy_loss: 0.007291723508387804\n",
      "      total_loss: 30.07016944885254\n",
      "      vf_explained_var: 0.9759915471076965\n",
      "      vf_loss: 30.06287956237793\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.37169504165649414\n",
      "      kl: 0.01894441433250904\n",
      "      policy_loss: 0.0013453965075314045\n",
      "      total_loss: 26.863765716552734\n",
      "      vf_explained_var: 0.9737542867660522\n",
      "      vf_loss: 26.862417221069336\n",
      "    sample_time_ms: 19931.212\n",
      "    update_time_ms: 7.453\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.1884364662147\n",
      "    rl_1: 74.66898205694693\n",
      "  time_since_restore: 11109.869329690933\n",
      "  time_this_iter_s: 23.176738739013672\n",
      "  time_total_s: 11109.869329690933\n",
      "  timestamp: 1550891712\n",
      "  timesteps_since_restore: 4780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4780000\n",
      "  training_iteration: 478\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11109 s, 478 iter, 4780000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-15-35\n",
      "  done: false\n",
      "  episode_len_mean: 109.85\n",
      "  episode_reward_max: 225.7986203977287\n",
      "  episode_reward_mean: 166.8987383406535\n",
      "  episode_reward_min: -169.77801187383648\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 40532\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3096.427\n",
      "    load_time_ms: 2.163\n",
      "    num_steps_sampled: 4790000\n",
      "    num_steps_trained: 4790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10948946326971054\n",
      "      kl: 0.013770156539976597\n",
      "      policy_loss: 0.0022071851417422295\n",
      "      total_loss: 46.24866485595703\n",
      "      vf_explained_var: 0.9640112519264221\n",
      "      vf_loss: 46.2464599609375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.25843775272369385\n",
      "      kl: 0.021175716072320938\n",
      "      policy_loss: 0.002697750460356474\n",
      "      total_loss: 37.9568977355957\n",
      "      vf_explained_var: 0.9676463007926941\n",
      "      vf_loss: 37.95419692993164\n",
      "    sample_time_ms: 19923.858\n",
      "    update_time_ms: 7.395\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.57682065124123\n",
      "    rl_1: 73.32191768941229\n",
      "  time_since_restore: 11132.857101917267\n",
      "  time_this_iter_s: 22.987772226333618\n",
      "  time_total_s: 11132.857101917267\n",
      "  timestamp: 1550891735\n",
      "  timesteps_since_restore: 4790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4790000\n",
      "  training_iteration: 479\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11132 s, 479 iter, 4790000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-15-58\n",
      "  done: false\n",
      "  episode_len_mean: 104.86\n",
      "  episode_reward_max: 225.13340481814993\n",
      "  episode_reward_mean: 142.48796698702256\n",
      "  episode_reward_min: -171.31908178052606\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 40629\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.233\n",
      "    load_time_ms: 2.166\n",
      "    num_steps_sampled: 4800000\n",
      "    num_steps_trained: 4800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2961336672306061\n",
      "      kl: 0.015535027720034122\n",
      "      policy_loss: 0.003088978584855795\n",
      "      total_loss: 75.95279693603516\n",
      "      vf_explained_var: 0.9637309312820435\n",
      "      vf_loss: 75.94969940185547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3559580445289612\n",
      "      kl: 0.012105105444788933\n",
      "      policy_loss: -5.031367618357763e-05\n",
      "      total_loss: 58.39737319946289\n",
      "      vf_explained_var: 0.9673925638198853\n",
      "      vf_loss: 58.397422790527344\n",
      "    sample_time_ms: 19881.731\n",
      "    update_time_ms: 7.233\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.56510932461049\n",
      "    rl_1: 61.92285766241204\n",
      "  time_since_restore: 11155.591527700424\n",
      "  time_this_iter_s: 22.73442578315735\n",
      "  time_total_s: 11155.591527700424\n",
      "  timestamp: 1550891758\n",
      "  timesteps_since_restore: 4800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4800000\n",
      "  training_iteration: 480\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11155 s, 480 iter, 4800000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-16-21\n",
      "  done: false\n",
      "  episode_len_mean: 115.6\n",
      "  episode_reward_max: 225.82181064559455\n",
      "  episode_reward_mean: 167.16781151127455\n",
      "  episode_reward_min: -166.84349620267724\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 40714\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.176\n",
      "    load_time_ms: 2.176\n",
      "    num_steps_sampled: 4810000\n",
      "    num_steps_trained: 4810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.0026259657461196184\n",
      "      kl: 0.018364183604717255\n",
      "      policy_loss: 0.002927824854850769\n",
      "      total_loss: 41.68256378173828\n",
      "      vf_explained_var: 0.9668919444084167\n",
      "      vf_loss: 41.67964172363281\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1775054633617401\n",
      "      kl: 0.012570732273161411\n",
      "      policy_loss: 0.0010691470233723521\n",
      "      total_loss: 34.860923767089844\n",
      "      vf_explained_var: 0.9684937596321106\n",
      "      vf_loss: 34.85985565185547\n",
      "    sample_time_ms: 19905.878\n",
      "    update_time_ms: 7.18\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.1116885665622\n",
      "    rl_1: 72.0561229447124\n",
      "  time_since_restore: 11178.770056009293\n",
      "  time_this_iter_s: 23.178528308868408\n",
      "  time_total_s: 11178.770056009293\n",
      "  timestamp: 1550891781\n",
      "  timesteps_since_restore: 4810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4810000\n",
      "  training_iteration: 481\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11178 s, 481 iter, 4810000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 100.16\n",
      "  episode_reward_max: 228.61251958563577\n",
      "  episode_reward_mean: 150.6923370673269\n",
      "  episode_reward_min: -162.17137030142356\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 40814\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.923\n",
      "    load_time_ms: 2.193\n",
      "    num_steps_sampled: 4820000\n",
      "    num_steps_trained: 4820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35582271218299866\n",
      "      kl: 0.019603027030825615\n",
      "      policy_loss: 0.004119283519685268\n",
      "      total_loss: 66.7205581665039\n",
      "      vf_explained_var: 0.9642711281776428\n",
      "      vf_loss: 66.71644592285156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38800591230392456\n",
      "      kl: 0.03761577233672142\n",
      "      policy_loss: 0.007010842673480511\n",
      "      total_loss: 56.62286376953125\n",
      "      vf_explained_var: 0.9634265303611755\n",
      "      vf_loss: 56.615848541259766\n",
      "    sample_time_ms: 19892.075\n",
      "    update_time_ms: 7.641\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.36619425486548\n",
      "    rl_1: 66.32614281246141\n",
      "  time_since_restore: 11201.783761501312\n",
      "  time_this_iter_s: 23.013705492019653\n",
      "  time_total_s: 11201.783761501312\n",
      "  timestamp: 1550891804\n",
      "  timesteps_since_restore: 4820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4820000\n",
      "  training_iteration: 482\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11201 s, 482 iter, 4820000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-17-07\n",
      "  done: false\n",
      "  episode_len_mean: 112.48\n",
      "  episode_reward_max: 228.61251958563577\n",
      "  episode_reward_mean: 148.0917321802977\n",
      "  episode_reward_min: -162.17137030142356\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 40901\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.184\n",
      "    load_time_ms: 2.276\n",
      "    num_steps_sampled: 4830000\n",
      "    num_steps_trained: 4830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.050851985812187195\n",
      "      kl: 0.013317611068487167\n",
      "      policy_loss: 0.0005963749717921019\n",
      "      total_loss: 57.239601135253906\n",
      "      vf_explained_var: 0.9626570343971252\n",
      "      vf_loss: 57.2390022277832\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21859318017959595\n",
      "      kl: 0.02498100884258747\n",
      "      policy_loss: 0.0027799755334854126\n",
      "      total_loss: 49.839454650878906\n",
      "      vf_explained_var: 0.9628689289093018\n",
      "      vf_loss: 49.836673736572266\n",
      "    sample_time_ms: 19929.481\n",
      "    update_time_ms: 7.552\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.5888498023774\n",
      "    rl_1: 63.502882377920294\n",
      "  time_since_restore: 11225.168562173843\n",
      "  time_this_iter_s: 23.384800672531128\n",
      "  time_total_s: 11225.168562173843\n",
      "  timestamp: 1550891827\n",
      "  timesteps_since_restore: 4830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4830000\n",
      "  training_iteration: 483\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11225 s, 483 iter, 4830000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-17-30\n",
      "  done: false\n",
      "  episode_len_mean: 111.77\n",
      "  episode_reward_max: 224.03058588164217\n",
      "  episode_reward_mean: 160.9553794913539\n",
      "  episode_reward_min: -164.01892357514873\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 40989\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.092\n",
      "    load_time_ms: 2.283\n",
      "    num_steps_sampled: 4840000\n",
      "    num_steps_trained: 4840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.058130476623773575\n",
      "      kl: 13.014455795288086\n",
      "      policy_loss: 0.09754293411970139\n",
      "      total_loss: 43.14795684814453\n",
      "      vf_explained_var: 0.9660792946815491\n",
      "      vf_loss: 43.050418853759766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.20350146293640137\n",
      "      kl: 0.026122337207198143\n",
      "      policy_loss: 0.006462853867560625\n",
      "      total_loss: 38.887779235839844\n",
      "      vf_explained_var: 0.966265082359314\n",
      "      vf_loss: 38.88131332397461\n",
      "    sample_time_ms: 19899.135\n",
      "    update_time_ms: 7.667\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.39928853343666\n",
      "    rl_1: 69.55609095791722\n",
      "  time_since_restore: 11247.888822317123\n",
      "  time_this_iter_s: 22.72026014328003\n",
      "  time_total_s: 11247.888822317123\n",
      "  timestamp: 1550891850\n",
      "  timesteps_since_restore: 4840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4840000\n",
      "  training_iteration: 484\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11247 s, 484 iter, 4840000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-17-53\n",
      "  done: false\n",
      "  episode_len_mean: 117.63\n",
      "  episode_reward_max: 234.32844451913914\n",
      "  episode_reward_mean: 159.34760329623225\n",
      "  episode_reward_min: -162.66061619503301\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 41078\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.348\n",
      "    load_time_ms: 2.28\n",
      "    num_steps_sampled: 4850000\n",
      "    num_steps_trained: 4850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2214435487985611\n",
      "      kl: 0.018881412222981453\n",
      "      policy_loss: -0.000691966968588531\n",
      "      total_loss: 80.53026580810547\n",
      "      vf_explained_var: 0.94967120885849\n",
      "      vf_loss: 80.53095245361328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3130076825618744\n",
      "      kl: 0.019177883863449097\n",
      "      policy_loss: -4.919102593703428e-06\n",
      "      total_loss: 70.6326904296875\n",
      "      vf_explained_var: 0.9489789009094238\n",
      "      vf_loss: 70.6326904296875\n",
      "    sample_time_ms: 19939.024\n",
      "    update_time_ms: 7.719\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.19560494815272\n",
      "    rl_1: 70.15199834807952\n",
      "  time_since_restore: 11271.221314907074\n",
      "  time_this_iter_s: 23.33249258995056\n",
      "  time_total_s: 11271.221314907074\n",
      "  timestamp: 1550891873\n",
      "  timesteps_since_restore: 4850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4850000\n",
      "  training_iteration: 485\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11271 s, 485 iter, 4850000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-18-17\n",
      "  done: false\n",
      "  episode_len_mean: 114.13\n",
      "  episode_reward_max: 228.92224863448143\n",
      "  episode_reward_mean: 159.45516375138578\n",
      "  episode_reward_min: -159.88356729463032\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 41166\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.309\n",
      "    load_time_ms: 2.289\n",
      "    num_steps_sampled: 4860000\n",
      "    num_steps_trained: 4860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07272882759571075\n",
      "      kl: 0.017626052722334862\n",
      "      policy_loss: 0.0014011845923960209\n",
      "      total_loss: 93.9411392211914\n",
      "      vf_explained_var: 0.9404441714286804\n",
      "      vf_loss: 93.93971252441406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1947987824678421\n",
      "      kl: 0.024916227906942368\n",
      "      policy_loss: 0.0010214385110884905\n",
      "      total_loss: 76.36841583251953\n",
      "      vf_explained_var: 0.9417808651924133\n",
      "      vf_loss: 76.36738586425781\n",
      "    sample_time_ms: 19975.745\n",
      "    update_time_ms: 7.812\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.84734749275269\n",
      "    rl_1: 69.60781625863306\n",
      "  time_since_restore: 11294.666207075119\n",
      "  time_this_iter_s: 23.444892168045044\n",
      "  time_total_s: 11294.666207075119\n",
      "  timestamp: 1550891897\n",
      "  timesteps_since_restore: 4860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4860000\n",
      "  training_iteration: 486\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11294 s, 486 iter, 4860000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-18-40\n",
      "  done: false\n",
      "  episode_len_mean: 111.28\n",
      "  episode_reward_max: 236.71442195240908\n",
      "  episode_reward_mean: 152.89377481045503\n",
      "  episode_reward_min: -148.49965803034735\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 41254\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.367\n",
      "    load_time_ms: 2.276\n",
      "    num_steps_sampled: 4870000\n",
      "    num_steps_trained: 4870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22974146902561188\n",
      "      kl: 0.014341194182634354\n",
      "      policy_loss: -0.0008273224229924381\n",
      "      total_loss: 76.67483520507812\n",
      "      vf_explained_var: 0.9503297805786133\n",
      "      vf_loss: 76.67565155029297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2948603332042694\n",
      "      kl: 0.011050318367779255\n",
      "      policy_loss: 0.0006627738475799561\n",
      "      total_loss: 65.34538269042969\n",
      "      vf_explained_var: 0.9475873112678528\n",
      "      vf_loss: 65.34471893310547\n",
      "    sample_time_ms: 20007.838\n",
      "    update_time_ms: 7.798\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.99751602263561\n",
      "    rl_1: 64.89625878781939\n",
      "  time_since_restore: 11317.821340560913\n",
      "  time_this_iter_s: 23.155133485794067\n",
      "  time_total_s: 11317.821340560913\n",
      "  timestamp: 1550891920\n",
      "  timesteps_since_restore: 4870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4870000\n",
      "  training_iteration: 487\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11317 s, 487 iter, 4870000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-19-03\n",
      "  done: false\n",
      "  episode_len_mean: 113.45\n",
      "  episode_reward_max: 230.0708161465581\n",
      "  episode_reward_mean: 163.09591250320446\n",
      "  episode_reward_min: -147.9175669695106\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 41342\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.652\n",
      "    load_time_ms: 2.272\n",
      "    num_steps_sampled: 4880000\n",
      "    num_steps_trained: 4880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21701182425022125\n",
      "      kl: 0.019369879737496376\n",
      "      policy_loss: -0.0012387618189677596\n",
      "      total_loss: 71.01747131347656\n",
      "      vf_explained_var: 0.9458695650100708\n",
      "      vf_loss: 71.01870727539062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.29457348585128784\n",
      "      kl: 0.02904530055820942\n",
      "      policy_loss: 0.007689208723604679\n",
      "      total_loss: 57.038204193115234\n",
      "      vf_explained_var: 0.947547435760498\n",
      "      vf_loss: 57.03050994873047\n",
      "    sample_time_ms: 19946.684\n",
      "    update_time_ms: 7.998\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.94785468926705\n",
      "    rl_1: 71.14805781393743\n",
      "  time_since_restore: 11340.351383209229\n",
      "  time_this_iter_s: 22.53004264831543\n",
      "  time_total_s: 11340.351383209229\n",
      "  timestamp: 1550891943\n",
      "  timesteps_since_restore: 4880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4880000\n",
      "  training_iteration: 488\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11340 s, 488 iter, 4880000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-19-26\n",
      "  done: false\n",
      "  episode_len_mean: 109.02\n",
      "  episode_reward_max: 232.7101963702873\n",
      "  episode_reward_mean: 171.24571154392575\n",
      "  episode_reward_min: -164.62968457647997\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 41434\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.676\n",
      "    load_time_ms: 2.286\n",
      "    num_steps_sampled: 4890000\n",
      "    num_steps_trained: 4890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2972872257232666\n",
      "      kl: 2.1301867961883545\n",
      "      policy_loss: 0.04623357579112053\n",
      "      total_loss: 37.9564323425293\n",
      "      vf_explained_var: 0.972299337387085\n",
      "      vf_loss: 37.91020202636719\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.37640246748924255\n",
      "      kl: 0.06673024594783783\n",
      "      policy_loss: 0.007521392311900854\n",
      "      total_loss: 30.94978904724121\n",
      "      vf_explained_var: 0.9734852910041809\n",
      "      vf_loss: 30.942264556884766\n",
      "    sample_time_ms: 19984.351\n",
      "    update_time_ms: 7.993\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.83941969765388\n",
      "    rl_1: 75.40629184627188\n",
      "  time_since_restore: 11363.695542812347\n",
      "  time_this_iter_s: 23.344159603118896\n",
      "  time_total_s: 11363.695542812347\n",
      "  timestamp: 1550891966\n",
      "  timesteps_since_restore: 4890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4890000\n",
      "  training_iteration: 489\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11363 s, 489 iter, 4890000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-19-49\n",
      "  done: false\n",
      "  episode_len_mean: 110.12\n",
      "  episode_reward_max: 232.2018289017942\n",
      "  episode_reward_mean: 150.64489502587463\n",
      "  episode_reward_min: -167.6062953510615\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 41524\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.295\n",
      "    load_time_ms: 2.322\n",
      "    num_steps_sampled: 4900000\n",
      "    num_steps_trained: 4900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22935928404331207\n",
      "      kl: 0.02158486284315586\n",
      "      policy_loss: 0.0013757589040324092\n",
      "      total_loss: 82.66432189941406\n",
      "      vf_explained_var: 0.9453253149986267\n",
      "      vf_loss: 82.66293334960938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3315378427505493\n",
      "      kl: 0.014948384836316109\n",
      "      policy_loss: 0.0008263494237326086\n",
      "      total_loss: 72.7981185913086\n",
      "      vf_explained_var: 0.9452177882194519\n",
      "      vf_loss: 72.79730224609375\n",
      "    sample_time_ms: 20033.203\n",
      "    update_time_ms: 8.456\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.75659644523857\n",
      "    rl_1: 65.88829858063606\n",
      "  time_since_restore: 11386.96109366417\n",
      "  time_this_iter_s: 23.2655508518219\n",
      "  time_total_s: 11386.96109366417\n",
      "  timestamp: 1550891989\n",
      "  timesteps_since_restore: 4900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4900000\n",
      "  training_iteration: 490\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11386 s, 490 iter, 4900000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-20-13\n",
      "  done: false\n",
      "  episode_len_mean: 119.07\n",
      "  episode_reward_max: 221.20839461935225\n",
      "  episode_reward_mean: 154.4937665313645\n",
      "  episode_reward_min: -160.99061665221873\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 41610\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.049\n",
      "    load_time_ms: 2.325\n",
      "    num_steps_sampled: 4910000\n",
      "    num_steps_trained: 4910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.07489613443613052\n",
      "      kl: 0.012092734687030315\n",
      "      policy_loss: -0.0018359163077548146\n",
      "      total_loss: 50.91352844238281\n",
      "      vf_explained_var: 0.9630027413368225\n",
      "      vf_loss: 50.91535949707031\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.25063344836235046\n",
      "      kl: 0.014792196452617645\n",
      "      policy_loss: 0.0025049480609595776\n",
      "      total_loss: 43.52864456176758\n",
      "      vf_explained_var: 0.9657487869262695\n",
      "      vf_loss: 43.526145935058594\n",
      "    sample_time_ms: 20083.283\n",
      "    update_time_ms: 8.813\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.98737661871448\n",
      "    rl_1: 67.50638991265005\n",
      "  time_since_restore: 11410.741904497147\n",
      "  time_this_iter_s: 23.780810832977295\n",
      "  time_total_s: 11410.741904497147\n",
      "  timestamp: 1550892013\n",
      "  timesteps_since_restore: 4910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4910000\n",
      "  training_iteration: 491\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11410 s, 491 iter, 4910000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-20-36\n",
      "  done: false\n",
      "  episode_len_mean: 125.7\n",
      "  episode_reward_max: 236.58550340506116\n",
      "  episode_reward_mean: 148.1242467596765\n",
      "  episode_reward_min: -182.15961045434557\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 41690\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.625\n",
      "    load_time_ms: 2.383\n",
      "    num_steps_sampled: 4920000\n",
      "    num_steps_trained: 4920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.09919675439596176\n",
      "      kl: 0.017950937151908875\n",
      "      policy_loss: 0.004953952971845865\n",
      "      total_loss: 71.99873352050781\n",
      "      vf_explained_var: 0.9513275027275085\n",
      "      vf_loss: 71.9937973022461\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.12126535922288895\n",
      "      kl: 0.013682532124221325\n",
      "      policy_loss: 0.0008920504478737712\n",
      "      total_loss: 53.6069221496582\n",
      "      vf_explained_var: 0.963455080986023\n",
      "      vf_loss: 53.60603332519531\n",
      "    sample_time_ms: 20071.643\n",
      "    update_time_ms: 8.394\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.77124636505592\n",
      "    rl_1: 65.35300039462058\n",
      "  time_since_restore: 11433.644245386124\n",
      "  time_this_iter_s: 22.90234088897705\n",
      "  time_total_s: 11433.644245386124\n",
      "  timestamp: 1550892036\n",
      "  timesteps_since_restore: 4920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4920000\n",
      "  training_iteration: 492\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11433 s, 492 iter, 4920000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-20-59\n",
      "  done: false\n",
      "  episode_len_mean: 112.22\n",
      "  episode_reward_max: 221.79518111941408\n",
      "  episode_reward_mean: 158.27995735757892\n",
      "  episode_reward_min: -159.54106794521837\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 41781\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.96\n",
      "    load_time_ms: 2.302\n",
      "    num_steps_sampled: 4930000\n",
      "    num_steps_trained: 4930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2488172948360443\n",
      "      kl: 0.024403903633356094\n",
      "      policy_loss: 0.0018956405110657215\n",
      "      total_loss: 49.75770568847656\n",
      "      vf_explained_var: 0.9626479744911194\n",
      "      vf_loss: 49.75581741333008\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.34981441497802734\n",
      "      kl: 0.01775040477514267\n",
      "      policy_loss: 0.0003264240804128349\n",
      "      total_loss: 42.32898712158203\n",
      "      vf_explained_var: 0.961708664894104\n",
      "      vf_loss: 42.32866668701172\n",
      "    sample_time_ms: 20054.748\n",
      "    update_time_ms: 8.507\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.46991202744495\n",
      "    rl_1: 69.81004533013396\n",
      "  time_since_restore: 11456.69329738617\n",
      "  time_this_iter_s: 23.049052000045776\n",
      "  time_total_s: 11456.69329738617\n",
      "  timestamp: 1550892059\n",
      "  timesteps_since_restore: 4930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4930000\n",
      "  training_iteration: 493\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11456 s, 493 iter, 4930000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-21-22\n",
      "  done: false\n",
      "  episode_len_mean: 115.23\n",
      "  episode_reward_max: 233.10875553516343\n",
      "  episode_reward_mean: 167.05413421788862\n",
      "  episode_reward_min: -145.0442672845375\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 41871\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.043\n",
      "    load_time_ms: 2.308\n",
      "    num_steps_sampled: 4940000\n",
      "    num_steps_trained: 4940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15991033613681793\n",
      "      kl: 0.018600109964609146\n",
      "      policy_loss: 0.0017868394497781992\n",
      "      total_loss: 52.99660110473633\n",
      "      vf_explained_var: 0.9536523818969727\n",
      "      vf_loss: 52.994815826416016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3193887174129486\n",
      "      kl: 0.011910881847143173\n",
      "      policy_loss: -0.0002328279661014676\n",
      "      total_loss: 48.19381332397461\n",
      "      vf_explained_var: 0.9464215040206909\n",
      "      vf_loss: 48.19403839111328\n",
      "    sample_time_ms: 20096.361\n",
      "    update_time_ms: 8.536\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.43865439005756\n",
      "    rl_1: 72.61547982783105\n",
      "  time_since_restore: 11479.820411920547\n",
      "  time_this_iter_s: 23.12711453437805\n",
      "  time_total_s: 11479.820411920547\n",
      "  timestamp: 1550892082\n",
      "  timesteps_since_restore: 4940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4940000\n",
      "  training_iteration: 494\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11479 s, 494 iter, 4940000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-21-46\n",
      "  done: false\n",
      "  episode_len_mean: 109.05\n",
      "  episode_reward_max: 231.01153922281492\n",
      "  episode_reward_mean: 149.5087470581695\n",
      "  episode_reward_min: -175.84398276110454\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 41962\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.845\n",
      "    load_time_ms: 2.287\n",
      "    num_steps_sampled: 4950000\n",
      "    num_steps_trained: 4950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22994934022426605\n",
      "      kl: 0.12046761065721512\n",
      "      policy_loss: 0.0242648683488369\n",
      "      total_loss: 69.37397003173828\n",
      "      vf_explained_var: 0.9592781066894531\n",
      "      vf_loss: 69.34971618652344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3509807288646698\n",
      "      kl: 0.023853329941630363\n",
      "      policy_loss: -0.0021124393679201603\n",
      "      total_loss: 59.29765701293945\n",
      "      vf_explained_var: 0.9571312069892883\n",
      "      vf_loss: 59.29976272583008\n",
      "    sample_time_ms: 20116.921\n",
      "    update_time_ms: 8.545\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.35784243240767\n",
      "    rl_1: 63.15090462576186\n",
      "  time_since_restore: 11503.32587647438\n",
      "  time_this_iter_s: 23.505464553833008\n",
      "  time_total_s: 11503.32587647438\n",
      "  timestamp: 1550892106\n",
      "  timesteps_since_restore: 4950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4950000\n",
      "  training_iteration: 495\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11503 s, 495 iter, 4950000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-22-09\n",
      "  done: false\n",
      "  episode_len_mean: 111.72\n",
      "  episode_reward_max: 233.73197384231062\n",
      "  episode_reward_mean: 167.1551632298272\n",
      "  episode_reward_min: -157.18569401053406\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 42050\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.11\n",
      "    load_time_ms: 2.299\n",
      "    num_steps_sampled: 4960000\n",
      "    num_steps_trained: 4960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2246883362531662\n",
      "      kl: 0.03202560171484947\n",
      "      policy_loss: 0.007114281877875328\n",
      "      total_loss: 52.666622161865234\n",
      "      vf_explained_var: 0.9581931829452515\n",
      "      vf_loss: 52.65951156616211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35654112696647644\n",
      "      kl: 0.016135428100824356\n",
      "      policy_loss: -0.0014889140147715807\n",
      "      total_loss: 46.944820404052734\n",
      "      vf_explained_var: 0.955598771572113\n",
      "      vf_loss: 46.9463005065918\n",
      "    sample_time_ms: 20039.542\n",
      "    update_time_ms: 8.432\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.26789823979693\n",
      "    rl_1: 73.8872649900302\n",
      "  time_since_restore: 11526.168801307678\n",
      "  time_this_iter_s: 22.84292483329773\n",
      "  time_total_s: 11526.168801307678\n",
      "  timestamp: 1550892129\n",
      "  timesteps_since_restore: 4960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4960000\n",
      "  training_iteration: 496\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11526 s, 496 iter, 4960000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-22-32\n",
      "  done: false\n",
      "  episode_len_mean: 128.8\n",
      "  episode_reward_max: 233.73197384231062\n",
      "  episode_reward_mean: 165.22402752250167\n",
      "  episode_reward_min: -148.17140109258042\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 42127\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.238\n",
      "    load_time_ms: 2.393\n",
      "    num_steps_sampled: 4970000\n",
      "    num_steps_trained: 4970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: 0.08803029358386993\n",
      "      kl: 0.026367731392383575\n",
      "      policy_loss: 0.00530289439484477\n",
      "      total_loss: 39.42730712890625\n",
      "      vf_explained_var: 0.9703004360198975\n",
      "      vf_loss: 39.42200469970703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.13283587992191315\n",
      "      kl: 0.016575057059526443\n",
      "      policy_loss: 0.0011077147210016847\n",
      "      total_loss: 39.66816711425781\n",
      "      vf_explained_var: 0.9664453268051147\n",
      "      vf_loss: 39.66706085205078\n",
      "    sample_time_ms: 20053.543\n",
      "    update_time_ms: 8.176\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.72094427236517\n",
      "    rl_1: 70.50308325013648\n",
      "  time_since_restore: 11549.436511278152\n",
      "  time_this_iter_s: 23.267709970474243\n",
      "  time_total_s: 11549.436511278152\n",
      "  timestamp: 1550892152\n",
      "  timesteps_since_restore: 4970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4970000\n",
      "  training_iteration: 497\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11549 s, 497 iter, 4970000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-22-56\n",
      "  done: false\n",
      "  episode_len_mean: 117.29\n",
      "  episode_reward_max: 235.41103093087014\n",
      "  episode_reward_mean: 161.01287897035144\n",
      "  episode_reward_min: -158.75030619900923\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 42215\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.689\n",
      "    load_time_ms: 2.439\n",
      "    num_steps_sampled: 4980000\n",
      "    num_steps_trained: 4980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.17591789364814758\n",
      "      kl: 0.025234956294298172\n",
      "      policy_loss: 0.003601549193263054\n",
      "      total_loss: 62.73688507080078\n",
      "      vf_explained_var: 0.9524337649345398\n",
      "      vf_loss: 62.73329162597656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.31240609288215637\n",
      "      kl: 0.015726935118436813\n",
      "      policy_loss: 0.0011359263444319367\n",
      "      total_loss: 56.14994430541992\n",
      "      vf_explained_var: 0.9464967250823975\n",
      "      vf_loss: 56.148799896240234\n",
      "    sample_time_ms: 20164.328\n",
      "    update_time_ms: 7.689\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.39629748483482\n",
      "    rl_1: 68.61658148551666\n",
      "  time_since_restore: 11573.124151468277\n",
      "  time_this_iter_s: 23.68764019012451\n",
      "  time_total_s: 11573.124151468277\n",
      "  timestamp: 1550892176\n",
      "  timesteps_since_restore: 4980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4980000\n",
      "  training_iteration: 498\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11573 s, 498 iter, 4980000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-23-19\n",
      "  done: false\n",
      "  episode_len_mean: 108.54\n",
      "  episode_reward_max: 229.6050639066381\n",
      "  episode_reward_mean: 155.07963517031519\n",
      "  episode_reward_min: -149.30101446823312\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 42307\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.922\n",
      "    load_time_ms: 2.494\n",
      "    num_steps_sampled: 4990000\n",
      "    num_steps_trained: 4990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4252556562423706\n",
      "      kl: 0.03630500286817551\n",
      "      policy_loss: 0.0053734430111944675\n",
      "      total_loss: 79.4412841796875\n",
      "      vf_explained_var: 0.9555578231811523\n",
      "      vf_loss: 79.43590545654297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5014433860778809\n",
      "      kl: 0.026847995817661285\n",
      "      policy_loss: 0.003787099150940776\n",
      "      total_loss: 67.22859191894531\n",
      "      vf_explained_var: 0.9537829756736755\n",
      "      vf_loss: 67.22480010986328\n",
      "    sample_time_ms: 20135.166\n",
      "    update_time_ms: 8.031\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.11130041483467\n",
      "    rl_1: 67.96833475548051\n",
      "  time_since_restore: 11596.235987663269\n",
      "  time_this_iter_s: 23.111836194992065\n",
      "  time_total_s: 11596.235987663269\n",
      "  timestamp: 1550892199\n",
      "  timesteps_since_restore: 4990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 4990000\n",
      "  training_iteration: 499\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11596 s, 499 iter, 4990000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-23-42\n",
      "  done: false\n",
      "  episode_len_mean: 109.36\n",
      "  episode_reward_max: 235.802522107093\n",
      "  episode_reward_mean: 164.38353001752205\n",
      "  episode_reward_min: -143.716348924685\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 42398\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.107\n",
      "    load_time_ms: 2.462\n",
      "    num_steps_sampled: 5000000\n",
      "    num_steps_trained: 5000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35206514596939087\n",
      "      kl: 0.02855575643479824\n",
      "      policy_loss: 0.003945839591324329\n",
      "      total_loss: 38.814125061035156\n",
      "      vf_explained_var: 0.9736409187316895\n",
      "      vf_loss: 38.8101806640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43575766682624817\n",
      "      kl: 0.018016433343291283\n",
      "      policy_loss: 0.0019419296877458692\n",
      "      total_loss: 38.301692962646484\n",
      "      vf_explained_var: 0.9691583514213562\n",
      "      vf_loss: 38.29974365234375\n",
      "    sample_time_ms: 20136.222\n",
      "    update_time_ms: 7.782\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.71577163365069\n",
      "    rl_1: 71.66775838387137\n",
      "  time_since_restore: 11619.509850025177\n",
      "  time_this_iter_s: 23.27386236190796\n",
      "  time_total_s: 11619.509850025177\n",
      "  timestamp: 1550892222\n",
      "  timesteps_since_restore: 5000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5000000\n",
      "  training_iteration: 500\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11619 s, 500 iter, 5000000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-24-06\n",
      "  done: false\n",
      "  episode_len_mean: 116.72\n",
      "  episode_reward_max: 223.35244771512413\n",
      "  episode_reward_mean: 167.56872972322327\n",
      "  episode_reward_min: -148.2507561782779\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 42483\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.342\n",
      "    load_time_ms: 2.453\n",
      "    num_steps_sampled: 5010000\n",
      "    num_steps_trained: 5010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09350131452083588\n",
      "      kl: 0.03103695996105671\n",
      "      policy_loss: 0.010247751139104366\n",
      "      total_loss: 32.14387512207031\n",
      "      vf_explained_var: 0.9715242385864258\n",
      "      vf_loss: 32.133636474609375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2527197301387787\n",
      "      kl: 0.013746123760938644\n",
      "      policy_loss: 0.0024622685741633177\n",
      "      total_loss: 28.705753326416016\n",
      "      vf_explained_var: 0.9697670340538025\n",
      "      vf_loss: 28.70328712463379\n",
      "    sample_time_ms: 20077.305\n",
      "    update_time_ms: 7.337\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.41789563964636\n",
      "    rl_1: 72.1508340835769\n",
      "  time_since_restore: 11642.628961086273\n",
      "  time_this_iter_s: 23.11911106109619\n",
      "  time_total_s: 11642.628961086273\n",
      "  timestamp: 1550892246\n",
      "  timesteps_since_restore: 5010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5010000\n",
      "  training_iteration: 501\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11642 s, 501 iter, 5010000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-24-29\n",
      "  done: false\n",
      "  episode_len_mean: 121.01\n",
      "  episode_reward_max: 228.59571735309802\n",
      "  episode_reward_mean: 167.028675902827\n",
      "  episode_reward_min: -158.40971590428518\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 42567\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.613\n",
      "    load_time_ms: 2.374\n",
      "    num_steps_sampled: 5020000\n",
      "    num_steps_trained: 5020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1093834862112999\n",
      "      kl: 0.02255052886903286\n",
      "      policy_loss: 0.0020954376086592674\n",
      "      total_loss: 40.26090621948242\n",
      "      vf_explained_var: 0.9637259244918823\n",
      "      vf_loss: 40.258819580078125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2747446894645691\n",
      "      kl: 0.010757328942418098\n",
      "      policy_loss: 0.0011751389829441905\n",
      "      total_loss: 33.71855926513672\n",
      "      vf_explained_var: 0.9674351811408997\n",
      "      vf_loss: 33.717384338378906\n",
      "    sample_time_ms: 20116.491\n",
      "    update_time_ms: 7.23\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.11460143769476\n",
      "    rl_1: 72.91407446513226\n",
      "  time_since_restore: 11665.931388378143\n",
      "  time_this_iter_s: 23.302427291870117\n",
      "  time_total_s: 11665.931388378143\n",
      "  timestamp: 1550892269\n",
      "  timesteps_since_restore: 5020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5020000\n",
      "  training_iteration: 502\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11665 s, 502 iter, 5020000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-24-52\n",
      "  done: false\n",
      "  episode_len_mean: 106.62\n",
      "  episode_reward_max: 224.780298626696\n",
      "  episode_reward_mean: 150.27786630539728\n",
      "  episode_reward_min: -177.4537091409258\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 42662\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.748\n",
      "    load_time_ms: 2.491\n",
      "    num_steps_sampled: 5030000\n",
      "    num_steps_trained: 5030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3592647612094879\n",
      "      kl: 0.02182772196829319\n",
      "      policy_loss: 0.004105537198483944\n",
      "      total_loss: 49.192710876464844\n",
      "      vf_explained_var: 0.9721766710281372\n",
      "      vf_loss: 49.188602447509766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39712002873420715\n",
      "      kl: 0.014951815828680992\n",
      "      policy_loss: 0.001307425438426435\n",
      "      total_loss: 37.877559661865234\n",
      "      vf_explained_var: 0.9734613299369812\n",
      "      vf_loss: 37.876251220703125\n",
      "    sample_time_ms: 20147.331\n",
      "    update_time_ms: 7.366\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.49851952948472\n",
      "    rl_1: 64.77934677591256\n",
      "  time_since_restore: 11689.291791439056\n",
      "  time_this_iter_s: 23.360403060913086\n",
      "  time_total_s: 11689.291791439056\n",
      "  timestamp: 1550892292\n",
      "  timesteps_since_restore: 5030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5030000\n",
      "  training_iteration: 503\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11689 s, 503 iter, 5030000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 120.06\n",
      "  episode_reward_max: 234.16058433242287\n",
      "  episode_reward_mean: 165.68670115494584\n",
      "  episode_reward_min: -149.64341370205352\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 42743\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.634\n",
      "    load_time_ms: 2.484\n",
      "    num_steps_sampled: 5040000\n",
      "    num_steps_trained: 5040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.048486270010471344\n",
      "      kl: 0.0493561290204525\n",
      "      policy_loss: 0.01364054623991251\n",
      "      total_loss: 35.06100845336914\n",
      "      vf_explained_var: 0.9733774065971375\n",
      "      vf_loss: 35.04736328125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1622639149427414\n",
      "      kl: 0.09675527364015579\n",
      "      policy_loss: 0.038646575063467026\n",
      "      total_loss: 26.11129379272461\n",
      "      vf_explained_var: 0.9792340397834778\n",
      "      vf_loss: 26.072647094726562\n",
      "    sample_time_ms: 20126.329\n",
      "    update_time_ms: 7.094\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.40206093161152\n",
      "    rl_1: 72.2846402233343\n",
      "  time_since_restore: 11712.207567453384\n",
      "  time_this_iter_s: 22.915776014328003\n",
      "  time_total_s: 11712.207567453384\n",
      "  timestamp: 1550892315\n",
      "  timesteps_since_restore: 5040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5040000\n",
      "  training_iteration: 504\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11712 s, 504 iter, 5040000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-25-38\n",
      "  done: false\n",
      "  episode_len_mean: 111.73\n",
      "  episode_reward_max: 234.16058433242287\n",
      "  episode_reward_mean: 158.18542690720278\n",
      "  episode_reward_min: -161.3231695461467\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 42832\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3107.488\n",
      "    load_time_ms: 2.518\n",
      "    num_steps_sampled: 5050000\n",
      "    num_steps_trained: 5050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.20997215807437897\n",
      "      kl: 0.018473923206329346\n",
      "      policy_loss: 0.0020700872410088778\n",
      "      total_loss: 94.73334503173828\n",
      "      vf_explained_var: 0.936128556728363\n",
      "      vf_loss: 94.73127746582031\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.28681570291519165\n",
      "      kl: 0.018467191606760025\n",
      "      policy_loss: 0.0030619422905147076\n",
      "      total_loss: 81.35599517822266\n",
      "      vf_explained_var: 0.9346968531608582\n",
      "      vf_loss: 81.35293579101562\n",
      "    sample_time_ms: 20064.353\n",
      "    update_time_ms: 6.893\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.40488240082992\n",
      "    rl_1: 68.78054450637285\n",
      "  time_since_restore: 11735.318689107895\n",
      "  time_this_iter_s: 23.111121654510498\n",
      "  time_total_s: 11735.318689107895\n",
      "  timestamp: 1550892338\n",
      "  timesteps_since_restore: 5050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5050000\n",
      "  training_iteration: 505\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11735 s, 505 iter, 5050000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-26-01\n",
      "  done: false\n",
      "  episode_len_mean: 113.45\n",
      "  episode_reward_max: 232.33087705620795\n",
      "  episode_reward_mean: 165.3626130237076\n",
      "  episode_reward_min: -160.3015123587655\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 42920\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.896\n",
      "    load_time_ms: 2.588\n",
      "    num_steps_sampled: 5060000\n",
      "    num_steps_trained: 5060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2993389070034027\n",
      "      kl: 0.04242559149861336\n",
      "      policy_loss: 0.008614708669483662\n",
      "      total_loss: 49.446712493896484\n",
      "      vf_explained_var: 0.9633156061172485\n",
      "      vf_loss: 49.43809509277344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.341380774974823\n",
      "      kl: 0.014873434789478779\n",
      "      policy_loss: 0.0012659599306061864\n",
      "      total_loss: 44.7021369934082\n",
      "      vf_explained_var: 0.9636012315750122\n",
      "      vf_loss: 44.70087432861328\n",
      "    sample_time_ms: 20080.448\n",
      "    update_time_ms: 7.169\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.36072867976169\n",
      "    rl_1: 72.00188434394589\n",
      "  time_since_restore: 11758.128747224808\n",
      "  time_this_iter_s: 22.810058116912842\n",
      "  time_total_s: 11758.128747224808\n",
      "  timestamp: 1550892361\n",
      "  timesteps_since_restore: 5060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5060000\n",
      "  training_iteration: 506\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11758 s, 506 iter, 5060000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-26-24\n",
      "  done: false\n",
      "  episode_len_mean: 118.18\n",
      "  episode_reward_max: 231.80965396295014\n",
      "  episode_reward_mean: 158.68171904146854\n",
      "  episode_reward_min: -166.60887360204816\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 43005\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.214\n",
      "    load_time_ms: 2.5\n",
      "    num_steps_sampled: 5070000\n",
      "    num_steps_trained: 5070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18085050582885742\n",
      "      kl: 0.035528816282749176\n",
      "      policy_loss: 0.005227565299719572\n",
      "      total_loss: 39.82140350341797\n",
      "      vf_explained_var: 0.9679177403450012\n",
      "      vf_loss: 39.81616973876953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.29238006472587585\n",
      "      kl: 0.012617778964340687\n",
      "      policy_loss: 0.004152659792453051\n",
      "      total_loss: 33.54711151123047\n",
      "      vf_explained_var: 0.9698668122291565\n",
      "      vf_loss: 33.542964935302734\n",
      "    sample_time_ms: 20044.332\n",
      "    update_time_ms: 7.146\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.29939623067985\n",
      "    rl_1: 67.38232281078868\n",
      "  time_since_restore: 11781.125935554504\n",
      "  time_this_iter_s: 22.997188329696655\n",
      "  time_total_s: 11781.125935554504\n",
      "  timestamp: 1550892384\n",
      "  timesteps_since_restore: 5070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5070000\n",
      "  training_iteration: 507\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11781 s, 507 iter, 5070000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-26-47\n",
      "  done: false\n",
      "  episode_len_mean: 109.86\n",
      "  episode_reward_max: 223.0216591646038\n",
      "  episode_reward_mean: 162.96454173438045\n",
      "  episode_reward_min: -160.5078666721689\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 43096\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.885\n",
      "    load_time_ms: 2.543\n",
      "    num_steps_sampled: 5080000\n",
      "    num_steps_trained: 5080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.27939313650131226\n",
      "      kl: 0.02068488486111164\n",
      "      policy_loss: 0.0001734892575768754\n",
      "      total_loss: 44.9271240234375\n",
      "      vf_explained_var: 0.9681259393692017\n",
      "      vf_loss: 44.92694854736328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.336967408657074\n",
      "      kl: 0.015097320079803467\n",
      "      policy_loss: 0.0017641064478084445\n",
      "      total_loss: 37.13878631591797\n",
      "      vf_explained_var: 0.9669998288154602\n",
      "      vf_loss: 37.13700485229492\n",
      "    sample_time_ms: 19966.488\n",
      "    update_time_ms: 7.314\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.94051504261635\n",
      "    rl_1: 70.02402669176412\n",
      "  time_since_restore: 11804.003737211227\n",
      "  time_this_iter_s: 22.877801656723022\n",
      "  time_total_s: 11804.003737211227\n",
      "  timestamp: 1550892407\n",
      "  timesteps_since_restore: 5080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5080000\n",
      "  training_iteration: 508\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11804 s, 508 iter, 5080000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-27-10\n",
      "  done: false\n",
      "  episode_len_mean: 110.64\n",
      "  episode_reward_max: 236.5130149705748\n",
      "  episode_reward_mean: 153.2011770202718\n",
      "  episode_reward_min: -165.34336181607392\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 43186\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.134\n",
      "    load_time_ms: 2.477\n",
      "    num_steps_sampled: 5090000\n",
      "    num_steps_trained: 5090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2904185652732849\n",
      "      kl: 0.013560722582042217\n",
      "      policy_loss: 0.00027126321219839156\n",
      "      total_loss: 84.61082458496094\n",
      "      vf_explained_var: 0.9455705285072327\n",
      "      vf_loss: 84.61055755615234\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3947039246559143\n",
      "      kl: 0.011821338906884193\n",
      "      policy_loss: 0.0007779778679832816\n",
      "      total_loss: 73.0703353881836\n",
      "      vf_explained_var: 0.9458706378936768\n",
      "      vf_loss: 73.06956481933594\n",
      "    sample_time_ms: 19940.857\n",
      "    update_time_ms: 6.946\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.91576069752365\n",
      "    rl_1: 67.28541632274813\n",
      "  time_since_restore: 11826.815408229828\n",
      "  time_this_iter_s: 22.811671018600464\n",
      "  time_total_s: 11826.815408229828\n",
      "  timestamp: 1550892430\n",
      "  timesteps_since_restore: 5090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5090000\n",
      "  training_iteration: 509\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11826 s, 509 iter, 5090000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-27-33\n",
      "  done: false\n",
      "  episode_len_mean: 108.74\n",
      "  episode_reward_max: 236.5130149705748\n",
      "  episode_reward_mean: 161.5526555286623\n",
      "  episode_reward_min: -165.9254057116443\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 43278\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.424\n",
      "    load_time_ms: 2.48\n",
      "    num_steps_sampled: 5100000\n",
      "    num_steps_trained: 5100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.379798948764801\n",
      "      kl: 0.018088718876242638\n",
      "      policy_loss: 0.0021107459906488657\n",
      "      total_loss: 39.393585205078125\n",
      "      vf_explained_var: 0.9702853560447693\n",
      "      vf_loss: 39.39147186279297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4332031309604645\n",
      "      kl: 0.01827128976583481\n",
      "      policy_loss: -0.0018200967460870743\n",
      "      total_loss: 31.365903854370117\n",
      "      vf_explained_var: 0.9701778888702393\n",
      "      vf_loss: 31.36772918701172\n",
      "    sample_time_ms: 19875.941\n",
      "    update_time_ms: 7.015\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.05077723164926\n",
      "    rl_1: 70.50187829701306\n",
      "  time_since_restore: 11849.417615413666\n",
      "  time_this_iter_s: 22.60220718383789\n",
      "  time_total_s: 11849.417615413666\n",
      "  timestamp: 1550892453\n",
      "  timesteps_since_restore: 5100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5100000\n",
      "  training_iteration: 510\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11849 s, 510 iter, 5100000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-27-56\n",
      "  done: false\n",
      "  episode_len_mean: 109.48\n",
      "  episode_reward_max: 230.12801335521837\n",
      "  episode_reward_mean: 155.87716118511318\n",
      "  episode_reward_min: -165.811127954863\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 43368\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.955\n",
      "    load_time_ms: 2.483\n",
      "    num_steps_sampled: 5110000\n",
      "    num_steps_trained: 5110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.334771066904068\n",
      "      kl: 0.03083205595612526\n",
      "      policy_loss: 0.007612340617924929\n",
      "      total_loss: 64.45718383789062\n",
      "      vf_explained_var: 0.959629237651825\n",
      "      vf_loss: 64.44955444335938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44859564304351807\n",
      "      kl: 0.02596725896000862\n",
      "      policy_loss: 0.00150388537440449\n",
      "      total_loss: 64.19108581542969\n",
      "      vf_explained_var: 0.9541441798210144\n",
      "      vf_loss: 64.1895980834961\n",
      "    sample_time_ms: 19885.752\n",
      "    update_time_ms: 7.255\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.27589451105334\n",
      "    rl_1: 67.60126667405986\n",
      "  time_since_restore: 11872.612983226776\n",
      "  time_this_iter_s: 23.19536781311035\n",
      "  time_total_s: 11872.612983226776\n",
      "  timestamp: 1550892476\n",
      "  timesteps_since_restore: 5110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5110000\n",
      "  training_iteration: 511\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11872 s, 511 iter, 5110000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-28-19\n",
      "  done: false\n",
      "  episode_len_mean: 111.09\n",
      "  episode_reward_max: 228.19278544930728\n",
      "  episode_reward_mean: 172.63151101145803\n",
      "  episode_reward_min: -130.72092020795662\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 43459\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.849\n",
      "    load_time_ms: 2.576\n",
      "    num_steps_sampled: 5120000\n",
      "    num_steps_trained: 5120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2973789572715759\n",
      "      kl: 0.02099001407623291\n",
      "      policy_loss: 0.00313664716668427\n",
      "      total_loss: 28.02150535583496\n",
      "      vf_explained_var: 0.9744489789009094\n",
      "      vf_loss: 28.018373489379883\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4070707857608795\n",
      "      kl: 0.034181080758571625\n",
      "      policy_loss: 0.008357468992471695\n",
      "      total_loss: 24.124134063720703\n",
      "      vf_explained_var: 0.9752097725868225\n",
      "      vf_loss: 24.11577796936035\n",
      "    sample_time_ms: 19874.922\n",
      "    update_time_ms: 7.279\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.68877428457348\n",
      "    rl_1: 76.94273672688455\n",
      "  time_since_restore: 11895.769023418427\n",
      "  time_this_iter_s: 23.15604019165039\n",
      "  time_total_s: 11895.769023418427\n",
      "  timestamp: 1550892499\n",
      "  timesteps_since_restore: 5120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5120000\n",
      "  training_iteration: 512\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11895 s, 512 iter, 5120000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-28-42\n",
      "  done: false\n",
      "  episode_len_mean: 106.19\n",
      "  episode_reward_max: 229.77741044493598\n",
      "  episode_reward_mean: 167.3994095641119\n",
      "  episode_reward_min: -178.54369302585184\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 43550\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.199\n",
      "    load_time_ms: 2.461\n",
      "    num_steps_sampled: 5130000\n",
      "    num_steps_trained: 5130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35874348878860474\n",
      "      kl: 0.02028701826930046\n",
      "      policy_loss: 0.0026728608645498753\n",
      "      total_loss: 51.721534729003906\n",
      "      vf_explained_var: 0.9624552726745605\n",
      "      vf_loss: 51.71886444091797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4226785898208618\n",
      "      kl: 0.0387173555791378\n",
      "      policy_loss: 0.00950361043214798\n",
      "      total_loss: 41.48421859741211\n",
      "      vf_explained_var: 0.9630494713783264\n",
      "      vf_loss: 41.474708557128906\n",
      "    sample_time_ms: 19809.146\n",
      "    update_time_ms: 7.055\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.02924189927961\n",
      "    rl_1: 74.3701676648323\n",
      "  time_since_restore: 11918.481977701187\n",
      "  time_this_iter_s: 22.71295428276062\n",
      "  time_total_s: 11918.481977701187\n",
      "  timestamp: 1550892522\n",
      "  timesteps_since_restore: 5130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5130000\n",
      "  training_iteration: 513\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11918 s, 513 iter, 5130000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-29-06\n",
      "  done: false\n",
      "  episode_len_mean: 113.37\n",
      "  episode_reward_max: 229.34838263193492\n",
      "  episode_reward_mean: 155.78570841633038\n",
      "  episode_reward_min: -158.94228293865277\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 43640\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.436\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 5140000\n",
      "    num_steps_trained: 5140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2787915766239166\n",
      "      kl: 0.08349770307540894\n",
      "      policy_loss: 0.01744864322245121\n",
      "      total_loss: 50.006935119628906\n",
      "      vf_explained_var: 0.9646241664886475\n",
      "      vf_loss: 49.9894905090332\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3611908555030823\n",
      "      kl: 0.01828741282224655\n",
      "      policy_loss: -0.0003808157052844763\n",
      "      total_loss: 45.12333297729492\n",
      "      vf_explained_var: 0.9614958167076111\n",
      "      vf_loss: 45.12370681762695\n",
      "    sample_time_ms: 19857.227\n",
      "    update_time_ms: 7.155\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.06526939301371\n",
      "    rl_1: 67.72043902331667\n",
      "  time_since_restore: 11941.901752948761\n",
      "  time_this_iter_s: 23.419775247573853\n",
      "  time_total_s: 11941.901752948761\n",
      "  timestamp: 1550892546\n",
      "  timesteps_since_restore: 5140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5140000\n",
      "  training_iteration: 514\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11941 s, 514 iter, 5140000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 111.76\n",
      "  episode_reward_max: 230.76132666256828\n",
      "  episode_reward_mean: 164.68799983977374\n",
      "  episode_reward_min: -125.734686325882\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 43730\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.958\n",
      "    load_time_ms: 2.533\n",
      "    num_steps_sampled: 5150000\n",
      "    num_steps_trained: 5150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.31258898973464966\n",
      "      kl: 0.022760625928640366\n",
      "      policy_loss: 0.004036230035126209\n",
      "      total_loss: 32.97639083862305\n",
      "      vf_explained_var: 0.9741465449333191\n",
      "      vf_loss: 32.97235107421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3889608681201935\n",
      "      kl: 0.03247364982962608\n",
      "      policy_loss: 0.0087819155305624\n",
      "      total_loss: 27.588573455810547\n",
      "      vf_explained_var: 0.9790765643119812\n",
      "      vf_loss: 27.57978630065918\n",
      "    sample_time_ms: 19902.484\n",
      "    update_time_ms: 7.175\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.85502561249079\n",
      "    rl_1: 73.83297422728293\n",
      "  time_since_restore: 11965.243795394897\n",
      "  time_this_iter_s: 23.342042446136475\n",
      "  time_total_s: 11965.243795394897\n",
      "  timestamp: 1550892569\n",
      "  timesteps_since_restore: 5150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5150000\n",
      "  training_iteration: 515\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11965 s, 515 iter, 5150000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-29-52\n",
      "  done: false\n",
      "  episode_len_mean: 117.6\n",
      "  episode_reward_max: 224.6114641889008\n",
      "  episode_reward_mean: 160.7892398815663\n",
      "  episode_reward_min: -150.47027757893522\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 43813\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.027\n",
      "    load_time_ms: 2.467\n",
      "    num_steps_sampled: 5160000\n",
      "    num_steps_trained: 5160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.09522679448127747\n",
      "      kl: 0.021757960319519043\n",
      "      policy_loss: 0.007882100529968739\n",
      "      total_loss: 35.37127685546875\n",
      "      vf_explained_var: 0.9715965390205383\n",
      "      vf_loss: 35.3633918762207\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21655148267745972\n",
      "      kl: 0.02718851901590824\n",
      "      policy_loss: 0.0008912363555282354\n",
      "      total_loss: 23.80766487121582\n",
      "      vf_explained_var: 0.9794644117355347\n",
      "      vf_loss: 23.806774139404297\n",
      "    sample_time_ms: 19896.489\n",
      "    update_time_ms: 6.872\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.4144477850374\n",
      "    rl_1: 69.37479209652892\n",
      "  time_since_restore: 11987.981196165085\n",
      "  time_this_iter_s: 22.737400770187378\n",
      "  time_total_s: 11987.981196165085\n",
      "  timestamp: 1550892592\n",
      "  timesteps_since_restore: 5160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5160000\n",
      "  training_iteration: 516\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 11987 s, 516 iter, 5160000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-30-14\n",
      "  done: false\n",
      "  episode_len_mean: 111.53\n",
      "  episode_reward_max: 231.15874113933825\n",
      "  episode_reward_mean: 172.8837472066192\n",
      "  episode_reward_min: -175.17494285075574\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 43903\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3063.709\n",
      "    load_time_ms: 2.454\n",
      "    num_steps_sampled: 5170000\n",
      "    num_steps_trained: 5170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35688093304634094\n",
      "      kl: 0.03530901297926903\n",
      "      policy_loss: 0.011137478984892368\n",
      "      total_loss: 42.92694091796875\n",
      "      vf_explained_var: 0.9673383831977844\n",
      "      vf_loss: 42.91580581665039\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42189115285873413\n",
      "      kl: 0.014456730335950851\n",
      "      policy_loss: 0.0017870370065793395\n",
      "      total_loss: 39.16837692260742\n",
      "      vf_explained_var: 0.9683857560157776\n",
      "      vf_loss: 39.166587829589844\n",
      "    sample_time_ms: 19838.603\n",
      "    update_time_ms: 7.222\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.01983995213841\n",
      "    rl_1: 75.86390725448072\n",
      "  time_since_restore: 12010.431550979614\n",
      "  time_this_iter_s: 22.45035481452942\n",
      "  time_total_s: 12010.431550979614\n",
      "  timestamp: 1550892614\n",
      "  timesteps_since_restore: 5170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5170000\n",
      "  training_iteration: 517\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12010 s, 517 iter, 5170000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-30-38\n",
      "  done: false\n",
      "  episode_len_mean: 117.79\n",
      "  episode_reward_max: 231.79166957008377\n",
      "  episode_reward_mean: 166.1284693180066\n",
      "  episode_reward_min: -154.17206685718668\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 43990\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.458\n",
      "    load_time_ms: 2.357\n",
      "    num_steps_sampled: 5180000\n",
      "    num_steps_trained: 5180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.30801481008529663\n",
      "      kl: 0.030631957575678825\n",
      "      policy_loss: 0.008250340819358826\n",
      "      total_loss: 36.793975830078125\n",
      "      vf_explained_var: 0.972560465335846\n",
      "      vf_loss: 36.785728454589844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.36193251609802246\n",
      "      kl: 0.02306976355612278\n",
      "      policy_loss: 0.0014273873530328274\n",
      "      total_loss: 33.21896743774414\n",
      "      vf_explained_var: 0.9723429679870605\n",
      "      vf_loss: 33.21754455566406\n",
      "    sample_time_ms: 19863.927\n",
      "    update_time_ms: 7.437\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.90633684742285\n",
      "    rl_1: 70.22213247058376\n",
      "  time_since_restore: 12033.798189878464\n",
      "  time_this_iter_s: 23.366638898849487\n",
      "  time_total_s: 12033.798189878464\n",
      "  timestamp: 1550892638\n",
      "  timesteps_since_restore: 5180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5180000\n",
      "  training_iteration: 518\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12033 s, 518 iter, 5180000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-31-01\n",
      "  done: false\n",
      "  episode_len_mean: 116.61\n",
      "  episode_reward_max: 232.39660655626176\n",
      "  episode_reward_mean: 167.65262417341074\n",
      "  episode_reward_min: -165.983006814246\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 44078\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.271\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 5190000\n",
      "    num_steps_trained: 5190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2539829611778259\n",
      "      kl: 0.055447857826948166\n",
      "      policy_loss: 0.013860717415809631\n",
      "      total_loss: 27.068077087402344\n",
      "      vf_explained_var: 0.9737787246704102\n",
      "      vf_loss: 27.054218292236328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3481861650943756\n",
      "      kl: 0.02132253721356392\n",
      "      policy_loss: 0.001477160258218646\n",
      "      total_loss: 18.976877212524414\n",
      "      vf_explained_var: 0.9809089303016663\n",
      "      vf_loss: 18.975400924682617\n",
      "    sample_time_ms: 19935.88\n",
      "    update_time_ms: 7.628\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.27517803487562\n",
      "    rl_1: 72.37744613853509\n",
      "  time_since_restore: 12057.357892513275\n",
      "  time_this_iter_s: 23.5597026348114\n",
      "  time_total_s: 12057.357892513275\n",
      "  timestamp: 1550892661\n",
      "  timesteps_since_restore: 5190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5190000\n",
      "  training_iteration: 519\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12057 s, 519 iter, 5190000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-31-24\n",
      "  done: false\n",
      "  episode_len_mean: 107.38\n",
      "  episode_reward_max: 233.56617580903352\n",
      "  episode_reward_mean: 172.06132766002142\n",
      "  episode_reward_min: -151.97776842903764\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 44171\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.916\n",
      "    load_time_ms: 2.33\n",
      "    num_steps_sampled: 5200000\n",
      "    num_steps_trained: 5200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42875486612319946\n",
      "      kl: 0.052696797996759415\n",
      "      policy_loss: 0.010856415145099163\n",
      "      total_loss: 33.12082290649414\n",
      "      vf_explained_var: 0.9721173048019409\n",
      "      vf_loss: 33.10996627807617\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4935111403465271\n",
      "      kl: 0.024163518100976944\n",
      "      policy_loss: -0.0008396498742513359\n",
      "      total_loss: 27.879817962646484\n",
      "      vf_explained_var: 0.9722325205802917\n",
      "      vf_loss: 27.880653381347656\n",
      "    sample_time_ms: 19946.586\n",
      "    update_time_ms: 7.557\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.61307634202707\n",
      "    rl_1: 76.4482513179944\n",
      "  time_since_restore: 12080.05864572525\n",
      "  time_this_iter_s: 22.700753211975098\n",
      "  time_total_s: 12080.05864572525\n",
      "  timestamp: 1550892684\n",
      "  timesteps_since_restore: 5200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5200000\n",
      "  training_iteration: 520\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12080 s, 520 iter, 5200000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-31-47\n",
      "  done: false\n",
      "  episode_len_mean: 112.31\n",
      "  episode_reward_max: 233.29320759322235\n",
      "  episode_reward_mean: 154.9736113327237\n",
      "  episode_reward_min: -167.34348736068\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 44259\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.941\n",
      "    load_time_ms: 2.342\n",
      "    num_steps_sampled: 5210000\n",
      "    num_steps_trained: 5210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2626726031303406\n",
      "      kl: 0.02116682194173336\n",
      "      policy_loss: 0.0032610022462904453\n",
      "      total_loss: 37.06941223144531\n",
      "      vf_explained_var: 0.9781053066253662\n",
      "      vf_loss: 37.06614685058594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35497406125068665\n",
      "      kl: 0.025831440463662148\n",
      "      policy_loss: 0.003322877921164036\n",
      "      total_loss: 33.220794677734375\n",
      "      vf_explained_var: 0.9766311645507812\n",
      "      vf_loss: 33.21746826171875\n",
      "    sample_time_ms: 19931.592\n",
      "    update_time_ms: 7.453\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.01687711011746\n",
      "    rl_1: 65.95673422260624\n",
      "  time_since_restore: 12103.11591720581\n",
      "  time_this_iter_s: 23.057271480560303\n",
      "  time_total_s: 12103.11591720581\n",
      "  timestamp: 1550892707\n",
      "  timesteps_since_restore: 5210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5210000\n",
      "  training_iteration: 521\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12103 s, 521 iter, 5210000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-32-11\n",
      "  done: false\n",
      "  episode_len_mean: 111.3\n",
      "  episode_reward_max: 226.62628435776983\n",
      "  episode_reward_mean: 162.75660116169394\n",
      "  episode_reward_min: -167.34348736068\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 44349\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3094.662\n",
      "    load_time_ms: 2.269\n",
      "    num_steps_sampled: 5220000\n",
      "    num_steps_trained: 5220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.293630450963974\n",
      "      kl: 0.03213278204202652\n",
      "      policy_loss: 0.0033369259908795357\n",
      "      total_loss: 24.68283462524414\n",
      "      vf_explained_var: 0.9806805849075317\n",
      "      vf_loss: 24.679500579833984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.37549054622650146\n",
      "      kl: 0.16554327309131622\n",
      "      policy_loss: 0.004397958051413298\n",
      "      total_loss: 20.108919143676758\n",
      "      vf_explained_var: 0.9807726740837097\n",
      "      vf_loss: 20.104522705078125\n",
      "    sample_time_ms: 19956.206\n",
      "    update_time_ms: 7.663\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.29202735793905\n",
      "    rl_1: 70.46457380375489\n",
      "  time_since_restore: 12126.553848028183\n",
      "  time_this_iter_s: 23.437930822372437\n",
      "  time_total_s: 12126.553848028183\n",
      "  timestamp: 1550892731\n",
      "  timesteps_since_restore: 5220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5220000\n",
      "  training_iteration: 522\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12126 s, 522 iter, 5220000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-32-34\n",
      "  done: false\n",
      "  episode_len_mean: 111.61\n",
      "  episode_reward_max: 237.12027183890487\n",
      "  episode_reward_mean: 157.88682673696783\n",
      "  episode_reward_min: -159.05192702039835\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 44439\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.882\n",
      "    load_time_ms: 2.389\n",
      "    num_steps_sampled: 5230000\n",
      "    num_steps_trained: 5230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3297116458415985\n",
      "      kl: 0.03715670108795166\n",
      "      policy_loss: 0.00653839809820056\n",
      "      total_loss: 67.5474853515625\n",
      "      vf_explained_var: 0.9519450068473816\n",
      "      vf_loss: 67.54093933105469\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4070119261741638\n",
      "      kl: 0.023914817720651627\n",
      "      policy_loss: 0.0018261306686326861\n",
      "      total_loss: 54.07441329956055\n",
      "      vf_explained_var: 0.9547731280326843\n",
      "      vf_loss: 54.07257843017578\n",
      "    sample_time_ms: 20011.552\n",
      "    update_time_ms: 7.73\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.09535817890432\n",
      "    rl_1: 66.79146855806353\n",
      "  time_since_restore: 12149.813879966736\n",
      "  time_this_iter_s: 23.260031938552856\n",
      "  time_total_s: 12149.813879966736\n",
      "  timestamp: 1550892754\n",
      "  timesteps_since_restore: 5230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5230000\n",
      "  training_iteration: 523\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12149 s, 523 iter, 5230000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-32-57\n",
      "  done: false\n",
      "  episode_len_mean: 113.1\n",
      "  episode_reward_max: 233.10479822787258\n",
      "  episode_reward_mean: 159.73147106767638\n",
      "  episode_reward_min: -165.8391492252225\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 44528\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3092.593\n",
      "    load_time_ms: 2.403\n",
      "    num_steps_sampled: 5240000\n",
      "    num_steps_trained: 5240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3264768123626709\n",
      "      kl: 0.02384750358760357\n",
      "      policy_loss: 0.004737301729619503\n",
      "      total_loss: 40.47761917114258\n",
      "      vf_explained_var: 0.9659614562988281\n",
      "      vf_loss: 40.47287368774414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4335876405239105\n",
      "      kl: 0.019193904474377632\n",
      "      policy_loss: -0.001703892950899899\n",
      "      total_loss: 40.26822280883789\n",
      "      vf_explained_var: 0.959006667137146\n",
      "      vf_loss: 40.26993179321289\n",
      "    sample_time_ms: 19998.937\n",
      "    update_time_ms: 7.868\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.2928566921462\n",
      "    rl_1: 68.43861437553016\n",
      "  time_since_restore: 12173.094544649124\n",
      "  time_this_iter_s: 23.280664682388306\n",
      "  time_total_s: 12173.094544649124\n",
      "  timestamp: 1550892777\n",
      "  timesteps_since_restore: 5240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5240000\n",
      "  training_iteration: 524\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12173 s, 524 iter, 5240000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-33-20\n",
      "  done: false\n",
      "  episode_len_mean: 105.39\n",
      "  episode_reward_max: 227.00082786444236\n",
      "  episode_reward_mean: 149.03688736140774\n",
      "  episode_reward_min: -175.33486060255706\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 44624\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.217\n",
      "    load_time_ms: 2.369\n",
      "    num_steps_sampled: 5250000\n",
      "    num_steps_trained: 5250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4567863345146179\n",
      "      kl: 0.015776213258504868\n",
      "      policy_loss: -0.0008795405738055706\n",
      "      total_loss: 88.5728759765625\n",
      "      vf_explained_var: 0.9525032043457031\n",
      "      vf_loss: 88.5737533569336\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5120387673377991\n",
      "      kl: 0.02422156371176243\n",
      "      policy_loss: 0.0007318724528886378\n",
      "      total_loss: 77.9046859741211\n",
      "      vf_explained_var: 0.9486099481582642\n",
      "      vf_loss: 77.90393829345703\n",
      "    sample_time_ms: 19963.913\n",
      "    update_time_ms: 7.885\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.01247246234085\n",
      "    rl_1: 65.02441489906688\n",
      "  time_since_restore: 12196.072869300842\n",
      "  time_this_iter_s: 22.97832465171814\n",
      "  time_total_s: 12196.072869300842\n",
      "  timestamp: 1550892800\n",
      "  timesteps_since_restore: 5250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5250000\n",
      "  training_iteration: 525\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12196 s, 525 iter, 5250000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-33-43\n",
      "  done: false\n",
      "  episode_len_mean: 113.11\n",
      "  episode_reward_max: 237.40824930033315\n",
      "  episode_reward_mean: 148.3036321291387\n",
      "  episode_reward_min: -175.33486060255706\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 44705\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.035\n",
      "    load_time_ms: 2.336\n",
      "    num_steps_sampled: 5260000\n",
      "    num_steps_trained: 5260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.02488861046731472\n",
      "      kl: 0.03747124224901199\n",
      "      policy_loss: 0.0062288823537528515\n",
      "      total_loss: 56.578468322753906\n",
      "      vf_explained_var: 0.9642747044563293\n",
      "      vf_loss: 56.572235107421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.19351743161678314\n",
      "      kl: 0.03560976684093475\n",
      "      policy_loss: 0.002837749198079109\n",
      "      total_loss: 43.3072395324707\n",
      "      vf_explained_var: 0.9704394340515137\n",
      "      vf_loss: 43.30439758300781\n",
      "    sample_time_ms: 20005.138\n",
      "    update_time_ms: 7.979\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.57509574206414\n",
      "    rl_1: 63.72853638707459\n",
      "  time_since_restore: 12219.210233449936\n",
      "  time_this_iter_s: 23.137364149093628\n",
      "  time_total_s: 12219.210233449936\n",
      "  timestamp: 1550892823\n",
      "  timesteps_since_restore: 5260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5260000\n",
      "  training_iteration: 526\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12219 s, 526 iter, 5260000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-34-07\n",
      "  done: false\n",
      "  episode_len_mean: 119.25\n",
      "  episode_reward_max: 237.40824930033315\n",
      "  episode_reward_mean: 161.7910977082182\n",
      "  episode_reward_min: -166.57114784541824\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 44791\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.095\n",
      "    load_time_ms: 2.335\n",
      "    num_steps_sampled: 5270000\n",
      "    num_steps_trained: 5270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1541125327348709\n",
      "      kl: 0.01772097311913967\n",
      "      policy_loss: -0.0005432135658338666\n",
      "      total_loss: 43.64031219482422\n",
      "      vf_explained_var: 0.9627940058708191\n",
      "      vf_loss: 43.64085388183594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3143746554851532\n",
      "      kl: 0.01820516213774681\n",
      "      policy_loss: 0.0012556994333863258\n",
      "      total_loss: 36.5916633605957\n",
      "      vf_explained_var: 0.9641714096069336\n",
      "      vf_loss: 36.59040832519531\n",
      "    sample_time_ms: 20097.339\n",
      "    update_time_ms: 7.733\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.09908511813063\n",
      "    rl_1: 69.69201259008753\n",
      "  time_since_restore: 12242.573466062546\n",
      "  time_this_iter_s: 23.363232612609863\n",
      "  time_total_s: 12242.573466062546\n",
      "  timestamp: 1550892847\n",
      "  timesteps_since_restore: 5270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5270000\n",
      "  training_iteration: 527\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12242 s, 527 iter, 5270000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-34-30\n",
      "  done: false\n",
      "  episode_len_mean: 111.59\n",
      "  episode_reward_max: 228.05693743968249\n",
      "  episode_reward_mean: 159.0271128323001\n",
      "  episode_reward_min: -154.18981786230384\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 44881\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.923\n",
      "    load_time_ms: 2.325\n",
      "    num_steps_sampled: 5280000\n",
      "    num_steps_trained: 5280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2451707124710083\n",
      "      kl: 0.031452737748622894\n",
      "      policy_loss: 0.007102526258677244\n",
      "      total_loss: 57.451473236083984\n",
      "      vf_explained_var: 0.9558222889900208\n",
      "      vf_loss: 57.444374084472656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4025503098964691\n",
      "      kl: 1.1561882495880127\n",
      "      policy_loss: 0.041957151144742966\n",
      "      total_loss: 53.29935836791992\n",
      "      vf_explained_var: 0.9526382088661194\n",
      "      vf_loss: 53.25739288330078\n",
      "    sample_time_ms: 20098.225\n",
      "    update_time_ms: 7.481\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.94927110566016\n",
      "    rl_1: 69.07784172663993\n",
      "  time_since_restore: 12265.707270622253\n",
      "  time_this_iter_s: 23.13380455970764\n",
      "  time_total_s: 12265.707270622253\n",
      "  timestamp: 1550892870\n",
      "  timesteps_since_restore: 5280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5280000\n",
      "  training_iteration: 528\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12265 s, 528 iter, 5280000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-34-53\n",
      "  done: false\n",
      "  episode_len_mean: 114.13\n",
      "  episode_reward_max: 232.46382706605056\n",
      "  episode_reward_mean: 162.834688642891\n",
      "  episode_reward_min: -124.70219410543952\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 44969\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.353\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 5290000\n",
      "    num_steps_trained: 5290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2888590693473816\n",
      "      kl: 0.018271856009960175\n",
      "      policy_loss: -0.0016109057469293475\n",
      "      total_loss: 31.0686092376709\n",
      "      vf_explained_var: 0.9740766882896423\n",
      "      vf_loss: 31.070219039916992\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4426376521587372\n",
      "      kl: 0.02150026522576809\n",
      "      policy_loss: 0.003968850709497929\n",
      "      total_loss: 30.055458068847656\n",
      "      vf_explained_var: 0.9685745239257812\n",
      "      vf_loss: 30.05149269104004\n",
      "    sample_time_ms: 20025.944\n",
      "    update_time_ms: 7.148\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.95301710056842\n",
      "    rl_1: 68.88167154232255\n",
      "  time_since_restore: 12288.517649650574\n",
      "  time_this_iter_s: 22.810379028320312\n",
      "  time_total_s: 12288.517649650574\n",
      "  timestamp: 1550892893\n",
      "  timesteps_since_restore: 5290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5290000\n",
      "  training_iteration: 529\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12288 s, 529 iter, 5290000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-35-16\n",
      "  done: false\n",
      "  episode_len_mean: 110.11\n",
      "  episode_reward_max: 231.46287263926556\n",
      "  episode_reward_mean: 162.11038198867263\n",
      "  episode_reward_min: -168.73755447806826\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 45060\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.293\n",
      "    load_time_ms: 2.345\n",
      "    num_steps_sampled: 5300000\n",
      "    num_steps_trained: 5300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3592437505722046\n",
      "      kl: 0.028829995542764664\n",
      "      policy_loss: 0.009239424020051956\n",
      "      total_loss: 41.563262939453125\n",
      "      vf_explained_var: 0.9688280820846558\n",
      "      vf_loss: 41.554019927978516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.472261518239975\n",
      "      kl: 0.014898269437253475\n",
      "      policy_loss: 0.0044692764058709145\n",
      "      total_loss: 34.74534225463867\n",
      "      vf_explained_var: 0.968643307685852\n",
      "      vf_loss: 34.74087142944336\n",
      "    sample_time_ms: 20039.48\n",
      "    update_time_ms: 7.433\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.37183104770664\n",
      "    rl_1: 68.738550940966\n",
      "  time_since_restore: 12311.357600450516\n",
      "  time_this_iter_s: 22.839950799942017\n",
      "  time_total_s: 12311.357600450516\n",
      "  timestamp: 1550892916\n",
      "  timesteps_since_restore: 5300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5300000\n",
      "  training_iteration: 530\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12311 s, 530 iter, 5300000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-35-39\n",
      "  done: false\n",
      "  episode_len_mean: 112.94\n",
      "  episode_reward_max: 227.14331626876498\n",
      "  episode_reward_mean: 160.42713800416016\n",
      "  episode_reward_min: -154.25328810208288\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 45148\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.36\n",
      "    load_time_ms: 2.35\n",
      "    num_steps_sampled: 5310000\n",
      "    num_steps_trained: 5310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.15687057375907898\n",
      "      kl: 0.02349410019814968\n",
      "      policy_loss: 0.0016977997729554772\n",
      "      total_loss: 53.546630859375\n",
      "      vf_explained_var: 0.9585708975791931\n",
      "      vf_loss: 53.5449333190918\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3167104721069336\n",
      "      kl: 0.014697275124490261\n",
      "      policy_loss: 0.0025321603752672672\n",
      "      total_loss: 42.51150894165039\n",
      "      vf_explained_var: 0.9649395942687988\n",
      "      vf_loss: 42.50897979736328\n",
      "    sample_time_ms: 20037.635\n",
      "    update_time_ms: 7.351\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.9861850241437\n",
      "    rl_1: 69.44095298001649\n",
      "  time_since_restore: 12334.593667507172\n",
      "  time_this_iter_s: 23.236067056655884\n",
      "  time_total_s: 12334.593667507172\n",
      "  timestamp: 1550892939\n",
      "  timesteps_since_restore: 5310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5310000\n",
      "  training_iteration: 531\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12334 s, 531 iter, 5310000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-36-02\n",
      "  done: false\n",
      "  episode_len_mean: 117.27\n",
      "  episode_reward_max: 228.12973748868228\n",
      "  episode_reward_mean: 160.5067212014632\n",
      "  episode_reward_min: -172.64732155528947\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 45231\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.318\n",
      "    load_time_ms: 2.336\n",
      "    num_steps_sampled: 5320000\n",
      "    num_steps_trained: 5320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.10293777287006378\n",
      "      kl: 0.015648415312170982\n",
      "      policy_loss: -0.000821516674477607\n",
      "      total_loss: 50.723548889160156\n",
      "      vf_explained_var: 0.952987015247345\n",
      "      vf_loss: 50.72437286376953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24450625479221344\n",
      "      kl: 0.01402374729514122\n",
      "      policy_loss: -0.002775181084871292\n",
      "      total_loss: 32.353172302246094\n",
      "      vf_explained_var: 0.9701055884361267\n",
      "      vf_loss: 32.3559455871582\n",
      "    sample_time_ms: 19997.013\n",
      "    update_time_ms: 7.505\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.39705490210116\n",
      "    rl_1: 69.10966629936199\n",
      "  time_since_restore: 12357.62720656395\n",
      "  time_this_iter_s: 23.033539056777954\n",
      "  time_total_s: 12357.62720656395\n",
      "  timestamp: 1550892962\n",
      "  timesteps_since_restore: 5320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5320000\n",
      "  training_iteration: 532\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12357 s, 532 iter, 5320000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-36-25\n",
      "  done: false\n",
      "  episode_len_mean: 115.65\n",
      "  episode_reward_max: 223.48498771391786\n",
      "  episode_reward_mean: 163.11949248662754\n",
      "  episode_reward_min: -159.13383748989412\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 45318\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.942\n",
      "    load_time_ms: 2.319\n",
      "    num_steps_sampled: 5330000\n",
      "    num_steps_trained: 5330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.32584449648857117\n",
      "      kl: 0.03531477227807045\n",
      "      policy_loss: 0.007093374617397785\n",
      "      total_loss: 30.332040786743164\n",
      "      vf_explained_var: 0.9755539298057556\n",
      "      vf_loss: 30.324941635131836\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4204028248786926\n",
      "      kl: 0.028020329773426056\n",
      "      policy_loss: 0.00488947844132781\n",
      "      total_loss: 25.90974998474121\n",
      "      vf_explained_var: 0.9761708378791809\n",
      "      vf_loss: 25.904861450195312\n",
      "    sample_time_ms: 20003.682\n",
      "    update_time_ms: 7.366\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.18348175328852\n",
      "    rl_1: 69.936010733339\n",
      "  time_since_restore: 12380.940499067307\n",
      "  time_this_iter_s: 23.313292503356934\n",
      "  time_total_s: 12380.940499067307\n",
      "  timestamp: 1550892985\n",
      "  timesteps_since_restore: 5330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5330000\n",
      "  training_iteration: 533\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12380 s, 533 iter, 5330000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-36-48\n",
      "  done: false\n",
      "  episode_len_mean: 107.26\n",
      "  episode_reward_max: 226.84248426771575\n",
      "  episode_reward_mean: 173.03753475329967\n",
      "  episode_reward_min: -156.4704175546704\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 45411\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.491\n",
      "    load_time_ms: 2.314\n",
      "    num_steps_sampled: 5340000\n",
      "    num_steps_trained: 5340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4652726650238037\n",
      "      kl: 0.019648417830467224\n",
      "      policy_loss: 0.0027932929806411266\n",
      "      total_loss: 39.423465728759766\n",
      "      vf_explained_var: 0.968439519405365\n",
      "      vf_loss: 39.42067337036133\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5069651007652283\n",
      "      kl: 0.02035297267138958\n",
      "      policy_loss: 0.0033370638266205788\n",
      "      total_loss: 32.671852111816406\n",
      "      vf_explained_var: 0.9675586223602295\n",
      "      vf_loss: 32.66851806640625\n",
      "    sample_time_ms: 19951.801\n",
      "    update_time_ms: 7.238\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.16836745557886\n",
      "    rl_1: 76.86916729772082\n",
      "  time_since_restore: 12403.698507785797\n",
      "  time_this_iter_s: 22.7580087184906\n",
      "  time_total_s: 12403.698507785797\n",
      "  timestamp: 1550893008\n",
      "  timesteps_since_restore: 5340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5340000\n",
      "  training_iteration: 534\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12403 s, 534 iter, 5340000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-37-11\n",
      "  done: false\n",
      "  episode_len_mean: 112.79\n",
      "  episode_reward_max: 233.56048508350767\n",
      "  episode_reward_mean: 161.20988589121222\n",
      "  episode_reward_min: -173.83373095221893\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 45500\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.973\n",
      "    load_time_ms: 2.278\n",
      "    num_steps_sampled: 5350000\n",
      "    num_steps_trained: 5350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3342002034187317\n",
      "      kl: 0.047270648181438446\n",
      "      policy_loss: 0.006747989449650049\n",
      "      total_loss: 44.744441986083984\n",
      "      vf_explained_var: 0.9703410267829895\n",
      "      vf_loss: 44.73768615722656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42315366864204407\n",
      "      kl: 0.032502975314855576\n",
      "      policy_loss: 0.017431719228625298\n",
      "      total_loss: 36.94376754760742\n",
      "      vf_explained_var: 0.9720087051391602\n",
      "      vf_loss: 36.92633819580078\n",
      "    sample_time_ms: 19970.462\n",
      "    update_time_ms: 7.218\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.0565401167482\n",
      "    rl_1: 70.153345774464\n",
      "  time_since_restore: 12426.906014204025\n",
      "  time_this_iter_s: 23.20750641822815\n",
      "  time_total_s: 12426.906014204025\n",
      "  timestamp: 1550893031\n",
      "  timesteps_since_restore: 5350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5350000\n",
      "  training_iteration: 535\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12426 s, 535 iter, 5350000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-37-35\n",
      "  done: false\n",
      "  episode_len_mean: 113.35\n",
      "  episode_reward_max: 231.10661638394222\n",
      "  episode_reward_mean: 156.79672528198972\n",
      "  episode_reward_min: -175.7738664132745\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 45590\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.38\n",
      "    load_time_ms: 2.35\n",
      "    num_steps_sampled: 5360000\n",
      "    num_steps_trained: 5360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3533715605735779\n",
      "      kl: 0.06541351974010468\n",
      "      policy_loss: 0.010156750679016113\n",
      "      total_loss: 56.655242919921875\n",
      "      vf_explained_var: 0.965255081653595\n",
      "      vf_loss: 56.645076751708984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4111776053905487\n",
      "      kl: 0.013915129005908966\n",
      "      policy_loss: -5.1490387704689056e-05\n",
      "      total_loss: 48.866512298583984\n",
      "      vf_explained_var: 0.9654814600944519\n",
      "      vf_loss: 48.86656188964844\n",
      "    sample_time_ms: 19969.481\n",
      "    update_time_ms: 7.365\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.50406207227135\n",
      "    rl_1: 67.29266320971837\n",
      "  time_since_restore: 12450.029333353043\n",
      "  time_this_iter_s: 23.123319149017334\n",
      "  time_total_s: 12450.029333353043\n",
      "  timestamp: 1550893055\n",
      "  timesteps_since_restore: 5360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5360000\n",
      "  training_iteration: 536\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12450 s, 536 iter, 5360000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-37-58\n",
      "  done: false\n",
      "  episode_len_mean: 105.4\n",
      "  episode_reward_max: 230.17343837847892\n",
      "  episode_reward_mean: 154.442767226377\n",
      "  episode_reward_min: -137.96197059736733\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 45686\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.446\n",
      "    load_time_ms: 2.392\n",
      "    num_steps_sampled: 5370000\n",
      "    num_steps_trained: 5370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4230239689350128\n",
      "      kl: 0.028271552175283432\n",
      "      policy_loss: 0.008190298452973366\n",
      "      total_loss: 44.442691802978516\n",
      "      vf_explained_var: 0.9755908250808716\n",
      "      vf_loss: 44.43450927734375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47606611251831055\n",
      "      kl: 0.016112536191940308\n",
      "      policy_loss: 0.008543825708329678\n",
      "      total_loss: 34.61046600341797\n",
      "      vf_explained_var: 0.9775248765945435\n",
      "      vf_loss: 34.601924896240234\n",
      "    sample_time_ms: 19937.555\n",
      "    update_time_ms: 7.362\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.2241204408013\n",
      "    rl_1: 68.21864678557569\n",
      "  time_since_restore: 12472.967092037201\n",
      "  time_this_iter_s: 22.937758684158325\n",
      "  time_total_s: 12472.967092037201\n",
      "  timestamp: 1550893078\n",
      "  timesteps_since_restore: 5370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5370000\n",
      "  training_iteration: 537\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12472 s, 537 iter, 5370000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-38-21\n",
      "  done: false\n",
      "  episode_len_mean: 110.09\n",
      "  episode_reward_max: 230.17343837847892\n",
      "  episode_reward_mean: 152.27832320245057\n",
      "  episode_reward_min: -173.47372256130276\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 45776\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.94\n",
      "    load_time_ms: 2.43\n",
      "    num_steps_sampled: 5380000\n",
      "    num_steps_trained: 5380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.26811376214027405\n",
      "      kl: 0.03540816530585289\n",
      "      policy_loss: 0.0058235889300704\n",
      "      total_loss: 73.28529357910156\n",
      "      vf_explained_var: 0.959770679473877\n",
      "      vf_loss: 73.27947998046875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3538977801799774\n",
      "      kl: 0.012572897598147392\n",
      "      policy_loss: -0.0004057803889736533\n",
      "      total_loss: 57.85847473144531\n",
      "      vf_explained_var: 0.9650384783744812\n",
      "      vf_loss: 57.8588752746582\n",
      "    sample_time_ms: 19946.845\n",
      "    update_time_ms: 7.257\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.46683660861339\n",
      "    rl_1: 66.81148659383715\n",
      "  time_since_restore: 12496.206687927246\n",
      "  time_this_iter_s: 23.239595890045166\n",
      "  time_total_s: 12496.206687927246\n",
      "  timestamp: 1550893101\n",
      "  timesteps_since_restore: 5380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5380000\n",
      "  training_iteration: 538\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12496 s, 538 iter, 5380000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-38-44\n",
      "  done: false\n",
      "  episode_len_mean: 114.97\n",
      "  episode_reward_max: 232.72114328297303\n",
      "  episode_reward_mean: 174.39026728186994\n",
      "  episode_reward_min: -142.89543597981077\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 45863\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.46\n",
      "    load_time_ms: 2.441\n",
      "    num_steps_sampled: 5390000\n",
      "    num_steps_trained: 5390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3548237085342407\n",
      "      kl: 0.015950048342347145\n",
      "      policy_loss: -0.0026033639442175627\n",
      "      total_loss: 20.088117599487305\n",
      "      vf_explained_var: 0.9808468222618103\n",
      "      vf_loss: 20.09071922302246\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.45680275559425354\n",
      "      kl: 0.02203146182000637\n",
      "      policy_loss: 0.0034301388077437878\n",
      "      total_loss: 18.863313674926758\n",
      "      vf_explained_var: 0.9804894924163818\n",
      "      vf_loss: 18.859886169433594\n",
      "    sample_time_ms: 19938.544\n",
      "    update_time_ms: 7.396\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.13371373589358\n",
      "    rl_1: 76.25655354597637\n",
      "  time_since_restore: 12518.928315401077\n",
      "  time_this_iter_s: 22.721627473831177\n",
      "  time_total_s: 12518.928315401077\n",
      "  timestamp: 1550893124\n",
      "  timesteps_since_restore: 5390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5390000\n",
      "  training_iteration: 539\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12518 s, 539 iter, 5390000 ts, 174 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-39-06\n",
      "  done: false\n",
      "  episode_len_mean: 116.92\n",
      "  episode_reward_max: 230.60000382539698\n",
      "  episode_reward_mean: 172.63889924149555\n",
      "  episode_reward_min: -170.4515036248887\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 45947\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.514\n",
      "    load_time_ms: 2.54\n",
      "    num_steps_sampled: 5400000\n",
      "    num_steps_trained: 5400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18564370274543762\n",
      "      kl: 0.0186283178627491\n",
      "      policy_loss: 0.003838991979137063\n",
      "      total_loss: 18.469005584716797\n",
      "      vf_explained_var: 0.9831895232200623\n",
      "      vf_loss: 18.465164184570312\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.29006731510162354\n",
      "      kl: 0.009879421442747116\n",
      "      policy_loss: 0.0005385391996242106\n",
      "      total_loss: 13.998506546020508\n",
      "      vf_explained_var: 0.9864367246627808\n",
      "      vf_loss: 13.997966766357422\n",
      "    sample_time_ms: 19888.257\n",
      "    update_time_ms: 6.95\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.39870829641481\n",
      "    rl_1: 75.24019094508076\n",
      "  time_since_restore: 12541.250449419022\n",
      "  time_this_iter_s: 22.322134017944336\n",
      "  time_total_s: 12541.250449419022\n",
      "  timestamp: 1550893146\n",
      "  timesteps_since_restore: 5400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5400000\n",
      "  training_iteration: 540\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12541 s, 540 iter, 5400000 ts, 173 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-39-29\n",
      "  done: false\n",
      "  episode_len_mean: 107.86\n",
      "  episode_reward_max: 232.2874266902151\n",
      "  episode_reward_mean: 163.3952006768105\n",
      "  episode_reward_min: -163.41443731195562\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 46039\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3053.535\n",
      "    load_time_ms: 2.621\n",
      "    num_steps_sampled: 5410000\n",
      "    num_steps_trained: 5410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4751965403556824\n",
      "      kl: 0.05385937541723251\n",
      "      policy_loss: 0.013645472005009651\n",
      "      total_loss: 64.29069519042969\n",
      "      vf_explained_var: 0.9576587080955505\n",
      "      vf_loss: 64.27704620361328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48400795459747314\n",
      "      kl: 0.024712391197681427\n",
      "      policy_loss: 0.0032004830427467823\n",
      "      total_loss: 52.878692626953125\n",
      "      vf_explained_var: 0.9573774337768555\n",
      "      vf_loss: 52.87549591064453\n",
      "    sample_time_ms: 19910.439\n",
      "    update_time_ms: 7.207\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.2607451248031\n",
      "    rl_1: 72.13445555200741\n",
      "  time_since_restore: 12564.503600358963\n",
      "  time_this_iter_s: 23.253150939941406\n",
      "  time_total_s: 12564.503600358963\n",
      "  timestamp: 1550893169\n",
      "  timesteps_since_restore: 5410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5410000\n",
      "  training_iteration: 541\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12564 s, 541 iter, 5410000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-39-52\n",
      "  done: false\n",
      "  episode_len_mean: 112.36\n",
      "  episode_reward_max: 235.2975135804373\n",
      "  episode_reward_mean: 157.66204038686365\n",
      "  episode_reward_min: -155.4703710867716\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 46129\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3052.727\n",
      "    load_time_ms: 2.629\n",
      "    num_steps_sampled: 5420000\n",
      "    num_steps_trained: 5420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.34864839911460876\n",
      "      kl: 0.033615320920944214\n",
      "      policy_loss: 0.0074113355949521065\n",
      "      total_loss: 69.29183959960938\n",
      "      vf_explained_var: 0.9541552662849426\n",
      "      vf_loss: 69.28441619873047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3965238034725189\n",
      "      kl: 0.05366186425089836\n",
      "      policy_loss: 0.013777833431959152\n",
      "      total_loss: 54.78680419921875\n",
      "      vf_explained_var: 0.9568750262260437\n",
      "      vf_loss: 54.77302551269531\n",
      "    sample_time_ms: 19911.523\n",
      "    update_time_ms: 6.856\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.51892657857961\n",
      "    rl_1: 67.14311380828401\n",
      "  time_since_restore: 12587.537644863129\n",
      "  time_this_iter_s: 23.03404450416565\n",
      "  time_total_s: 12587.537644863129\n",
      "  timestamp: 1550893192\n",
      "  timesteps_since_restore: 5420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5420000\n",
      "  training_iteration: 542\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12587 s, 542 iter, 5420000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-40-16\n",
      "  done: false\n",
      "  episode_len_mean: 118.83\n",
      "  episode_reward_max: 234.52969779047217\n",
      "  episode_reward_mean: 171.23502072642106\n",
      "  episode_reward_min: -163.44729131269958\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 46213\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3055.302\n",
      "    load_time_ms: 2.553\n",
      "    num_steps_sampled: 5430000\n",
      "    num_steps_trained: 5430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.28966403007507324\n",
      "      kl: 0.024280350655317307\n",
      "      policy_loss: 0.001239123521372676\n",
      "      total_loss: 45.59822463989258\n",
      "      vf_explained_var: 0.9597665071487427\n",
      "      vf_loss: 45.59697723388672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35697031021118164\n",
      "      kl: 0.018877167254686356\n",
      "      policy_loss: -0.0013906536623835564\n",
      "      total_loss: 38.2684440612793\n",
      "      vf_explained_var: 0.9612016677856445\n",
      "      vf_loss: 38.26983642578125\n",
      "    sample_time_ms: 19927.193\n",
      "    update_time_ms: 7.359\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.88976879778056\n",
      "    rl_1: 74.34525192864052\n",
      "  time_since_restore: 12611.034846544266\n",
      "  time_this_iter_s: 23.497201681137085\n",
      "  time_total_s: 12611.034846544266\n",
      "  timestamp: 1550893216\n",
      "  timesteps_since_restore: 5430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5430000\n",
      "  training_iteration: 543\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12611 s, 543 iter, 5430000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-40-39\n",
      "  done: false\n",
      "  episode_len_mean: 108.59\n",
      "  episode_reward_max: 232.66802063615543\n",
      "  episode_reward_mean: 169.40632603662291\n",
      "  episode_reward_min: -159.59044662519614\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 46304\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.897\n",
      "    load_time_ms: 2.631\n",
      "    num_steps_sampled: 5440000\n",
      "    num_steps_trained: 5440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5276696681976318\n",
      "      kl: 0.035706307739019394\n",
      "      policy_loss: 0.006320867221802473\n",
      "      total_loss: 51.0453987121582\n",
      "      vf_explained_var: 0.9616760611534119\n",
      "      vf_loss: 51.0390739440918\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5230385065078735\n",
      "      kl: 0.013049819506704807\n",
      "      policy_loss: 0.002456593792885542\n",
      "      total_loss: 42.240909576416016\n",
      "      vf_explained_var: 0.9627415537834167\n",
      "      vf_loss: 42.23845291137695\n",
      "    sample_time_ms: 19938.559\n",
      "    update_time_ms: 7.397\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.64394936755608\n",
      "    rl_1: 74.76237666906687\n",
      "  time_since_restore: 12634.093259096146\n",
      "  time_this_iter_s: 23.058412551879883\n",
      "  time_total_s: 12634.093259096146\n",
      "  timestamp: 1550893239\n",
      "  timesteps_since_restore: 5440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5440000\n",
      "  training_iteration: 544\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12634 s, 544 iter, 5440000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-41-02\n",
      "  done: false\n",
      "  episode_len_mean: 108.25\n",
      "  episode_reward_max: 228.440474168232\n",
      "  episode_reward_mean: 156.05004707354107\n",
      "  episode_reward_min: -155.30921259634266\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 46396\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.216\n",
      "    load_time_ms: 2.658\n",
      "    num_steps_sampled: 5450000\n",
      "    num_steps_trained: 5450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3757028877735138\n",
      "      kl: 55.62832260131836\n",
      "      policy_loss: 0.08379770815372467\n",
      "      total_loss: 52.721580505371094\n",
      "      vf_explained_var: 0.963412344455719\n",
      "      vf_loss: 52.63778305053711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.445119172334671\n",
      "      kl: 0.02399519458413124\n",
      "      policy_loss: 0.0009425345342606306\n",
      "      total_loss: 47.4072380065918\n",
      "      vf_explained_var: 0.9611607789993286\n",
      "      vf_loss: 47.40629196166992\n",
      "    sample_time_ms: 19888.275\n",
      "    update_time_ms: 7.483\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.0003202001497\n",
      "    rl_1: 69.04972687339131\n",
      "  time_since_restore: 12656.773684740067\n",
      "  time_this_iter_s: 22.6804256439209\n",
      "  time_total_s: 12656.773684740067\n",
      "  timestamp: 1550893262\n",
      "  timesteps_since_restore: 5450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5450000\n",
      "  training_iteration: 545\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12656 s, 545 iter, 5450000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 119.64\n",
      "  episode_reward_max: 236.55226125105784\n",
      "  episode_reward_mean: 139.88635376847415\n",
      "  episode_reward_min: -174.4165891951834\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 46479\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.93\n",
      "    load_time_ms: 2.594\n",
      "    num_steps_sampled: 5460000\n",
      "    num_steps_trained: 5460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21500834822654724\n",
      "      kl: 0.0053001102060079575\n",
      "      policy_loss: -0.0006215578760020435\n",
      "      total_loss: 157.3070526123047\n",
      "      vf_explained_var: 0.9231181740760803\n",
      "      vf_loss: 157.3076629638672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3154873251914978\n",
      "      kl: 0.013227698393166065\n",
      "      policy_loss: 0.0032565623987466097\n",
      "      total_loss: 163.339599609375\n",
      "      vf_explained_var: 0.9041522145271301\n",
      "      vf_loss: 163.33631896972656\n",
      "    sample_time_ms: 19831.375\n",
      "    update_time_ms: 7.229\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.51746984782415\n",
      "    rl_1: 60.368883920650035\n",
      "  time_since_restore: 12679.363760948181\n",
      "  time_this_iter_s: 22.590076208114624\n",
      "  time_total_s: 12679.363760948181\n",
      "  timestamp: 1550893284\n",
      "  timesteps_since_restore: 5460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5460000\n",
      "  training_iteration: 546\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 5.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12679 s, 546 iter, 5460000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-41-48\n",
      "  done: false\n",
      "  episode_len_mean: 118.1\n",
      "  episode_reward_max: 238.91796313892166\n",
      "  episode_reward_mean: 134.535517206921\n",
      "  episode_reward_min: -160.5020388285432\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 46564\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.33\n",
      "    load_time_ms: 2.55\n",
      "    num_steps_sampled: 5470000\n",
      "    num_steps_trained: 5470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.26238560676574707\n",
      "      kl: 0.011892824433743954\n",
      "      policy_loss: 0.002411779249086976\n",
      "      total_loss: 209.85641479492188\n",
      "      vf_explained_var: 0.9158725142478943\n",
      "      vf_loss: 209.85400390625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.37290140986442566\n",
      "      kl: 0.016038978472352028\n",
      "      policy_loss: -0.0003769157046917826\n",
      "      total_loss: 220.88824462890625\n",
      "      vf_explained_var: 0.8905943036079407\n",
      "      vf_loss: 220.8885955810547\n",
      "    sample_time_ms: 19877.465\n",
      "    update_time_ms: 7.327\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.51303024449123\n",
      "    rl_1: 58.022486962429774\n",
      "  time_since_restore: 12702.747639894485\n",
      "  time_this_iter_s: 23.38387894630432\n",
      "  time_total_s: 12702.747639894485\n",
      "  timestamp: 1550893308\n",
      "  timesteps_since_restore: 5470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5470000\n",
      "  training_iteration: 547\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12702 s, 547 iter, 5470000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 124.62\n",
      "  episode_reward_max: 228.40437501935784\n",
      "  episode_reward_mean: 117.72467615911093\n",
      "  episode_reward_min: -158.49785289743596\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 46645\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.423\n",
      "    load_time_ms: 2.529\n",
      "    num_steps_sampled: 5480000\n",
      "    num_steps_trained: 5480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1846032291650772\n",
      "      kl: 0.008084479719400406\n",
      "      policy_loss: 0.002178620547056198\n",
      "      total_loss: 152.53713989257812\n",
      "      vf_explained_var: 0.9376477003097534\n",
      "      vf_loss: 152.53494262695312\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.30037054419517517\n",
      "      kl: 0.01624242402613163\n",
      "      policy_loss: 0.0008591783116571605\n",
      "      total_loss: 149.23428344726562\n",
      "      vf_explained_var: 0.9241865277290344\n",
      "      vf_loss: 149.23342895507812\n",
      "    sample_time_ms: 19868.165\n",
      "    update_time_ms: 7.37\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.97509752440511\n",
      "    rl_1: 49.74957863470582\n",
      "  time_since_restore: 12725.855275392532\n",
      "  time_this_iter_s: 23.107635498046875\n",
      "  time_total_s: 12725.855275392532\n",
      "  timestamp: 1550893331\n",
      "  timesteps_since_restore: 5480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5480000\n",
      "  training_iteration: 548\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12725 s, 548 iter, 5480000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-42-34\n",
      "  done: false\n",
      "  episode_len_mean: 111.58\n",
      "  episode_reward_max: 227.09921679927376\n",
      "  episode_reward_mean: 109.1982182662173\n",
      "  episode_reward_min: -172.3417121949807\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 46733\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.04\n",
      "    load_time_ms: 2.493\n",
      "    num_steps_sampled: 5490000\n",
      "    num_steps_trained: 5490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.29375362396240234\n",
      "      kl: 0.008602661080658436\n",
      "      policy_loss: -0.0009932315442711115\n",
      "      total_loss: 217.86538696289062\n",
      "      vf_explained_var: 0.9321531653404236\n",
      "      vf_loss: 217.8663787841797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42163145542144775\n",
      "      kl: 0.016997428610920906\n",
      "      policy_loss: -4.0605638787383214e-05\n",
      "      total_loss: 207.82899475097656\n",
      "      vf_explained_var: 0.9170544743537903\n",
      "      vf_loss: 207.8290252685547\n",
      "    sample_time_ms: 19927.45\n",
      "    update_time_ms: 7.423\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.10284635648024\n",
      "    rl_1: 47.09537190973709\n",
      "  time_since_restore: 12749.18717288971\n",
      "  time_this_iter_s: 23.331897497177124\n",
      "  time_total_s: 12749.18717288971\n",
      "  timestamp: 1550893354\n",
      "  timesteps_since_restore: 5490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5490000\n",
      "  training_iteration: 549\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12749 s, 549 iter, 5490000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-42-57\n",
      "  done: false\n",
      "  episode_len_mean: 112.85\n",
      "  episode_reward_max: 227.63083521227145\n",
      "  episode_reward_mean: 112.46244851558889\n",
      "  episode_reward_min: -173.31551579119574\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 46822\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.766\n",
      "    load_time_ms: 2.405\n",
      "    num_steps_sampled: 5500000\n",
      "    num_steps_trained: 5500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.34280985593795776\n",
      "      kl: 0.008447380736470222\n",
      "      policy_loss: -0.0003250545123592019\n",
      "      total_loss: 169.17645263671875\n",
      "      vf_explained_var: 0.9345335364341736\n",
      "      vf_loss: 169.17678833007812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4369216859340668\n",
      "      kl: 0.019360700622200966\n",
      "      policy_loss: -0.0004559327499009669\n",
      "      total_loss: 159.3480682373047\n",
      "      vf_explained_var: 0.9204103350639343\n",
      "      vf_loss: 159.34854125976562\n",
      "    sample_time_ms: 19972.552\n",
      "    update_time_ms: 7.497\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.3633328848944\n",
      "    rl_1: 47.099115630694506\n",
      "  time_since_restore: 12771.988285303116\n",
      "  time_this_iter_s: 22.801112413406372\n",
      "  time_total_s: 12771.988285303116\n",
      "  timestamp: 1550893377\n",
      "  timesteps_since_restore: 5500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5500000\n",
      "  training_iteration: 550\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12771 s, 550 iter, 5500000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 112.4\n",
      "  episode_reward_max: 235.36522346192356\n",
      "  episode_reward_mean: 108.83555228249547\n",
      "  episode_reward_min: -182.29809173540863\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 46910\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.01\n",
      "    load_time_ms: 2.301\n",
      "    num_steps_sampled: 5510000\n",
      "    num_steps_trained: 5510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2566131055355072\n",
      "      kl: 0.010737719014286995\n",
      "      policy_loss: 0.003382725641131401\n",
      "      total_loss: 179.1046905517578\n",
      "      vf_explained_var: 0.9398377537727356\n",
      "      vf_loss: 179.101318359375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38690775632858276\n",
      "      kl: 0.01745704375207424\n",
      "      policy_loss: 0.0009420032729394734\n",
      "      total_loss: 172.08607482910156\n",
      "      vf_explained_var: 0.928800642490387\n",
      "      vf_loss: 172.08511352539062\n",
      "    sample_time_ms: 19917.514\n",
      "    update_time_ms: 7.244\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.23167147415277\n",
      "    rl_1: 45.6038808083427\n",
      "  time_since_restore: 12794.709301710129\n",
      "  time_this_iter_s: 22.72101640701294\n",
      "  time_total_s: 12794.709301710129\n",
      "  timestamp: 1550893400\n",
      "  timesteps_since_restore: 5510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5510000\n",
      "  training_iteration: 551\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12794 s, 551 iter, 5510000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-43-43\n",
      "  done: false\n",
      "  episode_len_mean: 116.01\n",
      "  episode_reward_max: 236.61029988675128\n",
      "  episode_reward_mean: 108.24685916507013\n",
      "  episode_reward_min: -182.29809173540863\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 46996\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.618\n",
      "    load_time_ms: 2.292\n",
      "    num_steps_sampled: 5520000\n",
      "    num_steps_trained: 5520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.371262788772583\n",
      "      kl: 0.026226148009300232\n",
      "      policy_loss: -0.0004872503341175616\n",
      "      total_loss: 175.40943908691406\n",
      "      vf_explained_var: 0.9342451095581055\n",
      "      vf_loss: 175.40994262695312\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.459747850894928\n",
      "      kl: 0.017822610214352608\n",
      "      policy_loss: -0.002024985384196043\n",
      "      total_loss: 166.18948364257812\n",
      "      vf_explained_var: 0.9180229306221008\n",
      "      vf_loss: 166.19151306152344\n",
      "    sample_time_ms: 19914.164\n",
      "    update_time_ms: 7.269\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.19292924885351\n",
      "    rl_1: 45.05392991621663\n",
      "  time_since_restore: 12817.725757598877\n",
      "  time_this_iter_s: 23.01645588874817\n",
      "  time_total_s: 12817.725757598877\n",
      "  timestamp: 1550893423\n",
      "  timesteps_since_restore: 5520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5520000\n",
      "  training_iteration: 552\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12817 s, 552 iter, 5520000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-44-06\n",
      "  done: false\n",
      "  episode_len_mean: 108.53\n",
      "  episode_reward_max: 229.91768178243586\n",
      "  episode_reward_mean: 122.469041495888\n",
      "  episode_reward_min: -168.32875765620082\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 47088\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.924\n",
      "    load_time_ms: 2.271\n",
      "    num_steps_sampled: 5530000\n",
      "    num_steps_trained: 5530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4851585924625397\n",
      "      kl: 0.019647741690278053\n",
      "      policy_loss: 0.0035854154266417027\n",
      "      total_loss: 143.6162872314453\n",
      "      vf_explained_var: 0.9427800178527832\n",
      "      vf_loss: 143.6127166748047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5251852869987488\n",
      "      kl: 0.020134098827838898\n",
      "      policy_loss: 0.0033806513529270887\n",
      "      total_loss: 130.06922912597656\n",
      "      vf_explained_var: 0.9341769814491272\n",
      "      vf_loss: 130.0658416748047\n",
      "    sample_time_ms: 19866.99\n",
      "    update_time_ms: 6.854\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.7397999996197\n",
      "    rl_1: 52.72924149626829\n",
      "  time_since_restore: 12840.688940763474\n",
      "  time_this_iter_s: 22.963183164596558\n",
      "  time_total_s: 12840.688940763474\n",
      "  timestamp: 1550893446\n",
      "  timesteps_since_restore: 5530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5530000\n",
      "  training_iteration: 553\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12840 s, 553 iter, 5530000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-44-29\n",
      "  done: false\n",
      "  episode_len_mean: 120.18\n",
      "  episode_reward_max: 239.47161674126494\n",
      "  episode_reward_mean: 132.28818878152765\n",
      "  episode_reward_min: -168.32875765620082\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 47168\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3053.899\n",
      "    load_time_ms: 2.167\n",
      "    num_steps_sampled: 5540000\n",
      "    num_steps_trained: 5540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3138512372970581\n",
      "      kl: 0.02043996751308441\n",
      "      policy_loss: 0.0030071530491113663\n",
      "      total_loss: 106.39947509765625\n",
      "      vf_explained_var: 0.943777322769165\n",
      "      vf_loss: 106.39646911621094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3840183913707733\n",
      "      kl: 0.019584299996495247\n",
      "      policy_loss: 0.007769247051328421\n",
      "      total_loss: 89.97354888916016\n",
      "      vf_explained_var: 0.9376665949821472\n",
      "      vf_loss: 89.96576690673828\n",
      "    sample_time_ms: 19878.41\n",
      "    update_time_ms: 6.792\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.94503277185652\n",
      "    rl_1: 56.34315600967113\n",
      "  time_since_restore: 12863.680119276047\n",
      "  time_this_iter_s: 22.991178512573242\n",
      "  time_total_s: 12863.680119276047\n",
      "  timestamp: 1550893469\n",
      "  timesteps_since_restore: 5540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5540000\n",
      "  training_iteration: 554\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12863 s, 554 iter, 5540000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-44-52\n",
      "  done: false\n",
      "  episode_len_mean: 120.09\n",
      "  episode_reward_max: 233.8766286624379\n",
      "  episode_reward_mean: 111.65495966612092\n",
      "  episode_reward_min: -174.79762506383986\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 47251\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3053.101\n",
      "    load_time_ms: 2.168\n",
      "    num_steps_sampled: 5550000\n",
      "    num_steps_trained: 5550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.22328154742717743\n",
      "      kl: 0.016987768933176994\n",
      "      policy_loss: 0.0023704026825726032\n",
      "      total_loss: 186.12014770507812\n",
      "      vf_explained_var: 0.9309545755386353\n",
      "      vf_loss: 186.11778259277344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.32344621419906616\n",
      "      kl: 0.02383214607834816\n",
      "      policy_loss: 0.003213299671187997\n",
      "      total_loss: 172.3464813232422\n",
      "      vf_explained_var: 0.9151923060417175\n",
      "      vf_loss: 172.34326171875\n",
      "    sample_time_ms: 19888.782\n",
      "    update_time_ms: 6.733\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.03791957391932\n",
      "    rl_1: 47.61704009220158\n",
      "  time_since_restore: 12886.454159498215\n",
      "  time_this_iter_s: 22.77404022216797\n",
      "  time_total_s: 12886.454159498215\n",
      "  timestamp: 1550893492\n",
      "  timesteps_since_restore: 5550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5550000\n",
      "  training_iteration: 555\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12886 s, 555 iter, 5550000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-45-15\n",
      "  done: false\n",
      "  episode_len_mean: 114.82\n",
      "  episode_reward_max: 240.72697712388032\n",
      "  episode_reward_mean: 130.00763140651335\n",
      "  episode_reward_min: -177.8600002590532\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 47338\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3049.987\n",
      "    load_time_ms: 2.154\n",
      "    num_steps_sampled: 5560000\n",
      "    num_steps_trained: 5560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.36219289898872375\n",
      "      kl: 0.019410070031881332\n",
      "      policy_loss: -0.0008398099453188479\n",
      "      total_loss: 168.02603149414062\n",
      "      vf_explained_var: 0.9232760667800903\n",
      "      vf_loss: 168.02687072753906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.46458083391189575\n",
      "      kl: 0.019594207406044006\n",
      "      policy_loss: 0.0019821610767394304\n",
      "      total_loss: 157.20205688476562\n",
      "      vf_explained_var: 0.9127758741378784\n",
      "      vf_loss: 157.20008850097656\n",
      "    sample_time_ms: 19895.58\n",
      "    update_time_ms: 6.967\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 73.5801578432354\n",
      "    rl_1: 56.427473563277935\n",
      "  time_since_restore: 12909.08140707016\n",
      "  time_this_iter_s: 22.62724757194519\n",
      "  time_total_s: 12909.08140707016\n",
      "  timestamp: 1550893515\n",
      "  timesteps_since_restore: 5560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5560000\n",
      "  training_iteration: 556\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12909 s, 556 iter, 5560000 ts, 130 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-45-38\n",
      "  done: false\n",
      "  episode_len_mean: 111.96\n",
      "  episode_reward_max: 232.99546007299753\n",
      "  episode_reward_mean: 103.80891435284478\n",
      "  episode_reward_min: -171.4205745399139\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 47429\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.362\n",
      "    load_time_ms: 2.182\n",
      "    num_steps_sampled: 5570000\n",
      "    num_steps_trained: 5570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.36457160115242004\n",
      "      kl: 0.030934780836105347\n",
      "      policy_loss: 0.0037491016555577517\n",
      "      total_loss: 132.3525390625\n",
      "      vf_explained_var: 0.9561697244644165\n",
      "      vf_loss: 132.3488006591797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4500318765640259\n",
      "      kl: 0.016725782305002213\n",
      "      policy_loss: 0.0016760405851528049\n",
      "      total_loss: 126.98857879638672\n",
      "      vf_explained_var: 0.9474608302116394\n",
      "      vf_loss: 126.9869155883789\n",
      "    sample_time_ms: 19844.311\n",
      "    update_time_ms: 6.732\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.17322382750771\n",
      "    rl_1: 43.635690525337075\n",
      "  time_since_restore: 12932.16492819786\n",
      "  time_this_iter_s: 23.083521127700806\n",
      "  time_total_s: 12932.16492819786\n",
      "  timestamp: 1550893538\n",
      "  timesteps_since_restore: 5570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5570000\n",
      "  training_iteration: 557\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12932 s, 557 iter, 5570000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-46-01\n",
      "  done: false\n",
      "  episode_len_mean: 117.35\n",
      "  episode_reward_max: 233.6960421794443\n",
      "  episode_reward_mean: 121.08787951077538\n",
      "  episode_reward_min: -171.4205745399139\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 47513\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.593\n",
      "    load_time_ms: 2.21\n",
      "    num_steps_sampled: 5580000\n",
      "    num_steps_trained: 5580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2638486325740814\n",
      "      kl: 0.019899163395166397\n",
      "      policy_loss: 0.0013964815298095345\n",
      "      total_loss: 156.81979370117188\n",
      "      vf_explained_var: 0.9312823414802551\n",
      "      vf_loss: 156.8184051513672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3851946294307709\n",
      "      kl: 0.036422356963157654\n",
      "      policy_loss: 0.005319683812558651\n",
      "      total_loss: 150.5736541748047\n",
      "      vf_explained_var: 0.9181947708129883\n",
      "      vf_loss: 150.56832885742188\n",
      "    sample_time_ms: 19824.452\n",
      "    update_time_ms: 6.755\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.79868521226236\n",
      "    rl_1: 52.28919429851306\n",
      "  time_since_restore: 12955.097716093063\n",
      "  time_this_iter_s: 22.932787895202637\n",
      "  time_total_s: 12955.097716093063\n",
      "  timestamp: 1550893561\n",
      "  timesteps_since_restore: 5580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5580000\n",
      "  training_iteration: 558\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12955 s, 558 iter, 5580000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-46-24\n",
      "  done: false\n",
      "  episode_len_mean: 107.15\n",
      "  episode_reward_max: 233.6960421794443\n",
      "  episode_reward_mean: 107.66056440147035\n",
      "  episode_reward_min: -172.92863236195265\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 47604\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.151\n",
      "    load_time_ms: 2.248\n",
      "    num_steps_sampled: 5590000\n",
      "    num_steps_trained: 5590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43568915128707886\n",
      "      kl: 0.016586601734161377\n",
      "      policy_loss: 0.0008538265828974545\n",
      "      total_loss: 152.04730224609375\n",
      "      vf_explained_var: 0.9464637637138367\n",
      "      vf_loss: 152.04641723632812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.522179126739502\n",
      "      kl: 0.030466007068753242\n",
      "      policy_loss: 0.005262073129415512\n",
      "      total_loss: 139.47055053710938\n",
      "      vf_explained_var: 0.9358526468276978\n",
      "      vf_loss: 139.46527099609375\n",
      "    sample_time_ms: 19818.311\n",
      "    update_time_ms: 6.688\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.15703426064182\n",
      "    rl_1: 45.503530140828545\n",
      "  time_since_restore: 12978.373101472855\n",
      "  time_this_iter_s: 23.27538537979126\n",
      "  time_total_s: 12978.373101472855\n",
      "  timestamp: 1550893584\n",
      "  timesteps_since_restore: 5590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5590000\n",
      "  training_iteration: 559\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 12978 s, 559 iter, 5590000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-46-47\n",
      "  done: false\n",
      "  episode_len_mean: 108.9\n",
      "  episode_reward_max: 232.94127340954876\n",
      "  episode_reward_mean: 83.711278706137\n",
      "  episode_reward_min: -172.95284647373694\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 47699\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.521\n",
      "    load_time_ms: 2.332\n",
      "    num_steps_sampled: 5600000\n",
      "    num_steps_trained: 5600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42682257294654846\n",
      "      kl: 0.039202138781547546\n",
      "      policy_loss: 0.006221523508429527\n",
      "      total_loss: 232.00433349609375\n",
      "      vf_explained_var: 0.9298365712165833\n",
      "      vf_loss: 231.9981231689453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47700509428977966\n",
      "      kl: 0.018022550269961357\n",
      "      policy_loss: 0.000323696993291378\n",
      "      total_loss: 196.8527069091797\n",
      "      vf_explained_var: 0.9211844205856323\n",
      "      vf_loss: 196.85238647460938\n",
      "    sample_time_ms: 19848.076\n",
      "    update_time_ms: 6.82\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.99633945615404\n",
      "    rl_1: 34.71493924998297\n",
      "  time_since_restore: 13001.447793483734\n",
      "  time_this_iter_s: 23.074692010879517\n",
      "  time_total_s: 13001.447793483734\n",
      "  timestamp: 1550893607\n",
      "  timesteps_since_restore: 5600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5600000\n",
      "  training_iteration: 560\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13001 s, 560 iter, 5600000 ts, 83.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-47-10\n",
      "  done: false\n",
      "  episode_len_mean: 117.08\n",
      "  episode_reward_max: 236.81988705954555\n",
      "  episode_reward_mean: 127.92932029805968\n",
      "  episode_reward_min: -162.15253181234053\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 47783\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.803\n",
      "    load_time_ms: 2.42\n",
      "    num_steps_sampled: 5610000\n",
      "    num_steps_trained: 5610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.31625381112098694\n",
      "      kl: 0.018587538972496986\n",
      "      policy_loss: 0.004005790688097477\n",
      "      total_loss: 86.59645080566406\n",
      "      vf_explained_var: 0.9553561210632324\n",
      "      vf_loss: 86.59246063232422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3858000636100769\n",
      "      kl: 0.012593141756951809\n",
      "      policy_loss: 0.0008446883875876665\n",
      "      total_loss: 76.33650207519531\n",
      "      vf_explained_var: 0.94614177942276\n",
      "      vf_loss: 76.33564758300781\n",
      "    sample_time_ms: 19886.806\n",
      "    update_time_ms: 7.004\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.7055237302384\n",
      "    rl_1: 53.22379656782127\n",
      "  time_since_restore: 13024.562693834305\n",
      "  time_this_iter_s: 23.11490035057068\n",
      "  time_total_s: 13024.562693834305\n",
      "  timestamp: 1550893630\n",
      "  timesteps_since_restore: 5610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5610000\n",
      "  training_iteration: 561\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13024 s, 561 iter, 5610000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-47-33\n",
      "  done: false\n",
      "  episode_len_mean: 107.0\n",
      "  episode_reward_max: 234.6294740365076\n",
      "  episode_reward_mean: 114.07916524408199\n",
      "  episode_reward_min: -169.77405545254823\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 47876\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.518\n",
      "    load_time_ms: 2.429\n",
      "    num_steps_sampled: 5620000\n",
      "    num_steps_trained: 5620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4851720631122589\n",
      "      kl: 0.02092042565345764\n",
      "      policy_loss: 0.0037033939734101295\n",
      "      total_loss: 160.6323699951172\n",
      "      vf_explained_var: 0.9452105760574341\n",
      "      vf_loss: 160.628662109375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5104318857192993\n",
      "      kl: 0.01657889224588871\n",
      "      policy_loss: 0.003737029852345586\n",
      "      total_loss: 149.6934051513672\n",
      "      vf_explained_var: 0.9326747059822083\n",
      "      vf_loss: 149.68968200683594\n",
      "    sample_time_ms: 19892.084\n",
      "    update_time_ms: 6.93\n",
      "  iterations_since_restore: 562\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.62630847288781\n",
      "    rl_1: 48.4528567711942\n",
      "  time_since_restore: 13047.600198745728\n",
      "  time_this_iter_s: 23.03750491142273\n",
      "  time_total_s: 13047.600198745728\n",
      "  timestamp: 1550893653\n",
      "  timesteps_since_restore: 5620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5620000\n",
      "  training_iteration: 562\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13047 s, 562 iter, 5620000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-47-57\n",
      "  done: false\n",
      "  episode_len_mean: 113.99\n",
      "  episode_reward_max: 235.1383748258656\n",
      "  episode_reward_mean: 134.2690882770166\n",
      "  episode_reward_min: -170.90105105579119\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 47963\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.67\n",
      "    load_time_ms: 2.403\n",
      "    num_steps_sampled: 5630000\n",
      "    num_steps_trained: 5630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42899635434150696\n",
      "      kl: 0.021459702402353287\n",
      "      policy_loss: 0.0014217125717550516\n",
      "      total_loss: 132.6170654296875\n",
      "      vf_explained_var: 0.9408522248268127\n",
      "      vf_loss: 132.61561584472656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.483571320772171\n",
      "      kl: 0.018967267125844955\n",
      "      policy_loss: 0.0007124523399397731\n",
      "      total_loss: 127.50779724121094\n",
      "      vf_explained_var: 0.9281461834907532\n",
      "      vf_loss: 127.50707244873047\n",
      "    sample_time_ms: 19956.495\n",
      "    update_time_ms: 7.046\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.27801447917135\n",
      "    rl_1: 57.99107379784527\n",
      "  time_since_restore: 13071.270616054535\n",
      "  time_this_iter_s: 23.670417308807373\n",
      "  time_total_s: 13071.270616054535\n",
      "  timestamp: 1550893677\n",
      "  timesteps_since_restore: 5630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5630000\n",
      "  training_iteration: 563\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13071 s, 563 iter, 5630000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-48-21\n",
      "  done: false\n",
      "  episode_len_mean: 119.27\n",
      "  episode_reward_max: 225.9862551464782\n",
      "  episode_reward_mean: 127.08938282028716\n",
      "  episode_reward_min: -168.5406358098869\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 48046\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.652\n",
      "    load_time_ms: 2.458\n",
      "    num_steps_sampled: 5640000\n",
      "    num_steps_trained: 5640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3063097596168518\n",
      "      kl: 0.023632241412997246\n",
      "      policy_loss: 0.0019389352528378367\n",
      "      total_loss: 131.75718688964844\n",
      "      vf_explained_var: 0.9358130097389221\n",
      "      vf_loss: 131.7552490234375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3849388062953949\n",
      "      kl: 0.022450381889939308\n",
      "      policy_loss: 0.007991551421582699\n",
      "      total_loss: 117.51556396484375\n",
      "      vf_explained_var: 0.9270079135894775\n",
      "      vf_loss: 117.50757598876953\n",
      "    sample_time_ms: 20029.376\n",
      "    update_time_ms: 7.101\n",
      "  iterations_since_restore: 564\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 73.43620946834372\n",
      "    rl_1: 53.65317335194343\n",
      "  time_since_restore: 13094.98222541809\n",
      "  time_this_iter_s: 23.711609363555908\n",
      "  time_total_s: 13094.98222541809\n",
      "  timestamp: 1550893701\n",
      "  timesteps_since_restore: 5640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5640000\n",
      "  training_iteration: 564\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13094 s, 564 iter, 5640000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-48-44\n",
      "  done: false\n",
      "  episode_len_mean: 108.34\n",
      "  episode_reward_max: 235.3953002573247\n",
      "  episode_reward_mean: 117.33117129158386\n",
      "  episode_reward_min: -167.39605279529079\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 48139\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.437\n",
      "    load_time_ms: 2.465\n",
      "    num_steps_sampled: 5650000\n",
      "    num_steps_trained: 5650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5340510606765747\n",
      "      kl: 0.02336244285106659\n",
      "      policy_loss: 0.00384919298812747\n",
      "      total_loss: 131.79917907714844\n",
      "      vf_explained_var: 0.9538410902023315\n",
      "      vf_loss: 131.79530334472656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5467192530632019\n",
      "      kl: 0.03426208347082138\n",
      "      policy_loss: 0.008393417112529278\n",
      "      total_loss: 113.40557098388672\n",
      "      vf_explained_var: 0.9483144879341125\n",
      "      vf_loss: 113.39717102050781\n",
      "    sample_time_ms: 20112.579\n",
      "    update_time_ms: 7.367\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.19770950249587\n",
      "    rl_1: 49.13346178908799\n",
      "  time_since_restore: 13118.579537153244\n",
      "  time_this_iter_s: 23.5973117351532\n",
      "  time_total_s: 13118.579537153244\n",
      "  timestamp: 1550893724\n",
      "  timesteps_since_restore: 5650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5650000\n",
      "  training_iteration: 565\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13118 s, 565 iter, 5650000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-49-08\n",
      "  done: false\n",
      "  episode_len_mean: 111.56\n",
      "  episode_reward_max: 233.7749535541632\n",
      "  episode_reward_mean: 121.54879823513251\n",
      "  episode_reward_min: -178.89042902625766\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 48228\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.129\n",
      "    load_time_ms: 2.563\n",
      "    num_steps_sampled: 5660000\n",
      "    num_steps_trained: 5660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44675156474113464\n",
      "      kl: 0.029976053163409233\n",
      "      policy_loss: 0.006128548178821802\n",
      "      total_loss: 144.0061798095703\n",
      "      vf_explained_var: 0.948585033416748\n",
      "      vf_loss: 144.00003051757812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5207921266555786\n",
      "      kl: 0.021019354462623596\n",
      "      policy_loss: 0.00023164913000073284\n",
      "      total_loss: 125.30994415283203\n",
      "      vf_explained_var: 0.9426469802856445\n",
      "      vf_loss: 125.30970764160156\n",
      "    sample_time_ms: 20179.779\n",
      "    update_time_ms: 7.296\n",
      "  iterations_since_restore: 566\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.78902532896899\n",
      "    rl_1: 51.75977290616353\n",
      "  time_since_restore: 13142.066894054413\n",
      "  time_this_iter_s: 23.487356901168823\n",
      "  time_total_s: 13142.066894054413\n",
      "  timestamp: 1550893748\n",
      "  timesteps_since_restore: 5660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5660000\n",
      "  training_iteration: 566\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13142 s, 566 iter, 5660000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-49-31\n",
      "  done: false\n",
      "  episode_len_mean: 116.74\n",
      "  episode_reward_max: 234.2314942858522\n",
      "  episode_reward_mean: 135.9461806648485\n",
      "  episode_reward_min: -161.68958139291107\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 48313\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.305\n",
      "    load_time_ms: 2.561\n",
      "    num_steps_sampled: 5670000\n",
      "    num_steps_trained: 5670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.341702938079834\n",
      "      kl: 0.029974136501550674\n",
      "      policy_loss: 0.007348515093326569\n",
      "      total_loss: 109.2762451171875\n",
      "      vf_explained_var: 0.9460800290107727\n",
      "      vf_loss: 109.26890563964844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44132521748542786\n",
      "      kl: 0.023641271516680717\n",
      "      policy_loss: -0.0006226924015209079\n",
      "      total_loss: 93.95111846923828\n",
      "      vf_explained_var: 0.9444571137428284\n",
      "      vf_loss: 93.95172882080078\n",
      "    sample_time_ms: 20199.177\n",
      "    update_time_ms: 7.508\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.75592313056758\n",
      "    rl_1: 59.1902575342809\n",
      "  time_since_restore: 13165.159703731537\n",
      "  time_this_iter_s: 23.092809677124023\n",
      "  time_total_s: 13165.159703731537\n",
      "  timestamp: 1550893771\n",
      "  timesteps_since_restore: 5670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5670000\n",
      "  training_iteration: 567\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13165 s, 567 iter, 5670000 ts, 136 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-49-55\n",
      "  done: false\n",
      "  episode_len_mean: 108.34\n",
      "  episode_reward_max: 228.82029607325944\n",
      "  episode_reward_mean: 116.272877389738\n",
      "  episode_reward_min: -172.709736370634\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 48406\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.432\n",
      "    load_time_ms: 2.547\n",
      "    num_steps_sampled: 5680000\n",
      "    num_steps_trained: 5680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5146352052688599\n",
      "      kl: 0.018446091562509537\n",
      "      policy_loss: 0.0024404064752161503\n",
      "      total_loss: 145.89791870117188\n",
      "      vf_explained_var: 0.948165774345398\n",
      "      vf_loss: 145.89547729492188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5600106120109558\n",
      "      kl: 0.022071579471230507\n",
      "      policy_loss: 0.0035910778678953648\n",
      "      total_loss: 134.13809204101562\n",
      "      vf_explained_var: 0.9387086629867554\n",
      "      vf_loss: 134.13449096679688\n",
      "    sample_time_ms: 20246.375\n",
      "    update_time_ms: 7.441\n",
      "  iterations_since_restore: 568\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.21599542576361\n",
      "    rl_1: 50.056881963974426\n",
      "  time_since_restore: 13188.575076580048\n",
      "  time_this_iter_s: 23.415372848510742\n",
      "  time_total_s: 13188.575076580048\n",
      "  timestamp: 1550893795\n",
      "  timesteps_since_restore: 5680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5680000\n",
      "  training_iteration: 568\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13188 s, 568 iter, 5680000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-50-18\n",
      "  done: false\n",
      "  episode_len_mean: 109.37\n",
      "  episode_reward_max: 226.14839637891816\n",
      "  episode_reward_mean: 122.67017929550073\n",
      "  episode_reward_min: -173.7979749338299\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 48496\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.51\n",
      "    load_time_ms: 2.541\n",
      "    num_steps_sampled: 5690000\n",
      "    num_steps_trained: 5690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4598384201526642\n",
      "      kl: 0.02867121808230877\n",
      "      policy_loss: 0.006233956664800644\n",
      "      total_loss: 137.02963256835938\n",
      "      vf_explained_var: 0.9459971189498901\n",
      "      vf_loss: 137.0233917236328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5297623872756958\n",
      "      kl: 0.025954781100153923\n",
      "      policy_loss: 0.0071246931329369545\n",
      "      total_loss: 124.63287353515625\n",
      "      vf_explained_var: 0.9369314908981323\n",
      "      vf_loss: 124.62574768066406\n",
      "    sample_time_ms: 20232.939\n",
      "    update_time_ms: 7.737\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.03766682615287\n",
      "    rl_1: 51.63251246934786\n",
      "  time_since_restore: 13211.709296226501\n",
      "  time_this_iter_s: 23.134219646453857\n",
      "  time_total_s: 13211.709296226501\n",
      "  timestamp: 1550893818\n",
      "  timesteps_since_restore: 5690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5690000\n",
      "  training_iteration: 569\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13211 s, 569 iter, 5690000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-50-41\n",
      "  done: false\n",
      "  episode_len_mean: 120.83\n",
      "  episode_reward_max: 224.8123159231975\n",
      "  episode_reward_mean: 131.81912988259762\n",
      "  episode_reward_min: -177.133352537744\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 48577\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.935\n",
      "    load_time_ms: 2.543\n",
      "    num_steps_sampled: 5700000\n",
      "    num_steps_trained: 5700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2849991023540497\n",
      "      kl: 0.0181417278945446\n",
      "      policy_loss: 0.0003548514796420932\n",
      "      total_loss: 113.90583801269531\n",
      "      vf_explained_var: 0.9415855407714844\n",
      "      vf_loss: 113.90550231933594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38574156165122986\n",
      "      kl: 0.017881544306874275\n",
      "      policy_loss: 0.003049441147595644\n",
      "      total_loss: 90.90208435058594\n",
      "      vf_explained_var: 0.9414970278739929\n",
      "      vf_loss: 90.8990478515625\n",
      "    sample_time_ms: 20265.2\n",
      "    update_time_ms: 7.426\n",
      "  iterations_since_restore: 570\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.28863022996791\n",
      "    rl_1: 54.53049965262972\n",
      "  time_since_restore: 13235.097389221191\n",
      "  time_this_iter_s: 23.38809299468994\n",
      "  time_total_s: 13235.097389221191\n",
      "  timestamp: 1550893841\n",
      "  timesteps_since_restore: 5700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5700000\n",
      "  training_iteration: 570\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13235 s, 570 iter, 5700000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-51-04\n",
      "  done: false\n",
      "  episode_len_mean: 112.42\n",
      "  episode_reward_max: 228.8613116380704\n",
      "  episode_reward_mean: 124.31662019737352\n",
      "  episode_reward_min: -177.133352537744\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 48667\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.962\n",
      "    load_time_ms: 2.459\n",
      "    num_steps_sampled: 5710000\n",
      "    num_steps_trained: 5710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.423525869846344\n",
      "      kl: 0.022086597979068756\n",
      "      policy_loss: 0.004624329507350922\n",
      "      total_loss: 139.66104125976562\n",
      "      vf_explained_var: 0.9358332753181458\n",
      "      vf_loss: 139.65640258789062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5156930088996887\n",
      "      kl: 0.018007393926382065\n",
      "      policy_loss: 0.002388706896454096\n",
      "      total_loss: 115.60538482666016\n",
      "      vf_explained_var: 0.932389497756958\n",
      "      vf_loss: 115.60298919677734\n",
      "    sample_time_ms: 20241.358\n",
      "    update_time_ms: 7.448\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.9179663061007\n",
      "    rl_1: 52.39865389127282\n",
      "  time_since_restore: 13257.942006111145\n",
      "  time_this_iter_s: 22.844616889953613\n",
      "  time_total_s: 13257.942006111145\n",
      "  timestamp: 1550893864\n",
      "  timesteps_since_restore: 5710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5710000\n",
      "  training_iteration: 571\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13257 s, 571 iter, 5710000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-51-27\n",
      "  done: false\n",
      "  episode_len_mean: 122.22\n",
      "  episode_reward_max: 239.2631267957723\n",
      "  episode_reward_mean: 132.06098312668894\n",
      "  episode_reward_min: -169.03255564245507\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 48748\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.999\n",
      "    load_time_ms: 2.487\n",
      "    num_steps_sampled: 5720000\n",
      "    num_steps_trained: 5720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.29591527581214905\n",
      "      kl: 0.04381614178419113\n",
      "      policy_loss: 0.012075388804078102\n",
      "      total_loss: 98.47708129882812\n",
      "      vf_explained_var: 0.9476298689842224\n",
      "      vf_loss: 98.46499633789062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4011382758617401\n",
      "      kl: 0.03716059401631355\n",
      "      policy_loss: 0.011096538975834846\n",
      "      total_loss: 91.73101806640625\n",
      "      vf_explained_var: 0.9369770884513855\n",
      "      vf_loss: 91.71992492675781\n",
      "    sample_time_ms: 20227.107\n",
      "    update_time_ms: 7.432\n",
      "  iterations_since_restore: 572\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.12659832393375\n",
      "    rl_1: 54.9343848027552\n",
      "  time_since_restore: 13280.835801124573\n",
      "  time_this_iter_s: 22.893795013427734\n",
      "  time_total_s: 13280.835801124573\n",
      "  timestamp: 1550893887\n",
      "  timesteps_since_restore: 5720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5720000\n",
      "  training_iteration: 572\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13280 s, 572 iter, 5720000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-51-50\n",
      "  done: false\n",
      "  episode_len_mean: 120.54\n",
      "  episode_reward_max: 233.8825234853687\n",
      "  episode_reward_mean: 144.67017988012657\n",
      "  episode_reward_min: -141.40837324582313\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 48828\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.45\n",
      "    load_time_ms: 2.554\n",
      "    num_steps_sampled: 5730000\n",
      "    num_steps_trained: 5730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2831867039203644\n",
      "      kl: 0.020186973735690117\n",
      "      policy_loss: 0.005654199980199337\n",
      "      total_loss: 124.94054412841797\n",
      "      vf_explained_var: 0.9286555647850037\n",
      "      vf_loss: 124.93489837646484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4005434215068817\n",
      "      kl: 0.02346593327820301\n",
      "      policy_loss: -0.00040057062869891524\n",
      "      total_loss: 105.21086120605469\n",
      "      vf_explained_var: 0.927902102470398\n",
      "      vf_loss: 105.21126556396484\n",
      "    sample_time_ms: 20141.303\n",
      "    update_time_ms: 7.386\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.98090153724361\n",
      "    rl_1: 62.689278342882965\n",
      "  time_since_restore: 13303.613931417465\n",
      "  time_this_iter_s: 22.778130292892456\n",
      "  time_total_s: 13303.613931417465\n",
      "  timestamp: 1550893910\n",
      "  timesteps_since_restore: 5730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5730000\n",
      "  training_iteration: 573\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13303 s, 573 iter, 5730000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-52-13\n",
      "  done: false\n",
      "  episode_len_mean: 125.47\n",
      "  episode_reward_max: 225.9334049093541\n",
      "  episode_reward_mean: 142.7345502364248\n",
      "  episode_reward_min: -141.75498160571473\n",
      "  episodes_this_iter: 80\n",
      "  episodes_total: 48908\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.673\n",
      "    load_time_ms: 2.581\n",
      "    num_steps_sampled: 5740000\n",
      "    num_steps_trained: 5740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.20220625400543213\n",
      "      kl: 0.015609163790941238\n",
      "      policy_loss: -0.0010113778989762068\n",
      "      total_loss: 94.03697967529297\n",
      "      vf_explained_var: 0.9419338703155518\n",
      "      vf_loss: 94.0379867553711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.28975945711135864\n",
      "      kl: 0.03406321257352829\n",
      "      policy_loss: -0.0018463734304532409\n",
      "      total_loss: 80.50952911376953\n",
      "      vf_explained_var: 0.9398033022880554\n",
      "      vf_loss: 80.5113525390625\n",
      "    sample_time_ms: 20055.143\n",
      "    update_time_ms: 7.287\n",
      "  iterations_since_restore: 574\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.78955950333162\n",
      "    rl_1: 60.944990733093185\n",
      "  time_since_restore: 13326.523284196854\n",
      "  time_this_iter_s: 22.909352779388428\n",
      "  time_total_s: 13326.523284196854\n",
      "  timestamp: 1550893933\n",
      "  timesteps_since_restore: 5740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5740000\n",
      "  training_iteration: 574\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13326 s, 574 iter, 5740000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-52-36\n",
      "  done: false\n",
      "  episode_len_mean: 115.78\n",
      "  episode_reward_max: 224.68931583629816\n",
      "  episode_reward_mean: 141.55977903612362\n",
      "  episode_reward_min: -168.43974116603985\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 48995\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.504\n",
      "    load_time_ms: 2.528\n",
      "    num_steps_sampled: 5750000\n",
      "    num_steps_trained: 5750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.31110310554504395\n",
      "      kl: 0.024517517536878586\n",
      "      policy_loss: 0.004354142118245363\n",
      "      total_loss: 105.65654754638672\n",
      "      vf_explained_var: 0.943961501121521\n",
      "      vf_loss: 105.65218353271484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38496914505958557\n",
      "      kl: 0.015753719955682755\n",
      "      policy_loss: 0.0025436372961848974\n",
      "      total_loss: 88.93488311767578\n",
      "      vf_explained_var: 0.9407444596290588\n",
      "      vf_loss: 88.93233489990234\n",
      "    sample_time_ms: 19966.195\n",
      "    update_time_ms: 6.981\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.74974558034674\n",
      "    rl_1: 62.810033455776875\n",
      "  time_since_restore: 13349.216000795364\n",
      "  time_this_iter_s: 22.692716598510742\n",
      "  time_total_s: 13349.216000795364\n",
      "  timestamp: 1550893956\n",
      "  timesteps_since_restore: 5750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5750000\n",
      "  training_iteration: 575\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13349 s, 575 iter, 5750000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 120.98\n",
      "  episode_reward_max: 232.6148658160899\n",
      "  episode_reward_mean: 119.04057611311775\n",
      "  episode_reward_min: -169.481847662276\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 49076\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3055.468\n",
      "    load_time_ms: 2.592\n",
      "    num_steps_sampled: 5760000\n",
      "    num_steps_trained: 5760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.21369914710521698\n",
      "      kl: 0.02961522713303566\n",
      "      policy_loss: 0.009613607078790665\n",
      "      total_loss: 114.64754486083984\n",
      "      vf_explained_var: 0.948024570941925\n",
      "      vf_loss: 114.63792419433594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3231115937232971\n",
      "      kl: 0.012221496552228928\n",
      "      policy_loss: -0.003174911718815565\n",
      "      total_loss: 102.7337417602539\n",
      "      vf_explained_var: 0.9396725296974182\n",
      "      vf_loss: 102.7369155883789\n",
      "    sample_time_ms: 19923.894\n",
      "    update_time_ms: 6.988\n",
      "  iterations_since_restore: 576\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.17054982457414\n",
      "    rl_1: 49.87002628854362\n",
      "  time_since_restore: 13372.131847858429\n",
      "  time_this_iter_s: 22.915847063064575\n",
      "  time_total_s: 13372.131847858429\n",
      "  timestamp: 1550893979\n",
      "  timesteps_since_restore: 5760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5760000\n",
      "  training_iteration: 576\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13372 s, 576 iter, 5760000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-53-22\n",
      "  done: false\n",
      "  episode_len_mean: 112.65\n",
      "  episode_reward_max: 232.6148658160899\n",
      "  episode_reward_mean: 147.03777302287511\n",
      "  episode_reward_min: -162.53776027279383\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 49163\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3051.417\n",
      "    load_time_ms: 2.58\n",
      "    num_steps_sampled: 5770000\n",
      "    num_steps_trained: 5770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.510502815246582\n",
      "      kl: 0.022699862718582153\n",
      "      policy_loss: 0.0032738291192799807\n",
      "      total_loss: 98.43270874023438\n",
      "      vf_explained_var: 0.9448835849761963\n",
      "      vf_loss: 98.42943572998047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.579230785369873\n",
      "      kl: 0.02076040208339691\n",
      "      policy_loss: 0.0022453879937529564\n",
      "      total_loss: 86.47207641601562\n",
      "      vf_explained_var: 0.9353546500205994\n",
      "      vf_loss: 86.46981811523438\n",
      "    sample_time_ms: 19957.544\n",
      "    update_time_ms: 7.215\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.10035118719281\n",
      "    rl_1: 63.93742183568233\n",
      "  time_since_restore: 13395.5226354599\n",
      "  time_this_iter_s: 23.390787601470947\n",
      "  time_total_s: 13395.5226354599\n",
      "  timestamp: 1550894002\n",
      "  timesteps_since_restore: 5770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5770000\n",
      "  training_iteration: 577\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13395 s, 577 iter, 5770000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-53-46\n",
      "  done: false\n",
      "  episode_len_mean: 113.6\n",
      "  episode_reward_max: 231.05036033895058\n",
      "  episode_reward_mean: 120.50388844542637\n",
      "  episode_reward_min: -171.7952558896069\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 49252\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3051.262\n",
      "    load_time_ms: 2.651\n",
      "    num_steps_sampled: 5780000\n",
      "    num_steps_trained: 5780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.34770625829696655\n",
      "      kl: 0.013988305814564228\n",
      "      policy_loss: 0.002203188370913267\n",
      "      total_loss: 123.75919342041016\n",
      "      vf_explained_var: 0.9522044062614441\n",
      "      vf_loss: 123.7569580078125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43663331866264343\n",
      "      kl: 0.024411147460341454\n",
      "      policy_loss: 0.004788605961948633\n",
      "      total_loss: 106.78791046142578\n",
      "      vf_explained_var: 0.9508692622184753\n",
      "      vf_loss: 106.78311920166016\n",
      "    sample_time_ms: 19977.612\n",
      "    update_time_ms: 7.384\n",
      "  iterations_since_restore: 578\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.73481717703974\n",
      "    rl_1: 52.76907126838663\n",
      "  time_since_restore: 13419.140433549881\n",
      "  time_this_iter_s: 23.61779808998108\n",
      "  time_total_s: 13419.140433549881\n",
      "  timestamp: 1550894026\n",
      "  timesteps_since_restore: 5780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5780000\n",
      "  training_iteration: 578\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13419 s, 578 iter, 5780000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-54-09\n",
      "  done: false\n",
      "  episode_len_mean: 116.01\n",
      "  episode_reward_max: 235.42517078527706\n",
      "  episode_reward_mean: 131.63150727375364\n",
      "  episode_reward_min: -168.03448782394156\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 49336\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.802\n",
      "    load_time_ms: 2.631\n",
      "    num_steps_sampled: 5790000\n",
      "    num_steps_trained: 5790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3690502941608429\n",
      "      kl: 0.08635149896144867\n",
      "      policy_loss: 0.017540842294692993\n",
      "      total_loss: 79.55326080322266\n",
      "      vf_explained_var: 0.9614493250846863\n",
      "      vf_loss: 79.53570556640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.45939087867736816\n",
      "      kl: 0.018830256536602974\n",
      "      policy_loss: -0.00037173047894611955\n",
      "      total_loss: 70.11612701416016\n",
      "      vf_explained_var: 0.9579290747642517\n",
      "      vf_loss: 70.11650085449219\n",
      "    sample_time_ms: 19980.284\n",
      "    update_time_ms: 7.056\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.8905768914625\n",
      "    rl_1: 56.7409303822911\n",
      "  time_since_restore: 13442.493758440018\n",
      "  time_this_iter_s: 23.35332489013672\n",
      "  time_total_s: 13442.493758440018\n",
      "  timestamp: 1550894049\n",
      "  timesteps_since_restore: 5790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5790000\n",
      "  training_iteration: 579\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13442 s, 579 iter, 5790000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-54-32\n",
      "  done: false\n",
      "  episode_len_mean: 113.02\n",
      "  episode_reward_max: 235.72415679863911\n",
      "  episode_reward_mean: 120.03265547437482\n",
      "  episode_reward_min: -171.40026471920623\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 49426\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.194\n",
      "    load_time_ms: 2.633\n",
      "    num_steps_sampled: 5800000\n",
      "    num_steps_trained: 5800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42176172137260437\n",
      "      kl: 0.022374499589204788\n",
      "      policy_loss: 0.003659907029941678\n",
      "      total_loss: 124.09337615966797\n",
      "      vf_explained_var: 0.9558629989624023\n",
      "      vf_loss: 124.0897216796875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5160385370254517\n",
      "      kl: 0.01743254065513611\n",
      "      policy_loss: 0.003560621291399002\n",
      "      total_loss: 105.71070861816406\n",
      "      vf_explained_var: 0.9500644207000732\n",
      "      vf_loss: 105.7071533203125\n",
      "    sample_time_ms: 19953.785\n",
      "    update_time_ms: 7.255\n",
      "  iterations_since_restore: 580\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.10980612142379\n",
      "    rl_1: 50.922849352951026\n",
      "  time_since_restore: 13465.613114356995\n",
      "  time_this_iter_s: 23.11935591697693\n",
      "  time_total_s: 13465.613114356995\n",
      "  timestamp: 1550894072\n",
      "  timesteps_since_restore: 5800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5800000\n",
      "  training_iteration: 580\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13465 s, 580 iter, 5800000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-54-55\n",
      "  done: false\n",
      "  episode_len_mean: 108.42\n",
      "  episode_reward_max: 228.53586789782818\n",
      "  episode_reward_mean: 140.39646367977514\n",
      "  episode_reward_min: -170.70615839812427\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 49518\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.037\n",
      "    load_time_ms: 2.662\n",
      "    num_steps_sampled: 5810000\n",
      "    num_steps_trained: 5810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5245698094367981\n",
      "      kl: 0.02954827807843685\n",
      "      policy_loss: 0.00965634174644947\n",
      "      total_loss: 111.61017608642578\n",
      "      vf_explained_var: 0.9456272721290588\n",
      "      vf_loss: 111.60050201416016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5753106474876404\n",
      "      kl: 0.023323245346546173\n",
      "      policy_loss: 0.007416790816932917\n",
      "      total_loss: 106.15337371826172\n",
      "      vf_explained_var: 0.9301971793174744\n",
      "      vf_loss: 106.1459732055664\n",
      "    sample_time_ms: 19992.334\n",
      "    update_time_ms: 7.089\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.8395423716033\n",
      "    rl_1: 61.556921308171816\n",
      "  time_since_restore: 13488.832342147827\n",
      "  time_this_iter_s: 23.21922779083252\n",
      "  time_total_s: 13488.832342147827\n",
      "  timestamp: 1550894095\n",
      "  timesteps_since_restore: 5810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5810000\n",
      "  training_iteration: 581\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13488 s, 581 iter, 5810000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-55-18\n",
      "  done: false\n",
      "  episode_len_mean: 110.84\n",
      "  episode_reward_max: 234.6673171159172\n",
      "  episode_reward_mean: 120.96368157264837\n",
      "  episode_reward_min: -173.04000114191982\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 49607\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.318\n",
      "    load_time_ms: 2.63\n",
      "    num_steps_sampled: 5820000\n",
      "    num_steps_trained: 5820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4115894138813019\n",
      "      kl: 0.026412110775709152\n",
      "      policy_loss: 0.003212509909644723\n",
      "      total_loss: 117.6133041381836\n",
      "      vf_explained_var: 0.9526711702346802\n",
      "      vf_loss: 117.61007690429688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49277418851852417\n",
      "      kl: 0.019594671204686165\n",
      "      policy_loss: -0.0010260662529617548\n",
      "      total_loss: 102.78617095947266\n",
      "      vf_explained_var: 0.9508386254310608\n",
      "      vf_loss: 102.78720092773438\n",
      "    sample_time_ms: 19987.32\n",
      "    update_time_ms: 7.248\n",
      "  iterations_since_restore: 582\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.77638085664206\n",
      "    rl_1: 52.18730071600629\n",
      "  time_since_restore: 13511.687455415726\n",
      "  time_this_iter_s: 22.85511326789856\n",
      "  time_total_s: 13511.687455415726\n",
      "  timestamp: 1550894118\n",
      "  timesteps_since_restore: 5820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5820000\n",
      "  training_iteration: 582\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13511 s, 582 iter, 5820000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-55-42\n",
      "  done: false\n",
      "  episode_len_mean: 114.65\n",
      "  episode_reward_max: 230.58807392308483\n",
      "  episode_reward_mean: 128.82847653427402\n",
      "  episode_reward_min: -169.65580140166708\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 49693\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.496\n",
      "    load_time_ms: 2.68\n",
      "    num_steps_sampled: 5830000\n",
      "    num_steps_trained: 5830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.40368619561195374\n",
      "      kl: 0.013800299726426601\n",
      "      policy_loss: 0.0033174853306263685\n",
      "      total_loss: 90.01870727539062\n",
      "      vf_explained_var: 0.96470046043396\n",
      "      vf_loss: 90.015380859375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5057429075241089\n",
      "      kl: 0.018460817635059357\n",
      "      policy_loss: 0.002720241667702794\n",
      "      total_loss: 76.2532958984375\n",
      "      vf_explained_var: 0.9612987041473389\n",
      "      vf_loss: 76.25056457519531\n",
      "    sample_time_ms: 20060.794\n",
      "    update_time_ms: 7.402\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.5136233319805\n",
      "    rl_1: 54.314853202293534\n",
      "  time_since_restore: 13535.224990606308\n",
      "  time_this_iter_s: 23.537535190582275\n",
      "  time_total_s: 13535.224990606308\n",
      "  timestamp: 1550894142\n",
      "  timesteps_since_restore: 5830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5830000\n",
      "  training_iteration: 583\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13535 s, 583 iter, 5830000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-56-05\n",
      "  done: false\n",
      "  episode_len_mean: 117.1\n",
      "  episode_reward_max: 236.13773832226056\n",
      "  episode_reward_mean: 128.93531109666756\n",
      "  episode_reward_min: -162.47447971429813\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 49777\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.173\n",
      "    load_time_ms: 2.593\n",
      "    num_steps_sampled: 5840000\n",
      "    num_steps_trained: 5840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3160329759120941\n",
      "      kl: 0.017388908192515373\n",
      "      policy_loss: 0.002321313600987196\n",
      "      total_loss: 109.71068572998047\n",
      "      vf_explained_var: 0.9477396011352539\n",
      "      vf_loss: 109.70838165283203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42790108919143677\n",
      "      kl: 0.023795638233423233\n",
      "      policy_loss: 0.002332486677914858\n",
      "      total_loss: 93.6021957397461\n",
      "      vf_explained_var: 0.9415839910507202\n",
      "      vf_loss: 93.59983825683594\n",
      "    sample_time_ms: 20121.587\n",
      "    update_time_ms: 7.849\n",
      "  iterations_since_restore: 584\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.44565027789231\n",
      "    rl_1: 52.48966081877523\n",
      "  time_since_restore: 13558.690879583359\n",
      "  time_this_iter_s: 23.46588897705078\n",
      "  time_total_s: 13558.690879583359\n",
      "  timestamp: 1550894165\n",
      "  timesteps_since_restore: 5840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5840000\n",
      "  training_iteration: 584\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13558 s, 584 iter, 5840000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-56-29\n",
      "  done: false\n",
      "  episode_len_mean: 117.16\n",
      "  episode_reward_max: 235.6975536520177\n",
      "  episode_reward_mean: 120.82492323383345\n",
      "  episode_reward_min: -173.34814915311193\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 49863\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.311\n",
      "    load_time_ms: 2.576\n",
      "    num_steps_sampled: 5850000\n",
      "    num_steps_trained: 5850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3788833022117615\n",
      "      kl: 0.02025512605905533\n",
      "      policy_loss: 0.003451559692621231\n",
      "      total_loss: 105.51429748535156\n",
      "      vf_explained_var: 0.9579586982727051\n",
      "      vf_loss: 105.51082611083984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5203245878219604\n",
      "      kl: 0.029981622472405434\n",
      "      policy_loss: 0.0015453187515959144\n",
      "      total_loss: 94.38883209228516\n",
      "      vf_explained_var: 0.9461780190467834\n",
      "      vf_loss: 94.38728332519531\n",
      "    sample_time_ms: 20152.204\n",
      "    update_time_ms: 7.911\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.02835853595964\n",
      "    rl_1: 48.79656469787382\n",
      "  time_since_restore: 13581.702512979507\n",
      "  time_this_iter_s: 23.01163339614868\n",
      "  time_total_s: 13581.702512979507\n",
      "  timestamp: 1550894189\n",
      "  timesteps_since_restore: 5850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5850000\n",
      "  training_iteration: 585\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13581 s, 585 iter, 5850000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-56-52\n",
      "  done: false\n",
      "  episode_len_mean: 110.75\n",
      "  episode_reward_max: 231.52133634095298\n",
      "  episode_reward_mean: 120.45928667549242\n",
      "  episode_reward_min: -180.61585325279623\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 49954\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.657\n",
      "    load_time_ms: 2.454\n",
      "    num_steps_sampled: 5860000\n",
      "    num_steps_trained: 5860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4984073042869568\n",
      "      kl: 0.029135318472981453\n",
      "      policy_loss: 0.00795335415750742\n",
      "      total_loss: 139.42929077148438\n",
      "      vf_explained_var: 0.9434117078781128\n",
      "      vf_loss: 139.42132568359375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5663416981697083\n",
      "      kl: 0.027633056044578552\n",
      "      policy_loss: 0.0004885050584562123\n",
      "      total_loss: 123.52833557128906\n",
      "      vf_explained_var: 0.9339892864227295\n",
      "      vf_loss: 123.5278549194336\n",
      "    sample_time_ms: 20181.956\n",
      "    update_time_ms: 7.798\n",
      "  iterations_since_restore: 586\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.06948765517231\n",
      "    rl_1: 50.38979902032014\n",
      "  time_since_restore: 13605.05504155159\n",
      "  time_this_iter_s: 23.35252857208252\n",
      "  time_total_s: 13605.05504155159\n",
      "  timestamp: 1550894212\n",
      "  timesteps_since_restore: 5860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5860000\n",
      "  training_iteration: 586\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13605 s, 586 iter, 5860000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-57-15\n",
      "  done: false\n",
      "  episode_len_mean: 113.57\n",
      "  episode_reward_max: 233.10362520119432\n",
      "  episode_reward_mean: 131.04321001530803\n",
      "  episode_reward_min: -169.83202500796477\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 50042\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.134\n",
      "    load_time_ms: 2.44\n",
      "    num_steps_sampled: 5870000\n",
      "    num_steps_trained: 5870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4124985337257385\n",
      "      kl: 0.035281695425510406\n",
      "      policy_loss: 0.00802483968436718\n",
      "      total_loss: 110.74391174316406\n",
      "      vf_explained_var: 0.9527254104614258\n",
      "      vf_loss: 110.73590087890625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49966028332710266\n",
      "      kl: 0.019535118713974953\n",
      "      policy_loss: 0.001680888468399644\n",
      "      total_loss: 89.60177612304688\n",
      "      vf_explained_var: 0.9517694115638733\n",
      "      vf_loss: 89.60010528564453\n",
      "    sample_time_ms: 20142.432\n",
      "    update_time_ms: 7.566\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.895062272706\n",
      "    rl_1: 55.14814774260201\n",
      "  time_since_restore: 13628.062845468521\n",
      "  time_this_iter_s: 23.007803916931152\n",
      "  time_total_s: 13628.062845468521\n",
      "  timestamp: 1550894235\n",
      "  timesteps_since_restore: 5870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5870000\n",
      "  training_iteration: 587\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13628 s, 587 iter, 5870000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-57-38\n",
      "  done: false\n",
      "  episode_len_mean: 114.46\n",
      "  episode_reward_max: 232.7308533992616\n",
      "  episode_reward_mean: 138.00484918967115\n",
      "  episode_reward_min: -177.95363767720994\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 50128\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3104.324\n",
      "    load_time_ms: 2.396\n",
      "    num_steps_sampled: 5880000\n",
      "    num_steps_trained: 5880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49554434418678284\n",
      "      kl: 0.029499325901269913\n",
      "      policy_loss: 0.009773928672075272\n",
      "      total_loss: 85.63674926757812\n",
      "      vf_explained_var: 0.9571394324302673\n",
      "      vf_loss: 85.62696838378906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5846742391586304\n",
      "      kl: 0.02649880386888981\n",
      "      policy_loss: 0.004215088207274675\n",
      "      total_loss: 78.07503509521484\n",
      "      vf_explained_var: 0.9513572454452515\n",
      "      vf_loss: 78.07081604003906\n",
      "    sample_time_ms: 20055.306\n",
      "    update_time_ms: 7.368\n",
      "  iterations_since_restore: 588\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.42724951108953\n",
      "    rl_1: 58.57759967858162\n",
      "  time_since_restore: 13651.007040977478\n",
      "  time_this_iter_s: 22.94419550895691\n",
      "  time_total_s: 13651.007040977478\n",
      "  timestamp: 1550894258\n",
      "  timesteps_since_restore: 5880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5880000\n",
      "  training_iteration: 588\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13651 s, 588 iter, 5880000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-58-01\n",
      "  done: false\n",
      "  episode_len_mean: 111.33\n",
      "  episode_reward_max: 227.88293249115821\n",
      "  episode_reward_mean: 119.88505304171822\n",
      "  episode_reward_min: -163.4307216622137\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 50219\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.644\n",
      "    load_time_ms: 2.394\n",
      "    num_steps_sampled: 5890000\n",
      "    num_steps_trained: 5890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.46966996788978577\n",
      "      kl: 0.01477350015193224\n",
      "      policy_loss: -0.00015212041034828871\n",
      "      total_loss: 111.10343170166016\n",
      "      vf_explained_var: 0.9607802033424377\n",
      "      vf_loss: 111.10359191894531\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5591329336166382\n",
      "      kl: 0.015330632217228413\n",
      "      policy_loss: 0.0006475755944848061\n",
      "      total_loss: 99.35131072998047\n",
      "      vf_explained_var: 0.953944206237793\n",
      "      vf_loss: 99.35066986083984\n",
      "    sample_time_ms: 20053.175\n",
      "    update_time_ms: 7.387\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.18568405707211\n",
      "    rl_1: 50.69936898464607\n",
      "  time_since_restore: 13674.140946388245\n",
      "  time_this_iter_s: 23.1339054107666\n",
      "  time_total_s: 13674.140946388245\n",
      "  timestamp: 1550894281\n",
      "  timesteps_since_restore: 5890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5890000\n",
      "  training_iteration: 589\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13674 s, 589 iter, 5890000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-58-24\n",
      "  done: false\n",
      "  episode_len_mean: 117.19\n",
      "  episode_reward_max: 233.2989359684513\n",
      "  episode_reward_mean: 138.3216186430367\n",
      "  episode_reward_min: -163.4307216622137\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 50305\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.156\n",
      "    load_time_ms: 2.318\n",
      "    num_steps_sampled: 5900000\n",
      "    num_steps_trained: 5900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3701843321323395\n",
      "      kl: 7.037219047546387\n",
      "      policy_loss: 0.05876084044575691\n",
      "      total_loss: 100.23038482666016\n",
      "      vf_explained_var: 0.9491928219795227\n",
      "      vf_loss: 100.171630859375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.503298819065094\n",
      "      kl: 0.020065579563379288\n",
      "      policy_loss: 0.002357564168050885\n",
      "      total_loss: 87.43574523925781\n",
      "      vf_explained_var: 0.9464248418807983\n",
      "      vf_loss: 87.43338775634766\n",
      "    sample_time_ms: 20040.307\n",
      "    update_time_ms: 7.265\n",
      "  iterations_since_restore: 590\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.26529372045114\n",
      "    rl_1: 59.05632492258551\n",
      "  time_since_restore: 13697.165670394897\n",
      "  time_this_iter_s: 23.024724006652832\n",
      "  time_total_s: 13697.165670394897\n",
      "  timestamp: 1550894304\n",
      "  timesteps_since_restore: 5900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5900000\n",
      "  training_iteration: 590\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13697 s, 590 iter, 5900000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-58-47\n",
      "  done: false\n",
      "  episode_len_mean: 108.84\n",
      "  episode_reward_max: 234.47003015507974\n",
      "  episode_reward_mean: 121.2285064514616\n",
      "  episode_reward_min: -163.59816671391138\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 50397\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.405\n",
      "    load_time_ms: 2.296\n",
      "    num_steps_sampled: 5910000\n",
      "    num_steps_trained: 5910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5477961301803589\n",
      "      kl: 0.026479853317141533\n",
      "      policy_loss: 0.006932626944035292\n",
      "      total_loss: 129.92959594726562\n",
      "      vf_explained_var: 0.9520036578178406\n",
      "      vf_loss: 129.9226837158203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6547617316246033\n",
      "      kl: 0.03005560301244259\n",
      "      policy_loss: 0.009613104164600372\n",
      "      total_loss: 116.74932098388672\n",
      "      vf_explained_var: 0.9433910846710205\n",
      "      vf_loss: 116.7397232055664\n",
      "    sample_time_ms: 19997.173\n",
      "    update_time_ms: 7.997\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.81028587070132\n",
      "    rl_1: 51.41822058076027\n",
      "  time_since_restore: 13719.941967964172\n",
      "  time_this_iter_s: 22.776297569274902\n",
      "  time_total_s: 13719.941967964172\n",
      "  timestamp: 1550894327\n",
      "  timesteps_since_restore: 5910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5910000\n",
      "  training_iteration: 591\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13719 s, 591 iter, 5910000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-59-10\n",
      "  done: false\n",
      "  episode_len_mean: 117.18\n",
      "  episode_reward_max: 235.50362006978847\n",
      "  episode_reward_mean: 132.7049171765214\n",
      "  episode_reward_min: -163.59816671391138\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 50482\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.646\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 5920000\n",
      "    num_steps_trained: 5920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4194704592227936\n",
      "      kl: 0.021638616919517517\n",
      "      policy_loss: 0.007918047718703747\n",
      "      total_loss: 84.71981048583984\n",
      "      vf_explained_var: 0.9578644037246704\n",
      "      vf_loss: 84.71189880371094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5750426054000854\n",
      "      kl: 0.021737297996878624\n",
      "      policy_loss: 0.0010458340402692556\n",
      "      total_loss: 76.24850463867188\n",
      "      vf_explained_var: 0.9506747126579285\n",
      "      vf_loss: 76.24747467041016\n",
      "    sample_time_ms: 20026.641\n",
      "    update_time_ms: 7.929\n",
      "  iterations_since_restore: 592\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.17270298504327\n",
      "    rl_1: 55.532214191478126\n",
      "  time_since_restore: 13743.0866355896\n",
      "  time_this_iter_s: 23.144667625427246\n",
      "  time_total_s: 13743.0866355896\n",
      "  timestamp: 1550894350\n",
      "  timesteps_since_restore: 5920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5920000\n",
      "  training_iteration: 592\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13743 s, 592 iter, 5920000 ts, 133 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-59-33\n",
      "  done: false\n",
      "  episode_len_mean: 116.08\n",
      "  episode_reward_max: 233.02908482363497\n",
      "  episode_reward_mean: 106.88200279840311\n",
      "  episode_reward_min: -153.23346976406282\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 50567\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.282\n",
      "    load_time_ms: 2.274\n",
      "    num_steps_sampled: 5930000\n",
      "    num_steps_trained: 5930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3158988654613495\n",
      "      kl: 0.06192875653505325\n",
      "      policy_loss: 0.014977063983678818\n",
      "      total_loss: 149.85934448242188\n",
      "      vf_explained_var: 0.9405891299247742\n",
      "      vf_loss: 149.84437561035156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.460396945476532\n",
      "      kl: 0.033736225217580795\n",
      "      policy_loss: 0.016557548195123672\n",
      "      total_loss: 137.32415771484375\n",
      "      vf_explained_var: 0.9296028017997742\n",
      "      vf_loss: 137.30758666992188\n",
      "    sample_time_ms: 19977.965\n",
      "    update_time_ms: 7.804\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.90551762531992\n",
      "    rl_1: 45.976485173083184\n",
      "  time_since_restore: 13766.118280649185\n",
      "  time_this_iter_s: 23.03164505958557\n",
      "  time_total_s: 13766.118280649185\n",
      "  timestamp: 1550894373\n",
      "  timesteps_since_restore: 5930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5930000\n",
      "  training_iteration: 593\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13766 s, 593 iter, 5930000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_04-59-56\n",
      "  done: false\n",
      "  episode_len_mean: 115.11\n",
      "  episode_reward_max: 227.64542819800485\n",
      "  episode_reward_mean: 145.46848425505632\n",
      "  episode_reward_min: -146.0673334554169\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 50650\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.621\n",
      "    load_time_ms: 2.308\n",
      "    num_steps_sampled: 5940000\n",
      "    num_steps_trained: 5940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.33034589886665344\n",
      "      kl: 0.041762858629226685\n",
      "      policy_loss: 0.009022622369229794\n",
      "      total_loss: 89.42642211914062\n",
      "      vf_explained_var: 0.9433311820030212\n",
      "      vf_loss: 89.41738891601562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48073285818099976\n",
      "      kl: 0.024343250319361687\n",
      "      policy_loss: 0.000836677965708077\n",
      "      total_loss: 81.26939392089844\n",
      "      vf_explained_var: 0.9365285038948059\n",
      "      vf_loss: 81.26856231689453\n",
      "    sample_time_ms: 19872.386\n",
      "    update_time_ms: 7.345\n",
      "  iterations_since_restore: 594\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.83414769913112\n",
      "    rl_1: 63.63433655592521\n",
      "  time_since_restore: 13788.521385192871\n",
      "  time_this_iter_s: 22.403104543685913\n",
      "  time_total_s: 13788.521385192871\n",
      "  timestamp: 1550894396\n",
      "  timesteps_since_restore: 5940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5940000\n",
      "  training_iteration: 594\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13788 s, 594 iter, 5940000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-00-19\n",
      "  done: false\n",
      "  episode_len_mean: 119.81\n",
      "  episode_reward_max: 229.86928404643277\n",
      "  episode_reward_mean: 127.16477898319336\n",
      "  episode_reward_min: -155.0382981906651\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 50736\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.855\n",
      "    load_time_ms: 2.32\n",
      "    num_steps_sampled: 5950000\n",
      "    num_steps_trained: 5950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3455013930797577\n",
      "      kl: 38.615482330322266\n",
      "      policy_loss: 0.11033327132463455\n",
      "      total_loss: 117.76717376708984\n",
      "      vf_explained_var: 0.9469085335731506\n",
      "      vf_loss: 117.6568603515625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4215645492076874\n",
      "      kl: 0.23438793420791626\n",
      "      policy_loss: 0.028576575219631195\n",
      "      total_loss: 105.9571533203125\n",
      "      vf_explained_var: 0.9389298558235168\n",
      "      vf_loss: 105.9285888671875\n",
      "    sample_time_ms: 19872.94\n",
      "    update_time_ms: 7.293\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.00788534346646\n",
      "    rl_1: 53.1568936397269\n",
      "  time_since_restore: 13811.550629377365\n",
      "  time_this_iter_s: 23.02924418449402\n",
      "  time_total_s: 13811.550629377365\n",
      "  timestamp: 1550894419\n",
      "  timesteps_since_restore: 5950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5950000\n",
      "  training_iteration: 595\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13811 s, 595 iter, 5950000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-00-42\n",
      "  done: false\n",
      "  episode_len_mean: 120.1\n",
      "  episode_reward_max: 229.86928404643277\n",
      "  episode_reward_mean: 163.83654638746816\n",
      "  episode_reward_min: -173.70130181246793\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 50822\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.114\n",
      "    load_time_ms: 2.301\n",
      "    num_steps_sampled: 5960000\n",
      "    num_steps_trained: 5960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.41805505752563477\n",
      "      kl: 0.014166905544698238\n",
      "      policy_loss: 0.0038867814000695944\n",
      "      total_loss: 82.43745422363281\n",
      "      vf_explained_var: 0.9381324648857117\n",
      "      vf_loss: 82.43357849121094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5479786992073059\n",
      "      kl: 0.018527446314692497\n",
      "      policy_loss: 0.00021606798691209406\n",
      "      total_loss: 76.38799285888672\n",
      "      vf_explained_var: 0.9307644963264465\n",
      "      vf_loss: 76.38777160644531\n",
      "    sample_time_ms: 19823.053\n",
      "    update_time_ms: 7.282\n",
      "  iterations_since_restore: 596\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.4023022288517\n",
      "    rl_1: 71.43424415861647\n",
      "  time_since_restore: 13834.247026205063\n",
      "  time_this_iter_s: 22.696396827697754\n",
      "  time_total_s: 13834.247026205063\n",
      "  timestamp: 1550894442\n",
      "  timesteps_since_restore: 5960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5960000\n",
      "  training_iteration: 596\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13834 s, 596 iter, 5960000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-01-05\n",
      "  done: false\n",
      "  episode_len_mean: 107.31\n",
      "  episode_reward_max: 233.2037015045602\n",
      "  episode_reward_mean: 146.14874455451852\n",
      "  episode_reward_min: -171.26825187629834\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 50915\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.351\n",
      "    load_time_ms: 2.317\n",
      "    num_steps_sampled: 5970000\n",
      "    num_steps_trained: 5970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5061214566230774\n",
      "      kl: 0.017616908997297287\n",
      "      policy_loss: 0.0007297116098925471\n",
      "      total_loss: 101.61053466796875\n",
      "      vf_explained_var: 0.9466337561607361\n",
      "      vf_loss: 101.60980224609375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5890774726867676\n",
      "      kl: 0.019304493442177773\n",
      "      policy_loss: 0.005301118828356266\n",
      "      total_loss: 89.28046417236328\n",
      "      vf_explained_var: 0.9409136772155762\n",
      "      vf_loss: 89.27517700195312\n",
      "    sample_time_ms: 19840.14\n",
      "    update_time_ms: 7.224\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.50411437928435\n",
      "    rl_1: 63.64463017523415\n",
      "  time_since_restore: 13857.435185909271\n",
      "  time_this_iter_s: 23.188159704208374\n",
      "  time_total_s: 13857.435185909271\n",
      "  timestamp: 1550894465\n",
      "  timesteps_since_restore: 5970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5970000\n",
      "  training_iteration: 597\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13857 s, 597 iter, 5970000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-01-28\n",
      "  done: false\n",
      "  episode_len_mean: 115.77\n",
      "  episode_reward_max: 233.82404989461077\n",
      "  episode_reward_mean: 150.7800580652359\n",
      "  episode_reward_min: -167.5203128522607\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 51000\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3050.401\n",
      "    load_time_ms: 2.26\n",
      "    num_steps_sampled: 5980000\n",
      "    num_steps_trained: 5980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.33709919452667236\n",
      "      kl: 12.271023750305176\n",
      "      policy_loss: 0.12488993257284164\n",
      "      total_loss: 79.61243438720703\n",
      "      vf_explained_var: 0.941489577293396\n",
      "      vf_loss: 79.48753356933594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49522703886032104\n",
      "      kl: 0.01910906471312046\n",
      "      policy_loss: -0.00014260612078942358\n",
      "      total_loss: 69.3903579711914\n",
      "      vf_explained_var: 0.943587601184845\n",
      "      vf_loss: 69.39049530029297\n",
      "    sample_time_ms: 19880.173\n",
      "    update_time_ms: 7.274\n",
      "  iterations_since_restore: 598\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.23126605089614\n",
      "    rl_1: 64.54879201433978\n",
      "  time_since_restore: 13880.579069375992\n",
      "  time_this_iter_s: 23.14388346672058\n",
      "  time_total_s: 13880.579069375992\n",
      "  timestamp: 1550894488\n",
      "  timesteps_since_restore: 5980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5980000\n",
      "  training_iteration: 598\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13880 s, 598 iter, 5980000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-01-51\n",
      "  done: false\n",
      "  episode_len_mean: 116.73\n",
      "  episode_reward_max: 227.26361635755865\n",
      "  episode_reward_mean: 143.68885981449534\n",
      "  episode_reward_min: -158.17452394402892\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 51086\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3048.806\n",
      "    load_time_ms: 2.3\n",
      "    num_steps_sampled: 5990000\n",
      "    num_steps_trained: 5990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2893238663673401\n",
      "      kl: 0.020369993522763252\n",
      "      policy_loss: 0.0031124029774218798\n",
      "      total_loss: 76.38401794433594\n",
      "      vf_explained_var: 0.9510273337364197\n",
      "      vf_loss: 76.38091278076172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4324779510498047\n",
      "      kl: 0.028247589245438576\n",
      "      policy_loss: 0.01067692693322897\n",
      "      total_loss: 72.78731536865234\n",
      "      vf_explained_var: 0.9449260234832764\n",
      "      vf_loss: 72.7766342163086\n",
      "    sample_time_ms: 19897.35\n",
      "    update_time_ms: 7.185\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.63046971963551\n",
      "    rl_1: 62.05839009485983\n",
      "  time_since_restore: 13903.867793798447\n",
      "  time_this_iter_s: 23.288724422454834\n",
      "  time_total_s: 13903.867793798447\n",
      "  timestamp: 1550894511\n",
      "  timesteps_since_restore: 5990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 5990000\n",
      "  training_iteration: 599\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13903 s, 599 iter, 5990000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-02-14\n",
      "  done: false\n",
      "  episode_len_mean: 121.98\n",
      "  episode_reward_max: 234.70666815138674\n",
      "  episode_reward_mean: 152.12878092788551\n",
      "  episode_reward_min: -159.8819615487842\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 51169\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3060.642\n",
      "    load_time_ms: 2.281\n",
      "    num_steps_sampled: 6000000\n",
      "    num_steps_trained: 6000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3624298870563507\n",
      "      kl: 0.012687752023339272\n",
      "      policy_loss: 0.0020263323094695807\n",
      "      total_loss: 73.63719177246094\n",
      "      vf_explained_var: 0.9503923058509827\n",
      "      vf_loss: 73.63516235351562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4999106824398041\n",
      "      kl: 0.01955069787800312\n",
      "      policy_loss: -0.002413703128695488\n",
      "      total_loss: 71.14366912841797\n",
      "      vf_explained_var: 0.9456483125686646\n",
      "      vf_loss: 71.14608001708984\n",
      "    sample_time_ms: 19892.924\n",
      "    update_time_ms: 7.499\n",
      "  iterations_since_restore: 600\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.38458943815951\n",
      "    rl_1: 66.744191489726\n",
      "  time_since_restore: 13926.967156648636\n",
      "  time_this_iter_s: 23.09936285018921\n",
      "  time_total_s: 13926.967156648636\n",
      "  timestamp: 1550894534\n",
      "  timesteps_since_restore: 6000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6000000\n",
      "  training_iteration: 600\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13926 s, 600 iter, 6000000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-02-37\n",
      "  done: false\n",
      "  episode_len_mean: 115.69\n",
      "  episode_reward_max: 236.8229809899969\n",
      "  episode_reward_mean: 146.5111978439992\n",
      "  episode_reward_min: -172.75807202623255\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 51256\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.017\n",
      "    load_time_ms: 2.297\n",
      "    num_steps_sampled: 6010000\n",
      "    num_steps_trained: 6010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.45823219418525696\n",
      "      kl: 0.059742577373981476\n",
      "      policy_loss: 0.01715518720448017\n",
      "      total_loss: 66.53619384765625\n",
      "      vf_explained_var: 0.9633482694625854\n",
      "      vf_loss: 66.51902770996094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5697274208068848\n",
      "      kl: 0.013729500584304333\n",
      "      policy_loss: 0.0023960061371326447\n",
      "      total_loss: 59.54533386230469\n",
      "      vf_explained_var: 0.9610527157783508\n",
      "      vf_loss: 59.54294204711914\n",
      "    sample_time_ms: 19889.742\n",
      "    update_time_ms: 7.089\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.53735135510384\n",
      "    rl_1: 62.97384648889539\n",
      "  time_since_restore: 13949.950902938843\n",
      "  time_this_iter_s: 22.98374629020691\n",
      "  time_total_s: 13949.950902938843\n",
      "  timestamp: 1550894557\n",
      "  timesteps_since_restore: 6010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6010000\n",
      "  training_iteration: 601\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13949 s, 601 iter, 6010000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-03-01\n",
      "  done: false\n",
      "  episode_len_mean: 109.85\n",
      "  episode_reward_max: 224.69995943446952\n",
      "  episode_reward_mean: 147.84687604880807\n",
      "  episode_reward_min: -166.83056293902564\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 51347\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.109\n",
      "    load_time_ms: 2.255\n",
      "    num_steps_sampled: 6020000\n",
      "    num_steps_trained: 6020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4324473738670349\n",
      "      kl: 1.592772126197815\n",
      "      policy_loss: 0.04227690026164055\n",
      "      total_loss: 88.32388305664062\n",
      "      vf_explained_var: 0.9491872787475586\n",
      "      vf_loss: 88.2816162109375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5732725262641907\n",
      "      kl: 0.02135816030204296\n",
      "      policy_loss: 0.005818211939185858\n",
      "      total_loss: 81.5479736328125\n",
      "      vf_explained_var: 0.940009593963623\n",
      "      vf_loss: 81.54215240478516\n",
      "    sample_time_ms: 19887.781\n",
      "    update_time_ms: 7.158\n",
      "  iterations_since_restore: 602\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.63986514265744\n",
      "    rl_1: 65.20701090615063\n",
      "  time_since_restore: 13973.087989330292\n",
      "  time_this_iter_s: 23.137086391448975\n",
      "  time_total_s: 13973.087989330292\n",
      "  timestamp: 1550894581\n",
      "  timesteps_since_restore: 6020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6020000\n",
      "  training_iteration: 602\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13973 s, 602 iter, 6020000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-03-24\n",
      "  done: false\n",
      "  episode_len_mean: 113.0\n",
      "  episode_reward_max: 222.34211397920686\n",
      "  episode_reward_mean: 145.80002509788534\n",
      "  episode_reward_min: -153.3885960524829\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 51433\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.678\n",
      "    load_time_ms: 2.355\n",
      "    num_steps_sampled: 6030000\n",
      "    num_steps_trained: 6030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3855297267436981\n",
      "      kl: 0.012269275262951851\n",
      "      policy_loss: -2.4116001441143453e-05\n",
      "      total_loss: 85.52110290527344\n",
      "      vf_explained_var: 0.9499136209487915\n",
      "      vf_loss: 85.5211181640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5273973941802979\n",
      "      kl: 0.026197727769613266\n",
      "      policy_loss: -0.0002455709327477962\n",
      "      total_loss: 75.58364868164062\n",
      "      vf_explained_var: 0.9445888996124268\n",
      "      vf_loss: 75.58390045166016\n",
      "    sample_time_ms: 19897.329\n",
      "    update_time_ms: 6.99\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.99982291503773\n",
      "    rl_1: 62.800202182847606\n",
      "  time_since_restore: 13996.25394654274\n",
      "  time_this_iter_s: 23.16595721244812\n",
      "  time_total_s: 13996.25394654274\n",
      "  timestamp: 1550894604\n",
      "  timesteps_since_restore: 6030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6030000\n",
      "  training_iteration: 603\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 13996 s, 603 iter, 6030000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-03-47\n",
      "  done: false\n",
      "  episode_len_mean: 114.29\n",
      "  episode_reward_max: 227.01812856319455\n",
      "  episode_reward_mean: 141.86230378563985\n",
      "  episode_reward_min: -143.6732232048094\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 51522\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.449\n",
      "    load_time_ms: 2.33\n",
      "    num_steps_sampled: 6040000\n",
      "    num_steps_trained: 6040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4620281755924225\n",
      "      kl: 0.02405576780438423\n",
      "      policy_loss: 0.0018870431231334805\n",
      "      total_loss: 90.01681518554688\n",
      "      vf_explained_var: 0.9536257982254028\n",
      "      vf_loss: 90.01492309570312\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5926080346107483\n",
      "      kl: 0.0190601646900177\n",
      "      policy_loss: 0.00150046416092664\n",
      "      total_loss: 79.81900787353516\n",
      "      vf_explained_var: 0.94625324010849\n",
      "      vf_loss: 79.8175048828125\n",
      "    sample_time_ms: 19989.234\n",
      "    update_time_ms: 7.255\n",
      "  iterations_since_restore: 604\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.36202700445308\n",
      "    rl_1: 59.50027678118674\n",
      "  time_since_restore: 14019.575661182404\n",
      "  time_this_iter_s: 23.321714639663696\n",
      "  time_total_s: 14019.575661182404\n",
      "  timestamp: 1550894627\n",
      "  timesteps_since_restore: 6040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6040000\n",
      "  training_iteration: 604\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14019 s, 604 iter, 6040000 ts, 142 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-04-10\n",
      "  done: false\n",
      "  episode_len_mean: 115.18\n",
      "  episode_reward_max: 227.44621978242574\n",
      "  episode_reward_mean: 134.05863322632266\n",
      "  episode_reward_min: -174.3825915438128\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 51608\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.068\n",
      "    load_time_ms: 2.333\n",
      "    num_steps_sampled: 6050000\n",
      "    num_steps_trained: 6050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3912418782711029\n",
      "      kl: 0.01984558440744877\n",
      "      policy_loss: 0.001806346233934164\n",
      "      total_loss: 81.96258544921875\n",
      "      vf_explained_var: 0.9576713442802429\n",
      "      vf_loss: 81.96077728271484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5434951186180115\n",
      "      kl: 0.02109423279762268\n",
      "      policy_loss: 0.002086163032799959\n",
      "      total_loss: 74.52642059326172\n",
      "      vf_explained_var: 0.9522368311882019\n",
      "      vf_loss: 74.52433013916016\n",
      "    sample_time_ms: 19993.45\n",
      "    update_time_ms: 7.447\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.26248030771693\n",
      "    rl_1: 55.79615291860572\n",
      "  time_since_restore: 14042.643036365509\n",
      "  time_this_iter_s: 23.06737518310547\n",
      "  time_total_s: 14042.643036365509\n",
      "  timestamp: 1550894650\n",
      "  timesteps_since_restore: 6050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6050000\n",
      "  training_iteration: 605\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14042 s, 605 iter, 6050000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-04-34\n",
      "  done: false\n",
      "  episode_len_mean: 110.57\n",
      "  episode_reward_max: 230.54672598844783\n",
      "  episode_reward_mean: 134.24345883896015\n",
      "  episode_reward_min: -174.3825915438128\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 51698\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.406\n",
      "    load_time_ms: 2.441\n",
      "    num_steps_sampled: 6060000\n",
      "    num_steps_trained: 6060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47541213035583496\n",
      "      kl: 0.03951970487833023\n",
      "      policy_loss: 0.007304488681256771\n",
      "      total_loss: 116.76017761230469\n",
      "      vf_explained_var: 0.9456841945648193\n",
      "      vf_loss: 116.75286865234375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5929141640663147\n",
      "      kl: 0.027349747717380524\n",
      "      policy_loss: 0.0025659578386694193\n",
      "      total_loss: 106.9295654296875\n",
      "      vf_explained_var: 0.9390798807144165\n",
      "      vf_loss: 106.92698669433594\n",
      "    sample_time_ms: 20067.489\n",
      "    update_time_ms: 7.45\n",
      "  iterations_since_restore: 606\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.71665728703768\n",
      "    rl_1: 58.52680155192243\n",
      "  time_since_restore: 14066.086931943893\n",
      "  time_this_iter_s: 23.4438955783844\n",
      "  time_total_s: 14066.086931943893\n",
      "  timestamp: 1550894674\n",
      "  timesteps_since_restore: 6060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6060000\n",
      "  training_iteration: 606\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14066 s, 606 iter, 6060000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-04-57\n",
      "  done: false\n",
      "  episode_len_mean: 116.42\n",
      "  episode_reward_max: 233.35554737784605\n",
      "  episode_reward_mean: 148.68538122910203\n",
      "  episode_reward_min: -135.87606602508873\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 51785\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.439\n",
      "    load_time_ms: 2.433\n",
      "    num_steps_sampled: 6070000\n",
      "    num_steps_trained: 6070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43345674872398376\n",
      "      kl: 0.021892789751291275\n",
      "      policy_loss: 0.005740896798670292\n",
      "      total_loss: 66.33351135253906\n",
      "      vf_explained_var: 0.9623649716377258\n",
      "      vf_loss: 66.3277816772461\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5418916940689087\n",
      "      kl: 0.018057242035865784\n",
      "      policy_loss: 0.005084994714707136\n",
      "      total_loss: 60.3376350402832\n",
      "      vf_explained_var: 0.9568609595298767\n",
      "      vf_loss: 60.33254623413086\n",
      "    sample_time_ms: 20050.533\n",
      "    update_time_ms: 7.628\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.24366122771154\n",
      "    rl_1: 63.441720001390486\n",
      "  time_since_restore: 14089.097686767578\n",
      "  time_this_iter_s: 23.010754823684692\n",
      "  time_total_s: 14089.097686767578\n",
      "  timestamp: 1550894697\n",
      "  timesteps_since_restore: 6070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6070000\n",
      "  training_iteration: 607\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14089 s, 607 iter, 6070000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-05-20\n",
      "  done: false\n",
      "  episode_len_mean: 111.99\n",
      "  episode_reward_max: 234.94794810621357\n",
      "  episode_reward_mean: 158.49316317898965\n",
      "  episode_reward_min: -135.69994004781546\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 51874\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.319\n",
      "    load_time_ms: 2.439\n",
      "    num_steps_sampled: 6080000\n",
      "    num_steps_trained: 6080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.46113577485084534\n",
      "      kl: 0.03562235087156296\n",
      "      policy_loss: 0.00972167681902647\n",
      "      total_loss: 84.11277770996094\n",
      "      vf_explained_var: 0.950136125087738\n",
      "      vf_loss: 84.10304260253906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.584830105304718\n",
      "      kl: 0.013145185075700283\n",
      "      policy_loss: 0.0021194692235440016\n",
      "      total_loss: 73.61917877197266\n",
      "      vf_explained_var: 0.9415992498397827\n",
      "      vf_loss: 73.61705780029297\n",
      "    sample_time_ms: 20050.55\n",
      "    update_time_ms: 7.588\n",
      "  iterations_since_restore: 608\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.5677055312387\n",
      "    rl_1: 69.9254576477509\n",
      "  time_since_restore: 14112.200911283493\n",
      "  time_this_iter_s: 23.103224515914917\n",
      "  time_total_s: 14112.200911283493\n",
      "  timestamp: 1550894720\n",
      "  timesteps_since_restore: 6080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6080000\n",
      "  training_iteration: 608\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14112 s, 608 iter, 6080000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-05-43\n",
      "  done: false\n",
      "  episode_len_mean: 111.27\n",
      "  episode_reward_max: 237.22932098769914\n",
      "  episode_reward_mean: 142.84552749365474\n",
      "  episode_reward_min: -166.93109166350516\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 51964\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.547\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 6090000\n",
      "    num_steps_trained: 6090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.46822234988212585\n",
      "      kl: 0.019764525815844536\n",
      "      policy_loss: 0.004564702045172453\n",
      "      total_loss: 76.79912567138672\n",
      "      vf_explained_var: 0.9612376689910889\n",
      "      vf_loss: 76.7945785522461\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.593019962310791\n",
      "      kl: 0.021999593824148178\n",
      "      policy_loss: 0.00702029699459672\n",
      "      total_loss: 72.5367431640625\n",
      "      vf_explained_var: 0.9562765955924988\n",
      "      vf_loss: 72.52971649169922\n",
      "    sample_time_ms: 20029.941\n",
      "    update_time_ms: 8.59\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.13309004120622\n",
      "    rl_1: 61.71243745244854\n",
      "  time_since_restore: 14135.298734426498\n",
      "  time_this_iter_s: 23.09782314300537\n",
      "  time_total_s: 14135.298734426498\n",
      "  timestamp: 1550894743\n",
      "  timesteps_since_restore: 6090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6090000\n",
      "  training_iteration: 609\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14135 s, 609 iter, 6090000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-06-06\n",
      "  done: false\n",
      "  episode_len_mean: 111.05\n",
      "  episode_reward_max: 237.22932098769914\n",
      "  episode_reward_mean: 143.020800094762\n",
      "  episode_reward_min: -147.8087689064676\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 52055\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.679\n",
      "    load_time_ms: 2.521\n",
      "    num_steps_sampled: 6100000\n",
      "    num_steps_trained: 6100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39457860589027405\n",
      "      kl: 0.03037112206220627\n",
      "      policy_loss: 0.002464729594066739\n",
      "      total_loss: 90.06616973876953\n",
      "      vf_explained_var: 0.9481785297393799\n",
      "      vf_loss: 90.06369018554688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.523590087890625\n",
      "      kl: 0.04109245911240578\n",
      "      policy_loss: 0.006143845152109861\n",
      "      total_loss: 84.8685531616211\n",
      "      vf_explained_var: 0.9405466914176941\n",
      "      vf_loss: 84.8624038696289\n",
      "    sample_time_ms: 20022.969\n",
      "    update_time_ms: 8.373\n",
      "  iterations_since_restore: 610\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.56615769589466\n",
      "    rl_1: 63.45464239886734\n",
      "  time_since_restore: 14158.200841665268\n",
      "  time_this_iter_s: 22.90210723876953\n",
      "  time_total_s: 14158.200841665268\n",
      "  timestamp: 1550894766\n",
      "  timesteps_since_restore: 6100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6100000\n",
      "  training_iteration: 610\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14158 s, 610 iter, 6100000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-06-30\n",
      "  done: false\n",
      "  episode_len_mean: 113.99\n",
      "  episode_reward_max: 232.20072406382013\n",
      "  episode_reward_mean: 158.04801773764726\n",
      "  episode_reward_min: -132.78353406420246\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 52141\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3050.295\n",
      "    load_time_ms: 2.526\n",
      "    num_steps_sampled: 6110000\n",
      "    num_steps_trained: 6110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43785330653190613\n",
      "      kl: 0.02903514727950096\n",
      "      policy_loss: 0.006934242323040962\n",
      "      total_loss: 77.96805572509766\n",
      "      vf_explained_var: 0.9494284391403198\n",
      "      vf_loss: 77.96112823486328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5544372797012329\n",
      "      kl: 0.022583065554499626\n",
      "      policy_loss: 0.0038928736466914415\n",
      "      total_loss: 74.34272003173828\n",
      "      vf_explained_var: 0.9397755265235901\n",
      "      vf_loss: 74.33883666992188\n",
      "    sample_time_ms: 20137.112\n",
      "    update_time_ms: 8.286\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.44727298837499\n",
      "    rl_1: 69.60074474927225\n",
      "  time_since_restore: 14182.111543893814\n",
      "  time_this_iter_s: 23.910702228546143\n",
      "  time_total_s: 14182.111543893814\n",
      "  timestamp: 1550894790\n",
      "  timesteps_since_restore: 6110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6110000\n",
      "  training_iteration: 611\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14182 s, 611 iter, 6110000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-06-54\n",
      "  done: false\n",
      "  episode_len_mean: 115.43\n",
      "  episode_reward_max: 233.98881343447107\n",
      "  episode_reward_mean: 139.10194811030556\n",
      "  episode_reward_min: -156.20636742281673\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 52230\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3050.12\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 6120000\n",
      "    num_steps_trained: 6120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3702359199523926\n",
      "      kl: 0.01655152067542076\n",
      "      policy_loss: -0.0002191464154748246\n",
      "      total_loss: 87.87316131591797\n",
      "      vf_explained_var: 0.9556044340133667\n",
      "      vf_loss: 87.8733901977539\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.503743588924408\n",
      "      kl: 0.025367487221956253\n",
      "      policy_loss: 0.0063361213542521\n",
      "      total_loss: 75.01717376708984\n",
      "      vf_explained_var: 0.9544939994812012\n",
      "      vf_loss: 75.01082611083984\n",
      "    sample_time_ms: 20163.255\n",
      "    update_time_ms: 8.141\n",
      "  iterations_since_restore: 612\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.21991344252159\n",
      "    rl_1: 59.88203466778398\n",
      "  time_since_restore: 14205.508481025696\n",
      "  time_this_iter_s: 23.396937131881714\n",
      "  time_total_s: 14205.508481025696\n",
      "  timestamp: 1550894814\n",
      "  timesteps_since_restore: 6120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6120000\n",
      "  training_iteration: 612\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14205 s, 612 iter, 6120000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-07-17\n",
      "  done: false\n",
      "  episode_len_mean: 110.09\n",
      "  episode_reward_max: 227.8763047117065\n",
      "  episode_reward_mean: 110.96269846094421\n",
      "  episode_reward_min: -179.5847006736496\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 52321\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3043.569\n",
      "    load_time_ms: 2.429\n",
      "    num_steps_sampled: 6130000\n",
      "    num_steps_trained: 6130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.40030449628829956\n",
      "      kl: 0.026574745774269104\n",
      "      policy_loss: 0.00462883897125721\n",
      "      total_loss: 145.6302032470703\n",
      "      vf_explained_var: 0.9479061961174011\n",
      "      vf_loss: 145.62554931640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5473122596740723\n",
      "      kl: 0.032250192016363144\n",
      "      policy_loss: 0.004069710616022348\n",
      "      total_loss: 135.8412628173828\n",
      "      vf_explained_var: 0.9406515955924988\n",
      "      vf_loss: 135.837158203125\n",
      "    sample_time_ms: 20149.241\n",
      "    update_time_ms: 8.575\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.06381346946089\n",
      "    rl_1: 47.898884991483335\n",
      "  time_since_restore: 14228.469711780548\n",
      "  time_this_iter_s: 22.961230754852295\n",
      "  time_total_s: 14228.469711780548\n",
      "  timestamp: 1550894837\n",
      "  timesteps_since_restore: 6130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6130000\n",
      "  training_iteration: 613\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14228 s, 613 iter, 6130000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-07-40\n",
      "  done: false\n",
      "  episode_len_mean: 110.84\n",
      "  episode_reward_max: 230.6065490800801\n",
      "  episode_reward_mean: 140.2376958878311\n",
      "  episode_reward_min: -173.13156504755054\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 52410\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.052\n",
      "    load_time_ms: 2.469\n",
      "    num_steps_sampled: 6140000\n",
      "    num_steps_trained: 6140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4766293168067932\n",
      "      kl: 0.029649414122104645\n",
      "      policy_loss: 0.00560089061036706\n",
      "      total_loss: 133.8241729736328\n",
      "      vf_explained_var: 0.9341625571250916\n",
      "      vf_loss: 133.81857299804688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5926721692085266\n",
      "      kl: 0.020249510183930397\n",
      "      policy_loss: 0.00246469140984118\n",
      "      total_loss: 125.14982604980469\n",
      "      vf_explained_var: 0.9275073409080505\n",
      "      vf_loss: 125.14734649658203\n",
      "    sample_time_ms: 20103.017\n",
      "    update_time_ms: 8.318\n",
      "  iterations_since_restore: 614\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.25812529732443\n",
      "    rl_1: 61.979570590506675\n",
      "  time_since_restore: 14251.532029151917\n",
      "  time_this_iter_s: 23.062317371368408\n",
      "  time_total_s: 14251.532029151917\n",
      "  timestamp: 1550894860\n",
      "  timesteps_since_restore: 6140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6140000\n",
      "  training_iteration: 614\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14251 s, 614 iter, 6140000 ts, 140 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-08-02\n",
      "  done: false\n",
      "  episode_len_mean: 114.75\n",
      "  episode_reward_max: 225.29910616320146\n",
      "  episode_reward_mean: 151.6843214192917\n",
      "  episode_reward_min: -159.43601323518175\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 52496\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.196\n",
      "    load_time_ms: 2.592\n",
      "    num_steps_sampled: 6150000\n",
      "    num_steps_trained: 6150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4292255938053131\n",
      "      kl: 0.025940876454114914\n",
      "      policy_loss: 0.0010419663740321994\n",
      "      total_loss: 88.19428253173828\n",
      "      vf_explained_var: 0.9427960515022278\n",
      "      vf_loss: 88.19325256347656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5716050267219543\n",
      "      kl: 0.021543605253100395\n",
      "      policy_loss: 0.00046871171798557043\n",
      "      total_loss: 81.57063293457031\n",
      "      vf_explained_var: 0.9296838641166687\n",
      "      vf_loss: 81.57015991210938\n",
      "    sample_time_ms: 20036.178\n",
      "    update_time_ms: 8.26\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.75984382743668\n",
      "    rl_1: 65.92447759185502\n",
      "  time_since_restore: 14273.934188127518\n",
      "  time_this_iter_s: 22.402158975601196\n",
      "  time_total_s: 14273.934188127518\n",
      "  timestamp: 1550894882\n",
      "  timesteps_since_restore: 6150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6150000\n",
      "  training_iteration: 615\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14273 s, 615 iter, 6150000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-08-25\n",
      "  done: false\n",
      "  episode_len_mean: 110.35\n",
      "  episode_reward_max: 221.53238851575304\n",
      "  episode_reward_mean: 124.52158104367736\n",
      "  episode_reward_min: -173.23174384124172\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 52588\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.968\n",
      "    load_time_ms: 2.514\n",
      "    num_steps_sampled: 6160000\n",
      "    num_steps_trained: 6160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4698548913002014\n",
      "      kl: 0.013157276436686516\n",
      "      policy_loss: -0.0002881778927985579\n",
      "      total_loss: 106.59913635253906\n",
      "      vf_explained_var: 0.955746591091156\n",
      "      vf_loss: 106.59943389892578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6189043521881104\n",
      "      kl: 0.029496492817997932\n",
      "      policy_loss: 0.004122737795114517\n",
      "      total_loss: 92.97463989257812\n",
      "      vf_explained_var: 0.9518351554870605\n",
      "      vf_loss: 92.97051239013672\n",
      "    sample_time_ms: 20009.606\n",
      "    update_time_ms: 8.229\n",
      "  iterations_since_restore: 616\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.64789837610766\n",
      "    rl_1: 52.873682667569675\n",
      "  time_since_restore: 14297.096687316895\n",
      "  time_this_iter_s: 23.16249918937683\n",
      "  time_total_s: 14297.096687316895\n",
      "  timestamp: 1550894905\n",
      "  timesteps_since_restore: 6160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6160000\n",
      "  training_iteration: 616\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14297 s, 616 iter, 6160000 ts, 125 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-08-48\n",
      "  done: false\n",
      "  episode_len_mean: 110.84\n",
      "  episode_reward_max: 231.53635697542626\n",
      "  episode_reward_mean: 133.74299966807325\n",
      "  episode_reward_min: -166.16027454546068\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 52674\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3063.246\n",
      "    load_time_ms: 2.5\n",
      "    num_steps_sampled: 6170000\n",
      "    num_steps_trained: 6170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.41107770800590515\n",
      "      kl: 0.02827765978872776\n",
      "      policy_loss: 0.00747279729694128\n",
      "      total_loss: 93.63363647460938\n",
      "      vf_explained_var: 0.9585897922515869\n",
      "      vf_loss: 93.62615203857422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5666022300720215\n",
      "      kl: 0.014025385491549969\n",
      "      policy_loss: 0.0031135864555835724\n",
      "      total_loss: 92.44525909423828\n",
      "      vf_explained_var: 0.9495775103569031\n",
      "      vf_loss: 92.44214630126953\n",
      "    sample_time_ms: 19966.864\n",
      "    update_time_ms: 8.129\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.40585131467422\n",
      "    rl_1: 58.337148353398995\n",
      "  time_since_restore: 14319.681645393372\n",
      "  time_this_iter_s: 22.58495807647705\n",
      "  time_total_s: 14319.681645393372\n",
      "  timestamp: 1550894928\n",
      "  timesteps_since_restore: 6170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6170000\n",
      "  training_iteration: 617\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14319 s, 617 iter, 6170000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-09-11\n",
      "  done: false\n",
      "  episode_len_mean: 119.9\n",
      "  episode_reward_max: 239.99742358372666\n",
      "  episode_reward_mean: 153.60470491584135\n",
      "  episode_reward_min: -166.16027454546068\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 52760\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.583\n",
      "    load_time_ms: 2.492\n",
      "    num_steps_sampled: 6180000\n",
      "    num_steps_trained: 6180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39556699991226196\n",
      "      kl: 0.016955522820353508\n",
      "      policy_loss: 0.003707761177793145\n",
      "      total_loss: 71.08049774169922\n",
      "      vf_explained_var: 0.9566975235939026\n",
      "      vf_loss: 71.0767822265625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5862733125686646\n",
      "      kl: 0.011466641910374165\n",
      "      policy_loss: 0.0001972592726815492\n",
      "      total_loss: 64.12379455566406\n",
      "      vf_explained_var: 0.9524531960487366\n",
      "      vf_loss: 64.12359619140625\n",
      "    sample_time_ms: 19994.088\n",
      "    update_time_ms: 8.313\n",
      "  iterations_since_restore: 618\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.90645431521318\n",
      "    rl_1: 67.69825060062816\n",
      "  time_since_restore: 14343.101016998291\n",
      "  time_this_iter_s: 23.419371604919434\n",
      "  time_total_s: 14343.101016998291\n",
      "  timestamp: 1550894951\n",
      "  timesteps_since_restore: 6180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6180000\n",
      "  training_iteration: 618\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14343 s, 618 iter, 6180000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-09-34\n",
      "  done: false\n",
      "  episode_len_mean: 112.11\n",
      "  episode_reward_max: 238.16469796405607\n",
      "  episode_reward_mean: 132.63224034951295\n",
      "  episode_reward_min: -163.13509801526467\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 52850\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.138\n",
      "    load_time_ms: 2.485\n",
      "    num_steps_sampled: 6190000\n",
      "    num_steps_trained: 6190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4687545895576477\n",
      "      kl: 0.034543730318546295\n",
      "      policy_loss: 0.00997880194336176\n",
      "      total_loss: 107.1820068359375\n",
      "      vf_explained_var: 0.9508979916572571\n",
      "      vf_loss: 107.17202758789062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6284897923469543\n",
      "      kl: 0.023809662088751793\n",
      "      policy_loss: 0.005091267172247171\n",
      "      total_loss: 100.33738708496094\n",
      "      vf_explained_var: 0.9410328269004822\n",
      "      vf_loss: 100.33229064941406\n",
      "    sample_time_ms: 19984.152\n",
      "    update_time_ms: 7.303\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.03847047486114\n",
      "    rl_1: 56.59376987465182\n",
      "  time_since_restore: 14366.09460234642\n",
      "  time_this_iter_s: 22.993585348129272\n",
      "  time_total_s: 14366.09460234642\n",
      "  timestamp: 1550894974\n",
      "  timesteps_since_restore: 6190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6190000\n",
      "  training_iteration: 619\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14366 s, 619 iter, 6190000 ts, 133 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-09-58\n",
      "  done: false\n",
      "  episode_len_mean: 125.74\n",
      "  episode_reward_max: 231.53050273046156\n",
      "  episode_reward_mean: 138.58780922767278\n",
      "  episode_reward_min: -164.1942564634606\n",
      "  episodes_this_iter: 77\n",
      "  episodes_total: 52927\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.84\n",
      "    load_time_ms: 2.399\n",
      "    num_steps_sampled: 6200000\n",
      "    num_steps_trained: 6200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.1578211486339569\n",
      "      kl: 0.017712682485580444\n",
      "      policy_loss: 0.002816808642819524\n",
      "      total_loss: 79.20256805419922\n",
      "      vf_explained_var: 0.9449486136436462\n",
      "      vf_loss: 79.19975280761719\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.351959228515625\n",
      "      kl: 0.07885106652975082\n",
      "      policy_loss: 0.02254188247025013\n",
      "      total_loss: 70.90226745605469\n",
      "      vf_explained_var: 0.9393734335899353\n",
      "      vf_loss: 70.87972259521484\n",
      "    sample_time_ms: 20023.825\n",
      "    update_time_ms: 7.321\n",
      "  iterations_since_restore: 620\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.48353582220889\n",
      "    rl_1: 57.104273405463886\n",
      "  time_since_restore: 14389.418621778488\n",
      "  time_this_iter_s: 23.32401943206787\n",
      "  time_total_s: 14389.418621778488\n",
      "  timestamp: 1550894998\n",
      "  timesteps_since_restore: 6200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6200000\n",
      "  training_iteration: 620\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14389 s, 620 iter, 6200000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-10-21\n",
      "  done: false\n",
      "  episode_len_mean: 117.48\n",
      "  episode_reward_max: 229.32172151554846\n",
      "  episode_reward_mean: 148.14381414256798\n",
      "  episode_reward_min: -173.59888890156765\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 53013\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.866\n",
      "    load_time_ms: 2.382\n",
      "    num_steps_sampled: 6210000\n",
      "    num_steps_trained: 6210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3962688446044922\n",
      "      kl: 0.026754280552268028\n",
      "      policy_loss: 0.0025573696475476027\n",
      "      total_loss: 67.7650146484375\n",
      "      vf_explained_var: 0.9595757722854614\n",
      "      vf_loss: 67.76244354248047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5647022128105164\n",
      "      kl: 0.018076153472065926\n",
      "      policy_loss: -0.00029042497044429183\n",
      "      total_loss: 54.56690216064453\n",
      "      vf_explained_var: 0.9615298509597778\n",
      "      vf_loss: 54.567195892333984\n",
      "    sample_time_ms: 19920.919\n",
      "    update_time_ms: 7.462\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.0914243041188\n",
      "    rl_1: 63.05238983844918\n",
      "  time_since_restore: 14412.310719013214\n",
      "  time_this_iter_s: 22.892097234725952\n",
      "  time_total_s: 14412.310719013214\n",
      "  timestamp: 1550895021\n",
      "  timesteps_since_restore: 6210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6210000\n",
      "  training_iteration: 621\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14412 s, 621 iter, 6210000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-10-44\n",
      "  done: false\n",
      "  episode_len_mean: 112.39\n",
      "  episode_reward_max: 235.08836958449245\n",
      "  episode_reward_mean: 152.15256217748\n",
      "  episode_reward_min: -147.68796202557684\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 53101\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.776\n",
      "    load_time_ms: 2.361\n",
      "    num_steps_sampled: 6220000\n",
      "    num_steps_trained: 6220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.46932679414749146\n",
      "      kl: 0.031085362657904625\n",
      "      policy_loss: 0.0027955821715295315\n",
      "      total_loss: 78.18329620361328\n",
      "      vf_explained_var: 0.9540959000587463\n",
      "      vf_loss: 78.1805191040039\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6219197511672974\n",
      "      kl: 0.02789747342467308\n",
      "      policy_loss: 0.0039082602597773075\n",
      "      total_loss: 69.11359405517578\n",
      "      vf_explained_var: 0.9444723725318909\n",
      "      vf_loss: 69.10967254638672\n",
      "    sample_time_ms: 19857.308\n",
      "    update_time_ms: 7.482\n",
      "  iterations_since_restore: 622\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.91087596375884\n",
      "    rl_1: 66.24168621372115\n",
      "  time_since_restore: 14435.086841106415\n",
      "  time_this_iter_s: 22.776122093200684\n",
      "  time_total_s: 14435.086841106415\n",
      "  timestamp: 1550895044\n",
      "  timesteps_since_restore: 6220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6220000\n",
      "  training_iteration: 622\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14435 s, 622 iter, 6220000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-11-06\n",
      "  done: false\n",
      "  episode_len_mean: 117.57\n",
      "  episode_reward_max: 234.56497285742998\n",
      "  episode_reward_mean: 155.19005800758873\n",
      "  episode_reward_min: -164.32476675758545\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 53185\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.461\n",
      "    load_time_ms: 2.438\n",
      "    num_steps_sampled: 6230000\n",
      "    num_steps_trained: 6230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.32479211688041687\n",
      "      kl: 0.09685610234737396\n",
      "      policy_loss: 0.02353154681622982\n",
      "      total_loss: 77.5042953491211\n",
      "      vf_explained_var: 0.9435731768608093\n",
      "      vf_loss: 77.48076629638672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4941646456718445\n",
      "      kl: 0.015560314990580082\n",
      "      policy_loss: 0.0043707918375730515\n",
      "      total_loss: 62.91557693481445\n",
      "      vf_explained_var: 0.9437503218650818\n",
      "      vf_loss: 62.91120147705078\n",
      "    sample_time_ms: 19833.433\n",
      "    update_time_ms: 7.283\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.06980518912037\n",
      "    rl_1: 66.12025281846837\n",
      "  time_since_restore: 14457.84809589386\n",
      "  time_this_iter_s: 22.76125478744507\n",
      "  time_total_s: 14457.84809589386\n",
      "  timestamp: 1550895066\n",
      "  timesteps_since_restore: 6230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6230000\n",
      "  training_iteration: 623\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14457 s, 623 iter, 6230000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-11-29\n",
      "  done: false\n",
      "  episode_len_mean: 113.67\n",
      "  episode_reward_max: 237.1818348226908\n",
      "  episode_reward_mean: 146.95632010007841\n",
      "  episode_reward_min: -166.56999379401705\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 53274\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.974\n",
      "    load_time_ms: 2.409\n",
      "    num_steps_sampled: 6240000\n",
      "    num_steps_trained: 6240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42484962940216064\n",
      "      kl: 0.026843849569559097\n",
      "      policy_loss: 0.00638167466968298\n",
      "      total_loss: 80.94241333007812\n",
      "      vf_explained_var: 0.9554374814033508\n",
      "      vf_loss: 80.93604278564453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6072672605514526\n",
      "      kl: 8.783232688903809\n",
      "      policy_loss: 0.10654115676879883\n",
      "      total_loss: 65.40284729003906\n",
      "      vf_explained_var: 0.9563494920730591\n",
      "      vf_loss: 65.29630279541016\n",
      "    sample_time_ms: 19831.123\n",
      "    update_time_ms: 7.329\n",
      "  iterations_since_restore: 624\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.90719207225642\n",
      "    rl_1: 64.049128027822\n",
      "  time_since_restore: 14480.741303443909\n",
      "  time_this_iter_s: 22.893207550048828\n",
      "  time_total_s: 14480.741303443909\n",
      "  timestamp: 1550895089\n",
      "  timesteps_since_restore: 6240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6240000\n",
      "  training_iteration: 624\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14480 s, 624 iter, 6240000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-11-52\n",
      "  done: false\n",
      "  episode_len_mean: 118.37\n",
      "  episode_reward_max: 230.21623239090516\n",
      "  episode_reward_mean: 143.38492099130184\n",
      "  episode_reward_min: -166.56999379401705\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 53359\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.146\n",
      "    load_time_ms: 2.266\n",
      "    num_steps_sampled: 6250000\n",
      "    num_steps_trained: 6250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.28608381748199463\n",
      "      kl: 0.34593167901039124\n",
      "      policy_loss: 0.00790761411190033\n",
      "      total_loss: 115.62874603271484\n",
      "      vf_explained_var: 0.9312946796417236\n",
      "      vf_loss: 115.62085723876953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4637942612171173\n",
      "      kl: 2.8712308406829834\n",
      "      policy_loss: 0.046465735882520676\n",
      "      total_loss: 102.71564483642578\n",
      "      vf_explained_var: 0.9269515872001648\n",
      "      vf_loss: 102.66918182373047\n",
      "    sample_time_ms: 19877.423\n",
      "    update_time_ms: 7.612\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.56078901471706\n",
      "    rl_1: 60.82413197658479\n",
      "  time_since_restore: 14503.598893165588\n",
      "  time_this_iter_s: 22.857589721679688\n",
      "  time_total_s: 14503.598893165588\n",
      "  timestamp: 1550895112\n",
      "  timesteps_since_restore: 6250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6250000\n",
      "  training_iteration: 625\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14503 s, 625 iter, 6250000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-12-15\n",
      "  done: false\n",
      "  episode_len_mean: 115.75\n",
      "  episode_reward_max: 217.96371823338572\n",
      "  episode_reward_mean: 114.9924989532041\n",
      "  episode_reward_min: -143.78758949699443\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 53446\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.895\n",
      "    load_time_ms: 2.275\n",
      "    num_steps_sampled: 6260000\n",
      "    num_steps_trained: 6260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2750634551048279\n",
      "      kl: 0.03198924660682678\n",
      "      policy_loss: 0.0030631350819021463\n",
      "      total_loss: 190.3977813720703\n",
      "      vf_explained_var: 0.9202252626419067\n",
      "      vf_loss: 190.39474487304688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4829306900501251\n",
      "      kl: 0.013467649929225445\n",
      "      policy_loss: -0.0012776580406352878\n",
      "      total_loss: 168.8741912841797\n",
      "      vf_explained_var: 0.8989836573600769\n",
      "      vf_loss: 168.87548828125\n",
      "    sample_time_ms: 19846.494\n",
      "    update_time_ms: 7.888\n",
      "  iterations_since_restore: 626\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.74179206777207\n",
      "    rl_1: 47.25070688543202\n",
      "  time_since_restore: 14526.54261803627\n",
      "  time_this_iter_s: 22.943724870681763\n",
      "  time_total_s: 14526.54261803627\n",
      "  timestamp: 1550895135\n",
      "  timesteps_since_restore: 6260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6260000\n",
      "  training_iteration: 626\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14526 s, 626 iter, 6260000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-12-39\n",
      "  done: false\n",
      "  episode_len_mean: 109.65\n",
      "  episode_reward_max: 220.9993727122717\n",
      "  episode_reward_mean: 91.82274807882327\n",
      "  episode_reward_min: -164.55293549090771\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 53537\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.835\n",
      "    load_time_ms: 2.355\n",
      "    num_steps_sampled: 6270000\n",
      "    num_steps_trained: 6270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.27337148785591125\n",
      "      kl: 0.014163527637720108\n",
      "      policy_loss: 0.0006393726216629148\n",
      "      total_loss: 218.27249145507812\n",
      "      vf_explained_var: 0.920181155204773\n",
      "      vf_loss: 218.27183532714844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47072142362594604\n",
      "      kl: 0.01372280903160572\n",
      "      policy_loss: 0.0018385747680440545\n",
      "      total_loss: 185.2107696533203\n",
      "      vf_explained_var: 0.9076656699180603\n",
      "      vf_loss: 185.2089385986328\n",
      "    sample_time_ms: 19950.505\n",
      "    update_time_ms: 7.725\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.98364409740656\n",
      "    rl_1: 35.83910398141673\n",
      "  time_since_restore: 14550.361638784409\n",
      "  time_this_iter_s: 23.819020748138428\n",
      "  time_total_s: 14550.361638784409\n",
      "  timestamp: 1550895159\n",
      "  timesteps_since_restore: 6270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6270000\n",
      "  training_iteration: 627\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14550 s, 627 iter, 6270000 ts, 91.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-13-02\n",
      "  done: false\n",
      "  episode_len_mean: 110.23\n",
      "  episode_reward_max: 234.0021293173577\n",
      "  episode_reward_mean: 92.20433942733227\n",
      "  episode_reward_min: -169.71754454181902\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 53628\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.168\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 6280000\n",
      "    num_steps_trained: 6280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2874102294445038\n",
      "      kl: 0.010049821808934212\n",
      "      policy_loss: 0.0020949863828718662\n",
      "      total_loss: 272.3164367675781\n",
      "      vf_explained_var: 0.9071458578109741\n",
      "      vf_loss: 272.3143615722656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47789040207862854\n",
      "      kl: 0.022532695904374123\n",
      "      policy_loss: 0.004992655478417873\n",
      "      total_loss: 235.6278533935547\n",
      "      vf_explained_var: 0.8978453278541565\n",
      "      vf_loss: 235.62289428710938\n",
      "    sample_time_ms: 19912.25\n",
      "    update_time_ms: 7.575\n",
      "  iterations_since_restore: 628\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.712273843558414\n",
      "    rl_1: 37.492065583773886\n",
      "  time_since_restore: 14573.382252931595\n",
      "  time_this_iter_s: 23.02061414718628\n",
      "  time_total_s: 14573.382252931595\n",
      "  timestamp: 1550895182\n",
      "  timesteps_since_restore: 6280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6280000\n",
      "  training_iteration: 628\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14573 s, 628 iter, 6280000 ts, 92.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-13-25\n",
      "  done: false\n",
      "  episode_len_mean: 109.38\n",
      "  episode_reward_max: 230.99451235132813\n",
      "  episode_reward_mean: 98.96675534510884\n",
      "  episode_reward_min: -165.38357761633955\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 53718\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.164\n",
      "    load_time_ms: 2.346\n",
      "    num_steps_sampled: 6290000\n",
      "    num_steps_trained: 6290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24833530187606812\n",
      "      kl: 0.018955018371343613\n",
      "      policy_loss: 0.0009546424844302237\n",
      "      total_loss: 189.99449157714844\n",
      "      vf_explained_var: 0.9246075749397278\n",
      "      vf_loss: 189.99354553222656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4277450740337372\n",
      "      kl: 0.019450906664133072\n",
      "      policy_loss: 0.003766079433262348\n",
      "      total_loss: 174.1529998779297\n",
      "      vf_explained_var: 0.9107226133346558\n",
      "      vf_loss: 174.1492462158203\n",
      "    sample_time_ms: 19939.464\n",
      "    update_time_ms: 7.557\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.110485712683555\n",
      "    rl_1: 40.85626963242533\n",
      "  time_since_restore: 14596.635892391205\n",
      "  time_this_iter_s: 23.253639459609985\n",
      "  time_total_s: 14596.635892391205\n",
      "  timestamp: 1550895205\n",
      "  timesteps_since_restore: 6290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6290000\n",
      "  training_iteration: 629\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14596 s, 629 iter, 6290000 ts, 99 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-13-49\n",
      "  done: false\n",
      "  episode_len_mean: 105.28\n",
      "  episode_reward_max: 233.68946881438816\n",
      "  episode_reward_mean: 110.4725247424436\n",
      "  episode_reward_min: -161.97349644918498\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 53813\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.232\n",
      "    load_time_ms: 2.339\n",
      "    num_steps_sampled: 6300000\n",
      "    num_steps_trained: 6300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.40182361006736755\n",
      "      kl: 0.04283663630485535\n",
      "      policy_loss: 0.015275247395038605\n",
      "      total_loss: 218.4796905517578\n",
      "      vf_explained_var: 0.9137921333312988\n",
      "      vf_loss: 218.46438598632812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5916432738304138\n",
      "      kl: 0.03280786797404289\n",
      "      policy_loss: 0.0064568123780190945\n",
      "      total_loss: 190.62213134765625\n",
      "      vf_explained_var: 0.9060197472572327\n",
      "      vf_loss: 190.6156768798828\n",
      "    sample_time_ms: 19935.29\n",
      "    update_time_ms: 7.96\n",
      "  iterations_since_restore: 630\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.292032839323156\n",
      "    rl_1: 47.18049190312048\n",
      "  time_since_restore: 14619.891221523285\n",
      "  time_this_iter_s: 23.255329132080078\n",
      "  time_total_s: 14619.891221523285\n",
      "  timestamp: 1550895229\n",
      "  timesteps_since_restore: 6300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6300000\n",
      "  training_iteration: 630\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14619 s, 630 iter, 6300000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-14-12\n",
      "  done: false\n",
      "  episode_len_mean: 114.28\n",
      "  episode_reward_max: 228.4042494417949\n",
      "  episode_reward_mean: 118.91333450914075\n",
      "  episode_reward_min: -157.94630740204707\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 53898\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.007\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 6310000\n",
      "    num_steps_trained: 6310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.24474464356899261\n",
      "      kl: 0.020306425169110298\n",
      "      policy_loss: 0.004956841468811035\n",
      "      total_loss: 106.91130828857422\n",
      "      vf_explained_var: 0.9475854635238647\n",
      "      vf_loss: 106.9063491821289\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4770863354206085\n",
      "      kl: 0.025573620572686195\n",
      "      policy_loss: 0.004261034540832043\n",
      "      total_loss: 98.5194091796875\n",
      "      vf_explained_var: 0.9375939965248108\n",
      "      vf_loss: 98.51515197753906\n",
      "    sample_time_ms: 19940.754\n",
      "    update_time_ms: 7.673\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.71590342017339\n",
      "    rl_1: 49.19743108896737\n",
      "  time_since_restore: 14642.842783212662\n",
      "  time_this_iter_s: 22.95156168937683\n",
      "  time_total_s: 14642.842783212662\n",
      "  timestamp: 1550895252\n",
      "  timesteps_since_restore: 6310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6310000\n",
      "  training_iteration: 631\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14642 s, 631 iter, 6310000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-14-35\n",
      "  done: false\n",
      "  episode_len_mean: 111.38\n",
      "  episode_reward_max: 219.89343343890675\n",
      "  episode_reward_mean: 122.9520675895425\n",
      "  episode_reward_min: -163.71899465110775\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 53990\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.506\n",
      "    load_time_ms: 2.394\n",
      "    num_steps_sampled: 6320000\n",
      "    num_steps_trained: 6320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.29685667157173157\n",
      "      kl: 0.03366653248667717\n",
      "      policy_loss: 0.0051132389344275\n",
      "      total_loss: 140.80224609375\n",
      "      vf_explained_var: 0.9368484616279602\n",
      "      vf_loss: 140.79714965820312\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5435177683830261\n",
      "      kl: 0.01742149330675602\n",
      "      policy_loss: 0.0026976598892360926\n",
      "      total_loss: 120.30509185791016\n",
      "      vf_explained_var: 0.9310829043388367\n",
      "      vf_loss: 120.30240631103516\n",
      "    sample_time_ms: 19966.018\n",
      "    update_time_ms: 7.757\n",
      "  iterations_since_restore: 632\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.56772934454763\n",
      "    rl_1: 52.38433824499488\n",
      "  time_since_restore: 14665.840081453323\n",
      "  time_this_iter_s: 22.99729824066162\n",
      "  time_total_s: 14665.840081453323\n",
      "  timestamp: 1550895275\n",
      "  timesteps_since_restore: 6320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6320000\n",
      "  training_iteration: 632\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14665 s, 632 iter, 6320000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-14-58\n",
      "  done: false\n",
      "  episode_len_mean: 109.07\n",
      "  episode_reward_max: 226.87399895568927\n",
      "  episode_reward_mean: 116.77077886262414\n",
      "  episode_reward_min: -163.71899465110775\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 54080\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.993\n",
      "    load_time_ms: 2.28\n",
      "    num_steps_sampled: 6330000\n",
      "    num_steps_trained: 6330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3332257866859436\n",
      "      kl: 0.013374833390116692\n",
      "      policy_loss: 0.001880680676549673\n",
      "      total_loss: 166.187744140625\n",
      "      vf_explained_var: 0.9222546815872192\n",
      "      vf_loss: 166.18582153320312\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6108283400535583\n",
      "      kl: 0.012584013864398003\n",
      "      policy_loss: -0.001300211064517498\n",
      "      total_loss: 143.4225616455078\n",
      "      vf_explained_var: 0.9188644289970398\n",
      "      vf_loss: 143.42388916015625\n",
      "    sample_time_ms: 19997.842\n",
      "    update_time_ms: 7.494\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.87963273034838\n",
      "    rl_1: 49.89114613227577\n",
      "  time_since_restore: 14688.897449493408\n",
      "  time_this_iter_s: 23.05736804008484\n",
      "  time_total_s: 14688.897449493408\n",
      "  timestamp: 1550895298\n",
      "  timesteps_since_restore: 6330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6330000\n",
      "  training_iteration: 633\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14688 s, 633 iter, 6330000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-15-20\n",
      "  done: false\n",
      "  episode_len_mean: 102.46\n",
      "  episode_reward_max: 230.21492009832195\n",
      "  episode_reward_mean: 88.69826780258782\n",
      "  episode_reward_min: -169.70814815048303\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 54178\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.674\n",
      "    load_time_ms: 2.389\n",
      "    num_steps_sampled: 6340000\n",
      "    num_steps_trained: 6340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3814862370491028\n",
      "      kl: 0.017774682492017746\n",
      "      policy_loss: 0.0037849307991564274\n",
      "      total_loss: 160.6122589111328\n",
      "      vf_explained_var: 0.9506548643112183\n",
      "      vf_loss: 160.6084442138672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6260661482810974\n",
      "      kl: 0.014275459572672844\n",
      "      policy_loss: 0.0009701093658804893\n",
      "      total_loss: 136.5838623046875\n",
      "      vf_explained_var: 0.946363091468811\n",
      "      vf_loss: 136.58290100097656\n",
      "    sample_time_ms: 19941.019\n",
      "    update_time_ms: 7.66\n",
      "  iterations_since_restore: 634\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.13490369628363\n",
      "    rl_1: 37.563364106304185\n",
      "  time_since_restore: 14711.174779176712\n",
      "  time_this_iter_s: 22.277329683303833\n",
      "  time_total_s: 14711.174779176712\n",
      "  timestamp: 1550895320\n",
      "  timesteps_since_restore: 6340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6340000\n",
      "  training_iteration: 634\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14711 s, 634 iter, 6340000 ts, 88.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-15-43\n",
      "  done: false\n",
      "  episode_len_mean: 102.2\n",
      "  episode_reward_max: 217.92503339850225\n",
      "  episode_reward_mean: 96.3316164198176\n",
      "  episode_reward_min: -146.30372446529924\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 54276\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.9\n",
      "    load_time_ms: 2.453\n",
      "    num_steps_sampled: 6350000\n",
      "    num_steps_trained: 6350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.416736364364624\n",
      "      kl: 0.016228755936026573\n",
      "      policy_loss: 0.0033665220253169537\n",
      "      total_loss: 156.9628448486328\n",
      "      vf_explained_var: 0.9465627670288086\n",
      "      vf_loss: 156.95948791503906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6439332365989685\n",
      "      kl: 0.020828962326049805\n",
      "      policy_loss: -0.00012410603812895715\n",
      "      total_loss: 144.07823181152344\n",
      "      vf_explained_var: 0.9388355612754822\n",
      "      vf_loss: 144.078369140625\n",
      "    sample_time_ms: 19975.334\n",
      "    update_time_ms: 7.334\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.92220297799043\n",
      "    rl_1: 41.409413441827176\n",
      "  time_since_restore: 14734.386242389679\n",
      "  time_this_iter_s: 23.21146321296692\n",
      "  time_total_s: 14734.386242389679\n",
      "  timestamp: 1550895343\n",
      "  timesteps_since_restore: 6350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6350000\n",
      "  training_iteration: 635\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14734 s, 635 iter, 6350000 ts, 96.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-16-06\n",
      "  done: false\n",
      "  episode_len_mean: 107.71\n",
      "  episode_reward_max: 208.30170956275174\n",
      "  episode_reward_mean: 117.20401803124389\n",
      "  episode_reward_min: -147.12590523970175\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 54368\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.476\n",
      "    load_time_ms: 2.446\n",
      "    num_steps_sampled: 6360000\n",
      "    num_steps_trained: 6360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3237442076206207\n",
      "      kl: 0.01230217982083559\n",
      "      policy_loss: -0.0018035537796095014\n",
      "      total_loss: 161.8981475830078\n",
      "      vf_explained_var: 0.9345077276229858\n",
      "      vf_loss: 161.8999786376953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5595096945762634\n",
      "      kl: 0.017643431201577187\n",
      "      policy_loss: 0.003794231917709112\n",
      "      total_loss: 143.6472625732422\n",
      "      vf_explained_var: 0.9226985573768616\n",
      "      vf_loss: 143.64344787597656\n",
      "    sample_time_ms: 19942.617\n",
      "    update_time_ms: 7.236\n",
      "  iterations_since_restore: 636\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.2738861829008\n",
      "    rl_1: 50.93013184834309\n",
      "  time_since_restore: 14756.906955957413\n",
      "  time_this_iter_s: 22.520713567733765\n",
      "  time_total_s: 14756.906955957413\n",
      "  timestamp: 1550895366\n",
      "  timesteps_since_restore: 6360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6360000\n",
      "  training_iteration: 636\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14756 s, 636 iter, 6360000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 107.5\n",
      "  episode_reward_max: 238.25517841825942\n",
      "  episode_reward_mean: 110.54591416932163\n",
      "  episode_reward_min: -160.0208495110261\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 54460\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3046.583\n",
      "    load_time_ms: 2.361\n",
      "    num_steps_sampled: 6370000\n",
      "    num_steps_trained: 6370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3007757365703583\n",
      "      kl: 0.014604122377932072\n",
      "      policy_loss: 0.002667180960997939\n",
      "      total_loss: 243.21136474609375\n",
      "      vf_explained_var: 0.916102409362793\n",
      "      vf_loss: 243.20875549316406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5443122386932373\n",
      "      kl: 0.015272893942892551\n",
      "      policy_loss: 0.0022151758894324303\n",
      "      total_loss: 230.0144805908203\n",
      "      vf_explained_var: 0.9000949263572693\n",
      "      vf_loss: 230.01229858398438\n",
      "    sample_time_ms: 19933.988\n",
      "    update_time_ms: 7.304\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.7808436029244\n",
      "    rl_1: 47.76507056639727\n",
      "  time_since_restore: 14780.435810089111\n",
      "  time_this_iter_s: 23.52885413169861\n",
      "  time_total_s: 14780.435810089111\n",
      "  timestamp: 1550895390\n",
      "  timesteps_since_restore: 6370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6370000\n",
      "  training_iteration: 637\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14780 s, 637 iter, 6370000 ts, 111 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-16-52\n",
      "  done: false\n",
      "  episode_len_mean: 111.26\n",
      "  episode_reward_max: 230.92967817607584\n",
      "  episode_reward_mean: 113.2948860980447\n",
      "  episode_reward_min: -167.73726463111447\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 54551\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3046.761\n",
      "    load_time_ms: 2.371\n",
      "    num_steps_sampled: 6380000\n",
      "    num_steps_trained: 6380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2807430326938629\n",
      "      kl: 0.01589094288647175\n",
      "      policy_loss: 0.0002679578901734203\n",
      "      total_loss: 158.2472381591797\n",
      "      vf_explained_var: 0.9386498928070068\n",
      "      vf_loss: 158.24696350097656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5376874208450317\n",
      "      kl: 0.013802521862089634\n",
      "      policy_loss: 0.0024786731228232384\n",
      "      total_loss: 140.4445037841797\n",
      "      vf_explained_var: 0.9323420524597168\n",
      "      vf_loss: 140.44203186035156\n",
      "    sample_time_ms: 19910.203\n",
      "    update_time_ms: 7.282\n",
      "  iterations_since_restore: 638\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.95637481679084\n",
      "    rl_1: 48.338511281253844\n",
      "  time_since_restore: 14803.219780683517\n",
      "  time_this_iter_s: 22.783970594406128\n",
      "  time_total_s: 14803.219780683517\n",
      "  timestamp: 1550895412\n",
      "  timesteps_since_restore: 6380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6380000\n",
      "  training_iteration: 638\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14803 s, 638 iter, 6380000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-17-16\n",
      "  done: false\n",
      "  episode_len_mean: 107.55\n",
      "  episode_reward_max: 222.5912769657225\n",
      "  episode_reward_mean: 133.7008034150496\n",
      "  episode_reward_min: -161.04601748208205\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 54644\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3045.04\n",
      "    load_time_ms: 2.376\n",
      "    num_steps_sampled: 6390000\n",
      "    num_steps_trained: 6390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3396860957145691\n",
      "      kl: 0.026586327701807022\n",
      "      policy_loss: 0.004131952300667763\n",
      "      total_loss: 120.70075988769531\n",
      "      vf_explained_var: 0.9409888982772827\n",
      "      vf_loss: 120.69662475585938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.553350031375885\n",
      "      kl: 0.01693469099700451\n",
      "      policy_loss: 0.00044257729314267635\n",
      "      total_loss: 113.50421905517578\n",
      "      vf_explained_var: 0.9329653978347778\n",
      "      vf_loss: 113.5037841796875\n",
      "    sample_time_ms: 19912.124\n",
      "    update_time_ms: 7.591\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.43183583349135\n",
      "    rl_1: 59.26896758155826\n",
      "  time_since_restore: 14826.479736804962\n",
      "  time_this_iter_s: 23.259956121444702\n",
      "  time_total_s: 14826.479736804962\n",
      "  timestamp: 1550895436\n",
      "  timesteps_since_restore: 6390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6390000\n",
      "  training_iteration: 639\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14826 s, 639 iter, 6390000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-17-39\n",
      "  done: false\n",
      "  episode_len_mean: 109.01\n",
      "  episode_reward_max: 231.857780621273\n",
      "  episode_reward_mean: 116.1311698193399\n",
      "  episode_reward_min: -182.83158036595148\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 54736\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.383\n",
      "    load_time_ms: 2.405\n",
      "    num_steps_sampled: 6400000\n",
      "    num_steps_trained: 6400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.337588369846344\n",
      "      kl: 0.02083588019013405\n",
      "      policy_loss: 0.0006264203693717718\n",
      "      total_loss: 183.2369842529297\n",
      "      vf_explained_var: 0.9281653165817261\n",
      "      vf_loss: 183.23635864257812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.569654643535614\n",
      "      kl: 0.016478512436151505\n",
      "      policy_loss: 0.0020541262347251177\n",
      "      total_loss: 168.3751220703125\n",
      "      vf_explained_var: 0.9182509183883667\n",
      "      vf_loss: 168.37307739257812\n",
      "    sample_time_ms: 19877.621\n",
      "    update_time_ms: 7.04\n",
      "  iterations_since_restore: 640\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.94119380445845\n",
      "    rl_1: 51.18997601488146\n",
      "  time_since_restore: 14849.579340219498\n",
      "  time_this_iter_s: 23.099603414535522\n",
      "  time_total_s: 14849.579340219498\n",
      "  timestamp: 1550895459\n",
      "  timesteps_since_restore: 6400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6400000\n",
      "  training_iteration: 640\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14849 s, 640 iter, 6400000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-18-02\n",
      "  done: false\n",
      "  episode_len_mean: 112.05\n",
      "  episode_reward_max: 231.857780621273\n",
      "  episode_reward_mean: 111.92691231349676\n",
      "  episode_reward_min: -155.81852195385946\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 54824\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.617\n",
      "    load_time_ms: 2.4\n",
      "    num_steps_sampled: 6410000\n",
      "    num_steps_trained: 6410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3310544490814209\n",
      "      kl: 0.02220296487212181\n",
      "      policy_loss: 0.003955865278840065\n",
      "      total_loss: 170.55075073242188\n",
      "      vf_explained_var: 0.930339515209198\n",
      "      vf_loss: 170.54681396484375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5257474184036255\n",
      "      kl: 0.013496308587491512\n",
      "      policy_loss: 0.003465775866061449\n",
      "      total_loss: 153.8131561279297\n",
      "      vf_explained_var: 0.9130972027778625\n",
      "      vf_loss: 153.80972290039062\n",
      "    sample_time_ms: 19879.645\n",
      "    update_time_ms: 7.008\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.5540280300905\n",
      "    rl_1: 45.37288428340625\n",
      "  time_since_restore: 14872.5623254776\n",
      "  time_this_iter_s: 22.982985258102417\n",
      "  time_total_s: 14872.5623254776\n",
      "  timestamp: 1550895482\n",
      "  timesteps_since_restore: 6410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6410000\n",
      "  training_iteration: 641\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14872 s, 641 iter, 6410000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-18-25\n",
      "  done: false\n",
      "  episode_len_mean: 109.09\n",
      "  episode_reward_max: 219.50775754626434\n",
      "  episode_reward_mean: 96.36515755060945\n",
      "  episode_reward_min: -171.17769598721253\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 54915\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.334\n",
      "    load_time_ms: 2.339\n",
      "    num_steps_sampled: 6420000\n",
      "    num_steps_trained: 6420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.31233832240104675\n",
      "      kl: 0.016659066081047058\n",
      "      policy_loss: 0.002795668551698327\n",
      "      total_loss: 189.94273376464844\n",
      "      vf_explained_var: 0.9308255314826965\n",
      "      vf_loss: 189.93994140625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.546625018119812\n",
      "      kl: 0.018914252519607544\n",
      "      policy_loss: 0.00561947887763381\n",
      "      total_loss: 180.5570068359375\n",
      "      vf_explained_var: 0.9167811870574951\n",
      "      vf_loss: 180.5513916015625\n",
      "    sample_time_ms: 19884.46\n",
      "    update_time_ms: 6.955\n",
      "  iterations_since_restore: 642\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.136571437831364\n",
      "    rl_1: 40.22858611277811\n",
      "  time_since_restore: 14895.623947381973\n",
      "  time_this_iter_s: 23.06162190437317\n",
      "  time_total_s: 14895.623947381973\n",
      "  timestamp: 1550895505\n",
      "  timesteps_since_restore: 6420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6420000\n",
      "  training_iteration: 642\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14895 s, 642 iter, 6420000 ts, 96.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-18-48\n",
      "  done: false\n",
      "  episode_len_mean: 109.49\n",
      "  episode_reward_max: 233.3871267472577\n",
      "  episode_reward_mean: 109.39122098937347\n",
      "  episode_reward_min: -162.43778134080213\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 55007\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.839\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 6430000\n",
      "    num_steps_trained: 6430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3270060122013092\n",
      "      kl: 0.07563015818595886\n",
      "      policy_loss: 0.01311725564301014\n",
      "      total_loss: 174.78526306152344\n",
      "      vf_explained_var: 0.9261285066604614\n",
      "      vf_loss: 174.7721405029297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5644518136978149\n",
      "      kl: 0.010733155533671379\n",
      "      policy_loss: 0.0008924913126975298\n",
      "      total_loss: 150.2909393310547\n",
      "      vf_explained_var: 0.918249249458313\n",
      "      vf_loss: 150.29005432128906\n",
      "    sample_time_ms: 19894.12\n",
      "    update_time_ms: 7.187\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.99373165169014\n",
      "    rl_1: 46.39748933768334\n",
      "  time_since_restore: 14918.78593158722\n",
      "  time_this_iter_s: 23.16198420524597\n",
      "  time_total_s: 14918.78593158722\n",
      "  timestamp: 1550895528\n",
      "  timesteps_since_restore: 6430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6430000\n",
      "  training_iteration: 643\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14918 s, 643 iter, 6430000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-19-12\n",
      "  done: false\n",
      "  episode_len_mean: 109.81\n",
      "  episode_reward_max: 221.87395463725508\n",
      "  episode_reward_mean: 122.69849123202738\n",
      "  episode_reward_min: -168.6218124641633\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 55097\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.61\n",
      "    load_time_ms: 2.226\n",
      "    num_steps_sampled: 6440000\n",
      "    num_steps_trained: 6440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3652663230895996\n",
      "      kl: 0.015324401669204235\n",
      "      policy_loss: 0.00023093436902854592\n",
      "      total_loss: 139.2978057861328\n",
      "      vf_explained_var: 0.9341951012611389\n",
      "      vf_loss: 139.29759216308594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.583026111125946\n",
      "      kl: 0.011186259798705578\n",
      "      policy_loss: 0.00034384438185952604\n",
      "      total_loss: 129.87640380859375\n",
      "      vf_explained_var: 0.9218043684959412\n",
      "      vf_loss: 129.87603759765625\n",
      "    sample_time_ms: 20005.74\n",
      "    update_time_ms: 7.045\n",
      "  iterations_since_restore: 644\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.17586806112621\n",
      "    rl_1: 52.52262317090116\n",
      "  time_since_restore: 14942.202593803406\n",
      "  time_this_iter_s: 23.416662216186523\n",
      "  time_total_s: 14942.202593803406\n",
      "  timestamp: 1550895552\n",
      "  timesteps_since_restore: 6440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6440000\n",
      "  training_iteration: 644\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14942 s, 644 iter, 6440000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-19-35\n",
      "  done: false\n",
      "  episode_len_mean: 108.39\n",
      "  episode_reward_max: 225.54353280943985\n",
      "  episode_reward_mean: 121.2690478172204\n",
      "  episode_reward_min: -152.10814498264082\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 55189\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.114\n",
      "    load_time_ms: 2.209\n",
      "    num_steps_sampled: 6450000\n",
      "    num_steps_trained: 6450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.33922380208969116\n",
      "      kl: 0.025464827194809914\n",
      "      policy_loss: 0.006460254080593586\n",
      "      total_loss: 159.93099975585938\n",
      "      vf_explained_var: 0.933531641960144\n",
      "      vf_loss: 159.92454528808594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5627193450927734\n",
      "      kl: 0.01507177297025919\n",
      "      policy_loss: -0.00011800248466897756\n",
      "      total_loss: 149.93495178222656\n",
      "      vf_explained_var: 0.9216936826705933\n",
      "      vf_loss: 149.9351043701172\n",
      "    sample_time_ms: 20035.067\n",
      "    update_time_ms: 7.115\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.58214894773437\n",
      "    rl_1: 52.686898869486015\n",
      "  time_since_restore: 14965.714285612106\n",
      "  time_this_iter_s: 23.51169180870056\n",
      "  time_total_s: 14965.714285612106\n",
      "  timestamp: 1550895575\n",
      "  timesteps_since_restore: 6450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6450000\n",
      "  training_iteration: 645\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14965 s, 645 iter, 6450000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-19-58\n",
      "  done: false\n",
      "  episode_len_mean: 101.0\n",
      "  episode_reward_max: 215.98690711651196\n",
      "  episode_reward_mean: 79.2480459432688\n",
      "  episode_reward_min: -162.19353749257812\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 55289\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.683\n",
      "    load_time_ms: 2.165\n",
      "    num_steps_sampled: 6460000\n",
      "    num_steps_trained: 6460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4343479871749878\n",
      "      kl: 0.016407055780291557\n",
      "      policy_loss: 0.006933492608368397\n",
      "      total_loss: 158.48245239257812\n",
      "      vf_explained_var: 0.9552436470985413\n",
      "      vf_loss: 158.47549438476562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6227546334266663\n",
      "      kl: 0.03366362676024437\n",
      "      policy_loss: 0.01325172372162342\n",
      "      total_loss: 143.6439666748047\n",
      "      vf_explained_var: 0.94917231798172\n",
      "      vf_loss: 143.63070678710938\n",
      "    sample_time_ms: 20103.394\n",
      "    update_time_ms: 7.154\n",
      "  iterations_since_restore: 646\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 45.556233456814965\n",
      "    rl_1: 33.69181248645384\n",
      "  time_since_restore: 14988.916590452194\n",
      "  time_this_iter_s: 23.20230484008789\n",
      "  time_total_s: 14988.916590452194\n",
      "  timestamp: 1550895598\n",
      "  timesteps_since_restore: 6460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6460000\n",
      "  training_iteration: 646\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 14988 s, 646 iter, 6460000 ts, 79.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-20-22\n",
      "  done: false\n",
      "  episode_len_mean: 116.84\n",
      "  episode_reward_max: 222.2956308812705\n",
      "  episode_reward_mean: 111.7125080015787\n",
      "  episode_reward_min: -145.96620324087226\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 55373\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.918\n",
      "    load_time_ms: 2.2\n",
      "    num_steps_sampled: 6470000\n",
      "    num_steps_trained: 6470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.18750575184822083\n",
      "      kl: 0.012136576697230339\n",
      "      policy_loss: 0.0008799934294074774\n",
      "      total_loss: 121.0198974609375\n",
      "      vf_explained_var: 0.9498251080513\n",
      "      vf_loss: 121.0190200805664\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.41812652349472046\n",
      "      kl: 0.016447221860289574\n",
      "      policy_loss: 0.004569536540657282\n",
      "      total_loss: 111.03099060058594\n",
      "      vf_explained_var: 0.9387490749359131\n",
      "      vf_loss: 111.02642822265625\n",
      "    sample_time_ms: 20149.143\n",
      "    update_time_ms: 7.126\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.79362320781371\n",
      "    rl_1: 45.918884793764974\n",
      "  time_since_restore: 15012.907151937485\n",
      "  time_this_iter_s: 23.990561485290527\n",
      "  time_total_s: 15012.907151937485\n",
      "  timestamp: 1550895622\n",
      "  timesteps_since_restore: 6470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6470000\n",
      "  training_iteration: 647\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15012 s, 647 iter, 6470000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-20-46\n",
      "  done: false\n",
      "  episode_len_mean: 105.37\n",
      "  episode_reward_max: 216.55270556219568\n",
      "  episode_reward_mean: 84.4586297695259\n",
      "  episode_reward_min: -169.5301954078992\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 55465\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.056\n",
      "    load_time_ms: 2.215\n",
      "    num_steps_sampled: 6480000\n",
      "    num_steps_trained: 6480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44231078028678894\n",
      "      kl: 0.020648380741477013\n",
      "      policy_loss: 0.005865438841283321\n",
      "      total_loss: 134.22247314453125\n",
      "      vf_explained_var: 0.9583810567855835\n",
      "      vf_loss: 134.21661376953125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6230689287185669\n",
      "      kl: 0.02030344121158123\n",
      "      policy_loss: -0.0001806129585020244\n",
      "      total_loss: 119.9315185546875\n",
      "      vf_explained_var: 0.9490707516670227\n",
      "      vf_loss: 119.93169403076172\n",
      "    sample_time_ms: 20192.785\n",
      "    update_time_ms: 7.384\n",
      "  iterations_since_restore: 648\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.387443149066414\n",
      "    rl_1: 33.07118662045949\n",
      "  time_since_restore: 15036.121593236923\n",
      "  time_this_iter_s: 23.214441299438477\n",
      "  time_total_s: 15036.121593236923\n",
      "  timestamp: 1550895646\n",
      "  timesteps_since_restore: 6480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6480000\n",
      "  training_iteration: 648\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15036 s, 648 iter, 6480000 ts, 84.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-21-09\n",
      "  done: false\n",
      "  episode_len_mean: 101.69\n",
      "  episode_reward_max: 232.11029728364053\n",
      "  episode_reward_mean: 83.09725387919933\n",
      "  episode_reward_min: -153.58334765559033\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 55565\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3096.544\n",
      "    load_time_ms: 2.185\n",
      "    num_steps_sampled: 6490000\n",
      "    num_steps_trained: 6490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5141792893409729\n",
      "      kl: 0.028494039550423622\n",
      "      policy_loss: 0.008213801309466362\n",
      "      total_loss: 210.1242218017578\n",
      "      vf_explained_var: 0.9399583339691162\n",
      "      vf_loss: 210.1160125732422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7178610563278198\n",
      "      kl: 0.028170522302389145\n",
      "      policy_loss: 0.006714643444865942\n",
      "      total_loss: 184.67422485351562\n",
      "      vf_explained_var: 0.929662823677063\n",
      "      vf_loss: 184.66749572753906\n",
      "    sample_time_ms: 20191.002\n",
      "    update_time_ms: 7.205\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.297537968641834\n",
      "    rl_1: 34.799715910557474\n",
      "  time_since_restore: 15059.628051280975\n",
      "  time_this_iter_s: 23.506458044052124\n",
      "  time_total_s: 15059.628051280975\n",
      "  timestamp: 1550895669\n",
      "  timesteps_since_restore: 6490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6490000\n",
      "  training_iteration: 649\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15059 s, 649 iter, 6490000 ts, 83.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-21-33\n",
      "  done: false\n",
      "  episode_len_mean: 107.77\n",
      "  episode_reward_max: 223.91291923944283\n",
      "  episode_reward_mean: 119.14793920826651\n",
      "  episode_reward_min: -158.5297419371241\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 55657\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.506\n",
      "    load_time_ms: 2.228\n",
      "    num_steps_sampled: 6500000\n",
      "    num_steps_trained: 6500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4205421507358551\n",
      "      kl: 0.027101345360279083\n",
      "      policy_loss: 0.004068026784807444\n",
      "      total_loss: 121.33546447753906\n",
      "      vf_explained_var: 0.9467458724975586\n",
      "      vf_loss: 121.33138275146484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.584281861782074\n",
      "      kl: 0.028748227283358574\n",
      "      policy_loss: 0.010482961311936378\n",
      "      total_loss: 109.91718292236328\n",
      "      vf_explained_var: 0.9394199848175049\n",
      "      vf_loss: 109.90670013427734\n",
      "    sample_time_ms: 20215.999\n",
      "    update_time_ms: 7.284\n",
      "  iterations_since_restore: 650\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.81499386233455\n",
      "    rl_1: 50.332945345931975\n",
      "  time_since_restore: 15082.801372289658\n",
      "  time_this_iter_s: 23.17332100868225\n",
      "  time_total_s: 15082.801372289658\n",
      "  timestamp: 1550895693\n",
      "  timesteps_since_restore: 6500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6500000\n",
      "  training_iteration: 650\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15082 s, 650 iter, 6500000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-21-56\n",
      "  done: false\n",
      "  episode_len_mean: 111.84\n",
      "  episode_reward_max: 219.73450427451067\n",
      "  episode_reward_mean: 115.85360209865493\n",
      "  episode_reward_min: -164.34568517465675\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 55746\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.372\n",
      "    load_time_ms: 2.224\n",
      "    num_steps_sampled: 6510000\n",
      "    num_steps_trained: 6510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.37655383348464966\n",
      "      kl: 0.035975851118564606\n",
      "      policy_loss: 0.012280896306037903\n",
      "      total_loss: 112.20967102050781\n",
      "      vf_explained_var: 0.95733243227005\n",
      "      vf_loss: 112.19738006591797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5864604115486145\n",
      "      kl: 0.022321542724967003\n",
      "      policy_loss: 0.0013169199228286743\n",
      "      total_loss: 104.50079345703125\n",
      "      vf_explained_var: 0.9450036287307739\n",
      "      vf_loss: 104.49948120117188\n",
      "    sample_time_ms: 20234.185\n",
      "    update_time_ms: 7.135\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.16706551673661\n",
      "    rl_1: 47.686536581918354\n",
      "  time_since_restore: 15105.944403886795\n",
      "  time_this_iter_s: 23.14303159713745\n",
      "  time_total_s: 15105.944403886795\n",
      "  timestamp: 1550895716\n",
      "  timesteps_since_restore: 6510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6510000\n",
      "  training_iteration: 651\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15105 s, 651 iter, 6510000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-22-19\n",
      "  done: false\n",
      "  episode_len_mean: 112.61\n",
      "  episode_reward_max: 223.49917888800468\n",
      "  episode_reward_mean: 104.94837281717687\n",
      "  episode_reward_min: -141.4867892047494\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 55834\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.852\n",
      "    load_time_ms: 2.234\n",
      "    num_steps_sampled: 6520000\n",
      "    num_steps_trained: 6520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.34015077352523804\n",
      "      kl: 0.017429174855351448\n",
      "      policy_loss: 0.0021957033313810825\n",
      "      total_loss: 143.8837127685547\n",
      "      vf_explained_var: 0.9466842412948608\n",
      "      vf_loss: 143.8815460205078\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5512012839317322\n",
      "      kl: 0.016044482588768005\n",
      "      policy_loss: -0.0017693090485408902\n",
      "      total_loss: 134.7484893798828\n",
      "      vf_explained_var: 0.9309993386268616\n",
      "      vf_loss: 134.750244140625\n",
      "    sample_time_ms: 20278.94\n",
      "    update_time_ms: 7.089\n",
      "  iterations_since_restore: 652\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.21496678369084\n",
      "    rl_1: 42.73340603348599\n",
      "  time_since_restore: 15129.449241876602\n",
      "  time_this_iter_s: 23.50483798980713\n",
      "  time_total_s: 15129.449241876602\n",
      "  timestamp: 1550895739\n",
      "  timesteps_since_restore: 6520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6520000\n",
      "  training_iteration: 652\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15129 s, 652 iter, 6520000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-22-42\n",
      "  done: false\n",
      "  episode_len_mean: 112.74\n",
      "  episode_reward_max: 229.32598793517036\n",
      "  episode_reward_mean: 99.68010028263728\n",
      "  episode_reward_min: -174.11070112394458\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 55924\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.018\n",
      "    load_time_ms: 2.3\n",
      "    num_steps_sampled: 6530000\n",
      "    num_steps_trained: 6530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3185727000236511\n",
      "      kl: 0.03014472872018814\n",
      "      policy_loss: 0.006816093809902668\n",
      "      total_loss: 143.14450073242188\n",
      "      vf_explained_var: 0.9519211053848267\n",
      "      vf_loss: 143.13768005371094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5191669464111328\n",
      "      kl: 0.015806179493665695\n",
      "      policy_loss: 0.0009155580773949623\n",
      "      total_loss: 129.3417510986328\n",
      "      vf_explained_var: 0.9445900321006775\n",
      "      vf_loss: 129.3408203125\n",
      "    sample_time_ms: 20250.386\n",
      "    update_time_ms: 7.079\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.1877124170197\n",
      "    rl_1: 41.49238786561759\n",
      "  time_since_restore: 15152.308968782425\n",
      "  time_this_iter_s: 22.859726905822754\n",
      "  time_total_s: 15152.308968782425\n",
      "  timestamp: 1550895762\n",
      "  timesteps_since_restore: 6530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6530000\n",
      "  training_iteration: 653\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15152 s, 653 iter, 6530000 ts, 99.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-23-05\n",
      "  done: false\n",
      "  episode_len_mean: 115.42\n",
      "  episode_reward_max: 221.47804964045415\n",
      "  episode_reward_mean: 99.4588793015457\n",
      "  episode_reward_min: -154.5232403255307\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 56008\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.736\n",
      "    load_time_ms: 2.337\n",
      "    num_steps_sampled: 6540000\n",
      "    num_steps_trained: 6540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.2917313873767853\n",
      "      kl: 0.015444714576005936\n",
      "      policy_loss: 0.002843324327841401\n",
      "      total_loss: 122.66609954833984\n",
      "      vf_explained_var: 0.943158745765686\n",
      "      vf_loss: 122.66327667236328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5113563537597656\n",
      "      kl: 0.01967063546180725\n",
      "      policy_loss: 0.003175002057105303\n",
      "      total_loss: 105.9423828125\n",
      "      vf_explained_var: 0.929144024848938\n",
      "      vf_loss: 105.93921661376953\n",
      "    sample_time_ms: 20193.679\n",
      "    update_time_ms: 7.118\n",
      "  iterations_since_restore: 654\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.02085292513336\n",
      "    rl_1: 38.438026376412346\n",
      "  time_since_restore: 15175.147691488266\n",
      "  time_this_iter_s: 22.838722705841064\n",
      "  time_total_s: 15175.147691488266\n",
      "  timestamp: 1550895785\n",
      "  timesteps_since_restore: 6540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6540000\n",
      "  training_iteration: 654\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15175 s, 654 iter, 6540000 ts, 99.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-23-28\n",
      "  done: false\n",
      "  episode_len_mean: 109.55\n",
      "  episode_reward_max: 220.57742836861956\n",
      "  episode_reward_mean: 107.12161288009304\n",
      "  episode_reward_min: -153.69680437710656\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 56100\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.215\n",
      "    load_time_ms: 2.316\n",
      "    num_steps_sampled: 6550000\n",
      "    num_steps_trained: 6550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3471585214138031\n",
      "      kl: 0.015033717267215252\n",
      "      policy_loss: -0.0007921855431050062\n",
      "      total_loss: 183.36614990234375\n",
      "      vf_explained_var: 0.9294512867927551\n",
      "      vf_loss: 183.36695861816406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5537825226783752\n",
      "      kl: 0.02845146134495735\n",
      "      policy_loss: 0.013752803206443787\n",
      "      total_loss: 166.4969940185547\n",
      "      vf_explained_var: 0.9160637259483337\n",
      "      vf_loss: 166.48324584960938\n",
      "    sample_time_ms: 20160.678\n",
      "    update_time_ms: 6.982\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.828279979004556\n",
      "    rl_1: 44.29333290108846\n",
      "  time_since_restore: 15198.3308198452\n",
      "  time_this_iter_s: 23.183128356933594\n",
      "  time_total_s: 15198.3308198452\n",
      "  timestamp: 1550895808\n",
      "  timesteps_since_restore: 6550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6550000\n",
      "  training_iteration: 655\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15198 s, 655 iter, 6550000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-23-52\n",
      "  done: false\n",
      "  episode_len_mean: 108.6\n",
      "  episode_reward_max: 219.1282392803152\n",
      "  episode_reward_mean: 126.9515751963291\n",
      "  episode_reward_min: -178.75738577406634\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 56192\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.797\n",
      "    load_time_ms: 2.407\n",
      "    num_steps_sampled: 6560000\n",
      "    num_steps_trained: 6560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3836783766746521\n",
      "      kl: 0.020024484023451805\n",
      "      policy_loss: 0.0004897675244137645\n",
      "      total_loss: 142.61380004882812\n",
      "      vf_explained_var: 0.9376235604286194\n",
      "      vf_loss: 142.61331176757812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6133909821510315\n",
      "      kl: 0.020064515992999077\n",
      "      policy_loss: 0.0054423571564257145\n",
      "      total_loss: 135.6213836669922\n",
      "      vf_explained_var: 0.9254803657531738\n",
      "      vf_loss: 135.61593627929688\n",
      "    sample_time_ms: 20169.725\n",
      "    update_time_ms: 6.773\n",
      "  iterations_since_restore: 656\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.09263145857831\n",
      "    rl_1: 54.858943737750806\n",
      "  time_since_restore: 15221.648696660995\n",
      "  time_this_iter_s: 23.3178768157959\n",
      "  time_total_s: 15221.648696660995\n",
      "  timestamp: 1550895832\n",
      "  timesteps_since_restore: 6560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6560000\n",
      "  training_iteration: 656\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15221 s, 656 iter, 6560000 ts, 127 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-24-15\n",
      "  done: false\n",
      "  episode_len_mean: 113.3\n",
      "  episode_reward_max: 216.51273365923714\n",
      "  episode_reward_mean: 114.78454430114789\n",
      "  episode_reward_min: -169.13912665732553\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 56281\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.968\n",
      "    load_time_ms: 2.383\n",
      "    num_steps_sampled: 6570000\n",
      "    num_steps_trained: 6570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.27627745270729065\n",
      "      kl: 0.034509435296058655\n",
      "      policy_loss: 0.010940813459455967\n",
      "      total_loss: 114.7156982421875\n",
      "      vf_explained_var: 0.9553927183151245\n",
      "      vf_loss: 114.70476531982422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5371954441070557\n",
      "      kl: 0.015181655995547771\n",
      "      policy_loss: 0.0007573130424134433\n",
      "      total_loss: 111.52070617675781\n",
      "      vf_explained_var: 0.9430392384529114\n",
      "      vf_loss: 111.51994323730469\n",
      "    sample_time_ms: 20121.482\n",
      "    update_time_ms: 7.587\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.05741786708023\n",
      "    rl_1: 48.72712643406764\n",
      "  time_since_restore: 15245.235118865967\n",
      "  time_this_iter_s: 23.586422204971313\n",
      "  time_total_s: 15245.235118865967\n",
      "  timestamp: 1550895855\n",
      "  timesteps_since_restore: 6570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6570000\n",
      "  training_iteration: 657\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15245 s, 657 iter, 6570000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-24-39\n",
      "  done: false\n",
      "  episode_len_mean: 111.69\n",
      "  episode_reward_max: 221.56898909803195\n",
      "  episode_reward_mean: 116.65981250367226\n",
      "  episode_reward_min: -161.96971259691745\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 56370\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3101.977\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 6580000\n",
      "    num_steps_trained: 6580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3171974718570709\n",
      "      kl: 0.016473259776830673\n",
      "      policy_loss: 0.0009461733279749751\n",
      "      total_loss: 132.42483520507812\n",
      "      vf_explained_var: 0.9426843523979187\n",
      "      vf_loss: 132.42388916015625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5617214441299438\n",
      "      kl: 0.01736464723944664\n",
      "      policy_loss: 0.004596911836415529\n",
      "      total_loss: 119.07121276855469\n",
      "      vf_explained_var: 0.9364644289016724\n",
      "      vf_loss: 119.06660461425781\n",
      "    sample_time_ms: 20123.157\n",
      "    update_time_ms: 7.373\n",
      "  iterations_since_restore: 658\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.87463075769969\n",
      "    rl_1: 49.785181745972565\n",
      "  time_since_restore: 15268.655099630356\n",
      "  time_this_iter_s: 23.419980764389038\n",
      "  time_total_s: 15268.655099630356\n",
      "  timestamp: 1550895879\n",
      "  timesteps_since_restore: 6580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6580000\n",
      "  training_iteration: 658\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15268 s, 658 iter, 6580000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-25-02\n",
      "  done: false\n",
      "  episode_len_mean: 109.22\n",
      "  episode_reward_max: 218.95616724363168\n",
      "  episode_reward_mean: 121.26660753959867\n",
      "  episode_reward_min: -138.97163646356722\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 56461\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.602\n",
      "    load_time_ms: 2.518\n",
      "    num_steps_sampled: 6590000\n",
      "    num_steps_trained: 6590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44691094756126404\n",
      "      kl: 0.022862358018755913\n",
      "      policy_loss: 0.0011099643306806684\n",
      "      total_loss: 130.549560546875\n",
      "      vf_explained_var: 0.9480578899383545\n",
      "      vf_loss: 130.54844665527344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6672652959823608\n",
      "      kl: 0.01646720990538597\n",
      "      policy_loss: 0.0022442527115345\n",
      "      total_loss: 122.26457214355469\n",
      "      vf_explained_var: 0.9327113628387451\n",
      "      vf_loss: 122.26232147216797\n",
      "    sample_time_ms: 20132.018\n",
      "    update_time_ms: 7.285\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.56243421138667\n",
      "    rl_1: 51.70417332821203\n",
      "  time_since_restore: 15291.995330095291\n",
      "  time_this_iter_s: 23.340230464935303\n",
      "  time_total_s: 15291.995330095291\n",
      "  timestamp: 1550895902\n",
      "  timesteps_since_restore: 6590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6590000\n",
      "  training_iteration: 659\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15291 s, 659 iter, 6590000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-25-26\n",
      "  done: false\n",
      "  episode_len_mean: 115.44\n",
      "  episode_reward_max: 213.22290929032977\n",
      "  episode_reward_mean: 110.26964727191371\n",
      "  episode_reward_min: -172.9834858526171\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 56546\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.654\n",
      "    load_time_ms: 2.445\n",
      "    num_steps_sampled: 6600000\n",
      "    num_steps_trained: 6600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3000338077545166\n",
      "      kl: 0.01569190062582493\n",
      "      policy_loss: 0.004567583557218313\n",
      "      total_loss: 116.83183288574219\n",
      "      vf_explained_var: 0.9463037252426147\n",
      "      vf_loss: 116.82726287841797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5515999794006348\n",
      "      kl: 0.01769004575908184\n",
      "      policy_loss: 0.0013138947542756796\n",
      "      total_loss: 113.69976043701172\n",
      "      vf_explained_var: 0.9290107488632202\n",
      "      vf_loss: 113.69843292236328\n",
      "    sample_time_ms: 20200.293\n",
      "    update_time_ms: 7.404\n",
      "  iterations_since_restore: 660\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.93530960252403\n",
      "    rl_1: 45.33433766938969\n",
      "  time_since_restore: 15315.84870505333\n",
      "  time_this_iter_s: 23.85337495803833\n",
      "  time_total_s: 15315.84870505333\n",
      "  timestamp: 1550895926\n",
      "  timesteps_since_restore: 6600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6600000\n",
      "  training_iteration: 660\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15315 s, 660 iter, 6600000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-25-49\n",
      "  done: false\n",
      "  episode_len_mean: 109.4\n",
      "  episode_reward_max: 223.23704642767044\n",
      "  episode_reward_mean: 116.59833818331457\n",
      "  episode_reward_min: -145.96843666107122\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 56638\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.367\n",
      "    load_time_ms: 2.51\n",
      "    num_steps_sampled: 6610000\n",
      "    num_steps_trained: 6610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4053504168987274\n",
      "      kl: 0.02591962367296219\n",
      "      policy_loss: 0.004923315718770027\n",
      "      total_loss: 146.6511993408203\n",
      "      vf_explained_var: 0.93602055311203\n",
      "      vf_loss: 146.6462860107422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6402693390846252\n",
      "      kl: 0.02377799153327942\n",
      "      policy_loss: 0.002512761391699314\n",
      "      total_loss: 141.90904235839844\n",
      "      vf_explained_var: 0.9182583689689636\n",
      "      vf_loss: 141.9065399169922\n",
      "    sample_time_ms: 20190.825\n",
      "    update_time_ms: 7.501\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.61355248495356\n",
      "    rl_1: 48.98478569836101\n",
      "  time_since_restore: 15338.905920028687\n",
      "  time_this_iter_s: 23.057214975357056\n",
      "  time_total_s: 15338.905920028687\n",
      "  timestamp: 1550895949\n",
      "  timesteps_since_restore: 6610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6610000\n",
      "  training_iteration: 661\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15338 s, 661 iter, 6610000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-26-13\n",
      "  done: false\n",
      "  episode_len_mean: 109.84\n",
      "  episode_reward_max: 214.27155164534776\n",
      "  episode_reward_mean: 102.50875604803059\n",
      "  episode_reward_min: -153.2509422632096\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 56729\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.255\n",
      "    load_time_ms: 2.496\n",
      "    num_steps_sampled: 6620000\n",
      "    num_steps_trained: 6620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3681960105895996\n",
      "      kl: 0.020681198686361313\n",
      "      policy_loss: 0.005109218414872885\n",
      "      total_loss: 139.56993103027344\n",
      "      vf_explained_var: 0.9479070901870728\n",
      "      vf_loss: 139.56478881835938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5694945454597473\n",
      "      kl: 0.023909376934170723\n",
      "      policy_loss: 0.004793486092239618\n",
      "      total_loss: 119.10664367675781\n",
      "      vf_explained_var: 0.9420130848884583\n",
      "      vf_loss: 119.10183715820312\n",
      "    sample_time_ms: 20173.746\n",
      "    update_time_ms: 7.601\n",
      "  iterations_since_restore: 662\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.02132600543593\n",
      "    rl_1: 41.48743004259468\n",
      "  time_since_restore: 15362.377825737\n",
      "  time_this_iter_s: 23.47190570831299\n",
      "  time_total_s: 15362.377825737\n",
      "  timestamp: 1550895973\n",
      "  timesteps_since_restore: 6620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6620000\n",
      "  training_iteration: 662\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15362 s, 662 iter, 6620000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-26-35\n",
      "  done: false\n",
      "  episode_len_mean: 112.74\n",
      "  episode_reward_max: 232.47660646578018\n",
      "  episode_reward_mean: 117.23988267254452\n",
      "  episode_reward_min: -157.87010127987503\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 56819\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.729\n",
      "    load_time_ms: 2.476\n",
      "    num_steps_sampled: 6630000\n",
      "    num_steps_trained: 6630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.37860146164894104\n",
      "      kl: 0.016595246270298958\n",
      "      policy_loss: 0.0037340670824050903\n",
      "      total_loss: 171.3406982421875\n",
      "      vf_explained_var: 0.9258520603179932\n",
      "      vf_loss: 171.3369598388672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5911405086517334\n",
      "      kl: 0.023102303966879845\n",
      "      policy_loss: 0.006679867394268513\n",
      "      total_loss: 158.2976531982422\n",
      "      vf_explained_var: 0.9109194874763489\n",
      "      vf_loss: 158.29098510742188\n",
      "    sample_time_ms: 20166.298\n",
      "    update_time_ms: 7.565\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.4772690594102\n",
      "    rl_1: 48.762613613134306\n",
      "  time_since_restore: 15385.166969060898\n",
      "  time_this_iter_s: 22.789143323898315\n",
      "  time_total_s: 15385.166969060898\n",
      "  timestamp: 1550895995\n",
      "  timesteps_since_restore: 6630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6630000\n",
      "  training_iteration: 663\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15385 s, 663 iter, 6630000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-26-59\n",
      "  done: false\n",
      "  episode_len_mean: 107.85\n",
      "  episode_reward_max: 217.76212967455953\n",
      "  episode_reward_mean: 113.8445151169203\n",
      "  episode_reward_min: -174.8192384742005\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 56912\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.923\n",
      "    load_time_ms: 2.519\n",
      "    num_steps_sampled: 6640000\n",
      "    num_steps_trained: 6640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38411325216293335\n",
      "      kl: 0.023261651396751404\n",
      "      policy_loss: 0.0034500372130423784\n",
      "      total_loss: 131.53399658203125\n",
      "      vf_explained_var: 0.945586085319519\n",
      "      vf_loss: 131.530517578125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5972797870635986\n",
      "      kl: 0.024124247953295708\n",
      "      policy_loss: 0.007591476198285818\n",
      "      total_loss: 116.00859832763672\n",
      "      vf_explained_var: 0.9400826692581177\n",
      "      vf_loss: 116.00101470947266\n",
      "    sample_time_ms: 20250.879\n",
      "    update_time_ms: 7.721\n",
      "  iterations_since_restore: 664\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.37123591394008\n",
      "    rl_1: 48.4732792029802\n",
      "  time_since_restore: 15408.84312748909\n",
      "  time_this_iter_s: 23.67615842819214\n",
      "  time_total_s: 15408.84312748909\n",
      "  timestamp: 1550896019\n",
      "  timesteps_since_restore: 6640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6640000\n",
      "  training_iteration: 664\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15408 s, 664 iter, 6640000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-27-23\n",
      "  done: false\n",
      "  episode_len_mean: 110.72\n",
      "  episode_reward_max: 214.90438124103858\n",
      "  episode_reward_mean: 98.92347378152061\n",
      "  episode_reward_min: -170.39383964354298\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 57001\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.568\n",
      "    load_time_ms: 2.616\n",
      "    num_steps_sampled: 6650000\n",
      "    num_steps_trained: 6650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3152346611022949\n",
      "      kl: 0.026232484728097916\n",
      "      policy_loss: 0.01023201085627079\n",
      "      total_loss: 147.71458435058594\n",
      "      vf_explained_var: 0.943810760974884\n",
      "      vf_loss: 147.704345703125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5869686007499695\n",
      "      kl: 0.019792350009083748\n",
      "      policy_loss: 0.0031590894795954227\n",
      "      total_loss: 139.1640625\n",
      "      vf_explained_var: 0.9302436709403992\n",
      "      vf_loss: 139.16090393066406\n",
      "    sample_time_ms: 20264.361\n",
      "    update_time_ms: 7.84\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.353475150849526\n",
      "    rl_1: 40.569998630671094\n",
      "  time_since_restore: 15432.161790370941\n",
      "  time_this_iter_s: 23.318662881851196\n",
      "  time_total_s: 15432.161790370941\n",
      "  timestamp: 1550896043\n",
      "  timesteps_since_restore: 6650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6650000\n",
      "  training_iteration: 665\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15432 s, 665 iter, 6650000 ts, 98.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-27-46\n",
      "  done: false\n",
      "  episode_len_mean: 112.14\n",
      "  episode_reward_max: 225.14931322798904\n",
      "  episode_reward_mean: 105.57374840583302\n",
      "  episode_reward_min: -154.99987340234378\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 57089\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.258\n",
      "    load_time_ms: 2.538\n",
      "    num_steps_sampled: 6660000\n",
      "    num_steps_trained: 6660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.356625497341156\n",
      "      kl: 0.013036341406404972\n",
      "      policy_loss: 0.0026789135299623013\n",
      "      total_loss: 121.91883087158203\n",
      "      vf_explained_var: 0.94785475730896\n",
      "      vf_loss: 121.91613006591797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6108824014663696\n",
      "      kl: 0.016258640214800835\n",
      "      policy_loss: 0.0021630648989230394\n",
      "      total_loss: 117.57189178466797\n",
      "      vf_explained_var: 0.9339140057563782\n",
      "      vf_loss: 117.5697250366211\n",
      "    sample_time_ms: 20232.837\n",
      "    update_time_ms: 8.23\n",
      "  iterations_since_restore: 666\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.2884122281703\n",
      "    rl_1: 42.28533617766269\n",
      "  time_since_restore: 15455.160545349121\n",
      "  time_this_iter_s: 22.99875497817993\n",
      "  time_total_s: 15455.160545349121\n",
      "  timestamp: 1550896066\n",
      "  timesteps_since_restore: 6660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6660000\n",
      "  training_iteration: 666\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15455 s, 666 iter, 6660000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-28-08\n",
      "  done: false\n",
      "  episode_len_mean: 111.14\n",
      "  episode_reward_max: 217.00399655217277\n",
      "  episode_reward_mean: 117.63375368592796\n",
      "  episode_reward_min: -159.5380884780905\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 57179\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3104.082\n",
      "    load_time_ms: 2.544\n",
      "    num_steps_sampled: 6670000\n",
      "    num_steps_trained: 6670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3637033700942993\n",
      "      kl: 0.023318186402320862\n",
      "      policy_loss: 0.0015230511780828238\n",
      "      total_loss: 96.74739837646484\n",
      "      vf_explained_var: 0.958772599697113\n",
      "      vf_loss: 96.7458724975586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6209717988967896\n",
      "      kl: 0.012064637616276741\n",
      "      policy_loss: 0.0013747388729825616\n",
      "      total_loss: 89.090087890625\n",
      "      vf_explained_var: 0.9481824040412903\n",
      "      vf_loss: 89.08871459960938\n",
      "    sample_time_ms: 20123.659\n",
      "    update_time_ms: 7.357\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.36531324842865\n",
      "    rl_1: 48.26844043749935\n",
      "  time_since_restore: 15477.785926818848\n",
      "  time_this_iter_s: 22.625381469726562\n",
      "  time_total_s: 15477.785926818848\n",
      "  timestamp: 1550896088\n",
      "  timesteps_since_restore: 6670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6670000\n",
      "  training_iteration: 667\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15477 s, 667 iter, 6670000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-28-31\n",
      "  done: false\n",
      "  episode_len_mean: 109.37\n",
      "  episode_reward_max: 227.3664986211348\n",
      "  episode_reward_mean: 91.07608350138221\n",
      "  episode_reward_min: -163.35068366001968\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 57270\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.256\n",
      "    load_time_ms: 2.621\n",
      "    num_steps_sampled: 6680000\n",
      "    num_steps_trained: 6680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3313292860984802\n",
      "      kl: 0.02429044432938099\n",
      "      policy_loss: 0.002525118412449956\n",
      "      total_loss: 179.89581298828125\n",
      "      vf_explained_var: 0.9352030754089355\n",
      "      vf_loss: 179.89328002929688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5767912268638611\n",
      "      kl: 0.04193760082125664\n",
      "      policy_loss: 0.009034978225827217\n",
      "      total_loss: 165.76028442382812\n",
      "      vf_explained_var: 0.9277123808860779\n",
      "      vf_loss: 165.75123596191406\n",
      "    sample_time_ms: 20106.134\n",
      "    update_time_ms: 7.245\n",
      "  iterations_since_restore: 668\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.66527168427725\n",
      "    rl_1: 37.410811817104964\n",
      "  time_since_restore: 15500.824072599411\n",
      "  time_this_iter_s: 23.038145780563354\n",
      "  time_total_s: 15500.824072599411\n",
      "  timestamp: 1550896111\n",
      "  timesteps_since_restore: 6680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6680000\n",
      "  training_iteration: 668\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15500 s, 668 iter, 6680000 ts, 91.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-28-54\n",
      "  done: false\n",
      "  episode_len_mean: 108.85\n",
      "  episode_reward_max: 218.85198684322475\n",
      "  episode_reward_mean: 85.55062243188857\n",
      "  episode_reward_min: -156.8516313091308\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 57360\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.136\n",
      "    load_time_ms: 2.534\n",
      "    num_steps_sampled: 6690000\n",
      "    num_steps_trained: 6690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39207929372787476\n",
      "      kl: 0.0178427342325449\n",
      "      policy_loss: 0.0004466033715289086\n",
      "      total_loss: 125.65751647949219\n",
      "      vf_explained_var: 0.9596126079559326\n",
      "      vf_loss: 125.65707397460938\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6198042631149292\n",
      "      kl: 0.017994292080402374\n",
      "      policy_loss: 0.0003852990048471838\n",
      "      total_loss: 114.5850601196289\n",
      "      vf_explained_var: 0.9499902725219727\n",
      "      vf_loss: 114.58468627929688\n",
      "    sample_time_ms: 20062.713\n",
      "    update_time_ms: 7.248\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.45094653664617\n",
      "    rl_1: 33.0996758952424\n",
      "  time_since_restore: 15523.736218214035\n",
      "  time_this_iter_s: 22.912145614624023\n",
      "  time_total_s: 15523.736218214035\n",
      "  timestamp: 1550896134\n",
      "  timesteps_since_restore: 6690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6690000\n",
      "  training_iteration: 669\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15523 s, 669 iter, 6690000 ts, 85.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-29-18\n",
      "  done: false\n",
      "  episode_len_mean: 111.23\n",
      "  episode_reward_max: 221.68922189988245\n",
      "  episode_reward_mean: 110.39988238476391\n",
      "  episode_reward_min: -147.8815255185603\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 57449\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.217\n",
      "    load_time_ms: 2.539\n",
      "    num_steps_sampled: 6700000\n",
      "    num_steps_trained: 6700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38987261056900024\n",
      "      kl: 0.0398196242749691\n",
      "      policy_loss: 0.003705316223204136\n",
      "      total_loss: 161.04063415527344\n",
      "      vf_explained_var: 0.9370703101158142\n",
      "      vf_loss: 161.0369415283203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6331011056900024\n",
      "      kl: 0.015378479845821857\n",
      "      policy_loss: 0.0015382652636617422\n",
      "      total_loss: 146.8539276123047\n",
      "      vf_explained_var: 0.9268667697906494\n",
      "      vf_loss: 146.85238647460938\n",
      "    sample_time_ms: 20010.025\n",
      "    update_time_ms: 7.408\n",
      "  iterations_since_restore: 670\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.47217130383689\n",
      "    rl_1: 46.927711080927004\n",
      "  time_since_restore: 15547.047288894653\n",
      "  time_this_iter_s: 23.311070680618286\n",
      "  time_total_s: 15547.047288894653\n",
      "  timestamp: 1550896158\n",
      "  timesteps_since_restore: 6700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6700000\n",
      "  training_iteration: 670\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15547 s, 670 iter, 6700000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-29-41\n",
      "  done: false\n",
      "  episode_len_mean: 111.32\n",
      "  episode_reward_max: 213.3597478965623\n",
      "  episode_reward_mean: 109.61402634016503\n",
      "  episode_reward_min: -160.56152190917334\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 57539\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.576\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 6710000\n",
      "    num_steps_trained: 6710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3754211962223053\n",
      "      kl: 0.019727617502212524\n",
      "      policy_loss: 0.005010292399674654\n",
      "      total_loss: 77.42642974853516\n",
      "      vf_explained_var: 0.9690585136413574\n",
      "      vf_loss: 77.42142486572266\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6354947090148926\n",
      "      kl: 0.0167914517223835\n",
      "      policy_loss: 0.00706506846472621\n",
      "      total_loss: 74.87715148925781\n",
      "      vf_explained_var: 0.9633381962776184\n",
      "      vf_loss: 74.87007904052734\n",
      "    sample_time_ms: 20011.396\n",
      "    update_time_ms: 7.404\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.88047952522063\n",
      "    rl_1: 45.73354681494438\n",
      "  time_since_restore: 15570.153428792953\n",
      "  time_this_iter_s: 23.10613989830017\n",
      "  time_total_s: 15570.153428792953\n",
      "  timestamp: 1550896181\n",
      "  timesteps_since_restore: 6710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6710000\n",
      "  training_iteration: 671\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15570 s, 671 iter, 6710000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-30-04\n",
      "  done: false\n",
      "  episode_len_mean: 103.97\n",
      "  episode_reward_max: 228.84587142559133\n",
      "  episode_reward_mean: 105.69756239670329\n",
      "  episode_reward_min: -156.31287476878202\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 57636\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.363\n",
      "    load_time_ms: 2.553\n",
      "    num_steps_sampled: 6720000\n",
      "    num_steps_trained: 6720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.520427405834198\n",
      "      kl: 0.029108187183737755\n",
      "      policy_loss: 0.005504212807863951\n",
      "      total_loss: 262.73199462890625\n",
      "      vf_explained_var: 0.9060617089271545\n",
      "      vf_loss: 262.72650146484375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7620458602905273\n",
      "      kl: 0.01620628498494625\n",
      "      policy_loss: 0.0013045297237113118\n",
      "      total_loss: 233.3367462158203\n",
      "      vf_explained_var: 0.898675262928009\n",
      "      vf_loss: 233.33541870117188\n",
      "    sample_time_ms: 19945.798\n",
      "    update_time_ms: 7.307\n",
      "  iterations_since_restore: 672\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.89499849641856\n",
      "    rl_1: 45.802563900284724\n",
      "  time_since_restore: 15592.825628519058\n",
      "  time_this_iter_s: 22.672199726104736\n",
      "  time_total_s: 15592.825628519058\n",
      "  timestamp: 1550896204\n",
      "  timesteps_since_restore: 6720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6720000\n",
      "  training_iteration: 672\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15592 s, 672 iter, 6720000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-30-27\n",
      "  done: false\n",
      "  episode_len_mean: 105.4\n",
      "  episode_reward_max: 218.8672111012151\n",
      "  episode_reward_mean: 119.29029082536063\n",
      "  episode_reward_min: -175.5675385698443\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 57731\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.022\n",
      "    load_time_ms: 2.524\n",
      "    num_steps_sampled: 6730000\n",
      "    num_steps_trained: 6730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4646244943141937\n",
      "      kl: 0.02103297971189022\n",
      "      policy_loss: 0.00350772263482213\n",
      "      total_loss: 200.30715942382812\n",
      "      vf_explained_var: 0.9151359796524048\n",
      "      vf_loss: 200.30368041992188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7196177244186401\n",
      "      kl: 0.01605908013880253\n",
      "      policy_loss: 0.003525852458551526\n",
      "      total_loss: 187.3713836669922\n",
      "      vf_explained_var: 0.9001861214637756\n",
      "      vf_loss: 187.3678741455078\n",
      "    sample_time_ms: 19975.738\n",
      "    update_time_ms: 7.337\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.25914777887216\n",
      "    rl_1: 52.03114304648846\n",
      "  time_since_restore: 15615.942921638489\n",
      "  time_this_iter_s: 23.117293119430542\n",
      "  time_total_s: 15615.942921638489\n",
      "  timestamp: 1550896227\n",
      "  timesteps_since_restore: 6730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6730000\n",
      "  training_iteration: 673\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15615 s, 673 iter, 6730000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-30-50\n",
      "  done: false\n",
      "  episode_len_mean: 111.42\n",
      "  episode_reward_max: 217.65184802117176\n",
      "  episode_reward_mean: 118.35387771154065\n",
      "  episode_reward_min: -175.5675385698443\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 57820\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.845\n",
      "    load_time_ms: 2.444\n",
      "    num_steps_sampled: 6740000\n",
      "    num_steps_trained: 6740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39958587288856506\n",
      "      kl: 0.01845342293381691\n",
      "      policy_loss: 0.0035828638356179\n",
      "      total_loss: 115.21051025390625\n",
      "      vf_explained_var: 0.9464371800422668\n",
      "      vf_loss: 115.20695495605469\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6437853574752808\n",
      "      kl: 0.018712898716330528\n",
      "      policy_loss: 0.0024075841065496206\n",
      "      total_loss: 108.19290924072266\n",
      "      vf_explained_var: 0.9369193911552429\n",
      "      vf_loss: 108.19049072265625\n",
      "    sample_time_ms: 19962.842\n",
      "    update_time_ms: 7.254\n",
      "  iterations_since_restore: 674\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.11894727770142\n",
      "    rl_1: 50.23493043383921\n",
      "  time_since_restore: 15639.48777461052\n",
      "  time_this_iter_s: 23.54485297203064\n",
      "  time_total_s: 15639.48777461052\n",
      "  timestamp: 1550896250\n",
      "  timesteps_since_restore: 6740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6740000\n",
      "  training_iteration: 674\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15639 s, 674 iter, 6740000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 113.96\n",
      "  episode_reward_max: 214.05351573819237\n",
      "  episode_reward_mean: 109.95860950457505\n",
      "  episode_reward_min: -174.84316063691463\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 57908\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.242\n",
      "    load_time_ms: 2.34\n",
      "    num_steps_sampled: 6750000\n",
      "    num_steps_trained: 6750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4424079358577728\n",
      "      kl: 0.02178829535841942\n",
      "      policy_loss: 0.005041111260652542\n",
      "      total_loss: 137.7229461669922\n",
      "      vf_explained_var: 0.9460029602050781\n",
      "      vf_loss: 137.71791076660156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6596242189407349\n",
      "      kl: 0.01778770051896572\n",
      "      policy_loss: 0.0027952869422733784\n",
      "      total_loss: 122.34795379638672\n",
      "      vf_explained_var: 0.937178373336792\n",
      "      vf_loss: 122.34517669677734\n",
      "    sample_time_ms: 19933.919\n",
      "    update_time_ms: 7.237\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.83749689159623\n",
      "    rl_1: 44.12111261297881\n",
      "  time_since_restore: 15662.496008872986\n",
      "  time_this_iter_s: 23.00823426246643\n",
      "  time_total_s: 15662.496008872986\n",
      "  timestamp: 1550896273\n",
      "  timesteps_since_restore: 6750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6750000\n",
      "  training_iteration: 675\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15662 s, 675 iter, 6750000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-31-37\n",
      "  done: false\n",
      "  episode_len_mean: 114.19\n",
      "  episode_reward_max: 232.97865788311393\n",
      "  episode_reward_mean: 114.29107911153505\n",
      "  episode_reward_min: -174.84316063691463\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 57995\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.652\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 6760000\n",
      "    num_steps_trained: 6760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.40036630630493164\n",
      "      kl: 0.01462073065340519\n",
      "      policy_loss: 0.001274891197681427\n",
      "      total_loss: 119.57267761230469\n",
      "      vf_explained_var: 0.943252682685852\n",
      "      vf_loss: 119.57140350341797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6406514644622803\n",
      "      kl: 0.02467246726155281\n",
      "      policy_loss: 0.0032671375665813684\n",
      "      total_loss: 113.15171813964844\n",
      "      vf_explained_var: 0.9306849241256714\n",
      "      vf_loss: 113.14845275878906\n",
      "    sample_time_ms: 19974.306\n",
      "    update_time_ms: 6.894\n",
      "  iterations_since_restore: 676\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.89227138444068\n",
      "    rl_1: 47.39880772709438\n",
      "  time_since_restore: 15685.983552455902\n",
      "  time_this_iter_s: 23.48754358291626\n",
      "  time_total_s: 15685.983552455902\n",
      "  timestamp: 1550896297\n",
      "  timesteps_since_restore: 6760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6760000\n",
      "  training_iteration: 676\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15685 s, 676 iter, 6760000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-32-00\n",
      "  done: false\n",
      "  episode_len_mean: 112.14\n",
      "  episode_reward_max: 231.09409918729162\n",
      "  episode_reward_mean: 132.27635616845274\n",
      "  episode_reward_min: -139.89378520850374\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 58085\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3057.509\n",
      "    load_time_ms: 2.406\n",
      "    num_steps_sampled: 6770000\n",
      "    num_steps_trained: 6770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.41958877444267273\n",
      "      kl: 0.013724691234529018\n",
      "      policy_loss: -0.0005203056498430669\n",
      "      total_loss: 95.1268081665039\n",
      "      vf_explained_var: 0.9530196785926819\n",
      "      vf_loss: 95.1273422241211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6677190661430359\n",
      "      kl: 0.019052395597100258\n",
      "      policy_loss: -0.0009648167761042714\n",
      "      total_loss: 95.14283752441406\n",
      "      vf_explained_var: 0.9416785836219788\n",
      "      vf_loss: 95.143798828125\n",
      "    sample_time_ms: 20017.022\n",
      "    update_time_ms: 7.116\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.38410578983945\n",
      "    rl_1: 57.89225037861329\n",
      "  time_since_restore: 15708.808280229568\n",
      "  time_this_iter_s: 22.824727773666382\n",
      "  time_total_s: 15708.808280229568\n",
      "  timestamp: 1550896320\n",
      "  timesteps_since_restore: 6770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6770000\n",
      "  training_iteration: 677\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15708 s, 677 iter, 6770000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-32-23\n",
      "  done: false\n",
      "  episode_len_mean: 113.22\n",
      "  episode_reward_max: 223.01335994487823\n",
      "  episode_reward_mean: 104.8921654144359\n",
      "  episode_reward_min: -164.72486744340378\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 58173\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3059.001\n",
      "    load_time_ms: 2.311\n",
      "    num_steps_sampled: 6780000\n",
      "    num_steps_trained: 6780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3526618480682373\n",
      "      kl: 1.9853785037994385\n",
      "      policy_loss: 0.06620398908853531\n",
      "      total_loss: 123.35546875\n",
      "      vf_explained_var: 0.9470466375350952\n",
      "      vf_loss: 123.28927612304688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6274382472038269\n",
      "      kl: 0.019242361187934875\n",
      "      policy_loss: 0.008328504860401154\n",
      "      total_loss: 118.37293243408203\n",
      "      vf_explained_var: 0.933933675289154\n",
      "      vf_loss: 118.36458587646484\n",
      "    sample_time_ms: 20020.953\n",
      "    update_time_ms: 7.18\n",
      "  iterations_since_restore: 678\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.34093236910469\n",
      "    rl_1: 42.55123304533121\n",
      "  time_since_restore: 15731.896379709244\n",
      "  time_this_iter_s: 23.088099479675293\n",
      "  time_total_s: 15731.896379709244\n",
      "  timestamp: 1550896343\n",
      "  timesteps_since_restore: 6780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6780000\n",
      "  training_iteration: 678\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15731 s, 678 iter, 6780000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-32-46\n",
      "  done: false\n",
      "  episode_len_mean: 108.33\n",
      "  episode_reward_max: 220.81149458046355\n",
      "  episode_reward_mean: 118.5507091186207\n",
      "  episode_reward_min: -166.73639129879308\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 58265\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3060.686\n",
      "    load_time_ms: 2.256\n",
      "    num_steps_sampled: 6790000\n",
      "    num_steps_trained: 6790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5064274668693542\n",
      "      kl: 0.030950041487812996\n",
      "      policy_loss: 0.006599922198802233\n",
      "      total_loss: 127.65689849853516\n",
      "      vf_explained_var: 0.9504390358924866\n",
      "      vf_loss: 127.6502914428711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7409582734107971\n",
      "      kl: 0.01892823539674282\n",
      "      policy_loss: 0.0038345307111740112\n",
      "      total_loss: 124.61449432373047\n",
      "      vf_explained_var: 0.9355725049972534\n",
      "      vf_loss: 124.61066436767578\n",
      "    sample_time_ms: 20046.131\n",
      "    update_time_ms: 7.144\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.44911965090198\n",
      "    rl_1: 50.10158946771873\n",
      "  time_since_restore: 15755.076852798462\n",
      "  time_this_iter_s: 23.18047308921814\n",
      "  time_total_s: 15755.076852798462\n",
      "  timestamp: 1550896366\n",
      "  timesteps_since_restore: 6790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6790000\n",
      "  training_iteration: 679\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15755 s, 679 iter, 6790000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-33-09\n",
      "  done: false\n",
      "  episode_len_mean: 108.03\n",
      "  episode_reward_max: 227.07777847428443\n",
      "  episode_reward_mean: 128.32020159147112\n",
      "  episode_reward_min: -158.6226336998447\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 58359\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.627\n",
      "    load_time_ms: 2.276\n",
      "    num_steps_sampled: 6800000\n",
      "    num_steps_trained: 6800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5388298630714417\n",
      "      kl: 0.034248556941747665\n",
      "      policy_loss: 0.008359664119780064\n",
      "      total_loss: 117.55732727050781\n",
      "      vf_explained_var: 0.9530078172683716\n",
      "      vf_loss: 117.54894256591797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7557366490364075\n",
      "      kl: 0.02473427914083004\n",
      "      policy_loss: 0.008572835475206375\n",
      "      total_loss: 108.66212463378906\n",
      "      vf_explained_var: 0.9442857503890991\n",
      "      vf_loss: 108.65351867675781\n",
      "    sample_time_ms: 19940.903\n",
      "    update_time_ms: 6.739\n",
      "  iterations_since_restore: 680\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 73.06626345501415\n",
      "    rl_1: 55.25393813645699\n",
      "  time_since_restore: 15777.499073982239\n",
      "  time_this_iter_s: 22.422221183776855\n",
      "  time_total_s: 15777.499073982239\n",
      "  timestamp: 1550896389\n",
      "  timesteps_since_restore: 6800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6800000\n",
      "  training_iteration: 680\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15777 s, 680 iter, 6800000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-33-31\n",
      "  done: false\n",
      "  episode_len_mean: 115.98\n",
      "  episode_reward_max: 216.39136322329819\n",
      "  episode_reward_mean: 108.00721568054573\n",
      "  episode_reward_min: -173.618284648275\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 58444\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.174\n",
      "    load_time_ms: 2.305\n",
      "    num_steps_sampled: 6810000\n",
      "    num_steps_trained: 6810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3300777077674866\n",
      "      kl: 0.023540833964943886\n",
      "      policy_loss: 0.01051395945250988\n",
      "      total_loss: 118.74312591552734\n",
      "      vf_explained_var: 0.9511619806289673\n",
      "      vf_loss: 118.73262023925781\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.604619562625885\n",
      "      kl: 0.16590136289596558\n",
      "      policy_loss: 0.029605837538838387\n",
      "      total_loss: 109.94904327392578\n",
      "      vf_explained_var: 0.9392299056053162\n",
      "      vf_loss: 109.9194107055664\n",
      "    sample_time_ms: 19889.642\n",
      "    update_time_ms: 6.777\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.10726544588384\n",
      "    rl_1: 43.8999502346619\n",
      "  time_since_restore: 15800.067867040634\n",
      "  time_this_iter_s: 22.568793058395386\n",
      "  time_total_s: 15800.067867040634\n",
      "  timestamp: 1550896411\n",
      "  timesteps_since_restore: 6810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6810000\n",
      "  training_iteration: 681\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15800 s, 681 iter, 6810000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-33-55\n",
      "  done: false\n",
      "  episode_len_mean: 111.93\n",
      "  episode_reward_max: 221.68617355145867\n",
      "  episode_reward_mean: 107.34704647642685\n",
      "  episode_reward_min: -144.93676640310576\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 58534\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.814\n",
      "    load_time_ms: 2.295\n",
      "    num_steps_sampled: 6820000\n",
      "    num_steps_trained: 6820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43816956877708435\n",
      "      kl: 0.009935573674738407\n",
      "      policy_loss: 0.003546628402546048\n",
      "      total_loss: 187.8341064453125\n",
      "      vf_explained_var: 0.9261781573295593\n",
      "      vf_loss: 187.83056640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7201636433601379\n",
      "      kl: 0.0209630336612463\n",
      "      policy_loss: 0.003155321814119816\n",
      "      total_loss: 173.1117706298828\n",
      "      vf_explained_var: 0.909130871295929\n",
      "      vf_loss: 173.10862731933594\n",
      "    sample_time_ms: 19952.256\n",
      "    update_time_ms: 6.814\n",
      "  iterations_since_restore: 682\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.507802391836506\n",
      "    rl_1: 43.83924408459033\n",
      "  time_since_restore: 15823.374682426453\n",
      "  time_this_iter_s: 23.30681538581848\n",
      "  time_total_s: 15823.374682426453\n",
      "  timestamp: 1550896435\n",
      "  timesteps_since_restore: 6820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6820000\n",
      "  training_iteration: 682\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15823 s, 682 iter, 6820000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-34-18\n",
      "  done: false\n",
      "  episode_len_mean: 114.15\n",
      "  episode_reward_max: 222.12024557042042\n",
      "  episode_reward_mean: 93.35241664404282\n",
      "  episode_reward_min: -172.18138776647277\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 58620\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.82\n",
      "    load_time_ms: 2.27\n",
      "    num_steps_sampled: 6830000\n",
      "    num_steps_trained: 6830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3157361149787903\n",
      "      kl: 0.011746927164494991\n",
      "      policy_loss: 0.001823405851610005\n",
      "      total_loss: 153.6379852294922\n",
      "      vf_explained_var: 0.9353050589561462\n",
      "      vf_loss: 153.6361846923828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6013761758804321\n",
      "      kl: 0.016262156888842583\n",
      "      policy_loss: 0.0036012029740959406\n",
      "      total_loss: 129.95358276367188\n",
      "      vf_explained_var: 0.9303624033927917\n",
      "      vf_loss: 129.949951171875\n",
      "    sample_time_ms: 19933.608\n",
      "    update_time_ms: 7.142\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.943685721891306\n",
      "    rl_1: 38.408730922151506\n",
      "  time_since_restore: 15846.29530453682\n",
      "  time_this_iter_s: 22.92062211036682\n",
      "  time_total_s: 15846.29530453682\n",
      "  timestamp: 1550896458\n",
      "  timesteps_since_restore: 6830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6830000\n",
      "  training_iteration: 683\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15846 s, 683 iter, 6830000 ts, 93.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-34-40\n",
      "  done: false\n",
      "  episode_len_mean: 113.87\n",
      "  episode_reward_max: 226.44361870167123\n",
      "  episode_reward_mean: 119.84925936689284\n",
      "  episode_reward_min: -171.52496247264213\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 58709\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.031\n",
      "    load_time_ms: 2.271\n",
      "    num_steps_sampled: 6840000\n",
      "    num_steps_trained: 6840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5114413499832153\n",
      "      kl: 0.02356310561299324\n",
      "      policy_loss: 0.010203331708908081\n",
      "      total_loss: 94.10861206054688\n",
      "      vf_explained_var: 0.9554492235183716\n",
      "      vf_loss: 94.09841918945312\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7751770615577698\n",
      "      kl: 0.026003774255514145\n",
      "      policy_loss: 0.007878148928284645\n",
      "      total_loss: 87.84294128417969\n",
      "      vf_explained_var: 0.9494645595550537\n",
      "      vf_loss: 87.83506774902344\n",
      "    sample_time_ms: 19868.201\n",
      "    update_time_ms: 6.935\n",
      "  iterations_since_restore: 684\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.370736876661\n",
      "    rl_1: 51.478522490231846\n",
      "  time_since_restore: 15869.184584140778\n",
      "  time_this_iter_s: 22.88927960395813\n",
      "  time_total_s: 15869.184584140778\n",
      "  timestamp: 1550896480\n",
      "  timesteps_since_restore: 6840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6840000\n",
      "  training_iteration: 684\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15869 s, 684 iter, 6840000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-35-03\n",
      "  done: false\n",
      "  episode_len_mean: 121.05\n",
      "  episode_reward_max: 226.44361870167123\n",
      "  episode_reward_mean: 120.09159661814492\n",
      "  episode_reward_min: -156.00688894281586\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 58792\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.941\n",
      "    load_time_ms: 2.347\n",
      "    num_steps_sampled: 6850000\n",
      "    num_steps_trained: 6850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.30427461862564087\n",
      "      kl: 0.020124753937125206\n",
      "      policy_loss: 0.0048410543240606785\n",
      "      total_loss: 150.3380584716797\n",
      "      vf_explained_var: 0.9272961020469666\n",
      "      vf_loss: 150.33322143554688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5834048986434937\n",
      "      kl: 0.023561954498291016\n",
      "      policy_loss: 0.006159266456961632\n",
      "      total_loss: 137.9773712158203\n",
      "      vf_explained_var: 0.9211666584014893\n",
      "      vf_loss: 137.97122192382812\n",
      "    sample_time_ms: 19861.121\n",
      "    update_time_ms: 6.853\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.49039921915445\n",
      "    rl_1: 50.601197398990465\n",
      "  time_since_restore: 15892.13433599472\n",
      "  time_this_iter_s: 22.94975185394287\n",
      "  time_total_s: 15892.13433599472\n",
      "  timestamp: 1550896503\n",
      "  timesteps_since_restore: 6850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6850000\n",
      "  training_iteration: 685\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15892 s, 685 iter, 6850000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-35-27\n",
      "  done: false\n",
      "  episode_len_mean: 111.5\n",
      "  episode_reward_max: 220.58317125607033\n",
      "  episode_reward_mean: 99.46642148772618\n",
      "  episode_reward_min: -165.3814760023529\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 58883\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.956\n",
      "    load_time_ms: 2.331\n",
      "    num_steps_sampled: 6860000\n",
      "    num_steps_trained: 6860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.46180260181427\n",
      "      kl: 0.019422262907028198\n",
      "      policy_loss: 0.007976870983839035\n",
      "      total_loss: 104.28119659423828\n",
      "      vf_explained_var: 0.9644108414649963\n",
      "      vf_loss: 104.27323150634766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6995620131492615\n",
      "      kl: 2.081533908843994\n",
      "      policy_loss: 0.01603872887790203\n",
      "      total_loss: 90.77449035644531\n",
      "      vf_explained_var: 0.9590218663215637\n",
      "      vf_loss: 90.75846099853516\n",
      "    sample_time_ms: 19833.723\n",
      "    update_time_ms: 7.087\n",
      "  iterations_since_restore: 686\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.89269322493138\n",
      "    rl_1: 40.573728262794795\n",
      "  time_since_restore: 15915.275212526321\n",
      "  time_this_iter_s: 23.140876531600952\n",
      "  time_total_s: 15915.275212526321\n",
      "  timestamp: 1550896527\n",
      "  timesteps_since_restore: 6860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6860000\n",
      "  training_iteration: 686\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15915 s, 686 iter, 6860000 ts, 99.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-35-49\n",
      "  done: false\n",
      "  episode_len_mean: 113.69\n",
      "  episode_reward_max: 220.79932039949182\n",
      "  episode_reward_mean: 117.6615438712927\n",
      "  episode_reward_min: -169.31147972705065\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 58970\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.917\n",
      "    load_time_ms: 2.281\n",
      "    num_steps_sampled: 6870000\n",
      "    num_steps_trained: 6870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.35481828451156616\n",
      "      kl: 0.014323558658361435\n",
      "      policy_loss: 0.0038140362594276667\n",
      "      total_loss: 117.7055435180664\n",
      "      vf_explained_var: 0.9510713219642639\n",
      "      vf_loss: 117.70172119140625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6364233493804932\n",
      "      kl: 0.01810077391564846\n",
      "      policy_loss: 0.005210876930505037\n",
      "      total_loss: 118.14017486572266\n",
      "      vf_explained_var: 0.9402340650558472\n",
      "      vf_loss: 118.13494110107422\n",
      "    sample_time_ms: 19824.652\n",
      "    update_time_ms: 7.167\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 66.64638849546698\n",
      "    rl_1: 51.0151553758257\n",
      "  time_since_restore: 15938.039811611176\n",
      "  time_this_iter_s: 22.764599084854126\n",
      "  time_total_s: 15938.039811611176\n",
      "  timestamp: 1550896549\n",
      "  timesteps_since_restore: 6870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6870000\n",
      "  training_iteration: 687\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15938 s, 687 iter, 6870000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-36-13\n",
      "  done: false\n",
      "  episode_len_mean: 118.66\n",
      "  episode_reward_max: 221.43119373366267\n",
      "  episode_reward_mean: 131.8623362944278\n",
      "  episode_reward_min: -168.3404533375463\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 59057\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.19\n",
      "    load_time_ms: 2.348\n",
      "    num_steps_sampled: 6880000\n",
      "    num_steps_trained: 6880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3729102909564972\n",
      "      kl: 0.0316711887717247\n",
      "      policy_loss: 0.007554898038506508\n",
      "      total_loss: 94.4008560180664\n",
      "      vf_explained_var: 0.9488075375556946\n",
      "      vf_loss: 94.39330291748047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6710544228553772\n",
      "      kl: 0.021592319011688232\n",
      "      policy_loss: 0.005472679156810045\n",
      "      total_loss: 97.911865234375\n",
      "      vf_explained_var: 0.9345386028289795\n",
      "      vf_loss: 97.90638732910156\n",
      "    sample_time_ms: 19813.823\n",
      "    update_time_ms: 7.271\n",
      "  iterations_since_restore: 688\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.6064976197703\n",
      "    rl_1: 56.2558386746575\n",
      "  time_since_restore: 15961.104914665222\n",
      "  time_this_iter_s: 23.06510305404663\n",
      "  time_total_s: 15961.104914665222\n",
      "  timestamp: 1550896573\n",
      "  timesteps_since_restore: 6880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6880000\n",
      "  training_iteration: 688\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15961 s, 688 iter, 6880000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-36-36\n",
      "  done: false\n",
      "  episode_len_mean: 106.95\n",
      "  episode_reward_max: 228.05952532428896\n",
      "  episode_reward_mean: 106.53991898948296\n",
      "  episode_reward_min: -143.72325638763658\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 59151\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.185\n",
      "    load_time_ms: 2.42\n",
      "    num_steps_sampled: 6890000\n",
      "    num_steps_trained: 6890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5689836740493774\n",
      "      kl: 0.032467424869537354\n",
      "      policy_loss: 0.007954487577080727\n",
      "      total_loss: 146.03749084472656\n",
      "      vf_explained_var: 0.9501437544822693\n",
      "      vf_loss: 146.029541015625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8053671717643738\n",
      "      kl: 0.039724938571453094\n",
      "      policy_loss: 0.013937504030764103\n",
      "      total_loss: 139.88497924804688\n",
      "      vf_explained_var: 0.9341776967048645\n",
      "      vf_loss: 139.87106323242188\n",
      "    sample_time_ms: 19793.592\n",
      "    update_time_ms: 7.317\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.3317908815822\n",
      "    rl_1: 44.208128107900755\n",
      "  time_since_restore: 15984.045170545578\n",
      "  time_this_iter_s: 22.940255880355835\n",
      "  time_total_s: 15984.045170545578\n",
      "  timestamp: 1550896596\n",
      "  timesteps_since_restore: 6890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6890000\n",
      "  training_iteration: 689\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 15984 s, 689 iter, 6890000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-36-59\n",
      "  done: false\n",
      "  episode_len_mean: 113.67\n",
      "  episode_reward_max: 229.6224490514468\n",
      "  episode_reward_mean: 141.18527803071584\n",
      "  episode_reward_min: -165.6845618919705\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 59238\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3058.243\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 6900000\n",
      "    num_steps_trained: 6900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.43851953744888306\n",
      "      kl: 0.014848356135189533\n",
      "      policy_loss: 0.0023703104816377163\n",
      "      total_loss: 83.7883071899414\n",
      "      vf_explained_var: 0.9558628797531128\n",
      "      vf_loss: 83.78594207763672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6643509268760681\n",
      "      kl: 0.025372926145792007\n",
      "      policy_loss: 0.012942798435688019\n",
      "      total_loss: 75.80707550048828\n",
      "      vf_explained_var: 0.9485592246055603\n",
      "      vf_loss: 75.79412841796875\n",
      "    sample_time_ms: 19871.769\n",
      "    update_time_ms: 7.312\n",
      "  iterations_since_restore: 690\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.50770733550992\n",
      "    rl_1: 59.677570695205944\n",
      "  time_since_restore: 16007.071380615234\n",
      "  time_this_iter_s: 23.026210069656372\n",
      "  time_total_s: 16007.071380615234\n",
      "  timestamp: 1550896619\n",
      "  timesteps_since_restore: 6900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6900000\n",
      "  training_iteration: 690\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16007 s, 690 iter, 6900000 ts, 141 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-37-22\n",
      "  done: false\n",
      "  episode_len_mean: 116.18\n",
      "  episode_reward_max: 229.34052203031473\n",
      "  episode_reward_mean: 148.38050986921147\n",
      "  episode_reward_min: -163.75099288841955\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 59325\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3056.067\n",
      "    load_time_ms: 2.411\n",
      "    num_steps_sampled: 6910000\n",
      "    num_steps_trained: 6910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44362252950668335\n",
      "      kl: 0.02046060934662819\n",
      "      policy_loss: 0.005651325453072786\n",
      "      total_loss: 94.39400482177734\n",
      "      vf_explained_var: 0.9525113105773926\n",
      "      vf_loss: 94.38836669921875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6869358420372009\n",
      "      kl: 0.02228682115674019\n",
      "      policy_loss: 0.00262510241009295\n",
      "      total_loss: 92.74373626708984\n",
      "      vf_explained_var: 0.9392289519309998\n",
      "      vf_loss: 92.74113464355469\n",
      "    sample_time_ms: 19910.965\n",
      "    update_time_ms: 7.28\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.09699332016754\n",
      "    rl_1: 63.28351654904392\n",
      "  time_since_restore: 16030.007503271103\n",
      "  time_this_iter_s: 22.93612265586853\n",
      "  time_total_s: 16030.007503271103\n",
      "  timestamp: 1550896642\n",
      "  timesteps_since_restore: 6910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6910000\n",
      "  training_iteration: 691\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16030 s, 691 iter, 6910000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-37-45\n",
      "  done: false\n",
      "  episode_len_mean: 109.96\n",
      "  episode_reward_max: 224.41598430352784\n",
      "  episode_reward_mean: 125.6715328958474\n",
      "  episode_reward_min: -142.5575228558591\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 59415\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3055.437\n",
      "    load_time_ms: 2.427\n",
      "    num_steps_sampled: 6920000\n",
      "    num_steps_trained: 6920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49834519624710083\n",
      "      kl: 0.02626669965684414\n",
      "      policy_loss: 0.0051120189018547535\n",
      "      total_loss: 108.0206069946289\n",
      "      vf_explained_var: 0.9509261846542358\n",
      "      vf_loss: 108.0155029296875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7260032296180725\n",
      "      kl: 0.01752988062798977\n",
      "      policy_loss: 0.011379003524780273\n",
      "      total_loss: 108.14508056640625\n",
      "      vf_explained_var: 0.9324125647544861\n",
      "      vf_loss: 108.13370513916016\n",
      "    sample_time_ms: 19903.032\n",
      "    update_time_ms: 7.414\n",
      "  iterations_since_restore: 692\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.9640064947046\n",
      "    rl_1: 53.707526401142815\n",
      "  time_since_restore: 16053.229082345963\n",
      "  time_this_iter_s: 23.22157907485962\n",
      "  time_total_s: 16053.229082345963\n",
      "  timestamp: 1550896665\n",
      "  timesteps_since_restore: 6920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6920000\n",
      "  training_iteration: 692\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16053 s, 692 iter, 6920000 ts, 126 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-38-08\n",
      "  done: false\n",
      "  episode_len_mean: 113.09\n",
      "  episode_reward_max: 225.63153530411566\n",
      "  episode_reward_mean: 116.5235134860325\n",
      "  episode_reward_min: -173.96701488479596\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 59504\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.45\n",
      "    load_time_ms: 2.431\n",
      "    num_steps_sampled: 6930000\n",
      "    num_steps_trained: 6930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5351084470748901\n",
      "      kl: 0.033586155623197556\n",
      "      policy_loss: 0.005075945984572172\n",
      "      total_loss: 96.73223876953125\n",
      "      vf_explained_var: 0.9618452191352844\n",
      "      vf_loss: 96.7271728515625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7609543204307556\n",
      "      kl: 0.04141398146748543\n",
      "      policy_loss: 0.004292354453355074\n",
      "      total_loss: 79.82453918457031\n",
      "      vf_explained_var: 0.9532121419906616\n",
      "      vf_loss: 79.82025146484375\n",
      "    sample_time_ms: 19898.343\n",
      "    update_time_ms: 7.017\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.40734454445325\n",
      "    rl_1: 46.11616894157922\n",
      "  time_since_restore: 16076.261241912842\n",
      "  time_this_iter_s: 23.032159566879272\n",
      "  time_total_s: 16076.261241912842\n",
      "  timestamp: 1550896688\n",
      "  timesteps_since_restore: 6930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6930000\n",
      "  training_iteration: 693\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16076 s, 693 iter, 6930000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-38-31\n",
      "  done: false\n",
      "  episode_len_mean: 110.75\n",
      "  episode_reward_max: 234.91575133725152\n",
      "  episode_reward_mean: 127.93873235967546\n",
      "  episode_reward_min: -149.9616460267237\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 59593\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.067\n",
      "    load_time_ms: 2.425\n",
      "    num_steps_sampled: 6940000\n",
      "    num_steps_trained: 6940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.46471190452575684\n",
      "      kl: 0.02950843796133995\n",
      "      policy_loss: 0.0066137611865997314\n",
      "      total_loss: 134.3699493408203\n",
      "      vf_explained_var: 0.9375442266464233\n",
      "      vf_loss: 134.36331176757812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7260584235191345\n",
      "      kl: 0.02158818021416664\n",
      "      policy_loss: 0.001816420815885067\n",
      "      total_loss: 132.051025390625\n",
      "      vf_explained_var: 0.9181010723114014\n",
      "      vf_loss: 132.04920959472656\n",
      "    sample_time_ms: 19867.802\n",
      "    update_time_ms: 7.021\n",
      "  iterations_since_restore: 694\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.94843653132078\n",
      "    rl_1: 54.990295828354704\n",
      "  time_since_restore: 16098.841367483139\n",
      "  time_this_iter_s: 22.58012557029724\n",
      "  time_total_s: 16098.841367483139\n",
      "  timestamp: 1550896711\n",
      "  timesteps_since_restore: 6940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6940000\n",
      "  training_iteration: 694\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16098 s, 694 iter, 6940000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-38-54\n",
      "  done: false\n",
      "  episode_len_mean: 110.18\n",
      "  episode_reward_max: 234.91575133725152\n",
      "  episode_reward_mean: 141.1207092873061\n",
      "  episode_reward_min: -142.0469197346021\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 59682\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.92\n",
      "    load_time_ms: 2.348\n",
      "    num_steps_sampled: 6950000\n",
      "    num_steps_trained: 6950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4956282675266266\n",
      "      kl: 0.030391763895750046\n",
      "      policy_loss: 0.010949000716209412\n",
      "      total_loss: 125.53933715820312\n",
      "      vf_explained_var: 0.9379505515098572\n",
      "      vf_loss: 125.52838134765625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7593902349472046\n",
      "      kl: 0.024262355640530586\n",
      "      policy_loss: 0.006318408064544201\n",
      "      total_loss: 117.84659576416016\n",
      "      vf_explained_var: 0.9255164861679077\n",
      "      vf_loss: 117.84027862548828\n",
      "    sample_time_ms: 19884.774\n",
      "    update_time_ms: 6.988\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.93587769392292\n",
      "    rl_1: 63.18483159338319\n",
      "  time_since_restore: 16121.957518577576\n",
      "  time_this_iter_s: 23.116151094436646\n",
      "  time_total_s: 16121.957518577576\n",
      "  timestamp: 1550896734\n",
      "  timesteps_since_restore: 6950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6950000\n",
      "  training_iteration: 695\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16121 s, 695 iter, 6950000 ts, 141 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-39-17\n",
      "  done: false\n",
      "  episode_len_mean: 114.67\n",
      "  episode_reward_max: 234.80274177294388\n",
      "  episode_reward_mean: 132.32064589135473\n",
      "  episode_reward_min: -156.92609688340562\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 59769\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.316\n",
      "    load_time_ms: 2.362\n",
      "    num_steps_sampled: 6960000\n",
      "    num_steps_trained: 6960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.3918208181858063\n",
      "      kl: 0.014338657259941101\n",
      "      policy_loss: 0.0039095571264624596\n",
      "      total_loss: 151.3311767578125\n",
      "      vf_explained_var: 0.928605318069458\n",
      "      vf_loss: 151.32725524902344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6940495371818542\n",
      "      kl: 0.04752172529697418\n",
      "      policy_loss: 0.018741639330983162\n",
      "      total_loss: 144.2749786376953\n",
      "      vf_explained_var: 0.9098296761512756\n",
      "      vf_loss: 144.25621032714844\n",
      "    sample_time_ms: 19866.04\n",
      "    update_time_ms: 6.709\n",
      "  iterations_since_restore: 696\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.00096839374937\n",
      "    rl_1: 57.319677497605355\n",
      "  time_since_restore: 16144.874105215073\n",
      "  time_this_iter_s: 22.91658663749695\n",
      "  time_total_s: 16144.874105215073\n",
      "  timestamp: 1550896757\n",
      "  timesteps_since_restore: 6960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6960000\n",
      "  training_iteration: 696\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16144 s, 696 iter, 6960000 ts, 132 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-39-40\n",
      "  done: false\n",
      "  episode_len_mean: 109.59\n",
      "  episode_reward_max: 218.88126291932628\n",
      "  episode_reward_mean: 114.74235121229171\n",
      "  episode_reward_min: -164.6474530545732\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 59861\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.202\n",
      "    load_time_ms: 2.378\n",
      "    num_steps_sampled: 6970000\n",
      "    num_steps_trained: 6970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5499570369720459\n",
      "      kl: 0.01320150587707758\n",
      "      policy_loss: -0.0009313501650467515\n",
      "      total_loss: 148.1461944580078\n",
      "      vf_explained_var: 0.9458869695663452\n",
      "      vf_loss: 148.14712524414062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7763645648956299\n",
      "      kl: 0.12398086488246918\n",
      "      policy_loss: 0.03827764466404915\n",
      "      total_loss: 117.73809051513672\n",
      "      vf_explained_var: 0.940398097038269\n",
      "      vf_loss: 117.6998062133789\n",
      "    sample_time_ms: 19919.317\n",
      "    update_time_ms: 6.526\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.46443755480789\n",
      "    rl_1: 47.27791365748379\n",
      "  time_since_restore: 16168.16670203209\n",
      "  time_this_iter_s: 23.2925968170166\n",
      "  time_total_s: 16168.16670203209\n",
      "  timestamp: 1550896780\n",
      "  timesteps_since_restore: 6970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6970000\n",
      "  training_iteration: 697\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16168 s, 697 iter, 6970000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-40-03\n",
      "  done: false\n",
      "  episode_len_mean: 110.61\n",
      "  episode_reward_max: 216.6888984272571\n",
      "  episode_reward_mean: 109.29280632415092\n",
      "  episode_reward_min: -177.95809357304526\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 59950\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.263\n",
      "    load_time_ms: 2.304\n",
      "    num_steps_sampled: 6980000\n",
      "    num_steps_trained: 6980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4711573123931885\n",
      "      kl: 0.028089795261621475\n",
      "      policy_loss: 0.004312457982450724\n",
      "      total_loss: 158.84510803222656\n",
      "      vf_explained_var: 0.9354857206344604\n",
      "      vf_loss: 158.84078979492188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7121803164482117\n",
      "      kl: 0.7374674677848816\n",
      "      policy_loss: 0.0811675414443016\n",
      "      total_loss: 153.70687866210938\n",
      "      vf_explained_var: 0.9213157892227173\n",
      "      vf_loss: 153.62570190429688\n",
      "    sample_time_ms: 19874.111\n",
      "    update_time_ms: 6.475\n",
      "  iterations_since_restore: 698\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.82892017577988\n",
      "    rl_1: 46.463886148371\n",
      "  time_since_restore: 16190.719468355179\n",
      "  time_this_iter_s: 22.5527663230896\n",
      "  time_total_s: 16190.719468355179\n",
      "  timestamp: 1550896803\n",
      "  timesteps_since_restore: 6980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6980000\n",
      "  training_iteration: 698\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16190 s, 698 iter, 6980000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-40-26\n",
      "  done: false\n",
      "  episode_len_mean: 108.21\n",
      "  episode_reward_max: 217.21728345970155\n",
      "  episode_reward_mean: 116.5756813674603\n",
      "  episode_reward_min: -172.04066185610196\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 60043\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.914\n",
      "    load_time_ms: 2.277\n",
      "    num_steps_sampled: 6990000\n",
      "    num_steps_trained: 6990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5929559469223022\n",
      "      kl: 0.01729760505259037\n",
      "      policy_loss: -0.0018491795053705573\n",
      "      total_loss: 100.31616973876953\n",
      "      vf_explained_var: 0.9642229080200195\n",
      "      vf_loss: 100.31802368164062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8076865077018738\n",
      "      kl: 0.02553561143577099\n",
      "      policy_loss: 0.008410709910094738\n",
      "      total_loss: 94.28168487548828\n",
      "      vf_explained_var: 0.9540536403656006\n",
      "      vf_loss: 94.27327728271484\n",
      "    sample_time_ms: 19905.093\n",
      "    update_time_ms: 6.527\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.24167947204008\n",
      "    rl_1: 49.33400189542022\n",
      "  time_since_restore: 16213.988976955414\n",
      "  time_this_iter_s: 23.269508600234985\n",
      "  time_total_s: 16213.988976955414\n",
      "  timestamp: 1550896826\n",
      "  timesteps_since_restore: 6990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 6990000\n",
      "  training_iteration: 699\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16213 s, 699 iter, 6990000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-40-49\n",
      "  done: false\n",
      "  episode_len_mean: 107.72\n",
      "  episode_reward_max: 213.8269965775181\n",
      "  episode_reward_mean: 93.63251496888584\n",
      "  episode_reward_min: -177.44308801642742\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 60136\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.546\n",
      "    load_time_ms: 2.349\n",
      "    num_steps_sampled: 7000000\n",
      "    num_steps_trained: 7000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5352062582969666\n",
      "      kl: 0.022485284134745598\n",
      "      policy_loss: 0.006504531018435955\n",
      "      total_loss: 184.83644104003906\n",
      "      vf_explained_var: 0.9408587217330933\n",
      "      vf_loss: 184.82994079589844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7819953560829163\n",
      "      kl: 0.03436404466629028\n",
      "      policy_loss: 0.01143640000373125\n",
      "      total_loss: 167.78814697265625\n",
      "      vf_explained_var: 0.9304803013801575\n",
      "      vf_loss: 167.7766876220703\n",
      "    sample_time_ms: 19937.951\n",
      "    update_time_ms: 6.82\n",
      "  iterations_since_restore: 700\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.84824453026695\n",
      "    rl_1: 38.784270438618876\n",
      "  time_since_restore: 16237.374982595444\n",
      "  time_this_iter_s: 23.386005640029907\n",
      "  time_total_s: 16237.374982595444\n",
      "  timestamp: 1550896849\n",
      "  timesteps_since_restore: 7000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7000000\n",
      "  training_iteration: 700\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16237 s, 700 iter, 7000000 ts, 93.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-41-12\n",
      "  done: false\n",
      "  episode_len_mean: 113.66\n",
      "  episode_reward_max: 220.90488828486832\n",
      "  episode_reward_mean: 109.94709952277177\n",
      "  episode_reward_min: -159.82014790449387\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 60223\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.557\n",
      "    load_time_ms: 2.279\n",
      "    num_steps_sampled: 7010000\n",
      "    num_steps_trained: 7010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4630735218524933\n",
      "      kl: 0.022487755864858627\n",
      "      policy_loss: 0.002079370431602001\n",
      "      total_loss: 127.64373016357422\n",
      "      vf_explained_var: 0.9467474818229675\n",
      "      vf_loss: 127.6416244506836\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.715336799621582\n",
      "      kl: 0.031681086868047714\n",
      "      policy_loss: 0.007754886988550425\n",
      "      total_loss: 114.70719146728516\n",
      "      vf_explained_var: 0.9320364594459534\n",
      "      vf_loss: 114.69943237304688\n",
      "    sample_time_ms: 19936.604\n",
      "    update_time_ms: 6.748\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.56331874575953\n",
      "    rl_1: 44.38378077701224\n",
      "  time_since_restore: 16260.308191299438\n",
      "  time_this_iter_s: 22.93320870399475\n",
      "  time_total_s: 16260.308191299438\n",
      "  timestamp: 1550896872\n",
      "  timesteps_since_restore: 7010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7010000\n",
      "  training_iteration: 701\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16260 s, 701 iter, 7010000 ts, 110 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-41-35\n",
      "  done: false\n",
      "  episode_len_mean: 111.97\n",
      "  episode_reward_max: 221.722405540587\n",
      "  episode_reward_mean: 114.69915523764674\n",
      "  episode_reward_min: -159.82014790449387\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 60311\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.408\n",
      "    load_time_ms: 2.296\n",
      "    num_steps_sampled: 7020000\n",
      "    num_steps_trained: 7020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4449958801269531\n",
      "      kl: 0.02407849207520485\n",
      "      policy_loss: 0.009616888128221035\n",
      "      total_loss: 112.53097534179688\n",
      "      vf_explained_var: 0.9475672841072083\n",
      "      vf_loss: 112.52136993408203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6975894570350647\n",
      "      kl: 0.04625093564391136\n",
      "      policy_loss: 0.016083959490060806\n",
      "      total_loss: 106.4716796875\n",
      "      vf_explained_var: 0.9309996366500854\n",
      "      vf_loss: 106.4555892944336\n",
      "    sample_time_ms: 19855.754\n",
      "    update_time_ms: 6.744\n",
      "  iterations_since_restore: 702\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.15142832791427\n",
      "    rl_1: 47.54772690973246\n",
      "  time_since_restore: 16282.701454877853\n",
      "  time_this_iter_s: 22.393263578414917\n",
      "  time_total_s: 16282.701454877853\n",
      "  timestamp: 1550896895\n",
      "  timesteps_since_restore: 7020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7020000\n",
      "  training_iteration: 702\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16282 s, 702 iter, 7020000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-41-58\n",
      "  done: false\n",
      "  episode_len_mean: 110.94\n",
      "  episode_reward_max: 223.869919371016\n",
      "  episode_reward_mean: 105.73660170226522\n",
      "  episode_reward_min: -150.2235343130305\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 60405\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3048.192\n",
      "    load_time_ms: 2.303\n",
      "    num_steps_sampled: 7030000\n",
      "    num_steps_trained: 7030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5480139255523682\n",
      "      kl: 0.7179543375968933\n",
      "      policy_loss: 0.08340108394622803\n",
      "      total_loss: 163.39698791503906\n",
      "      vf_explained_var: 0.9458571076393127\n",
      "      vf_loss: 163.31358337402344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7467244267463684\n",
      "      kl: 0.027647146955132484\n",
      "      policy_loss: 0.008464964106678963\n",
      "      total_loss: 148.30584716796875\n",
      "      vf_explained_var: 0.9348949790000916\n",
      "      vf_loss: 148.29737854003906\n",
      "    sample_time_ms: 19863.996\n",
      "    update_time_ms: 6.613\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.61267259725261\n",
      "    rl_1: 44.123929105012586\n",
      "  time_since_restore: 16305.650327682495\n",
      "  time_this_iter_s: 22.948872804641724\n",
      "  time_total_s: 16305.650327682495\n",
      "  timestamp: 1550896918\n",
      "  timesteps_since_restore: 7030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7030000\n",
      "  training_iteration: 703\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16305 s, 703 iter, 7030000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-42-21\n",
      "  done: false\n",
      "  episode_len_mean: 112.17\n",
      "  episode_reward_max: 228.37786925521465\n",
      "  episode_reward_mean: 106.3604676850319\n",
      "  episode_reward_min: -156.6405136493738\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 60493\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3046.912\n",
      "    load_time_ms: 2.318\n",
      "    num_steps_sampled: 7040000\n",
      "    num_steps_trained: 7040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38252946734428406\n",
      "      kl: 0.014835009351372719\n",
      "      policy_loss: -0.00040524796349927783\n",
      "      total_loss: 109.46398162841797\n",
      "      vf_explained_var: 0.9577347040176392\n",
      "      vf_loss: 109.46437072753906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6269840598106384\n",
      "      kl: 0.025505345314741135\n",
      "      policy_loss: 0.005749895237386227\n",
      "      total_loss: 108.9746322631836\n",
      "      vf_explained_var: 0.946887195110321\n",
      "      vf_loss: 108.96888732910156\n",
      "    sample_time_ms: 19915.561\n",
      "    update_time_ms: 6.71\n",
      "  iterations_since_restore: 704\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.819089189077914\n",
      "    rl_1: 44.541378495954035\n",
      "  time_since_restore: 16328.734421253204\n",
      "  time_this_iter_s: 23.08409357070923\n",
      "  time_total_s: 16328.734421253204\n",
      "  timestamp: 1550896941\n",
      "  timesteps_since_restore: 7040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7040000\n",
      "  training_iteration: 704\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16328 s, 704 iter, 7040000 ts, 106 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-42-44\n",
      "  done: false\n",
      "  episode_len_mean: 109.56\n",
      "  episode_reward_max: 225.49892087177747\n",
      "  episode_reward_mean: 105.48541559912013\n",
      "  episode_reward_min: -173.08968321555352\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 60584\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3044.518\n",
      "    load_time_ms: 2.31\n",
      "    num_steps_sampled: 7050000\n",
      "    num_steps_trained: 7050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4802808165550232\n",
      "      kl: 0.025918444618582726\n",
      "      policy_loss: 0.009251749143004417\n",
      "      total_loss: 151.2079620361328\n",
      "      vf_explained_var: 0.9448022842407227\n",
      "      vf_loss: 151.19869995117188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6660910248756409\n",
      "      kl: 0.02638934552669525\n",
      "      policy_loss: 0.005491422954946756\n",
      "      total_loss: 136.24029541015625\n",
      "      vf_explained_var: 0.9338807463645935\n",
      "      vf_loss: 136.2348175048828\n",
      "    sample_time_ms: 19934.245\n",
      "    update_time_ms: 6.765\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.34899778607714\n",
      "    rl_1: 43.13641781304301\n",
      "  time_since_restore: 16352.011903524399\n",
      "  time_this_iter_s: 23.277482271194458\n",
      "  time_total_s: 16352.011903524399\n",
      "  timestamp: 1550896964\n",
      "  timesteps_since_restore: 7050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7050000\n",
      "  training_iteration: 705\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16352 s, 705 iter, 7050000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-43-07\n",
      "  done: false\n",
      "  episode_len_mean: 113.37\n",
      "  episode_reward_max: 232.52639201477933\n",
      "  episode_reward_mean: 119.65869388376294\n",
      "  episode_reward_min: -176.5695749891658\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 60672\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.373\n",
      "    load_time_ms: 2.348\n",
      "    num_steps_sampled: 7060000\n",
      "    num_steps_trained: 7060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47054579854011536\n",
      "      kl: 0.025265447795391083\n",
      "      policy_loss: 0.010670376010239124\n",
      "      total_loss: 83.85283660888672\n",
      "      vf_explained_var: 0.9657052755355835\n",
      "      vf_loss: 83.84217834472656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7230220437049866\n",
      "      kl: 0.0260928962379694\n",
      "      policy_loss: 0.0035894375760108232\n",
      "      total_loss: 81.49288177490234\n",
      "      vf_explained_var: 0.957067608833313\n",
      "      vf_loss: 81.4892807006836\n",
      "    sample_time_ms: 19930.707\n",
      "    update_time_ms: 6.764\n",
      "  iterations_since_restore: 706\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.92674164565805\n",
      "    rl_1: 49.731952238104896\n",
      "  time_since_restore: 16375.062478542328\n",
      "  time_this_iter_s: 23.050575017929077\n",
      "  time_total_s: 16375.062478542328\n",
      "  timestamp: 1550896987\n",
      "  timesteps_since_restore: 7060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7060000\n",
      "  training_iteration: 706\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16375 s, 706 iter, 7060000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-43-30\n",
      "  done: false\n",
      "  episode_len_mean: 107.13\n",
      "  episode_reward_max: 217.65508981093603\n",
      "  episode_reward_mean: 97.57068263226466\n",
      "  episode_reward_min: -180.20179156173688\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 60766\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3063.692\n",
      "    load_time_ms: 2.351\n",
      "    num_steps_sampled: 7070000\n",
      "    num_steps_trained: 7070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4964684247970581\n",
      "      kl: 0.02256288006901741\n",
      "      policy_loss: 0.006181672215461731\n",
      "      total_loss: 151.2776641845703\n",
      "      vf_explained_var: 0.9473791718482971\n",
      "      vf_loss: 151.27151489257812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7118216753005981\n",
      "      kl: 0.01973559707403183\n",
      "      policy_loss: 0.0037762783467769623\n",
      "      total_loss: 141.39234924316406\n",
      "      vf_explained_var: 0.936811089515686\n",
      "      vf_loss: 141.38856506347656\n",
      "    sample_time_ms: 19900.867\n",
      "    update_time_ms: 6.837\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 57.190343022238146\n",
      "    rl_1: 40.380339610026496\n",
      "  time_since_restore: 16398.079562664032\n",
      "  time_this_iter_s: 23.0170841217041\n",
      "  time_total_s: 16398.079562664032\n",
      "  timestamp: 1550897010\n",
      "  timesteps_since_restore: 7070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7070000\n",
      "  training_iteration: 707\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16398 s, 707 iter, 7070000 ts, 97.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-43-54\n",
      "  done: false\n",
      "  episode_len_mean: 107.5\n",
      "  episode_reward_max: 218.39422129874458\n",
      "  episode_reward_mean: 111.93818408072013\n",
      "  episode_reward_min: -158.08719826972387\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 60859\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.505\n",
      "    load_time_ms: 2.381\n",
      "    num_steps_sampled: 7080000\n",
      "    num_steps_trained: 7080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5222307443618774\n",
      "      kl: 0.04721945896744728\n",
      "      policy_loss: 0.014243466779589653\n",
      "      total_loss: 181.90478515625\n",
      "      vf_explained_var: 0.9240374565124512\n",
      "      vf_loss: 181.89059448242188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7221966981887817\n",
      "      kl: 0.7049472332000732\n",
      "      policy_loss: 0.04011251777410507\n",
      "      total_loss: 174.781982421875\n",
      "      vf_explained_var: 0.9080594182014465\n",
      "      vf_loss: 174.7418670654297\n",
      "    sample_time_ms: 19977.896\n",
      "    update_time_ms: 6.818\n",
      "  iterations_since_restore: 708\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.49912748207582\n",
      "    rl_1: 48.43905659864429\n",
      "  time_since_restore: 16421.382548570633\n",
      "  time_this_iter_s: 23.302985906600952\n",
      "  time_total_s: 16421.382548570633\n",
      "  timestamp: 1550897034\n",
      "  timesteps_since_restore: 7080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7080000\n",
      "  training_iteration: 708\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16421 s, 708 iter, 7080000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-44-17\n",
      "  done: false\n",
      "  episode_len_mean: 108.73\n",
      "  episode_reward_max: 233.35221663752404\n",
      "  episode_reward_mean: 114.5747377277399\n",
      "  episode_reward_min: -161.48536619523696\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 60950\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.758\n",
      "    load_time_ms: 2.34\n",
      "    num_steps_sampled: 7090000\n",
      "    num_steps_trained: 7090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5057849884033203\n",
      "      kl: 0.019864002242684364\n",
      "      policy_loss: 0.006837820168584585\n",
      "      total_loss: 161.46534729003906\n",
      "      vf_explained_var: 0.930945098400116\n",
      "      vf_loss: 161.45849609375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6960961818695068\n",
      "      kl: 0.024641262367367744\n",
      "      policy_loss: 0.0053146299906075\n",
      "      total_loss: 152.78915405273438\n",
      "      vf_explained_var: 0.9154678583145142\n",
      "      vf_loss: 152.78382873535156\n",
      "    sample_time_ms: 19986.368\n",
      "    update_time_ms: 6.79\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.94517825715319\n",
      "    rl_1: 49.62955947058676\n",
      "  time_since_restore: 16444.765302181244\n",
      "  time_this_iter_s: 23.382753610610962\n",
      "  time_total_s: 16444.765302181244\n",
      "  timestamp: 1550897057\n",
      "  timesteps_since_restore: 7090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7090000\n",
      "  training_iteration: 709\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16444 s, 709 iter, 7090000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-44-40\n",
      "  done: false\n",
      "  episode_len_mean: 110.73\n",
      "  episode_reward_max: 233.35221663752404\n",
      "  episode_reward_mean: 97.63122555582777\n",
      "  episode_reward_min: -174.37002642277287\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 61038\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.903\n",
      "    load_time_ms: 2.252\n",
      "    num_steps_sampled: 7100000\n",
      "    num_steps_trained: 7100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4750915467739105\n",
      "      kl: 0.03238270431756973\n",
      "      policy_loss: 0.008368229493498802\n",
      "      total_loss: 176.82215881347656\n",
      "      vf_explained_var: 0.9281973242759705\n",
      "      vf_loss: 176.8137969970703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6638185977935791\n",
      "      kl: 0.03847724199295044\n",
      "      policy_loss: 0.010056190192699432\n",
      "      total_loss: 161.35763549804688\n",
      "      vf_explained_var: 0.907884955406189\n",
      "      vf_loss: 161.34754943847656\n",
      "    sample_time_ms: 19944.721\n",
      "    update_time_ms: 6.651\n",
      "  iterations_since_restore: 710\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.750778602766246\n",
      "    rl_1: 37.880446953061494\n",
      "  time_since_restore: 16467.701848745346\n",
      "  time_this_iter_s: 22.936546564102173\n",
      "  time_total_s: 16467.701848745346\n",
      "  timestamp: 1550897080\n",
      "  timesteps_since_restore: 7100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7100000\n",
      "  training_iteration: 710\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16467 s, 710 iter, 7100000 ts, 97.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-45-03\n",
      "  done: false\n",
      "  episode_len_mean: 115.43\n",
      "  episode_reward_max: 218.21876910638417\n",
      "  episode_reward_mean: 134.74283322685574\n",
      "  episode_reward_min: -134.90624368549823\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 61127\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3060.006\n",
      "    load_time_ms: 2.26\n",
      "    num_steps_sampled: 7110000\n",
      "    num_steps_trained: 7110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.45423951745033264\n",
      "      kl: 0.013200619257986546\n",
      "      policy_loss: -0.0014211258385330439\n",
      "      total_loss: 131.4170379638672\n",
      "      vf_explained_var: 0.9317589998245239\n",
      "      vf_loss: 131.41842651367188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6583811044692993\n",
      "      kl: 0.017688652500510216\n",
      "      policy_loss: 0.003659219015389681\n",
      "      total_loss: 130.7663116455078\n",
      "      vf_explained_var: 0.9178735017776489\n",
      "      vf_loss: 130.76266479492188\n",
      "    sample_time_ms: 19935.198\n",
      "    update_time_ms: 6.664\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.41298435371124\n",
      "    rl_1: 58.329848873144485\n",
      "  time_since_restore: 16490.519184827805\n",
      "  time_this_iter_s: 22.817336082458496\n",
      "  time_total_s: 16490.519184827805\n",
      "  timestamp: 1550897103\n",
      "  timesteps_since_restore: 7110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7110000\n",
      "  training_iteration: 711\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16490 s, 711 iter, 7110000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-45-26\n",
      "  done: false\n",
      "  episode_len_mean: 110.96\n",
      "  episode_reward_max: 217.66160467506725\n",
      "  episode_reward_mean: 122.75077025140152\n",
      "  episode_reward_min: -141.48814072613294\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 61218\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3060.968\n",
      "    load_time_ms: 2.243\n",
      "    num_steps_sampled: 7120000\n",
      "    num_steps_trained: 7120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49093788862228394\n",
      "      kl: 0.03458040952682495\n",
      "      policy_loss: 0.00411158287897706\n",
      "      total_loss: 81.1776351928711\n",
      "      vf_explained_var: 0.9685641527175903\n",
      "      vf_loss: 81.17350769042969\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.699853777885437\n",
      "      kl: 0.023440444841980934\n",
      "      policy_loss: 0.006733637768775225\n",
      "      total_loss: 77.3870849609375\n",
      "      vf_explained_var: 0.9594204425811768\n",
      "      vf_loss: 77.38034057617188\n",
      "    sample_time_ms: 20010.464\n",
      "    update_time_ms: 6.613\n",
      "  iterations_since_restore: 712\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.8142533591112\n",
      "    rl_1: 51.93651689229032\n",
      "  time_since_restore: 16513.67301750183\n",
      "  time_this_iter_s: 23.15383267402649\n",
      "  time_total_s: 16513.67301750183\n",
      "  timestamp: 1550897126\n",
      "  timesteps_since_restore: 7120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7120000\n",
      "  training_iteration: 712\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16513 s, 712 iter, 7120000 ts, 123 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-45-49\n",
      "  done: false\n",
      "  episode_len_mean: 108.41\n",
      "  episode_reward_max: 213.12618916318485\n",
      "  episode_reward_mean: 102.28284622096535\n",
      "  episode_reward_min: -146.33627732461133\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 61309\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3059.389\n",
      "    load_time_ms: 2.27\n",
      "    num_steps_sampled: 7130000\n",
      "    num_steps_trained: 7130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5231303572654724\n",
      "      kl: 0.020354032516479492\n",
      "      policy_loss: -0.00028964856755919755\n",
      "      total_loss: 113.77339935302734\n",
      "      vf_explained_var: 0.95741868019104\n",
      "      vf_loss: 113.77368927001953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7135317921638489\n",
      "      kl: 0.03143066167831421\n",
      "      policy_loss: 0.006333533208817244\n",
      "      total_loss: 108.92222595214844\n",
      "      vf_explained_var: 0.9457757472991943\n",
      "      vf_loss: 108.91590118408203\n",
      "    sample_time_ms: 20018.054\n",
      "    update_time_ms: 6.643\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.01665028150221\n",
      "    rl_1: 42.26619593946316\n",
      "  time_since_restore: 16536.68359375\n",
      "  time_this_iter_s: 23.010576248168945\n",
      "  time_total_s: 16536.68359375\n",
      "  timestamp: 1550897149\n",
      "  timesteps_since_restore: 7130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7130000\n",
      "  training_iteration: 713\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16536 s, 713 iter, 7130000 ts, 102 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-46-13\n",
      "  done: false\n",
      "  episode_len_mean: 110.88\n",
      "  episode_reward_max: 214.3670074047648\n",
      "  episode_reward_mean: 119.09988293631297\n",
      "  episode_reward_min: -169.49193866806152\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 61399\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.122\n",
      "    load_time_ms: 2.277\n",
      "    num_steps_sampled: 7140000\n",
      "    num_steps_trained: 7140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4704287052154541\n",
      "      kl: 0.026087574660778046\n",
      "      policy_loss: 0.0019563138484954834\n",
      "      total_loss: 125.00662231445312\n",
      "      vf_explained_var: 0.9475464224815369\n",
      "      vf_loss: 125.00468444824219\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6919646263122559\n",
      "      kl: 0.020976973697543144\n",
      "      policy_loss: -0.002270708093419671\n",
      "      total_loss: 110.87476348876953\n",
      "      vf_explained_var: 0.9421829581260681\n",
      "      vf_loss: 110.8770523071289\n",
      "    sample_time_ms: 20020.31\n",
      "    update_time_ms: 6.609\n",
      "  iterations_since_restore: 714\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.12940358270556\n",
      "    rl_1: 51.97047935360742\n",
      "  time_since_restore: 16559.948986053467\n",
      "  time_this_iter_s: 23.265392303466797\n",
      "  time_total_s: 16559.948986053467\n",
      "  timestamp: 1550897173\n",
      "  timesteps_since_restore: 7140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7140000\n",
      "  training_iteration: 714\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16559 s, 714 iter, 7140000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-46-36\n",
      "  done: false\n",
      "  episode_len_mean: 109.34\n",
      "  episode_reward_max: 228.54518978901243\n",
      "  episode_reward_mean: 121.8232520025646\n",
      "  episode_reward_min: -175.46458763996208\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 61491\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.943\n",
      "    load_time_ms: 2.288\n",
      "    num_steps_sampled: 7150000\n",
      "    num_steps_trained: 7150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.530061662197113\n",
      "      kl: 3.5119738578796387\n",
      "      policy_loss: 0.06716065853834152\n",
      "      total_loss: 148.27024841308594\n",
      "      vf_explained_var: 0.9310437440872192\n",
      "      vf_loss: 148.2030487060547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7090887427330017\n",
      "      kl: 0.023870592936873436\n",
      "      policy_loss: -0.004665111657232046\n",
      "      total_loss: 130.31170654296875\n",
      "      vf_explained_var: 0.9256607294082642\n",
      "      vf_loss: 130.31637573242188\n",
      "    sample_time_ms: 20027.105\n",
      "    update_time_ms: 6.528\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.75614850710969\n",
      "    rl_1: 53.06710349545492\n",
      "  time_since_restore: 16583.313096523285\n",
      "  time_this_iter_s: 23.364110469818115\n",
      "  time_total_s: 16583.313096523285\n",
      "  timestamp: 1550897196\n",
      "  timesteps_since_restore: 7150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7150000\n",
      "  training_iteration: 715\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16583 s, 715 iter, 7150000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-46-59\n",
      "  done: false\n",
      "  episode_len_mean: 110.55\n",
      "  episode_reward_max: 226.6834190403322\n",
      "  episode_reward_mean: 105.33184926448357\n",
      "  episode_reward_min: -174.1872258547089\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 61582\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3060.959\n",
      "    load_time_ms: 2.288\n",
      "    num_steps_sampled: 7160000\n",
      "    num_steps_trained: 7160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5031439661979675\n",
      "      kl: 0.02240152470767498\n",
      "      policy_loss: 0.0033753477036952972\n",
      "      total_loss: 142.45700073242188\n",
      "      vf_explained_var: 0.9517049789428711\n",
      "      vf_loss: 142.45361328125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6606280207633972\n",
      "      kl: 0.02673986926674843\n",
      "      policy_loss: 0.010641881264746189\n",
      "      total_loss: 131.99459838867188\n",
      "      vf_explained_var: 0.9409124851226807\n",
      "      vf_loss: 131.9839630126953\n",
      "    sample_time_ms: 20069.552\n",
      "    update_time_ms: 6.552\n",
      "  iterations_since_restore: 716\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.257654715156804\n",
      "    rl_1: 44.074194549326755\n",
      "  time_since_restore: 16606.629067659378\n",
      "  time_this_iter_s: 23.31597113609314\n",
      "  time_total_s: 16606.629067659378\n",
      "  timestamp: 1550897219\n",
      "  timesteps_since_restore: 7160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7160000\n",
      "  training_iteration: 716\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16606 s, 716 iter, 7160000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-47-23\n",
      "  done: false\n",
      "  episode_len_mean: 111.76\n",
      "  episode_reward_max: 224.93467703337737\n",
      "  episode_reward_mean: 103.9709303455678\n",
      "  episode_reward_min: -162.8843017801266\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 61670\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3058.991\n",
      "    load_time_ms: 2.253\n",
      "    num_steps_sampled: 7170000\n",
      "    num_steps_trained: 7170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4736497700214386\n",
      "      kl: 0.023379795253276825\n",
      "      policy_loss: 0.011531827040016651\n",
      "      total_loss: 123.70332336425781\n",
      "      vf_explained_var: 0.9519774317741394\n",
      "      vf_loss: 123.6917953491211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6349295973777771\n",
      "      kl: 0.022712362930178642\n",
      "      policy_loss: 0.009240484796464443\n",
      "      total_loss: 117.6294937133789\n",
      "      vf_explained_var: 0.9432116746902466\n",
      "      vf_loss: 117.6202392578125\n",
      "    sample_time_ms: 20113.48\n",
      "    update_time_ms: 6.366\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.87767834581291\n",
      "    rl_1: 44.09325199975488\n",
      "  time_since_restore: 16630.06381034851\n",
      "  time_this_iter_s: 23.43474268913269\n",
      "  time_total_s: 16630.06381034851\n",
      "  timestamp: 1550897243\n",
      "  timesteps_since_restore: 7170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7170000\n",
      "  training_iteration: 717\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16630 s, 717 iter, 7170000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-47-46\n",
      "  done: false\n",
      "  episode_len_mean: 111.55\n",
      "  episode_reward_max: 229.05823809716208\n",
      "  episode_reward_mean: 125.10698864540745\n",
      "  episode_reward_min: -158.08854254731722\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 61761\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.692\n",
      "    load_time_ms: 2.26\n",
      "    num_steps_sampled: 7180000\n",
      "    num_steps_trained: 7180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5679886937141418\n",
      "      kl: 0.01610470749437809\n",
      "      policy_loss: 0.00223362073302269\n",
      "      total_loss: 130.62643432617188\n",
      "      vf_explained_var: 0.9415377378463745\n",
      "      vf_loss: 130.6241912841797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6797761917114258\n",
      "      kl: 0.038331348448991776\n",
      "      policy_loss: 0.01334110926836729\n",
      "      total_loss: 122.47880554199219\n",
      "      vf_explained_var: 0.9292849898338318\n",
      "      vf_loss: 122.46546936035156\n",
      "    sample_time_ms: 20099.012\n",
      "    update_time_ms: 6.727\n",
      "  iterations_since_restore: 718\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 72.282683358346\n",
      "    rl_1: 52.82430528706147\n",
      "  time_since_restore: 16653.250698804855\n",
      "  time_this_iter_s: 23.186888456344604\n",
      "  time_total_s: 16653.250698804855\n",
      "  timestamp: 1550897266\n",
      "  timesteps_since_restore: 7180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7180000\n",
      "  training_iteration: 718\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16653 s, 718 iter, 7180000 ts, 125 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-48-09\n",
      "  done: false\n",
      "  episode_len_mean: 110.43\n",
      "  episode_reward_max: 219.5258983845172\n",
      "  episode_reward_mean: 112.5153056900877\n",
      "  episode_reward_min: -163.24473235782108\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 61851\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.271\n",
      "    load_time_ms: 2.262\n",
      "    num_steps_sampled: 7190000\n",
      "    num_steps_trained: 7190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.49354690313339233\n",
      "      kl: 6.09364652633667\n",
      "      policy_loss: 0.09556830674409866\n",
      "      total_loss: 99.24657440185547\n",
      "      vf_explained_var: 0.9591488242149353\n",
      "      vf_loss: 99.15100860595703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6462470889091492\n",
      "      kl: 0.04879208654165268\n",
      "      policy_loss: 0.013778336346149445\n",
      "      total_loss: 96.02523040771484\n",
      "      vf_explained_var: 0.950897216796875\n",
      "      vf_loss: 96.01145935058594\n",
      "    sample_time_ms: 20078.579\n",
      "    update_time_ms: 6.78\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.58406891751666\n",
      "    rl_1: 46.93123677257102\n",
      "  time_since_restore: 16676.57412290573\n",
      "  time_this_iter_s: 23.323424100875854\n",
      "  time_total_s: 16676.57412290573\n",
      "  timestamp: 1550897289\n",
      "  timesteps_since_restore: 7190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7190000\n",
      "  training_iteration: 719\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16676 s, 719 iter, 7190000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-48-33\n",
      "  done: false\n",
      "  episode_len_mean: 104.08\n",
      "  episode_reward_max: 225.3140253172462\n",
      "  episode_reward_mean: 98.46238614043354\n",
      "  episode_reward_min: -177.57815795315096\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 61947\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.633\n",
      "    load_time_ms: 2.342\n",
      "    num_steps_sampled: 7200000\n",
      "    num_steps_trained: 7200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6164475679397583\n",
      "      kl: 0.029515167698264122\n",
      "      policy_loss: 0.005543801002204418\n",
      "      total_loss: 206.2909698486328\n",
      "      vf_explained_var: 0.937045156955719\n",
      "      vf_loss: 206.28543090820312\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.735438883304596\n",
      "      kl: 0.025860466063022614\n",
      "      policy_loss: 0.006067443173378706\n",
      "      total_loss: 199.8345489501953\n",
      "      vf_explained_var: 0.9212304353713989\n",
      "      vf_loss: 199.82847595214844\n",
      "    sample_time_ms: 20089.578\n",
      "    update_time_ms: 6.797\n",
      "  iterations_since_restore: 720\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.693712977072046\n",
      "    rl_1: 41.76867316336151\n",
      "  time_since_restore: 16699.66818165779\n",
      "  time_this_iter_s: 23.094058752059937\n",
      "  time_total_s: 16699.66818165779\n",
      "  timestamp: 1550897313\n",
      "  timesteps_since_restore: 7200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7200000\n",
      "  training_iteration: 720\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16699 s, 720 iter, 7200000 ts, 98.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-48-56\n",
      "  done: false\n",
      "  episode_len_mean: 108.97\n",
      "  episode_reward_max: 229.67710801431372\n",
      "  episode_reward_mean: 104.15730386845338\n",
      "  episode_reward_min: -166.52319525665655\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 62038\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.86\n",
      "    load_time_ms: 2.373\n",
      "    num_steps_sampled: 7210000\n",
      "    num_steps_trained: 7210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5191662907600403\n",
      "      kl: 0.024384230375289917\n",
      "      policy_loss: 0.0018034126842394471\n",
      "      total_loss: 115.50601959228516\n",
      "      vf_explained_var: 0.9608390927314758\n",
      "      vf_loss: 115.50420379638672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6606259346008301\n",
      "      kl: 0.02326766774058342\n",
      "      policy_loss: 0.004085409455001354\n",
      "      total_loss: 110.8559341430664\n",
      "      vf_explained_var: 0.9528301954269409\n",
      "      vf_loss: 110.85185241699219\n",
      "    sample_time_ms: 20148.172\n",
      "    update_time_ms: 7.029\n",
      "  iterations_since_restore: 721\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.331763050792425\n",
      "    rl_1: 43.82554081766096\n",
      "  time_since_restore: 16723.09860420227\n",
      "  time_this_iter_s: 23.43042254447937\n",
      "  time_total_s: 16723.09860420227\n",
      "  timestamp: 1550897336\n",
      "  timesteps_since_restore: 7210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7210000\n",
      "  training_iteration: 721\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16723 s, 721 iter, 7210000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-49-20\n",
      "  done: false\n",
      "  episode_len_mean: 113.61\n",
      "  episode_reward_max: 218.37966348268552\n",
      "  episode_reward_mean: 99.89141607035073\n",
      "  episode_reward_min: -139.31360827444757\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 62126\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.441\n",
      "    load_time_ms: 2.345\n",
      "    num_steps_sampled: 7220000\n",
      "    num_steps_trained: 7220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4100457429885864\n",
      "      kl: 0.05677643045783043\n",
      "      policy_loss: 0.012558238580822945\n",
      "      total_loss: 144.9502410888672\n",
      "      vf_explained_var: 0.9428530931472778\n",
      "      vf_loss: 144.9376678466797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6034988760948181\n",
      "      kl: 0.021099163219332695\n",
      "      policy_loss: 0.003044262295588851\n",
      "      total_loss: 140.0997772216797\n",
      "      vf_explained_var: 0.9219788908958435\n",
      "      vf_loss: 140.09671020507812\n",
      "    sample_time_ms: 20193.855\n",
      "    update_time_ms: 6.968\n",
      "  iterations_since_restore: 722\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.48698626187304\n",
      "    rl_1: 40.404429808477715\n",
      "  time_since_restore: 16746.732838869095\n",
      "  time_this_iter_s: 23.63423466682434\n",
      "  time_total_s: 16746.732838869095\n",
      "  timestamp: 1550897360\n",
      "  timesteps_since_restore: 7220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7220000\n",
      "  training_iteration: 722\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16746 s, 722 iter, 7220000 ts, 99.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-49-43\n",
      "  done: false\n",
      "  episode_len_mean: 112.71\n",
      "  episode_reward_max: 229.7148863245836\n",
      "  episode_reward_mean: 112.48890054315844\n",
      "  episode_reward_min: -157.49987323830953\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 62216\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.2\n",
      "    load_time_ms: 2.333\n",
      "    num_steps_sampled: 7230000\n",
      "    num_steps_trained: 7230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.527337372303009\n",
      "      kl: 0.03500882163643837\n",
      "      policy_loss: 0.01302291639149189\n",
      "      total_loss: 178.3166046142578\n",
      "      vf_explained_var: 0.927065908908844\n",
      "      vf_loss: 178.30361938476562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6964859366416931\n",
      "      kl: 0.023867804557085037\n",
      "      policy_loss: 0.005795940291136503\n",
      "      total_loss: 170.43991088867188\n",
      "      vf_explained_var: 0.9148353338241577\n",
      "      vf_loss: 170.4341278076172\n",
      "    sample_time_ms: 20253.098\n",
      "    update_time_ms: 7.165\n",
      "  iterations_since_restore: 723\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.36233037034712\n",
      "    rl_1: 47.12657017281131\n",
      "  time_since_restore: 16770.355125904083\n",
      "  time_this_iter_s: 23.622287034988403\n",
      "  time_total_s: 16770.355125904083\n",
      "  timestamp: 1550897383\n",
      "  timesteps_since_restore: 7230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7230000\n",
      "  training_iteration: 723\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16770 s, 723 iter, 7230000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-50-06\n",
      "  done: false\n",
      "  episode_len_mean: 111.44\n",
      "  episode_reward_max: 211.56804677256002\n",
      "  episode_reward_mean: 103.25422535481441\n",
      "  episode_reward_min: -174.52036080515055\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 62307\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.762\n",
      "    load_time_ms: 2.427\n",
      "    num_steps_sampled: 7240000\n",
      "    num_steps_trained: 7240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5034540295600891\n",
      "      kl: 0.022002113983035088\n",
      "      policy_loss: 0.006860499270260334\n",
      "      total_loss: 76.13816833496094\n",
      "      vf_explained_var: 0.9729510545730591\n",
      "      vf_loss: 76.13130187988281\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6618370413780212\n",
      "      kl: 0.013645229861140251\n",
      "      policy_loss: 0.005718206986784935\n",
      "      total_loss: 72.0934829711914\n",
      "      vf_explained_var: 0.96685391664505\n",
      "      vf_loss: 72.08775329589844\n",
      "    sample_time_ms: 20240.706\n",
      "    update_time_ms: 7.204\n",
      "  iterations_since_restore: 724\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 61.48792810180754\n",
      "    rl_1: 41.766297253006876\n",
      "  time_since_restore: 16793.35577607155\n",
      "  time_this_iter_s: 23.00065016746521\n",
      "  time_total_s: 16793.35577607155\n",
      "  timestamp: 1550897406\n",
      "  timesteps_since_restore: 7240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7240000\n",
      "  training_iteration: 724\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16793 s, 724 iter, 7240000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-50-30\n",
      "  done: false\n",
      "  episode_len_mean: 105.55\n",
      "  episode_reward_max: 209.59305126881597\n",
      "  episode_reward_mean: 115.44976238680691\n",
      "  episode_reward_min: -142.20960322842828\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 62401\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.575\n",
      "    load_time_ms: 2.416\n",
      "    num_steps_sampled: 7250000\n",
      "    num_steps_trained: 7250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5733689665794373\n",
      "      kl: 0.016369963064789772\n",
      "      policy_loss: 0.0009693853789940476\n",
      "      total_loss: 120.46614837646484\n",
      "      vf_explained_var: 0.9542599320411682\n",
      "      vf_loss: 120.46514129638672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7805150151252747\n",
      "      kl: 0.01939154416322708\n",
      "      policy_loss: -0.0008535514934919775\n",
      "      total_loss: 118.9224853515625\n",
      "      vf_explained_var: 0.9435154795646667\n",
      "      vf_loss: 118.92333984375\n",
      "    sample_time_ms: 20248.686\n",
      "    update_time_ms: 7.629\n",
      "  iterations_since_restore: 725\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.06673507678687\n",
      "    rl_1: 51.383027310020026\n",
      "  time_since_restore: 16816.80000948906\n",
      "  time_this_iter_s: 23.444233417510986\n",
      "  time_total_s: 16816.80000948906\n",
      "  timestamp: 1550897430\n",
      "  timesteps_since_restore: 7250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7250000\n",
      "  training_iteration: 725\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16816 s, 725 iter, 7250000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-50-53\n",
      "  done: false\n",
      "  episode_len_mean: 113.83\n",
      "  episode_reward_max: 229.44381810963782\n",
      "  episode_reward_mean: 108.79717336233762\n",
      "  episode_reward_min: -155.1920778119785\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 62487\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.425\n",
      "    load_time_ms: 2.393\n",
      "    num_steps_sampled: 7260000\n",
      "    num_steps_trained: 7260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.38956835865974426\n",
      "      kl: 0.017696397379040718\n",
      "      policy_loss: 0.00260693090967834\n",
      "      total_loss: 112.42234802246094\n",
      "      vf_explained_var: 0.9555861353874207\n",
      "      vf_loss: 112.41972351074219\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6098516583442688\n",
      "      kl: 0.023251503705978394\n",
      "      policy_loss: 0.0021896164398640394\n",
      "      total_loss: 108.70366668701172\n",
      "      vf_explained_var: 0.9473033547401428\n",
      "      vf_loss: 108.70146942138672\n",
      "    sample_time_ms: 20241.102\n",
      "    update_time_ms: 7.718\n",
      "  iterations_since_restore: 726\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.78034608168166\n",
      "    rl_1: 46.01682728065601\n",
      "  time_since_restore: 16840.068873167038\n",
      "  time_this_iter_s: 23.268863677978516\n",
      "  time_total_s: 16840.068873167038\n",
      "  timestamp: 1550897453\n",
      "  timesteps_since_restore: 7260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7260000\n",
      "  training_iteration: 726\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16840 s, 726 iter, 7260000 ts, 109 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-51-16\n",
      "  done: false\n",
      "  episode_len_mean: 104.31\n",
      "  episode_reward_max: 212.7364269836312\n",
      "  episode_reward_mean: 93.51821951050269\n",
      "  episode_reward_min: -167.32648539691405\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 62583\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.648\n",
      "    load_time_ms: 2.394\n",
      "    num_steps_sampled: 7270000\n",
      "    num_steps_trained: 7270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6704761981964111\n",
      "      kl: 0.024857524782419205\n",
      "      policy_loss: 0.0038195252418518066\n",
      "      total_loss: 156.40980529785156\n",
      "      vf_explained_var: 0.9494880437850952\n",
      "      vf_loss: 156.40599060058594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8226523995399475\n",
      "      kl: 0.0345984511077404\n",
      "      policy_loss: 0.00520732905715704\n",
      "      total_loss: 139.13172912597656\n",
      "      vf_explained_var: 0.9423178434371948\n",
      "      vf_loss: 139.1265106201172\n",
      "    sample_time_ms: 20174.238\n",
      "    update_time_ms: 8.355\n",
      "  iterations_since_restore: 727\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.19333817894852\n",
      "    rl_1: 38.32488133155418\n",
      "  time_since_restore: 16862.845069408417\n",
      "  time_this_iter_s: 22.776196241378784\n",
      "  time_total_s: 16862.845069408417\n",
      "  timestamp: 1550897476\n",
      "  timesteps_since_restore: 7270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7270000\n",
      "  training_iteration: 727\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16862 s, 727 iter, 7270000 ts, 93.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-51-39\n",
      "  done: false\n",
      "  episode_len_mean: 104.28\n",
      "  episode_reward_max: 218.9881641940329\n",
      "  episode_reward_mean: 126.02491014049532\n",
      "  episode_reward_min: -172.72611727535866\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 62679\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.162\n",
      "    load_time_ms: 2.396\n",
      "    num_steps_sampled: 7280000\n",
      "    num_steps_trained: 7280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6497300863265991\n",
      "      kl: 0.0342068187892437\n",
      "      policy_loss: 0.006863371469080448\n",
      "      total_loss: 107.6235122680664\n",
      "      vf_explained_var: 0.9597342014312744\n",
      "      vf_loss: 107.61664581298828\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7990882396697998\n",
      "      kl: 0.017528021708130836\n",
      "      policy_loss: 0.00028678542003035545\n",
      "      total_loss: 100.34215545654297\n",
      "      vf_explained_var: 0.9534695148468018\n",
      "      vf_loss: 100.34185791015625\n",
      "    sample_time_ms: 20120.618\n",
      "    update_time_ms: 8.005\n",
      "  iterations_since_restore: 728\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.74418361663744\n",
      "    rl_1: 55.280726523857865\n",
      "  time_since_restore: 16885.636669158936\n",
      "  time_this_iter_s: 22.7915997505188\n",
      "  time_total_s: 16885.636669158936\n",
      "  timestamp: 1550897499\n",
      "  timesteps_since_restore: 7280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7280000\n",
      "  training_iteration: 728\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16885 s, 728 iter, 7280000 ts, 126 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-52-01\n",
      "  done: false\n",
      "  episode_len_mean: 110.94\n",
      "  episode_reward_max: 213.03780433035507\n",
      "  episode_reward_mean: 113.35566374646714\n",
      "  episode_reward_min: -140.89338312543913\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 62770\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.975\n",
      "    load_time_ms: 2.468\n",
      "    num_steps_sampled: 7290000\n",
      "    num_steps_trained: 7290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4880049228668213\n",
      "      kl: 0.0228961743414402\n",
      "      policy_loss: 0.008279738947749138\n",
      "      total_loss: 95.94725036621094\n",
      "      vf_explained_var: 0.9640960693359375\n",
      "      vf_loss: 95.93896484375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.688898503780365\n",
      "      kl: 0.01948644034564495\n",
      "      policy_loss: 0.0017961007542908192\n",
      "      total_loss: 96.10562896728516\n",
      "      vf_explained_var: 0.9530242681503296\n",
      "      vf_loss: 96.10384368896484\n",
      "    sample_time_ms: 20052.746\n",
      "    update_time_ms: 7.995\n",
      "  iterations_since_restore: 729\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.9960410469741\n",
      "    rl_1: 47.359622699493045\n",
      "  time_since_restore: 16908.154712438583\n",
      "  time_this_iter_s: 22.518043279647827\n",
      "  time_total_s: 16908.154712438583\n",
      "  timestamp: 1550897521\n",
      "  timesteps_since_restore: 7290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7290000\n",
      "  training_iteration: 729\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16908 s, 729 iter, 7290000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-52-24\n",
      "  done: false\n",
      "  episode_len_mean: 112.07\n",
      "  episode_reward_max: 225.2660865132682\n",
      "  episode_reward_mean: 114.20522062038907\n",
      "  episode_reward_min: -176.59903819779592\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 62858\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.724\n",
      "    load_time_ms: 2.441\n",
      "    num_steps_sampled: 7300000\n",
      "    num_steps_trained: 7300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.44456803798675537\n",
      "      kl: 0.029357796534895897\n",
      "      policy_loss: 0.010744304396212101\n",
      "      total_loss: 132.01768493652344\n",
      "      vf_explained_var: 0.9476417899131775\n",
      "      vf_loss: 132.0069580078125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6598541140556335\n",
      "      kl: 0.03202519938349724\n",
      "      policy_loss: 0.007610812317579985\n",
      "      total_loss: 127.66425323486328\n",
      "      vf_explained_var: 0.9407017230987549\n",
      "      vf_loss: 127.65665435791016\n",
      "    sample_time_ms: 20031.695\n",
      "    update_time_ms: 7.959\n",
      "  iterations_since_restore: 730\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 64.70270422244946\n",
      "    rl_1: 49.5025163979396\n",
      "  time_since_restore: 16931.0124669075\n",
      "  time_this_iter_s: 22.857754468917847\n",
      "  time_total_s: 16931.0124669075\n",
      "  timestamp: 1550897544\n",
      "  timesteps_since_restore: 7300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7300000\n",
      "  training_iteration: 730\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16931 s, 730 iter, 7300000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-52-47\n",
      "  done: false\n",
      "  episode_len_mean: 103.17\n",
      "  episode_reward_max: 216.80055716148718\n",
      "  episode_reward_mean: 83.57966545713337\n",
      "  episode_reward_min: -165.55475526649198\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 62955\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.366\n",
      "    load_time_ms: 2.467\n",
      "    num_steps_sampled: 7310000\n",
      "    num_steps_trained: 7310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6065992712974548\n",
      "      kl: 0.03036324866116047\n",
      "      policy_loss: 0.008535975590348244\n",
      "      total_loss: 205.6840057373047\n",
      "      vf_explained_var: 0.9367024302482605\n",
      "      vf_loss: 205.67544555664062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7610304355621338\n",
      "      kl: 0.05149146914482117\n",
      "      policy_loss: 0.015236356295645237\n",
      "      total_loss: 185.0388946533203\n",
      "      vf_explained_var: 0.9272946119308472\n",
      "      vf_loss: 185.023681640625\n",
      "    sample_time_ms: 19981.204\n",
      "    update_time_ms: 7.748\n",
      "  iterations_since_restore: 731\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.50083649633867\n",
      "    rl_1: 35.07882896079471\n",
      "  time_since_restore: 16953.923050642014\n",
      "  time_this_iter_s: 22.91058373451233\n",
      "  time_total_s: 16953.923050642014\n",
      "  timestamp: 1550897567\n",
      "  timesteps_since_restore: 7310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7310000\n",
      "  training_iteration: 731\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16953 s, 731 iter, 7310000 ts, 83.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-53-10\n",
      "  done: false\n",
      "  episode_len_mean: 105.71\n",
      "  episode_reward_max: 213.29438688933337\n",
      "  episode_reward_mean: 87.7886626420032\n",
      "  episode_reward_min: -169.93144763687206\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 63049\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.701\n",
      "    load_time_ms: 2.585\n",
      "    num_steps_sampled: 7320000\n",
      "    num_steps_trained: 7320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5273578763008118\n",
      "      kl: 0.027166152372956276\n",
      "      policy_loss: 0.009496924467384815\n",
      "      total_loss: 138.83152770996094\n",
      "      vf_explained_var: 0.9586264491081238\n",
      "      vf_loss: 138.82200622558594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7372358441352844\n",
      "      kl: 0.026032915338873863\n",
      "      policy_loss: 0.006920199375599623\n",
      "      total_loss: 128.63720703125\n",
      "      vf_explained_var: 0.9503071904182434\n",
      "      vf_loss: 128.63026428222656\n",
      "    sample_time_ms: 19931.293\n",
      "    update_time_ms: 7.781\n",
      "  iterations_since_restore: 732\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.99606175569368\n",
      "    rl_1: 37.79260088630947\n",
      "  time_since_restore: 16977.033185005188\n",
      "  time_this_iter_s: 23.11013436317444\n",
      "  time_total_s: 16977.033185005188\n",
      "  timestamp: 1550897590\n",
      "  timesteps_since_restore: 7320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7320000\n",
      "  training_iteration: 732\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 16977 s, 732 iter, 7320000 ts, 87.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-53-34\n",
      "  done: false\n",
      "  episode_len_mean: 104.71\n",
      "  episode_reward_max: 221.7892632656426\n",
      "  episode_reward_mean: 87.52549829203677\n",
      "  episode_reward_min: -172.44408052201328\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 63144\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.16\n",
      "    load_time_ms: 2.582\n",
      "    num_steps_sampled: 7330000\n",
      "    num_steps_trained: 7330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5884143710136414\n",
      "      kl: 0.03235028684139252\n",
      "      policy_loss: 0.00984644703567028\n",
      "      total_loss: 168.4065704345703\n",
      "      vf_explained_var: 0.947961688041687\n",
      "      vf_loss: 168.39674377441406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7588382363319397\n",
      "      kl: 0.033711645752191544\n",
      "      policy_loss: 0.011228115297853947\n",
      "      total_loss: 152.26052856445312\n",
      "      vf_explained_var: 0.9405470490455627\n",
      "      vf_loss: 152.2493133544922\n",
      "    sample_time_ms: 19867.897\n",
      "    update_time_ms: 7.682\n",
      "  iterations_since_restore: 733\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.413690014456535\n",
      "    rl_1: 36.11180827758025\n",
      "  time_since_restore: 17000.003158807755\n",
      "  time_this_iter_s: 22.96997380256653\n",
      "  time_total_s: 17000.003158807755\n",
      "  timestamp: 1550897614\n",
      "  timesteps_since_restore: 7330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7330000\n",
      "  training_iteration: 733\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17000 s, 733 iter, 7330000 ts, 87.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-53-57\n",
      "  done: false\n",
      "  episode_len_mean: 112.25\n",
      "  episode_reward_max: 217.98306945999522\n",
      "  episode_reward_mean: 90.08066211088585\n",
      "  episode_reward_min: -171.15656223525545\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 63233\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.067\n",
      "    load_time_ms: 2.479\n",
      "    num_steps_sampled: 7340000\n",
      "    num_steps_trained: 7340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4897928833961487\n",
      "      kl: 0.021499991416931152\n",
      "      policy_loss: 0.008912763558328152\n",
      "      total_loss: 112.6440658569336\n",
      "      vf_explained_var: 0.9608084559440613\n",
      "      vf_loss: 112.63513946533203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.676485002040863\n",
      "      kl: 0.02322053723037243\n",
      "      policy_loss: 0.00515018729493022\n",
      "      total_loss: 106.42034912109375\n",
      "      vf_explained_var: 0.9527509808540344\n",
      "      vf_loss: 106.41519927978516\n",
      "    sample_time_ms: 19904.609\n",
      "    update_time_ms: 7.699\n",
      "  iterations_since_restore: 734\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.819249248793675\n",
      "    rl_1: 35.2614128620922\n",
      "  time_since_restore: 17023.345822811127\n",
      "  time_this_iter_s: 23.342664003372192\n",
      "  time_total_s: 17023.345822811127\n",
      "  timestamp: 1550897637\n",
      "  timesteps_since_restore: 7340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7340000\n",
      "  training_iteration: 734\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17023 s, 734 iter, 7340000 ts, 90.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-54-20\n",
      "  done: false\n",
      "  episode_len_mean: 113.77\n",
      "  episode_reward_max: 227.7963238166531\n",
      "  episode_reward_mean: 94.75241112572138\n",
      "  episode_reward_min: -165.5203724194706\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 63323\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.449\n",
      "    load_time_ms: 2.475\n",
      "    num_steps_sampled: 7350000\n",
      "    num_steps_trained: 7350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.425812304019928\n",
      "      kl: 68.48876190185547\n",
      "      policy_loss: 0.11312665790319443\n",
      "      total_loss: 172.6763153076172\n",
      "      vf_explained_var: 0.941994309425354\n",
      "      vf_loss: 172.56320190429688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6706751585006714\n",
      "      kl: 0.024839499965310097\n",
      "      policy_loss: 0.0027478784322738647\n",
      "      total_loss: 162.8356475830078\n",
      "      vf_explained_var: 0.9266981482505798\n",
      "      vf_loss: 162.83290100097656\n",
      "    sample_time_ms: 19883.635\n",
      "    update_time_ms: 7.34\n",
      "  iterations_since_restore: 735\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.82682055676409\n",
      "    rl_1: 37.92559056895725\n",
      "  time_since_restore: 17046.572832107544\n",
      "  time_this_iter_s: 23.227009296417236\n",
      "  time_total_s: 17046.572832107544\n",
      "  timestamp: 1550897660\n",
      "  timesteps_since_restore: 7350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7350000\n",
      "  training_iteration: 735\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17046 s, 735 iter, 7350000 ts, 94.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-54-43\n",
      "  done: false\n",
      "  episode_len_mean: 113.69\n",
      "  episode_reward_max: 221.3201852666881\n",
      "  episode_reward_mean: 86.35502418855373\n",
      "  episode_reward_min: -165.5203724194706\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 63407\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.824\n",
      "    load_time_ms: 2.458\n",
      "    num_steps_sampled: 7360000\n",
      "    num_steps_trained: 7360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.47273924946784973\n",
      "      kl: 0.011817244812846184\n",
      "      policy_loss: 0.0010843997588381171\n",
      "      total_loss: 223.00563049316406\n",
      "      vf_explained_var: 0.9285712838172913\n",
      "      vf_loss: 223.00460815429688\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.707868218421936\n",
      "      kl: 0.025853872299194336\n",
      "      policy_loss: 0.0074162851087749004\n",
      "      total_loss: 212.0031280517578\n",
      "      vf_explained_var: 0.9152265787124634\n",
      "      vf_loss: 211.99571228027344\n",
      "    sample_time_ms: 19838.327\n",
      "    update_time_ms: 7.432\n",
      "  iterations_since_restore: 736\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.36835959457792\n",
      "    rl_1: 33.986664593975824\n",
      "  time_since_restore: 17069.38305902481\n",
      "  time_this_iter_s: 22.810226917266846\n",
      "  time_total_s: 17069.38305902481\n",
      "  timestamp: 1550897683\n",
      "  timesteps_since_restore: 7360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7360000\n",
      "  training_iteration: 736\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17069 s, 736 iter, 7360000 ts, 86.4 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-55-06\n",
      "  done: false\n",
      "  episode_len_mean: 113.0\n",
      "  episode_reward_max: 215.84590399464025\n",
      "  episode_reward_mean: 81.2125097244732\n",
      "  episode_reward_min: -164.97207042046062\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 63497\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.513\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 7370000\n",
      "    num_steps_trained: 7370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5466368794441223\n",
      "      kl: 0.008862845599651337\n",
      "      policy_loss: 0.0022675509098917246\n",
      "      total_loss: 263.3983459472656\n",
      "      vf_explained_var: 0.9167582392692566\n",
      "      vf_loss: 263.3961181640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7804574966430664\n",
      "      kl: 0.029863815754652023\n",
      "      policy_loss: 0.0020286126527935266\n",
      "      total_loss: 245.29421997070312\n",
      "      vf_explained_var: 0.8976907730102539\n",
      "      vf_loss: 245.29214477539062\n",
      "    sample_time_ms: 19864.193\n",
      "    update_time_ms: 6.732\n",
      "  iterations_since_restore: 737\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.59364635769018\n",
      "    rl_1: 31.618863366783025\n",
      "  time_since_restore: 17092.416400909424\n",
      "  time_this_iter_s: 23.033341884613037\n",
      "  time_total_s: 17092.416400909424\n",
      "  timestamp: 1550897706\n",
      "  timesteps_since_restore: 7370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7370000\n",
      "  training_iteration: 737\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17092 s, 737 iter, 7370000 ts, 81.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-55-29\n",
      "  done: false\n",
      "  episode_len_mean: 110.71\n",
      "  episode_reward_max: 210.8440003029746\n",
      "  episode_reward_mean: 89.34226792733705\n",
      "  episode_reward_min: -159.82490836681245\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 63589\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3050.293\n",
      "    load_time_ms: 2.535\n",
      "    num_steps_sampled: 7380000\n",
      "    num_steps_trained: 7380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5479284524917603\n",
      "      kl: 0.015546209178864956\n",
      "      policy_loss: 0.0014852763852104545\n",
      "      total_loss: 200.66326904296875\n",
      "      vf_explained_var: 0.9402905702590942\n",
      "      vf_loss: 200.6617889404297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7697595357894897\n",
      "      kl: 0.03297444432973862\n",
      "      policy_loss: 0.006350383162498474\n",
      "      total_loss: 190.1835479736328\n",
      "      vf_explained_var: 0.9267752170562744\n",
      "      vf_loss: 190.17721557617188\n",
      "    sample_time_ms: 19911.176\n",
      "    update_time_ms: 6.92\n",
      "  iterations_since_restore: 738\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 53.695955452174985\n",
      "    rl_1: 35.646312475162055\n",
      "  time_since_restore: 17115.517946004868\n",
      "  time_this_iter_s: 23.101545095443726\n",
      "  time_total_s: 17115.517946004868\n",
      "  timestamp: 1550897729\n",
      "  timesteps_since_restore: 7380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7380000\n",
      "  training_iteration: 738\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17115 s, 738 iter, 7380000 ts, 89.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-55-53\n",
      "  done: false\n",
      "  episode_len_mean: 109.67\n",
      "  episode_reward_max: 226.3648350951157\n",
      "  episode_reward_mean: 75.92861817839646\n",
      "  episode_reward_min: -167.48465759466956\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 63679\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3050.043\n",
      "    load_time_ms: 2.462\n",
      "    num_steps_sampled: 7390000\n",
      "    num_steps_trained: 7390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5260334610939026\n",
      "      kl: 0.017094459384679794\n",
      "      policy_loss: 0.001930374768562615\n",
      "      total_loss: 186.5521697998047\n",
      "      vf_explained_var: 0.9446821212768555\n",
      "      vf_loss: 186.55026245117188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7848201394081116\n",
      "      kl: 0.03174484521150589\n",
      "      policy_loss: 0.005388478748500347\n",
      "      total_loss: 182.58639526367188\n",
      "      vf_explained_var: 0.9314674735069275\n",
      "      vf_loss: 182.58099365234375\n",
      "    sample_time_ms: 20009.345\n",
      "    update_time_ms: 6.969\n",
      "  iterations_since_restore: 739\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 44.44022573187548\n",
      "    rl_1: 31.488392446520983\n",
      "  time_since_restore: 17139.012229442596\n",
      "  time_this_iter_s: 23.494283437728882\n",
      "  time_total_s: 17139.012229442596\n",
      "  timestamp: 1550897753\n",
      "  timesteps_since_restore: 7390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7390000\n",
      "  training_iteration: 739\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17139 s, 739 iter, 7390000 ts, 75.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-56-16\n",
      "  done: false\n",
      "  episode_len_mean: 107.69\n",
      "  episode_reward_max: 212.058834596938\n",
      "  episode_reward_mean: 88.84439781913439\n",
      "  episode_reward_min: -160.86649496155457\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 63772\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3053.782\n",
      "    load_time_ms: 2.412\n",
      "    num_steps_sampled: 7400000\n",
      "    num_steps_trained: 7400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5074535608291626\n",
      "      kl: 0.026500921696424484\n",
      "      policy_loss: 0.009508232586085796\n",
      "      total_loss: 176.996337890625\n",
      "      vf_explained_var: 0.9438515901565552\n",
      "      vf_loss: 176.98684692382812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7394559979438782\n",
      "      kl: 0.021543582901358604\n",
      "      policy_loss: 0.0012183415237814188\n",
      "      total_loss: 171.75428771972656\n",
      "      vf_explained_var: 0.9311463832855225\n",
      "      vf_loss: 171.75308227539062\n",
      "    sample_time_ms: 20036.826\n",
      "    update_time_ms: 7.391\n",
      "  iterations_since_restore: 740\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.46289486628025\n",
      "    rl_1: 38.38150295285414\n",
      "  time_since_restore: 17162.186012268066\n",
      "  time_this_iter_s: 23.17378282546997\n",
      "  time_total_s: 17162.186012268066\n",
      "  timestamp: 1550897776\n",
      "  timesteps_since_restore: 7400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7400000\n",
      "  training_iteration: 740\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17162 s, 740 iter, 7400000 ts, 88.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-56-39\n",
      "  done: false\n",
      "  episode_len_mean: 112.38\n",
      "  episode_reward_max: 233.88822282916408\n",
      "  episode_reward_mean: 78.92695063426616\n",
      "  episode_reward_min: -169.83193015889245\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 63859\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.267\n",
      "    load_time_ms: 2.414\n",
      "    num_steps_sampled: 7410000\n",
      "    num_steps_trained: 7410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5197213292121887\n",
      "      kl: 0.017842816188931465\n",
      "      policy_loss: 0.0013000782346352935\n",
      "      total_loss: 196.0221710205078\n",
      "      vf_explained_var: 0.9425250291824341\n",
      "      vf_loss: 196.02088928222656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7318559288978577\n",
      "      kl: 0.02326810359954834\n",
      "      policy_loss: 0.005572414491325617\n",
      "      total_loss: 171.63368225097656\n",
      "      vf_explained_var: 0.9334083199501038\n",
      "      vf_loss: 171.62815856933594\n",
      "    sample_time_ms: 20041.067\n",
      "    update_time_ms: 7.552\n",
      "  iterations_since_restore: 741\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 47.16807387193112\n",
      "    rl_1: 31.758876762335053\n",
      "  time_since_restore: 17185.3654794693\n",
      "  time_this_iter_s: 23.17946720123291\n",
      "  time_total_s: 17185.3654794693\n",
      "  timestamp: 1550897799\n",
      "  timesteps_since_restore: 7410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7410000\n",
      "  training_iteration: 741\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17185 s, 741 iter, 7410000 ts, 78.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-57-02\n",
      "  done: false\n",
      "  episode_len_mean: 118.98\n",
      "  episode_reward_max: 211.91764225688868\n",
      "  episode_reward_mean: 95.57266463654243\n",
      "  episode_reward_min: -169.83193015889245\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 63942\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.84\n",
      "    load_time_ms: 2.423\n",
      "    num_steps_sampled: 7420000\n",
      "    num_steps_trained: 7420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.42792999744415283\n",
      "      kl: 0.02428184077143669\n",
      "      policy_loss: 0.0033677236642688513\n",
      "      total_loss: 119.36420440673828\n",
      "      vf_explained_var: 0.9510501027107239\n",
      "      vf_loss: 119.3608169555664\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6187468767166138\n",
      "      kl: 0.021562155336141586\n",
      "      policy_loss: 0.003842298872768879\n",
      "      total_loss: 104.47329711914062\n",
      "      vf_explained_var: 0.9418172836303711\n",
      "      vf_loss: 104.4694595336914\n",
      "    sample_time_ms: 20002.268\n",
      "    update_time_ms: 7.505\n",
      "  iterations_since_restore: 742\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 57.26137134039427\n",
      "    rl_1: 38.31129329614815\n",
      "  time_since_restore: 17208.123938560486\n",
      "  time_this_iter_s: 22.758459091186523\n",
      "  time_total_s: 17208.123938560486\n",
      "  timestamp: 1550897822\n",
      "  timesteps_since_restore: 7420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7420000\n",
      "  training_iteration: 742\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17208 s, 742 iter, 7420000 ts, 95.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-57-25\n",
      "  done: false\n",
      "  episode_len_mean: 122.61\n",
      "  episode_reward_max: 220.68044495469783\n",
      "  episode_reward_mean: 90.71951663654993\n",
      "  episode_reward_min: -173.53333865440408\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 64024\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.626\n",
      "    load_time_ms: 2.444\n",
      "    num_steps_sampled: 7430000\n",
      "    num_steps_trained: 7430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.39066579937934875\n",
      "      kl: 0.01602988690137863\n",
      "      policy_loss: -0.0007902281358838081\n",
      "      total_loss: 193.149658203125\n",
      "      vf_explained_var: 0.9347570538520813\n",
      "      vf_loss: 193.1504364013672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5565835237503052\n",
      "      kl: 0.025946522131562233\n",
      "      policy_loss: 0.007112542167305946\n",
      "      total_loss: 172.42926025390625\n",
      "      vf_explained_var: 0.9305018186569214\n",
      "      vf_loss: 172.42213439941406\n",
      "    sample_time_ms: 20027.711\n",
      "    update_time_ms: 7.435\n",
      "  iterations_since_restore: 743\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.09458586968358\n",
      "    rl_1: 36.62493076686635\n",
      "  time_since_restore: 17231.366686344147\n",
      "  time_this_iter_s: 23.24274778366089\n",
      "  time_total_s: 17231.366686344147\n",
      "  timestamp: 1550897845\n",
      "  timesteps_since_restore: 7430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7430000\n",
      "  training_iteration: 743\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17231 s, 743 iter, 7430000 ts, 90.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-57-49\n",
      "  done: false\n",
      "  episode_len_mean: 108.93\n",
      "  episode_reward_max: 203.6204673116279\n",
      "  episode_reward_mean: 63.83519541407951\n",
      "  episode_reward_min: -163.73046317163238\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 64116\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.231\n",
      "    load_time_ms: 2.461\n",
      "    num_steps_sampled: 7440000\n",
      "    num_steps_trained: 7440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.559315025806427\n",
      "      kl: 0.021361781284213066\n",
      "      policy_loss: 0.0030783778056502342\n",
      "      total_loss: 162.98147583007812\n",
      "      vf_explained_var: 0.9539803862571716\n",
      "      vf_loss: 162.97837829589844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7454854249954224\n",
      "      kl: 0.0252228993922472\n",
      "      policy_loss: 0.003704348113387823\n",
      "      total_loss: 153.81671142578125\n",
      "      vf_explained_var: 0.9428120255470276\n",
      "      vf_loss: 153.81300354003906\n",
      "    sample_time_ms: 20031.329\n",
      "    update_time_ms: 7.651\n",
      "  iterations_since_restore: 744\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 39.47939624280746\n",
      "    rl_1: 24.355799171272047\n",
      "  time_since_restore: 17254.76299381256\n",
      "  time_this_iter_s: 23.396307468414307\n",
      "  time_total_s: 17254.76299381256\n",
      "  timestamp: 1550897869\n",
      "  timesteps_since_restore: 7440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7440000\n",
      "  training_iteration: 744\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17254 s, 744 iter, 7440000 ts, 63.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-58-12\n",
      "  done: false\n",
      "  episode_len_mean: 115.18\n",
      "  episode_reward_max: 221.83041974892106\n",
      "  episode_reward_mean: 94.92890287684585\n",
      "  episode_reward_min: -160.67662808395994\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 64203\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.47\n",
      "    load_time_ms: 2.464\n",
      "    num_steps_sampled: 7450000\n",
      "    num_steps_trained: 7450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5872854590415955\n",
      "      kl: 0.023804927244782448\n",
      "      policy_loss: 0.007550565060228109\n",
      "      total_loss: 139.45892333984375\n",
      "      vf_explained_var: 0.9489973783493042\n",
      "      vf_loss: 139.4513702392578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7629519104957581\n",
      "      kl: 0.022286059334874153\n",
      "      policy_loss: 0.009394343942403793\n",
      "      total_loss: 129.9262237548828\n",
      "      vf_explained_var: 0.9405521750450134\n",
      "      vf_loss: 129.91685485839844\n",
      "    sample_time_ms: 20020.086\n",
      "    update_time_ms: 7.696\n",
      "  iterations_since_restore: 745\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 55.76513534660486\n",
      "    rl_1: 39.163767530240996\n",
      "  time_since_restore: 17277.92086482048\n",
      "  time_this_iter_s: 23.15787100791931\n",
      "  time_total_s: 17277.92086482048\n",
      "  timestamp: 1550897892\n",
      "  timesteps_since_restore: 7450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7450000\n",
      "  training_iteration: 745\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17277 s, 745 iter, 7450000 ts, 94.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-58-35\n",
      "  done: false\n",
      "  episode_len_mean: 112.49\n",
      "  episode_reward_max: 228.25113488485957\n",
      "  episode_reward_mean: 79.62079596452159\n",
      "  episode_reward_min: -160.1202988674503\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 64292\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.839\n",
      "    load_time_ms: 2.477\n",
      "    num_steps_sampled: 7460000\n",
      "    num_steps_trained: 7460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.502027153968811\n",
      "      kl: 0.01719791814684868\n",
      "      policy_loss: 0.00364434951916337\n",
      "      total_loss: 157.2924041748047\n",
      "      vf_explained_var: 0.9530038833618164\n",
      "      vf_loss: 157.28875732421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6718536615371704\n",
      "      kl: 0.01963389851152897\n",
      "      policy_loss: 0.0035429031122475863\n",
      "      total_loss: 147.69712829589844\n",
      "      vf_explained_var: 0.9418696761131287\n",
      "      vf_loss: 147.69358825683594\n",
      "    sample_time_ms: 20079.047\n",
      "    update_time_ms: 7.696\n",
      "  iterations_since_restore: 746\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 46.8091934817145\n",
      "    rl_1: 32.81160248280708\n",
      "  time_since_restore: 17301.28546357155\n",
      "  time_this_iter_s: 23.364598751068115\n",
      "  time_total_s: 17301.28546357155\n",
      "  timestamp: 1550897915\n",
      "  timesteps_since_restore: 7460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7460000\n",
      "  training_iteration: 746\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17301 s, 746 iter, 7460000 ts, 79.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-58-59\n",
      "  done: false\n",
      "  episode_len_mean: 108.54\n",
      "  episode_reward_max: 223.74274832153574\n",
      "  episode_reward_mean: 86.61548736630095\n",
      "  episode_reward_min: -174.38640297001731\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 64383\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.671\n",
      "    load_time_ms: 2.54\n",
      "    num_steps_sampled: 7470000\n",
      "    num_steps_trained: 7470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6272906064987183\n",
      "      kl: 3.23156476020813\n",
      "      policy_loss: 0.12660761177539825\n",
      "      total_loss: 196.67425537109375\n",
      "      vf_explained_var: 0.9402516484260559\n",
      "      vf_loss: 196.54766845703125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8161611557006836\n",
      "      kl: 0.0348866730928421\n",
      "      policy_loss: 0.006399530451744795\n",
      "      total_loss: 170.57522583007812\n",
      "      vf_explained_var: 0.9368283152580261\n",
      "      vf_loss: 170.56881713867188\n",
      "    sample_time_ms: 20122.61\n",
      "    update_time_ms: 7.911\n",
      "  iterations_since_restore: 747\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 49.334880385343816\n",
      "    rl_1: 37.280606980957124\n",
      "  time_since_restore: 17324.75947213173\n",
      "  time_this_iter_s: 23.474008560180664\n",
      "  time_total_s: 17324.75947213173\n",
      "  timestamp: 1550897939\n",
      "  timesteps_since_restore: 7470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7470000\n",
      "  training_iteration: 747\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17324 s, 747 iter, 7470000 ts, 86.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-59-22\n",
      "  done: false\n",
      "  episode_len_mean: 102.0\n",
      "  episode_reward_max: 230.13654586140225\n",
      "  episode_reward_mean: 44.343536019608834\n",
      "  episode_reward_min: -160.31356199143917\n",
      "  episodes_this_iter: 97\n",
      "  episodes_total: 64480\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.208\n",
      "    load_time_ms: 2.502\n",
      "    num_steps_sampled: 7480000\n",
      "    num_steps_trained: 7480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5957974195480347\n",
      "      kl: 0.02263016812503338\n",
      "      policy_loss: 0.0033260327763855457\n",
      "      total_loss: 248.21218872070312\n",
      "      vf_explained_var: 0.9382344484329224\n",
      "      vf_loss: 248.20887756347656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7609034776687622\n",
      "      kl: 0.024342939257621765\n",
      "      policy_loss: 0.0066179861314594746\n",
      "      total_loss: 240.4342498779297\n",
      "      vf_explained_var: 0.9226300120353699\n",
      "      vf_loss: 240.42762756347656\n",
      "    sample_time_ms: 20168.178\n",
      "    update_time_ms: 7.675\n",
      "  iterations_since_restore: 748\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 27.929894477583378\n",
      "    rl_1: 16.413641542025456\n",
      "  time_since_restore: 17348.29861140251\n",
      "  time_this_iter_s: 23.53913927078247\n",
      "  time_total_s: 17348.29861140251\n",
      "  timestamp: 1550897962\n",
      "  timesteps_since_restore: 7480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7480000\n",
      "  training_iteration: 748\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17348 s, 748 iter, 7480000 ts, 44.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_05-59-45\n",
      "  done: false\n",
      "  episode_len_mean: 110.92\n",
      "  episode_reward_max: 229.30377288207868\n",
      "  episode_reward_mean: 89.86538131092713\n",
      "  episode_reward_min: -159.91479417035174\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 64569\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.362\n",
      "    load_time_ms: 2.588\n",
      "    num_steps_sampled: 7490000\n",
      "    num_steps_trained: 7490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5337138772010803\n",
      "      kl: 0.018113762140274048\n",
      "      policy_loss: 0.002822782611474395\n",
      "      total_loss: 198.0094451904297\n",
      "      vf_explained_var: 0.9315828084945679\n",
      "      vf_loss: 198.00660705566406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7418885231018066\n",
      "      kl: 0.028852906078100204\n",
      "      policy_loss: 0.003977235872298479\n",
      "      total_loss: 181.57583618164062\n",
      "      vf_explained_var: 0.9249213933944702\n",
      "      vf_loss: 181.57183837890625\n",
      "    sample_time_ms: 20109.489\n",
      "    update_time_ms: 7.658\n",
      "  iterations_since_restore: 749\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 51.19453964786342\n",
      "    rl_1: 38.67084166306373\n",
      "  time_since_restore: 17371.204503059387\n",
      "  time_this_iter_s: 22.90589165687561\n",
      "  time_total_s: 17371.204503059387\n",
      "  timestamp: 1550897985\n",
      "  timesteps_since_restore: 7490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7490000\n",
      "  training_iteration: 749\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17371 s, 749 iter, 7490000 ts, 89.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-00-09\n",
      "  done: false\n",
      "  episode_len_mean: 113.05\n",
      "  episode_reward_max: 219.92240702851572\n",
      "  episode_reward_mean: 96.47200933115718\n",
      "  episode_reward_min: -147.4707939626848\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 64657\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.498\n",
      "    load_time_ms: 2.579\n",
      "    num_steps_sampled: 7500000\n",
      "    num_steps_trained: 7500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5902290940284729\n",
      "      kl: 0.02392340824007988\n",
      "      policy_loss: 0.003992673009634018\n",
      "      total_loss: 145.38902282714844\n",
      "      vf_explained_var: 0.9525063633918762\n",
      "      vf_loss: 145.38502502441406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7896558046340942\n",
      "      kl: 0.02361663244664669\n",
      "      policy_loss: 0.006338750012218952\n",
      "      total_loss: 138.54226684570312\n",
      "      vf_explained_var: 0.9403254985809326\n",
      "      vf_loss: 138.5359649658203\n",
      "    sample_time_ms: 20119.838\n",
      "    update_time_ms: 7.102\n",
      "  iterations_since_restore: 750\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.640186212263934\n",
      "    rl_1: 39.831823118893254\n",
      "  time_since_restore: 17394.597445964813\n",
      "  time_this_iter_s: 23.392942905426025\n",
      "  time_total_s: 17394.597445964813\n",
      "  timestamp: 1550898009\n",
      "  timesteps_since_restore: 7500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7500000\n",
      "  training_iteration: 750\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17394 s, 750 iter, 7500000 ts, 96.5 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-00-32\n",
      "  done: false\n",
      "  episode_len_mean: 110.3\n",
      "  episode_reward_max: 208.0978951054979\n",
      "  episode_reward_mean: 81.0710729145669\n",
      "  episode_reward_min: -157.02216730804125\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 64750\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.201\n",
      "    load_time_ms: 2.548\n",
      "    num_steps_sampled: 7510000\n",
      "    num_steps_trained: 7510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6460809707641602\n",
      "      kl: 29.657167434692383\n",
      "      policy_loss: 0.13567832112312317\n",
      "      total_loss: 136.4034881591797\n",
      "      vf_explained_var: 0.961903989315033\n",
      "      vf_loss: 136.26780700683594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7881410121917725\n",
      "      kl: 0.0171439778059721\n",
      "      policy_loss: 0.0009852451039478183\n",
      "      total_loss: 128.5541534423828\n",
      "      vf_explained_var: 0.9521516561508179\n",
      "      vf_loss: 128.5531768798828\n",
      "    sample_time_ms: 20112.687\n",
      "    update_time_ms: 6.977\n",
      "  iterations_since_restore: 751\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 48.58248893756481\n",
      "    rl_1: 32.48858397700208\n",
      "  time_since_restore: 17417.501120328903\n",
      "  time_this_iter_s: 22.903674364089966\n",
      "  time_total_s: 17417.501120328903\n",
      "  timestamp: 1550898032\n",
      "  timesteps_since_restore: 7510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7510000\n",
      "  training_iteration: 751\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17417 s, 751 iter, 7510000 ts, 81.1 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-00-55\n",
      "  done: false\n",
      "  episode_len_mean: 105.8\n",
      "  episode_reward_max: 233.21519290040143\n",
      "  episode_reward_mean: 92.16001696315462\n",
      "  episode_reward_min: -157.02216730804125\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 64844\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.866\n",
      "    load_time_ms: 2.43\n",
      "    num_steps_sampled: 7520000\n",
      "    num_steps_trained: 7520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6178723573684692\n",
      "      kl: 0.027218198403716087\n",
      "      policy_loss: 0.007138533517718315\n",
      "      total_loss: 171.07374572753906\n",
      "      vf_explained_var: 0.9413092136383057\n",
      "      vf_loss: 171.0665740966797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7966633439064026\n",
      "      kl: 0.04233452305197716\n",
      "      policy_loss: 0.005001254379749298\n",
      "      total_loss: 168.6161651611328\n",
      "      vf_explained_var: 0.9268313646316528\n",
      "      vf_loss: 168.6111602783203\n",
      "    sample_time_ms: 20160.132\n",
      "    update_time_ms: 7.401\n",
      "  iterations_since_restore: 752\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.68467504679019\n",
      "    rl_1: 39.47534191636442\n",
      "  time_since_restore: 17440.723838329315\n",
      "  time_this_iter_s: 23.222718000411987\n",
      "  time_total_s: 17440.723838329315\n",
      "  timestamp: 1550898055\n",
      "  timesteps_since_restore: 7520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7520000\n",
      "  training_iteration: 752\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17440 s, 752 iter, 7520000 ts, 92.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-01-18\n",
      "  done: false\n",
      "  episode_len_mean: 108.7\n",
      "  episode_reward_max: 215.96184959422598\n",
      "  episode_reward_mean: 88.67034074557226\n",
      "  episode_reward_min: -170.0256218849795\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 64934\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.732\n",
      "    load_time_ms: 2.406\n",
      "    num_steps_sampled: 7530000\n",
      "    num_steps_trained: 7530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5554860234260559\n",
      "      kl: 0.019799984991550446\n",
      "      policy_loss: 0.002643053187057376\n",
      "      total_loss: 137.2566375732422\n",
      "      vf_explained_var: 0.9570608735084534\n",
      "      vf_loss: 137.25401306152344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7401707768440247\n",
      "      kl: 0.02497141622006893\n",
      "      policy_loss: 0.0010816106805577874\n",
      "      total_loss: 124.57240295410156\n",
      "      vf_explained_var: 0.9470251798629761\n",
      "      vf_loss: 124.57134246826172\n",
      "    sample_time_ms: 20156.24\n",
      "    update_time_ms: 7.731\n",
      "  iterations_since_restore: 753\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.151003320031315\n",
      "    rl_1: 36.519337425540954\n",
      "  time_since_restore: 17463.911525964737\n",
      "  time_this_iter_s: 23.187687635421753\n",
      "  time_total_s: 17463.911525964737\n",
      "  timestamp: 1550898078\n",
      "  timesteps_since_restore: 7530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7530000\n",
      "  training_iteration: 753\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17463 s, 753 iter, 7530000 ts, 88.7 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-01-42\n",
      "  done: false\n",
      "  episode_len_mean: 114.28\n",
      "  episode_reward_max: 220.76844025851543\n",
      "  episode_reward_mean: 105.12232329326251\n",
      "  episode_reward_min: -170.0256218849795\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 65022\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.437\n",
      "    load_time_ms: 2.394\n",
      "    num_steps_sampled: 7540000\n",
      "    num_steps_trained: 7540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5118473768234253\n",
      "      kl: 0.01406489871442318\n",
      "      policy_loss: 0.001972333062440157\n",
      "      total_loss: 123.02997589111328\n",
      "      vf_explained_var: 0.948562502861023\n",
      "      vf_loss: 123.02796936035156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7038869857788086\n",
      "      kl: 0.027690481394529343\n",
      "      policy_loss: 0.004860801622271538\n",
      "      total_loss: 118.93923950195312\n",
      "      vf_explained_var: 0.9337733387947083\n",
      "      vf_loss: 118.93437957763672\n",
      "    sample_time_ms: 20141.016\n",
      "    update_time_ms: 7.602\n",
      "  iterations_since_restore: 754\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.44021851616767\n",
      "    rl_1: 42.6821047770948\n",
      "  time_since_restore: 17487.22183585167\n",
      "  time_this_iter_s: 23.310309886932373\n",
      "  time_total_s: 17487.22183585167\n",
      "  timestamp: 1550898102\n",
      "  timesteps_since_restore: 7540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7540000\n",
      "  training_iteration: 754\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17487 s, 754 iter, 7540000 ts, 105 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-02-05\n",
      "  done: false\n",
      "  episode_len_mean: 112.37\n",
      "  episode_reward_max: 221.33353180458593\n",
      "  episode_reward_mean: 107.20715464703298\n",
      "  episode_reward_min: -174.131619459027\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 65111\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.394\n",
      "    load_time_ms: 2.403\n",
      "    num_steps_sampled: 7550000\n",
      "    num_steps_trained: 7550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5304161906242371\n",
      "      kl: 0.019066492095589638\n",
      "      policy_loss: 0.006872063037008047\n",
      "      total_loss: 123.3305892944336\n",
      "      vf_explained_var: 0.9534153938293457\n",
      "      vf_loss: 123.3237075805664\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7696284651756287\n",
      "      kl: 0.03644360229372978\n",
      "      policy_loss: 0.004533256404101849\n",
      "      total_loss: 103.54237365722656\n",
      "      vf_explained_var: 0.9494110345840454\n",
      "      vf_loss: 103.53783416748047\n",
      "    sample_time_ms: 20146.928\n",
      "    update_time_ms: 7.502\n",
      "  iterations_since_restore: 755\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.21049468923512\n",
      "    rl_1: 43.996659957797874\n",
      "  time_since_restore: 17510.397785425186\n",
      "  time_this_iter_s: 23.175949573516846\n",
      "  time_total_s: 17510.397785425186\n",
      "  timestamp: 1550898125\n",
      "  timesteps_since_restore: 7550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7550000\n",
      "  training_iteration: 755\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17510 s, 755 iter, 7550000 ts, 107 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-02-28\n",
      "  done: false\n",
      "  episode_len_mean: 108.58\n",
      "  episode_reward_max: 216.97024006484622\n",
      "  episode_reward_mean: 112.07746066746603\n",
      "  episode_reward_min: -151.54507665217884\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 65204\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.471\n",
      "    load_time_ms: 2.389\n",
      "    num_steps_sampled: 7560000\n",
      "    num_steps_trained: 7560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5027127861976624\n",
      "      kl: 0.025569457560777664\n",
      "      policy_loss: 0.003897300222888589\n",
      "      total_loss: 122.79532623291016\n",
      "      vf_explained_var: 0.9557327628135681\n",
      "      vf_loss: 122.79144287109375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7644312381744385\n",
      "      kl: 0.019100371748209\n",
      "      policy_loss: 0.0034968776162713766\n",
      "      total_loss: 124.39472961425781\n",
      "      vf_explained_var: 0.9454900026321411\n",
      "      vf_loss: 124.39122772216797\n",
      "    sample_time_ms: 20166.927\n",
      "    update_time_ms: 7.4\n",
      "  iterations_since_restore: 756\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.12861475566641\n",
      "    rl_1: 48.94884591179961\n",
      "  time_since_restore: 17533.960062742233\n",
      "  time_this_iter_s: 23.56227731704712\n",
      "  time_total_s: 17533.960062742233\n",
      "  timestamp: 1550898148\n",
      "  timesteps_since_restore: 7560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7560000\n",
      "  training_iteration: 756\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17533 s, 756 iter, 7560000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-02-52\n",
      "  done: false\n",
      "  episode_len_mean: 104.28\n",
      "  episode_reward_max: 226.46314480886716\n",
      "  episode_reward_mean: 87.80859522162923\n",
      "  episode_reward_min: -162.91223031542438\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 65302\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.207\n",
      "    load_time_ms: 2.296\n",
      "    num_steps_sampled: 7570000\n",
      "    num_steps_trained: 7570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6045441031455994\n",
      "      kl: 0.019176000729203224\n",
      "      policy_loss: 0.003628050209954381\n",
      "      total_loss: 157.30490112304688\n",
      "      vf_explained_var: 0.9540414810180664\n",
      "      vf_loss: 157.30125427246094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8335000276565552\n",
      "      kl: 0.02196688763797283\n",
      "      policy_loss: 0.0017422748496755958\n",
      "      total_loss: 153.9545135498047\n",
      "      vf_explained_var: 0.9446383714675903\n",
      "      vf_loss: 153.9527587890625\n",
      "    sample_time_ms: 20164.9\n",
      "    update_time_ms: 7.608\n",
      "  iterations_since_restore: 757\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 50.26994982971144\n",
      "    rl_1: 37.53864539191783\n",
      "  time_since_restore: 17557.38062644005\n",
      "  time_this_iter_s: 23.42056369781494\n",
      "  time_total_s: 17557.38062644005\n",
      "  timestamp: 1550898172\n",
      "  timesteps_since_restore: 7570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7570000\n",
      "  training_iteration: 757\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17557 s, 757 iter, 7570000 ts, 87.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-03-15\n",
      "  done: false\n",
      "  episode_len_mean: 108.58\n",
      "  episode_reward_max: 216.65905498573775\n",
      "  episode_reward_mean: 98.5794913829685\n",
      "  episode_reward_min: -163.17028261978763\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 65394\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3067.08\n",
      "    load_time_ms: 2.334\n",
      "    num_steps_sampled: 7580000\n",
      "    num_steps_trained: 7580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48397794365882874\n",
      "      kl: 0.015363908372819424\n",
      "      policy_loss: 0.0015542403561994433\n",
      "      total_loss: 153.5323944091797\n",
      "      vf_explained_var: 0.9482823610305786\n",
      "      vf_loss: 153.53082275390625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7573559284210205\n",
      "      kl: 0.02847166173160076\n",
      "      policy_loss: 0.0044369944371283054\n",
      "      total_loss: 141.3011474609375\n",
      "      vf_explained_var: 0.9413354396820068\n",
      "      vf_loss: 141.2967071533203\n",
      "    sample_time_ms: 20148.993\n",
      "    update_time_ms: 7.762\n",
      "  iterations_since_restore: 758\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.78244458335821\n",
      "    rl_1: 41.79704679961031\n",
      "  time_since_restore: 17580.74350833893\n",
      "  time_this_iter_s: 23.362881898880005\n",
      "  time_total_s: 17580.74350833893\n",
      "  timestamp: 1550898195\n",
      "  timesteps_since_restore: 7580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7580000\n",
      "  training_iteration: 758\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17580 s, 758 iter, 7580000 ts, 98.6 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-03-39\n",
      "  done: false\n",
      "  episode_len_mean: 108.95\n",
      "  episode_reward_max: 215.4581260911552\n",
      "  episode_reward_mean: 112.07381759723857\n",
      "  episode_reward_min: -148.2866527700706\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 65485\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.693\n",
      "    load_time_ms: 2.266\n",
      "    num_steps_sampled: 7590000\n",
      "    num_steps_trained: 7590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5767878890037537\n",
      "      kl: 0.023917218670248985\n",
      "      policy_loss: 0.003849024884402752\n",
      "      total_loss: 146.1046600341797\n",
      "      vf_explained_var: 0.9437420964241028\n",
      "      vf_loss: 146.10076904296875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8919849991798401\n",
      "      kl: 0.035481031984090805\n",
      "      policy_loss: 0.005355694331228733\n",
      "      total_loss: 134.57962036132812\n",
      "      vf_explained_var: 0.9337517023086548\n",
      "      vf_loss: 134.5742645263672\n",
      "    sample_time_ms: 20170.03\n",
      "    update_time_ms: 7.708\n",
      "  iterations_since_restore: 759\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.47378258109785\n",
      "    rl_1: 48.600035016140765\n",
      "  time_since_restore: 17604.04818367958\n",
      "  time_this_iter_s: 23.304675340652466\n",
      "  time_total_s: 17604.04818367958\n",
      "  timestamp: 1550898219\n",
      "  timesteps_since_restore: 7590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7590000\n",
      "  training_iteration: 759\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17604 s, 759 iter, 7590000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-04-01\n",
      "  done: false\n",
      "  episode_len_mean: 107.93\n",
      "  episode_reward_max: 215.2151331201895\n",
      "  episode_reward_mean: 104.19139543495247\n",
      "  episode_reward_min: -175.53937796063622\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 65579\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.971\n",
      "    load_time_ms: 2.277\n",
      "    num_steps_sampled: 7600000\n",
      "    num_steps_trained: 7600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5416255593299866\n",
      "      kl: 0.01896764524281025\n",
      "      policy_loss: 0.002273926045745611\n",
      "      total_loss: 137.6642303466797\n",
      "      vf_explained_var: 0.9525430202484131\n",
      "      vf_loss: 137.66197204589844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8206146359443665\n",
      "      kl: 0.03290730342268944\n",
      "      policy_loss: 0.0027718006167560816\n",
      "      total_loss: 132.85336303710938\n",
      "      vf_explained_var: 0.9442911148071289\n",
      "      vf_loss: 132.8505859375\n",
      "    sample_time_ms: 20104.72\n",
      "    update_time_ms: 7.807\n",
      "  iterations_since_restore: 760\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 59.456379566571975\n",
      "    rl_1: 44.73501586838047\n",
      "  time_since_restore: 17626.662668943405\n",
      "  time_this_iter_s: 22.614485263824463\n",
      "  time_total_s: 17626.662668943405\n",
      "  timestamp: 1550898241\n",
      "  timesteps_since_restore: 7600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7600000\n",
      "  training_iteration: 760\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17626 s, 760 iter, 7600000 ts, 104 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-04-25\n",
      "  done: false\n",
      "  episode_len_mean: 109.53\n",
      "  episode_reward_max: 215.67724295371406\n",
      "  episode_reward_mean: 92.94599782499762\n",
      "  episode_reward_min: -156.51105127512113\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 65669\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.148\n",
      "    load_time_ms: 2.246\n",
      "    num_steps_sampled: 7610000\n",
      "    num_steps_trained: 7610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5096302032470703\n",
      "      kl: 0.018820419907569885\n",
      "      policy_loss: 0.0050224196165800095\n",
      "      total_loss: 136.4612579345703\n",
      "      vf_explained_var: 0.9576964974403381\n",
      "      vf_loss: 136.4562225341797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7940452694892883\n",
      "      kl: 0.0276265200227499\n",
      "      policy_loss: 0.005041235126554966\n",
      "      total_loss: 132.0936279296875\n",
      "      vf_explained_var: 0.9469569325447083\n",
      "      vf_loss: 132.08860778808594\n",
      "    sample_time_ms: 20134.192\n",
      "    update_time_ms: 8.002\n",
      "  iterations_since_restore: 761\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 54.35243802413287\n",
      "    rl_1: 38.59355980086474\n",
      "  time_since_restore: 17649.86386871338\n",
      "  time_this_iter_s: 23.201199769973755\n",
      "  time_total_s: 17649.86386871338\n",
      "  timestamp: 1550898265\n",
      "  timesteps_since_restore: 7610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7610000\n",
      "  training_iteration: 761\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17649 s, 761 iter, 7610000 ts, 92.9 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-04-48\n",
      "  done: false\n",
      "  episode_len_mean: 107.04\n",
      "  episode_reward_max: 232.91820371457788\n",
      "  episode_reward_mean: 114.38525371199098\n",
      "  episode_reward_min: -143.1987669799932\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 65760\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.432\n",
      "    load_time_ms: 2.263\n",
      "    num_steps_sampled: 7620000\n",
      "    num_steps_trained: 7620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5049660801887512\n",
      "      kl: 0.021352458745241165\n",
      "      policy_loss: 0.010036991909146309\n",
      "      total_loss: 191.67262268066406\n",
      "      vf_explained_var: 0.9172288179397583\n",
      "      vf_loss: 191.66258239746094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7804388999938965\n",
      "      kl: 0.043485376983881\n",
      "      policy_loss: 0.010595817118883133\n",
      "      total_loss: 181.4211883544922\n",
      "      vf_explained_var: 0.9058260917663574\n",
      "      vf_loss: 181.4105682373047\n",
      "    sample_time_ms: 20147.481\n",
      "    update_time_ms: 7.672\n",
      "  iterations_since_restore: 762\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 62.57807391517057\n",
      "    rl_1: 51.80717979682041\n",
      "  time_since_restore: 17673.19984483719\n",
      "  time_this_iter_s: 23.335976123809814\n",
      "  time_total_s: 17673.19984483719\n",
      "  timestamp: 1550898288\n",
      "  timesteps_since_restore: 7620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7620000\n",
      "  training_iteration: 762\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17673 s, 762 iter, 7620000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-05-11\n",
      "  done: false\n",
      "  episode_len_mean: 112.44\n",
      "  episode_reward_max: 225.5586631587102\n",
      "  episode_reward_mean: 94.33177829892713\n",
      "  episode_reward_min: -176.39005754705948\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 65850\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.938\n",
      "    load_time_ms: 2.318\n",
      "    num_steps_sampled: 7630000\n",
      "    num_steps_trained: 7630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5425107479095459\n",
      "      kl: 0.016447635367512703\n",
      "      policy_loss: -0.0020084341522306204\n",
      "      total_loss: 142.0661163330078\n",
      "      vf_explained_var: 0.9512853622436523\n",
      "      vf_loss: 142.068115234375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7559192180633545\n",
      "      kl: 0.014256122522056103\n",
      "      policy_loss: 0.0024983121547847986\n",
      "      total_loss: 138.38031005859375\n",
      "      vf_explained_var: 0.9358239769935608\n",
      "      vf_loss: 138.37782287597656\n",
      "    sample_time_ms: 20154.853\n",
      "    update_time_ms: 7.36\n",
      "  iterations_since_restore: 763\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 56.910420604419706\n",
      "    rl_1: 37.42135769450741\n",
      "  time_since_restore: 17696.503738880157\n",
      "  time_this_iter_s: 23.30389404296875\n",
      "  time_total_s: 17696.503738880157\n",
      "  timestamp: 1550898311\n",
      "  timesteps_since_restore: 7630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7630000\n",
      "  training_iteration: 763\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17696 s, 763 iter, 7630000 ts, 94.3 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-05-34\n",
      "  done: false\n",
      "  episode_len_mean: 110.43\n",
      "  episode_reward_max: 216.66320674643913\n",
      "  episode_reward_mean: 118.33942924474691\n",
      "  episode_reward_min: -181.19507159804766\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 65941\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.935\n",
      "    load_time_ms: 2.377\n",
      "    num_steps_sampled: 7640000\n",
      "    num_steps_trained: 7640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5795987248420715\n",
      "      kl: 0.020099181681871414\n",
      "      policy_loss: 0.0036089695058763027\n",
      "      total_loss: 131.31712341308594\n",
      "      vf_explained_var: 0.9471325278282166\n",
      "      vf_loss: 131.31350708007812\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8313371539115906\n",
      "      kl: 0.027611523866653442\n",
      "      policy_loss: 0.0028854834381490946\n",
      "      total_loss: 124.16552734375\n",
      "      vf_explained_var: 0.9381110072135925\n",
      "      vf_loss: 124.16265106201172\n",
      "    sample_time_ms: 20098.595\n",
      "    update_time_ms: 7.183\n",
      "  iterations_since_restore: 764\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.86390861533708\n",
      "    rl_1: 50.475520629409836\n",
      "  time_since_restore: 17719.211872816086\n",
      "  time_this_iter_s: 22.708133935928345\n",
      "  time_total_s: 17719.211872816086\n",
      "  timestamp: 1550898334\n",
      "  timesteps_since_restore: 7640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7640000\n",
      "  training_iteration: 764\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17719 s, 764 iter, 7640000 ts, 118 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-05-58\n",
      "  done: false\n",
      "  episode_len_mean: 113.11\n",
      "  episode_reward_max: 220.26587485150577\n",
      "  episode_reward_mean: 113.09610016428225\n",
      "  episode_reward_min: -163.12281276071127\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 66031\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.693\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 7650000\n",
      "    num_steps_trained: 7650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5892435908317566\n",
      "      kl: 0.02160297892987728\n",
      "      policy_loss: 0.0045520709827542305\n",
      "      total_loss: 124.06722259521484\n",
      "      vf_explained_var: 0.9514136910438538\n",
      "      vf_loss: 124.06266021728516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8545770049095154\n",
      "      kl: 0.05351029336452484\n",
      "      policy_loss: 0.01689022406935692\n",
      "      total_loss: 121.00076293945312\n",
      "      vf_explained_var: 0.9406217932701111\n",
      "      vf_loss: 120.98387145996094\n",
      "    sample_time_ms: 20117.577\n",
      "    update_time_ms: 7.365\n",
      "  iterations_since_restore: 765\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.12385322458687\n",
      "    rl_1: 47.97224693969539\n",
      "  time_since_restore: 17742.596131324768\n",
      "  time_this_iter_s: 23.38425850868225\n",
      "  time_total_s: 17742.596131324768\n",
      "  timestamp: 1550898358\n",
      "  timesteps_since_restore: 7650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7650000\n",
      "  training_iteration: 765\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17742 s, 765 iter, 7650000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-06-21\n",
      "  done: false\n",
      "  episode_len_mean: 117.74\n",
      "  episode_reward_max: 220.26587485150577\n",
      "  episode_reward_mean: 112.29871142689238\n",
      "  episode_reward_min: -158.9334941338418\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 66115\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.914\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 7660000\n",
      "    num_steps_trained: 7660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.524055004119873\n",
      "      kl: 0.01765274628996849\n",
      "      policy_loss: 0.006729756947606802\n",
      "      total_loss: 92.64434814453125\n",
      "      vf_explained_var: 0.9575483798980713\n",
      "      vf_loss: 92.63761901855469\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7808740735054016\n",
      "      kl: 0.019674772396683693\n",
      "      policy_loss: 0.004618351813405752\n",
      "      total_loss: 85.01912689208984\n",
      "      vf_explained_var: 0.9459509253501892\n",
      "      vf_loss: 85.01451873779297\n",
      "    sample_time_ms: 20103.338\n",
      "    update_time_ms: 7.22\n",
      "  iterations_since_restore: 766\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.83990081958706\n",
      "    rl_1: 44.45881060730535\n",
      "  time_since_restore: 17766.0275990963\n",
      "  time_this_iter_s: 23.43146777153015\n",
      "  time_total_s: 17766.0275990963\n",
      "  timestamp: 1550898381\n",
      "  timesteps_since_restore: 7660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7660000\n",
      "  training_iteration: 766\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17766 s, 766 iter, 7660000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-06-45\n",
      "  done: false\n",
      "  episode_len_mean: 110.08\n",
      "  episode_reward_max: 210.61248804962335\n",
      "  episode_reward_mean: 107.57661060753236\n",
      "  episode_reward_min: -178.7245083272474\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 66205\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.564\n",
      "    load_time_ms: 2.441\n",
      "    num_steps_sampled: 7670000\n",
      "    num_steps_trained: 7670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5553909540176392\n",
      "      kl: 0.017473464831709862\n",
      "      policy_loss: 0.0064214421436190605\n",
      "      total_loss: 123.20793151855469\n",
      "      vf_explained_var: 0.9508731365203857\n",
      "      vf_loss: 123.20149993896484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8353128433227539\n",
      "      kl: 0.03507356718182564\n",
      "      policy_loss: 0.006739300675690174\n",
      "      total_loss: 123.4674072265625\n",
      "      vf_explained_var: 0.9420022964477539\n",
      "      vf_loss: 123.46066284179688\n",
      "    sample_time_ms: 20114.205\n",
      "    update_time_ms: 7.102\n",
      "  iterations_since_restore: 767\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.956550680426474\n",
      "    rl_1: 46.620059927105856\n",
      "  time_since_restore: 17789.562985420227\n",
      "  time_this_iter_s: 23.535386323928833\n",
      "  time_total_s: 17789.562985420227\n",
      "  timestamp: 1550898405\n",
      "  timesteps_since_restore: 7670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7670000\n",
      "  training_iteration: 767\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17789 s, 767 iter, 7670000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-07-08\n",
      "  done: false\n",
      "  episode_len_mean: 108.84\n",
      "  episode_reward_max: 212.68082186183773\n",
      "  episode_reward_mean: 127.61726329881613\n",
      "  episode_reward_min: -151.2500942244243\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 66297\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3103.861\n",
      "    load_time_ms: 2.468\n",
      "    num_steps_sampled: 7680000\n",
      "    num_steps_trained: 7680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5955133438110352\n",
      "      kl: 28.39689064025879\n",
      "      policy_loss: 0.15564540028572083\n",
      "      total_loss: 135.70654296875\n",
      "      vf_explained_var: 0.9415596127510071\n",
      "      vf_loss: 135.55088806152344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8171507716178894\n",
      "      kl: 0.03972335159778595\n",
      "      policy_loss: 0.016539547592401505\n",
      "      total_loss: 124.83625030517578\n",
      "      vf_explained_var: 0.9341181516647339\n",
      "      vf_loss: 124.81974029541016\n",
      "    sample_time_ms: 20072.32\n",
      "    update_time_ms: 6.955\n",
      "  iterations_since_restore: 768\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.38092490248874\n",
      "    rl_1: 56.23633839632736\n",
      "  time_since_restore: 17812.781003713608\n",
      "  time_this_iter_s: 23.218018293380737\n",
      "  time_total_s: 17812.781003713608\n",
      "  timestamp: 1550898428\n",
      "  timesteps_since_restore: 7680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7680000\n",
      "  training_iteration: 768\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17812 s, 768 iter, 7680000 ts, 128 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-07-30\n",
      "  done: false\n",
      "  episode_len_mean: 107.5\n",
      "  episode_reward_max: 233.8444269425352\n",
      "  episode_reward_mean: 103.05733869660395\n",
      "  episode_reward_min: -166.1146542655501\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 66390\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.035\n",
      "    load_time_ms: 2.512\n",
      "    num_steps_sampled: 7690000\n",
      "    num_steps_trained: 7690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5709932446479797\n",
      "      kl: 0.023687008768320084\n",
      "      policy_loss: 0.006870336830615997\n",
      "      total_loss: 123.68090057373047\n",
      "      vf_explained_var: 0.9568771123886108\n",
      "      vf_loss: 123.67402648925781\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7861942648887634\n",
      "      kl: 0.0191156305372715\n",
      "      policy_loss: 0.0012342857662588358\n",
      "      total_loss: 117.9815444946289\n",
      "      vf_explained_var: 0.9447451829910278\n",
      "      vf_loss: 117.98033142089844\n",
      "    sample_time_ms: 20010.122\n",
      "    update_time_ms: 6.932\n",
      "  iterations_since_restore: 769\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.825570147186916\n",
      "    rl_1: 42.23176854941702\n",
      "  time_since_restore: 17835.23774456978\n",
      "  time_this_iter_s: 22.456740856170654\n",
      "  time_total_s: 17835.23774456978\n",
      "  timestamp: 1550898450\n",
      "  timesteps_since_restore: 7690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7690000\n",
      "  training_iteration: 769\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17835 s, 769 iter, 7690000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-07-54\n",
      "  done: false\n",
      "  episode_len_mean: 106.73\n",
      "  episode_reward_max: 217.94660075294448\n",
      "  episode_reward_mean: 124.34678702845336\n",
      "  episode_reward_min: -180.01076663702273\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 66483\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.096\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 7700000\n",
      "    num_steps_trained: 7700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6357531547546387\n",
      "      kl: 0.02779804728925228\n",
      "      policy_loss: 0.003410428063943982\n",
      "      total_loss: 185.3536834716797\n",
      "      vf_explained_var: 0.9257895350456238\n",
      "      vf_loss: 185.35028076171875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.857304036617279\n",
      "      kl: 0.03085951879620552\n",
      "      policy_loss: 0.007840720936655998\n",
      "      total_loss: 168.7027130126953\n",
      "      vf_explained_var: 0.9137905836105347\n",
      "      vf_loss: 168.69485473632812\n",
      "    sample_time_ms: 20060.104\n",
      "    update_time_ms: 6.876\n",
      "  iterations_since_restore: 770\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.25718898829959\n",
      "    rl_1: 54.08959804015378\n",
      "  time_since_restore: 17858.331472873688\n",
      "  time_this_iter_s: 23.0937283039093\n",
      "  time_total_s: 17858.331472873688\n",
      "  timestamp: 1550898474\n",
      "  timesteps_since_restore: 7700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7700000\n",
      "  training_iteration: 770\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17858 s, 770 iter, 7700000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-08-17\n",
      "  done: false\n",
      "  episode_len_mean: 108.19\n",
      "  episode_reward_max: 223.00087714548792\n",
      "  episode_reward_mean: 112.80777745042873\n",
      "  episode_reward_min: -168.8545654281089\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 66577\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.04\n",
      "    load_time_ms: 2.533\n",
      "    num_steps_sampled: 7710000\n",
      "    num_steps_trained: 7710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6343218684196472\n",
      "      kl: 0.021412009373307228\n",
      "      policy_loss: 0.0022981076035648584\n",
      "      total_loss: 177.31605529785156\n",
      "      vf_explained_var: 0.9368566870689392\n",
      "      vf_loss: 177.3137664794922\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8402561545372009\n",
      "      kl: 0.01904807798564434\n",
      "      policy_loss: 0.004993381444364786\n",
      "      total_loss: 163.81385803222656\n",
      "      vf_explained_var: 0.9282557368278503\n",
      "      vf_loss: 163.80886840820312\n",
      "    sample_time_ms: 20086.643\n",
      "    update_time_ms: 6.661\n",
      "  iterations_since_restore: 771\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.98154423796871\n",
      "    rl_1: 48.82623321246003\n",
      "  time_since_restore: 17881.793110370636\n",
      "  time_this_iter_s: 23.461637496948242\n",
      "  time_total_s: 17881.793110370636\n",
      "  timestamp: 1550898497\n",
      "  timesteps_since_restore: 7710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7710000\n",
      "  training_iteration: 771\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17881 s, 771 iter, 7710000 ts, 113 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-08-40\n",
      "  done: false\n",
      "  episode_len_mean: 109.28\n",
      "  episode_reward_max: 210.39088861496631\n",
      "  episode_reward_mean: 118.74092390592277\n",
      "  episode_reward_min: -143.23063479241972\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 66668\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.059\n",
      "    load_time_ms: 2.547\n",
      "    num_steps_sampled: 7720000\n",
      "    num_steps_trained: 7720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6130467057228088\n",
      "      kl: 0.04000324010848999\n",
      "      policy_loss: 0.010679983533918858\n",
      "      total_loss: 115.48332214355469\n",
      "      vf_explained_var: 0.956041693687439\n",
      "      vf_loss: 115.47265625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8315147757530212\n",
      "      kl: 0.02512228488922119\n",
      "      policy_loss: 0.0027491827495396137\n",
      "      total_loss: 107.91324615478516\n",
      "      vf_explained_var: 0.9467887878417969\n",
      "      vf_loss: 107.91050720214844\n",
      "    sample_time_ms: 20038.026\n",
      "    update_time_ms: 6.527\n",
      "  iterations_since_restore: 772\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.07756176627414\n",
      "    rl_1: 50.663362139648605\n",
      "  time_since_restore: 17904.681329488754\n",
      "  time_this_iter_s: 22.888219118118286\n",
      "  time_total_s: 17904.681329488754\n",
      "  timestamp: 1550898520\n",
      "  timesteps_since_restore: 7720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7720000\n",
      "  training_iteration: 772\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17904 s, 772 iter, 7720000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-09-03\n",
      "  done: false\n",
      "  episode_len_mean: 107.47\n",
      "  episode_reward_max: 220.92919602120162\n",
      "  episode_reward_mean: 96.24409982776359\n",
      "  episode_reward_min: -164.81806416171528\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 66761\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.338\n",
      "    load_time_ms: 2.469\n",
      "    num_steps_sampled: 7730000\n",
      "    num_steps_trained: 7730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6465206146240234\n",
      "      kl: 0.0168085265904665\n",
      "      policy_loss: 0.005032217130064964\n",
      "      total_loss: 124.26587677001953\n",
      "      vf_explained_var: 0.958907961845398\n",
      "      vf_loss: 124.26082611083984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8009246587753296\n",
      "      kl: 0.04140504077076912\n",
      "      policy_loss: 0.00906588975340128\n",
      "      total_loss: 116.30119323730469\n",
      "      vf_explained_var: 0.948382556438446\n",
      "      vf_loss: 116.2921142578125\n",
      "    sample_time_ms: 20034.989\n",
      "    update_time_ms: 6.565\n",
      "  iterations_since_restore: 773\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 58.876677277363285\n",
      "    rl_1: 37.36742255040028\n",
      "  time_since_restore: 17927.906437158585\n",
      "  time_this_iter_s: 23.225107669830322\n",
      "  time_total_s: 17927.906437158585\n",
      "  timestamp: 1550898543\n",
      "  timesteps_since_restore: 7730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7730000\n",
      "  training_iteration: 773\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17927 s, 773 iter, 7730000 ts, 96.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-09-26\n",
      "  done: false\n",
      "  episode_len_mean: 110.28\n",
      "  episode_reward_max: 227.0946592930266\n",
      "  episode_reward_mean: 114.85242495083621\n",
      "  episode_reward_min: -175.91569579481092\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 66853\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.398\n",
      "    load_time_ms: 2.413\n",
      "    num_steps_sampled: 7740000\n",
      "    num_steps_trained: 7740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.627193033695221\n",
      "      kl: 0.021372923627495766\n",
      "      policy_loss: 0.003996762912720442\n",
      "      total_loss: 146.86842346191406\n",
      "      vf_explained_var: 0.947257399559021\n",
      "      vf_loss: 146.86439514160156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8386353850364685\n",
      "      kl: 0.027226557955145836\n",
      "      policy_loss: 0.008496148511767387\n",
      "      total_loss: 144.91867065429688\n",
      "      vf_explained_var: 0.9318689107894897\n",
      "      vf_loss: 144.91018676757812\n",
      "    sample_time_ms: 20063.187\n",
      "    update_time_ms: 6.788\n",
      "  iterations_since_restore: 774\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 67.62933200366136\n",
      "    rl_1: 47.22309294717483\n",
      "  time_since_restore: 17950.88809156418\n",
      "  time_this_iter_s: 22.981654405593872\n",
      "  time_total_s: 17950.88809156418\n",
      "  timestamp: 1550898566\n",
      "  timesteps_since_restore: 7740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7740000\n",
      "  training_iteration: 774\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17950 s, 774 iter, 7740000 ts, 115 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-09-49\n",
      "  done: false\n",
      "  episode_len_mean: 109.27\n",
      "  episode_reward_max: 223.59652842865796\n",
      "  episode_reward_mean: 108.41302388427619\n",
      "  episode_reward_min: -152.65587700038216\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 66944\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.639\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 7750000\n",
      "    num_steps_trained: 7750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5779311060905457\n",
      "      kl: 0.014431798830628395\n",
      "      policy_loss: 0.00307506718672812\n",
      "      total_loss: 124.78458404541016\n",
      "      vf_explained_var: 0.950296938419342\n",
      "      vf_loss: 124.78150939941406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7786679863929749\n",
      "      kl: 0.028677603229880333\n",
      "      policy_loss: 0.00217573088593781\n",
      "      total_loss: 111.56324768066406\n",
      "      vf_explained_var: 0.9413366317749023\n",
      "      vf_loss: 111.56108856201172\n",
      "    sample_time_ms: 20016.845\n",
      "    update_time_ms: 6.915\n",
      "  iterations_since_restore: 775\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.92357147343345\n",
      "    rl_1: 44.489452410842745\n",
      "  time_since_restore: 17973.83338212967\n",
      "  time_this_iter_s: 22.945290565490723\n",
      "  time_total_s: 17973.83338212967\n",
      "  timestamp: 1550898589\n",
      "  timesteps_since_restore: 7750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7750000\n",
      "  training_iteration: 775\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17973 s, 775 iter, 7750000 ts, 108 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-10-12\n",
      "  done: false\n",
      "  episode_len_mean: 109.36\n",
      "  episode_reward_max: 232.02220467462777\n",
      "  episode_reward_mean: 131.0469108766854\n",
      "  episode_reward_min: -152.65587700038216\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 67036\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.884\n",
      "    load_time_ms: 2.448\n",
      "    num_steps_sampled: 7760000\n",
      "    num_steps_trained: 7760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6493446826934814\n",
      "      kl: 0.02495163306593895\n",
      "      policy_loss: 0.0053539094515144825\n",
      "      total_loss: 98.00902557373047\n",
      "      vf_explained_var: 0.9552203416824341\n",
      "      vf_loss: 98.00367736816406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8089744448661804\n",
      "      kl: 0.020459312945604324\n",
      "      policy_loss: 0.0041462513618171215\n",
      "      total_loss: 94.08870697021484\n",
      "      vf_explained_var: 0.944956362247467\n",
      "      vf_loss: 94.08455657958984\n",
      "    sample_time_ms: 19981.15\n",
      "    update_time_ms: 7.027\n",
      "  iterations_since_restore: 776\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 74.57134717838056\n",
      "    rl_1: 56.47556369830485\n",
      "  time_since_restore: 17997.00017118454\n",
      "  time_this_iter_s: 23.166789054870605\n",
      "  time_total_s: 17997.00017118454\n",
      "  timestamp: 1550898612\n",
      "  timesteps_since_restore: 7760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7760000\n",
      "  training_iteration: 776\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 17997 s, 776 iter, 7760000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-10-35\n",
      "  done: false\n",
      "  episode_len_mean: 109.57\n",
      "  episode_reward_max: 230.99153556463824\n",
      "  episode_reward_mean: 131.43226206401494\n",
      "  episode_reward_min: -172.06268426259123\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 67127\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.585\n",
      "    load_time_ms: 2.338\n",
      "    num_steps_sampled: 7770000\n",
      "    num_steps_trained: 7770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6114217638969421\n",
      "      kl: 0.015784243121743202\n",
      "      policy_loss: 0.0036165399942547083\n",
      "      total_loss: 146.10350036621094\n",
      "      vf_explained_var: 0.9283849000930786\n",
      "      vf_loss: 146.0998992919922\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7749313116073608\n",
      "      kl: 0.026950787752866745\n",
      "      policy_loss: 0.011135886423289776\n",
      "      total_loss: 140.7377166748047\n",
      "      vf_explained_var: 0.9168248176574707\n",
      "      vf_loss: 140.7265625\n",
      "    sample_time_ms: 19903.485\n",
      "    update_time_ms: 6.936\n",
      "  iterations_since_restore: 777\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.16806644207709\n",
      "    rl_1: 56.264195621937816\n",
      "  time_since_restore: 18019.742114067078\n",
      "  time_this_iter_s: 22.741942882537842\n",
      "  time_total_s: 18019.742114067078\n",
      "  timestamp: 1550898635\n",
      "  timesteps_since_restore: 7770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7770000\n",
      "  training_iteration: 777\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18019 s, 777 iter, 7770000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-10-59\n",
      "  done: false\n",
      "  episode_len_mean: 108.99\n",
      "  episode_reward_max: 232.22963331684892\n",
      "  episode_reward_mean: 137.2604496617813\n",
      "  episode_reward_min: -181.11995039791066\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 67219\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.516\n",
      "    load_time_ms: 2.391\n",
      "    num_steps_sampled: 7780000\n",
      "    num_steps_trained: 7780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6172782778739929\n",
      "      kl: 0.018810581415891647\n",
      "      policy_loss: 0.0040695546194911\n",
      "      total_loss: 97.71549224853516\n",
      "      vf_explained_var: 0.9513546824455261\n",
      "      vf_loss: 97.71141815185547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.782695472240448\n",
      "      kl: 0.015765909105539322\n",
      "      policy_loss: 0.0038217504043132067\n",
      "      total_loss: 98.142578125\n",
      "      vf_explained_var: 0.9399541020393372\n",
      "      vf_loss: 98.1387710571289\n",
      "    sample_time_ms: 19933.314\n",
      "    update_time_ms: 7.055\n",
      "  iterations_since_restore: 778\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.92231993292843\n",
      "    rl_1: 60.33812972885289\n",
      "  time_since_restore: 18043.006390571594\n",
      "  time_this_iter_s: 23.2642765045166\n",
      "  time_total_s: 18043.006390571594\n",
      "  timestamp: 1550898659\n",
      "  timesteps_since_restore: 7780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7780000\n",
      "  training_iteration: 778\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18043 s, 778 iter, 7780000 ts, 137 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-11-22\n",
      "  done: false\n",
      "  episode_len_mean: 113.17\n",
      "  episode_reward_max: 221.5274516559112\n",
      "  episode_reward_mean: 120.44042410610946\n",
      "  episode_reward_min: -178.93839995842754\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 67305\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3062.344\n",
      "    load_time_ms: 2.437\n",
      "    num_steps_sampled: 7790000\n",
      "    num_steps_trained: 7790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5861666202545166\n",
      "      kl: 0.05814492329955101\n",
      "      policy_loss: 0.01853986270725727\n",
      "      total_loss: 122.93257904052734\n",
      "      vf_explained_var: 0.9494128823280334\n",
      "      vf_loss: 122.9140625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7957973480224609\n",
      "      kl: 0.018061846494674683\n",
      "      policy_loss: 0.0026379849296063185\n",
      "      total_loss: 108.40623474121094\n",
      "      vf_explained_var: 0.9408968687057495\n",
      "      vf_loss: 108.40361785888672\n",
      "    sample_time_ms: 20026.527\n",
      "    update_time_ms: 7.018\n",
      "  iterations_since_restore: 779\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.43892486754886\n",
      "    rl_1: 50.00149923856059\n",
      "  time_since_restore: 18066.39149594307\n",
      "  time_this_iter_s: 23.38510537147522\n",
      "  time_total_s: 18066.39149594307\n",
      "  timestamp: 1550898682\n",
      "  timesteps_since_restore: 7790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7790000\n",
      "  training_iteration: 779\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18066 s, 779 iter, 7790000 ts, 120 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-11-45\n",
      "  done: false\n",
      "  episode_len_mean: 109.06\n",
      "  episode_reward_max: 220.36830923012752\n",
      "  episode_reward_mean: 119.34566185777553\n",
      "  episode_reward_min: -143.16826608175288\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 67397\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3061.262\n",
      "    load_time_ms: 2.449\n",
      "    num_steps_sampled: 7800000\n",
      "    num_steps_trained: 7800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5502479672431946\n",
      "      kl: 0.0319368802011013\n",
      "      policy_loss: 0.00920466985553503\n",
      "      total_loss: 111.14814758300781\n",
      "      vf_explained_var: 0.9542810320854187\n",
      "      vf_loss: 111.13893127441406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7542358636856079\n",
      "      kl: 0.0238190870732069\n",
      "      policy_loss: 0.004761049523949623\n",
      "      total_loss: 108.61488342285156\n",
      "      vf_explained_var: 0.940684974193573\n",
      "      vf_loss: 108.61012268066406\n",
      "    sample_time_ms: 20048.083\n",
      "    update_time_ms: 7.181\n",
      "  iterations_since_restore: 780\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 69.61650443484614\n",
      "    rl_1: 49.72915742292938\n",
      "  time_since_restore: 18089.69366168976\n",
      "  time_this_iter_s: 23.302165746688843\n",
      "  time_total_s: 18089.69366168976\n",
      "  timestamp: 1550898705\n",
      "  timesteps_since_restore: 7800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7800000\n",
      "  training_iteration: 780\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18089 s, 780 iter, 7800000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-12-09\n",
      "  done: false\n",
      "  episode_len_mean: 110.4\n",
      "  episode_reward_max: 223.7063241487882\n",
      "  episode_reward_mean: 118.54008459281854\n",
      "  episode_reward_min: -172.95522002077698\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 67489\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.401\n",
      "    load_time_ms: 2.464\n",
      "    num_steps_sampled: 7810000\n",
      "    num_steps_trained: 7810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6210684180259705\n",
      "      kl: 0.017568521201610565\n",
      "      policy_loss: 0.004169910214841366\n",
      "      total_loss: 86.75253295898438\n",
      "      vf_explained_var: 0.9626310467720032\n",
      "      vf_loss: 86.74836730957031\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8324680924415588\n",
      "      kl: 0.027184782549738884\n",
      "      policy_loss: 0.005832203663885593\n",
      "      total_loss: 86.02542114257812\n",
      "      vf_explained_var: 0.9513790607452393\n",
      "      vf_loss: 86.01959991455078\n",
      "    sample_time_ms: 20009.708\n",
      "    update_time_ms: 7.313\n",
      "  iterations_since_restore: 781\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.14303057324045\n",
      "    rl_1: 48.3970540195781\n",
      "  time_since_restore: 18112.92521762848\n",
      "  time_this_iter_s: 23.231555938720703\n",
      "  time_total_s: 18112.92521762848\n",
      "  timestamp: 1550898729\n",
      "  timesteps_since_restore: 7810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7810000\n",
      "  training_iteration: 781\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18112 s, 781 iter, 7810000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-12-31\n",
      "  done: false\n",
      "  episode_len_mean: 110.4\n",
      "  episode_reward_max: 213.61767910362667\n",
      "  episode_reward_mean: 119.16597508788253\n",
      "  episode_reward_min: -176.66798810175035\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 67579\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.807\n",
      "    load_time_ms: 2.42\n",
      "    num_steps_sampled: 7820000\n",
      "    num_steps_trained: 7820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.603387713432312\n",
      "      kl: 0.031263574957847595\n",
      "      policy_loss: 0.007005808409303427\n",
      "      total_loss: 126.49021911621094\n",
      "      vf_explained_var: 0.9455779790878296\n",
      "      vf_loss: 126.48323822021484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8473272919654846\n",
      "      kl: 0.03847942501306534\n",
      "      policy_loss: 0.006078393664211035\n",
      "      total_loss: 120.04721069335938\n",
      "      vf_explained_var: 0.9355119466781616\n",
      "      vf_loss: 120.04116821289062\n",
      "    sample_time_ms: 19998.216\n",
      "    update_time_ms: 7.383\n",
      "  iterations_since_restore: 782\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.8704542443331\n",
      "    rl_1: 50.29552084354942\n",
      "  time_since_restore: 18135.6706802845\n",
      "  time_this_iter_s: 22.745462656021118\n",
      "  time_total_s: 18135.6706802845\n",
      "  timestamp: 1550898751\n",
      "  timesteps_since_restore: 7820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7820000\n",
      "  training_iteration: 782\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18135 s, 782 iter, 7820000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-12-55\n",
      "  done: false\n",
      "  episode_len_mean: 108.86\n",
      "  episode_reward_max: 213.85427878418795\n",
      "  episode_reward_mean: 102.71255781384082\n",
      "  episode_reward_min: -160.98332738951768\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 67672\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.242\n",
      "    load_time_ms: 2.447\n",
      "    num_steps_sampled: 7830000\n",
      "    num_steps_trained: 7830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.544191837310791\n",
      "      kl: 0.026248186826705933\n",
      "      policy_loss: 0.004179717041552067\n",
      "      total_loss: 137.3151092529297\n",
      "      vf_explained_var: 0.9509627223014832\n",
      "      vf_loss: 137.31092834472656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7640390396118164\n",
      "      kl: 0.031795602291822433\n",
      "      policy_loss: 0.003452898934483528\n",
      "      total_loss: 122.44156646728516\n",
      "      vf_explained_var: 0.9437993168830872\n",
      "      vf_loss: 122.43812561035156\n",
      "    sample_time_ms: 19984.005\n",
      "    update_time_ms: 7.311\n",
      "  iterations_since_restore: 783\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 60.23889212378194\n",
      "    rl_1: 42.47366569005886\n",
      "  time_since_restore: 18158.797820806503\n",
      "  time_this_iter_s: 23.127140522003174\n",
      "  time_total_s: 18158.797820806503\n",
      "  timestamp: 1550898775\n",
      "  timesteps_since_restore: 7830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7830000\n",
      "  training_iteration: 783\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18158 s, 783 iter, 7830000 ts, 103 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-13-18\n",
      "  done: false\n",
      "  episode_len_mean: 109.82\n",
      "  episode_reward_max: 217.7820023102716\n",
      "  episode_reward_mean: 116.1408919035934\n",
      "  episode_reward_min: -172.23592885486488\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 67762\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.66\n",
      "    load_time_ms: 2.441\n",
      "    num_steps_sampled: 7840000\n",
      "    num_steps_trained: 7840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5933708548545837\n",
      "      kl: 0.0414932556450367\n",
      "      policy_loss: 0.008507343009114265\n",
      "      total_loss: 74.84303283691406\n",
      "      vf_explained_var: 0.9701618552207947\n",
      "      vf_loss: 74.83451843261719\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8045380115509033\n",
      "      kl: 0.017815368250012398\n",
      "      policy_loss: 5.281544508761726e-05\n",
      "      total_loss: 73.01080322265625\n",
      "      vf_explained_var: 0.9618158340454102\n",
      "      vf_loss: 73.01074981689453\n",
      "    sample_time_ms: 19978.726\n",
      "    update_time_ms: 7.381\n",
      "  iterations_since_restore: 784\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.11828957550999\n",
      "    rl_1: 48.022602328083416\n",
      "  time_since_restore: 18181.74430179596\n",
      "  time_this_iter_s: 22.946480989456177\n",
      "  time_total_s: 18181.74430179596\n",
      "  timestamp: 1550898798\n",
      "  timesteps_since_restore: 7840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7840000\n",
      "  training_iteration: 784\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18181 s, 784 iter, 7840000 ts, 116 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-13-41\n",
      "  done: false\n",
      "  episode_len_mean: 110.83\n",
      "  episode_reward_max: 224.15211404982318\n",
      "  episode_reward_mean: 123.97353260177397\n",
      "  episode_reward_min: -176.89001878082684\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 67851\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3082.227\n",
      "    load_time_ms: 2.382\n",
      "    num_steps_sampled: 7850000\n",
      "    num_steps_trained: 7850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5801493525505066\n",
      "      kl: 0.03227816894650459\n",
      "      policy_loss: 0.01201231312006712\n",
      "      total_loss: 81.9326400756836\n",
      "      vf_explained_var: 0.9661266803741455\n",
      "      vf_loss: 81.92061614990234\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7729798555374146\n",
      "      kl: 0.02031530998647213\n",
      "      policy_loss: 0.0039053750224411488\n",
      "      total_loss: 70.4933853149414\n",
      "      vf_explained_var: 0.9632379412651062\n",
      "      vf_loss: 70.48947143554688\n",
      "    sample_time_ms: 19983.052\n",
      "    update_time_ms: 7.182\n",
      "  iterations_since_restore: 785\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.41131253239159\n",
      "    rl_1: 52.56222006938236\n",
      "  time_since_restore: 18204.755166053772\n",
      "  time_this_iter_s: 23.0108642578125\n",
      "  time_total_s: 18204.755166053772\n",
      "  timestamp: 1550898821\n",
      "  timesteps_since_restore: 7850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7850000\n",
      "  training_iteration: 785\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18204 s, 785 iter, 7850000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 114.37\n",
      "  episode_reward_max: 219.3192749480941\n",
      "  episode_reward_mean: 135.20837612546282\n",
      "  episode_reward_min: -178.77144012924333\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 67941\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.637\n",
      "    load_time_ms: 2.378\n",
      "    num_steps_sampled: 7860000\n",
      "    num_steps_trained: 7860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5236672163009644\n",
      "      kl: 0.019589027389883995\n",
      "      policy_loss: 0.005034756381064653\n",
      "      total_loss: 123.35903930664062\n",
      "      vf_explained_var: 0.9430938959121704\n",
      "      vf_loss: 123.35398864746094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6975270509719849\n",
      "      kl: 0.026326656341552734\n",
      "      policy_loss: 0.004939210135489702\n",
      "      total_loss: 115.62515258789062\n",
      "      vf_explained_var: 0.9318884015083313\n",
      "      vf_loss: 115.62019348144531\n",
      "    sample_time_ms: 19945.527\n",
      "    update_time_ms: 7.166\n",
      "  iterations_since_restore: 786\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.88078223860296\n",
      "    rl_1: 56.32759388685986\n",
      "  time_since_restore: 18227.441957712173\n",
      "  time_this_iter_s: 22.68679165840149\n",
      "  time_total_s: 18227.441957712173\n",
      "  timestamp: 1550898843\n",
      "  timesteps_since_restore: 7860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7860000\n",
      "  training_iteration: 786\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18227 s, 786 iter, 7860000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-14-27\n",
      "  done: false\n",
      "  episode_len_mean: 104.75\n",
      "  episode_reward_max: 221.4358606801815\n",
      "  episode_reward_mean: 89.15603728164933\n",
      "  episode_reward_min: -166.97481612347138\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 68035\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.106\n",
      "    load_time_ms: 2.375\n",
      "    num_steps_sampled: 7870000\n",
      "    num_steps_trained: 7870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5951531529426575\n",
      "      kl: 0.037196654826402664\n",
      "      policy_loss: 0.004306907299906015\n",
      "      total_loss: 100.26732635498047\n",
      "      vf_explained_var: 0.9687632918357849\n",
      "      vf_loss: 100.26302337646484\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8287704586982727\n",
      "      kl: 0.02777850069105625\n",
      "      policy_loss: 0.003607009071856737\n",
      "      total_loss: 97.7070541381836\n",
      "      vf_explained_var: 0.9619560241699219\n",
      "      vf_loss: 97.70346069335938\n",
      "    sample_time_ms: 20008.814\n",
      "    update_time_ms: 7.025\n",
      "  iterations_since_restore: 787\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 52.34697598379353\n",
      "    rl_1: 36.80906129785582\n",
      "  time_since_restore: 18250.831770658493\n",
      "  time_this_iter_s: 23.38981294631958\n",
      "  time_total_s: 18250.831770658493\n",
      "  timestamp: 1550898867\n",
      "  timesteps_since_restore: 7870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7870000\n",
      "  training_iteration: 787\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18250 s, 787 iter, 7870000 ts, 89.2 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-14-50\n",
      "  done: false\n",
      "  episode_len_mean: 109.2\n",
      "  episode_reward_max: 217.86817917854955\n",
      "  episode_reward_mean: 113.78368330314834\n",
      "  episode_reward_min: -137.90060287825614\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 68125\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.651\n",
      "    load_time_ms: 2.333\n",
      "    num_steps_sampled: 7880000\n",
      "    num_steps_trained: 7880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5317893624305725\n",
      "      kl: 0.01622130535542965\n",
      "      policy_loss: 0.0015344694256782532\n",
      "      total_loss: 97.12812805175781\n",
      "      vf_explained_var: 0.960439920425415\n",
      "      vf_loss: 97.12659454345703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7600439786911011\n",
      "      kl: 0.021615775302052498\n",
      "      policy_loss: 0.004652760922908783\n",
      "      total_loss: 95.06157684326172\n",
      "      vf_explained_var: 0.9469160437583923\n",
      "      vf_loss: 95.0569076538086\n",
      "    sample_time_ms: 20012.617\n",
      "    update_time_ms: 7.079\n",
      "  iterations_since_restore: 788\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 65.96228222732893\n",
      "    rl_1: 47.82140107581942\n",
      "  time_since_restore: 18274.140254735947\n",
      "  time_this_iter_s: 23.308484077453613\n",
      "  time_total_s: 18274.140254735947\n",
      "  timestamp: 1550898890\n",
      "  timesteps_since_restore: 7880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7880000\n",
      "  training_iteration: 788\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18274 s, 788 iter, 7880000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-15-14\n",
      "  done: false\n",
      "  episode_len_mean: 106.32\n",
      "  episode_reward_max: 232.98293510637185\n",
      "  episode_reward_mean: 119.13512273072558\n",
      "  episode_reward_min: -149.256666459183\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 68219\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.503\n",
      "    load_time_ms: 2.353\n",
      "    num_steps_sampled: 7890000\n",
      "    num_steps_trained: 7890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6682937741279602\n",
      "      kl: 0.016846925020217896\n",
      "      policy_loss: 0.003996218089014292\n",
      "      total_loss: 133.96405029296875\n",
      "      vf_explained_var: 0.9471891522407532\n",
      "      vf_loss: 133.96006774902344\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.885872483253479\n",
      "      kl: 0.020524900406599045\n",
      "      policy_loss: 0.0034376485273241997\n",
      "      total_loss: 130.20277404785156\n",
      "      vf_explained_var: 0.9321451187133789\n",
      "      vf_loss: 130.19932556152344\n",
      "    sample_time_ms: 20037.294\n",
      "    update_time_ms: 7.107\n",
      "  iterations_since_restore: 789\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.30803581804776\n",
      "    rl_1: 50.827086912677856\n",
      "  time_since_restore: 18297.783460378647\n",
      "  time_this_iter_s: 23.643205642700195\n",
      "  time_total_s: 18297.783460378647\n",
      "  timestamp: 1550898914\n",
      "  timesteps_since_restore: 7890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7890000\n",
      "  training_iteration: 789\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18297 s, 789 iter, 7890000 ts, 119 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 115.16\n",
      "  episode_reward_max: 232.98293510637185\n",
      "  episode_reward_mean: 121.08743212571973\n",
      "  episode_reward_min: -160.17231747194649\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 68305\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.487\n",
      "    load_time_ms: 2.413\n",
      "    num_steps_sampled: 7900000\n",
      "    num_steps_trained: 7900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4400714039802551\n",
      "      kl: 0.050260163843631744\n",
      "      policy_loss: 0.014061837457120419\n",
      "      total_loss: 101.29186248779297\n",
      "      vf_explained_var: 0.950009286403656\n",
      "      vf_loss: 101.27779388427734\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7245949506759644\n",
      "      kl: 0.025826826691627502\n",
      "      policy_loss: 0.007872318848967552\n",
      "      total_loss: 104.8592529296875\n",
      "      vf_explained_var: 0.9369952082633972\n",
      "      vf_loss: 104.85137939453125\n",
      "    sample_time_ms: 20001.217\n",
      "    update_time_ms: 7.228\n",
      "  iterations_since_restore: 790\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.36257897988573\n",
      "    rl_1: 49.724853145834025\n",
      "  time_since_restore: 18320.85763168335\n",
      "  time_this_iter_s: 23.07417130470276\n",
      "  time_total_s: 18320.85763168335\n",
      "  timestamp: 1550898937\n",
      "  timesteps_since_restore: 7900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7900000\n",
      "  training_iteration: 790\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18320 s, 790 iter, 7900000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-16-00\n",
      "  done: false\n",
      "  episode_len_mean: 106.66\n",
      "  episode_reward_max: 234.961584880331\n",
      "  episode_reward_mean: 99.7981196122133\n",
      "  episode_reward_min: -177.66107800325537\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 68401\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.353\n",
      "    load_time_ms: 2.41\n",
      "    num_steps_sampled: 7910000\n",
      "    num_steps_trained: 7910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6398593187332153\n",
      "      kl: 0.02388995885848999\n",
      "      policy_loss: 0.006413316819816828\n",
      "      total_loss: 108.47722625732422\n",
      "      vf_explained_var: 0.9659438729286194\n",
      "      vf_loss: 108.47081756591797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8803442120552063\n",
      "      kl: 0.016077393665909767\n",
      "      policy_loss: 0.001990300603210926\n",
      "      total_loss: 107.392578125\n",
      "      vf_explained_var: 0.9580481052398682\n",
      "      vf_loss: 107.39056396484375\n",
      "    sample_time_ms: 19995.84\n",
      "    update_time_ms: 7.23\n",
      "  iterations_since_restore: 791\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 57.968355136974196\n",
      "    rl_1: 41.82976447523912\n",
      "  time_since_restore: 18343.883985996246\n",
      "  time_this_iter_s: 23.02635431289673\n",
      "  time_total_s: 18343.883985996246\n",
      "  timestamp: 1550898960\n",
      "  timesteps_since_restore: 7910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7910000\n",
      "  training_iteration: 791\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18343 s, 791 iter, 7910000 ts, 99.8 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-16-23\n",
      "  done: false\n",
      "  episode_len_mean: 105.87\n",
      "  episode_reward_max: 220.0156714615566\n",
      "  episode_reward_mean: 112.25224453325762\n",
      "  episode_reward_min: -170.2080055031998\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 68494\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.167\n",
      "    load_time_ms: 2.419\n",
      "    num_steps_sampled: 7920000\n",
      "    num_steps_trained: 7920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5538365840911865\n",
      "      kl: 0.023790068924427032\n",
      "      policy_loss: 0.004126667510718107\n",
      "      total_loss: 143.9532928466797\n",
      "      vf_explained_var: 0.9439874291419983\n",
      "      vf_loss: 143.94918823242188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7881221175193787\n",
      "      kl: 0.04091433063149452\n",
      "      policy_loss: 0.011341460980474949\n",
      "      total_loss: 138.99693298339844\n",
      "      vf_explained_var: 0.9327991008758545\n",
      "      vf_loss: 138.985595703125\n",
      "    sample_time_ms: 20010.362\n",
      "    update_time_ms: 7.487\n",
      "  iterations_since_restore: 792\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 63.711196895538116\n",
      "    rl_1: 48.541047637719494\n",
      "  time_since_restore: 18366.78699851036\n",
      "  time_this_iter_s: 22.90301251411438\n",
      "  time_total_s: 18366.78699851036\n",
      "  timestamp: 1550898983\n",
      "  timesteps_since_restore: 7920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7920000\n",
      "  training_iteration: 792\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18366 s, 792 iter, 7920000 ts, 112 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-16-46\n",
      "  done: false\n",
      "  episode_len_mean: 108.97\n",
      "  episode_reward_max: 229.29385953516007\n",
      "  episode_reward_mean: 122.36333875979096\n",
      "  episode_reward_min: -163.93482201411717\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 68585\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.185\n",
      "    load_time_ms: 2.491\n",
      "    num_steps_sampled: 7930000\n",
      "    num_steps_trained: 7930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4959450662136078\n",
      "      kl: 6.621846675872803\n",
      "      policy_loss: 0.14144723117351532\n",
      "      total_loss: 117.02070617675781\n",
      "      vf_explained_var: 0.9483883380889893\n",
      "      vf_loss: 116.87928009033203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7924514412879944\n",
      "      kl: 0.024448474869132042\n",
      "      policy_loss: 0.007078615482896566\n",
      "      total_loss: 107.50603485107422\n",
      "      vf_explained_var: 0.9398483037948608\n",
      "      vf_loss: 107.49893951416016\n",
      "    sample_time_ms: 19970.432\n",
      "    update_time_ms: 7.706\n",
      "  iterations_since_restore: 793\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.24988842722748\n",
      "    rl_1: 52.113450332563495\n",
      "  time_since_restore: 18389.527503967285\n",
      "  time_this_iter_s: 22.74050545692444\n",
      "  time_total_s: 18389.527503967285\n",
      "  timestamp: 1550899006\n",
      "  timesteps_since_restore: 7930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7930000\n",
      "  training_iteration: 793\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18389 s, 793 iter, 7930000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 106.91\n",
      "  episode_reward_max: 217.5003773088789\n",
      "  episode_reward_mean: 123.58247243163619\n",
      "  episode_reward_min: -163.36495022499034\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 68679\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.442\n",
      "    load_time_ms: 2.471\n",
      "    num_steps_sampled: 7940000\n",
      "    num_steps_trained: 7940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5287648439407349\n",
      "      kl: 0.014076719991862774\n",
      "      policy_loss: 0.0007493104785680771\n",
      "      total_loss: 128.40501403808594\n",
      "      vf_explained_var: 0.9488417506217957\n",
      "      vf_loss: 128.40426635742188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8994359970092773\n",
      "      kl: 0.033918868750333786\n",
      "      policy_loss: 0.0055297682993113995\n",
      "      total_loss: 133.30210876464844\n",
      "      vf_explained_var: 0.9368055462837219\n",
      "      vf_loss: 133.29660034179688\n",
      "    sample_time_ms: 19967.364\n",
      "    update_time_ms: 7.378\n",
      "  iterations_since_restore: 794\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.67791255709841\n",
      "    rl_1: 54.904559874537775\n",
      "  time_since_restore: 18412.650919675827\n",
      "  time_this_iter_s: 23.12341570854187\n",
      "  time_total_s: 18412.650919675827\n",
      "  timestamp: 1550899029\n",
      "  timesteps_since_restore: 7940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7940000\n",
      "  training_iteration: 794\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18412 s, 794 iter, 7940000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-17-32\n",
      "  done: false\n",
      "  episode_len_mean: 105.58\n",
      "  episode_reward_max: 217.5003773088789\n",
      "  episode_reward_mean: 129.00126246859028\n",
      "  episode_reward_min: -163.36495022499034\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 68772\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.536\n",
      "    load_time_ms: 2.529\n",
      "    num_steps_sampled: 7950000\n",
      "    num_steps_trained: 7950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5287463068962097\n",
      "      kl: 0.017573708668351173\n",
      "      policy_loss: -0.00015803541464265436\n",
      "      total_loss: 86.13587951660156\n",
      "      vf_explained_var: 0.9620739817619324\n",
      "      vf_loss: 86.13603973388672\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8165707588195801\n",
      "      kl: 0.02698734775185585\n",
      "      policy_loss: 0.00856658536940813\n",
      "      total_loss: 86.78324127197266\n",
      "      vf_explained_var: 0.9552635550498962\n",
      "      vf_loss: 86.77467346191406\n",
      "    sample_time_ms: 19946.317\n",
      "    update_time_ms: 7.319\n",
      "  iterations_since_restore: 795\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.21702028798386\n",
      "    rl_1: 57.78424218060641\n",
      "  time_since_restore: 18435.402619600296\n",
      "  time_this_iter_s: 22.751699924468994\n",
      "  time_total_s: 18435.402619600296\n",
      "  timestamp: 1550899052\n",
      "  timesteps_since_restore: 7950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7950000\n",
      "  training_iteration: 795\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18435 s, 795 iter, 7950000 ts, 129 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-17-54\n",
      "  done: false\n",
      "  episode_len_mean: 110.85\n",
      "  episode_reward_max: 232.60070834452736\n",
      "  episode_reward_mean: 122.4547999880146\n",
      "  episode_reward_min: -173.3474043932995\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 68861\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3094.327\n",
      "    load_time_ms: 2.521\n",
      "    num_steps_sampled: 7960000\n",
      "    num_steps_trained: 7960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4708039164543152\n",
      "      kl: 0.03309280425310135\n",
      "      policy_loss: 0.011236571706831455\n",
      "      total_loss: 110.1805648803711\n",
      "      vf_explained_var: 0.9488562345504761\n",
      "      vf_loss: 110.16931915283203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7583019137382507\n",
      "      kl: 0.02615715004503727\n",
      "      policy_loss: 0.0044672247022390366\n",
      "      total_loss: 115.26631164550781\n",
      "      vf_explained_var: 0.9338468909263611\n",
      "      vf_loss: 115.26185607910156\n",
      "    sample_time_ms: 19929.687\n",
      "    update_time_ms: 7.395\n",
      "  iterations_since_restore: 796\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.21281812475408\n",
      "    rl_1: 51.24198186326052\n",
      "  time_since_restore: 18457.961002111435\n",
      "  time_this_iter_s: 22.558382511138916\n",
      "  time_total_s: 18457.961002111435\n",
      "  timestamp: 1550899074\n",
      "  timesteps_since_restore: 7960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7960000\n",
      "  training_iteration: 796\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18457 s, 796 iter, 7960000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-18-17\n",
      "  done: false\n",
      "  episode_len_mean: 114.04\n",
      "  episode_reward_max: 221.25867852639595\n",
      "  episode_reward_mean: 114.44394168848488\n",
      "  episode_reward_min: -169.7120527852062\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 68950\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.375\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 7970000\n",
      "    num_steps_trained: 7970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.48744437098503113\n",
      "      kl: 0.03590589389204979\n",
      "      policy_loss: 0.011251850984990597\n",
      "      total_loss: 113.86052703857422\n",
      "      vf_explained_var: 0.9548721313476562\n",
      "      vf_loss: 113.84927368164062\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7277620434761047\n",
      "      kl: 0.022710304707288742\n",
      "      policy_loss: 0.0049199736677110195\n",
      "      total_loss: 112.09661865234375\n",
      "      vf_explained_var: 0.9374272227287292\n",
      "      vf_loss: 112.09168243408203\n",
      "    sample_time_ms: 19861.347\n",
      "    update_time_ms: 7.755\n",
      "  iterations_since_restore: 797\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 70.44398154152945\n",
      "    rl_1: 43.99996014695544\n",
      "  time_since_restore: 18480.71968317032\n",
      "  time_this_iter_s: 22.758681058883667\n",
      "  time_total_s: 18480.71968317032\n",
      "  timestamp: 1550899097\n",
      "  timesteps_since_restore: 7970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7970000\n",
      "  training_iteration: 797\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18480 s, 797 iter, 7970000 ts, 114 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-18-40\n",
      "  done: false\n",
      "  episode_len_mean: 109.36\n",
      "  episode_reward_max: 209.20419222860966\n",
      "  episode_reward_mean: 122.32280538240332\n",
      "  episode_reward_min: -165.84330907662743\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 69043\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.807\n",
      "    load_time_ms: 2.474\n",
      "    num_steps_sampled: 7980000\n",
      "    num_steps_trained: 7980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5882583856582642\n",
      "      kl: 0.022200316190719604\n",
      "      policy_loss: 0.0007789247902110219\n",
      "      total_loss: 100.10039520263672\n",
      "      vf_explained_var: 0.9596495032310486\n",
      "      vf_loss: 100.09962463378906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7944337129592896\n",
      "      kl: 0.03107450343668461\n",
      "      policy_loss: 0.006082271691411734\n",
      "      total_loss: 95.74700927734375\n",
      "      vf_explained_var: 0.9486842751502991\n",
      "      vf_loss: 95.74092864990234\n",
      "    sample_time_ms: 19817.016\n",
      "    update_time_ms: 7.58\n",
      "  iterations_since_restore: 798\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.8623747352209\n",
      "    rl_1: 50.46043064718241\n",
      "  time_since_restore: 18503.616184473038\n",
      "  time_this_iter_s: 22.896501302719116\n",
      "  time_total_s: 18503.616184473038\n",
      "  timestamp: 1550899120\n",
      "  timesteps_since_restore: 7980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7980000\n",
      "  training_iteration: 798\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18503 s, 798 iter, 7980000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-19-03\n",
      "  done: false\n",
      "  episode_len_mean: 107.88\n",
      "  episode_reward_max: 223.20130332613235\n",
      "  episode_reward_mean: 122.42167113991577\n",
      "  episode_reward_min: -179.40823745925968\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 69136\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3105.402\n",
      "    load_time_ms: 2.427\n",
      "    num_steps_sampled: 7990000\n",
      "    num_steps_trained: 7990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5606911778450012\n",
      "      kl: 0.023594122380018234\n",
      "      policy_loss: 0.003777977079153061\n",
      "      total_loss: 110.3135986328125\n",
      "      vf_explained_var: 0.9528028964996338\n",
      "      vf_loss: 110.30982208251953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8469237089157104\n",
      "      kl: 0.028627613559365273\n",
      "      policy_loss: 0.004705345723778009\n",
      "      total_loss: 108.38771057128906\n",
      "      vf_explained_var: 0.9429426789283752\n",
      "      vf_loss: 108.38301086425781\n",
      "    sample_time_ms: 19727.291\n",
      "    update_time_ms: 7.565\n",
      "  iterations_since_restore: 799\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.13271741283299\n",
      "    rl_1: 51.2889537270828\n",
      "  time_since_restore: 18526.386057138443\n",
      "  time_this_iter_s: 22.769872665405273\n",
      "  time_total_s: 18526.386057138443\n",
      "  timestamp: 1550899143\n",
      "  timesteps_since_restore: 7990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 7990000\n",
      "  training_iteration: 799\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18526 s, 799 iter, 7990000 ts, 122 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-19-27\n",
      "  done: false\n",
      "  episode_len_mean: 109.24\n",
      "  episode_reward_max: 218.42122197893778\n",
      "  episode_reward_mean: 123.51043972857873\n",
      "  episode_reward_min: -144.7730692373723\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 69227\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.006\n",
      "    load_time_ms: 2.406\n",
      "    num_steps_sampled: 8000000\n",
      "    num_steps_trained: 8000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5418898463249207\n",
      "      kl: 4.884096145629883\n",
      "      policy_loss: 0.09382513165473938\n",
      "      total_loss: 94.09318542480469\n",
      "      vf_explained_var: 0.961336076259613\n",
      "      vf_loss: 93.99937438964844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.872298002243042\n",
      "      kl: 0.028898801654577255\n",
      "      policy_loss: 0.004999757744371891\n",
      "      total_loss: 92.95748138427734\n",
      "      vf_explained_var: 0.9512646198272705\n",
      "      vf_loss: 92.95247650146484\n",
      "    sample_time_ms: 19845.322\n",
      "    update_time_ms: 7.495\n",
      "  iterations_since_restore: 800\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.31147941052494\n",
      "    rl_1: 52.198960318053786\n",
      "  time_since_restore: 18550.49312901497\n",
      "  time_this_iter_s: 24.10707187652588\n",
      "  time_total_s: 18550.49312901497\n",
      "  timestamp: 1550899167\n",
      "  timesteps_since_restore: 8000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8000000\n",
      "  training_iteration: 800\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18550 s, 800 iter, 8000000 ts, 124 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-19-50\n",
      "  done: false\n",
      "  episode_len_mean: 113.07\n",
      "  episode_reward_max: 222.1769454057357\n",
      "  episode_reward_mean: 138.42443949123762\n",
      "  episode_reward_min: -157.84897519041587\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 69315\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.909\n",
      "    load_time_ms: 2.444\n",
      "    num_steps_sampled: 8010000\n",
      "    num_steps_trained: 8010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.4720861613750458\n",
      "      kl: 0.01610325649380684\n",
      "      policy_loss: 0.0015602136263623834\n",
      "      total_loss: 98.85800170898438\n",
      "      vf_explained_var: 0.9507837295532227\n",
      "      vf_loss: 98.85643768310547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8147854208946228\n",
      "      kl: 10.755362510681152\n",
      "      policy_loss: 0.16485224664211273\n",
      "      total_loss: 92.8245849609375\n",
      "      vf_explained_var: 0.9396820068359375\n",
      "      vf_loss: 92.65972900390625\n",
      "    sample_time_ms: 19873.141\n",
      "    update_time_ms: 7.344\n",
      "  iterations_since_restore: 801\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.48472129334316\n",
      "    rl_1: 58.93971819789447\n",
      "  time_since_restore: 18573.82670688629\n",
      "  time_this_iter_s: 23.333577871322632\n",
      "  time_total_s: 18573.82670688629\n",
      "  timestamp: 1550899190\n",
      "  timesteps_since_restore: 8010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8010000\n",
      "  training_iteration: 801\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18573 s, 801 iter, 8010000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-20-14\n",
      "  done: false\n",
      "  episode_len_mean: 109.53\n",
      "  episode_reward_max: 222.97890516906494\n",
      "  episode_reward_mean: 134.62002116001074\n",
      "  episode_reward_min: -175.20283817983525\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 69407\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3105.838\n",
      "    load_time_ms: 2.428\n",
      "    num_steps_sampled: 8020000\n",
      "    num_steps_trained: 8020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.556714653968811\n",
      "      kl: 0.018139012157917023\n",
      "      policy_loss: 0.0028910445980727673\n",
      "      total_loss: 90.01483917236328\n",
      "      vf_explained_var: 0.9584455490112305\n",
      "      vf_loss: 90.01194763183594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8283765912055969\n",
      "      kl: 0.024344552308321\n",
      "      policy_loss: 0.002850813092663884\n",
      "      total_loss: 93.28053283691406\n",
      "      vf_explained_var: 0.945857048034668\n",
      "      vf_loss: 93.27767944335938\n",
      "    sample_time_ms: 19895.743\n",
      "    update_time_ms: 7.318\n",
      "  iterations_since_restore: 802\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 76.16893720357069\n",
      "    rl_1: 58.45108395644004\n",
      "  time_since_restore: 18597.071872472763\n",
      "  time_this_iter_s: 23.245165586471558\n",
      "  time_total_s: 18597.071872472763\n",
      "  timestamp: 1550899214\n",
      "  timesteps_since_restore: 8020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8020000\n",
      "  training_iteration: 802\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18597 s, 802 iter, 8020000 ts, 135 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-20-36\n",
      "  done: false\n",
      "  episode_len_mean: 109.88\n",
      "  episode_reward_max: 225.2158766180051\n",
      "  episode_reward_mean: 134.32428699447735\n",
      "  episode_reward_min: -182.10082021621076\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 69497\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3104.864\n",
      "    load_time_ms: 2.326\n",
      "    num_steps_sampled: 8030000\n",
      "    num_steps_trained: 8030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5752980709075928\n",
      "      kl: 0.01940312050282955\n",
      "      policy_loss: 0.002006258349865675\n",
      "      total_loss: 104.85639190673828\n",
      "      vf_explained_var: 0.9484231472015381\n",
      "      vf_loss: 104.85438537597656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8527858257293701\n",
      "      kl: 1.3108406066894531\n",
      "      policy_loss: 0.014318551868200302\n",
      "      total_loss: 91.89981842041016\n",
      "      vf_explained_var: 0.9444813132286072\n",
      "      vf_loss: 91.88548278808594\n",
      "    sample_time_ms: 19892.532\n",
      "    update_time_ms: 7.163\n",
      "  iterations_since_restore: 803\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 77.73250065294332\n",
      "    rl_1: 56.59178634153405\n",
      "  time_since_restore: 18619.767818689346\n",
      "  time_this_iter_s: 22.695946216583252\n",
      "  time_total_s: 18619.767818689346\n",
      "  timestamp: 1550899236\n",
      "  timesteps_since_restore: 8030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8030000\n",
      "  training_iteration: 803\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18619 s, 803 iter, 8030000 ts, 134 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-21-00\n",
      "  done: false\n",
      "  episode_len_mean: 112.6\n",
      "  episode_reward_max: 222.5878210672078\n",
      "  episode_reward_mean: 146.96244523140774\n",
      "  episode_reward_min: -182.10082021621076\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 69586\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.756\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 8040000\n",
      "    num_steps_trained: 8040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5125349760055542\n",
      "      kl: 0.018233003094792366\n",
      "      policy_loss: 0.005842301528900862\n",
      "      total_loss: 123.56214904785156\n",
      "      vf_explained_var: 0.9338156580924988\n",
      "      vf_loss: 123.55631256103516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7786310911178589\n",
      "      kl: 0.02262517623603344\n",
      "      policy_loss: 0.0035047936253249645\n",
      "      total_loss: 117.2337875366211\n",
      "      vf_explained_var: 0.923311173915863\n",
      "      vf_loss: 117.23025512695312\n",
      "    sample_time_ms: 19952.66\n",
      "    update_time_ms: 7.256\n",
      "  iterations_since_restore: 804\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.24612558869075\n",
      "    rl_1: 63.71631964271698\n",
      "  time_since_restore: 18643.25266098976\n",
      "  time_this_iter_s: 23.48484230041504\n",
      "  time_total_s: 18643.25266098976\n",
      "  timestamp: 1550899260\n",
      "  timesteps_since_restore: 8040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8040000\n",
      "  training_iteration: 804\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18643 s, 804 iter, 8040000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-21-23\n",
      "  done: false\n",
      "  episode_len_mean: 113.02\n",
      "  episode_reward_max: 233.51400826694334\n",
      "  episode_reward_mean: 153.61355839417283\n",
      "  episode_reward_min: -168.59369784224066\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 69674\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.566\n",
      "    load_time_ms: 2.368\n",
      "    num_steps_sampled: 8050000\n",
      "    num_steps_trained: 8050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5849526524543762\n",
      "      kl: 0.024737855419516563\n",
      "      policy_loss: 0.005483543034642935\n",
      "      total_loss: 97.2398681640625\n",
      "      vf_explained_var: 0.9380431771278381\n",
      "      vf_loss: 97.23438262939453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8343992829322815\n",
      "      kl: 0.025317344814538956\n",
      "      policy_loss: 0.0013050478883087635\n",
      "      total_loss: 89.3221664428711\n",
      "      vf_explained_var: 0.924546480178833\n",
      "      vf_loss: 89.32086944580078\n",
      "    sample_time_ms: 19947.093\n",
      "    update_time_ms: 7.358\n",
      "  iterations_since_restore: 805\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.09737992969231\n",
      "    rl_1: 65.5161784644805\n",
      "  time_since_restore: 18665.93799805641\n",
      "  time_this_iter_s: 22.68533706665039\n",
      "  time_total_s: 18665.93799805641\n",
      "  timestamp: 1550899283\n",
      "  timesteps_since_restore: 8050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8050000\n",
      "  training_iteration: 805\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18665 s, 805 iter, 8050000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-21-46\n",
      "  done: false\n",
      "  episode_len_mean: 112.16\n",
      "  episode_reward_max: 235.25589066359888\n",
      "  episode_reward_mean: 121.17549962016223\n",
      "  episode_reward_min: -162.40344621372728\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 69764\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.688\n",
      "    load_time_ms: 2.379\n",
      "    num_steps_sampled: 8060000\n",
      "    num_steps_trained: 8060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5640919804573059\n",
      "      kl: 26.30074691772461\n",
      "      policy_loss: 0.10842815041542053\n",
      "      total_loss: 124.81903839111328\n",
      "      vf_explained_var: 0.9480079412460327\n",
      "      vf_loss: 124.71062469482422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.796474039554596\n",
      "      kl: 0.04963405430316925\n",
      "      policy_loss: 0.012706441804766655\n",
      "      total_loss: 108.48294830322266\n",
      "      vf_explained_var: 0.9396052360534668\n",
      "      vf_loss: 108.47023010253906\n",
      "    sample_time_ms: 20023.712\n",
      "    update_time_ms: 7.381\n",
      "  iterations_since_restore: 806\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 71.19759109978736\n",
      "    rl_1: 49.97790852037486\n",
      "  time_since_restore: 18689.24755525589\n",
      "  time_this_iter_s: 23.30955719947815\n",
      "  time_total_s: 18689.24755525589\n",
      "  timestamp: 1550899306\n",
      "  timesteps_since_restore: 8060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8060000\n",
      "  training_iteration: 806\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18689 s, 806 iter, 8060000 ts, 121 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-22-09\n",
      "  done: false\n",
      "  episode_len_mean: 107.64\n",
      "  episode_reward_max: 237.3192221907155\n",
      "  episode_reward_mean: 147.536548990155\n",
      "  episode_reward_min: -157.58942566589923\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 69857\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3092.976\n",
      "    load_time_ms: 2.38\n",
      "    num_steps_sampled: 8070000\n",
      "    num_steps_trained: 8070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6196359992027283\n",
      "      kl: 0.023380635306239128\n",
      "      policy_loss: -0.0009157988824881613\n",
      "      total_loss: 104.8611068725586\n",
      "      vf_explained_var: 0.9422537088394165\n",
      "      vf_loss: 104.86202239990234\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8195196986198425\n",
      "      kl: 0.7246711850166321\n",
      "      policy_loss: 0.037907205522060394\n",
      "      total_loss: 86.97476196289062\n",
      "      vf_explained_var: 0.9391114711761475\n",
      "      vf_loss: 86.93685150146484\n",
      "    sample_time_ms: 20054.376\n",
      "    update_time_ms: 7.025\n",
      "  iterations_since_restore: 807\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.03622620501619\n",
      "    rl_1: 63.50032278513884\n",
      "  time_since_restore: 18712.461793899536\n",
      "  time_this_iter_s: 23.21423864364624\n",
      "  time_total_s: 18712.461793899536\n",
      "  timestamp: 1550899329\n",
      "  timesteps_since_restore: 8070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8070000\n",
      "  training_iteration: 807\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18712 s, 807 iter, 8070000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-22-32\n",
      "  done: false\n",
      "  episode_len_mean: 112.06\n",
      "  episode_reward_max: 237.27292226422378\n",
      "  episode_reward_mean: 156.93657962721042\n",
      "  episode_reward_min: -139.9793240251729\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 69944\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.312\n",
      "    load_time_ms: 2.411\n",
      "    num_steps_sampled: 8080000\n",
      "    num_steps_trained: 8080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5600486397743225\n",
      "      kl: 0.01801876910030842\n",
      "      policy_loss: 0.00550055643543601\n",
      "      total_loss: 80.5725326538086\n",
      "      vf_explained_var: 0.9412236213684082\n",
      "      vf_loss: 80.5670394897461\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.815739095211029\n",
      "      kl: 0.03034409135580063\n",
      "      policy_loss: 0.004728065803647041\n",
      "      total_loss: 75.0550308227539\n",
      "      vf_explained_var: 0.9267176985740662\n",
      "      vf_loss: 75.05030059814453\n",
      "    sample_time_ms: 20053.783\n",
      "    update_time_ms: 7.066\n",
      "  iterations_since_restore: 808\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.51482537933876\n",
      "    rl_1: 66.42175424787166\n",
      "  time_since_restore: 18735.37917780876\n",
      "  time_this_iter_s: 22.917383909225464\n",
      "  time_total_s: 18735.37917780876\n",
      "  timestamp: 1550899352\n",
      "  timesteps_since_restore: 8080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8080000\n",
      "  training_iteration: 808\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18735 s, 808 iter, 8080000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-22-55\n",
      "  done: false\n",
      "  episode_len_mean: 115.06\n",
      "  episode_reward_max: 237.27292226422378\n",
      "  episode_reward_mean: 163.71391641986165\n",
      "  episode_reward_min: -172.63845719774383\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 70032\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.703\n",
      "    load_time_ms: 2.407\n",
      "    num_steps_sampled: 8090000\n",
      "    num_steps_trained: 8090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5909380316734314\n",
      "      kl: 0.037057116627693176\n",
      "      policy_loss: 0.012355636805295944\n",
      "      total_loss: 74.09663391113281\n",
      "      vf_explained_var: 0.9456976652145386\n",
      "      vf_loss: 74.08426666259766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8048341870307922\n",
      "      kl: 0.03737713396549225\n",
      "      policy_loss: 0.012628341093659401\n",
      "      total_loss: 66.06783294677734\n",
      "      vf_explained_var: 0.9408904910087585\n",
      "      vf_loss: 66.05520629882812\n",
      "    sample_time_ms: 20074.101\n",
      "    update_time_ms: 7.277\n",
      "  iterations_since_restore: 809\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.97452805112219\n",
      "    rl_1: 69.73938836873944\n",
      "  time_since_restore: 18758.34093117714\n",
      "  time_this_iter_s: 22.961753368377686\n",
      "  time_total_s: 18758.34093117714\n",
      "  timestamp: 1550899375\n",
      "  timesteps_since_restore: 8090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8090000\n",
      "  training_iteration: 809\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18758 s, 809 iter, 8090000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-23-18\n",
      "  done: false\n",
      "  episode_len_mean: 112.36\n",
      "  episode_reward_max: 233.86380807439863\n",
      "  episode_reward_mean: 147.81074537107628\n",
      "  episode_reward_min: -168.5184688431174\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 70122\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.886\n",
      "    load_time_ms: 2.446\n",
      "    num_steps_sampled: 8100000\n",
      "    num_steps_trained: 8100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5798709392547607\n",
      "      kl: 0.012402686290442944\n",
      "      policy_loss: 0.0028600513469427824\n",
      "      total_loss: 60.05000686645508\n",
      "      vf_explained_var: 0.9610934853553772\n",
      "      vf_loss: 60.047149658203125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8198410868644714\n",
      "      kl: 0.03212624415755272\n",
      "      policy_loss: 0.003981783054769039\n",
      "      total_loss: 49.06415939331055\n",
      "      vf_explained_var: 0.9614858627319336\n",
      "      vf_loss: 49.0601806640625\n",
      "    sample_time_ms: 19946.149\n",
      "    update_time_ms: 7.119\n",
      "  iterations_since_restore: 810\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.69438224839769\n",
      "    rl_1: 62.116363122678585\n",
      "  time_since_restore: 18781.1695125103\n",
      "  time_this_iter_s: 22.8285813331604\n",
      "  time_total_s: 18781.1695125103\n",
      "  timestamp: 1550899398\n",
      "  timesteps_since_restore: 8100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8100000\n",
      "  training_iteration: 810\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18781 s, 810 iter, 8100000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-23-41\n",
      "  done: false\n",
      "  episode_len_mean: 110.04\n",
      "  episode_reward_max: 229.7772882572333\n",
      "  episode_reward_mean: 151.93088258783345\n",
      "  episode_reward_min: -169.82191011207289\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 70213\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3090.946\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 8110000\n",
      "    num_steps_trained: 8110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.547248125076294\n",
      "      kl: 0.025126751512289047\n",
      "      policy_loss: 0.004395968746393919\n",
      "      total_loss: 85.9084701538086\n",
      "      vf_explained_var: 0.9456521272659302\n",
      "      vf_loss: 85.9040756225586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7467775940895081\n",
      "      kl: 0.028705786913633347\n",
      "      policy_loss: 0.002811103593558073\n",
      "      total_loss: 81.47405242919922\n",
      "      vf_explained_var: 0.9405352473258972\n",
      "      vf_loss: 81.47123718261719\n",
      "    sample_time_ms: 19918.961\n",
      "    update_time_ms: 7.149\n",
      "  iterations_since_restore: 811\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.17031277614127\n",
      "    rl_1: 64.76056981169219\n",
      "  time_since_restore: 18804.20193219185\n",
      "  time_this_iter_s: 23.032419681549072\n",
      "  time_total_s: 18804.20193219185\n",
      "  timestamp: 1550899421\n",
      "  timesteps_since_restore: 8110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8110000\n",
      "  training_iteration: 811\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18804 s, 811 iter, 8110000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-24-04\n",
      "  done: false\n",
      "  episode_len_mean: 114.59\n",
      "  episode_reward_max: 234.13073802684613\n",
      "  episode_reward_mean: 152.0593664997286\n",
      "  episode_reward_min: -157.104756991601\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 70300\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.237\n",
      "    load_time_ms: 2.468\n",
      "    num_steps_sampled: 8120000\n",
      "    num_steps_trained: 8120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5720709562301636\n",
      "      kl: 0.02032667212188244\n",
      "      policy_loss: 0.001092167804017663\n",
      "      total_loss: 81.0653305053711\n",
      "      vf_explained_var: 0.9462556838989258\n",
      "      vf_loss: 81.0642318725586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8084280490875244\n",
      "      kl: 0.04419191554188728\n",
      "      policy_loss: 0.009447823278605938\n",
      "      total_loss: 76.7431640625\n",
      "      vf_explained_var: 0.9356152415275574\n",
      "      vf_loss: 76.73372650146484\n",
      "    sample_time_ms: 19839.678\n",
      "    update_time_ms: 6.815\n",
      "  iterations_since_restore: 812\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.35459084411879\n",
      "    rl_1: 63.70477565560986\n",
      "  time_since_restore: 18826.548743009567\n",
      "  time_this_iter_s: 22.346810817718506\n",
      "  time_total_s: 18826.548743009567\n",
      "  timestamp: 1550899444\n",
      "  timesteps_since_restore: 8120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8120000\n",
      "  training_iteration: 812\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18826 s, 812 iter, 8120000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-24-27\n",
      "  done: false\n",
      "  episode_len_mean: 111.28\n",
      "  episode_reward_max: 236.22995904715543\n",
      "  episode_reward_mean: 155.0690727689555\n",
      "  episode_reward_min: -169.38543644400417\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 70390\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.804\n",
      "    load_time_ms: 2.503\n",
      "    num_steps_sampled: 8130000\n",
      "    num_steps_trained: 8130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5972539186477661\n",
      "      kl: 0.03790703043341637\n",
      "      policy_loss: 0.007912371307611465\n",
      "      total_loss: 66.8565902709961\n",
      "      vf_explained_var: 0.9510471820831299\n",
      "      vf_loss: 66.84867858886719\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8032364249229431\n",
      "      kl: 0.04633190482854843\n",
      "      policy_loss: 0.012866029515862465\n",
      "      total_loss: 61.73115921020508\n",
      "      vf_explained_var: 0.9466873407363892\n",
      "      vf_loss: 61.718292236328125\n",
      "    sample_time_ms: 19913.911\n",
      "    update_time_ms: 6.769\n",
      "  iterations_since_restore: 813\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.3494287551185\n",
      "    rl_1: 66.719644013837\n",
      "  time_since_restore: 18849.964970827103\n",
      "  time_this_iter_s: 23.4162278175354\n",
      "  time_total_s: 18849.964970827103\n",
      "  timestamp: 1550899467\n",
      "  timesteps_since_restore: 8130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8130000\n",
      "  training_iteration: 813\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18849 s, 813 iter, 8130000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-24-50\n",
      "  done: false\n",
      "  episode_len_mean: 109.06\n",
      "  episode_reward_max: 234.37533684405773\n",
      "  episode_reward_mean: 150.83785571364612\n",
      "  episode_reward_min: -169.2310711464542\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 70484\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.806\n",
      "    load_time_ms: 2.476\n",
      "    num_steps_sampled: 8140000\n",
      "    num_steps_trained: 8140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6471303105354309\n",
      "      kl: 0.02723202295601368\n",
      "      policy_loss: 0.004059793893247843\n",
      "      total_loss: 80.99419403076172\n",
      "      vf_explained_var: 0.9486052393913269\n",
      "      vf_loss: 80.99015045166016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.82522052526474\n",
      "      kl: 0.023946017026901245\n",
      "      policy_loss: 0.002048450754955411\n",
      "      total_loss: 80.86365509033203\n",
      "      vf_explained_var: 0.9420472383499146\n",
      "      vf_loss: 80.86161041259766\n",
      "    sample_time_ms: 19898.499\n",
      "    update_time_ms: 6.871\n",
      "  iterations_since_restore: 814\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.81413462465122\n",
      "    rl_1: 66.02372108899486\n",
      "  time_since_restore: 18873.314910411835\n",
      "  time_this_iter_s: 23.349939584732056\n",
      "  time_total_s: 18873.314910411835\n",
      "  timestamp: 1550899490\n",
      "  timesteps_since_restore: 8140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8140000\n",
      "  training_iteration: 814\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18873 s, 814 iter, 8140000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-25-14\n",
      "  done: false\n",
      "  episode_len_mean: 113.99\n",
      "  episode_reward_max: 236.57733913502238\n",
      "  episode_reward_mean: 158.6076268515692\n",
      "  episode_reward_min: -163.90670353217916\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 70571\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.342\n",
      "    load_time_ms: 2.478\n",
      "    num_steps_sampled: 8150000\n",
      "    num_steps_trained: 8150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5955860614776611\n",
      "      kl: 0.025368981063365936\n",
      "      policy_loss: 0.010597308166325092\n",
      "      total_loss: 57.08512496948242\n",
      "      vf_explained_var: 0.9531352519989014\n",
      "      vf_loss: 57.07452392578125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8250047564506531\n",
      "      kl: 0.03814325109124184\n",
      "      policy_loss: 0.015763433650135994\n",
      "      total_loss: 51.45916748046875\n",
      "      vf_explained_var: 0.9511724710464478\n",
      "      vf_loss: 51.44339370727539\n",
      "    sample_time_ms: 19959.761\n",
      "    update_time_ms: 6.962\n",
      "  iterations_since_restore: 815\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.40256685061091\n",
      "    rl_1: 68.2050600009583\n",
      "  time_since_restore: 18896.599102973938\n",
      "  time_this_iter_s: 23.28419256210327\n",
      "  time_total_s: 18896.599102973938\n",
      "  timestamp: 1550899514\n",
      "  timesteps_since_restore: 8150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8150000\n",
      "  training_iteration: 815\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18896 s, 815 iter, 8150000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-25-37\n",
      "  done: false\n",
      "  episode_len_mean: 115.41\n",
      "  episode_reward_max: 224.69881412091667\n",
      "  episode_reward_mean: 164.7740428912126\n",
      "  episode_reward_min: -135.26392791411345\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 70658\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.095\n",
      "    load_time_ms: 2.48\n",
      "    num_steps_sampled: 8160000\n",
      "    num_steps_trained: 8160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5871120095252991\n",
      "      kl: 0.0194191113114357\n",
      "      policy_loss: 0.005012798588722944\n",
      "      total_loss: 44.006954193115234\n",
      "      vf_explained_var: 0.9624464511871338\n",
      "      vf_loss: 44.0019416809082\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8049701452255249\n",
      "      kl: 0.03366263583302498\n",
      "      policy_loss: 0.011567918583750725\n",
      "      total_loss: 40.496334075927734\n",
      "      vf_explained_var: 0.9564527869224548\n",
      "      vf_loss: 40.48476028442383\n",
      "    sample_time_ms: 19910.678\n",
      "    update_time_ms: 6.805\n",
      "  iterations_since_restore: 816\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.90497825425102\n",
      "    rl_1: 68.8690646369616\n",
      "  time_since_restore: 18919.547845363617\n",
      "  time_this_iter_s: 22.948742389678955\n",
      "  time_total_s: 18919.547845363617\n",
      "  timestamp: 1550899537\n",
      "  timesteps_since_restore: 8160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8160000\n",
      "  training_iteration: 816\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18919 s, 816 iter, 8160000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-26-00\n",
      "  done: false\n",
      "  episode_len_mean: 111.45\n",
      "  episode_reward_max: 238.83159969473286\n",
      "  episode_reward_mean: 149.0480574393891\n",
      "  episode_reward_min: -166.4996615875558\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 70749\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.595\n",
      "    load_time_ms: 2.487\n",
      "    num_steps_sampled: 8170000\n",
      "    num_steps_trained: 8170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5898360013961792\n",
      "      kl: 0.02672595903277397\n",
      "      policy_loss: 0.0069545963779091835\n",
      "      total_loss: 57.29489517211914\n",
      "      vf_explained_var: 0.9663588404655457\n",
      "      vf_loss: 57.287940979003906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7770628929138184\n",
      "      kl: 0.03521520271897316\n",
      "      policy_loss: 0.011451752856373787\n",
      "      total_loss: 49.9968147277832\n",
      "      vf_explained_var: 0.9617686867713928\n",
      "      vf_loss: 49.98535919189453\n",
      "    sample_time_ms: 19916.245\n",
      "    update_time_ms: 7.358\n",
      "  iterations_since_restore: 817\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.11564456131693\n",
      "    rl_1: 61.932412878072164\n",
      "  time_since_restore: 18942.638420820236\n",
      "  time_this_iter_s: 23.090575456619263\n",
      "  time_total_s: 18942.638420820236\n",
      "  timestamp: 1550899560\n",
      "  timesteps_since_restore: 8170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8170000\n",
      "  training_iteration: 817\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18942 s, 817 iter, 8170000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-26-23\n",
      "  done: false\n",
      "  episode_len_mean: 109.06\n",
      "  episode_reward_max: 225.7040671480345\n",
      "  episode_reward_mean: 146.40502442461752\n",
      "  episode_reward_min: -171.44752746353015\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 70840\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.58\n",
      "    load_time_ms: 2.512\n",
      "    num_steps_sampled: 8180000\n",
      "    num_steps_trained: 8180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.613947331905365\n",
      "      kl: 0.06524840742349625\n",
      "      policy_loss: 0.018497416749596596\n",
      "      total_loss: 68.59976959228516\n",
      "      vf_explained_var: 0.96314936876297\n",
      "      vf_loss: 68.5812759399414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8041464686393738\n",
      "      kl: 0.028464075177907944\n",
      "      policy_loss: 0.006391145288944244\n",
      "      total_loss: 60.144718170166016\n",
      "      vf_explained_var: 0.9563786387443542\n",
      "      vf_loss: 60.13832092285156\n",
      "    sample_time_ms: 19965.265\n",
      "    update_time_ms: 7.499\n",
      "  iterations_since_restore: 818\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.5415396328799\n",
      "    rl_1: 60.86348479173764\n",
      "  time_since_restore: 18966.00774025917\n",
      "  time_this_iter_s: 23.369319438934326\n",
      "  time_total_s: 18966.00774025917\n",
      "  timestamp: 1550899583\n",
      "  timesteps_since_restore: 8180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8180000\n",
      "  training_iteration: 818\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18966 s, 818 iter, 8180000 ts, 146 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-26-46\n",
      "  done: false\n",
      "  episode_len_mean: 112.33\n",
      "  episode_reward_max: 238.7214691278533\n",
      "  episode_reward_mean: 150.79729055143792\n",
      "  episode_reward_min: -153.82127931313283\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 70928\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.491\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 8190000\n",
      "    num_steps_trained: 8190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.574683427810669\n",
      "      kl: 0.014600402675569057\n",
      "      policy_loss: 0.005872998386621475\n",
      "      total_loss: 61.101444244384766\n",
      "      vf_explained_var: 0.9589138627052307\n",
      "      vf_loss: 61.09557342529297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7573162317276001\n",
      "      kl: 0.030241113156080246\n",
      "      policy_loss: 0.004499268252402544\n",
      "      total_loss: 54.652549743652344\n",
      "      vf_explained_var: 0.954748272895813\n",
      "      vf_loss: 54.64805603027344\n",
      "    sample_time_ms: 19968.374\n",
      "    update_time_ms: 8.044\n",
      "  iterations_since_restore: 819\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.87146697914761\n",
      "    rl_1: 62.92582357229031\n",
      "  time_since_restore: 18989.02754330635\n",
      "  time_this_iter_s: 23.019803047180176\n",
      "  time_total_s: 18989.02754330635\n",
      "  timestamp: 1550899606\n",
      "  timesteps_since_restore: 8190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8190000\n",
      "  training_iteration: 819\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 18989 s, 819 iter, 8190000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-27-10\n",
      "  done: false\n",
      "  episode_len_mean: 111.86\n",
      "  episode_reward_max: 234.43673498129505\n",
      "  episode_reward_mean: 152.2507325178409\n",
      "  episode_reward_min: -172.5047635563438\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 71017\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.381\n",
      "    load_time_ms: 2.32\n",
      "    num_steps_sampled: 8200000\n",
      "    num_steps_trained: 8200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6452869176864624\n",
      "      kl: 0.03465662896633148\n",
      "      policy_loss: 0.009456517174839973\n",
      "      total_loss: 82.89070892333984\n",
      "      vf_explained_var: 0.9496352076530457\n",
      "      vf_loss: 82.88126373291016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8588670492172241\n",
      "      kl: 0.03924044221639633\n",
      "      policy_loss: 0.004562749061733484\n",
      "      total_loss: 74.05741882324219\n",
      "      vf_explained_var: 0.9428954720497131\n",
      "      vf_loss: 74.0528564453125\n",
      "    sample_time_ms: 19984.268\n",
      "    update_time_ms: 7.994\n",
      "  iterations_since_restore: 820\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.28510517273786\n",
      "    rl_1: 63.96562734510307\n",
      "  time_since_restore: 19012.260060071945\n",
      "  time_this_iter_s: 23.232516765594482\n",
      "  time_total_s: 19012.260060071945\n",
      "  timestamp: 1550899630\n",
      "  timesteps_since_restore: 8200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8200000\n",
      "  training_iteration: 820\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19012 s, 820 iter, 8200000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-27-33\n",
      "  done: false\n",
      "  episode_len_mean: 111.19\n",
      "  episode_reward_max: 238.38878862558423\n",
      "  episode_reward_mean: 164.14546586972577\n",
      "  episode_reward_min: -142.28290689801793\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 71107\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3117.849\n",
      "    load_time_ms: 2.436\n",
      "    num_steps_sampled: 8210000\n",
      "    num_steps_trained: 8210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6047754883766174\n",
      "      kl: 0.024371007457375526\n",
      "      policy_loss: 0.006073775235563517\n",
      "      total_loss: 56.54037094116211\n",
      "      vf_explained_var: 0.9525068998336792\n",
      "      vf_loss: 56.534305572509766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8139000535011292\n",
      "      kl: 0.03953808546066284\n",
      "      policy_loss: 0.0032036365009844303\n",
      "      total_loss: 48.3213005065918\n",
      "      vf_explained_var: 0.9486686587333679\n",
      "      vf_loss: 48.31809616088867\n",
      "    sample_time_ms: 19979.676\n",
      "    update_time_ms: 7.959\n",
      "  iterations_since_restore: 821\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.3657287497944\n",
      "    rl_1: 70.77973711993137\n",
      "  time_since_restore: 19035.475063562393\n",
      "  time_this_iter_s: 23.215003490447998\n",
      "  time_total_s: 19035.475063562393\n",
      "  timestamp: 1550899653\n",
      "  timesteps_since_restore: 8210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8210000\n",
      "  training_iteration: 821\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19035 s, 821 iter, 8210000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-27-56\n",
      "  done: false\n",
      "  episode_len_mean: 114.4\n",
      "  episode_reward_max: 234.66389678179306\n",
      "  episode_reward_mean: 154.30757323597635\n",
      "  episode_reward_min: -163.02006011289166\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 71194\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3115.033\n",
      "    load_time_ms: 2.407\n",
      "    num_steps_sampled: 8220000\n",
      "    num_steps_trained: 8220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6495769023895264\n",
      "      kl: 0.012377663515508175\n",
      "      policy_loss: 0.0034589439164847136\n",
      "      total_loss: 57.44544982910156\n",
      "      vf_explained_var: 0.9618847370147705\n",
      "      vf_loss: 57.44200897216797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8608182072639465\n",
      "      kl: 0.03752772882580757\n",
      "      policy_loss: 0.007553172297775745\n",
      "      total_loss: 52.058441162109375\n",
      "      vf_explained_var: 0.957868218421936\n",
      "      vf_loss: 52.0508918762207\n",
      "    sample_time_ms: 20020.904\n",
      "    update_time_ms: 8.078\n",
      "  iterations_since_restore: 822\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.03243438957315\n",
      "    rl_1: 64.27513884640324\n",
      "  time_since_restore: 19058.206679344177\n",
      "  time_this_iter_s: 22.731615781784058\n",
      "  time_total_s: 19058.206679344177\n",
      "  timestamp: 1550899676\n",
      "  timesteps_since_restore: 8220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8220000\n",
      "  training_iteration: 822\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19058 s, 822 iter, 8220000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-28-19\n",
      "  done: false\n",
      "  episode_len_mean: 108.08\n",
      "  episode_reward_max: 229.10730983398028\n",
      "  episode_reward_mean: 156.07923947149308\n",
      "  episode_reward_min: -154.03789349504862\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 71286\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3116.801\n",
      "    load_time_ms: 2.398\n",
      "    num_steps_sampled: 8230000\n",
      "    num_steps_trained: 8230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6721272468566895\n",
      "      kl: 0.02371758595108986\n",
      "      policy_loss: -0.0010685758898034692\n",
      "      total_loss: 70.76773834228516\n",
      "      vf_explained_var: 0.9574070572853088\n",
      "      vf_loss: 70.76880645751953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8345117568969727\n",
      "      kl: 0.02660866267979145\n",
      "      policy_loss: 0.004985520150512457\n",
      "      total_loss: 66.81512451171875\n",
      "      vf_explained_var: 0.9498913884162903\n",
      "      vf_loss: 66.81014251708984\n",
      "    sample_time_ms: 19999.55\n",
      "    update_time_ms: 8.012\n",
      "  iterations_since_restore: 823\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.35130447736624\n",
      "    rl_1: 67.72793499412684\n",
      "  time_since_restore: 19081.425843954086\n",
      "  time_this_iter_s: 23.219164609909058\n",
      "  time_total_s: 19081.425843954086\n",
      "  timestamp: 1550899699\n",
      "  timesteps_since_restore: 8230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8230000\n",
      "  training_iteration: 823\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19081 s, 823 iter, 8230000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-28-42\n",
      "  done: false\n",
      "  episode_len_mean: 113.16\n",
      "  episode_reward_max: 225.48332130856892\n",
      "  episode_reward_mean: 171.06924078138175\n",
      "  episode_reward_min: -121.98501112708531\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 71375\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3115.819\n",
      "    load_time_ms: 2.375\n",
      "    num_steps_sampled: 8240000\n",
      "    num_steps_trained: 8240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6726388931274414\n",
      "      kl: 0.025403045117855072\n",
      "      policy_loss: 0.00341863464564085\n",
      "      total_loss: 27.19852638244629\n",
      "      vf_explained_var: 0.9762916564941406\n",
      "      vf_loss: 27.19510841369629\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.850250244140625\n",
      "      kl: 0.04283926263451576\n",
      "      policy_loss: 0.006570784840732813\n",
      "      total_loss: 25.621519088745117\n",
      "      vf_explained_var: 0.9704114198684692\n",
      "      vf_loss: 25.614946365356445\n",
      "    sample_time_ms: 19926.602\n",
      "    update_time_ms: 7.906\n",
      "  iterations_since_restore: 824\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.49598496803377\n",
      "    rl_1: 72.57325581334798\n",
      "  time_since_restore: 19104.034625530243\n",
      "  time_this_iter_s: 22.608781576156616\n",
      "  time_total_s: 19104.034625530243\n",
      "  timestamp: 1550899722\n",
      "  timesteps_since_restore: 8240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8240000\n",
      "  training_iteration: 824\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19104 s, 824 iter, 8240000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-29-04\n",
      "  done: false\n",
      "  episode_len_mean: 113.69\n",
      "  episode_reward_max: 240.24770309313362\n",
      "  episode_reward_mean: 163.42501767853625\n",
      "  episode_reward_min: -166.10030760625196\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 71464\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3115.332\n",
      "    load_time_ms: 2.394\n",
      "    num_steps_sampled: 8250000\n",
      "    num_steps_trained: 8250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6026398539543152\n",
      "      kl: 0.014311606995761395\n",
      "      policy_loss: 0.0006084020133130252\n",
      "      total_loss: 52.749237060546875\n",
      "      vf_explained_var: 0.9616268873214722\n",
      "      vf_loss: 52.748634338378906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7945810556411743\n",
      "      kl: 0.02925313077867031\n",
      "      policy_loss: 0.0029093169141560793\n",
      "      total_loss: 50.27901077270508\n",
      "      vf_explained_var: 0.9569395184516907\n",
      "      vf_loss: 50.276100158691406\n",
      "    sample_time_ms: 19847.382\n",
      "    update_time_ms: 7.943\n",
      "  iterations_since_restore: 825\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.91660069220605\n",
      "    rl_1: 69.50841698633019\n",
      "  time_since_restore: 19126.52197790146\n",
      "  time_this_iter_s: 22.48735237121582\n",
      "  time_total_s: 19126.52197790146\n",
      "  timestamp: 1550899744\n",
      "  timesteps_since_restore: 8250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8250000\n",
      "  training_iteration: 825\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19126 s, 825 iter, 8250000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-29-27\n",
      "  done: false\n",
      "  episode_len_mean: 111.13\n",
      "  episode_reward_max: 229.31054912930102\n",
      "  episode_reward_mean: 151.74608673116936\n",
      "  episode_reward_min: -175.88226587472445\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 71554\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3103.123\n",
      "    load_time_ms: 2.409\n",
      "    num_steps_sampled: 8260000\n",
      "    num_steps_trained: 8260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6661519408226013\n",
      "      kl: 0.026116471737623215\n",
      "      policy_loss: 0.0026029974687844515\n",
      "      total_loss: 73.50662994384766\n",
      "      vf_explained_var: 0.9579277038574219\n",
      "      vf_loss: 73.5040283203125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8137354850769043\n",
      "      kl: 0.06373703479766846\n",
      "      policy_loss: 0.0015364105347543955\n",
      "      total_loss: 57.81379699707031\n",
      "      vf_explained_var: 0.960107147693634\n",
      "      vf_loss: 57.81226348876953\n",
      "    sample_time_ms: 19846.413\n",
      "    update_time_ms: 8.056\n",
      "  iterations_since_restore: 826\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.87031076135595\n",
      "    rl_1: 63.87577596981341\n",
      "  time_since_restore: 19149.33250117302\n",
      "  time_this_iter_s: 22.81052327156067\n",
      "  time_total_s: 19149.33250117302\n",
      "  timestamp: 1550899767\n",
      "  timesteps_since_restore: 8260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8260000\n",
      "  training_iteration: 826\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.7/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19149 s, 826 iter, 8260000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-29-50\n",
      "  done: false\n",
      "  episode_len_mean: 111.91\n",
      "  episode_reward_max: 234.57717960209897\n",
      "  episode_reward_mean: 157.1329694975581\n",
      "  episode_reward_min: -175.88226587472445\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 71643\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3103.816\n",
      "    load_time_ms: 2.399\n",
      "    num_steps_sampled: 8270000\n",
      "    num_steps_trained: 8270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7085267901420593\n",
      "      kl: 0.023242073133587837\n",
      "      policy_loss: 0.0015187693061307073\n",
      "      total_loss: 39.76141357421875\n",
      "      vf_explained_var: 0.9710032939910889\n",
      "      vf_loss: 39.75989532470703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.9166993498802185\n",
      "      kl: 0.03382505103945732\n",
      "      policy_loss: 0.006743387319147587\n",
      "      total_loss: 34.070213317871094\n",
      "      vf_explained_var: 0.9708957076072693\n",
      "      vf_loss: 34.06346893310547\n",
      "    sample_time_ms: 19852.485\n",
      "    update_time_ms: 7.601\n",
      "  iterations_since_restore: 827\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.69660256462215\n",
      "    rl_1: 67.43636693293591\n",
      "  time_since_restore: 19172.486572742462\n",
      "  time_this_iter_s: 23.15407156944275\n",
      "  time_total_s: 19172.486572742462\n",
      "  timestamp: 1550899790\n",
      "  timesteps_since_restore: 8270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8270000\n",
      "  training_iteration: 827\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19172 s, 827 iter, 8270000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-30-13\n",
      "  done: false\n",
      "  episode_len_mean: 110.13\n",
      "  episode_reward_max: 240.9003020290356\n",
      "  episode_reward_mean: 164.96518616951045\n",
      "  episode_reward_min: -147.40049845887285\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 71733\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3111.345\n",
      "    load_time_ms: 2.366\n",
      "    num_steps_sampled: 8280000\n",
      "    num_steps_trained: 8280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7253391742706299\n",
      "      kl: 0.02400532364845276\n",
      "      policy_loss: 0.0008156016701832414\n",
      "      total_loss: 57.73970413208008\n",
      "      vf_explained_var: 0.9565122723579407\n",
      "      vf_loss: 57.738887786865234\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8773547410964966\n",
      "      kl: 0.018553299829363823\n",
      "      policy_loss: 0.003617066890001297\n",
      "      total_loss: 53.45252227783203\n",
      "      vf_explained_var: 0.9520565867424011\n",
      "      vf_loss: 53.44890594482422\n",
      "    sample_time_ms: 19829.049\n",
      "    update_time_ms: 7.666\n",
      "  iterations_since_restore: 828\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.55064888091985\n",
      "    rl_1: 72.4145372885906\n",
      "  time_since_restore: 19195.697231054306\n",
      "  time_this_iter_s: 23.210658311843872\n",
      "  time_total_s: 19195.697231054306\n",
      "  timestamp: 1550899813\n",
      "  timesteps_since_restore: 8280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8280000\n",
      "  training_iteration: 828\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19195 s, 828 iter, 8280000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 107.73\n",
      "  episode_reward_max: 235.13690967078682\n",
      "  episode_reward_mean: 159.9772386587515\n",
      "  episode_reward_min: -169.8343755113533\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 71826\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3108.37\n",
      "    load_time_ms: 2.325\n",
      "    num_steps_sampled: 8290000\n",
      "    num_steps_trained: 8290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7308449745178223\n",
      "      kl: 0.024041030555963516\n",
      "      policy_loss: 0.002079789759591222\n",
      "      total_loss: 69.31317138671875\n",
      "      vf_explained_var: 0.9565063118934631\n",
      "      vf_loss: 69.31108856201172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8613705635070801\n",
      "      kl: 0.02777237445116043\n",
      "      policy_loss: 0.0018666088581085205\n",
      "      total_loss: 59.14662170410156\n",
      "      vf_explained_var: 0.9564744830131531\n",
      "      vf_loss: 59.1447639465332\n",
      "    sample_time_ms: 19802.579\n",
      "    update_time_ms: 6.978\n",
      "  iterations_since_restore: 829\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.35451989481408\n",
      "    rl_1: 70.62271876393739\n",
      "  time_since_restore: 19218.406930923462\n",
      "  time_this_iter_s: 22.709699869155884\n",
      "  time_total_s: 19218.406930923462\n",
      "  timestamp: 1550899836\n",
      "  timesteps_since_restore: 8290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8290000\n",
      "  training_iteration: 829\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19218 s, 829 iter, 8290000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-31-00\n",
      "  done: false\n",
      "  episode_len_mean: 108.66\n",
      "  episode_reward_max: 228.94812139368256\n",
      "  episode_reward_mean: 149.53215006469435\n",
      "  episode_reward_min: -177.44548274890568\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 71917\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.135\n",
      "    load_time_ms: 2.329\n",
      "    num_steps_sampled: 8300000\n",
      "    num_steps_trained: 8300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6975575685501099\n",
      "      kl: 0.027244996279478073\n",
      "      policy_loss: 0.005558915436267853\n",
      "      total_loss: 62.86777114868164\n",
      "      vf_explained_var: 0.9593574404716492\n",
      "      vf_loss: 62.86220932006836\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8070687055587769\n",
      "      kl: 0.0254997406154871\n",
      "      policy_loss: 0.004848202224820852\n",
      "      total_loss: 54.22871780395508\n",
      "      vf_explained_var: 0.9519737362861633\n",
      "      vf_loss: 54.2238655090332\n",
      "    sample_time_ms: 19851.185\n",
      "    update_time_ms: 6.94\n",
      "  iterations_since_restore: 830\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.48347563400267\n",
      "    rl_1: 64.0486744306917\n",
      "  time_since_restore: 19241.89444541931\n",
      "  time_this_iter_s: 23.48751449584961\n",
      "  time_total_s: 19241.89444541931\n",
      "  timestamp: 1550899860\n",
      "  timesteps_since_restore: 8300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8300000\n",
      "  training_iteration: 830\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19241 s, 830 iter, 8300000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-31-23\n",
      "  done: false\n",
      "  episode_len_mean: 109.28\n",
      "  episode_reward_max: 237.0326287655353\n",
      "  episode_reward_mean: 147.66384497336279\n",
      "  episode_reward_min: -177.15907928753296\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 72009\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3058.685\n",
      "    load_time_ms: 2.268\n",
      "    num_steps_sampled: 8310000\n",
      "    num_steps_trained: 8310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7171856164932251\n",
      "      kl: 0.01907217875123024\n",
      "      policy_loss: -9.859066631179303e-05\n",
      "      total_loss: 72.36038970947266\n",
      "      vf_explained_var: 0.9632978439331055\n",
      "      vf_loss: 72.3604736328125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8269320726394653\n",
      "      kl: 0.04513508453965187\n",
      "      policy_loss: 0.008329042233526707\n",
      "      total_loss: 59.28093719482422\n",
      "      vf_explained_var: 0.9668078422546387\n",
      "      vf_loss: 59.272605895996094\n",
      "    sample_time_ms: 19845.386\n",
      "    update_time_ms: 6.925\n",
      "  iterations_since_restore: 831\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.33316296497416\n",
      "    rl_1: 64.33068200838859\n",
      "  time_since_restore: 19264.78508591652\n",
      "  time_this_iter_s: 22.89064049720764\n",
      "  time_total_s: 19264.78508591652\n",
      "  timestamp: 1550899883\n",
      "  timesteps_since_restore: 8310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8310000\n",
      "  training_iteration: 831\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19264 s, 831 iter, 8310000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-31-46\n",
      "  done: false\n",
      "  episode_len_mean: 110.58\n",
      "  episode_reward_max: 235.52296723934376\n",
      "  episode_reward_mean: 155.17175432309804\n",
      "  episode_reward_min: -160.97910637909638\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 72100\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3059.763\n",
      "    load_time_ms: 2.337\n",
      "    num_steps_sampled: 8320000\n",
      "    num_steps_trained: 8320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7104020714759827\n",
      "      kl: 0.03301341459155083\n",
      "      policy_loss: 0.00857927743345499\n",
      "      total_loss: 46.17609405517578\n",
      "      vf_explained_var: 0.9676240086555481\n",
      "      vf_loss: 46.167518615722656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.844690203666687\n",
      "      kl: 0.028820110484957695\n",
      "      policy_loss: 0.005729672499001026\n",
      "      total_loss: 40.39649200439453\n",
      "      vf_explained_var: 0.9661804437637329\n",
      "      vf_loss: 40.39076232910156\n",
      "    sample_time_ms: 19883.205\n",
      "    update_time_ms: 7.138\n",
      "  iterations_since_restore: 832\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.94431482656206\n",
      "    rl_1: 66.22743949653602\n",
      "  time_since_restore: 19287.90819311142\n",
      "  time_this_iter_s: 23.123107194900513\n",
      "  time_total_s: 19287.90819311142\n",
      "  timestamp: 1550899906\n",
      "  timesteps_since_restore: 8320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8320000\n",
      "  training_iteration: 832\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19287 s, 832 iter, 8320000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-32-10\n",
      "  done: false\n",
      "  episode_len_mean: 109.78\n",
      "  episode_reward_max: 235.52296723934376\n",
      "  episode_reward_mean: 136.9937924160488\n",
      "  episode_reward_min: -171.48446438263903\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 72191\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.233\n",
      "    load_time_ms: 2.33\n",
      "    num_steps_sampled: 8330000\n",
      "    num_steps_trained: 8330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6971449851989746\n",
      "      kl: 0.03031413070857525\n",
      "      policy_loss: 0.0008851060410961509\n",
      "      total_loss: 73.89103698730469\n",
      "      vf_explained_var: 0.9664819240570068\n",
      "      vf_loss: 73.89015197753906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.868315577507019\n",
      "      kl: 0.031742364168167114\n",
      "      policy_loss: 0.002261957386508584\n",
      "      total_loss: 70.01881408691406\n",
      "      vf_explained_var: 0.9623855948448181\n",
      "      vf_loss: 70.0165786743164\n",
      "    sample_time_ms: 19905.782\n",
      "    update_time_ms: 7.536\n",
      "  iterations_since_restore: 833\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.97094502097046\n",
      "    rl_1: 58.022847395078294\n",
      "  time_since_restore: 19311.5422000885\n",
      "  time_this_iter_s: 23.6340069770813\n",
      "  time_total_s: 19311.5422000885\n",
      "  timestamp: 1550899930\n",
      "  timesteps_since_restore: 8330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8330000\n",
      "  training_iteration: 833\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19311 s, 833 iter, 8330000 ts, 137 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-32-33\n",
      "  done: false\n",
      "  episode_len_mean: 113.24\n",
      "  episode_reward_max: 233.73145226598024\n",
      "  episode_reward_mean: 153.6266958642177\n",
      "  episode_reward_min: -172.36511609652496\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 72279\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.808\n",
      "    load_time_ms: 2.318\n",
      "    num_steps_sampled: 8340000\n",
      "    num_steps_trained: 8340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5751883387565613\n",
      "      kl: 0.017640430480241776\n",
      "      policy_loss: -0.00010726902110036463\n",
      "      total_loss: 80.58173370361328\n",
      "      vf_explained_var: 0.9445115327835083\n",
      "      vf_loss: 80.58185577392578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7024089694023132\n",
      "      kl: 0.046980712562799454\n",
      "      policy_loss: 0.012761122547090054\n",
      "      total_loss: 72.3186264038086\n",
      "      vf_explained_var: 0.9439185857772827\n",
      "      vf_loss: 72.30587768554688\n",
      "    sample_time_ms: 19955.084\n",
      "    update_time_ms: 7.517\n",
      "  iterations_since_restore: 834\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.71317696499032\n",
      "    rl_1: 65.91351889922743\n",
      "  time_since_restore: 19334.65000486374\n",
      "  time_this_iter_s: 23.107804775238037\n",
      "  time_total_s: 19334.65000486374\n",
      "  timestamp: 1550899953\n",
      "  timesteps_since_restore: 8340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8340000\n",
      "  training_iteration: 834\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19334 s, 834 iter, 8340000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-32-56\n",
      "  done: false\n",
      "  episode_len_mean: 112.97\n",
      "  episode_reward_max: 235.07172629351226\n",
      "  episode_reward_mean: 158.1627721319545\n",
      "  episode_reward_min: -172.36511609652496\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 72367\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.001\n",
      "    load_time_ms: 2.269\n",
      "    num_steps_sampled: 8350000\n",
      "    num_steps_trained: 8350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6677677631378174\n",
      "      kl: 0.0230824276804924\n",
      "      policy_loss: 0.002645964501425624\n",
      "      total_loss: 71.05905151367188\n",
      "      vf_explained_var: 0.9508740305900574\n",
      "      vf_loss: 71.05641174316406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8300807476043701\n",
      "      kl: 0.021634161472320557\n",
      "      policy_loss: 0.00516932550817728\n",
      "      total_loss: 68.4024887084961\n",
      "      vf_explained_var: 0.9422670006752014\n",
      "      vf_loss: 68.39730834960938\n",
      "    sample_time_ms: 19993.237\n",
      "    update_time_ms: 7.409\n",
      "  iterations_since_restore: 835\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.75189692601721\n",
      "    rl_1: 67.41087520593726\n",
      "  time_since_restore: 19357.529815912247\n",
      "  time_this_iter_s: 22.87981104850769\n",
      "  time_total_s: 19357.529815912247\n",
      "  timestamp: 1550899976\n",
      "  timesteps_since_restore: 8350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8350000\n",
      "  training_iteration: 835\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19357 s, 835 iter, 8350000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-33-19\n",
      "  done: false\n",
      "  episode_len_mean: 105.53\n",
      "  episode_reward_max: 225.28468563307922\n",
      "  episode_reward_mean: 117.32537763607777\n",
      "  episode_reward_min: -175.14066811942905\n",
      "  episodes_this_iter: 96\n",
      "  episodes_total: 72463\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.242\n",
      "    load_time_ms: 2.272\n",
      "    num_steps_sampled: 8360000\n",
      "    num_steps_trained: 8360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7093204259872437\n",
      "      kl: 0.052286546677351\n",
      "      policy_loss: 0.014144654385745525\n",
      "      total_loss: 119.32359313964844\n",
      "      vf_explained_var: 0.9531747102737427\n",
      "      vf_loss: 119.3094711303711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7731487154960632\n",
      "      kl: 6.889030933380127\n",
      "      policy_loss: 0.08831540495157242\n",
      "      total_loss: 101.16851043701172\n",
      "      vf_explained_var: 0.9506193399429321\n",
      "      vf_loss: 101.0802001953125\n",
      "    sample_time_ms: 20020.544\n",
      "    update_time_ms: 7.431\n",
      "  iterations_since_restore: 836\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 68.68941759005547\n",
      "    rl_1: 48.635960046022326\n",
      "  time_since_restore: 19380.586361169815\n",
      "  time_this_iter_s: 23.05654525756836\n",
      "  time_total_s: 19380.586361169815\n",
      "  timestamp: 1550899999\n",
      "  timesteps_since_restore: 8360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8360000\n",
      "  training_iteration: 836\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19380 s, 836 iter, 8360000 ts, 117 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-33-42\n",
      "  done: false\n",
      "  episode_len_mean: 111.54\n",
      "  episode_reward_max: 229.53094668270936\n",
      "  episode_reward_mean: 162.20172298046236\n",
      "  episode_reward_min: -167.2239524932076\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 72552\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.796\n",
      "    load_time_ms: 2.263\n",
      "    num_steps_sampled: 8370000\n",
      "    num_steps_trained: 8370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6900712847709656\n",
      "      kl: 0.01702943444252014\n",
      "      policy_loss: 0.0022979138884693384\n",
      "      total_loss: 49.95270538330078\n",
      "      vf_explained_var: 0.9612289667129517\n",
      "      vf_loss: 49.95040512084961\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7507241368293762\n",
      "      kl: 0.015471193939447403\n",
      "      policy_loss: 0.0032437420450150967\n",
      "      total_loss: 42.55731201171875\n",
      "      vf_explained_var: 0.9586816430091858\n",
      "      vf_loss: 42.55406951904297\n",
      "    sample_time_ms: 20012.644\n",
      "    update_time_ms: 7.374\n",
      "  iterations_since_restore: 837\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.48151299782108\n",
      "    rl_1: 68.72020998264131\n",
      "  time_since_restore: 19403.67000746727\n",
      "  time_this_iter_s: 23.083646297454834\n",
      "  time_total_s: 19403.67000746727\n",
      "  timestamp: 1550900022\n",
      "  timesteps_since_restore: 8370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8370000\n",
      "  training_iteration: 837\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19403 s, 837 iter, 8370000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-34-04\n",
      "  done: false\n",
      "  episode_len_mean: 108.3\n",
      "  episode_reward_max: 234.55002097669382\n",
      "  episode_reward_mean: 160.86925110229055\n",
      "  episode_reward_min: -171.15178275599354\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 72644\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3066.677\n",
      "    load_time_ms: 2.212\n",
      "    num_steps_sampled: 8380000\n",
      "    num_steps_trained: 8380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7549083828926086\n",
      "      kl: 0.07788393646478653\n",
      "      policy_loss: 0.009379196912050247\n",
      "      total_loss: 74.43458557128906\n",
      "      vf_explained_var: 0.9530621767044067\n",
      "      vf_loss: 74.42520904541016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.825812816619873\n",
      "      kl: 0.034680936485528946\n",
      "      policy_loss: -0.0025268385652452707\n",
      "      total_loss: 67.85649871826172\n",
      "      vf_explained_var: 0.9504562020301819\n",
      "      vf_loss: 67.8590316772461\n",
      "    sample_time_ms: 19952.615\n",
      "    update_time_ms: 7.385\n",
      "  iterations_since_restore: 838\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.57367008700126\n",
      "    rl_1: 71.29558101528926\n",
      "  time_since_restore: 19426.16806125641\n",
      "  time_this_iter_s: 22.498053789138794\n",
      "  time_total_s: 19426.16806125641\n",
      "  timestamp: 1550900044\n",
      "  timesteps_since_restore: 8380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8380000\n",
      "  training_iteration: 838\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19426 s, 838 iter, 8380000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-34-27\n",
      "  done: false\n",
      "  episode_len_mean: 105.93\n",
      "  episode_reward_max: 233.0728295895819\n",
      "  episode_reward_mean: 130.835193272587\n",
      "  episode_reward_min: -172.98614791949723\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 72738\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.49\n",
      "    load_time_ms: 2.27\n",
      "    num_steps_sampled: 8390000\n",
      "    num_steps_trained: 8390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6887124180793762\n",
      "      kl: 0.024440882727503777\n",
      "      policy_loss: 0.004410142544656992\n",
      "      total_loss: 62.46866989135742\n",
      "      vf_explained_var: 0.9733912348747253\n",
      "      vf_loss: 62.46424865722656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7421835064888\n",
      "      kl: 0.053363025188446045\n",
      "      policy_loss: 0.006645931862294674\n",
      "      total_loss: 55.89523696899414\n",
      "      vf_explained_var: 0.9712256193161011\n",
      "      vf_loss: 55.88860321044922\n",
      "    sample_time_ms: 19954.819\n",
      "    update_time_ms: 7.312\n",
      "  iterations_since_restore: 839\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 75.70896111470609\n",
      "    rl_1: 55.12623215788086\n",
      "  time_since_restore: 19448.880380153656\n",
      "  time_this_iter_s: 22.712318897247314\n",
      "  time_total_s: 19448.880380153656\n",
      "  timestamp: 1550900067\n",
      "  timesteps_since_restore: 8390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8390000\n",
      "  training_iteration: 839\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19448 s, 839 iter, 8390000 ts, 131 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-34-50\n",
      "  done: false\n",
      "  episode_len_mean: 109.2\n",
      "  episode_reward_max: 240.3928134530083\n",
      "  episode_reward_mean: 164.87360064569097\n",
      "  episode_reward_min: -159.71785766223402\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 72826\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.209\n",
      "    load_time_ms: 2.292\n",
      "    num_steps_sampled: 8400000\n",
      "    num_steps_trained: 8400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6384711265563965\n",
      "      kl: 0.01820308528840542\n",
      "      policy_loss: 0.002532648155465722\n",
      "      total_loss: 33.26449966430664\n",
      "      vf_explained_var: 0.9683587551116943\n",
      "      vf_loss: 33.261966705322266\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7182072401046753\n",
      "      kl: 0.036081090569496155\n",
      "      policy_loss: 0.00945309828966856\n",
      "      total_loss: 31.491304397583008\n",
      "      vf_explained_var: 0.9681283235549927\n",
      "      vf_loss: 31.481849670410156\n",
      "    sample_time_ms: 19923.0\n",
      "    update_time_ms: 7.446\n",
      "  iterations_since_restore: 840\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.45839868537247\n",
      "    rl_1: 71.41520196031853\n",
      "  time_since_restore: 19472.04704475403\n",
      "  time_this_iter_s: 23.166664600372314\n",
      "  time_total_s: 19472.04704475403\n",
      "  timestamp: 1550900090\n",
      "  timesteps_since_restore: 8400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8400000\n",
      "  training_iteration: 840\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19472 s, 840 iter, 8400000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-35-13\n",
      "  done: false\n",
      "  episode_len_mean: 115.28\n",
      "  episode_reward_max: 235.1975606033235\n",
      "  episode_reward_mean: 152.72801979285725\n",
      "  episode_reward_min: -168.84008899826455\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 72914\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3065.448\n",
      "    load_time_ms: 2.341\n",
      "    num_steps_sampled: 8410000\n",
      "    num_steps_trained: 8410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.657232940196991\n",
      "      kl: 0.021305548027157784\n",
      "      policy_loss: 0.002740325406193733\n",
      "      total_loss: 36.61052703857422\n",
      "      vf_explained_var: 0.97786945104599\n",
      "      vf_loss: 36.6077880859375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8031800389289856\n",
      "      kl: 0.031182121485471725\n",
      "      policy_loss: 0.006767016835510731\n",
      "      total_loss: 28.574031829833984\n",
      "      vf_explained_var: 0.9779353737831116\n",
      "      vf_loss: 28.567264556884766\n",
      "    sample_time_ms: 19904.758\n",
      "    update_time_ms: 7.744\n",
      "  iterations_since_restore: 841\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.13373906225291\n",
      "    rl_1: 63.59428073060437\n",
      "  time_since_restore: 19494.77057504654\n",
      "  time_this_iter_s: 22.723530292510986\n",
      "  time_total_s: 19494.77057504654\n",
      "  timestamp: 1550900113\n",
      "  timesteps_since_restore: 8410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8410000\n",
      "  training_iteration: 841\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19494 s, 841 iter, 8410000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-35-36\n",
      "  done: false\n",
      "  episode_len_mean: 110.59\n",
      "  episode_reward_max: 235.1975606033235\n",
      "  episode_reward_mean: 162.4019453048936\n",
      "  episode_reward_min: -165.8813046518302\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 73005\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.411\n",
      "    load_time_ms: 2.382\n",
      "    num_steps_sampled: 8420000\n",
      "    num_steps_trained: 8420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7591055035591125\n",
      "      kl: 9.95261287689209\n",
      "      policy_loss: 0.15456582605838776\n",
      "      total_loss: 40.55088806152344\n",
      "      vf_explained_var: 0.9728764295578003\n",
      "      vf_loss: 40.39632034301758\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8713645935058594\n",
      "      kl: 0.05151873826980591\n",
      "      policy_loss: 0.006859690882265568\n",
      "      total_loss: 33.15443801879883\n",
      "      vf_explained_var: 0.9752909541130066\n",
      "      vf_loss: 33.14757537841797\n",
      "    sample_time_ms: 19838.071\n",
      "    update_time_ms: 7.556\n",
      "  iterations_since_restore: 842\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.95622291760915\n",
      "    rl_1: 71.44572238728445\n",
      "  time_since_restore: 19517.21545290947\n",
      "  time_this_iter_s: 22.444877862930298\n",
      "  time_total_s: 19517.21545290947\n",
      "  timestamp: 1550900136\n",
      "  timesteps_since_restore: 8420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8420000\n",
      "  training_iteration: 842\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19517 s, 842 iter, 8420000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-35-59\n",
      "  done: false\n",
      "  episode_len_mean: 108.76\n",
      "  episode_reward_max: 231.09729560849212\n",
      "  episode_reward_mean: 155.71683137866464\n",
      "  episode_reward_min: -170.85529720564696\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 73096\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3046.219\n",
      "    load_time_ms: 2.374\n",
      "    num_steps_sampled: 8430000\n",
      "    num_steps_trained: 8430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7537082433700562\n",
      "      kl: 0.037734758108854294\n",
      "      policy_loss: 0.0037672098260372877\n",
      "      total_loss: 61.365291595458984\n",
      "      vf_explained_var: 0.9537767171859741\n",
      "      vf_loss: 61.36152267456055\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8392581343650818\n",
      "      kl: 0.05365142598748207\n",
      "      policy_loss: 0.009535371325910091\n",
      "      total_loss: 49.39720153808594\n",
      "      vf_explained_var: 0.9569057822227478\n",
      "      vf_loss: 49.387664794921875\n",
      "    sample_time_ms: 19808.712\n",
      "    update_time_ms: 7.327\n",
      "  iterations_since_restore: 843\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.29228511323137\n",
      "    rl_1: 66.42454626543329\n",
      "  time_since_restore: 19540.368118286133\n",
      "  time_this_iter_s: 23.152665376663208\n",
      "  time_total_s: 19540.368118286133\n",
      "  timestamp: 1550900159\n",
      "  timesteps_since_restore: 8430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8430000\n",
      "  training_iteration: 843\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19540 s, 843 iter, 8430000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-36-22\n",
      "  done: false\n",
      "  episode_len_mean: 112.35\n",
      "  episode_reward_max: 236.3427892517403\n",
      "  episode_reward_mean: 159.1210396002528\n",
      "  episode_reward_min: -168.92616003897993\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 73185\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3046.506\n",
      "    load_time_ms: 2.451\n",
      "    num_steps_sampled: 8440000\n",
      "    num_steps_trained: 8440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7341612577438354\n",
      "      kl: 0.01764560304582119\n",
      "      policy_loss: 0.0023934985511004925\n",
      "      total_loss: 33.13600158691406\n",
      "      vf_explained_var: 0.9760217666625977\n",
      "      vf_loss: 33.133609771728516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8214942812919617\n",
      "      kl: 0.02629476599395275\n",
      "      policy_loss: 0.003149667289108038\n",
      "      total_loss: 25.99567985534668\n",
      "      vf_explained_var: 0.9782371520996094\n",
      "      vf_loss: 25.992530822753906\n",
      "    sample_time_ms: 19817.266\n",
      "    update_time_ms: 7.386\n",
      "  iterations_since_restore: 844\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.87203471653719\n",
      "    rl_1: 67.2490048837156\n",
      "  time_since_restore: 19563.565940856934\n",
      "  time_this_iter_s: 23.19782257080078\n",
      "  time_total_s: 19563.565940856934\n",
      "  timestamp: 1550900182\n",
      "  timesteps_since_restore: 8440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8440000\n",
      "  training_iteration: 844\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19563 s, 844 iter, 8440000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-36-45\n",
      "  done: false\n",
      "  episode_len_mean: 109.22\n",
      "  episode_reward_max: 226.99682605688562\n",
      "  episode_reward_mean: 164.40606965246207\n",
      "  episode_reward_min: -141.89118842447925\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 73277\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3046.834\n",
      "    load_time_ms: 2.517\n",
      "    num_steps_sampled: 8450000\n",
      "    num_steps_trained: 8450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7294890284538269\n",
      "      kl: 2.791905164718628\n",
      "      policy_loss: 0.050956323742866516\n",
      "      total_loss: 52.614131927490234\n",
      "      vf_explained_var: 0.9632261395454407\n",
      "      vf_loss: 52.56318283081055\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7465918660163879\n",
      "      kl: 0.02198212407529354\n",
      "      policy_loss: 0.0026591892819851637\n",
      "      total_loss: 47.32657241821289\n",
      "      vf_explained_var: 0.9622305631637573\n",
      "      vf_loss: 47.32391357421875\n",
      "    sample_time_ms: 19858.27\n",
      "    update_time_ms: 7.655\n",
      "  iterations_since_restore: 845\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.10266720854814\n",
      "    rl_1: 71.30340244391392\n",
      "  time_since_restore: 19586.862150669098\n",
      "  time_this_iter_s: 23.296209812164307\n",
      "  time_total_s: 19586.862150669098\n",
      "  timestamp: 1550900205\n",
      "  timesteps_since_restore: 8450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8450000\n",
      "  training_iteration: 845\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19586 s, 845 iter, 8450000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-37-09\n",
      "  done: false\n",
      "  episode_len_mean: 110.16\n",
      "  episode_reward_max: 233.66720495881515\n",
      "  episode_reward_mean: 156.44037210280396\n",
      "  episode_reward_min: -159.8326074055005\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 73368\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3064.932\n",
      "    load_time_ms: 2.557\n",
      "    num_steps_sampled: 8460000\n",
      "    num_steps_trained: 8460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6365548372268677\n",
      "      kl: 0.035266924649477005\n",
      "      policy_loss: 0.014294726774096489\n",
      "      total_loss: 40.81759262084961\n",
      "      vf_explained_var: 0.9750043153762817\n",
      "      vf_loss: 40.80329895019531\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7317789793014526\n",
      "      kl: 0.06587713211774826\n",
      "      policy_loss: 0.019735796377062798\n",
      "      total_loss: 32.05989456176758\n",
      "      vf_explained_var: 0.9779165983200073\n",
      "      vf_loss: 32.040164947509766\n",
      "    sample_time_ms: 19849.892\n",
      "    update_time_ms: 7.489\n",
      "  iterations_since_restore: 846\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.70214484225198\n",
      "    rl_1: 66.73822726055201\n",
      "  time_since_restore: 19610.01478123665\n",
      "  time_this_iter_s: 23.15263056755066\n",
      "  time_total_s: 19610.01478123665\n",
      "  timestamp: 1550900229\n",
      "  timesteps_since_restore: 8460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8460000\n",
      "  training_iteration: 846\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19610 s, 846 iter, 8460000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-37-32\n",
      "  done: false\n",
      "  episode_len_mean: 108.78\n",
      "  episode_reward_max: 229.60926693557224\n",
      "  episode_reward_mean: 148.10169096988093\n",
      "  episode_reward_min: -163.60415862771288\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 73458\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3063.187\n",
      "    load_time_ms: 2.624\n",
      "    num_steps_sampled: 8470000\n",
      "    num_steps_trained: 8470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6729567050933838\n",
      "      kl: 0.019629649817943573\n",
      "      policy_loss: 0.0035687291529029608\n",
      "      total_loss: 40.73458480834961\n",
      "      vf_explained_var: 0.9723318815231323\n",
      "      vf_loss: 40.73101806640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7900453209877014\n",
      "      kl: 0.12194766849279404\n",
      "      policy_loss: 0.019951270893216133\n",
      "      total_loss: 29.212886810302734\n",
      "      vf_explained_var: 0.974949061870575\n",
      "      vf_loss: 29.192935943603516\n",
      "    sample_time_ms: 19868.881\n",
      "    update_time_ms: 7.689\n",
      "  iterations_since_restore: 847\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.25115223537128\n",
      "    rl_1: 61.85053873450966\n",
      "  time_since_restore: 19633.27117395401\n",
      "  time_this_iter_s: 23.25639271736145\n",
      "  time_total_s: 19633.27117395401\n",
      "  timestamp: 1550900252\n",
      "  timesteps_since_restore: 8470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8470000\n",
      "  training_iteration: 847\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19633 s, 847 iter, 8470000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-37-55\n",
      "  done: false\n",
      "  episode_len_mean: 108.15\n",
      "  episode_reward_max: 227.46295566873926\n",
      "  episode_reward_mean: 163.61956872051695\n",
      "  episode_reward_min: -161.56781442752015\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 73551\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.493\n",
      "    load_time_ms: 2.696\n",
      "    num_steps_sampled: 8480000\n",
      "    num_steps_trained: 8480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7234437465667725\n",
      "      kl: 0.02724161557853222\n",
      "      policy_loss: 0.006125741172581911\n",
      "      total_loss: 41.582027435302734\n",
      "      vf_explained_var: 0.969032883644104\n",
      "      vf_loss: 41.57590103149414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7937471270561218\n",
      "      kl: 0.04324327036738396\n",
      "      policy_loss: 0.009336360730230808\n",
      "      total_loss: 31.165740966796875\n",
      "      vf_explained_var: 0.9711663722991943\n",
      "      vf_loss: 31.156402587890625\n",
      "    sample_time_ms: 19930.483\n",
      "    update_time_ms: 7.505\n",
      "  iterations_since_restore: 848\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.133360449541\n",
      "    rl_1: 70.486208270976\n",
      "  time_since_restore: 19656.438010454178\n",
      "  time_this_iter_s: 23.166836500167847\n",
      "  time_total_s: 19656.438010454178\n",
      "  timestamp: 1550900275\n",
      "  timesteps_since_restore: 8480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8480000\n",
      "  training_iteration: 848\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19656 s, 848 iter, 8480000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-38-18\n",
      "  done: false\n",
      "  episode_len_mean: 109.99\n",
      "  episode_reward_max: 227.1226928161043\n",
      "  episode_reward_mean: 157.78676164787194\n",
      "  episode_reward_min: -168.8158430721091\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 73643\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.137\n",
      "    load_time_ms: 2.637\n",
      "    num_steps_sampled: 8490000\n",
      "    num_steps_trained: 8490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7139289975166321\n",
      "      kl: 0.02599518746137619\n",
      "      policy_loss: 0.005103950388729572\n",
      "      total_loss: 79.82395935058594\n",
      "      vf_explained_var: 0.946945309638977\n",
      "      vf_loss: 79.81885528564453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7856197357177734\n",
      "      kl: 0.048387132585048676\n",
      "      policy_loss: 0.0063068498857319355\n",
      "      total_loss: 67.3548583984375\n",
      "      vf_explained_var: 0.9451839923858643\n",
      "      vf_loss: 67.34854888916016\n",
      "    sample_time_ms: 19973.717\n",
      "    update_time_ms: 7.508\n",
      "  iterations_since_restore: 849\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.93342180839446\n",
      "    rl_1: 66.85333983947747\n",
      "  time_since_restore: 19679.618775367737\n",
      "  time_this_iter_s: 23.18076491355896\n",
      "  time_total_s: 19679.618775367737\n",
      "  timestamp: 1550900298\n",
      "  timesteps_since_restore: 8490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8490000\n",
      "  training_iteration: 849\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19679 s, 849 iter, 8490000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-38-41\n",
      "  done: false\n",
      "  episode_len_mean: 107.22\n",
      "  episode_reward_max: 221.8607879822298\n",
      "  episode_reward_mean: 165.20995970779222\n",
      "  episode_reward_min: -169.74122903523426\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 73736\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.18\n",
      "    load_time_ms: 2.618\n",
      "    num_steps_sampled: 8500000\n",
      "    num_steps_trained: 8500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8054736852645874\n",
      "      kl: 0.031455423682928085\n",
      "      policy_loss: 0.004274454899132252\n",
      "      total_loss: 34.979217529296875\n",
      "      vf_explained_var: 0.9751675128936768\n",
      "      vf_loss: 34.974937438964844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8164867162704468\n",
      "      kl: 0.041814181953668594\n",
      "      policy_loss: 0.0016056009335443377\n",
      "      total_loss: 27.297529220581055\n",
      "      vf_explained_var: 0.9752157926559448\n",
      "      vf_loss: 27.295927047729492\n",
      "    sample_time_ms: 19952.367\n",
      "    update_time_ms: 7.621\n",
      "  iterations_since_restore: 850\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.53560670430527\n",
      "    rl_1: 70.67435300348694\n",
      "  time_since_restore: 19702.572885274887\n",
      "  time_this_iter_s: 22.95410990715027\n",
      "  time_total_s: 19702.572885274887\n",
      "  timestamp: 1550900321\n",
      "  timesteps_since_restore: 8500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8500000\n",
      "  training_iteration: 850\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19702 s, 850 iter, 8500000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-39-04\n",
      "  done: false\n",
      "  episode_len_mean: 105.88\n",
      "  episode_reward_max: 231.5134285441515\n",
      "  episode_reward_mean: 144.4862619564204\n",
      "  episode_reward_min: -176.428983632396\n",
      "  episodes_this_iter: 95\n",
      "  episodes_total: 73831\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.848\n",
      "    load_time_ms: 2.522\n",
      "    num_steps_sampled: 8510000\n",
      "    num_steps_trained: 8510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6913919448852539\n",
      "      kl: 66.11271667480469\n",
      "      policy_loss: 0.09740550816059113\n",
      "      total_loss: 53.08332824707031\n",
      "      vf_explained_var: 0.9744537472724915\n",
      "      vf_loss: 52.98591995239258\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7687662839889526\n",
      "      kl: 2.3295371532440186\n",
      "      policy_loss: 0.02473345957696438\n",
      "      total_loss: 39.91721725463867\n",
      "      vf_explained_var: 0.9768174290657043\n",
      "      vf_loss: 39.89248275756836\n",
      "    sample_time_ms: 19985.475\n",
      "    update_time_ms: 7.381\n",
      "  iterations_since_restore: 851\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.49185363233246\n",
      "    rl_1: 60.994408324087956\n",
      "  time_since_restore: 19725.6290974617\n",
      "  time_this_iter_s: 23.056212186813354\n",
      "  time_total_s: 19725.6290974617\n",
      "  timestamp: 1550900344\n",
      "  timesteps_since_restore: 8510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8510000\n",
      "  training_iteration: 851\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19725 s, 851 iter, 8510000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-39-28\n",
      "  done: false\n",
      "  episode_len_mean: 109.87\n",
      "  episode_reward_max: 229.88442847176552\n",
      "  episode_reward_mean: 138.0421793787649\n",
      "  episode_reward_min: -169.37523579307265\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 73921\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.139\n",
      "    load_time_ms: 2.501\n",
      "    num_steps_sampled: 8520000\n",
      "    num_steps_trained: 8520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6482601761817932\n",
      "      kl: 0.014966700226068497\n",
      "      policy_loss: 0.0007777924765832722\n",
      "      total_loss: 118.19818878173828\n",
      "      vf_explained_var: 0.9472017288208008\n",
      "      vf_loss: 118.19744110107422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7590607404708862\n",
      "      kl: 6.2120561599731445\n",
      "      policy_loss: 0.06387602537870407\n",
      "      total_loss: 108.3609390258789\n",
      "      vf_explained_var: 0.9347162246704102\n",
      "      vf_loss: 108.29706573486328\n",
      "    sample_time_ms: 20047.875\n",
      "    update_time_ms: 7.408\n",
      "  iterations_since_restore: 852\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 78.74785981912488\n",
      "    rl_1: 59.29431955963997\n",
      "  time_since_restore: 19748.680747270584\n",
      "  time_this_iter_s: 23.051649808883667\n",
      "  time_total_s: 19748.680747270584\n",
      "  timestamp: 1550900368\n",
      "  timesteps_since_restore: 8520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8520000\n",
      "  training_iteration: 852\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19748 s, 852 iter, 8520000 ts, 138 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-39-51\n",
      "  done: false\n",
      "  episode_len_mean: 113.45\n",
      "  episode_reward_max: 233.3128698383344\n",
      "  episode_reward_mean: 157.67137403184736\n",
      "  episode_reward_min: -169.0464715532695\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 74008\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.808\n",
      "    load_time_ms: 2.581\n",
      "    num_steps_sampled: 8530000\n",
      "    num_steps_trained: 8530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.697027325630188\n",
      "      kl: 0.024285029619932175\n",
      "      policy_loss: 0.005016074050217867\n",
      "      total_loss: 30.97525978088379\n",
      "      vf_explained_var: 0.9764807224273682\n",
      "      vf_loss: 30.97023582458496\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7909601926803589\n",
      "      kl: 0.03343081846833229\n",
      "      policy_loss: 0.003982341382652521\n",
      "      total_loss: 24.03091049194336\n",
      "      vf_explained_var: 0.9759966731071472\n",
      "      vf_loss: 24.02692413330078\n",
      "    sample_time_ms: 20050.157\n",
      "    update_time_ms: 7.239\n",
      "  iterations_since_restore: 853\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.95012474051988\n",
      "    rl_1: 67.72124929132747\n",
      "  time_since_restore: 19771.832669973373\n",
      "  time_this_iter_s: 23.151922702789307\n",
      "  time_total_s: 19771.832669973373\n",
      "  timestamp: 1550900391\n",
      "  timesteps_since_restore: 8530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8530000\n",
      "  training_iteration: 853\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19771 s, 853 iter, 8530000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-40-14\n",
      "  done: false\n",
      "  episode_len_mean: 118.74\n",
      "  episode_reward_max: 236.75594508223688\n",
      "  episode_reward_mean: 171.9244691977941\n",
      "  episode_reward_min: -120.99842976831576\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 74092\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.169\n",
      "    load_time_ms: 2.515\n",
      "    num_steps_sampled: 8540000\n",
      "    num_steps_trained: 8540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6010518074035645\n",
      "      kl: 0.027472935616970062\n",
      "      policy_loss: 0.004629535600543022\n",
      "      total_loss: 37.893882751464844\n",
      "      vf_explained_var: 0.9610070586204529\n",
      "      vf_loss: 37.88924789428711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6886993050575256\n",
      "      kl: 0.020324038341641426\n",
      "      policy_loss: -0.000853600911796093\n",
      "      total_loss: 34.9477653503418\n",
      "      vf_explained_var: 0.9551523923873901\n",
      "      vf_loss: 34.94862365722656\n",
      "    sample_time_ms: 20005.137\n",
      "    update_time_ms: 7.448\n",
      "  iterations_since_restore: 854\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.03487796874373\n",
      "    rl_1: 73.88959122905042\n",
      "  time_since_restore: 19794.674060583115\n",
      "  time_this_iter_s: 22.84139060974121\n",
      "  time_total_s: 19794.674060583115\n",
      "  timestamp: 1550900414\n",
      "  timesteps_since_restore: 8540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8540000\n",
      "  training_iteration: 854\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19794 s, 854 iter, 8540000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-40-36\n",
      "  done: false\n",
      "  episode_len_mean: 112.86\n",
      "  episode_reward_max: 224.2190066399166\n",
      "  episode_reward_mean: 143.77148616923313\n",
      "  episode_reward_min: -167.41166453456606\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 74181\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.747\n",
      "    load_time_ms: 2.455\n",
      "    num_steps_sampled: 8550000\n",
      "    num_steps_trained: 8550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6864653825759888\n",
      "      kl: 0.026791797950863838\n",
      "      policy_loss: 0.004233032930642366\n",
      "      total_loss: 91.49580383300781\n",
      "      vf_explained_var: 0.9537112712860107\n",
      "      vf_loss: 91.49156188964844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7562718391418457\n",
      "      kl: 0.04145902022719383\n",
      "      policy_loss: 0.00536308204755187\n",
      "      total_loss: 84.68702697753906\n",
      "      vf_explained_var: 0.945961594581604\n",
      "      vf_loss: 84.68167114257812\n",
      "    sample_time_ms: 19946.533\n",
      "    update_time_ms: 6.981\n",
      "  iterations_since_restore: 855\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.73109522487601\n",
      "    rl_1: 61.040390944357135\n",
      "  time_since_restore: 19817.416117191315\n",
      "  time_this_iter_s: 22.742056608200073\n",
      "  time_total_s: 19817.416117191315\n",
      "  timestamp: 1550900436\n",
      "  timesteps_since_restore: 8550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8550000\n",
      "  training_iteration: 855\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19817 s, 855 iter, 8550000 ts, 144 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-41-00\n",
      "  done: false\n",
      "  episode_len_mean: 110.78\n",
      "  episode_reward_max: 235.28977732192783\n",
      "  episode_reward_mean: 138.99356880482375\n",
      "  episode_reward_min: -165.30114799765423\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 74272\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.718\n",
      "    load_time_ms: 2.405\n",
      "    num_steps_sampled: 8560000\n",
      "    num_steps_trained: 8560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6853306889533997\n",
      "      kl: 0.020681966096162796\n",
      "      policy_loss: 0.0033523053862154484\n",
      "      total_loss: 68.774169921875\n",
      "      vf_explained_var: 0.9656996130943298\n",
      "      vf_loss: 68.77082061767578\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7074000239372253\n",
      "      kl: 0.03435449302196503\n",
      "      policy_loss: 0.0028972476720809937\n",
      "      total_loss: 60.562461853027344\n",
      "      vf_explained_var: 0.9633654952049255\n",
      "      vf_loss: 60.5595703125\n",
      "    sample_time_ms: 19963.512\n",
      "    update_time_ms: 7.084\n",
      "  iterations_since_restore: 856\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 80.54705396571174\n",
      "    rl_1: 58.446514839112\n",
      "  time_since_restore: 19840.619386434555\n",
      "  time_this_iter_s: 23.203269243240356\n",
      "  time_total_s: 19840.619386434555\n",
      "  timestamp: 1550900460\n",
      "  timesteps_since_restore: 8560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8560000\n",
      "  training_iteration: 856\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19840 s, 856 iter, 8560000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-41-22\n",
      "  done: false\n",
      "  episode_len_mean: 116.18\n",
      "  episode_reward_max: 227.28965962347064\n",
      "  episode_reward_mean: 146.6663269121197\n",
      "  episode_reward_min: -176.78114800506512\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 74358\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.884\n",
      "    load_time_ms: 2.35\n",
      "    num_steps_sampled: 8570000\n",
      "    num_steps_trained: 8570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6914820671081543\n",
      "      kl: 0.02791210077702999\n",
      "      policy_loss: 0.006406113039702177\n",
      "      total_loss: 63.84307861328125\n",
      "      vf_explained_var: 0.9630158543586731\n",
      "      vf_loss: 63.83666229248047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7705532908439636\n",
      "      kl: 0.04121411219239235\n",
      "      policy_loss: 0.007157272193580866\n",
      "      total_loss: 55.69307327270508\n",
      "      vf_explained_var: 0.959567129611969\n",
      "      vf_loss: 55.685909271240234\n",
      "    sample_time_ms: 19902.02\n",
      "    update_time_ms: 6.876\n",
      "  iterations_since_restore: 857\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.09632281875294\n",
      "    rl_1: 61.570004093366734\n",
      "  time_since_restore: 19863.249771356583\n",
      "  time_this_iter_s: 22.630384922027588\n",
      "  time_total_s: 19863.249771356583\n",
      "  timestamp: 1550900482\n",
      "  timesteps_since_restore: 8570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8570000\n",
      "  training_iteration: 857\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19863 s, 857 iter, 8570000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-41-45\n",
      "  done: false\n",
      "  episode_len_mean: 119.31\n",
      "  episode_reward_max: 222.25682675436752\n",
      "  episode_reward_mean: 164.83667431313697\n",
      "  episode_reward_min: -176.78114800506512\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 74439\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.305\n",
      "    load_time_ms: 2.283\n",
      "    num_steps_sampled: 8580000\n",
      "    num_steps_trained: 8580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5585067272186279\n",
      "      kl: 10.91604995727539\n",
      "      policy_loss: 0.1442318707704544\n",
      "      total_loss: 20.8023624420166\n",
      "      vf_explained_var: 0.977916419506073\n",
      "      vf_loss: 20.65812873840332\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6831831932067871\n",
      "      kl: 0.026791993528604507\n",
      "      policy_loss: 0.006422767415642738\n",
      "      total_loss: 17.09238624572754\n",
      "      vf_explained_var: 0.9782350063323975\n",
      "      vf_loss: 17.085966110229492\n",
      "    sample_time_ms: 19874.373\n",
      "    update_time_ms: 7.048\n",
      "  iterations_since_restore: 858\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.05739125215788\n",
      "    rl_1: 69.7792830609791\n",
      "  time_since_restore: 19886.132841825485\n",
      "  time_this_iter_s: 22.883070468902588\n",
      "  time_total_s: 19886.132841825485\n",
      "  timestamp: 1550900505\n",
      "  timesteps_since_restore: 8580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8580000\n",
      "  training_iteration: 858\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19886 s, 858 iter, 8580000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-42-09\n",
      "  done: false\n",
      "  episode_len_mean: 114.35\n",
      "  episode_reward_max: 222.9764454969633\n",
      "  episode_reward_mean: 146.88641937131035\n",
      "  episode_reward_min: -164.62937619416948\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 74528\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.005\n",
      "    load_time_ms: 2.337\n",
      "    num_steps_sampled: 8590000\n",
      "    num_steps_trained: 8590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6648915410041809\n",
      "      kl: 0.028579825535416603\n",
      "      policy_loss: 0.003047181526198983\n",
      "      total_loss: 78.04598999023438\n",
      "      vf_explained_var: 0.9580588936805725\n",
      "      vf_loss: 78.04293823242188\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6856802701950073\n",
      "      kl: 0.1181076243519783\n",
      "      policy_loss: 0.016677571460604668\n",
      "      total_loss: 65.61058044433594\n",
      "      vf_explained_var: 0.9566383361816406\n",
      "      vf_loss: 65.5938949584961\n",
      "    sample_time_ms: 19883.261\n",
      "    update_time_ms: 7.008\n",
      "  iterations_since_restore: 859\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.91969851287072\n",
      "    rl_1: 59.96672085843965\n",
      "  time_since_restore: 19909.580330371857\n",
      "  time_this_iter_s: 23.44748854637146\n",
      "  time_total_s: 19909.580330371857\n",
      "  timestamp: 1550900529\n",
      "  timesteps_since_restore: 8590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8590000\n",
      "  training_iteration: 859\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19909 s, 859 iter, 8590000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-42-32\n",
      "  done: false\n",
      "  episode_len_mean: 112.15\n",
      "  episode_reward_max: 226.5392933839428\n",
      "  episode_reward_mean: 147.57837915548967\n",
      "  episode_reward_min: -175.8136577130712\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 74617\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.592\n",
      "    load_time_ms: 2.337\n",
      "    num_steps_sampled: 8600000\n",
      "    num_steps_trained: 8600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6276543736457825\n",
      "      kl: 0.3054029643535614\n",
      "      policy_loss: 0.00708939041942358\n",
      "      total_loss: 55.11878204345703\n",
      "      vf_explained_var: 0.9689485430717468\n",
      "      vf_loss: 55.111698150634766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6625197529792786\n",
      "      kl: 0.07431554049253464\n",
      "      policy_loss: 0.01957285776734352\n",
      "      total_loss: 49.46516799926758\n",
      "      vf_explained_var: 0.9662721157073975\n",
      "      vf_loss: 49.445587158203125\n",
      "    sample_time_ms: 19862.007\n",
      "    update_time_ms: 6.856\n",
      "  iterations_since_restore: 860\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.47528323635918\n",
      "    rl_1: 62.10309591913052\n",
      "  time_since_restore: 19932.317873716354\n",
      "  time_this_iter_s: 22.73754334449768\n",
      "  time_total_s: 19932.317873716354\n",
      "  timestamp: 1550900552\n",
      "  timesteps_since_restore: 8600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8600000\n",
      "  training_iteration: 860\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19932 s, 860 iter, 8600000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-42-55\n",
      "  done: false\n",
      "  episode_len_mean: 112.1\n",
      "  episode_reward_max: 227.70248129362125\n",
      "  episode_reward_mean: 159.25922104304576\n",
      "  episode_reward_min: -149.28904769063143\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 74705\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.839\n",
      "    load_time_ms: 2.312\n",
      "    num_steps_sampled: 8610000\n",
      "    num_steps_trained: 8610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6541142463684082\n",
      "      kl: 0.014343426562845707\n",
      "      policy_loss: 0.00016445743676740676\n",
      "      total_loss: 31.12375831604004\n",
      "      vf_explained_var: 0.978611409664154\n",
      "      vf_loss: 31.123584747314453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.628311812877655\n",
      "      kl: 0.020142344757914543\n",
      "      policy_loss: 0.0021047289483249187\n",
      "      total_loss: 26.716014862060547\n",
      "      vf_explained_var: 0.9762362837791443\n",
      "      vf_loss: 26.71390724182129\n",
      "    sample_time_ms: 19885.422\n",
      "    update_time_ms: 6.85\n",
      "  iterations_since_restore: 861\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.02267147401017\n",
      "    rl_1: 67.23654956903557\n",
      "  time_since_restore: 19955.610246896744\n",
      "  time_this_iter_s: 23.292373180389404\n",
      "  time_total_s: 19955.610246896744\n",
      "  timestamp: 1550900575\n",
      "  timesteps_since_restore: 8610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8610000\n",
      "  training_iteration: 861\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19955 s, 861 iter, 8610000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-43-18\n",
      "  done: false\n",
      "  episode_len_mean: 114.14\n",
      "  episode_reward_max: 229.8001516046733\n",
      "  episode_reward_mean: 154.68862378327535\n",
      "  episode_reward_min: -176.5794894448267\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 74793\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.884\n",
      "    load_time_ms: 2.213\n",
      "    num_steps_sampled: 8620000\n",
      "    num_steps_trained: 8620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6501542329788208\n",
      "      kl: 0.021652787923812866\n",
      "      policy_loss: 0.0016873425338417292\n",
      "      total_loss: 41.717018127441406\n",
      "      vf_explained_var: 0.9775083661079407\n",
      "      vf_loss: 41.715335845947266\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6792470216751099\n",
      "      kl: 0.024282123893499374\n",
      "      policy_loss: 0.0003488644433673471\n",
      "      total_loss: 35.53254318237305\n",
      "      vf_explained_var: 0.9778489470481873\n",
      "      vf_loss: 35.53219985961914\n",
      "    sample_time_ms: 19871.182\n",
      "    update_time_ms: 6.851\n",
      "  iterations_since_restore: 862\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.21470566166046\n",
      "    rl_1: 65.47391812161489\n",
      "  time_since_restore: 19978.555998563766\n",
      "  time_this_iter_s: 22.945751667022705\n",
      "  time_total_s: 19978.555998563766\n",
      "  timestamp: 1550900598\n",
      "  timesteps_since_restore: 8620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8620000\n",
      "  training_iteration: 862\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 19978 s, 862 iter, 8620000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-43-41\n",
      "  done: false\n",
      "  episode_len_mean: 116.12\n",
      "  episode_reward_max: 223.9998446945563\n",
      "  episode_reward_mean: 150.3976319520373\n",
      "  episode_reward_min: -161.9642570214834\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 74877\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.795\n",
      "    load_time_ms: 2.193\n",
      "    num_steps_sampled: 8630000\n",
      "    num_steps_trained: 8630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5488669872283936\n",
      "      kl: 0.02710304781794548\n",
      "      policy_loss: 0.0009250339935533702\n",
      "      total_loss: 46.53218460083008\n",
      "      vf_explained_var: 0.9719836115837097\n",
      "      vf_loss: 46.53125762939453\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6389675140380859\n",
      "      kl: 0.022526893764734268\n",
      "      policy_loss: 0.00039858336094766855\n",
      "      total_loss: 26.189851760864258\n",
      "      vf_explained_var: 0.9804604649543762\n",
      "      vf_loss: 26.189453125\n",
      "    sample_time_ms: 19833.716\n",
      "    update_time_ms: 7.0\n",
      "  iterations_since_restore: 863\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.03847308572668\n",
      "    rl_1: 61.359158866310615\n",
      "  time_since_restore: 20001.32494187355\n",
      "  time_this_iter_s: 22.768943309783936\n",
      "  time_total_s: 20001.32494187355\n",
      "  timestamp: 1550900621\n",
      "  timesteps_since_restore: 8630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8630000\n",
      "  training_iteration: 863\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20001 s, 863 iter, 8630000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-44-04\n",
      "  done: false\n",
      "  episode_len_mean: 114.55\n",
      "  episode_reward_max: 223.39163101138107\n",
      "  episode_reward_mean: 168.79551482890955\n",
      "  episode_reward_min: -166.8185892434879\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 74965\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.008\n",
      "    load_time_ms: 2.259\n",
      "    num_steps_sampled: 8640000\n",
      "    num_steps_trained: 8640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6339409351348877\n",
      "      kl: 0.02370908483862877\n",
      "      policy_loss: 0.003869990585371852\n",
      "      total_loss: 39.25172424316406\n",
      "      vf_explained_var: 0.9655454754829407\n",
      "      vf_loss: 39.24785232543945\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6432401537895203\n",
      "      kl: 0.027365773916244507\n",
      "      policy_loss: -0.0002435708447592333\n",
      "      total_loss: 28.768802642822266\n",
      "      vf_explained_var: 0.9728032350540161\n",
      "      vf_loss: 28.7690486907959\n",
      "    sample_time_ms: 19874.847\n",
      "    update_time_ms: 6.783\n",
      "  iterations_since_restore: 864\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.70275101979394\n",
      "    rl_1: 73.09276380911561\n",
      "  time_since_restore: 20024.450642824173\n",
      "  time_this_iter_s: 23.12570095062256\n",
      "  time_total_s: 20024.450642824173\n",
      "  timestamp: 1550900644\n",
      "  timesteps_since_restore: 8640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8640000\n",
      "  training_iteration: 864\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20024 s, 864 iter, 8640000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-44-27\n",
      "  done: false\n",
      "  episode_len_mean: 111.66\n",
      "  episode_reward_max: 227.2063563166683\n",
      "  episode_reward_mean: 156.20239784157576\n",
      "  episode_reward_min: -168.7024212185807\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 75056\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.495\n",
      "    load_time_ms: 2.247\n",
      "    num_steps_sampled: 8650000\n",
      "    num_steps_trained: 8650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.693490207195282\n",
      "      kl: 0.029323067516088486\n",
      "      policy_loss: 0.006084212101995945\n",
      "      total_loss: 43.425567626953125\n",
      "      vf_explained_var: 0.9746972918510437\n",
      "      vf_loss: 43.41949462890625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.731473982334137\n",
      "      kl: 0.03907223418354988\n",
      "      policy_loss: 0.010231340304017067\n",
      "      total_loss: 35.161888122558594\n",
      "      vf_explained_var: 0.9762315154075623\n",
      "      vf_loss: 35.15165710449219\n",
      "    sample_time_ms: 19930.133\n",
      "    update_time_ms: 6.879\n",
      "  iterations_since_restore: 865\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.78241600497897\n",
      "    rl_1: 67.4199818365968\n",
      "  time_since_restore: 20047.739431381226\n",
      "  time_this_iter_s: 23.288788557052612\n",
      "  time_total_s: 20047.739431381226\n",
      "  timestamp: 1550900667\n",
      "  timesteps_since_restore: 8650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8650000\n",
      "  training_iteration: 865\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20047 s, 865 iter, 8650000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-44-50\n",
      "  done: false\n",
      "  episode_len_mean: 112.59\n",
      "  episode_reward_max: 231.21108640890625\n",
      "  episode_reward_mean: 171.97825032259735\n",
      "  episode_reward_min: -160.82767826312926\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 75145\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.01\n",
      "    load_time_ms: 2.225\n",
      "    num_steps_sampled: 8660000\n",
      "    num_steps_trained: 8660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7356855869293213\n",
      "      kl: 0.027851125225424767\n",
      "      policy_loss: 0.002719879848882556\n",
      "      total_loss: 25.590192794799805\n",
      "      vf_explained_var: 0.9784486293792725\n",
      "      vf_loss: 25.58747673034668\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.788741409778595\n",
      "      kl: 0.03309747204184532\n",
      "      policy_loss: 0.00010850576654775068\n",
      "      total_loss: 17.779178619384766\n",
      "      vf_explained_var: 0.9814762473106384\n",
      "      vf_loss: 17.779069900512695\n",
      "    sample_time_ms: 19892.359\n",
      "    update_time_ms: 7.09\n",
      "  iterations_since_restore: 866\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.25862367995283\n",
      "    rl_1: 74.7196266426445\n",
      "  time_since_restore: 20070.53173685074\n",
      "  time_this_iter_s: 22.79230546951294\n",
      "  time_total_s: 20070.53173685074\n",
      "  timestamp: 1550900690\n",
      "  timesteps_since_restore: 8660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8660000\n",
      "  training_iteration: 866\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20070 s, 866 iter, 8660000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-45-13\n",
      "  done: false\n",
      "  episode_len_mean: 108.96\n",
      "  episode_reward_max: 235.02980665828522\n",
      "  episode_reward_mean: 151.7134504827172\n",
      "  episode_reward_min: -169.75000818805307\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 75236\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.782\n",
      "    load_time_ms: 2.277\n",
      "    num_steps_sampled: 8670000\n",
      "    num_steps_trained: 8670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7465119361877441\n",
      "      kl: 0.0990905910730362\n",
      "      policy_loss: 0.02088303491473198\n",
      "      total_loss: 54.860782623291016\n",
      "      vf_explained_var: 0.9685744047164917\n",
      "      vf_loss: 54.839900970458984\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7616603374481201\n",
      "      kl: 0.05214172229170799\n",
      "      policy_loss: 0.005517703015357256\n",
      "      total_loss: 46.452674865722656\n",
      "      vf_explained_var: 0.9669539332389832\n",
      "      vf_loss: 46.447147369384766\n",
      "    sample_time_ms: 19965.77\n",
      "    update_time_ms: 7.341\n",
      "  iterations_since_restore: 867\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.1458485746225\n",
      "    rl_1: 65.5676019080947\n",
      "  time_since_restore: 20093.89695072174\n",
      "  time_this_iter_s: 23.365213871002197\n",
      "  time_total_s: 20093.89695072174\n",
      "  timestamp: 1550900713\n",
      "  timesteps_since_restore: 8670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8670000\n",
      "  training_iteration: 867\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20093 s, 867 iter, 8670000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-45-37\n",
      "  done: false\n",
      "  episode_len_mean: 111.86\n",
      "  episode_reward_max: 223.7732736785405\n",
      "  episode_reward_mean: 156.9678433274687\n",
      "  episode_reward_min: -164.49393270920172\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 75325\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.186\n",
      "    load_time_ms: 2.309\n",
      "    num_steps_sampled: 8680000\n",
      "    num_steps_trained: 8680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6802313923835754\n",
      "      kl: 0.018530244007706642\n",
      "      policy_loss: -0.0034583397209644318\n",
      "      total_loss: 50.75139236450195\n",
      "      vf_explained_var: 0.9686656594276428\n",
      "      vf_loss: 50.75484848022461\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6946215033531189\n",
      "      kl: 0.019022764638066292\n",
      "      policy_loss: 0.0014511996414512396\n",
      "      total_loss: 34.90622329711914\n",
      "      vf_explained_var: 0.97267085313797\n",
      "      vf_loss: 34.90476608276367\n",
      "    sample_time_ms: 20003.135\n",
      "    update_time_ms: 7.091\n",
      "  iterations_since_restore: 868\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.3211275856894\n",
      "    rl_1: 66.6467157417793\n",
      "  time_since_restore: 20117.30809736252\n",
      "  time_this_iter_s: 23.411146640777588\n",
      "  time_total_s: 20117.30809736252\n",
      "  timestamp: 1550900737\n",
      "  timesteps_since_restore: 8680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8680000\n",
      "  training_iteration: 868\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20117 s, 868 iter, 8680000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-46-00\n",
      "  done: false\n",
      "  episode_len_mean: 111.76\n",
      "  episode_reward_max: 226.39864379117665\n",
      "  episode_reward_mean: 160.09420808457602\n",
      "  episode_reward_min: -175.0738838792228\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 75415\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3068.661\n",
      "    load_time_ms: 2.268\n",
      "    num_steps_sampled: 8690000\n",
      "    num_steps_trained: 8690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6560268402099609\n",
      "      kl: 0.06499616801738739\n",
      "      policy_loss: 0.011109545826911926\n",
      "      total_loss: 45.23592758178711\n",
      "      vf_explained_var: 0.9694468975067139\n",
      "      vf_loss: 45.22481918334961\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.680224597454071\n",
      "      kl: 0.019445039331912994\n",
      "      policy_loss: 0.005065808072686195\n",
      "      total_loss: 36.6188850402832\n",
      "      vf_explained_var: 0.971112072467804\n",
      "      vf_loss: 36.61381530761719\n",
      "    sample_time_ms: 19979.464\n",
      "    update_time_ms: 7.278\n",
      "  iterations_since_restore: 869\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.97366784806235\n",
      "    rl_1: 69.1205402365137\n",
      "  time_since_restore: 20140.332363128662\n",
      "  time_this_iter_s: 23.0242657661438\n",
      "  time_total_s: 20140.332363128662\n",
      "  timestamp: 1550900760\n",
      "  timesteps_since_restore: 8690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8690000\n",
      "  training_iteration: 869\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20140 s, 869 iter, 8690000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-46-23\n",
      "  done: false\n",
      "  episode_len_mean: 106.59\n",
      "  episode_reward_max: 227.05083612182315\n",
      "  episode_reward_mean: 159.45866177472658\n",
      "  episode_reward_min: -172.23841645439742\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 75508\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.756\n",
      "    load_time_ms: 2.266\n",
      "    num_steps_sampled: 8700000\n",
      "    num_steps_trained: 8700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7683469653129578\n",
      "      kl: 0.030477026477456093\n",
      "      policy_loss: 0.004847901873290539\n",
      "      total_loss: 29.236631393432617\n",
      "      vf_explained_var: 0.9836844205856323\n",
      "      vf_loss: 29.231781005859375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7138245701789856\n",
      "      kl: 0.024563850834965706\n",
      "      policy_loss: 0.0010078167542815208\n",
      "      total_loss: 24.273483276367188\n",
      "      vf_explained_var: 0.9827277064323425\n",
      "      vf_loss: 24.272472381591797\n",
      "    sample_time_ms: 20026.59\n",
      "    update_time_ms: 7.197\n",
      "  iterations_since_restore: 870\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.22993555010491\n",
      "    rl_1: 69.22872622462164\n",
      "  time_since_restore: 20163.55135655403\n",
      "  time_this_iter_s: 23.218993425369263\n",
      "  time_total_s: 20163.55135655403\n",
      "  timestamp: 1550900783\n",
      "  timesteps_since_restore: 8700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8700000\n",
      "  training_iteration: 870\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20163 s, 870 iter, 8700000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-46-46\n",
      "  done: false\n",
      "  episode_len_mean: 109.9\n",
      "  episode_reward_max: 227.89162298448338\n",
      "  episode_reward_mean: 147.56145189021893\n",
      "  episode_reward_min: -175.8855116154985\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 75598\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.56\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 8710000\n",
      "    num_steps_trained: 8710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7462467551231384\n",
      "      kl: 0.03466187044978142\n",
      "      policy_loss: 0.0010091511067003012\n",
      "      total_loss: 31.371713638305664\n",
      "      vf_explained_var: 0.9834823608398438\n",
      "      vf_loss: 31.370702743530273\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7816194295883179\n",
      "      kl: 0.03015710413455963\n",
      "      policy_loss: 0.004391320049762726\n",
      "      total_loss: 24.940792083740234\n",
      "      vf_explained_var: 0.9839526414871216\n",
      "      vf_loss: 24.9364013671875\n",
      "    sample_time_ms: 19988.209\n",
      "    update_time_ms: 7.469\n",
      "  iterations_since_restore: 871\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.05576071073666\n",
      "    rl_1: 62.50569117948226\n",
      "  time_since_restore: 20186.474425315857\n",
      "  time_this_iter_s: 22.92306876182556\n",
      "  time_total_s: 20186.474425315857\n",
      "  timestamp: 1550900806\n",
      "  timesteps_since_restore: 8710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8710000\n",
      "  training_iteration: 871\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20186 s, 871 iter, 8710000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-47-09\n",
      "  done: false\n",
      "  episode_len_mean: 112.93\n",
      "  episode_reward_max: 235.50573264403852\n",
      "  episode_reward_mean: 138.62541062334896\n",
      "  episode_reward_min: -161.3219400181669\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 75687\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.477\n",
      "    load_time_ms: 2.503\n",
      "    num_steps_sampled: 8720000\n",
      "    num_steps_trained: 8720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6701192259788513\n",
      "      kl: 0.0171491876244545\n",
      "      policy_loss: 0.0014513739151880145\n",
      "      total_loss: 54.35617446899414\n",
      "      vf_explained_var: 0.9736303687095642\n",
      "      vf_loss: 54.35472869873047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.749699592590332\n",
      "      kl: 0.0410524345934391\n",
      "      policy_loss: 0.005788661073893309\n",
      "      total_loss: 42.24220657348633\n",
      "      vf_explained_var: 0.9731252789497375\n",
      "      vf_loss: 42.236419677734375\n",
      "    sample_time_ms: 19992.434\n",
      "    update_time_ms: 7.41\n",
      "  iterations_since_restore: 872\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 82.12610194454923\n",
      "    rl_1: 56.49930867879973\n",
      "  time_since_restore: 20209.67591714859\n",
      "  time_this_iter_s: 23.201491832733154\n",
      "  time_total_s: 20209.67591714859\n",
      "  timestamp: 1550900829\n",
      "  timesteps_since_restore: 8720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8720000\n",
      "  training_iteration: 872\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20209 s, 872 iter, 8720000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-47-32\n",
      "  done: false\n",
      "  episode_len_mean: 112.01\n",
      "  episode_reward_max: 229.08641116974655\n",
      "  episode_reward_mean: 149.45489704158132\n",
      "  episode_reward_min: -178.16889746862807\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 75775\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.304\n",
      "    load_time_ms: 2.443\n",
      "    num_steps_sampled: 8730000\n",
      "    num_steps_trained: 8730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7070529460906982\n",
      "      kl: 0.05351453647017479\n",
      "      policy_loss: 0.006681091617792845\n",
      "      total_loss: 109.62913513183594\n",
      "      vf_explained_var: 0.9374148845672607\n",
      "      vf_loss: 109.62242126464844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7190843820571899\n",
      "      kl: 0.7227557897567749\n",
      "      policy_loss: 0.014092433266341686\n",
      "      total_loss: 66.18465423583984\n",
      "      vf_explained_var: 0.9527140855789185\n",
      "      vf_loss: 66.17057037353516\n",
      "    sample_time_ms: 19980.104\n",
      "    update_time_ms: 7.503\n",
      "  iterations_since_restore: 873\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.23347060796061\n",
      "    rl_1: 62.22142643362074\n",
      "  time_since_restore: 20232.3378841877\n",
      "  time_this_iter_s: 22.661967039108276\n",
      "  time_total_s: 20232.3378841877\n",
      "  timestamp: 1550900852\n",
      "  timesteps_since_restore: 8730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8730000\n",
      "  training_iteration: 873\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20232 s, 873 iter, 8730000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-47-56\n",
      "  done: false\n",
      "  episode_len_mean: 115.03\n",
      "  episode_reward_max: 231.34772301760748\n",
      "  episode_reward_mean: 147.90837620436028\n",
      "  episode_reward_min: -170.97355052671494\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 75862\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3094.187\n",
      "    load_time_ms: 2.42\n",
      "    num_steps_sampled: 8740000\n",
      "    num_steps_trained: 8740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6278693079948425\n",
      "      kl: 0.03132447227835655\n",
      "      policy_loss: 0.004827968310564756\n",
      "      total_loss: 65.74248504638672\n",
      "      vf_explained_var: 0.9638853669166565\n",
      "      vf_loss: 65.7376480102539\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.714381754398346\n",
      "      kl: 0.04223711043596268\n",
      "      policy_loss: 0.007247582543641329\n",
      "      total_loss: 47.511531829833984\n",
      "      vf_explained_var: 0.96750408411026\n",
      "      vf_loss: 47.5042839050293\n",
      "    sample_time_ms: 20022.128\n",
      "    update_time_ms: 7.452\n",
      "  iterations_since_restore: 874\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.64233752849479\n",
      "    rl_1: 60.26603867586546\n",
      "  time_since_restore: 20255.89178109169\n",
      "  time_this_iter_s: 23.5538969039917\n",
      "  time_total_s: 20255.89178109169\n",
      "  timestamp: 1550900876\n",
      "  timesteps_since_restore: 8740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8740000\n",
      "  training_iteration: 874\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20255 s, 874 iter, 8740000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-48-19\n",
      "  done: false\n",
      "  episode_len_mean: 115.52\n",
      "  episode_reward_max: 231.34740133631436\n",
      "  episode_reward_mean: 171.38967563704244\n",
      "  episode_reward_min: -152.9211918893459\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 75948\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3091.08\n",
      "    load_time_ms: 2.435\n",
      "    num_steps_sampled: 8750000\n",
      "    num_steps_trained: 8750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7078158259391785\n",
      "      kl: 0.04120590537786484\n",
      "      policy_loss: 0.010144759900867939\n",
      "      total_loss: 21.581920623779297\n",
      "      vf_explained_var: 0.9815225005149841\n",
      "      vf_loss: 21.571773529052734\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6556389927864075\n",
      "      kl: 0.03946393355727196\n",
      "      policy_loss: 0.005666697863489389\n",
      "      total_loss: 16.10700035095215\n",
      "      vf_explained_var: 0.983327329158783\n",
      "      vf_loss: 16.101333618164062\n",
      "    sample_time_ms: 20009.313\n",
      "    update_time_ms: 7.715\n",
      "  iterations_since_restore: 875\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 99.97186793027554\n",
      "    rl_1: 71.41780770676692\n",
      "  time_since_restore: 20279.027445793152\n",
      "  time_this_iter_s: 23.135664701461792\n",
      "  time_total_s: 20279.027445793152\n",
      "  timestamp: 1550900899\n",
      "  timesteps_since_restore: 8750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8750000\n",
      "  training_iteration: 875\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20279 s, 875 iter, 8750000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-48-42\n",
      "  done: false\n",
      "  episode_len_mean: 112.96\n",
      "  episode_reward_max: 232.8345438976304\n",
      "  episode_reward_mean: 153.1247446527119\n",
      "  episode_reward_min: -178.94965456127477\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 76038\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3093.275\n",
      "    load_time_ms: 2.438\n",
      "    num_steps_sampled: 8760000\n",
      "    num_steps_trained: 8760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6910836696624756\n",
      "      kl: 0.023421328514814377\n",
      "      policy_loss: 0.005053957924246788\n",
      "      total_loss: 45.98179244995117\n",
      "      vf_explained_var: 0.9738321304321289\n",
      "      vf_loss: 45.97674560546875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7026545405387878\n",
      "      kl: 0.027963224798440933\n",
      "      policy_loss: 0.0031612152233719826\n",
      "      total_loss: 36.918827056884766\n",
      "      vf_explained_var: 0.9746329188346863\n",
      "      vf_loss: 36.91566848754883\n",
      "    sample_time_ms: 20067.222\n",
      "    update_time_ms: 7.49\n",
      "  iterations_since_restore: 876\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.39001031883356\n",
      "    rl_1: 64.73473433387836\n",
      "  time_since_restore: 20302.420196294785\n",
      "  time_this_iter_s: 23.39275050163269\n",
      "  time_total_s: 20302.420196294785\n",
      "  timestamp: 1550900922\n",
      "  timesteps_since_restore: 8760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8760000\n",
      "  training_iteration: 876\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20302 s, 876 iter, 8760000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-49-05\n",
      "  done: false\n",
      "  episode_len_mean: 115.07\n",
      "  episode_reward_max: 235.30159376481228\n",
      "  episode_reward_mean: 133.28413798891935\n",
      "  episode_reward_min: -178.94965456127477\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 76124\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3092.992\n",
      "    load_time_ms: 2.384\n",
      "    num_steps_sampled: 8770000\n",
      "    num_steps_trained: 8770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.636738657951355\n",
      "      kl: 0.02591008134186268\n",
      "      policy_loss: 0.00449145445600152\n",
      "      total_loss: 51.319618225097656\n",
      "      vf_explained_var: 0.9751681685447693\n",
      "      vf_loss: 51.315128326416016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7369658350944519\n",
      "      kl: 0.04735945165157318\n",
      "      policy_loss: 0.005297164898365736\n",
      "      total_loss: 42.44769287109375\n",
      "      vf_explained_var: 0.9749866127967834\n",
      "      vf_loss: 42.4423942565918\n",
      "    sample_time_ms: 19991.947\n",
      "    update_time_ms: 7.374\n",
      "  iterations_since_restore: 877\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.23015717298397\n",
      "    rl_1: 54.05398081593541\n",
      "  time_since_restore: 20325.02921628952\n",
      "  time_this_iter_s: 22.609019994735718\n",
      "  time_total_s: 20325.02921628952\n",
      "  timestamp: 1550900945\n",
      "  timesteps_since_restore: 8770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8770000\n",
      "  training_iteration: 877\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20325 s, 877 iter, 8770000 ts, 133 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-49-28\n",
      "  done: false\n",
      "  episode_len_mean: 114.43\n",
      "  episode_reward_max: 225.20281220708168\n",
      "  episode_reward_mean: 162.43508100507435\n",
      "  episode_reward_min: -169.12912294615217\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 76211\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.159\n",
      "    load_time_ms: 2.408\n",
      "    num_steps_sampled: 8780000\n",
      "    num_steps_trained: 8780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7149291634559631\n",
      "      kl: 0.023811282590031624\n",
      "      policy_loss: 0.007259491365402937\n",
      "      total_loss: 35.01838684082031\n",
      "      vf_explained_var: 0.9753721356391907\n",
      "      vf_loss: 35.0111198425293\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7362974286079407\n",
      "      kl: 0.020763155072927475\n",
      "      policy_loss: 0.0007830625982023776\n",
      "      total_loss: 31.043041229248047\n",
      "      vf_explained_var: 0.9725098013877869\n",
      "      vf_loss: 31.042255401611328\n",
      "    sample_time_ms: 19930.629\n",
      "    update_time_ms: 7.479\n",
      "  iterations_since_restore: 878\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.4894478301795\n",
      "    rl_1: 68.94563317489488\n",
      "  time_since_restore: 20347.647807598114\n",
      "  time_this_iter_s: 22.61859130859375\n",
      "  time_total_s: 20347.647807598114\n",
      "  timestamp: 1550900968\n",
      "  timesteps_since_restore: 8780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8780000\n",
      "  training_iteration: 878\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20347 s, 878 iter, 8780000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-49-51\n",
      "  done: false\n",
      "  episode_len_mean: 110.37\n",
      "  episode_reward_max: 231.8179909769476\n",
      "  episode_reward_mean: 141.2400648117656\n",
      "  episode_reward_min: -172.9264923970938\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 76304\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.487\n",
      "    load_time_ms: 2.522\n",
      "    num_steps_sampled: 8790000\n",
      "    num_steps_trained: 8790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7215065360069275\n",
      "      kl: 0.022841474041342735\n",
      "      policy_loss: 0.0035177995450794697\n",
      "      total_loss: 49.84791564941406\n",
      "      vf_explained_var: 0.9766934514045715\n",
      "      vf_loss: 49.84440231323242\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6983279585838318\n",
      "      kl: 0.013673200272023678\n",
      "      policy_loss: 0.0007682011928409338\n",
      "      total_loss: 40.5745964050293\n",
      "      vf_explained_var: 0.9777815341949463\n",
      "      vf_loss: 40.57382583618164\n",
      "    sample_time_ms: 19925.013\n",
      "    update_time_ms: 7.504\n",
      "  iterations_since_restore: 879\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.78705920793865\n",
      "    rl_1: 59.45300560382696\n",
      "  time_since_restore: 20370.642194986343\n",
      "  time_this_iter_s: 22.99438738822937\n",
      "  time_total_s: 20370.642194986343\n",
      "  timestamp: 1550900991\n",
      "  timesteps_since_restore: 8790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8790000\n",
      "  training_iteration: 879\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20370 s, 879 iter, 8790000 ts, 141 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-50-14\n",
      "  done: false\n",
      "  episode_len_mean: 117.22\n",
      "  episode_reward_max: 228.06941069382628\n",
      "  episode_reward_mean: 164.26200276042334\n",
      "  episode_reward_min: -167.1459896185914\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 76389\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.573\n",
      "    load_time_ms: 2.594\n",
      "    num_steps_sampled: 8800000\n",
      "    num_steps_trained: 8800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6778767704963684\n",
      "      kl: 0.022025741636753082\n",
      "      policy_loss: 0.0027265488170087337\n",
      "      total_loss: 40.988304138183594\n",
      "      vf_explained_var: 0.9649764895439148\n",
      "      vf_loss: 40.9855842590332\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6865668892860413\n",
      "      kl: 0.2401367574930191\n",
      "      policy_loss: 0.015034455806016922\n",
      "      total_loss: 31.85777473449707\n",
      "      vf_explained_var: 0.967662513256073\n",
      "      vf_loss: 31.84273910522461\n",
      "    sample_time_ms: 19892.913\n",
      "    update_time_ms: 7.603\n",
      "  iterations_since_restore: 880\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.92263658318066\n",
      "    rl_1: 68.33936617724265\n",
      "  time_since_restore: 20393.662623405457\n",
      "  time_this_iter_s: 23.02042841911316\n",
      "  time_total_s: 20393.662623405457\n",
      "  timestamp: 1550901014\n",
      "  timesteps_since_restore: 8800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8800000\n",
      "  training_iteration: 880\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20393 s, 880 iter, 8800000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-50-37\n",
      "  done: false\n",
      "  episode_len_mean: 113.67\n",
      "  episode_reward_max: 235.22191495600708\n",
      "  episode_reward_mean: 152.734840854508\n",
      "  episode_reward_min: -169.0287085421719\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 76476\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3105.268\n",
      "    load_time_ms: 2.49\n",
      "    num_steps_sampled: 8810000\n",
      "    num_steps_trained: 8810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6429992318153381\n",
      "      kl: 7.766324520111084\n",
      "      policy_loss: 0.07419942319393158\n",
      "      total_loss: 48.20880126953125\n",
      "      vf_explained_var: 0.9734521508216858\n",
      "      vf_loss: 48.13460159301758\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7090532779693604\n",
      "      kl: 0.04767999425530434\n",
      "      policy_loss: -0.003193399403244257\n",
      "      total_loss: 36.636756896972656\n",
      "      vf_explained_var: 0.9761819839477539\n",
      "      vf_loss: 36.63994598388672\n",
      "    sample_time_ms: 19923.226\n",
      "    update_time_ms: 7.316\n",
      "  iterations_since_restore: 881\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.57035400373869\n",
      "    rl_1: 64.16448685076935\n",
      "  time_since_restore: 20417.04234814644\n",
      "  time_this_iter_s: 23.379724740982056\n",
      "  time_total_s: 20417.04234814644\n",
      "  timestamp: 1550901037\n",
      "  timesteps_since_restore: 8810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8810000\n",
      "  training_iteration: 881\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20417 s, 881 iter, 8810000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-51-00\n",
      "  done: false\n",
      "  episode_len_mean: 116.43\n",
      "  episode_reward_max: 232.12755665505833\n",
      "  episode_reward_mean: 157.84919337534492\n",
      "  episode_reward_min: -169.0287085421719\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 76559\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.144\n",
      "    load_time_ms: 2.415\n",
      "    num_steps_sampled: 8820000\n",
      "    num_steps_trained: 8820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7025524377822876\n",
      "      kl: 0.030177613720297813\n",
      "      policy_loss: 0.004050892777740955\n",
      "      total_loss: 52.15552520751953\n",
      "      vf_explained_var: 0.9589166045188904\n",
      "      vf_loss: 52.151466369628906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7863134741783142\n",
      "      kl: 0.029634786769747734\n",
      "      policy_loss: 0.0033832478802651167\n",
      "      total_loss: 43.179134368896484\n",
      "      vf_explained_var: 0.9576837420463562\n",
      "      vf_loss: 43.17575454711914\n",
      "    sample_time_ms: 19918.301\n",
      "    update_time_ms: 7.402\n",
      "  iterations_since_restore: 882\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.51269789075026\n",
      "    rl_1: 66.33649548459466\n",
      "  time_since_restore: 20439.98045682907\n",
      "  time_this_iter_s: 22.938108682632446\n",
      "  time_total_s: 20439.98045682907\n",
      "  timestamp: 1550901060\n",
      "  timesteps_since_restore: 8820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8820000\n",
      "  training_iteration: 882\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20439 s, 882 iter, 8820000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-51-23\n",
      "  done: false\n",
      "  episode_len_mean: 115.07\n",
      "  episode_reward_max: 233.25298912840785\n",
      "  episode_reward_mean: 163.97480426444002\n",
      "  episode_reward_min: -168.98023029842193\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 76647\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.235\n",
      "    load_time_ms: 2.457\n",
      "    num_steps_sampled: 8830000\n",
      "    num_steps_trained: 8830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7765712141990662\n",
      "      kl: 0.012345405295491219\n",
      "      policy_loss: 0.0009942377218976617\n",
      "      total_loss: 44.28379440307617\n",
      "      vf_explained_var: 0.9743674993515015\n",
      "      vf_loss: 44.282798767089844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8262057900428772\n",
      "      kl: 0.0352560356259346\n",
      "      policy_loss: 0.003575859824195504\n",
      "      total_loss: 31.748973846435547\n",
      "      vf_explained_var: 0.9770634770393372\n",
      "      vf_loss: 31.745399475097656\n",
      "    sample_time_ms: 19966.037\n",
      "    update_time_ms: 7.358\n",
      "  iterations_since_restore: 883\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.41801526338382\n",
      "    rl_1: 70.55678900105619\n",
      "  time_since_restore: 20463.114176273346\n",
      "  time_this_iter_s: 23.133719444274902\n",
      "  time_total_s: 20463.114176273346\n",
      "  timestamp: 1550901083\n",
      "  timesteps_since_restore: 8830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8830000\n",
      "  training_iteration: 883\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20463 s, 883 iter, 8830000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-51-47\n",
      "  done: false\n",
      "  episode_len_mean: 110.54\n",
      "  episode_reward_max: 232.71863467237023\n",
      "  episode_reward_mean: 162.80040961385595\n",
      "  episode_reward_min: -168.07090209215977\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 76737\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.646\n",
      "    load_time_ms: 2.495\n",
      "    num_steps_sampled: 8840000\n",
      "    num_steps_trained: 8840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7343832850456238\n",
      "      kl: 0.030680054798722267\n",
      "      policy_loss: 0.0036476748064160347\n",
      "      total_loss: 62.68342971801758\n",
      "      vf_explained_var: 0.9591830372810364\n",
      "      vf_loss: 62.67980194091797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7399731874465942\n",
      "      kl: 0.03671515733003616\n",
      "      policy_loss: 0.0026424317620694637\n",
      "      total_loss: 54.454872131347656\n",
      "      vf_explained_var: 0.9567875862121582\n",
      "      vf_loss: 54.45222854614258\n",
      "    sample_time_ms: 19913.81\n",
      "    update_time_ms: 7.595\n",
      "  iterations_since_restore: 884\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.21992784410388\n",
      "    rl_1: 71.58048176975207\n",
      "  time_since_restore: 20486.163019180298\n",
      "  time_this_iter_s: 23.048842906951904\n",
      "  time_total_s: 20486.163019180298\n",
      "  timestamp: 1550901107\n",
      "  timesteps_since_restore: 8840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8840000\n",
      "  training_iteration: 884\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20486 s, 884 iter, 8840000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-52-10\n",
      "  done: false\n",
      "  episode_len_mean: 109.73\n",
      "  episode_reward_max: 234.82879920437705\n",
      "  episode_reward_mean: 148.05469066851637\n",
      "  episode_reward_min: -173.13546739824227\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 76828\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3101.121\n",
      "    load_time_ms: 2.586\n",
      "    num_steps_sampled: 8850000\n",
      "    num_steps_trained: 8850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7503592371940613\n",
      "      kl: 0.04106482118368149\n",
      "      policy_loss: 0.005832836963236332\n",
      "      total_loss: 52.182220458984375\n",
      "      vf_explained_var: 0.971168041229248\n",
      "      vf_loss: 52.176395416259766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7377729415893555\n",
      "      kl: 0.027269553393125534\n",
      "      policy_loss: 0.002951489994302392\n",
      "      total_loss: 31.428817749023438\n",
      "      vf_explained_var: 0.9776256084442139\n",
      "      vf_loss: 31.42586898803711\n",
      "    sample_time_ms: 19906.199\n",
      "    update_time_ms: 7.345\n",
      "  iterations_since_restore: 885\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.48081460164845\n",
      "    rl_1: 63.573876066867925\n",
      "  time_since_restore: 20509.383554458618\n",
      "  time_this_iter_s: 23.220535278320312\n",
      "  time_total_s: 20509.383554458618\n",
      "  timestamp: 1550901130\n",
      "  timesteps_since_restore: 8850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8850000\n",
      "  training_iteration: 885\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20509 s, 885 iter, 8850000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-52-33\n",
      "  done: false\n",
      "  episode_len_mean: 114.02\n",
      "  episode_reward_max: 234.85321662229467\n",
      "  episode_reward_mean: 162.86297841267609\n",
      "  episode_reward_min: -160.53677613256843\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 76916\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3098.031\n",
      "    load_time_ms: 2.596\n",
      "    num_steps_sampled: 8860000\n",
      "    num_steps_trained: 8860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7356898784637451\n",
      "      kl: 0.028778668493032455\n",
      "      policy_loss: 0.0022272372152656317\n",
      "      total_loss: 38.38600540161133\n",
      "      vf_explained_var: 0.9706751704216003\n",
      "      vf_loss: 38.38378143310547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7326321005821228\n",
      "      kl: 0.0403626374900341\n",
      "      policy_loss: 0.0110015869140625\n",
      "      total_loss: 30.03632926940918\n",
      "      vf_explained_var: 0.9706474542617798\n",
      "      vf_loss: 30.025333404541016\n",
      "    sample_time_ms: 19871.671\n",
      "    update_time_ms: 7.303\n",
      "  iterations_since_restore: 886\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.11851235147351\n",
      "    rl_1: 68.74446606120259\n",
      "  time_since_restore: 20532.399287700653\n",
      "  time_this_iter_s: 23.015733242034912\n",
      "  time_total_s: 20532.399287700653\n",
      "  timestamp: 1550901153\n",
      "  timesteps_since_restore: 8860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8860000\n",
      "  training_iteration: 886\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20532 s, 886 iter, 8860000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-52-56\n",
      "  done: false\n",
      "  episode_len_mean: 118.87\n",
      "  episode_reward_max: 234.2508162186863\n",
      "  episode_reward_mean: 165.3889001417213\n",
      "  episode_reward_min: -146.4729724560019\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 77000\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3098.82\n",
      "    load_time_ms: 2.616\n",
      "    num_steps_sampled: 8870000\n",
      "    num_steps_trained: 8870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5938186049461365\n",
      "      kl: 0.029735393822193146\n",
      "      policy_loss: 0.007292567286640406\n",
      "      total_loss: 32.14670181274414\n",
      "      vf_explained_var: 0.9714332818984985\n",
      "      vf_loss: 32.139400482177734\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6242648959159851\n",
      "      kl: 0.020269813016057014\n",
      "      policy_loss: 0.006750572007149458\n",
      "      total_loss: 25.217247009277344\n",
      "      vf_explained_var: 0.9753063917160034\n",
      "      vf_loss: 25.21049690246582\n",
      "    sample_time_ms: 19911.392\n",
      "    update_time_ms: 7.285\n",
      "  iterations_since_restore: 887\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.1760762289853\n",
      "    rl_1: 69.21282391273603\n",
      "  time_since_restore: 20555.413090467453\n",
      "  time_this_iter_s: 23.013802766799927\n",
      "  time_total_s: 20555.413090467453\n",
      "  timestamp: 1550901176\n",
      "  timesteps_since_restore: 8870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8870000\n",
      "  training_iteration: 887\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20555 s, 887 iter, 8870000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-53-19\n",
      "  done: false\n",
      "  episode_len_mean: 114.65\n",
      "  episode_reward_max: 236.38717494349774\n",
      "  episode_reward_mean: 164.8061932722599\n",
      "  episode_reward_min: -165.48339199734824\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 77088\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.306\n",
      "    load_time_ms: 2.556\n",
      "    num_steps_sampled: 8880000\n",
      "    num_steps_trained: 8880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7209634780883789\n",
      "      kl: 0.03391387686133385\n",
      "      policy_loss: 0.006953086704015732\n",
      "      total_loss: 47.54220199584961\n",
      "      vf_explained_var: 0.9645563960075378\n",
      "      vf_loss: 47.535247802734375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.715299665927887\n",
      "      kl: 0.025463281199336052\n",
      "      policy_loss: 0.0036379725206643343\n",
      "      total_loss: 34.788543701171875\n",
      "      vf_explained_var: 0.9675087332725525\n",
      "      vf_loss: 34.78490447998047\n",
      "    sample_time_ms: 19996.744\n",
      "    update_time_ms: 7.552\n",
      "  iterations_since_restore: 888\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.9619714398\n",
      "    rl_1: 70.84422183245984\n",
      "  time_since_restore: 20578.90202689171\n",
      "  time_this_iter_s: 23.48893642425537\n",
      "  time_total_s: 20578.90202689171\n",
      "  timestamp: 1550901199\n",
      "  timesteps_since_restore: 8880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8880000\n",
      "  training_iteration: 888\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20578 s, 888 iter, 8880000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-53-43\n",
      "  done: false\n",
      "  episode_len_mean: 116.63\n",
      "  episode_reward_max: 236.38717494349774\n",
      "  episode_reward_mean: 154.62421984297296\n",
      "  episode_reward_min: -174.8229252903788\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 77174\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.875\n",
      "    load_time_ms: 2.463\n",
      "    num_steps_sampled: 8890000\n",
      "    num_steps_trained: 8890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6241613030433655\n",
      "      kl: 0.06329725682735443\n",
      "      policy_loss: 0.012563873082399368\n",
      "      total_loss: 46.99385452270508\n",
      "      vf_explained_var: 0.9718664288520813\n",
      "      vf_loss: 46.98128890991211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6523078680038452\n",
      "      kl: 0.05069836601614952\n",
      "      policy_loss: -0.004350581672042608\n",
      "      total_loss: 41.021575927734375\n",
      "      vf_explained_var: 0.9714241027832031\n",
      "      vf_loss: 41.025917053222656\n",
      "    sample_time_ms: 20012.612\n",
      "    update_time_ms: 7.37\n",
      "  iterations_since_restore: 889\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.92696161233991\n",
      "    rl_1: 64.69725823063305\n",
      "  time_since_restore: 20602.006571531296\n",
      "  time_this_iter_s: 23.104544639587402\n",
      "  time_total_s: 20602.006571531296\n",
      "  timestamp: 1550901223\n",
      "  timesteps_since_restore: 8890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8890000\n",
      "  training_iteration: 889\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20602 s, 889 iter, 8890000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-54-06\n",
      "  done: false\n",
      "  episode_len_mean: 114.68\n",
      "  episode_reward_max: 233.68066865800938\n",
      "  episode_reward_mean: 160.5864896614208\n",
      "  episode_reward_min: -169.43467462509335\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 77260\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.331\n",
      "    load_time_ms: 2.478\n",
      "    num_steps_sampled: 8900000\n",
      "    num_steps_trained: 8900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.634554386138916\n",
      "      kl: 0.032260023057460785\n",
      "      policy_loss: 0.009989476762712002\n",
      "      total_loss: 45.30982208251953\n",
      "      vf_explained_var: 0.9669448733329773\n",
      "      vf_loss: 45.29983139038086\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.710268497467041\n",
      "      kl: 0.02023489587008953\n",
      "      policy_loss: -0.0017568134935572743\n",
      "      total_loss: 38.63172912597656\n",
      "      vf_explained_var: 0.9661068320274353\n",
      "      vf_loss: 38.633487701416016\n",
      "    sample_time_ms: 20007.841\n",
      "    update_time_ms: 7.429\n",
      "  iterations_since_restore: 890\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.00276745899328\n",
      "    rl_1: 68.58372220242754\n",
      "  time_since_restore: 20624.86572575569\n",
      "  time_this_iter_s: 22.859154224395752\n",
      "  time_total_s: 20624.86572575569\n",
      "  timestamp: 1550901246\n",
      "  timesteps_since_restore: 8900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8900000\n",
      "  training_iteration: 890\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20624 s, 890 iter, 8900000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-54-29\n",
      "  done: false\n",
      "  episode_len_mean: 114.99\n",
      "  episode_reward_max: 230.39370601887924\n",
      "  episode_reward_mean: 159.52034623448387\n",
      "  episode_reward_min: -160.51897194815427\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 77347\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3070.828\n",
      "    load_time_ms: 2.534\n",
      "    num_steps_sampled: 8910000\n",
      "    num_steps_trained: 8910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6296090483665466\n",
      "      kl: 0.012835673987865448\n",
      "      policy_loss: 0.004194946493953466\n",
      "      total_loss: 51.320716857910156\n",
      "      vf_explained_var: 0.9575436115264893\n",
      "      vf_loss: 51.316532135009766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7099882960319519\n",
      "      kl: 3.6530261039733887\n",
      "      policy_loss: 0.03394355624914169\n",
      "      total_loss: 39.73351287841797\n",
      "      vf_explained_var: 0.9601172208786011\n",
      "      vf_loss: 39.699562072753906\n",
      "    sample_time_ms: 20060.915\n",
      "    update_time_ms: 7.482\n",
      "  iterations_since_restore: 891\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.47308490734254\n",
      "    rl_1: 68.04726132714127\n",
      "  time_since_restore: 20648.63817381859\n",
      "  time_this_iter_s: 23.77244806289673\n",
      "  time_total_s: 20648.63817381859\n",
      "  timestamp: 1550901269\n",
      "  timesteps_since_restore: 8910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8910000\n",
      "  training_iteration: 891\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20648 s, 891 iter, 8910000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-54-52\n",
      "  done: false\n",
      "  episode_len_mean: 116.81\n",
      "  episode_reward_max: 226.11081296927495\n",
      "  episode_reward_mean: 155.23182858606987\n",
      "  episode_reward_min: -160.2708872746877\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 77434\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.129\n",
      "    load_time_ms: 2.514\n",
      "    num_steps_sampled: 8920000\n",
      "    num_steps_trained: 8920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.713039755821228\n",
      "      kl: 0.02068035677075386\n",
      "      policy_loss: 0.0010949098505079746\n",
      "      total_loss: 41.830074310302734\n",
      "      vf_explained_var: 0.9743780493736267\n",
      "      vf_loss: 41.8289794921875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7614523768424988\n",
      "      kl: 0.017117653042078018\n",
      "      policy_loss: -0.001617211615666747\n",
      "      total_loss: 31.0224609375\n",
      "      vf_explained_var: 0.9748756289482117\n",
      "      vf_loss: 31.024078369140625\n",
      "    sample_time_ms: 20076.424\n",
      "    update_time_ms: 7.564\n",
      "  iterations_since_restore: 892\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.53490711346114\n",
      "    rl_1: 63.69692147260873\n",
      "  time_since_restore: 20671.757598876953\n",
      "  time_this_iter_s: 23.119425058364868\n",
      "  time_total_s: 20671.757598876953\n",
      "  timestamp: 1550901292\n",
      "  timesteps_since_restore: 8920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8920000\n",
      "  training_iteration: 892\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20671 s, 892 iter, 8920000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-55-16\n",
      "  done: false\n",
      "  episode_len_mean: 114.86\n",
      "  episode_reward_max: 232.72918897693663\n",
      "  episode_reward_mean: 162.2030356567221\n",
      "  episode_reward_min: -133.94018091391962\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 77521\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.943\n",
      "    load_time_ms: 2.467\n",
      "    num_steps_sampled: 8930000\n",
      "    num_steps_trained: 8930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.697908878326416\n",
      "      kl: 0.03535982221364975\n",
      "      policy_loss: 0.01307749468833208\n",
      "      total_loss: 33.71445083618164\n",
      "      vf_explained_var: 0.9752433896064758\n",
      "      vf_loss: 33.70137405395508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7235401272773743\n",
      "      kl: 0.021218324080109596\n",
      "      policy_loss: 0.000985570135526359\n",
      "      total_loss: 28.163002014160156\n",
      "      vf_explained_var: 0.9770612716674805\n",
      "      vf_loss: 28.162017822265625\n",
      "    sample_time_ms: 20109.482\n",
      "    update_time_ms: 7.482\n",
      "  iterations_since_restore: 893\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.01759565080096\n",
      "    rl_1: 70.1854400059211\n",
      "  time_since_restore: 20695.186161756516\n",
      "  time_this_iter_s: 23.428562879562378\n",
      "  time_total_s: 20695.186161756516\n",
      "  timestamp: 1550901316\n",
      "  timesteps_since_restore: 8930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8930000\n",
      "  training_iteration: 893\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20695 s, 893 iter, 8930000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-55-39\n",
      "  done: false\n",
      "  episode_len_mean: 118.39\n",
      "  episode_reward_max: 231.4670032406735\n",
      "  episode_reward_mean: 165.79857703669595\n",
      "  episode_reward_min: -161.37777249141072\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 77605\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.806\n",
      "    load_time_ms: 2.417\n",
      "    num_steps_sampled: 8940000\n",
      "    num_steps_trained: 8940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5946314334869385\n",
      "      kl: 3.394798755645752\n",
      "      policy_loss: 0.048437587916851044\n",
      "      total_loss: 27.381933212280273\n",
      "      vf_explained_var: 0.9763017296791077\n",
      "      vf_loss: 27.333492279052734\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6767857670783997\n",
      "      kl: 0.017927471548318863\n",
      "      policy_loss: -1.5978916053427383e-05\n",
      "      total_loss: 25.206727981567383\n",
      "      vf_explained_var: 0.9757072329521179\n",
      "      vf_loss: 25.206741333007812\n",
      "    sample_time_ms: 20120.957\n",
      "    update_time_ms: 7.249\n",
      "  iterations_since_restore: 894\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.19735120378974\n",
      "    rl_1: 70.60122583290618\n",
      "  time_since_restore: 20718.540526390076\n",
      "  time_this_iter_s: 23.35436463356018\n",
      "  time_total_s: 20718.540526390076\n",
      "  timestamp: 1550901339\n",
      "  timesteps_since_restore: 8940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8940000\n",
      "  training_iteration: 894\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20718 s, 894 iter, 8940000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-56-02\n",
      "  done: false\n",
      "  episode_len_mean: 115.76\n",
      "  episode_reward_max: 233.44404000368343\n",
      "  episode_reward_mean: 162.82643505543945\n",
      "  episode_reward_min: -143.9878940180437\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 77692\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.44\n",
      "    load_time_ms: 2.311\n",
      "    num_steps_sampled: 8950000\n",
      "    num_steps_trained: 8950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6886143088340759\n",
      "      kl: 0.02630298025906086\n",
      "      policy_loss: 0.009687920100986958\n",
      "      total_loss: 55.005470275878906\n",
      "      vf_explained_var: 0.9608743190765381\n",
      "      vf_loss: 54.99578094482422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7135652899742126\n",
      "      kl: 0.023669105023145676\n",
      "      policy_loss: 0.003687602700665593\n",
      "      total_loss: 42.51531982421875\n",
      "      vf_explained_var: 0.9620147943496704\n",
      "      vf_loss: 42.511634826660156\n",
      "    sample_time_ms: 20101.357\n",
      "    update_time_ms: 7.34\n",
      "  iterations_since_restore: 895\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.86817829123076\n",
      "    rl_1: 67.95825676420871\n",
      "  time_since_restore: 20741.438427209854\n",
      "  time_this_iter_s: 22.897900819778442\n",
      "  time_total_s: 20741.438427209854\n",
      "  timestamp: 1550901362\n",
      "  timesteps_since_restore: 8950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8950000\n",
      "  training_iteration: 895\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20741 s, 895 iter, 8950000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-56-25\n",
      "  done: false\n",
      "  episode_len_mean: 117.17\n",
      "  episode_reward_max: 231.52017759956013\n",
      "  episode_reward_mean: 157.70115537180914\n",
      "  episode_reward_min: -162.88633820939882\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 77778\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.521\n",
      "    load_time_ms: 2.299\n",
      "    num_steps_sampled: 8960000\n",
      "    num_steps_trained: 8960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6455140709877014\n",
      "      kl: 0.02416938915848732\n",
      "      policy_loss: 0.004632388241589069\n",
      "      total_loss: 22.140975952148438\n",
      "      vf_explained_var: 0.9846345782279968\n",
      "      vf_loss: 22.136341094970703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.700847327709198\n",
      "      kl: 0.021250484511256218\n",
      "      policy_loss: -0.002903963206335902\n",
      "      total_loss: 20.586299896240234\n",
      "      vf_explained_var: 0.98375004529953\n",
      "      vf_loss: 20.58920669555664\n",
      "    sample_time_ms: 20112.423\n",
      "    update_time_ms: 7.304\n",
      "  iterations_since_restore: 896\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.81570920975925\n",
      "    rl_1: 65.88544616204992\n",
      "  time_since_restore: 20764.55291557312\n",
      "  time_this_iter_s: 23.11448836326599\n",
      "  time_total_s: 20764.55291557312\n",
      "  timestamp: 1550901385\n",
      "  timesteps_since_restore: 8960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8960000\n",
      "  training_iteration: 896\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20764 s, 896 iter, 8960000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-56-48\n",
      "  done: false\n",
      "  episode_len_mean: 115.98\n",
      "  episode_reward_max: 233.56070459134222\n",
      "  episode_reward_mean: 160.851565355432\n",
      "  episode_reward_min: -165.62144841892234\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 77863\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.407\n",
      "    load_time_ms: 2.273\n",
      "    num_steps_sampled: 8970000\n",
      "    num_steps_trained: 8970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.608153760433197\n",
      "      kl: 0.061904821544885635\n",
      "      policy_loss: 0.01049899123609066\n",
      "      total_loss: 25.065467834472656\n",
      "      vf_explained_var: 0.9806291460990906\n",
      "      vf_loss: 25.054969787597656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6380469799041748\n",
      "      kl: 0.019418984651565552\n",
      "      policy_loss: 0.0024473746307194233\n",
      "      total_loss: 19.052597045898438\n",
      "      vf_explained_var: 0.9816540479660034\n",
      "      vf_loss: 19.05014991760254\n",
      "    sample_time_ms: 20093.059\n",
      "    update_time_ms: 7.45\n",
      "  iterations_since_restore: 897\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.45069404753465\n",
      "    rl_1: 67.40087130789732\n",
      "  time_since_restore: 20787.411932706833\n",
      "  time_this_iter_s: 22.85901713371277\n",
      "  time_total_s: 20787.411932706833\n",
      "  timestamp: 1550901408\n",
      "  timesteps_since_restore: 8970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8970000\n",
      "  training_iteration: 897\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20787 s, 897 iter, 8970000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-57-11\n",
      "  done: false\n",
      "  episode_len_mean: 115.84\n",
      "  episode_reward_max: 229.9194548446122\n",
      "  episode_reward_mean: 162.0733938140355\n",
      "  episode_reward_min: -181.0307665080988\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 77949\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.194\n",
      "    load_time_ms: 2.274\n",
      "    num_steps_sampled: 8980000\n",
      "    num_steps_trained: 8980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.626043438911438\n",
      "      kl: 0.013743112795054913\n",
      "      policy_loss: -0.0005632388056255877\n",
      "      total_loss: 47.01730728149414\n",
      "      vf_explained_var: 0.9650596976280212\n",
      "      vf_loss: 47.01787185668945\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6684551239013672\n",
      "      kl: 0.02524486929178238\n",
      "      policy_loss: -0.000420908909291029\n",
      "      total_loss: 32.445533752441406\n",
      "      vf_explained_var: 0.9705805778503418\n",
      "      vf_loss: 32.445960998535156\n",
      "    sample_time_ms: 20037.283\n",
      "    update_time_ms: 7.104\n",
      "  iterations_since_restore: 898\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.08476511067283\n",
      "    rl_1: 68.98862870336269\n",
      "  time_since_restore: 20810.34822845459\n",
      "  time_this_iter_s: 22.936295747756958\n",
      "  time_total_s: 20810.34822845459\n",
      "  timestamp: 1550901431\n",
      "  timesteps_since_restore: 8980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8980000\n",
      "  training_iteration: 898\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20810 s, 898 iter, 8980000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-57-34\n",
      "  done: false\n",
      "  episode_len_mean: 115.62\n",
      "  episode_reward_max: 230.82696987844216\n",
      "  episode_reward_mean: 169.59102837584544\n",
      "  episode_reward_min: -152.9778246860455\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 78035\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.82\n",
      "    load_time_ms: 2.281\n",
      "    num_steps_sampled: 8990000\n",
      "    num_steps_trained: 8990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6604323387145996\n",
      "      kl: 0.02173212543129921\n",
      "      policy_loss: 0.004299021326005459\n",
      "      total_loss: 16.525545120239258\n",
      "      vf_explained_var: 0.9862850904464722\n",
      "      vf_loss: 16.521249771118164\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6649417281150818\n",
      "      kl: 0.023251330479979515\n",
      "      policy_loss: 0.002442332450300455\n",
      "      total_loss: 13.316038131713867\n",
      "      vf_explained_var: 0.9855836629867554\n",
      "      vf_loss: 13.313596725463867\n",
      "    sample_time_ms: 20014.568\n",
      "    update_time_ms: 7.083\n",
      "  iterations_since_restore: 899\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.12928758501714\n",
      "    rl_1: 72.46174079082833\n",
      "  time_since_restore: 20833.24368572235\n",
      "  time_this_iter_s: 22.89545726776123\n",
      "  time_total_s: 20833.24368572235\n",
      "  timestamp: 1550901454\n",
      "  timesteps_since_restore: 8990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 8990000\n",
      "  training_iteration: 899\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20833 s, 899 iter, 8990000 ts, 170 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 109.97\n",
      "  episode_reward_max: 231.6352931816615\n",
      "  episode_reward_mean: 144.8225337800984\n",
      "  episode_reward_min: -168.6076367330535\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 78125\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.127\n",
      "    load_time_ms: 2.206\n",
      "    num_steps_sampled: 9000000\n",
      "    num_steps_trained: 9000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6961425542831421\n",
      "      kl: 0.03315814211964607\n",
      "      policy_loss: 0.009483273141086102\n",
      "      total_loss: 47.827430725097656\n",
      "      vf_explained_var: 0.977307140827179\n",
      "      vf_loss: 47.81794357299805\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6790814995765686\n",
      "      kl: 0.01831752434372902\n",
      "      policy_loss: -0.00023563325521536171\n",
      "      total_loss: 36.19480895996094\n",
      "      vf_explained_var: 0.9804070591926575\n",
      "      vf_loss: 36.195037841796875\n",
      "    sample_time_ms: 20028.605\n",
      "    update_time_ms: 7.059\n",
      "  iterations_since_restore: 900\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 81.91625257216513\n",
      "    rl_1: 62.90628120793328\n",
      "  time_since_restore: 20856.215415239334\n",
      "  time_this_iter_s: 22.971729516983032\n",
      "  time_total_s: 20856.215415239334\n",
      "  timestamp: 1550901477\n",
      "  timesteps_since_restore: 9000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9000000\n",
      "  training_iteration: 900\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20856 s, 900 iter, 9000000 ts, 145 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-58-20\n",
      "  done: false\n",
      "  episode_len_mean: 111.32\n",
      "  episode_reward_max: 231.69889177404986\n",
      "  episode_reward_mean: 148.3993189605394\n",
      "  episode_reward_min: -171.1928042774217\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 78214\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.446\n",
      "    load_time_ms: 2.135\n",
      "    num_steps_sampled: 9010000\n",
      "    num_steps_trained: 9010000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7103379368782043\n",
      "      kl: 0.02599330060184002\n",
      "      policy_loss: 0.0021784291602671146\n",
      "      total_loss: 33.82071304321289\n",
      "      vf_explained_var: 0.9808394312858582\n",
      "      vf_loss: 33.81853103637695\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6926259994506836\n",
      "      kl: 0.02342638373374939\n",
      "      policy_loss: -0.0011334914015606046\n",
      "      total_loss: 26.371891021728516\n",
      "      vf_explained_var: 0.9822047352790833\n",
      "      vf_loss: 26.373027801513672\n",
      "    sample_time_ms: 19948.851\n",
      "    update_time_ms: 7.021\n",
      "  iterations_since_restore: 901\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 84.60279462010556\n",
      "    rl_1: 63.79652434043383\n",
      "  time_since_restore: 20879.143507242203\n",
      "  time_this_iter_s: 22.928092002868652\n",
      "  time_total_s: 20879.143507242203\n",
      "  timestamp: 1550901500\n",
      "  timesteps_since_restore: 9010000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9010000\n",
      "  training_iteration: 901\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20879 s, 901 iter, 9010000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-58-43\n",
      "  done: false\n",
      "  episode_len_mean: 118.75\n",
      "  episode_reward_max: 231.69889177404986\n",
      "  episode_reward_mean: 167.29429464947344\n",
      "  episode_reward_min: -150.8481959825748\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 78297\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.614\n",
      "    load_time_ms: 2.248\n",
      "    num_steps_sampled: 9020000\n",
      "    num_steps_trained: 9020000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6454805135726929\n",
      "      kl: 0.02988618239760399\n",
      "      policy_loss: 0.0037948584649711847\n",
      "      total_loss: 18.756519317626953\n",
      "      vf_explained_var: 0.9825350642204285\n",
      "      vf_loss: 18.75272560119629\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6132206916809082\n",
      "      kl: 0.023384353145956993\n",
      "      policy_loss: 0.0034424487967044115\n",
      "      total_loss: 16.179828643798828\n",
      "      vf_explained_var: 0.9843807816505432\n",
      "      vf_loss: 16.1763858795166\n",
      "    sample_time_ms: 19950.656\n",
      "    update_time_ms: 6.778\n",
      "  iterations_since_restore: 902\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.2428469089478\n",
      "    rl_1: 71.05144774052569\n",
      "  time_since_restore: 20902.23117852211\n",
      "  time_this_iter_s: 23.087671279907227\n",
      "  time_total_s: 20902.23117852211\n",
      "  timestamp: 1550901523\n",
      "  timesteps_since_restore: 9020000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9020000\n",
      "  training_iteration: 902\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20902 s, 902 iter, 9020000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-59-06\n",
      "  done: false\n",
      "  episode_len_mean: 117.07\n",
      "  episode_reward_max: 235.10348240251597\n",
      "  episode_reward_mean: 165.27703510763294\n",
      "  episode_reward_min: -160.84689548438942\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 78382\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.167\n",
      "    load_time_ms: 2.249\n",
      "    num_steps_sampled: 9030000\n",
      "    num_steps_trained: 9030000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7417919635772705\n",
      "      kl: 0.03823550045490265\n",
      "      policy_loss: 0.00907338410615921\n",
      "      total_loss: 39.314552307128906\n",
      "      vf_explained_var: 0.9683420062065125\n",
      "      vf_loss: 39.305484771728516\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7097718119621277\n",
      "      kl: 0.042209822684526443\n",
      "      policy_loss: 0.0056505948305130005\n",
      "      total_loss: 34.711021423339844\n",
      "      vf_explained_var: 0.9646836519241333\n",
      "      vf_loss: 34.70536422729492\n",
      "    sample_time_ms: 19833.599\n",
      "    update_time_ms: 6.851\n",
      "  iterations_since_restore: 903\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.18644360308491\n",
      "    rl_1: 69.09059150454802\n",
      "  time_since_restore: 20924.53662633896\n",
      "  time_this_iter_s: 22.305447816848755\n",
      "  time_total_s: 20924.53662633896\n",
      "  timestamp: 1550901546\n",
      "  timesteps_since_restore: 9030000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9030000\n",
      "  training_iteration: 903\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20924 s, 903 iter, 9030000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-59-29\n",
      "  done: false\n",
      "  episode_len_mean: 115.29\n",
      "  episode_reward_max: 232.07818744806974\n",
      "  episode_reward_mean: 161.8247024842948\n",
      "  episode_reward_min: -160.84689548438942\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 78469\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3054.452\n",
      "    load_time_ms: 2.224\n",
      "    num_steps_sampled: 9040000\n",
      "    num_steps_trained: 9040000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7482238411903381\n",
      "      kl: 0.04316816106438637\n",
      "      policy_loss: 0.007531194947659969\n",
      "      total_loss: 40.359012603759766\n",
      "      vf_explained_var: 0.9713818430900574\n",
      "      vf_loss: 40.35148239135742\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6399845480918884\n",
      "      kl: 0.34982743859291077\n",
      "      policy_loss: 0.005277554038912058\n",
      "      total_loss: 37.5587043762207\n",
      "      vf_explained_var: 0.9657777547836304\n",
      "      vf_loss: 37.55342483520508\n",
      "    sample_time_ms: 19823.035\n",
      "    update_time_ms: 7.029\n",
      "  iterations_since_restore: 904\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.32021678631108\n",
      "    rl_1: 67.50448569798367\n",
      "  time_since_restore: 20947.583817481995\n",
      "  time_this_iter_s: 23.04719114303589\n",
      "  time_total_s: 20947.583817481995\n",
      "  timestamp: 1550901569\n",
      "  timesteps_since_restore: 9040000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9040000\n",
      "  training_iteration: 904\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20947 s, 904 iter, 9040000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_06-59-52\n",
      "  done: false\n",
      "  episode_len_mean: 113.65\n",
      "  episode_reward_max: 227.92560363711345\n",
      "  episode_reward_mean: 166.67073661350202\n",
      "  episode_reward_min: -163.02654840455466\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 78556\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3050.187\n",
      "    load_time_ms: 2.226\n",
      "    num_steps_sampled: 9050000\n",
      "    num_steps_trained: 9050000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6931370496749878\n",
      "      kl: 0.057595014572143555\n",
      "      policy_loss: 0.006194198504090309\n",
      "      total_loss: 57.25237274169922\n",
      "      vf_explained_var: 0.9555044770240784\n",
      "      vf_loss: 57.24618148803711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6613033413887024\n",
      "      kl: 0.06368853896856308\n",
      "      policy_loss: 0.006624831818044186\n",
      "      total_loss: 47.35479736328125\n",
      "      vf_explained_var: 0.9569342136383057\n",
      "      vf_loss: 47.34817886352539\n",
      "    sample_time_ms: 19829.814\n",
      "    update_time_ms: 6.854\n",
      "  iterations_since_restore: 905\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.6668670236647\n",
      "    rl_1: 72.00386958983728\n",
      "  time_since_restore: 20970.506863355637\n",
      "  time_this_iter_s: 22.923045873641968\n",
      "  time_total_s: 20970.506863355637\n",
      "  timestamp: 1550901592\n",
      "  timesteps_since_restore: 9050000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9050000\n",
      "  training_iteration: 905\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20970 s, 905 iter, 9050000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-00-15\n",
      "  done: false\n",
      "  episode_len_mean: 117.99\n",
      "  episode_reward_max: 222.22247769699422\n",
      "  episode_reward_mean: 155.00895548549394\n",
      "  episode_reward_min: -170.78350001328494\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 78641\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3058.723\n",
      "    load_time_ms: 2.226\n",
      "    num_steps_sampled: 9060000\n",
      "    num_steps_trained: 9060000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6807424426078796\n",
      "      kl: 0.02946135401725769\n",
      "      policy_loss: 0.0037396722473204136\n",
      "      total_loss: 50.025291442871094\n",
      "      vf_explained_var: 0.9532659649848938\n",
      "      vf_loss: 50.02155685424805\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6871722340583801\n",
      "      kl: 0.024427607655525208\n",
      "      policy_loss: 0.0008339922060258687\n",
      "      total_loss: 39.97096252441406\n",
      "      vf_explained_var: 0.9586269855499268\n",
      "      vf_loss: 39.97013473510742\n",
      "    sample_time_ms: 19841.107\n",
      "    update_time_ms: 7.298\n",
      "  iterations_since_restore: 906\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.32069593274062\n",
      "    rl_1: 65.68825955275331\n",
      "  time_since_restore: 20993.823710680008\n",
      "  time_this_iter_s: 23.316847324371338\n",
      "  time_total_s: 20993.823710680008\n",
      "  timestamp: 1550901615\n",
      "  timesteps_since_restore: 9060000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9060000\n",
      "  training_iteration: 906\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 20993 s, 906 iter, 9060000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-00-38\n",
      "  done: false\n",
      "  episode_len_mean: 115.22\n",
      "  episode_reward_max: 231.17940422486978\n",
      "  episode_reward_mean: 147.45647471122172\n",
      "  episode_reward_min: -170.78350001328494\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 78728\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.518\n",
      "    load_time_ms: 2.275\n",
      "    num_steps_sampled: 9070000\n",
      "    num_steps_trained: 9070000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6885074377059937\n",
      "      kl: 0.03342215344309807\n",
      "      policy_loss: 0.00862881913781166\n",
      "      total_loss: 54.28043746948242\n",
      "      vf_explained_var: 0.968277096748352\n",
      "      vf_loss: 54.27181625366211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6892069578170776\n",
      "      kl: 0.01606700010597706\n",
      "      policy_loss: 0.004839867353439331\n",
      "      total_loss: 41.394168853759766\n",
      "      vf_explained_var: 0.9693716764450073\n",
      "      vf_loss: 41.38932800292969\n",
      "    sample_time_ms: 19845.045\n",
      "    update_time_ms: 7.182\n",
      "  iterations_since_restore: 907\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.19425126727687\n",
      "    rl_1: 61.26222344394485\n",
      "  time_since_restore: 21016.88875102997\n",
      "  time_this_iter_s: 23.065040349960327\n",
      "  time_total_s: 21016.88875102997\n",
      "  timestamp: 1550901638\n",
      "  timesteps_since_restore: 9070000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9070000\n",
      "  training_iteration: 907\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21016 s, 907 iter, 9070000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-01-01\n",
      "  done: false\n",
      "  episode_len_mean: 114.64\n",
      "  episode_reward_max: 231.17940422486978\n",
      "  episode_reward_mean: 166.1700184197775\n",
      "  episode_reward_min: -148.6322844321857\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 78815\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.008\n",
      "    load_time_ms: 2.386\n",
      "    num_steps_sampled: 9080000\n",
      "    num_steps_trained: 9080000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7041723132133484\n",
      "      kl: 0.024053439497947693\n",
      "      policy_loss: 0.0046884543262422085\n",
      "      total_loss: 28.7368221282959\n",
      "      vf_explained_var: 0.9729277491569519\n",
      "      vf_loss: 28.73213005065918\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7196467518806458\n",
      "      kl: 0.023530060425400734\n",
      "      policy_loss: -0.002196364803239703\n",
      "      total_loss: 25.810367584228516\n",
      "      vf_explained_var: 0.971062958240509\n",
      "      vf_loss: 25.812562942504883\n",
      "    sample_time_ms: 19814.053\n",
      "    update_time_ms: 7.396\n",
      "  iterations_since_restore: 908\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.87493210915736\n",
      "    rl_1: 71.29508631062012\n",
      "  time_since_restore: 21039.50394177437\n",
      "  time_this_iter_s: 22.615190744400024\n",
      "  time_total_s: 21039.50394177437\n",
      "  timestamp: 1550901661\n",
      "  timesteps_since_restore: 9080000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9080000\n",
      "  training_iteration: 908\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21039 s, 908 iter, 9080000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-01-24\n",
      "  done: false\n",
      "  episode_len_mean: 115.64\n",
      "  episode_reward_max: 228.59253406881774\n",
      "  episode_reward_mean: 162.18651469182632\n",
      "  episode_reward_min: -167.02392303710292\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 78902\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.763\n",
      "    load_time_ms: 2.348\n",
      "    num_steps_sampled: 9090000\n",
      "    num_steps_trained: 9090000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7232446670532227\n",
      "      kl: 0.02127731218934059\n",
      "      policy_loss: 0.00011464943963801488\n",
      "      total_loss: 27.886343002319336\n",
      "      vf_explained_var: 0.9800829887390137\n",
      "      vf_loss: 27.886226654052734\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7197647094726562\n",
      "      kl: 0.021981986239552498\n",
      "      policy_loss: 0.0023438541684299707\n",
      "      total_loss: 25.257015228271484\n",
      "      vf_explained_var: 0.9770230054855347\n",
      "      vf_loss: 25.254671096801758\n",
      "    sample_time_ms: 19837.72\n",
      "    update_time_ms: 7.469\n",
      "  iterations_since_restore: 909\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.0435222771406\n",
      "    rl_1: 68.14299241468566\n",
      "  time_since_restore: 21062.663688659668\n",
      "  time_this_iter_s: 23.159746885299683\n",
      "  time_total_s: 21062.663688659668\n",
      "  timestamp: 1550901684\n",
      "  timesteps_since_restore: 9090000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9090000\n",
      "  training_iteration: 909\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21062 s, 909 iter, 9090000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-01-47\n",
      "  done: false\n",
      "  episode_len_mean: 117.83\n",
      "  episode_reward_max: 231.16121618414383\n",
      "  episode_reward_mean: 161.58505915939358\n",
      "  episode_reward_min: -166.35480503362533\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 78988\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.535\n",
      "    load_time_ms: 2.333\n",
      "    num_steps_sampled: 9100000\n",
      "    num_steps_trained: 9100000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6528252363204956\n",
      "      kl: 0.018004706129431725\n",
      "      policy_loss: -0.0005676396540366113\n",
      "      total_loss: 43.86682891845703\n",
      "      vf_explained_var: 0.9717394709587097\n",
      "      vf_loss: 43.86739730834961\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6799995303153992\n",
      "      kl: 0.024661054834723473\n",
      "      policy_loss: 0.0033462895080447197\n",
      "      total_loss: 32.54428482055664\n",
      "      vf_explained_var: 0.973839282989502\n",
      "      vf_loss: 32.54094314575195\n",
      "    sample_time_ms: 19800.923\n",
      "    update_time_ms: 8.385\n",
      "  iterations_since_restore: 910\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.09735114728335\n",
      "    rl_1: 67.4877080121102\n",
      "  time_since_restore: 21085.29318499565\n",
      "  time_this_iter_s: 22.629496335983276\n",
      "  time_total_s: 21085.29318499565\n",
      "  timestamp: 1550901707\n",
      "  timesteps_since_restore: 9100000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9100000\n",
      "  training_iteration: 910\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21085 s, 910 iter, 9100000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-02-10\n",
      "  done: false\n",
      "  episode_len_mean: 115.77\n",
      "  episode_reward_max: 224.57198092791776\n",
      "  episode_reward_mean: 166.64408989111087\n",
      "  episode_reward_min: -160.3017104012697\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 79073\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.319\n",
      "    load_time_ms: 2.405\n",
      "    num_steps_sampled: 9110000\n",
      "    num_steps_trained: 9110000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7190231680870056\n",
      "      kl: 0.03471533954143524\n",
      "      policy_loss: 0.00793368648737669\n",
      "      total_loss: 15.539536476135254\n",
      "      vf_explained_var: 0.9861264228820801\n",
      "      vf_loss: 15.531603813171387\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7316244840621948\n",
      "      kl: 0.03635208308696747\n",
      "      policy_loss: 0.005210431758314371\n",
      "      total_loss: 13.74167537689209\n",
      "      vf_explained_var: 0.9846916198730469\n",
      "      vf_loss: 13.736467361450195\n",
      "    sample_time_ms: 19774.523\n",
      "    update_time_ms: 8.423\n",
      "  iterations_since_restore: 911\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.78029296206687\n",
      "    rl_1: 70.86379692904401\n",
      "  time_since_restore: 21108.17810368538\n",
      "  time_this_iter_s: 22.884918689727783\n",
      "  time_total_s: 21108.17810368538\n",
      "  timestamp: 1550901730\n",
      "  timesteps_since_restore: 9110000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9110000\n",
      "  training_iteration: 911\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21108 s, 911 iter, 9110000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-02-33\n",
      "  done: false\n",
      "  episode_len_mean: 114.67\n",
      "  episode_reward_max: 226.27157477637698\n",
      "  episode_reward_mean: 157.19400349292152\n",
      "  episode_reward_min: -155.7951459486311\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 79159\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.109\n",
      "    load_time_ms: 2.282\n",
      "    num_steps_sampled: 9120000\n",
      "    num_steps_trained: 9120000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7191484570503235\n",
      "      kl: 0.02701677195727825\n",
      "      policy_loss: 0.004815445281565189\n",
      "      total_loss: 38.859519958496094\n",
      "      vf_explained_var: 0.9755262732505798\n",
      "      vf_loss: 38.85470962524414\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7112641334533691\n",
      "      kl: 0.027534527704119682\n",
      "      policy_loss: 0.0030567627400159836\n",
      "      total_loss: 28.155000686645508\n",
      "      vf_explained_var: 0.9760518074035645\n",
      "      vf_loss: 28.15194320678711\n",
      "    sample_time_ms: 19751.876\n",
      "    update_time_ms: 8.48\n",
      "  iterations_since_restore: 912\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.73746541992399\n",
      "    rl_1: 65.45653807299753\n",
      "  time_since_restore: 21131.05344080925\n",
      "  time_this_iter_s: 22.87533712387085\n",
      "  time_total_s: 21131.05344080925\n",
      "  timestamp: 1550901753\n",
      "  timesteps_since_restore: 9120000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9120000\n",
      "  training_iteration: 912\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21131 s, 912 iter, 9120000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-02-56\n",
      "  done: false\n",
      "  episode_len_mean: 114.44\n",
      "  episode_reward_max: 232.7624208820708\n",
      "  episode_reward_mean: 150.5685831638354\n",
      "  episode_reward_min: -155.8961807616409\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 79246\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.704\n",
      "    load_time_ms: 2.278\n",
      "    num_steps_sampled: 9130000\n",
      "    num_steps_trained: 9130000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6782100796699524\n",
      "      kl: 0.01962919346988201\n",
      "      policy_loss: 6.933433724043425e-06\n",
      "      total_loss: 59.46199417114258\n",
      "      vf_explained_var: 0.9613375663757324\n",
      "      vf_loss: 59.46200180053711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6832644939422607\n",
      "      kl: 0.03518233075737953\n",
      "      policy_loss: 0.01816491410136223\n",
      "      total_loss: 41.41621780395508\n",
      "      vf_explained_var: 0.9672697186470032\n",
      "      vf_loss: 41.39805221557617\n",
      "    sample_time_ms: 19876.471\n",
      "    update_time_ms: 8.351\n",
      "  iterations_since_restore: 913\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.85804903418631\n",
      "    rl_1: 62.710534129649076\n",
      "  time_since_restore: 21154.589069604874\n",
      "  time_this_iter_s: 23.53562879562378\n",
      "  time_total_s: 21154.589069604874\n",
      "  timestamp: 1550901776\n",
      "  timesteps_since_restore: 9130000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9130000\n",
      "  training_iteration: 913\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21154 s, 913 iter, 9130000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-03-20\n",
      "  done: false\n",
      "  episode_len_mean: 117.85\n",
      "  episode_reward_max: 233.74819137605863\n",
      "  episode_reward_mean: 154.60093058313123\n",
      "  episode_reward_min: -167.47048752800066\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 79333\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.886\n",
      "    load_time_ms: 2.334\n",
      "    num_steps_sampled: 9140000\n",
      "    num_steps_trained: 9140000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7085480093955994\n",
      "      kl: 0.032525140792131424\n",
      "      policy_loss: 0.004307427443563938\n",
      "      total_loss: 31.72294807434082\n",
      "      vf_explained_var: 0.9773154854774475\n",
      "      vf_loss: 31.718643188476562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.705636203289032\n",
      "      kl: 0.019234269857406616\n",
      "      policy_loss: 0.0014007389545440674\n",
      "      total_loss: 26.503042221069336\n",
      "      vf_explained_var: 0.9792259335517883\n",
      "      vf_loss: 26.50164031982422\n",
      "    sample_time_ms: 19911.658\n",
      "    update_time_ms: 8.543\n",
      "  iterations_since_restore: 914\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.2655378578079\n",
      "    rl_1: 64.33539272532333\n",
      "  time_since_restore: 21178.012148857117\n",
      "  time_this_iter_s: 23.423079252243042\n",
      "  time_total_s: 21178.012148857117\n",
      "  timestamp: 1550901800\n",
      "  timesteps_since_restore: 9140000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9140000\n",
      "  training_iteration: 914\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21178 s, 914 iter, 9140000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-03-43\n",
      "  done: false\n",
      "  episode_len_mean: 117.59\n",
      "  episode_reward_max: 222.79819101115248\n",
      "  episode_reward_mean: 152.28053685815573\n",
      "  episode_reward_min: -161.8690547235443\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 79419\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3104.653\n",
      "    load_time_ms: 2.357\n",
      "    num_steps_sampled: 9150000\n",
      "    num_steps_trained: 9150000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6320477724075317\n",
      "      kl: 0.02416580729186535\n",
      "      policy_loss: 0.0026460401713848114\n",
      "      total_loss: 29.610401153564453\n",
      "      vf_explained_var: 0.9829060435295105\n",
      "      vf_loss: 29.607757568359375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6430584788322449\n",
      "      kl: 0.01814686879515648\n",
      "      policy_loss: 0.0017653399845585227\n",
      "      total_loss: 26.80988883972168\n",
      "      vf_explained_var: 0.9798277616500854\n",
      "      vf_loss: 26.808124542236328\n",
      "    sample_time_ms: 19914.787\n",
      "    update_time_ms: 8.816\n",
      "  iterations_since_restore: 915\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.84640175993269\n",
      "    rl_1: 62.43413509822304\n",
      "  time_since_restore: 21200.98899292946\n",
      "  time_this_iter_s: 22.97684407234192\n",
      "  time_total_s: 21200.98899292946\n",
      "  timestamp: 1550901823\n",
      "  timesteps_since_restore: 9150000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9150000\n",
      "  training_iteration: 915\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21200 s, 915 iter, 9150000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-04-06\n",
      "  done: false\n",
      "  episode_len_mean: 108.57\n",
      "  episode_reward_max: 227.83719941960442\n",
      "  episode_reward_mean: 149.2737111831739\n",
      "  episode_reward_min: -169.81766025844624\n",
      "  episodes_this_iter: 92\n",
      "  episodes_total: 79511\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3095.428\n",
      "    load_time_ms: 2.383\n",
      "    num_steps_sampled: 9160000\n",
      "    num_steps_trained: 9160000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7480900883674622\n",
      "      kl: 0.03322991728782654\n",
      "      policy_loss: 0.0028760801069438457\n",
      "      total_loss: 73.04246520996094\n",
      "      vf_explained_var: 0.9638746380805969\n",
      "      vf_loss: 73.03958892822266\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7000447511672974\n",
      "      kl: 0.024895695969462395\n",
      "      policy_loss: 0.0007428412791341543\n",
      "      total_loss: 55.24427795410156\n",
      "      vf_explained_var: 0.9689971804618835\n",
      "      vf_loss: 55.243526458740234\n",
      "    sample_time_ms: 19896.254\n",
      "    update_time_ms: 8.399\n",
      "  iterations_since_restore: 916\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.46848056675093\n",
      "    rl_1: 65.80523061642292\n",
      "  time_since_restore: 21224.025682210922\n",
      "  time_this_iter_s: 23.036689281463623\n",
      "  time_total_s: 21224.025682210922\n",
      "  timestamp: 1550901846\n",
      "  timesteps_since_restore: 9160000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9160000\n",
      "  training_iteration: 916\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21224 s, 916 iter, 9160000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-04-29\n",
      "  done: false\n",
      "  episode_len_mean: 115.04\n",
      "  episode_reward_max: 229.19438624513356\n",
      "  episode_reward_mean: 153.2394933769953\n",
      "  episode_reward_min: -170.76911958236155\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 79597\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.732\n",
      "    load_time_ms: 2.375\n",
      "    num_steps_sampled: 9170000\n",
      "    num_steps_trained: 9170000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6796426177024841\n",
      "      kl: 14.57776927947998\n",
      "      policy_loss: 0.08855099231004715\n",
      "      total_loss: 40.15470504760742\n",
      "      vf_explained_var: 0.975340723991394\n",
      "      vf_loss: 40.06615447998047\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6811975836753845\n",
      "      kl: 0.020904984325170517\n",
      "      policy_loss: -0.00040625609108246863\n",
      "      total_loss: 32.35113525390625\n",
      "      vf_explained_var: 0.9759144186973572\n",
      "      vf_loss: 32.351539611816406\n",
      "    sample_time_ms: 19934.973\n",
      "    update_time_ms: 8.334\n",
      "  iterations_since_restore: 917\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.87527563438263\n",
      "    rl_1: 64.3642177426127\n",
      "  time_since_restore: 21247.274770498276\n",
      "  time_this_iter_s: 23.249088287353516\n",
      "  time_total_s: 21247.274770498276\n",
      "  timestamp: 1550901869\n",
      "  timesteps_since_restore: 9170000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9170000\n",
      "  training_iteration: 917\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21247 s, 917 iter, 9170000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-04-52\n",
      "  done: false\n",
      "  episode_len_mean: 116.02\n",
      "  episode_reward_max: 223.76067801244392\n",
      "  episode_reward_mean: 168.86914179702407\n",
      "  episode_reward_min: -114.60543950925398\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 79683\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.696\n",
      "    load_time_ms: 2.275\n",
      "    num_steps_sampled: 9180000\n",
      "    num_steps_trained: 9180000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6673068404197693\n",
      "      kl: 0.016560113057494164\n",
      "      policy_loss: 0.0013189503224566579\n",
      "      total_loss: 10.549989700317383\n",
      "      vf_explained_var: 0.9868844747543335\n",
      "      vf_loss: 10.54867172241211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7199007868766785\n",
      "      kl: 0.017985081300139427\n",
      "      policy_loss: 0.0016496324678882957\n",
      "      total_loss: 9.96701717376709\n",
      "      vf_explained_var: 0.9847360253334045\n",
      "      vf_loss: 9.96536922454834\n",
      "    sample_time_ms: 19977.452\n",
      "    update_time_ms: 8.063\n",
      "  iterations_since_restore: 918\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.17758134968126\n",
      "    rl_1: 70.69156044734282\n",
      "  time_since_restore: 21270.339607477188\n",
      "  time_this_iter_s: 23.064836978912354\n",
      "  time_total_s: 21270.339607477188\n",
      "  timestamp: 1550901892\n",
      "  timesteps_since_restore: 9180000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9180000\n",
      "  training_iteration: 918\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21270 s, 918 iter, 9180000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-05-15\n",
      "  done: false\n",
      "  episode_len_mean: 116.55\n",
      "  episode_reward_max: 229.15560846677567\n",
      "  episode_reward_mean: 159.13832639910504\n",
      "  episode_reward_min: -174.82023897736406\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 79770\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.303\n",
      "    load_time_ms: 2.418\n",
      "    num_steps_sampled: 9190000\n",
      "    num_steps_trained: 9190000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6985421776771545\n",
      "      kl: 0.05256178602576256\n",
      "      policy_loss: 0.004634704906493425\n",
      "      total_loss: 40.16259765625\n",
      "      vf_explained_var: 0.9709437489509583\n",
      "      vf_loss: 40.15796661376953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.759993851184845\n",
      "      kl: 0.040709808468818665\n",
      "      policy_loss: 0.0007187669980339706\n",
      "      total_loss: 30.6823673248291\n",
      "      vf_explained_var: 0.9707924127578735\n",
      "      vf_loss: 30.681644439697266\n",
      "    sample_time_ms: 19965.324\n",
      "    update_time_ms: 8.157\n",
      "  iterations_since_restore: 919\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.91413318938305\n",
      "    rl_1: 65.224193209722\n",
      "  time_since_restore: 21293.37568640709\n",
      "  time_this_iter_s: 23.036078929901123\n",
      "  time_total_s: 21293.37568640709\n",
      "  timestamp: 1550901915\n",
      "  timesteps_since_restore: 9190000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9190000\n",
      "  training_iteration: 919\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21293 s, 919 iter, 9190000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-05-39\n",
      "  done: false\n",
      "  episode_len_mean: 111.04\n",
      "  episode_reward_max: 227.17686932794905\n",
      "  episode_reward_mean: 153.91684387748606\n",
      "  episode_reward_min: -174.82023897736406\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 79859\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.941\n",
      "    load_time_ms: 2.438\n",
      "    num_steps_sampled: 9200000\n",
      "    num_steps_trained: 9200000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7337092757225037\n",
      "      kl: 0.0393659807741642\n",
      "      policy_loss: 0.0043258462101221085\n",
      "      total_loss: 51.73682403564453\n",
      "      vf_explained_var: 0.9714170694351196\n",
      "      vf_loss: 51.73249816894531\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6953458786010742\n",
      "      kl: 0.046582914888858795\n",
      "      policy_loss: 0.005987897049635649\n",
      "      total_loss: 36.23607635498047\n",
      "      vf_explained_var: 0.9778738021850586\n",
      "      vf_loss: 36.23008728027344\n",
      "    sample_time_ms: 19999.519\n",
      "    update_time_ms: 7.253\n",
      "  iterations_since_restore: 920\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.83043589110049\n",
      "    rl_1: 66.08640798638558\n",
      "  time_since_restore: 21316.56449699402\n",
      "  time_this_iter_s: 23.18881058692932\n",
      "  time_total_s: 21316.56449699402\n",
      "  timestamp: 1550901939\n",
      "  timesteps_since_restore: 9200000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9200000\n",
      "  training_iteration: 920\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21316 s, 920 iter, 9200000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-06-02\n",
      "  done: false\n",
      "  episode_len_mean: 110.24\n",
      "  episode_reward_max: 233.14753297689754\n",
      "  episode_reward_mean: 152.60538640537484\n",
      "  episode_reward_min: -177.83546012082056\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 79949\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.692\n",
      "    load_time_ms: 2.358\n",
      "    num_steps_sampled: 9210000\n",
      "    num_steps_trained: 9210000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7533932328224182\n",
      "      kl: 0.025518741458654404\n",
      "      policy_loss: 0.0015725309494882822\n",
      "      total_loss: 44.10022735595703\n",
      "      vf_explained_var: 0.9742727279663086\n",
      "      vf_loss: 44.09864807128906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6985434293746948\n",
      "      kl: 0.02970202825963497\n",
      "      policy_loss: 0.007451919373124838\n",
      "      total_loss: 32.735870361328125\n",
      "      vf_explained_var: 0.9784842133522034\n",
      "      vf_loss: 32.72842025756836\n",
      "    sample_time_ms: 20049.564\n",
      "    update_time_ms: 7.167\n",
      "  iterations_since_restore: 921\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.42200903923569\n",
      "    rl_1: 66.18337736613917\n",
      "  time_since_restore: 21339.78506088257\n",
      "  time_this_iter_s: 23.220563888549805\n",
      "  time_total_s: 21339.78506088257\n",
      "  timestamp: 1550901962\n",
      "  timesteps_since_restore: 9210000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9210000\n",
      "  training_iteration: 921\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21339 s, 921 iter, 9210000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-06-25\n",
      "  done: false\n",
      "  episode_len_mean: 113.38\n",
      "  episode_reward_max: 233.14753297689754\n",
      "  episode_reward_mean: 156.83959256484667\n",
      "  episode_reward_min: -151.48667061811804\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 80037\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3081.888\n",
      "    load_time_ms: 2.36\n",
      "    num_steps_sampled: 9220000\n",
      "    num_steps_trained: 9220000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7501953840255737\n",
      "      kl: 9.601651191711426\n",
      "      policy_loss: 0.08792728185653687\n",
      "      total_loss: 67.49655151367188\n",
      "      vf_explained_var: 0.9589807391166687\n",
      "      vf_loss: 67.40863037109375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7477744817733765\n",
      "      kl: 0.028826208785176277\n",
      "      policy_loss: 0.0004891056451015174\n",
      "      total_loss: 52.108848571777344\n",
      "      vf_explained_var: 0.9607313871383667\n",
      "      vf_loss: 52.108360290527344\n",
      "    sample_time_ms: 20056.32\n",
      "    update_time_ms: 7.072\n",
      "  iterations_since_restore: 922\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.62723018104047\n",
      "    rl_1: 66.21236238380614\n",
      "  time_since_restore: 21362.710354566574\n",
      "  time_this_iter_s: 22.925293684005737\n",
      "  time_total_s: 21362.710354566574\n",
      "  timestamp: 1550901985\n",
      "  timesteps_since_restore: 9220000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9220000\n",
      "  training_iteration: 922\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21362 s, 922 iter, 9220000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-06-48\n",
      "  done: false\n",
      "  episode_len_mean: 107.12\n",
      "  episode_reward_max: 231.34605699825823\n",
      "  episode_reward_mean: 154.93790253975337\n",
      "  episode_reward_min: -158.59570241213652\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 80131\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.994\n",
      "    load_time_ms: 2.358\n",
      "    num_steps_sampled: 9230000\n",
      "    num_steps_trained: 9230000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8368009924888611\n",
      "      kl: 0.033053867518901825\n",
      "      policy_loss: 0.0032955629285424948\n",
      "      total_loss: 40.56167221069336\n",
      "      vf_explained_var: 0.9756157994270325\n",
      "      vf_loss: 40.55837631225586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8159931302070618\n",
      "      kl: 0.03768743574619293\n",
      "      policy_loss: 0.0067186965607106686\n",
      "      total_loss: 35.36606216430664\n",
      "      vf_explained_var: 0.9742984175682068\n",
      "      vf_loss: 35.35934066772461\n",
      "    sample_time_ms: 20010.556\n",
      "    update_time_ms: 7.154\n",
      "  iterations_since_restore: 923\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.85536361638445\n",
      "    rl_1: 66.08253892336887\n",
      "  time_since_restore: 21385.827753782272\n",
      "  time_this_iter_s: 23.117399215698242\n",
      "  time_total_s: 21385.827753782272\n",
      "  timestamp: 1550902008\n",
      "  timesteps_since_restore: 9230000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9230000\n",
      "  training_iteration: 923\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.1/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21385 s, 923 iter, 9230000 ts, 155 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-07-11\n",
      "  done: false\n",
      "  episode_len_mean: 109.17\n",
      "  episode_reward_max: 229.94539437768103\n",
      "  episode_reward_mean: 167.1554736497167\n",
      "  episode_reward_min: -142.08573500922216\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 80221\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.38\n",
      "    load_time_ms: 2.288\n",
      "    num_steps_sampled: 9240000\n",
      "    num_steps_trained: 9240000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7937184572219849\n",
      "      kl: 0.05609309300780296\n",
      "      policy_loss: 0.011460182256996632\n",
      "      total_loss: 32.920982360839844\n",
      "      vf_explained_var: 0.9752490520477295\n",
      "      vf_loss: 32.909523010253906\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.762975811958313\n",
      "      kl: 0.028591103851795197\n",
      "      policy_loss: 0.0008127528708428144\n",
      "      total_loss: 27.606332778930664\n",
      "      vf_explained_var: 0.9743205308914185\n",
      "      vf_loss: 27.605525970458984\n",
      "    sample_time_ms: 19974.864\n",
      "    update_time_ms: 6.776\n",
      "  iterations_since_restore: 924\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.19164317708315\n",
      "    rl_1: 71.9638304726336\n",
      "  time_since_restore: 21408.892969608307\n",
      "  time_this_iter_s: 23.065215826034546\n",
      "  time_total_s: 21408.892969608307\n",
      "  timestamp: 1550902031\n",
      "  timesteps_since_restore: 9240000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9240000\n",
      "  training_iteration: 924\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21408 s, 924 iter, 9240000 ts, 167 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-07-34\n",
      "  done: false\n",
      "  episode_len_mean: 113.92\n",
      "  episode_reward_max: 230.29773991428354\n",
      "  episode_reward_mean: 161.040016596301\n",
      "  episode_reward_min: -140.77632821832967\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 80309\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.243\n",
      "    load_time_ms: 2.277\n",
      "    num_steps_sampled: 9250000\n",
      "    num_steps_trained: 9250000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7005984783172607\n",
      "      kl: 0.027053289115428925\n",
      "      policy_loss: 0.006127328146249056\n",
      "      total_loss: 37.2841682434082\n",
      "      vf_explained_var: 0.976710855960846\n",
      "      vf_loss: 37.27803421020508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7017085552215576\n",
      "      kl: 0.036336906254291534\n",
      "      policy_loss: 0.0010931596625596285\n",
      "      total_loss: 29.67134666442871\n",
      "      vf_explained_var: 0.9745578169822693\n",
      "      vf_loss: 29.670249938964844\n",
      "    sample_time_ms: 19966.316\n",
      "    update_time_ms: 6.663\n",
      "  iterations_since_restore: 925\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.47885412773341\n",
      "    rl_1: 66.56116246856757\n",
      "  time_since_restore: 21431.778834104538\n",
      "  time_this_iter_s: 22.88586449623108\n",
      "  time_total_s: 21431.778834104538\n",
      "  timestamp: 1550902054\n",
      "  timesteps_since_restore: 9250000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9250000\n",
      "  training_iteration: 925\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21431 s, 925 iter, 9250000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-07-57\n",
      "  done: false\n",
      "  episode_len_mean: 106.47\n",
      "  episode_reward_max: 224.0632535650819\n",
      "  episode_reward_mean: 152.48270864234118\n",
      "  episode_reward_min: -172.09991899769489\n",
      "  episodes_this_iter: 94\n",
      "  episodes_total: 80403\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.183\n",
      "    load_time_ms: 2.264\n",
      "    num_steps_sampled: 9260000\n",
      "    num_steps_trained: 9260000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7835494875907898\n",
      "      kl: 0.02920151688158512\n",
      "      policy_loss: 0.0024160712491720915\n",
      "      total_loss: 52.255706787109375\n",
      "      vf_explained_var: 0.9661610126495361\n",
      "      vf_loss: 52.25328826904297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7297975420951843\n",
      "      kl: 0.019841771572828293\n",
      "      policy_loss: 0.0051574851386249065\n",
      "      total_loss: 38.95168685913086\n",
      "      vf_explained_var: 0.9680085778236389\n",
      "      vf_loss: 38.946529388427734\n",
      "    sample_time_ms: 19966.057\n",
      "    update_time_ms: 6.816\n",
      "  iterations_since_restore: 926\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.51377252327384\n",
      "    rl_1: 64.96893611906734\n",
      "  time_since_restore: 21454.81641817093\n",
      "  time_this_iter_s: 23.03758406639099\n",
      "  time_total_s: 21454.81641817093\n",
      "  timestamp: 1550902077\n",
      "  timesteps_since_restore: 9260000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9260000\n",
      "  training_iteration: 926\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21454 s, 926 iter, 9260000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-08-21\n",
      "  done: false\n",
      "  episode_len_mean: 106.21\n",
      "  episode_reward_max: 230.33232165324205\n",
      "  episode_reward_mean: 157.26078539821137\n",
      "  episode_reward_min: -173.26054145583996\n",
      "  episodes_this_iter: 93\n",
      "  episodes_total: 80496\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.5\n",
      "    load_time_ms: 2.305\n",
      "    num_steps_sampled: 9270000\n",
      "    num_steps_trained: 9270000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8349046111106873\n",
      "      kl: 36.14492416381836\n",
      "      policy_loss: 0.10013619810342789\n",
      "      total_loss: 58.26250076293945\n",
      "      vf_explained_var: 0.966752290725708\n",
      "      vf_loss: 58.16236114501953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7690842747688293\n",
      "      kl: 0.09419958293437958\n",
      "      policy_loss: 0.0004974869079887867\n",
      "      total_loss: 47.56334686279297\n",
      "      vf_explained_var: 0.9664828777313232\n",
      "      vf_loss: 47.5628547668457\n",
      "    sample_time_ms: 19978.613\n",
      "    update_time_ms: 6.729\n",
      "  iterations_since_restore: 927\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.40180747051552\n",
      "    rl_1: 67.85897792769578\n",
      "  time_since_restore: 21478.179097890854\n",
      "  time_this_iter_s: 23.362679719924927\n",
      "  time_total_s: 21478.179097890854\n",
      "  timestamp: 1550902101\n",
      "  timesteps_since_restore: 9270000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9270000\n",
      "  training_iteration: 927\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21478 s, 927 iter, 9270000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-08-43\n",
      "  done: false\n",
      "  episode_len_mean: 110.58\n",
      "  episode_reward_max: 234.4125508905321\n",
      "  episode_reward_mean: 158.75372292303663\n",
      "  episode_reward_min: -173.26054145583996\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 80586\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.752\n",
      "    load_time_ms: 2.321\n",
      "    num_steps_sampled: 9280000\n",
      "    num_steps_trained: 9280000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8283810019493103\n",
      "      kl: 0.02947939932346344\n",
      "      policy_loss: 0.0011151243234053254\n",
      "      total_loss: 63.458194732666016\n",
      "      vf_explained_var: 0.964004397392273\n",
      "      vf_loss: 63.45707321166992\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7834469676017761\n",
      "      kl: 0.03589861840009689\n",
      "      policy_loss: 0.002419659635052085\n",
      "      total_loss: 46.07747268676758\n",
      "      vf_explained_var: 0.9686945676803589\n",
      "      vf_loss: 46.07505798339844\n",
      "    sample_time_ms: 19933.187\n",
      "    update_time_ms: 7.231\n",
      "  iterations_since_restore: 928\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.37242242768976\n",
      "    rl_1: 69.38130049534689\n",
      "  time_since_restore: 21500.747829675674\n",
      "  time_this_iter_s: 22.568731784820557\n",
      "  time_total_s: 21500.747829675674\n",
      "  timestamp: 1550902123\n",
      "  timesteps_since_restore: 9280000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9280000\n",
      "  training_iteration: 928\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21500 s, 928 iter, 9280000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-09-06\n",
      "  done: false\n",
      "  episode_len_mean: 114.51\n",
      "  episode_reward_max: 230.3259317218972\n",
      "  episode_reward_mean: 152.78081638175485\n",
      "  episode_reward_min: -157.50051126111998\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 80674\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3080.74\n",
      "    load_time_ms: 2.179\n",
      "    num_steps_sampled: 9290000\n",
      "    num_steps_trained: 9290000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.682412326335907\n",
      "      kl: 0.030709119513630867\n",
      "      policy_loss: 0.005399002227932215\n",
      "      total_loss: 66.25564575195312\n",
      "      vf_explained_var: 0.9627349972724915\n",
      "      vf_loss: 66.25025177001953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6992465853691101\n",
      "      kl: 0.07999507337808609\n",
      "      policy_loss: -0.0009034816757775843\n",
      "      total_loss: 53.17887496948242\n",
      "      vf_explained_var: 0.9642607569694519\n",
      "      vf_loss: 53.17977523803711\n",
      "    sample_time_ms: 19890.85\n",
      "    update_time_ms: 7.117\n",
      "  iterations_since_restore: 929\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.85481625046056\n",
      "    rl_1: 65.92600013129429\n",
      "  time_since_restore: 21523.356374263763\n",
      "  time_this_iter_s: 22.60854458808899\n",
      "  time_total_s: 21523.356374263763\n",
      "  timestamp: 1550902146\n",
      "  timesteps_since_restore: 9290000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9290000\n",
      "  training_iteration: 929\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21523 s, 929 iter, 9290000 ts, 153 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-09-29\n",
      "  done: false\n",
      "  episode_len_mean: 116.89\n",
      "  episode_reward_max: 230.3259317218972\n",
      "  episode_reward_mean: 161.58853990462566\n",
      "  episode_reward_min: -153.19357538763242\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 80759\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3059.808\n",
      "    load_time_ms: 2.17\n",
      "    num_steps_sampled: 9300000\n",
      "    num_steps_trained: 9300000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6054829955101013\n",
      "      kl: 0.026481442153453827\n",
      "      policy_loss: 0.005315123125910759\n",
      "      total_loss: 49.39978790283203\n",
      "      vf_explained_var: 0.9663397073745728\n",
      "      vf_loss: 49.39448165893555\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6173318028450012\n",
      "      kl: 0.07428277283906937\n",
      "      policy_loss: 0.012997118756175041\n",
      "      total_loss: 36.96937942504883\n",
      "      vf_explained_var: 0.968646228313446\n",
      "      vf_loss: 36.95637893676758\n",
      "    sample_time_ms: 19884.337\n",
      "    update_time_ms: 7.114\n",
      "  iterations_since_restore: 930\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.35503078220474\n",
      "    rl_1: 68.23350912242094\n",
      "  time_since_restore: 21546.27063536644\n",
      "  time_this_iter_s: 22.91426110267639\n",
      "  time_total_s: 21546.27063536644\n",
      "  timestamp: 1550902169\n",
      "  timesteps_since_restore: 9300000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9300000\n",
      "  training_iteration: 930\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21546 s, 930 iter, 9300000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-09-51\n",
      "  done: false\n",
      "  episode_len_mean: 115.29\n",
      "  episode_reward_max: 229.9034910416272\n",
      "  episode_reward_mean: 158.84584794081\n",
      "  episode_reward_min: -176.93665120201496\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 80843\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3054.329\n",
      "    load_time_ms: 2.174\n",
      "    num_steps_sampled: 9310000\n",
      "    num_steps_trained: 9310000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7342610359191895\n",
      "      kl: 0.0190564077347517\n",
      "      policy_loss: 0.0032027969136834145\n",
      "      total_loss: 31.6814022064209\n",
      "      vf_explained_var: 0.9776248335838318\n",
      "      vf_loss: 31.678197860717773\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7230066061019897\n",
      "      kl: 0.028310131281614304\n",
      "      policy_loss: 0.007074398919939995\n",
      "      total_loss: 19.091196060180664\n",
      "      vf_explained_var: 0.9830185174942017\n",
      "      vf_loss: 19.084123611450195\n",
      "    sample_time_ms: 19828.668\n",
      "    update_time_ms: 7.19\n",
      "  iterations_since_restore: 931\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.01983460826679\n",
      "    rl_1: 66.82601333254318\n",
      "  time_since_restore: 21568.878885746002\n",
      "  time_this_iter_s: 22.608250379562378\n",
      "  time_total_s: 21568.878885746002\n",
      "  timestamp: 1550902191\n",
      "  timesteps_since_restore: 9310000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9310000\n",
      "  training_iteration: 931\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21568 s, 931 iter, 9310000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-10-15\n",
      "  done: false\n",
      "  episode_len_mean: 115.92\n",
      "  episode_reward_max: 226.16091550707105\n",
      "  episode_reward_mean: 167.96868664095834\n",
      "  episode_reward_min: -167.1111699612669\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 80929\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3071.185\n",
      "    load_time_ms: 2.213\n",
      "    num_steps_sampled: 9320000\n",
      "    num_steps_trained: 9320000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.728644073009491\n",
      "      kl: 0.02189243584871292\n",
      "      policy_loss: 0.001214599353261292\n",
      "      total_loss: 25.03634262084961\n",
      "      vf_explained_var: 0.9807487726211548\n",
      "      vf_loss: 25.035125732421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7591832876205444\n",
      "      kl: 0.02456396445631981\n",
      "      policy_loss: 0.0016278806142508984\n",
      "      total_loss: 21.55924415588379\n",
      "      vf_explained_var: 0.981572687625885\n",
      "      vf_loss: 21.557613372802734\n",
      "    sample_time_ms: 19835.736\n",
      "    update_time_ms: 7.233\n",
      "  iterations_since_restore: 932\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.6091330685893\n",
      "    rl_1: 72.35955357236901\n",
      "  time_since_restore: 21592.044319868088\n",
      "  time_this_iter_s: 23.16543412208557\n",
      "  time_total_s: 21592.044319868088\n",
      "  timestamp: 1550902215\n",
      "  timesteps_since_restore: 9320000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9320000\n",
      "  training_iteration: 932\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21592 s, 932 iter, 9320000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-10-38\n",
      "  done: false\n",
      "  episode_len_mean: 116.24\n",
      "  episode_reward_max: 232.07649411282344\n",
      "  episode_reward_mean: 161.32641785586566\n",
      "  episode_reward_min: -159.98278899062646\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 81016\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.189\n",
      "    load_time_ms: 2.246\n",
      "    num_steps_sampled: 9330000\n",
      "    num_steps_trained: 9330000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7026084661483765\n",
      "      kl: 0.04374763369560242\n",
      "      policy_loss: 0.009982913732528687\n",
      "      total_loss: 45.103790283203125\n",
      "      vf_explained_var: 0.9686977863311768\n",
      "      vf_loss: 45.09379959106445\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.740696370601654\n",
      "      kl: 0.025432845577597618\n",
      "      policy_loss: 0.0014846514677628875\n",
      "      total_loss: 39.31219482421875\n",
      "      vf_explained_var: 0.9658027291297913\n",
      "      vf_loss: 39.31071853637695\n",
      "    sample_time_ms: 19812.159\n",
      "    update_time_ms: 7.217\n",
      "  iterations_since_restore: 933\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.66829006322091\n",
      "    rl_1: 68.65812779264476\n",
      "  time_since_restore: 21615.099519252777\n",
      "  time_this_iter_s: 23.05519938468933\n",
      "  time_total_s: 21615.099519252777\n",
      "  timestamp: 1550902238\n",
      "  timesteps_since_restore: 9330000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9330000\n",
      "  training_iteration: 933\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21615 s, 933 iter, 9330000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-11-00\n",
      "  done: false\n",
      "  episode_len_mean: 119.18\n",
      "  episode_reward_max: 230.03340055434887\n",
      "  episode_reward_mean: 160.70426663344233\n",
      "  episode_reward_min: -154.82369570445027\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 81099\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3087.332\n",
      "    load_time_ms: 2.338\n",
      "    num_steps_sampled: 9340000\n",
      "    num_steps_trained: 9340000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6451942920684814\n",
      "      kl: 0.033662665635347366\n",
      "      policy_loss: 0.006822768598794937\n",
      "      total_loss: 21.865360260009766\n",
      "      vf_explained_var: 0.9837220311164856\n",
      "      vf_loss: 21.858535766601562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6766328811645508\n",
      "      kl: 0.042632658034563065\n",
      "      policy_loss: 0.006721914745867252\n",
      "      total_loss: 16.0240478515625\n",
      "      vf_explained_var: 0.9850656390190125\n",
      "      vf_loss: 16.017330169677734\n",
      "    sample_time_ms: 19762.963\n",
      "    update_time_ms: 7.292\n",
      "  iterations_since_restore: 934\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.71081795521823\n",
      "    rl_1: 65.99344867822408\n",
      "  time_since_restore: 21637.667257785797\n",
      "  time_this_iter_s: 22.56773853302002\n",
      "  time_total_s: 21637.667257785797\n",
      "  timestamp: 1550902260\n",
      "  timesteps_since_restore: 9340000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9340000\n",
      "  training_iteration: 934\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21637 s, 934 iter, 9340000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-11-24\n",
      "  done: false\n",
      "  episode_len_mean: 117.79\n",
      "  episode_reward_max: 235.46432119097884\n",
      "  episode_reward_mean: 155.6694121142213\n",
      "  episode_reward_min: -170.26589783238717\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 81185\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.896\n",
      "    load_time_ms: 2.337\n",
      "    num_steps_sampled: 9350000\n",
      "    num_steps_trained: 9350000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.655349612236023\n",
      "      kl: 0.02243495173752308\n",
      "      policy_loss: 0.0022427700459957123\n",
      "      total_loss: 34.905269622802734\n",
      "      vf_explained_var: 0.977605402469635\n",
      "      vf_loss: 34.90302276611328\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7016128897666931\n",
      "      kl: 0.019542979076504707\n",
      "      policy_loss: 0.0011194911785423756\n",
      "      total_loss: 28.089086532592773\n",
      "      vf_explained_var: 0.9786708354949951\n",
      "      vf_loss: 28.087963104248047\n",
      "    sample_time_ms: 19787.795\n",
      "    update_time_ms: 7.686\n",
      "  iterations_since_restore: 935\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.27661010403796\n",
      "    rl_1: 65.39280201018337\n",
      "  time_since_restore: 21660.822179317474\n",
      "  time_this_iter_s: 23.154921531677246\n",
      "  time_total_s: 21660.822179317474\n",
      "  timestamp: 1550902284\n",
      "  timesteps_since_restore: 9350000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9350000\n",
      "  training_iteration: 935\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21660 s, 935 iter, 9350000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-11-46\n",
      "  done: false\n",
      "  episode_len_mean: 114.62\n",
      "  episode_reward_max: 231.9443736221635\n",
      "  episode_reward_mean: 165.91107496005745\n",
      "  episode_reward_min: -161.2968280738862\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 81272\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3092.604\n",
      "    load_time_ms: 2.414\n",
      "    num_steps_sampled: 9360000\n",
      "    num_steps_trained: 9360000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7405394315719604\n",
      "      kl: 0.04765094444155693\n",
      "      policy_loss: 0.018478257581591606\n",
      "      total_loss: 32.370155334472656\n",
      "      vf_explained_var: 0.976507306098938\n",
      "      vf_loss: 32.35167694091797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.750269889831543\n",
      "      kl: 0.03331954777240753\n",
      "      policy_loss: 0.009576710872352123\n",
      "      total_loss: 22.705488204956055\n",
      "      vf_explained_var: 0.9814271330833435\n",
      "      vf_loss: 22.69590950012207\n",
      "    sample_time_ms: 19769.299\n",
      "    update_time_ms: 7.918\n",
      "  iterations_since_restore: 936\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.47910999831512\n",
      "    rl_1: 71.43196496174231\n",
      "  time_since_restore: 21683.71471095085\n",
      "  time_this_iter_s: 22.892531633377075\n",
      "  time_total_s: 21683.71471095085\n",
      "  timestamp: 1550902306\n",
      "  timesteps_since_restore: 9360000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9360000\n",
      "  training_iteration: 936\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.2/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21683 s, 936 iter, 9360000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-12-09\n",
      "  done: false\n",
      "  episode_len_mean: 114.2\n",
      "  episode_reward_max: 233.20935698202302\n",
      "  episode_reward_mean: 155.6209685928854\n",
      "  episode_reward_min: -165.22142044926403\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 81359\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3110.509\n",
      "    load_time_ms: 2.364\n",
      "    num_steps_sampled: 9370000\n",
      "    num_steps_trained: 9370000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6827836036682129\n",
      "      kl: 0.024663567543029785\n",
      "      policy_loss: 0.0030674333684146404\n",
      "      total_loss: 47.61984634399414\n",
      "      vf_explained_var: 0.9674780368804932\n",
      "      vf_loss: 47.616783142089844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7528911828994751\n",
      "      kl: 0.036642372608184814\n",
      "      policy_loss: 0.012276104651391506\n",
      "      total_loss: 32.03485107421875\n",
      "      vf_explained_var: 0.974339485168457\n",
      "      vf_loss: 32.0225715637207\n",
      "    sample_time_ms: 19695.528\n",
      "    update_time_ms: 8.154\n",
      "  iterations_since_restore: 937\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.61286519045488\n",
      "    rl_1: 67.0081034024305\n",
      "  time_since_restore: 21706.521629333496\n",
      "  time_this_iter_s: 22.806918382644653\n",
      "  time_total_s: 21706.521629333496\n",
      "  timestamp: 1550902329\n",
      "  timesteps_since_restore: 9370000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9370000\n",
      "  training_iteration: 937\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21706 s, 937 iter, 9370000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-12-32\n",
      "  done: false\n",
      "  episode_len_mean: 118.25\n",
      "  episode_reward_max: 233.61589131068894\n",
      "  episode_reward_mean: 156.17559029690017\n",
      "  episode_reward_min: -158.9396939375236\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 81444\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3111.352\n",
      "    load_time_ms: 2.334\n",
      "    num_steps_sampled: 9380000\n",
      "    num_steps_trained: 9380000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5865618586540222\n",
      "      kl: 0.030529135838150978\n",
      "      policy_loss: 0.003651116043329239\n",
      "      total_loss: 52.23400115966797\n",
      "      vf_explained_var: 0.9663993716239929\n",
      "      vf_loss: 52.230350494384766\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6684842109680176\n",
      "      kl: 0.035266198217868805\n",
      "      policy_loss: 0.001940801739692688\n",
      "      total_loss: 46.93595886230469\n",
      "      vf_explained_var: 0.9656413197517395\n",
      "      vf_loss: 46.934017181396484\n",
      "    sample_time_ms: 19749.365\n",
      "    update_time_ms: 7.742\n",
      "  iterations_since_restore: 938\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.06572074738442\n",
      "    rl_1: 66.10986954951575\n",
      "  time_since_restore: 21729.630549669266\n",
      "  time_this_iter_s: 23.108920335769653\n",
      "  time_total_s: 21729.630549669266\n",
      "  timestamp: 1550902352\n",
      "  timesteps_since_restore: 9380000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9380000\n",
      "  training_iteration: 938\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21729 s, 938 iter, 9380000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-12-55\n",
      "  done: false\n",
      "  episode_len_mean: 118.47\n",
      "  episode_reward_max: 236.0069112886071\n",
      "  episode_reward_mean: 151.70178974527255\n",
      "  episode_reward_min: -163.69792508256728\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 81530\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3109.724\n",
      "    load_time_ms: 2.429\n",
      "    num_steps_sampled: 9390000\n",
      "    num_steps_trained: 9390000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6796014904975891\n",
      "      kl: 0.021611662581562996\n",
      "      policy_loss: 0.0015235337195917964\n",
      "      total_loss: 35.45139694213867\n",
      "      vf_explained_var: 0.9763737916946411\n",
      "      vf_loss: 35.44987487792969\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7521156668663025\n",
      "      kl: 0.02712360769510269\n",
      "      policy_loss: 0.001788735156878829\n",
      "      total_loss: 29.47239875793457\n",
      "      vf_explained_var: 0.9752165675163269\n",
      "      vf_loss: 29.470609664916992\n",
      "    sample_time_ms: 19765.302\n",
      "    update_time_ms: 7.752\n",
      "  iterations_since_restore: 939\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.37112431126211\n",
      "    rl_1: 63.33066543401046\n",
      "  time_since_restore: 21752.38589644432\n",
      "  time_this_iter_s: 22.75534677505493\n",
      "  time_total_s: 21752.38589644432\n",
      "  timestamp: 1550902375\n",
      "  timesteps_since_restore: 9390000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9390000\n",
      "  training_iteration: 939\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21752 s, 939 iter, 9390000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-13-18\n",
      "  done: false\n",
      "  episode_len_mean: 118.48\n",
      "  episode_reward_max: 225.02615136968308\n",
      "  episode_reward_mean: 165.2528988657971\n",
      "  episode_reward_min: -138.83819738995692\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 81615\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3109.165\n",
      "    load_time_ms: 2.468\n",
      "    num_steps_sampled: 9400000\n",
      "    num_steps_trained: 9400000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6328341364860535\n",
      "      kl: 0.48623526096343994\n",
      "      policy_loss: 0.027649087831377983\n",
      "      total_loss: 55.74753189086914\n",
      "      vf_explained_var: 0.9555255174636841\n",
      "      vf_loss: 55.71987533569336\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7364165782928467\n",
      "      kl: 0.02819349430501461\n",
      "      policy_loss: 0.00255954940803349\n",
      "      total_loss: 50.62478256225586\n",
      "      vf_explained_var: 0.9534721374511719\n",
      "      vf_loss: 50.622222900390625\n",
      "    sample_time_ms: 19743.433\n",
      "    update_time_ms: 7.751\n",
      "  iterations_since_restore: 940\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.31970982678793\n",
      "    rl_1: 70.93318903900915\n",
      "  time_since_restore: 21775.077456235886\n",
      "  time_this_iter_s: 22.69155979156494\n",
      "  time_total_s: 21775.077456235886\n",
      "  timestamp: 1550902398\n",
      "  timesteps_since_restore: 9400000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9400000\n",
      "  training_iteration: 940\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21775 s, 940 iter, 9400000 ts, 165 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-13-41\n",
      "  done: false\n",
      "  episode_len_mean: 112.02\n",
      "  episode_reward_max: 231.0562984456758\n",
      "  episode_reward_mean: 166.12301150099148\n",
      "  episode_reward_min: -172.0124360095732\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 81704\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3112.564\n",
      "    load_time_ms: 2.471\n",
      "    num_steps_sampled: 9410000\n",
      "    num_steps_trained: 9410000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7553344368934631\n",
      "      kl: 0.02525469660758972\n",
      "      policy_loss: 0.002917990554124117\n",
      "      total_loss: 41.17213439941406\n",
      "      vf_explained_var: 0.969413161277771\n",
      "      vf_loss: 41.16921615600586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8073806166648865\n",
      "      kl: 0.03257739916443825\n",
      "      policy_loss: 0.004966340027749538\n",
      "      total_loss: 36.52507019042969\n",
      "      vf_explained_var: 0.9691529870033264\n",
      "      vf_loss: 36.52010726928711\n",
      "    sample_time_ms: 19758.278\n",
      "    update_time_ms: 8.361\n",
      "  iterations_since_restore: 941\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.01448076155997\n",
      "    rl_1: 73.10853073943152\n",
      "  time_since_restore: 21797.873841047287\n",
      "  time_this_iter_s: 22.796384811401367\n",
      "  time_total_s: 21797.873841047287\n",
      "  timestamp: 1550902421\n",
      "  timesteps_since_restore: 9410000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9410000\n",
      "  training_iteration: 941\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21797 s, 941 iter, 9410000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-14-04\n",
      "  done: false\n",
      "  episode_len_mean: 115.21\n",
      "  episode_reward_max: 234.76557122093064\n",
      "  episode_reward_mean: 162.0283144987514\n",
      "  episode_reward_min: -166.1010005317663\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 81789\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.596\n",
      "    load_time_ms: 2.5\n",
      "    num_steps_sampled: 9420000\n",
      "    num_steps_trained: 9420000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6212039589881897\n",
      "      kl: 0.04062237590551376\n",
      "      policy_loss: 0.006781619507819414\n",
      "      total_loss: 36.925025939941406\n",
      "      vf_explained_var: 0.9709457159042358\n",
      "      vf_loss: 36.91823959350586\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6523904800415039\n",
      "      kl: 0.027227792888879776\n",
      "      policy_loss: -0.0011019433150067925\n",
      "      total_loss: 34.70606994628906\n",
      "      vf_explained_var: 0.9669710993766785\n",
      "      vf_loss: 34.70717239379883\n",
      "    sample_time_ms: 19726.381\n",
      "    update_time_ms: 8.47\n",
      "  iterations_since_restore: 942\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.70819467778931\n",
      "    rl_1: 68.32011982096208\n",
      "  time_since_restore: 21820.57199692726\n",
      "  time_this_iter_s: 22.698155879974365\n",
      "  time_total_s: 21820.57199692726\n",
      "  timestamp: 1550902444\n",
      "  timesteps_since_restore: 9420000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9420000\n",
      "  training_iteration: 942\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21820 s, 942 iter, 9420000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-14-27\n",
      "  done: false\n",
      "  episode_len_mean: 116.86\n",
      "  episode_reward_max: 232.38861541439272\n",
      "  episode_reward_mean: 162.77606996447213\n",
      "  episode_reward_min: -166.1010005317663\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 81874\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.813\n",
      "    load_time_ms: 2.504\n",
      "    num_steps_sampled: 9430000\n",
      "    num_steps_trained: 9430000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6516228318214417\n",
      "      kl: 0.014710996299982071\n",
      "      policy_loss: 0.004514770116657019\n",
      "      total_loss: 39.91609573364258\n",
      "      vf_explained_var: 0.9652454853057861\n",
      "      vf_loss: 39.91157913208008\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7131479382514954\n",
      "      kl: 0.041895028203725815\n",
      "      policy_loss: 0.0025776682887226343\n",
      "      total_loss: 35.53776931762695\n",
      "      vf_explained_var: 0.9616807699203491\n",
      "      vf_loss: 35.53519821166992\n",
      "    sample_time_ms: 19735.173\n",
      "    update_time_ms: 8.694\n",
      "  iterations_since_restore: 943\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.95979989797215\n",
      "    rl_1: 68.8162700665\n",
      "  time_since_restore: 21843.499435424805\n",
      "  time_this_iter_s: 22.927438497543335\n",
      "  time_total_s: 21843.499435424805\n",
      "  timestamp: 1550902467\n",
      "  timesteps_since_restore: 9430000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9430000\n",
      "  training_iteration: 943\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21843 s, 943 iter, 9430000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-14-50\n",
      "  done: false\n",
      "  episode_len_mean: 117.13\n",
      "  episode_reward_max: 229.7164342470285\n",
      "  episode_reward_mean: 149.71249464583025\n",
      "  episode_reward_min: -161.85754939974208\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 81960\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.549\n",
      "    load_time_ms: 2.408\n",
      "    num_steps_sampled: 9440000\n",
      "    num_steps_trained: 9440000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.644206702709198\n",
      "      kl: 0.016791904345154762\n",
      "      policy_loss: 0.0002915129589382559\n",
      "      total_loss: 42.20866012573242\n",
      "      vf_explained_var: 0.9771093726158142\n",
      "      vf_loss: 42.2083740234375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6961988806724548\n",
      "      kl: 0.02367335930466652\n",
      "      policy_loss: 0.0036918246187269688\n",
      "      total_loss: 31.901527404785156\n",
      "      vf_explained_var: 0.978956937789917\n",
      "      vf_loss: 31.8978328704834\n",
      "    sample_time_ms: 19789.135\n",
      "    update_time_ms: 8.571\n",
      "  iterations_since_restore: 944\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.12850068869415\n",
      "    rl_1: 62.58399395713609\n",
      "  time_since_restore: 21866.579899072647\n",
      "  time_this_iter_s: 23.080463647842407\n",
      "  time_total_s: 21866.579899072647\n",
      "  timestamp: 1550902490\n",
      "  timesteps_since_restore: 9440000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9440000\n",
      "  training_iteration: 944\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21866 s, 944 iter, 9440000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-15-13\n",
      "  done: false\n",
      "  episode_len_mean: 110.56\n",
      "  episode_reward_max: 236.71056972065654\n",
      "  episode_reward_mean: 146.66328359151245\n",
      "  episode_reward_min: -150.06804364026732\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 82050\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.167\n",
      "    load_time_ms: 2.413\n",
      "    num_steps_sampled: 9450000\n",
      "    num_steps_trained: 9450000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7228837609291077\n",
      "      kl: 0.05046767741441727\n",
      "      policy_loss: 0.012880063615739346\n",
      "      total_loss: 51.39863204956055\n",
      "      vf_explained_var: 0.9724894762039185\n",
      "      vf_loss: 51.3857421875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7412309050559998\n",
      "      kl: 0.03553548827767372\n",
      "      policy_loss: 0.008725021034479141\n",
      "      total_loss: 43.857704162597656\n",
      "      vf_explained_var: 0.9726349115371704\n",
      "      vf_loss: 43.84897232055664\n",
      "    sample_time_ms: 19748.869\n",
      "    update_time_ms: 8.027\n",
      "  iterations_since_restore: 945\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.37773745325305\n",
      "    rl_1: 63.28554613825945\n",
      "  time_since_restore: 21889.33393239975\n",
      "  time_this_iter_s: 22.75403332710266\n",
      "  time_total_s: 21889.33393239975\n",
      "  timestamp: 1550902513\n",
      "  timesteps_since_restore: 9450000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9450000\n",
      "  training_iteration: 945\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21889 s, 945 iter, 9450000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-15-35\n",
      "  done: false\n",
      "  episode_len_mean: 114.37\n",
      "  episode_reward_max: 226.15066352878026\n",
      "  episode_reward_mean: 138.8973209511425\n",
      "  episode_reward_min: -163.22147985416336\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 82137\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3069.883\n",
      "    load_time_ms: 2.328\n",
      "    num_steps_sampled: 9460000\n",
      "    num_steps_trained: 9460000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6090684533119202\n",
      "      kl: 0.030269885435700417\n",
      "      policy_loss: 0.004831086844205856\n",
      "      total_loss: 41.47916793823242\n",
      "      vf_explained_var: 0.9793394804000854\n",
      "      vf_loss: 41.474334716796875\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7114194631576538\n",
      "      kl: 0.02241874486207962\n",
      "      policy_loss: 0.0014620890142396092\n",
      "      total_loss: 30.81154441833496\n",
      "      vf_explained_var: 0.9824289083480835\n",
      "      vf_loss: 30.810087203979492\n",
      "    sample_time_ms: 19728.633\n",
      "    update_time_ms: 7.696\n",
      "  iterations_since_restore: 946\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 79.85894235760506\n",
      "    rl_1: 59.03837859353744\n",
      "  time_since_restore: 21911.97611618042\n",
      "  time_this_iter_s: 22.642183780670166\n",
      "  time_total_s: 21911.97611618042\n",
      "  timestamp: 1550902535\n",
      "  timesteps_since_restore: 9460000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9460000\n",
      "  training_iteration: 946\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21911 s, 946 iter, 9460000 ts, 139 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-15-58\n",
      "  done: false\n",
      "  episode_len_mean: 118.66\n",
      "  episode_reward_max: 232.30450824009893\n",
      "  episode_reward_mean: 152.09664829272305\n",
      "  episode_reward_min: -163.7030996022863\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 82218\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3053.943\n",
      "    load_time_ms: 2.536\n",
      "    num_steps_sampled: 9470000\n",
      "    num_steps_trained: 9470000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5534140467643738\n",
      "      kl: 0.022514071315526962\n",
      "      policy_loss: 0.005085308104753494\n",
      "      total_loss: 24.198488235473633\n",
      "      vf_explained_var: 0.9836967587471008\n",
      "      vf_loss: 24.193403244018555\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6588488817214966\n",
      "      kl: 0.018869837746024132\n",
      "      policy_loss: -0.0028851220849901438\n",
      "      total_loss: 18.259235382080078\n",
      "      vf_explained_var: 0.9844932556152344\n",
      "      vf_loss: 18.262121200561523\n",
      "    sample_time_ms: 19726.181\n",
      "    update_time_ms: 7.483\n",
      "  iterations_since_restore: 947\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.66714443044299\n",
      "    rl_1: 63.42950386228005\n",
      "  time_since_restore: 21934.60014271736\n",
      "  time_this_iter_s: 22.62402653694153\n",
      "  time_total_s: 21934.60014271736\n",
      "  timestamp: 1550902558\n",
      "  timesteps_since_restore: 9470000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9470000\n",
      "  training_iteration: 947\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21934 s, 947 iter, 9470000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-16-21\n",
      "  done: false\n",
      "  episode_len_mean: 116.87\n",
      "  episode_reward_max: 225.44833059014235\n",
      "  episode_reward_mean: 155.55847706064208\n",
      "  episode_reward_min: -174.5010980138153\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 82305\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3055.608\n",
      "    load_time_ms: 2.578\n",
      "    num_steps_sampled: 9480000\n",
      "    num_steps_trained: 9480000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6600545644760132\n",
      "      kl: 0.019865525886416435\n",
      "      policy_loss: 0.002076289616525173\n",
      "      total_loss: 67.73314666748047\n",
      "      vf_explained_var: 0.9543321132659912\n",
      "      vf_loss: 67.73107147216797\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6626047492027283\n",
      "      kl: 0.029025975614786148\n",
      "      policy_loss: -0.0017732044216245413\n",
      "      total_loss: 48.0865364074707\n",
      "      vf_explained_var: 0.9602925181388855\n",
      "      vf_loss: 48.08831024169922\n",
      "    sample_time_ms: 19768.506\n",
      "    update_time_ms: 7.435\n",
      "  iterations_since_restore: 948\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.78621602157254\n",
      "    rl_1: 63.772261039069534\n",
      "  time_since_restore: 21958.15050625801\n",
      "  time_this_iter_s: 23.550363540649414\n",
      "  time_total_s: 21958.15050625801\n",
      "  timestamp: 1550902581\n",
      "  timesteps_since_restore: 9480000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9480000\n",
      "  training_iteration: 948\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21958 s, 948 iter, 9480000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 119.82\n",
      "  episode_reward_max: 235.17491628295429\n",
      "  episode_reward_mean: 170.76436459445324\n",
      "  episode_reward_min: -149.3793494004367\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 82387\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3056.369\n",
      "    load_time_ms: 2.543\n",
      "    num_steps_sampled: 9490000\n",
      "    num_steps_trained: 9490000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6290079355239868\n",
      "      kl: 0.04333103448152542\n",
      "      policy_loss: 0.012284538708627224\n",
      "      total_loss: 30.206655502319336\n",
      "      vf_explained_var: 0.974164605140686\n",
      "      vf_loss: 30.194374084472656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6737658381462097\n",
      "      kl: 0.03930577263236046\n",
      "      policy_loss: 0.012509399093687534\n",
      "      total_loss: 20.98581886291504\n",
      "      vf_explained_var: 0.9801074266433716\n",
      "      vf_loss: 20.97331428527832\n",
      "    sample_time_ms: 19759.414\n",
      "    update_time_ms: 7.801\n",
      "  iterations_since_restore: 949\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.27425949548393\n",
      "    rl_1: 72.49010509896934\n",
      "  time_since_restore: 21980.826899290085\n",
      "  time_this_iter_s: 22.676393032073975\n",
      "  time_total_s: 21980.826899290085\n",
      "  timestamp: 1550902604\n",
      "  timesteps_since_restore: 9490000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9490000\n",
      "  training_iteration: 949\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 21980 s, 949 iter, 9490000 ts, 171 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-17-07\n",
      "  done: false\n",
      "  episode_len_mean: 117.24\n",
      "  episode_reward_max: 234.5907288224933\n",
      "  episode_reward_mean: 156.19543174567667\n",
      "  episode_reward_min: -159.03644301286738\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 82475\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.228\n",
      "    load_time_ms: 2.558\n",
      "    num_steps_sampled: 9500000\n",
      "    num_steps_trained: 9500000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6740977168083191\n",
      "      kl: 0.014465169981122017\n",
      "      policy_loss: 0.003213347867131233\n",
      "      total_loss: 27.972095489501953\n",
      "      vf_explained_var: 0.9813575744628906\n",
      "      vf_loss: 27.968887329101562\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7379709482192993\n",
      "      kl: 0.03491850942373276\n",
      "      policy_loss: 0.012460581958293915\n",
      "      total_loss: 21.508859634399414\n",
      "      vf_explained_var: 0.9823869466781616\n",
      "      vf_loss: 21.496400833129883\n",
      "    sample_time_ms: 19776.714\n",
      "    update_time_ms: 8.221\n",
      "  iterations_since_restore: 950\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.20776431595708\n",
      "    rl_1: 65.98766742971956\n",
      "  time_since_restore: 22003.881749868393\n",
      "  time_this_iter_s: 23.054850578308105\n",
      "  time_total_s: 22003.881749868393\n",
      "  timestamp: 1550902627\n",
      "  timesteps_since_restore: 9500000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9500000\n",
      "  training_iteration: 950\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22003 s, 950 iter, 9500000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-17-30\n",
      "  done: false\n",
      "  episode_len_mean: 114.64\n",
      "  episode_reward_max: 227.35850892881072\n",
      "  episode_reward_mean: 150.84395441202173\n",
      "  episode_reward_min: -158.2200646261064\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 82563\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.692\n",
      "    load_time_ms: 2.614\n",
      "    num_steps_sampled: 9510000\n",
      "    num_steps_trained: 9510000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7599686980247498\n",
      "      kl: 0.017722008749842644\n",
      "      policy_loss: 0.0007468757103197277\n",
      "      total_loss: 45.05583953857422\n",
      "      vf_explained_var: 0.9776877164840698\n",
      "      vf_loss: 45.055091857910156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7690249085426331\n",
      "      kl: 0.02961266040802002\n",
      "      policy_loss: -0.00025009302771650255\n",
      "      total_loss: 38.70182418823242\n",
      "      vf_explained_var: 0.9754384160041809\n",
      "      vf_loss: 38.70206832885742\n",
      "    sample_time_ms: 19752.881\n",
      "    update_time_ms: 7.546\n",
      "  iterations_since_restore: 951\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.9359069318462\n",
      "    rl_1: 63.90804748017552\n",
      "  time_since_restore: 22026.42152094841\n",
      "  time_this_iter_s: 22.53977108001709\n",
      "  time_total_s: 22026.42152094841\n",
      "  timestamp: 1550902650\n",
      "  timesteps_since_restore: 9510000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9510000\n",
      "  training_iteration: 951\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22026 s, 951 iter, 9510000 ts, 151 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-17-53\n",
      "  done: false\n",
      "  episode_len_mean: 118.02\n",
      "  episode_reward_max: 236.38946352614977\n",
      "  episode_reward_mean: 160.2302734474434\n",
      "  episode_reward_min: -144.39093427378202\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 82645\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.555\n",
      "    load_time_ms: 2.547\n",
      "    num_steps_sampled: 9520000\n",
      "    num_steps_trained: 9520000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6207477450370789\n",
      "      kl: 0.021730294451117516\n",
      "      policy_loss: 0.00595100037753582\n",
      "      total_loss: 18.94451332092285\n",
      "      vf_explained_var: 0.9834086894989014\n",
      "      vf_loss: 18.93856430053711\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6737212538719177\n",
      "      kl: 0.030039601027965546\n",
      "      policy_loss: 0.004458889365196228\n",
      "      total_loss: 15.159552574157715\n",
      "      vf_explained_var: 0.9854269027709961\n",
      "      vf_loss: 15.1550931930542\n",
      "    sample_time_ms: 19764.716\n",
      "    update_time_ms: 7.399\n",
      "  iterations_since_restore: 952\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.75498104270686\n",
      "    rl_1: 68.47529240473658\n",
      "  time_since_restore: 22049.22551369667\n",
      "  time_this_iter_s: 22.803992748260498\n",
      "  time_total_s: 22049.22551369667\n",
      "  timestamp: 1550902673\n",
      "  timesteps_since_restore: 9520000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9520000\n",
      "  training_iteration: 952\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22049 s, 952 iter, 9520000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-18-16\n",
      "  done: false\n",
      "  episode_len_mean: 116.84\n",
      "  episode_reward_max: 236.38946352614977\n",
      "  episode_reward_mean: 162.72630581592963\n",
      "  episode_reward_min: -170.48473021136266\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 82730\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.611\n",
      "    load_time_ms: 2.527\n",
      "    num_steps_sampled: 9530000\n",
      "    num_steps_trained: 9530000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6230191588401794\n",
      "      kl: 0.014588001184165478\n",
      "      policy_loss: 0.0003703960683196783\n",
      "      total_loss: 25.789894104003906\n",
      "      vf_explained_var: 0.9827197194099426\n",
      "      vf_loss: 25.789522171020508\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6232864260673523\n",
      "      kl: 0.013960342854261398\n",
      "      policy_loss: 0.0008781777578406036\n",
      "      total_loss: 18.131507873535156\n",
      "      vf_explained_var: 0.985769510269165\n",
      "      vf_loss: 18.13062858581543\n",
      "    sample_time_ms: 19790.204\n",
      "    update_time_ms: 7.668\n",
      "  iterations_since_restore: 953\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.33709060034464\n",
      "    rl_1: 70.389215215585\n",
      "  time_since_restore: 22072.46868777275\n",
      "  time_this_iter_s: 23.243174076080322\n",
      "  time_total_s: 22072.46868777275\n",
      "  timestamp: 1550902696\n",
      "  timesteps_since_restore: 9530000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9530000\n",
      "  training_iteration: 953\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22072 s, 953 iter, 9530000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-18-39\n",
      "  done: false\n",
      "  episode_len_mean: 119.88\n",
      "  episode_reward_max: 232.76120567890985\n",
      "  episode_reward_mean: 147.59405307583\n",
      "  episode_reward_min: -170.6101418184447\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 82813\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.943\n",
      "    load_time_ms: 2.61\n",
      "    num_steps_sampled: 9540000\n",
      "    num_steps_trained: 9540000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5587500333786011\n",
      "      kl: 0.022783836349844933\n",
      "      policy_loss: 0.0012405890738591552\n",
      "      total_loss: 60.77286148071289\n",
      "      vf_explained_var: 0.9612792730331421\n",
      "      vf_loss: 60.77162170410156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6423259973526001\n",
      "      kl: 0.06488344073295593\n",
      "      policy_loss: -0.005047916434705257\n",
      "      total_loss: 45.1415901184082\n",
      "      vf_explained_var: 0.9678261876106262\n",
      "      vf_loss: 45.14664077758789\n",
      "    sample_time_ms: 19774.43\n",
      "    update_time_ms: 7.673\n",
      "  iterations_since_restore: 954\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.41601069174783\n",
      "    rl_1: 61.178042384082175\n",
      "  time_since_restore: 22095.60700583458\n",
      "  time_this_iter_s: 23.138318061828613\n",
      "  time_total_s: 22095.60700583458\n",
      "  timestamp: 1550902719\n",
      "  timesteps_since_restore: 9540000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9540000\n",
      "  training_iteration: 954\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22095 s, 954 iter, 9540000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-19-02\n",
      "  done: false\n",
      "  episode_len_mean: 120.02\n",
      "  episode_reward_max: 235.30379912525729\n",
      "  episode_reward_mean: 161.973061143262\n",
      "  episode_reward_min: -150.23831202363928\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 82899\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.351\n",
      "    load_time_ms: 2.614\n",
      "    num_steps_sampled: 9550000\n",
      "    num_steps_trained: 9550000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6738044619560242\n",
      "      kl: 0.046835921704769135\n",
      "      policy_loss: 0.0037025879137218\n",
      "      total_loss: 29.75680160522461\n",
      "      vf_explained_var: 0.9763186573982239\n",
      "      vf_loss: 29.753095626831055\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6927397847175598\n",
      "      kl: 0.024446874856948853\n",
      "      policy_loss: 0.0011460077948868275\n",
      "      total_loss: 22.01368522644043\n",
      "      vf_explained_var: 0.9788328409194946\n",
      "      vf_loss: 22.01253890991211\n",
      "    sample_time_ms: 19796.618\n",
      "    update_time_ms: 7.698\n",
      "  iterations_since_restore: 955\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.25500840390623\n",
      "    rl_1: 68.71805273935574\n",
      "  time_since_restore: 22118.587510347366\n",
      "  time_this_iter_s: 22.980504512786865\n",
      "  time_total_s: 22118.587510347366\n",
      "  timestamp: 1550902742\n",
      "  timesteps_since_restore: 9550000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9550000\n",
      "  training_iteration: 955\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22118 s, 955 iter, 9550000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-19-25\n",
      "  done: false\n",
      "  episode_len_mean: 121.51\n",
      "  episode_reward_max: 235.30379912525729\n",
      "  episode_reward_mean: 162.5466557015767\n",
      "  episode_reward_min: -159.18334392810078\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 82981\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3101.499\n",
      "    load_time_ms: 2.665\n",
      "    num_steps_sampled: 9560000\n",
      "    num_steps_trained: 9560000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5859853029251099\n",
      "      kl: 2.5163891315460205\n",
      "      policy_loss: 0.05965747684240341\n",
      "      total_loss: 32.45939254760742\n",
      "      vf_explained_var: 0.9698582887649536\n",
      "      vf_loss: 32.39973831176758\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6405897736549377\n",
      "      kl: 0.023164620622992516\n",
      "      policy_loss: 0.0017320133047178388\n",
      "      total_loss: 22.851863861083984\n",
      "      vf_explained_var: 0.9763819575309753\n",
      "      vf_loss: 22.85013198852539\n",
      "    sample_time_ms: 19813.536\n",
      "    update_time_ms: 7.629\n",
      "  iterations_since_restore: 956\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.5290884127423\n",
      "    rl_1: 67.01756728883443\n",
      "  time_since_restore: 22141.408462762833\n",
      "  time_this_iter_s: 22.82095241546631\n",
      "  time_total_s: 22141.408462762833\n",
      "  timestamp: 1550902765\n",
      "  timesteps_since_restore: 9560000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9560000\n",
      "  training_iteration: 956\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22141 s, 956 iter, 9560000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-19-48\n",
      "  done: false\n",
      "  episode_len_mean: 118.43\n",
      "  episode_reward_max: 233.80807223899507\n",
      "  episode_reward_mean: 160.6850150796126\n",
      "  episode_reward_min: -153.9426602422272\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 83066\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3098.54\n",
      "    load_time_ms: 2.477\n",
      "    num_steps_sampled: 9570000\n",
      "    num_steps_trained: 9570000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5967496037483215\n",
      "      kl: 0.0895453616976738\n",
      "      policy_loss: 0.004406105726957321\n",
      "      total_loss: 28.543155670166016\n",
      "      vf_explained_var: 0.9765986204147339\n",
      "      vf_loss: 28.53874969482422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.657669186592102\n",
      "      kl: 0.04489413648843765\n",
      "      policy_loss: 0.009332181885838509\n",
      "      total_loss: 25.617595672607422\n",
      "      vf_explained_var: 0.9732936024665833\n",
      "      vf_loss: 25.608266830444336\n",
      "    sample_time_ms: 19844.439\n",
      "    update_time_ms: 8.115\n",
      "  iterations_since_restore: 957\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.07502636203742\n",
      "    rl_1: 66.6099887175752\n",
      "  time_since_restore: 22164.314779281616\n",
      "  time_this_iter_s: 22.90631651878357\n",
      "  time_total_s: 22164.314779281616\n",
      "  timestamp: 1550902788\n",
      "  timesteps_since_restore: 9570000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9570000\n",
      "  training_iteration: 957\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22164 s, 957 iter, 9570000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 113.71\n",
      "  episode_reward_max: 233.80807223899507\n",
      "  episode_reward_mean: 148.08091284309808\n",
      "  episode_reward_min: -165.26399815957214\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 83155\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3098.516\n",
      "    load_time_ms: 2.471\n",
      "    num_steps_sampled: 9580000\n",
      "    num_steps_trained: 9580000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6916705965995789\n",
      "      kl: 0.024966290220618248\n",
      "      policy_loss: 0.003665616037324071\n",
      "      total_loss: 55.29016876220703\n",
      "      vf_explained_var: 0.9708364605903625\n",
      "      vf_loss: 55.286521911621094\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6828835606575012\n",
      "      kl: 0.021237745881080627\n",
      "      policy_loss: 0.0034161226358264685\n",
      "      total_loss: 40.59634017944336\n",
      "      vf_explained_var: 0.9730639457702637\n",
      "      vf_loss: 40.59292984008789\n",
      "    sample_time_ms: 19764.923\n",
      "    update_time_ms: 8.252\n",
      "  iterations_since_restore: 958\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.17213958459132\n",
      "    rl_1: 60.90877325850673\n",
      "  time_since_restore: 22187.071313858032\n",
      "  time_this_iter_s: 22.756534576416016\n",
      "  time_total_s: 22187.071313858032\n",
      "  timestamp: 1550902811\n",
      "  timesteps_since_restore: 9580000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9580000\n",
      "  training_iteration: 958\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22187 s, 958 iter, 9580000 ts, 148 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-20-34\n",
      "  done: false\n",
      "  episode_len_mean: 113.75\n",
      "  episode_reward_max: 234.84351695035917\n",
      "  episode_reward_mean: 161.70639611024615\n",
      "  episode_reward_min: -165.26399815957214\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 83241\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3097.465\n",
      "    load_time_ms: 2.442\n",
      "    num_steps_sampled: 9590000\n",
      "    num_steps_trained: 9590000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5953591465950012\n",
      "      kl: 0.025825127959251404\n",
      "      policy_loss: 0.00659024016931653\n",
      "      total_loss: 30.40781593322754\n",
      "      vf_explained_var: 0.9760516285896301\n",
      "      vf_loss: 30.401226043701172\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6406188607215881\n",
      "      kl: 0.028876205906271935\n",
      "      policy_loss: 0.0005546858301386237\n",
      "      total_loss: 26.67515754699707\n",
      "      vf_explained_var: 0.9773710370063782\n",
      "      vf_loss: 26.674604415893555\n",
      "    sample_time_ms: 19784.923\n",
      "    update_time_ms: 7.804\n",
      "  iterations_since_restore: 959\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.69931302527944\n",
      "    rl_1: 69.00708308496671\n",
      "  time_since_restore: 22209.932522773743\n",
      "  time_this_iter_s: 22.86120891571045\n",
      "  time_total_s: 22209.932522773743\n",
      "  timestamp: 1550902834\n",
      "  timesteps_since_restore: 9590000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9590000\n",
      "  training_iteration: 959\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22209 s, 959 iter, 9590000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-20-57\n",
      "  done: false\n",
      "  episode_len_mean: 119.07\n",
      "  episode_reward_max: 228.21689113376462\n",
      "  episode_reward_mean: 172.07695583767156\n",
      "  episode_reward_min: -131.00266499195837\n",
      "  episodes_this_iter: 83\n",
      "  episodes_total: 83324\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.35\n",
      "    load_time_ms: 2.442\n",
      "    num_steps_sampled: 9600000\n",
      "    num_steps_trained: 9600000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5631063580513\n",
      "      kl: 0.021061688661575317\n",
      "      policy_loss: 0.003909769933670759\n",
      "      total_loss: 26.319766998291016\n",
      "      vf_explained_var: 0.975257396697998\n",
      "      vf_loss: 26.315860748291016\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6010932326316833\n",
      "      kl: 0.027554379776120186\n",
      "      policy_loss: 0.00032364725484512746\n",
      "      total_loss: 23.07343864440918\n",
      "      vf_explained_var: 0.9760197401046753\n",
      "      vf_loss: 23.07311248779297\n",
      "    sample_time_ms: 19797.137\n",
      "    update_time_ms: 7.194\n",
      "  iterations_since_restore: 960\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 98.02570836402731\n",
      "    rl_1: 74.0512474736443\n",
      "  time_since_restore: 22232.884707689285\n",
      "  time_this_iter_s: 22.952184915542603\n",
      "  time_total_s: 22232.884707689285\n",
      "  timestamp: 1550902857\n",
      "  timesteps_since_restore: 9600000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9600000\n",
      "  training_iteration: 960\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22232 s, 960 iter, 9600000 ts, 172 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-21-20\n",
      "  done: false\n",
      "  episode_len_mean: 116.45\n",
      "  episode_reward_max: 233.88108799436554\n",
      "  episode_reward_mean: 159.83276635403124\n",
      "  episode_reward_min: -156.0849008632247\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 83410\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3076.147\n",
      "    load_time_ms: 2.376\n",
      "    num_steps_sampled: 9610000\n",
      "    num_steps_trained: 9610000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5708962678909302\n",
      "      kl: 0.03289976343512535\n",
      "      policy_loss: 0.0014694122364744544\n",
      "      total_loss: 31.79521369934082\n",
      "      vf_explained_var: 0.9799020290374756\n",
      "      vf_loss: 31.793739318847656\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6253117918968201\n",
      "      kl: 0.01759336329996586\n",
      "      policy_loss: 0.0010585711570456624\n",
      "      total_loss: 24.68062400817871\n",
      "      vf_explained_var: 0.9816387891769409\n",
      "      vf_loss: 24.679561614990234\n",
      "    sample_time_ms: 19832.896\n",
      "    update_time_ms: 7.308\n",
      "  iterations_since_restore: 961\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.59323090413352\n",
      "    rl_1: 66.23953544989777\n",
      "  time_since_restore: 22255.788508415222\n",
      "  time_this_iter_s: 22.90380072593689\n",
      "  time_total_s: 22255.788508415222\n",
      "  timestamp: 1550902880\n",
      "  timesteps_since_restore: 9610000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9610000\n",
      "  training_iteration: 961\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22255 s, 961 iter, 9610000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-21-42\n",
      "  done: false\n",
      "  episode_len_mean: 112.45\n",
      "  episode_reward_max: 228.01557879430933\n",
      "  episode_reward_mean: 162.02889747191227\n",
      "  episode_reward_min: -161.92515017958806\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 83498\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.201\n",
      "    load_time_ms: 2.38\n",
      "    num_steps_sampled: 9620000\n",
      "    num_steps_trained: 9620000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6297147274017334\n",
      "      kl: 0.02673519030213356\n",
      "      policy_loss: 0.005722703877836466\n",
      "      total_loss: 53.17011642456055\n",
      "      vf_explained_var: 0.961195707321167\n",
      "      vf_loss: 53.16438674926758\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.666475772857666\n",
      "      kl: 0.06625449657440186\n",
      "      policy_loss: 0.00038308239891193807\n",
      "      total_loss: 36.36181640625\n",
      "      vf_explained_var: 0.9699599146842957\n",
      "      vf_loss: 36.36143112182617\n",
      "    sample_time_ms: 19811.166\n",
      "    update_time_ms: 7.557\n",
      "  iterations_since_restore: 962\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.25926692551279\n",
      "    rl_1: 69.76963054639951\n",
      "  time_since_restore: 22278.396494865417\n",
      "  time_this_iter_s: 22.607986450195312\n",
      "  time_total_s: 22278.396494865417\n",
      "  timestamp: 1550902902\n",
      "  timesteps_since_restore: 9620000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9620000\n",
      "  training_iteration: 962\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22278 s, 962 iter, 9620000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-22-05\n",
      "  done: false\n",
      "  episode_len_mean: 117.81\n",
      "  episode_reward_max: 220.51248484634166\n",
      "  episode_reward_mean: 164.49707054818865\n",
      "  episode_reward_min: -155.63962221460477\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 83584\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.795\n",
      "    load_time_ms: 2.371\n",
      "    num_steps_sampled: 9630000\n",
      "    num_steps_trained: 9630000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5994155406951904\n",
      "      kl: 0.02098248340189457\n",
      "      policy_loss: 0.000669632398057729\n",
      "      total_loss: 24.92628288269043\n",
      "      vf_explained_var: 0.9798364639282227\n",
      "      vf_loss: 24.92561149597168\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6454094648361206\n",
      "      kl: 0.020271284505724907\n",
      "      policy_loss: 0.00311296246945858\n",
      "      total_loss: 17.98850440979004\n",
      "      vf_explained_var: 0.9812204241752625\n",
      "      vf_loss: 17.985389709472656\n",
      "    sample_time_ms: 19750.495\n",
      "    update_time_ms: 6.999\n",
      "  iterations_since_restore: 963\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.94223458790785\n",
      "    rl_1: 68.55483596028077\n",
      "  time_since_restore: 22300.983397245407\n",
      "  time_this_iter_s: 22.586902379989624\n",
      "  time_total_s: 22300.983397245407\n",
      "  timestamp: 1550902925\n",
      "  timesteps_since_restore: 9630000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9630000\n",
      "  training_iteration: 963\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22300 s, 963 iter, 9630000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-22-28\n",
      "  done: false\n",
      "  episode_len_mean: 116.63\n",
      "  episode_reward_max: 233.55402283125042\n",
      "  episode_reward_mean: 148.6834042642032\n",
      "  episode_reward_min: -159.9766432923803\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 83671\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3055.185\n",
      "    load_time_ms: 2.37\n",
      "    num_steps_sampled: 9640000\n",
      "    num_steps_trained: 9640000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5940531492233276\n",
      "      kl: 0.022249160334467888\n",
      "      policy_loss: -0.0007156137144193053\n",
      "      total_loss: 39.41304016113281\n",
      "      vf_explained_var: 0.9790327548980713\n",
      "      vf_loss: 39.41374969482422\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.635243833065033\n",
      "      kl: 0.036300718784332275\n",
      "      policy_loss: -0.00040690170135349035\n",
      "      total_loss: 30.093875885009766\n",
      "      vf_explained_var: 0.9806554913520813\n",
      "      vf_loss: 30.094282150268555\n",
      "    sample_time_ms: 19748.629\n",
      "    update_time_ms: 7.135\n",
      "  iterations_since_restore: 964\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 86.66409351301495\n",
      "    rl_1: 62.01931075118827\n",
      "  time_since_restore: 22323.917735099792\n",
      "  time_this_iter_s: 22.934337854385376\n",
      "  time_total_s: 22323.917735099792\n",
      "  timestamp: 1550902948\n",
      "  timesteps_since_restore: 9640000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9640000\n",
      "  training_iteration: 964\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22323 s, 964 iter, 9640000 ts, 149 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-22-51\n",
      "  done: false\n",
      "  episode_len_mean: 110.13\n",
      "  episode_reward_max: 233.55402283125042\n",
      "  episode_reward_mean: 158.8719150323513\n",
      "  episode_reward_min: -167.91624340215446\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 83760\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3051.478\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 9650000\n",
      "    num_steps_trained: 9650000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6931700706481934\n",
      "      kl: 0.025412920862436295\n",
      "      policy_loss: 0.00028111939900554717\n",
      "      total_loss: 57.61147689819336\n",
      "      vf_explained_var: 0.9610660076141357\n",
      "      vf_loss: 57.611202239990234\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.711704432964325\n",
      "      kl: 0.029874764382839203\n",
      "      policy_loss: 0.0013698795810341835\n",
      "      total_loss: 42.18677520751953\n",
      "      vf_explained_var: 0.9651532173156738\n",
      "      vf_loss: 42.18540954589844\n",
      "    sample_time_ms: 19759.255\n",
      "    update_time_ms: 7.095\n",
      "  iterations_since_restore: 965\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.07060107883322\n",
      "    rl_1: 67.80131395351809\n",
      "  time_since_restore: 22346.96618127823\n",
      "  time_this_iter_s: 23.04844617843628\n",
      "  time_total_s: 22346.96618127823\n",
      "  timestamp: 1550902971\n",
      "  timesteps_since_restore: 9650000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9650000\n",
      "  training_iteration: 965\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22346 s, 965 iter, 9650000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-23-14\n",
      "  done: false\n",
      "  episode_len_mean: 112.74\n",
      "  episode_reward_max: 233.67870723200147\n",
      "  episode_reward_mean: 152.10378993691995\n",
      "  episode_reward_min: -170.1295783185293\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 83850\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3053.188\n",
      "    load_time_ms: 2.383\n",
      "    num_steps_sampled: 9660000\n",
      "    num_steps_trained: 9660000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7223195433616638\n",
      "      kl: 0.024397622793912888\n",
      "      policy_loss: 0.0036658686585724354\n",
      "      total_loss: 42.41934585571289\n",
      "      vf_explained_var: 0.9747148156166077\n",
      "      vf_loss: 42.415679931640625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7403388619422913\n",
      "      kl: 0.031013546511530876\n",
      "      policy_loss: 0.006683647632598877\n",
      "      total_loss: 31.78281593322754\n",
      "      vf_explained_var: 0.9761335849761963\n",
      "      vf_loss: 31.776126861572266\n",
      "    sample_time_ms: 19747.813\n",
      "    update_time_ms: 7.192\n",
      "  iterations_since_restore: 966\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.90621141170779\n",
      "    rl_1: 63.19757852521213\n",
      "  time_since_restore: 22369.690061330795\n",
      "  time_this_iter_s: 22.72388005256653\n",
      "  time_total_s: 22369.690061330795\n",
      "  timestamp: 1550902994\n",
      "  timesteps_since_restore: 9660000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9660000\n",
      "  training_iteration: 966\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22369 s, 966 iter, 9660000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-23-36\n",
      "  done: false\n",
      "  episode_len_mean: 109.82\n",
      "  episode_reward_max: 233.67870723200147\n",
      "  episode_reward_mean: 143.48723543649007\n",
      "  episode_reward_min: -170.3709822403724\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 83941\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3054.237\n",
      "    load_time_ms: 2.338\n",
      "    num_steps_sampled: 9670000\n",
      "    num_steps_trained: 9670000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7116122245788574\n",
      "      kl: 0.01965482160449028\n",
      "      policy_loss: 0.0030182963237166405\n",
      "      total_loss: 44.07613754272461\n",
      "      vf_explained_var: 0.9809058904647827\n",
      "      vf_loss: 44.07311248779297\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.704698920249939\n",
      "      kl: 0.015097181312739849\n",
      "      policy_loss: 0.0002683787024579942\n",
      "      total_loss: 36.18590545654297\n",
      "      vf_explained_var: 0.9818127155303955\n",
      "      vf_loss: 36.185638427734375\n",
      "    sample_time_ms: 19711.99\n",
      "    update_time_ms: 6.687\n",
      "  iterations_since_restore: 967\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.03417241507199\n",
      "    rl_1: 60.45306302141805\n",
      "  time_since_restore: 22392.244022607803\n",
      "  time_this_iter_s: 22.553961277008057\n",
      "  time_total_s: 22392.244022607803\n",
      "  timestamp: 1550903016\n",
      "  timesteps_since_restore: 9670000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9670000\n",
      "  training_iteration: 967\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22392 s, 967 iter, 9670000 ts, 143 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-23-59\n",
      "  done: false\n",
      "  episode_len_mean: 115.92\n",
      "  episode_reward_max: 227.6869136872476\n",
      "  episode_reward_mean: 158.16867073791727\n",
      "  episode_reward_min: -170.3709822403724\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 84028\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3054.325\n",
      "    load_time_ms: 2.306\n",
      "    num_steps_sampled: 9680000\n",
      "    num_steps_trained: 9680000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6929535269737244\n",
      "      kl: 0.03708382323384285\n",
      "      policy_loss: 0.0028590394649654627\n",
      "      total_loss: 29.259824752807617\n",
      "      vf_explained_var: 0.9774398803710938\n",
      "      vf_loss: 29.2569637298584\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7004981637001038\n",
      "      kl: 0.020478321239352226\n",
      "      policy_loss: 0.0022123674862086773\n",
      "      total_loss: 24.94415855407715\n",
      "      vf_explained_var: 0.9738006591796875\n",
      "      vf_loss: 24.941946029663086\n",
      "    sample_time_ms: 19706.448\n",
      "    update_time_ms: 7.357\n",
      "  iterations_since_restore: 968\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.06822293999123\n",
      "    rl_1: 65.10044779792605\n",
      "  time_since_restore: 22414.950795412064\n",
      "  time_this_iter_s: 22.706772804260254\n",
      "  time_total_s: 22414.950795412064\n",
      "  timestamp: 1550903039\n",
      "  timesteps_since_restore: 9680000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9680000\n",
      "  training_iteration: 968\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22414 s, 968 iter, 9680000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-24-22\n",
      "  done: false\n",
      "  episode_len_mean: 115.16\n",
      "  episode_reward_max: 232.64403420541527\n",
      "  episode_reward_mean: 168.40466667279995\n",
      "  episode_reward_min: -173.52781326148744\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 84115\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3054.869\n",
      "    load_time_ms: 2.29\n",
      "    num_steps_sampled: 9690000\n",
      "    num_steps_trained: 9690000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6745967864990234\n",
      "      kl: 0.02455892600119114\n",
      "      policy_loss: 0.0042375982739031315\n",
      "      total_loss: 24.106067657470703\n",
      "      vf_explained_var: 0.9809541702270508\n",
      "      vf_loss: 24.10182762145996\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7057218551635742\n",
      "      kl: 0.018670540302991867\n",
      "      policy_loss: -0.0027659889310598373\n",
      "      total_loss: 18.802091598510742\n",
      "      vf_explained_var: 0.9829647541046143\n",
      "      vf_loss: 18.80485725402832\n",
      "    sample_time_ms: 19739.379\n",
      "    update_time_ms: 7.36\n",
      "  iterations_since_restore: 969\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.08094291221862\n",
      "    rl_1: 71.32372376058134\n",
      "  time_since_restore: 22438.144516944885\n",
      "  time_this_iter_s: 23.193721532821655\n",
      "  time_total_s: 22438.144516944885\n",
      "  timestamp: 1550903062\n",
      "  timesteps_since_restore: 9690000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9690000\n",
      "  training_iteration: 969\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22438 s, 969 iter, 9690000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-24-45\n",
      "  done: false\n",
      "  episode_len_mean: 116.92\n",
      "  episode_reward_max: 232.64403420541527\n",
      "  episode_reward_mean: 157.29885193768115\n",
      "  episode_reward_min: -148.82544752754063\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 84199\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3057.227\n",
      "    load_time_ms: 2.282\n",
      "    num_steps_sampled: 9700000\n",
      "    num_steps_trained: 9700000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6060718297958374\n",
      "      kl: 7.413862228393555\n",
      "      policy_loss: 0.07099992781877518\n",
      "      total_loss: 35.20161819458008\n",
      "      vf_explained_var: 0.9776021242141724\n",
      "      vf_loss: 35.13062286376953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6687198281288147\n",
      "      kl: 0.03075508587062359\n",
      "      policy_loss: 0.006322561763226986\n",
      "      total_loss: 29.872676849365234\n",
      "      vf_explained_var: 0.9788346886634827\n",
      "      vf_loss: 29.86635398864746\n",
      "    sample_time_ms: 19742.712\n",
      "    update_time_ms: 7.74\n",
      "  iterations_since_restore: 970\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.13694027844282\n",
      "    rl_1: 66.16191165923834\n",
      "  time_since_restore: 22461.1554312706\n",
      "  time_this_iter_s: 23.01091432571411\n",
      "  time_total_s: 22461.1554312706\n",
      "  timestamp: 1550903085\n",
      "  timesteps_since_restore: 9700000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9700000\n",
      "  training_iteration: 970\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22461 s, 970 iter, 9700000 ts, 157 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-25-08\n",
      "  done: false\n",
      "  episode_len_mean: 113.13\n",
      "  episode_reward_max: 234.94145552199183\n",
      "  episode_reward_mean: 158.67680998157542\n",
      "  episode_reward_min: -170.21777864752735\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 84287\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.807\n",
      "    load_time_ms: 2.292\n",
      "    num_steps_sampled: 9710000\n",
      "    num_steps_trained: 9710000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6947401165962219\n",
      "      kl: 0.02343299426138401\n",
      "      policy_loss: 0.00403269287198782\n",
      "      total_loss: 42.652400970458984\n",
      "      vf_explained_var: 0.9751768112182617\n",
      "      vf_loss: 42.64836120605469\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7182469367980957\n",
      "      kl: 0.018223391845822334\n",
      "      policy_loss: -0.0004202578857075423\n",
      "      total_loss: 32.48905563354492\n",
      "      vf_explained_var: 0.9776007533073425\n",
      "      vf_loss: 32.489479064941406\n",
      "    sample_time_ms: 19681.181\n",
      "    update_time_ms: 7.667\n",
      "  iterations_since_restore: 971\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.81164223337316\n",
      "    rl_1: 67.86516774820225\n",
      "  time_since_restore: 22483.64984726906\n",
      "  time_this_iter_s: 22.494415998458862\n",
      "  time_total_s: 22483.64984726906\n",
      "  timestamp: 1550903108\n",
      "  timesteps_since_restore: 9710000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9710000\n",
      "  training_iteration: 971\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22483 s, 971 iter, 9710000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-25-31\n",
      "  done: false\n",
      "  episode_len_mean: 115.11\n",
      "  episode_reward_max: 235.9785800834205\n",
      "  episode_reward_mean: 169.4432982679915\n",
      "  episode_reward_min: -168.98982863357907\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 84375\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.885\n",
      "    load_time_ms: 2.399\n",
      "    num_steps_sampled: 9720000\n",
      "    num_steps_trained: 9720000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.700361430644989\n",
      "      kl: 0.027631115168333054\n",
      "      policy_loss: 0.0055096335709095\n",
      "      total_loss: 37.935176849365234\n",
      "      vf_explained_var: 0.9732313752174377\n",
      "      vf_loss: 37.929664611816406\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.742806613445282\n",
      "      kl: 0.01787392795085907\n",
      "      policy_loss: 0.0035258608404546976\n",
      "      total_loss: 34.02717971801758\n",
      "      vf_explained_var: 0.9736061096191406\n",
      "      vf_loss: 34.02365493774414\n",
      "    sample_time_ms: 19685.634\n",
      "    update_time_ms: 7.665\n",
      "  iterations_since_restore: 972\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 95.783087379654\n",
      "    rl_1: 73.66021088833753\n",
      "  time_since_restore: 22506.275499105453\n",
      "  time_this_iter_s: 22.625651836395264\n",
      "  time_total_s: 22506.275499105453\n",
      "  timestamp: 1550903131\n",
      "  timesteps_since_restore: 9720000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9720000\n",
      "  training_iteration: 972\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22506 s, 972 iter, 9720000 ts, 169 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-25-54\n",
      "  done: false\n",
      "  episode_len_mean: 116.97\n",
      "  episode_reward_max: 231.33822398296417\n",
      "  episode_reward_mean: 162.45571939069373\n",
      "  episode_reward_min: -167.4641984487011\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 84460\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3075.868\n",
      "    load_time_ms: 2.405\n",
      "    num_steps_sampled: 9730000\n",
      "    num_steps_trained: 9730000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6503313779830933\n",
      "      kl: 0.02663312293589115\n",
      "      policy_loss: 0.002285221591591835\n",
      "      total_loss: 50.24837112426758\n",
      "      vf_explained_var: 0.9658842086791992\n",
      "      vf_loss: 50.24608612060547\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7016981840133667\n",
      "      kl: 0.0615500845015049\n",
      "      policy_loss: 0.01479526050388813\n",
      "      total_loss: 37.026859283447266\n",
      "      vf_explained_var: 0.9704610109329224\n",
      "      vf_loss: 37.012062072753906\n",
      "    sample_time_ms: 19735.331\n",
      "    update_time_ms: 7.689\n",
      "  iterations_since_restore: 973\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.6035612082901\n",
      "    rl_1: 68.85215818240361\n",
      "  time_since_restore: 22529.371989250183\n",
      "  time_this_iter_s: 23.096490144729614\n",
      "  time_total_s: 22529.371989250183\n",
      "  timestamp: 1550903154\n",
      "  timesteps_since_restore: 9730000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9730000\n",
      "  training_iteration: 973\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22529 s, 973 iter, 9730000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-26-17\n",
      "  done: false\n",
      "  episode_len_mean: 110.51\n",
      "  episode_reward_max: 218.90950886517317\n",
      "  episode_reward_mean: 162.05594258574703\n",
      "  episode_reward_min: -171.72048978379854\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 84550\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3079.968\n",
      "    load_time_ms: 2.362\n",
      "    num_steps_sampled: 9740000\n",
      "    num_steps_trained: 9740000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7239809036254883\n",
      "      kl: 0.02905878610908985\n",
      "      policy_loss: 0.0019043070496991277\n",
      "      total_loss: 27.31253433227539\n",
      "      vf_explained_var: 0.980391263961792\n",
      "      vf_loss: 27.310630798339844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7414630651473999\n",
      "      kl: 0.034350935369729996\n",
      "      policy_loss: 0.002139065181836486\n",
      "      total_loss: 23.091981887817383\n",
      "      vf_explained_var: 0.9785792231559753\n",
      "      vf_loss: 23.08984375\n",
      "    sample_time_ms: 19782.175\n",
      "    update_time_ms: 7.853\n",
      "  iterations_since_restore: 974\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.93039921761492\n",
      "    rl_1: 69.12554336813209\n",
      "  time_since_restore: 22552.817150592804\n",
      "  time_this_iter_s: 23.44516134262085\n",
      "  time_total_s: 22552.817150592804\n",
      "  timestamp: 1550903177\n",
      "  timesteps_since_restore: 9740000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9740000\n",
      "  training_iteration: 974\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22552 s, 974 iter, 9740000 ts, 162 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-26-40\n",
      "  done: false\n",
      "  episode_len_mean: 111.88\n",
      "  episode_reward_max: 229.06389648916527\n",
      "  episode_reward_mean: 159.7009152178952\n",
      "  episode_reward_min: -176.88223698218934\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 84639\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.533\n",
      "    load_time_ms: 2.287\n",
      "    num_steps_sampled: 9750000\n",
      "    num_steps_trained: 9750000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6445721983909607\n",
      "      kl: 0.0190420001745224\n",
      "      policy_loss: 0.005384942051023245\n",
      "      total_loss: 34.44535446166992\n",
      "      vf_explained_var: 0.9748484492301941\n",
      "      vf_loss: 34.439964294433594\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6984973549842834\n",
      "      kl: 0.012614277191460133\n",
      "      policy_loss: 0.0006968596135266125\n",
      "      total_loss: 26.638275146484375\n",
      "      vf_explained_var: 0.9794645309448242\n",
      "      vf_loss: 26.637577056884766\n",
      "    sample_time_ms: 19757.8\n",
      "    update_time_ms: 8.024\n",
      "  iterations_since_restore: 975\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.22557023683626\n",
      "    rl_1: 70.4753449810589\n",
      "  time_since_restore: 22575.667757987976\n",
      "  time_this_iter_s: 22.85060739517212\n",
      "  time_total_s: 22575.667757987976\n",
      "  timestamp: 1550903200\n",
      "  timesteps_since_restore: 9750000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9750000\n",
      "  training_iteration: 975\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22575 s, 975 iter, 9750000 ts, 160 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-27-03\n",
      "  done: false\n",
      "  episode_len_mean: 120.19\n",
      "  episode_reward_max: 230.84180179805284\n",
      "  episode_reward_mean: 163.59789452369807\n",
      "  episode_reward_min: -176.88223698218934\n",
      "  episodes_this_iter: 82\n",
      "  episodes_total: 84721\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3084.979\n",
      "    load_time_ms: 2.371\n",
      "    num_steps_sampled: 9760000\n",
      "    num_steps_trained: 9760000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5863103866577148\n",
      "      kl: 0.03370102494955063\n",
      "      policy_loss: 0.007056291215121746\n",
      "      total_loss: 26.550350189208984\n",
      "      vf_explained_var: 0.97691410779953\n",
      "      vf_loss: 26.543296813964844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6928206086158752\n",
      "      kl: 0.021768653765320778\n",
      "      policy_loss: 0.0031679333187639713\n",
      "      total_loss: 21.80708122253418\n",
      "      vf_explained_var: 0.9777329564094543\n",
      "      vf_loss: 21.803911209106445\n",
      "    sample_time_ms: 19766.619\n",
      "    update_time_ms: 7.932\n",
      "  iterations_since_restore: 976\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 94.59386271873745\n",
      "    rl_1: 69.00403180496066\n",
      "  time_since_restore: 22598.48530602455\n",
      "  time_this_iter_s: 22.817548036575317\n",
      "  time_total_s: 22598.48530602455\n",
      "  timestamp: 1550903223\n",
      "  timesteps_since_restore: 9760000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9760000\n",
      "  training_iteration: 976\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22598 s, 976 iter, 9760000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-27-27\n",
      "  done: false\n",
      "  episode_len_mean: 111.5\n",
      "  episode_reward_max: 231.45961345283203\n",
      "  episode_reward_mean: 166.39703821208184\n",
      "  episode_reward_min: -125.92334033286598\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 84811\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3088.122\n",
      "    load_time_ms: 2.424\n",
      "    num_steps_sampled: 9770000\n",
      "    num_steps_trained: 9770000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7294831275939941\n",
      "      kl: 0.0396537259221077\n",
      "      policy_loss: 0.005350709892809391\n",
      "      total_loss: 44.211830139160156\n",
      "      vf_explained_var: 0.9702174067497253\n",
      "      vf_loss: 44.20648193359375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7434048056602478\n",
      "      kl: 0.04531171917915344\n",
      "      policy_loss: 0.0037018770817667246\n",
      "      total_loss: 38.89570236206055\n",
      "      vf_explained_var: 0.9676708579063416\n",
      "      vf_loss: 38.89200210571289\n",
      "    sample_time_ms: 19874.574\n",
      "    update_time_ms: 8.044\n",
      "  iterations_since_restore: 977\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.60638065888739\n",
      "    rl_1: 72.79065755319446\n",
      "  time_since_restore: 22622.15008163452\n",
      "  time_this_iter_s: 23.664775609970093\n",
      "  time_total_s: 22622.15008163452\n",
      "  timestamp: 1550903247\n",
      "  timesteps_since_restore: 9770000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9770000\n",
      "  training_iteration: 977\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22622 s, 977 iter, 9770000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-27-50\n",
      "  done: false\n",
      "  episode_len_mean: 114.12\n",
      "  episode_reward_max: 231.67615078282319\n",
      "  episode_reward_mean: 160.96208160428512\n",
      "  episode_reward_min: -146.0066225288738\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 84899\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.872\n",
      "    load_time_ms: 2.491\n",
      "    num_steps_sampled: 9780000\n",
      "    num_steps_trained: 9780000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6505786180496216\n",
      "      kl: 0.03850273787975311\n",
      "      policy_loss: 0.00645432947203517\n",
      "      total_loss: 30.7598819732666\n",
      "      vf_explained_var: 0.9801585674285889\n",
      "      vf_loss: 30.75343132019043\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7186616063117981\n",
      "      kl: 0.06906500458717346\n",
      "      policy_loss: 0.014761087484657764\n",
      "      total_loss: 26.2313289642334\n",
      "      vf_explained_var: 0.9789462685585022\n",
      "      vf_loss: 26.216569900512695\n",
      "    sample_time_ms: 19883.9\n",
      "    update_time_ms: 7.308\n",
      "  iterations_since_restore: 978\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.71781207218187\n",
      "    rl_1: 68.24426953210323\n",
      "  time_since_restore: 22644.96382212639\n",
      "  time_this_iter_s: 22.813740491867065\n",
      "  time_total_s: 22644.96382212639\n",
      "  timestamp: 1550903270\n",
      "  timesteps_since_restore: 9780000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9780000\n",
      "  training_iteration: 978\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22644 s, 978 iter, 9780000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-28-13\n",
      "  done: false\n",
      "  episode_len_mean: 111.23\n",
      "  episode_reward_max: 231.07875213089312\n",
      "  episode_reward_mean: 160.58911347841152\n",
      "  episode_reward_min: -165.41976432268012\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 84988\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3100.093\n",
      "    load_time_ms: 2.51\n",
      "    num_steps_sampled: 9790000\n",
      "    num_steps_trained: 9790000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7232145667076111\n",
      "      kl: 0.026343492791056633\n",
      "      policy_loss: 0.006482097785919905\n",
      "      total_loss: 40.04459762573242\n",
      "      vf_explained_var: 0.9723328948020935\n",
      "      vf_loss: 40.038116455078125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7646145224571228\n",
      "      kl: 0.03689682111144066\n",
      "      policy_loss: 0.00980405043810606\n",
      "      total_loss: 34.09292221069336\n",
      "      vf_explained_var: 0.972866952419281\n",
      "      vf_loss: 34.08312225341797\n",
      "    sample_time_ms: 19842.152\n",
      "    update_time_ms: 7.668\n",
      "  iterations_since_restore: 979\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.78259854364006\n",
      "    rl_1: 69.80651493477144\n",
      "  time_since_restore: 22667.84719967842\n",
      "  time_this_iter_s: 22.88337755203247\n",
      "  time_total_s: 22667.84719967842\n",
      "  timestamp: 1550903293\n",
      "  timesteps_since_restore: 9790000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9790000\n",
      "  training_iteration: 979\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22667 s, 979 iter, 9790000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-28-35\n",
      "  done: false\n",
      "  episode_len_mean: 111.69\n",
      "  episode_reward_max: 230.3789336521863\n",
      "  episode_reward_mean: 158.02653691627953\n",
      "  episode_reward_min: -163.72144639998803\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 85078\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3099.294\n",
      "    load_time_ms: 2.531\n",
      "    num_steps_sampled: 9800000\n",
      "    num_steps_trained: 9800000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7018633484840393\n",
      "      kl: 0.026223478838801384\n",
      "      policy_loss: 0.003589326748624444\n",
      "      total_loss: 36.413883209228516\n",
      "      vf_explained_var: 0.9807159304618835\n",
      "      vf_loss: 36.41029357910156\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7530413866043091\n",
      "      kl: 0.020595701411366463\n",
      "      policy_loss: -0.001093205763027072\n",
      "      total_loss: 24.861923217773438\n",
      "      vf_explained_var: 0.9842830300331116\n",
      "      vf_loss: 24.863018035888672\n",
      "    sample_time_ms: 19816.144\n",
      "    update_time_ms: 7.434\n",
      "  iterations_since_restore: 980\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.7629552529405\n",
      "    rl_1: 69.26358166333908\n",
      "  time_since_restore: 22690.59020924568\n",
      "  time_this_iter_s: 22.743009567260742\n",
      "  time_total_s: 22690.59020924568\n",
      "  timestamp: 1550903315\n",
      "  timesteps_since_restore: 9800000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9800000\n",
      "  training_iteration: 980\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22690 s, 980 iter, 9800000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-28-58\n",
      "  done: false\n",
      "  episode_len_mean: 112.11\n",
      "  episode_reward_max: 233.21518537151206\n",
      "  episode_reward_mean: 159.03807006969538\n",
      "  episode_reward_min: -163.72144639998803\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 85166\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.911\n",
      "    load_time_ms: 2.584\n",
      "    num_steps_sampled: 9810000\n",
      "    num_steps_trained: 9810000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.710337221622467\n",
      "      kl: 0.03083292581140995\n",
      "      policy_loss: 0.005332136061042547\n",
      "      total_loss: 35.84078598022461\n",
      "      vf_explained_var: 0.9742898344993591\n",
      "      vf_loss: 35.835453033447266\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7782641649246216\n",
      "      kl: 0.0248222965747118\n",
      "      policy_loss: 0.004169711377471685\n",
      "      total_loss: 30.123687744140625\n",
      "      vf_explained_var: 0.9755023121833801\n",
      "      vf_loss: 30.119522094726562\n",
      "    sample_time_ms: 19882.97\n",
      "    update_time_ms: 7.935\n",
      "  iterations_since_restore: 981\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.84213876801556\n",
      "    rl_1: 69.19593130167982\n",
      "  time_since_restore: 22713.54569220543\n",
      "  time_this_iter_s: 22.955482959747314\n",
      "  time_total_s: 22713.54569220543\n",
      "  timestamp: 1550903338\n",
      "  timesteps_since_restore: 9810000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9810000\n",
      "  training_iteration: 981\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22713 s, 981 iter, 9810000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-29-21\n",
      "  done: false\n",
      "  episode_len_mean: 112.61\n",
      "  episode_reward_max: 238.10708955991154\n",
      "  episode_reward_mean: 150.34563780460937\n",
      "  episode_reward_min: -171.76803551896825\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 85254\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3078.634\n",
      "    load_time_ms: 2.535\n",
      "    num_steps_sampled: 9820000\n",
      "    num_steps_trained: 9820000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.681721568107605\n",
      "      kl: 0.027330022305250168\n",
      "      policy_loss: 0.00177827721927315\n",
      "      total_loss: 59.44344711303711\n",
      "      vf_explained_var: 0.9673855900764465\n",
      "      vf_loss: 59.44166946411133\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7298315167427063\n",
      "      kl: 0.015228372067213058\n",
      "      policy_loss: -0.0010710430797189474\n",
      "      total_loss: 48.38528060913086\n",
      "      vf_explained_var: 0.9681051969528198\n",
      "      vf_loss: 48.386356353759766\n",
      "    sample_time_ms: 19899.166\n",
      "    update_time_ms: 7.687\n",
      "  iterations_since_restore: 982\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.33266168408485\n",
      "    rl_1: 63.0129761205245\n",
      "  time_since_restore: 22736.340355873108\n",
      "  time_this_iter_s: 22.794663667678833\n",
      "  time_total_s: 22736.340355873108\n",
      "  timestamp: 1550903361\n",
      "  timesteps_since_restore: 9820000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9820000\n",
      "  training_iteration: 982\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22736 s, 982 iter, 9820000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-29-45\n",
      "  done: false\n",
      "  episode_len_mean: 118.4\n",
      "  episode_reward_max: 230.297990768109\n",
      "  episode_reward_mean: 161.15404194531487\n",
      "  episode_reward_min: -166.82830952902546\n",
      "  episodes_this_iter: 84\n",
      "  episodes_total: 85338\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3077.193\n",
      "    load_time_ms: 2.522\n",
      "    num_steps_sampled: 9830000\n",
      "    num_steps_trained: 9830000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6030035018920898\n",
      "      kl: 0.020978908985853195\n",
      "      policy_loss: 0.0005823694518767297\n",
      "      total_loss: 16.280275344848633\n",
      "      vf_explained_var: 0.9843458533287048\n",
      "      vf_loss: 16.279693603515625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7187260389328003\n",
      "      kl: 0.01887437328696251\n",
      "      policy_loss: 0.0013539445353671908\n",
      "      total_loss: 13.466596603393555\n",
      "      vf_explained_var: 0.9859235882759094\n",
      "      vf_loss: 13.465242385864258\n",
      "    sample_time_ms: 19920.13\n",
      "    update_time_ms: 8.328\n",
      "  iterations_since_restore: 983\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.92994772098903\n",
      "    rl_1: 67.22409422432584\n",
      "  time_since_restore: 22759.63591313362\n",
      "  time_this_iter_s: 23.295557260513306\n",
      "  time_total_s: 22759.63591313362\n",
      "  timestamp: 1550903385\n",
      "  timesteps_since_restore: 9830000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9830000\n",
      "  training_iteration: 983\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22759 s, 983 iter, 9830000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-30-07\n",
      "  done: false\n",
      "  episode_len_mean: 113.18\n",
      "  episode_reward_max: 228.95972249338521\n",
      "  episode_reward_mean: 147.0900102611992\n",
      "  episode_reward_min: -144.75705562238085\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 85426\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3089.286\n",
      "    load_time_ms: 2.532\n",
      "    num_steps_sampled: 9840000\n",
      "    num_steps_trained: 9840000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6477376222610474\n",
      "      kl: 0.03596259653568268\n",
      "      policy_loss: 0.00010703351290430874\n",
      "      total_loss: 47.02846908569336\n",
      "      vf_explained_var: 0.9745611548423767\n",
      "      vf_loss: 47.02836227416992\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.752382218837738\n",
      "      kl: 0.03637176752090454\n",
      "      policy_loss: 0.0020104858558624983\n",
      "      total_loss: 41.68535614013672\n",
      "      vf_explained_var: 0.9743304252624512\n",
      "      vf_loss: 41.68334197998047\n",
      "    sample_time_ms: 19841.228\n",
      "    update_time_ms: 8.02\n",
      "  iterations_since_restore: 984\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.85123382005013\n",
      "    rl_1: 63.23877644114912\n",
      "  time_since_restore: 22782.41109585762\n",
      "  time_this_iter_s: 22.775182723999023\n",
      "  time_total_s: 22782.41109585762\n",
      "  timestamp: 1550903407\n",
      "  timesteps_since_restore: 9840000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9840000\n",
      "  training_iteration: 984\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22782 s, 984 iter, 9840000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-30-31\n",
      "  done: false\n",
      "  episode_len_mean: 116.95\n",
      "  episode_reward_max: 232.69858266714823\n",
      "  episode_reward_mean: 162.65559225303076\n",
      "  episode_reward_min: -168.64136532521718\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 85511\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3086.345\n",
      "    load_time_ms: 2.555\n",
      "    num_steps_sampled: 9850000\n",
      "    num_steps_trained: 9850000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6592262983322144\n",
      "      kl: 0.016444748267531395\n",
      "      policy_loss: 0.0017767384415492415\n",
      "      total_loss: 29.44147491455078\n",
      "      vf_explained_var: 0.9777629375457764\n",
      "      vf_loss: 29.439706802368164\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7367616295814514\n",
      "      kl: 0.02575814723968506\n",
      "      policy_loss: 0.00226806104183197\n",
      "      total_loss: 22.84607696533203\n",
      "      vf_explained_var: 0.9785574078559875\n",
      "      vf_loss: 22.84381103515625\n",
      "    sample_time_ms: 19882.564\n",
      "    update_time_ms: 7.904\n",
      "  iterations_since_restore: 985\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.50242369884221\n",
      "    rl_1: 69.15316855418853\n",
      "  time_since_restore: 22805.644847869873\n",
      "  time_this_iter_s: 23.233752012252808\n",
      "  time_total_s: 22805.644847869873\n",
      "  timestamp: 1550903431\n",
      "  timesteps_since_restore: 9850000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9850000\n",
      "  training_iteration: 985\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22805 s, 985 iter, 9850000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-30-54\n",
      "  done: false\n",
      "  episode_len_mean: 112.52\n",
      "  episode_reward_max: 227.75019082869863\n",
      "  episode_reward_mean: 159.00978864881307\n",
      "  episode_reward_min: -166.21470635724484\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 85601\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.774\n",
      "    load_time_ms: 2.546\n",
      "    num_steps_sampled: 9860000\n",
      "    num_steps_trained: 9860000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7226670384407043\n",
      "      kl: 0.02983088046312332\n",
      "      policy_loss: 0.005499781109392643\n",
      "      total_loss: 38.16313171386719\n",
      "      vf_explained_var: 0.9733650088310242\n",
      "      vf_loss: 38.15763473510742\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7734575867652893\n",
      "      kl: 0.03258541598916054\n",
      "      policy_loss: 0.0015550142852589488\n",
      "      total_loss: 31.044281005859375\n",
      "      vf_explained_var: 0.9729697108268738\n",
      "      vf_loss: 31.042720794677734\n",
      "    sample_time_ms: 19948.86\n",
      "    update_time_ms: 7.912\n",
      "  iterations_since_restore: 986\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 90.40441144001637\n",
      "    rl_1: 68.60537720879671\n",
      "  time_since_restore: 22829.121007680893\n",
      "  time_this_iter_s: 23.476159811019897\n",
      "  time_total_s: 22829.121007680893\n",
      "  timestamp: 1550903454\n",
      "  timesteps_since_restore: 9860000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9860000\n",
      "  training_iteration: 986\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22829 s, 986 iter, 9860000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-31-17\n",
      "  done: false\n",
      "  episode_len_mean: 116.39\n",
      "  episode_reward_max: 227.0784728100679\n",
      "  episode_reward_mean: 151.50194456888326\n",
      "  episode_reward_min: -173.74739141406533\n",
      "  episodes_this_iter: 86\n",
      "  episodes_total: 85687\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3083.95\n",
      "    load_time_ms: 2.577\n",
      "    num_steps_sampled: 9870000\n",
      "    num_steps_trained: 9870000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6335322856903076\n",
      "      kl: 0.03070875070989132\n",
      "      policy_loss: 0.004989749286323786\n",
      "      total_loss: 35.96422576904297\n",
      "      vf_explained_var: 0.9772300720214844\n",
      "      vf_loss: 35.95923614501953\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.679251492023468\n",
      "      kl: 0.044799093157052994\n",
      "      policy_loss: -0.0039974101819098\n",
      "      total_loss: 30.72075080871582\n",
      "      vf_explained_var: 0.9758215546607971\n",
      "      vf_loss: 30.724746704101562\n",
      "    sample_time_ms: 19880.734\n",
      "    update_time_ms: 7.96\n",
      "  iterations_since_restore: 987\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.97849777045684\n",
      "    rl_1: 62.52344679842642\n",
      "  time_since_restore: 22852.08712863922\n",
      "  time_this_iter_s: 22.966120958328247\n",
      "  time_total_s: 22852.08712863922\n",
      "  timestamp: 1550903477\n",
      "  timesteps_since_restore: 9870000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9870000\n",
      "  training_iteration: 987\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22852 s, 987 iter, 9870000 ts, 152 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-31-40\n",
      "  done: false\n",
      "  episode_len_mean: 117.97\n",
      "  episode_reward_max: 229.29341804667706\n",
      "  episode_reward_mean: 168.01171273505093\n",
      "  episode_reward_min: -140.24769461381365\n",
      "  episodes_this_iter: 87\n",
      "  episodes_total: 85774\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3085.037\n",
      "    load_time_ms: 2.577\n",
      "    num_steps_sampled: 9880000\n",
      "    num_steps_trained: 9880000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7037338614463806\n",
      "      kl: 0.028583679348230362\n",
      "      policy_loss: 0.00031891369144432247\n",
      "      total_loss: 20.611309051513672\n",
      "      vf_explained_var: 0.981246829032898\n",
      "      vf_loss: 20.610990524291992\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7466880679130554\n",
      "      kl: 0.03551195561885834\n",
      "      policy_loss: 0.010727785527706146\n",
      "      total_loss: 18.099891662597656\n",
      "      vf_explained_var: 0.9777955412864685\n",
      "      vf_loss: 18.089162826538086\n",
      "    sample_time_ms: 19870.401\n",
      "    update_time_ms: 7.96\n",
      "  iterations_since_restore: 988\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 97.54761553070546\n",
      "    rl_1: 70.46409720434548\n",
      "  time_since_restore: 22874.807788848877\n",
      "  time_this_iter_s: 22.72066020965576\n",
      "  time_total_s: 22874.807788848877\n",
      "  timestamp: 1550903500\n",
      "  timesteps_since_restore: 9880000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9880000\n",
      "  training_iteration: 988\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22874 s, 988 iter, 9880000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-32-03\n",
      "  done: false\n",
      "  episode_len_mean: 110.06\n",
      "  episode_reward_max: 226.41595330823472\n",
      "  episode_reward_mean: 159.24690786063354\n",
      "  episode_reward_min: -162.42158278193847\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 85865\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.486\n",
      "    load_time_ms: 2.585\n",
      "    num_steps_sampled: 9890000\n",
      "    num_steps_trained: 9890000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7530750036239624\n",
      "      kl: 0.021159254014492035\n",
      "      policy_loss: 0.0009593033464625478\n",
      "      total_loss: 38.62462615966797\n",
      "      vf_explained_var: 0.9752062559127808\n",
      "      vf_loss: 38.62366485595703\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7957796454429626\n",
      "      kl: 0.034819595515728\n",
      "      policy_loss: 0.006380180362612009\n",
      "      total_loss: 30.667695999145508\n",
      "      vf_explained_var: 0.9763907194137573\n",
      "      vf_loss: 30.661317825317383\n",
      "    sample_time_ms: 19885.162\n",
      "    update_time_ms: 7.776\n",
      "  iterations_since_restore: 989\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.52438501288822\n",
      "    rl_1: 69.7225228477453\n",
      "  time_since_restore: 22897.732477903366\n",
      "  time_this_iter_s: 22.924689054489136\n",
      "  time_total_s: 22897.732477903366\n",
      "  timestamp: 1550903523\n",
      "  timesteps_since_restore: 9890000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9890000\n",
      "  training_iteration: 989\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22897 s, 989 iter, 9890000 ts, 159 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-32-26\n",
      "  done: false\n",
      "  episode_len_mean: 116.24\n",
      "  episode_reward_max: 234.02537217439811\n",
      "  episode_reward_mean: 150.42853140848217\n",
      "  episode_reward_min: -169.8375626692768\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 85950\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3073.85\n",
      "    load_time_ms: 2.526\n",
      "    num_steps_sampled: 9900000\n",
      "    num_steps_trained: 9900000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.5643344521522522\n",
      "      kl: 0.021824868395924568\n",
      "      policy_loss: 0.00533814774826169\n",
      "      total_loss: 58.32260513305664\n",
      "      vf_explained_var: 0.9617354273796082\n",
      "      vf_loss: 58.31726837158203\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.657374918460846\n",
      "      kl: 0.02390809915959835\n",
      "      policy_loss: 0.002964893588796258\n",
      "      total_loss: 43.634910583496094\n",
      "      vf_explained_var: 0.968563973903656\n",
      "      vf_loss: 43.63194274902344\n",
      "    sample_time_ms: 19932.342\n",
      "    update_time_ms: 7.974\n",
      "  iterations_since_restore: 990\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 85.46674242702142\n",
      "    rl_1: 64.9617889814608\n",
      "  time_since_restore: 22920.940876960754\n",
      "  time_this_iter_s: 23.208399057388306\n",
      "  time_total_s: 22920.940876960754\n",
      "  timestamp: 1550903546\n",
      "  timesteps_since_restore: 9900000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9900000\n",
      "  training_iteration: 990\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22920 s, 990 iter, 9900000 ts, 150 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-32-49\n",
      "  done: false\n",
      "  episode_len_mean: 119.85\n",
      "  episode_reward_max: 229.46666305872438\n",
      "  episode_reward_mean: 158.1971386284191\n",
      "  episode_reward_min: -169.8375626692768\n",
      "  episodes_this_iter: 85\n",
      "  episodes_total: 86035\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.544\n",
      "    load_time_ms: 2.48\n",
      "    num_steps_sampled: 9910000\n",
      "    num_steps_trained: 9910000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6832754015922546\n",
      "      kl: 0.03781641274690628\n",
      "      policy_loss: 0.006167434621602297\n",
      "      total_loss: 31.375328063964844\n",
      "      vf_explained_var: 0.9747387766838074\n",
      "      vf_loss: 31.36916160583496\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7498313188552856\n",
      "      kl: 0.032904934138059616\n",
      "      policy_loss: 0.0013791926903650165\n",
      "      total_loss: 23.33627700805664\n",
      "      vf_explained_var: 0.976533830165863\n",
      "      vf_loss: 23.33489990234375\n",
      "    sample_time_ms: 19941.347\n",
      "    update_time_ms: 7.617\n",
      "  iterations_since_restore: 991\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 91.54967729625687\n",
      "    rl_1: 66.64746133216225\n",
      "  time_since_restore: 22943.967361927032\n",
      "  time_this_iter_s: 23.026484966278076\n",
      "  time_total_s: 22943.967361927032\n",
      "  timestamp: 1550903569\n",
      "  timesteps_since_restore: 9910000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9910000\n",
      "  training_iteration: 991\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22943 s, 991 iter, 9910000 ts, 158 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-33-12\n",
      "  done: false\n",
      "  episode_len_mean: 123.93\n",
      "  episode_reward_max: 238.1122087368044\n",
      "  episode_reward_mean: 165.57884625304186\n",
      "  episode_reward_min: -173.81782611933053\n",
      "  episodes_this_iter: 81\n",
      "  episodes_total: 86116\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3074.453\n",
      "    load_time_ms: 2.485\n",
      "    num_steps_sampled: 9920000\n",
      "    num_steps_trained: 9920000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.564659833908081\n",
      "      kl: 0.014898807741701603\n",
      "      policy_loss: 0.0038216866087168455\n",
      "      total_loss: 25.218509674072266\n",
      "      vf_explained_var: 0.9773930311203003\n",
      "      vf_loss: 25.21468734741211\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6847222447395325\n",
      "      kl: 0.02019313909113407\n",
      "      policy_loss: -0.0040021492168307304\n",
      "      total_loss: 21.303564071655273\n",
      "      vf_explained_var: 0.9782515168190002\n",
      "      vf_loss: 21.307567596435547\n",
      "    sample_time_ms: 19914.597\n",
      "    update_time_ms: 7.813\n",
      "  iterations_since_restore: 992\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 96.80886391710129\n",
      "    rl_1: 68.76998233594054\n",
      "  time_since_restore: 22966.513619184494\n",
      "  time_this_iter_s: 22.546257257461548\n",
      "  time_total_s: 22966.513619184494\n",
      "  timestamp: 1550903592\n",
      "  timesteps_since_restore: 9920000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9920000\n",
      "  training_iteration: 992\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22966 s, 992 iter, 9920000 ts, 166 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-33-35\n",
      "  done: false\n",
      "  episode_len_mean: 115.72\n",
      "  episode_reward_max: 228.07059546529072\n",
      "  episode_reward_mean: 153.80870179386548\n",
      "  episode_reward_min: -139.66268231872857\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 86204\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3072.804\n",
      "    load_time_ms: 2.512\n",
      "    num_steps_sampled: 9930000\n",
      "    num_steps_trained: 9930000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6320068836212158\n",
      "      kl: 1.2031375169754028\n",
      "      policy_loss: 0.04986952990293503\n",
      "      total_loss: 48.39769744873047\n",
      "      vf_explained_var: 0.9700468182563782\n",
      "      vf_loss: 48.34782028198242\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6838690638542175\n",
      "      kl: 0.05052371695637703\n",
      "      policy_loss: 0.0012718841899186373\n",
      "      total_loss: 38.985084533691406\n",
      "      vf_explained_var: 0.9731558561325073\n",
      "      vf_loss: 38.983821868896484\n",
      "    sample_time_ms: 19869.139\n",
      "    update_time_ms: 7.224\n",
      "  iterations_since_restore: 993\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 87.49037138701786\n",
      "    rl_1: 66.31833040684762\n",
      "  time_since_restore: 22989.332760572433\n",
      "  time_this_iter_s: 22.819141387939453\n",
      "  time_total_s: 22989.332760572433\n",
      "  timestamp: 1550903615\n",
      "  timesteps_since_restore: 9930000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9930000\n",
      "  training_iteration: 993\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 22989 s, 993 iter, 9930000 ts, 154 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-33-58\n",
      "  done: false\n",
      "  episode_len_mean: 113.02\n",
      "  episode_reward_max: 230.8448991182325\n",
      "  episode_reward_mean: 155.9034228512431\n",
      "  episode_reward_min: -158.38878871249796\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 86293\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3052.377\n",
      "    load_time_ms: 2.51\n",
      "    num_steps_sampled: 9940000\n",
      "    num_steps_trained: 9940000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6606425046920776\n",
      "      kl: 0.023495376110076904\n",
      "      policy_loss: 0.0044720652513206005\n",
      "      total_loss: 39.99230194091797\n",
      "      vf_explained_var: 0.9757095575332642\n",
      "      vf_loss: 39.987823486328125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6903328895568848\n",
      "      kl: 0.02045566402375698\n",
      "      policy_loss: 0.0012304147239774466\n",
      "      total_loss: 27.667036056518555\n",
      "      vf_explained_var: 0.9815548658370972\n",
      "      vf_loss: 27.665796279907227\n",
      "    sample_time_ms: 19897.293\n",
      "    update_time_ms: 7.376\n",
      "  iterations_since_restore: 994\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 88.1700038732084\n",
      "    rl_1: 67.7334189780347\n",
      "  time_since_restore: 23012.186948299408\n",
      "  time_this_iter_s: 22.854187726974487\n",
      "  time_total_s: 23012.186948299408\n",
      "  timestamp: 1550903638\n",
      "  timesteps_since_restore: 9940000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9940000\n",
      "  training_iteration: 994\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 23012 s, 994 iter, 9940000 ts, 156 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-34-21\n",
      "  done: false\n",
      "  episode_len_mean: 111.0\n",
      "  episode_reward_max: 234.4029011180867\n",
      "  episode_reward_mean: 146.53507325442615\n",
      "  episode_reward_min: -174.15894386203524\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 86382\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3052.295\n",
      "    load_time_ms: 2.499\n",
      "    num_steps_sampled: 9950000\n",
      "    num_steps_trained: 9950000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6908711791038513\n",
      "      kl: 0.019373439252376556\n",
      "      policy_loss: 0.0013647997984662652\n",
      "      total_loss: 56.48672103881836\n",
      "      vf_explained_var: 0.9729893803596497\n",
      "      vf_loss: 56.4853515625\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7233941555023193\n",
      "      kl: 0.016669591888785362\n",
      "      policy_loss: 0.0021684011444449425\n",
      "      total_loss: 42.72613525390625\n",
      "      vf_explained_var: 0.9764156937599182\n",
      "      vf_loss: 42.72395706176758\n",
      "    sample_time_ms: 19872.149\n",
      "    update_time_ms: 7.451\n",
      "  iterations_since_restore: 995\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 83.57068948601888\n",
      "    rl_1: 62.96438376840727\n",
      "  time_since_restore: 23035.169772148132\n",
      "  time_this_iter_s: 22.982823848724365\n",
      "  time_total_s: 23035.169772148132\n",
      "  timestamp: 1550903661\n",
      "  timesteps_since_restore: 9950000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9950000\n",
      "  training_iteration: 995\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 23035 s, 995 iter, 9950000 ts, 147 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-34-44\n",
      "  done: false\n",
      "  episode_len_mean: 112.79\n",
      "  episode_reward_max: 232.79408970656007\n",
      "  episode_reward_mean: 163.33198796461838\n",
      "  episode_reward_min: -175.9752816732716\n",
      "  episodes_this_iter: 88\n",
      "  episodes_total: 86470\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3051.035\n",
      "    load_time_ms: 2.442\n",
      "    num_steps_sampled: 9960000\n",
      "    num_steps_trained: 9960000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.6748103499412537\n",
      "      kl: 0.02069070190191269\n",
      "      policy_loss: 0.002874686848372221\n",
      "      total_loss: 30.182714462280273\n",
      "      vf_explained_var: 0.9781309962272644\n",
      "      vf_loss: 30.179838180541992\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7214841246604919\n",
      "      kl: 0.031102366745471954\n",
      "      policy_loss: -0.0023386050015687943\n",
      "      total_loss: 20.94509506225586\n",
      "      vf_explained_var: 0.9824746251106262\n",
      "      vf_loss: 20.94743537902832\n",
      "    sample_time_ms: 19824.837\n",
      "    update_time_ms: 8.108\n",
      "  iterations_since_restore: 996\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.31467511966885\n",
      "    rl_1: 71.01731284494952\n",
      "  time_since_restore: 23058.165778160095\n",
      "  time_this_iter_s: 22.99600601196289\n",
      "  time_total_s: 23058.165778160095\n",
      "  timestamp: 1550903684\n",
      "  timesteps_since_restore: 9960000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9960000\n",
      "  training_iteration: 996\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 23058 s, 996 iter, 9960000 ts, 163 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-35-08\n",
      "  done: false\n",
      "  episode_len_mean: 110.94\n",
      "  episode_reward_max: 227.95938499049714\n",
      "  episode_reward_mean: 164.3893276552981\n",
      "  episode_reward_min: -152.28740616648102\n",
      "  episodes_this_iter: 90\n",
      "  episodes_total: 86560\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3104.991\n",
      "    load_time_ms: 2.363\n",
      "    num_steps_sampled: 9970000\n",
      "    num_steps_trained: 9970000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7632231712341309\n",
      "      kl: 0.048433952033519745\n",
      "      policy_loss: 0.01067879144102335\n",
      "      total_loss: 39.1795654296875\n",
      "      vf_explained_var: 0.9689566493034363\n",
      "      vf_loss: 39.16888427734375\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.8059650659561157\n",
      "      kl: 0.038561489433050156\n",
      "      policy_loss: 0.00490680243819952\n",
      "      total_loss: 32.49852752685547\n",
      "      vf_explained_var: 0.9678757786750793\n",
      "      vf_loss: 32.493621826171875\n",
      "    sample_time_ms: 19892.439\n",
      "    update_time_ms: 7.972\n",
      "  iterations_since_restore: 997\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 92.98484742068707\n",
      "    rl_1: 71.40448023461103\n",
      "  time_since_restore: 23082.343353271484\n",
      "  time_this_iter_s: 24.17757511138916\n",
      "  time_total_s: 23082.343353271484\n",
      "  timestamp: 1550903708\n",
      "  timesteps_since_restore: 9970000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9970000\n",
      "  training_iteration: 997\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 23082 s, 997 iter, 9970000 ts, 164 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-35-31\n",
      "  done: false\n",
      "  episode_len_mean: 111.81\n",
      "  episode_reward_max: 227.00250435608237\n",
      "  episode_reward_mean: 160.58086581329883\n",
      "  episode_reward_min: -158.60120627812\n",
      "  episodes_this_iter: 91\n",
      "  episodes_total: 86651\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.17\n",
      "    load_time_ms: 2.303\n",
      "    num_steps_sampled: 9980000\n",
      "    num_steps_trained: 9980000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7971193194389343\n",
      "      kl: 0.06151280552148819\n",
      "      policy_loss: 0.02342538721859455\n",
      "      total_loss: 54.53544998168945\n",
      "      vf_explained_var: 0.9626182317733765\n",
      "      vf_loss: 54.51202392578125\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7888607382774353\n",
      "      kl: 0.010781685821712017\n",
      "      policy_loss: 0.000785253185313195\n",
      "      total_loss: 41.806156158447266\n",
      "      vf_explained_var: 0.9627097845077515\n",
      "      vf_loss: 41.80536651611328\n",
      "    sample_time_ms: 19901.943\n",
      "    update_time_ms: 7.97\n",
      "  iterations_since_restore: 998\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.07028405250338\n",
      "    rl_1: 67.51058176079543\n",
      "  time_since_restore: 23105.128729343414\n",
      "  time_this_iter_s: 22.78537607192993\n",
      "  time_total_s: 23105.128729343414\n",
      "  timestamp: 1550903731\n",
      "  timesteps_since_restore: 9980000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9980000\n",
      "  training_iteration: 998\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 23105 s, 998 iter, 9980000 ts, 161 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-35-54\n",
      "  done: false\n",
      "  episode_len_mean: 111.61\n",
      "  episode_reward_max: 237.48101045400855\n",
      "  episode_reward_mean: 167.57109458065207\n",
      "  episode_reward_min: -158.18811647874432\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 86740\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3102.852\n",
      "    load_time_ms: 2.297\n",
      "    num_steps_sampled: 9990000\n",
      "    num_steps_trained: 9990000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7267670035362244\n",
      "      kl: 0.02766990102827549\n",
      "      policy_loss: 0.0061272927559912205\n",
      "      total_loss: 41.702510833740234\n",
      "      vf_explained_var: 0.9698394536972046\n",
      "      vf_loss: 41.696372985839844\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7358459830284119\n",
      "      kl: 0.03479717671871185\n",
      "      policy_loss: 0.0020359153859317303\n",
      "      total_loss: 30.794593811035156\n",
      "      vf_explained_var: 0.9757142663002014\n",
      "      vf_loss: 30.792552947998047\n",
      "    sample_time_ms: 19916.455\n",
      "    update_time_ms: 8.002\n",
      "  iterations_since_restore: 999\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 93.53449395181353\n",
      "    rl_1: 74.03660062883847\n",
      "  time_since_restore: 23128.201821565628\n",
      "  time_this_iter_s: 23.073092222213745\n",
      "  time_total_s: 23128.201821565628\n",
      "  timestamp: 1550903754\n",
      "  timesteps_since_restore: 9990000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 9990000\n",
      "  training_iteration: 999\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "RUNNING trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tRUNNING [pid=12746], 23128 s, 999 iter, 9990000 ts, 168 rew\n",
      "\n",
      "Result for PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-02-23_07-36-17\n",
      "  done: true\n",
      "  episode_len_mean: 110.81\n",
      "  episode_reward_max: 237.48101045400855\n",
      "  episode_reward_mean: 157.08994961003972\n",
      "  episode_reward_min: -178.83785417867946\n",
      "  episodes_this_iter: 89\n",
      "  episodes_total: 86829\n",
      "  experiment_id: 1e6021831b8d437c9eb317160a4e5781\n",
      "  hostname: Gandalf\n",
      "  info:\n",
      "    grad_time_ms: 3109.352\n",
      "    load_time_ms: 2.3\n",
      "    num_steps_sampled: 10000000\n",
      "    num_steps_trained: 10000000\n",
      "    rl_0:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7738745212554932\n",
      "      kl: 0.02327972836792469\n",
      "      policy_loss: 0.0015150641556829214\n",
      "      total_loss: 29.250591278076172\n",
      "      vf_explained_var: 0.9823153614997864\n",
      "      vf_loss: 29.24907112121582\n",
      "    rl_1:\n",
      "      cur_kl_coeff: 0.0\n",
      "      cur_lr: 4.999999873689376e-05\n",
      "      entropy: -0.7696628570556641\n",
      "      kl: 0.014559543691575527\n",
      "      policy_loss: -0.0010203354759141803\n",
      "      total_loss: 22.21357536315918\n",
      "      vf_explained_var: 0.9832369685173035\n",
      "      vf_loss: 22.214599609375\n",
      "    sample_time_ms: 19925.715\n",
      "    update_time_ms: 7.868\n",
      "  iterations_since_restore: 1000\n",
      "  node_ip: 192.168.2.102\n",
      "  num_metric_batches_dropped: 0\n",
      "  pid: 12746\n",
      "  policy_reward_mean:\n",
      "    rl_0: 89.2871933824742\n",
      "    rl_1: 67.80275622756548\n",
      "  time_since_restore: 23151.567375183105\n",
      "  time_this_iter_s: 23.365553617477417\n",
      "  time_total_s: 23151.567375183105\n",
      "  timestamp: 1550903777\n",
      "  timesteps_since_restore: 10000000\n",
      "  timesteps_this_iter: 10000\n",
      "  timesteps_total: 10000000\n",
      "  training_iteration: 1000\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tTERMINATED [pid=12746], 23151 s, 1000 iter, 10000000 ts, 157 rew\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/3 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/16.4 GB\n",
      "Result logdir: /home/thorsten/ray_results/IntersectionExample\n",
      "TERMINATED trials:\n",
      " - PPO_MultiAgentTeamSpiritIntersectionEnv-v0_0:\tTERMINATED [pid=12746], 23151 s, 1000 iter, 10000000 ts, 157 rew\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    flow_params[\"exp_tag\"]: {\n",
    "        \"run\": alg_run,  # RL algorithm to run\n",
    "        \"env\": gym_name,  # environment name generated earlier\n",
    "        \"config\": {  # configuration params (must match \"run\" value)\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 1,  # number of iterations between checkpoints\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 1000,  # number of iterations to stop after\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (flow_2)",
   "language": "python",
   "name": "flow_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
